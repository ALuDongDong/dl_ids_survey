Using TensorFlow backend.
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-14 12:41:49,935 [INFO] Read 12 experiments from file: experiment_specs/additional_exps/training_time/train_time_ae_ann.csv
2020-01-14 12:41:49,935 [INFO] ================= Started running experiments ================= 

2020-01-14 12:41:49,935 [INFO] Created directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1
2020-01-14 12:41:49,935 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/run_log.log
2020-01-14 12:41:49,935 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:41:49,936 [INFO] Experiment parameters given below
2020-01-14 12:41:49,936 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.7488, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_shallow_rep1'}
2020-01-14 12:41:49,936 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/tf_logs_run_2020_01_14-12_41_49
2020-01-14 12:41:49,936 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:41:49,936 [INFO] Reading X, y files
2020-01-14 12:41:49,937 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:41:49,944 [INFO] NumExpr defaulting to 4 threads.
2020-01-14 12:41:50,196 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-14 12:41:50,196 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:41:50,260 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:41:50,260 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:41:50,318 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:41:50,318 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:41:50,325 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:41:50,326 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:41:50,329 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:41:50,330 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:41:50,333 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:41:50,484 [INFO] Initializing model
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-14 12:41:50,498 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-14 12:41:50,563 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-14 12:41:50,604 [INFO] _________________________________________________________________
2020-01-14 12:41:50,605 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:41:50,605 [INFO] =================================================================
2020-01-14 12:41:50,605 [INFO] dense_1 (Dense)              (None, 32)                3936      
2020-01-14 12:41:50,605 [INFO] _________________________________________________________________
2020-01-14 12:41:50,605 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2020-01-14 12:41:50,605 [INFO] _________________________________________________________________
2020-01-14 12:41:50,605 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2020-01-14 12:41:50,605 [INFO] _________________________________________________________________
2020-01-14 12:41:50,605 [INFO] dense_2 (Dense)              (None, 122)               4026      
2020-01-14 12:41:50,605 [INFO] =================================================================
2020-01-14 12:41:50,605 [INFO] Total params: 8,090
2020-01-14 12:41:50,605 [INFO] Trainable params: 8,026
2020-01-14 12:41:50,605 [INFO] Non-trainable params: 64
2020-01-14 12:41:50,605 [INFO] _________________________________________________________________
2020-01-14 12:41:50,713 [INFO] _________________________________________________________________
2020-01-14 12:41:50,713 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:41:50,713 [INFO] =================================================================
2020-01-14 12:41:50,713 [INFO] dense_3 (Dense)              (None, 32)                1056      
2020-01-14 12:41:50,713 [INFO] _________________________________________________________________
2020-01-14 12:41:50,713 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2020-01-14 12:41:50,713 [INFO] _________________________________________________________________
2020-01-14 12:41:50,713 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2020-01-14 12:41:50,713 [INFO] _________________________________________________________________
2020-01-14 12:41:50,713 [INFO] dense_4 (Dense)              (None, 5)                 165       
2020-01-14 12:41:50,713 [INFO] =================================================================
2020-01-14 12:41:50,713 [INFO] Total params: 1,349
2020-01-14 12:41:50,714 [INFO] Trainable params: 1,285
2020-01-14 12:41:50,714 [INFO] Non-trainable params: 64
2020-01-14 12:41:50,714 [INFO] _________________________________________________________________
2020-01-14 12:41:50,714 [INFO] Training model
2020-01-14 12:41:50,714 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3
OMP: Info #156: KMP_AFFINITY: 4 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 1 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8571 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8579 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8581 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8580 thread 2 bound to OS proc set 2
2020-01-14 12:41:51,443 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 51a9cbe8743b19744d874eb18b2edfaf06cbd363
2020-01-14 12:41:51,443 [INFO] Training autoencoder
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-14 12:41:51,817 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-14 12:41:52.108369: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-14 12:41:52.111055: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893400000 Hz
2020-01-14 12:41:52.111123: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x561e8eb33510 executing computations on platform Host. Devices:
2020-01-14 12:41:52.111132: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-14 12:41:52.111176: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8589 thread 4 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8588 thread 5 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8607 thread 6 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8608 thread 7 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 8609 thread 8 bound to OS proc set 0
Train on 50389 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.3144 - val_loss: -2.2645e-01
Epoch 2/10
 - 1s - loss: -7.1708e-01 - val_loss: -1.2859e+00
Epoch 3/10
 - 1s - loss: -1.5972e+00 - val_loss: -2.0370e+00
Epoch 4/10
 - 1s - loss: -2.2216e+00 - val_loss: -2.5659e+00
Epoch 5/10
 - 1s - loss: -2.5793e+00 - val_loss: -2.8326e+00
Epoch 6/10
 - 1s - loss: -2.7765e+00 - val_loss: -2.9764e+00
Epoch 7/10
 - 1s - loss: -2.8794e+00 - val_loss: -3.0512e+00
Epoch 8/10
 - 1s - loss: -2.9409e+00 - val_loss: -3.0926e+00
Epoch 9/10
 - 1s - loss: -2.9854e+00 - val_loss: -3.1220e+00
Epoch 10/10
 - 1s - loss: -3.0147e+00 - val_loss: -3.1418e+00
2020-01-14 12:42:01,083 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:42:02,165 [INFO] Last epoch loss evaluation: train_loss = -3.158065, val_loss = -3.141775
2020-01-14 12:42:02,165 [INFO] Training autoencoder complete
2020-01-14 12:42:02,165 [INFO] Encoding data for supervised training
2020-01-14 12:42:02,995 [INFO] Encoding complete
2020-01-14 12:42:02,995 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.2399 - val_loss: 0.0660
 - val_f1: 0.9533
 - out_of_sample_accuracy: 0.7007
Epoch 2/100
 - 0s - loss: 0.0670 - val_loss: 0.0441
 - val_f1: 0.9631
 - out_of_sample_accuracy: 0.7131
Epoch 3/100
 - 0s - loss: 0.0508 - val_loss: 0.0353
 - val_f1: 0.9667
 - out_of_sample_accuracy: 0.7344
Epoch 4/100
 - 0s - loss: 0.0429 - val_loss: 0.0299
 - val_f1: 0.9681
 - out_of_sample_accuracy: 0.7264
Epoch 5/100
 - 0s - loss: 0.0379 - val_loss: 0.0259
 - val_f1: 0.9719
 - out_of_sample_accuracy: 0.7252
Epoch 6/100
 - 0s - loss: 0.0344 - val_loss: 0.0235
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.7344
Epoch 7/100
 - 0s - loss: 0.0316 - val_loss: 0.0216
 - val_f1: 0.9812
 - out_of_sample_accuracy: 0.7314
Epoch 8/100
 - 0s - loss: 0.0294 - val_loss: 0.0202
 - val_f1: 0.9813
 - out_of_sample_accuracy: 0.7417
Epoch 9/100
 - 0s - loss: 0.0275 - val_loss: 0.0191
 - val_f1: 0.9836
 - out_of_sample_accuracy: 0.7323
Epoch 10/100
 - 0s - loss: 0.0262 - val_loss: 0.0180
 - val_f1: 0.9834
 - out_of_sample_accuracy: 0.7290
Epoch 11/100
 - 0s - loss: 0.0254 - val_loss: 0.0171
2020-01-14 12:42:15,412 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9858
 - out_of_sample_accuracy: 0.7386
Epoch 12/100
 - 0s - loss: 0.0239 - val_loss: 0.0164
 - val_f1: 0.9861
 - out_of_sample_accuracy: 0.7445
Epoch 13/100
 - 0s - loss: 0.0235 - val_loss: 0.0160
 - val_f1: 0.9871
 - out_of_sample_accuracy: 0.7411
Epoch 14/100
 - 0s - loss: 0.0232 - val_loss: 0.0160
 - val_f1: 0.9868
 - out_of_sample_accuracy: 0.7414
Epoch 15/100
 - 0s - loss: 0.0224 - val_loss: 0.0153
 - val_f1: 0.9868
 - out_of_sample_accuracy: 0.7425
Epoch 16/100
 - 0s - loss: 0.0222 - val_loss: 0.0151
2020-01-14 12:42:21,400 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7488, current_metric = 0.7492, num_epochs = 16
2020-01-14 12:42:21,400 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:42:22,360 [INFO] Last epoch loss evaluation: train_loss = 0.015819, val_loss = 0.015108
2020-01-14 12:42:22,360 [INFO] Training complete. time_to_train = 31.65 sec, 0.53 min
2020-01-14 12:42:22,515 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/best_model.pickle
2020-01-14 12:42:22,517 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/training_error_history.csv
2020-01-14 12:42:22,666 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/training_error_history.png
2020-01-14 12:42:22,809 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/training_f1_history.png
2020-01-14 12:42:22,809 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:42:25,773 [INFO] Making predictions complete. time_to_predict = 2.96 sec, 0.05 min
2020-01-14 12:42:25,776 [INFO] Evaluating predictions (results)
2020-01-14 12:42:26,353 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:42:26,353 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.80      0.87      7458
      normal       0.67      0.95      0.78      9711
       probe       0.79      0.69      0.74      2421
         r2l       0.98      0.10      0.18      2421
         u2r       1.00      0.01      0.01       533

    accuracy                           0.76     22544
   macro avg       0.88      0.51      0.52     22544
weighted avg       0.82      0.76      0.72     22544

2020-01-14 12:42:26,353 [INFO] Overall accuracy (micro avg): 0.7611337828246983
2020-01-14 12:42:26,881 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7611         0.7611                       0.7611                0.0597                   0.2389  0.7611
1     Macro avg        0.9045         0.8778                       0.5106                0.0806                   0.4894  0.5167
2  Weighted avg        0.8601         0.8156                       0.7611                0.1643                   0.2389  0.7248
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 12:42:27,500 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:42:27,500 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      1.00      0.99      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.97      0.97      2331
         r2l       0.91      0.53      0.67       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.99     25195
   macro avg       0.77      0.70      0.73     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-14 12:42:27,500 [INFO] Overall accuracy (micro avg): 0.9876959714229013
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:42:28,117 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9877         0.9877                       0.9877                0.0031                   0.0123  0.9877
1     Macro avg        0.9951         0.7738                       0.6984                0.0043                   0.3016  0.7261
2  Weighted avg        0.9921         0.9870                       0.9877                0.0093                   0.0123  0.9870
2020-01-14 12:42:30,741 [INFO] Dataset: Training. Classification report below
2020-01-14 12:42:30,741 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      1.00      0.99     36741
      normal       0.99      0.99      0.99     53874
       probe       0.98      0.96      0.97      9325
         r2l       0.91      0.53      0.67       796
         u2r       0.25      0.02      0.04        42

    accuracy                           0.99    100778
   macro avg       0.82      0.70      0.73    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-14 12:42:30,741 [INFO] Overall accuracy (micro avg): 0.9874079660243307
2020-01-14 12:42:33,557 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9874         0.9874                       0.9874                0.0031                   0.0126  0.9874
1     Macro avg        0.9950         0.8245                       0.7003                0.0045                   0.2997  0.7331
2  Weighted avg        0.9920         0.9869                       0.9874                0.0101                   0.0126  0.9867
2020-01-14 12:42:33,601 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep1/train_time_nsl_ae_ann_shallow_rep1_results.xlsx
2020-01-14 12:42:33,601 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 12:42:33,602 [INFO] Created directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2
2020-01-14 12:42:33,602 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/run_log.log
2020-01-14 12:42:33,602 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 12:42:33,602 [INFO] Experiment parameters given below
2020-01-14 12:42:33,603 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.7488, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_shallow_rep2'}
2020-01-14 12:42:33,603 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/tf_logs_run_2020_01_14-12_42_33
2020-01-14 12:42:33,603 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:42:33,603 [INFO] Reading X, y files
2020-01-14 12:42:33,603 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:42:33,843 [INFO] Reading complete. time_to_read=0.24 seconds
2020-01-14 12:42:33,843 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:42:33,907 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:42:33,907 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:42:33,965 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:42:33,965 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:42:33,973 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:42:33,973 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:42:33,977 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:42:33,977 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:42:33,981 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:42:34,140 [INFO] Initializing model
2020-01-14 12:42:34,251 [INFO] _________________________________________________________________
2020-01-14 12:42:34,251 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:42:34,251 [INFO] =================================================================
2020-01-14 12:42:34,251 [INFO] dense_5 (Dense)              (None, 32)                3936      
2020-01-14 12:42:34,251 [INFO] _________________________________________________________________
2020-01-14 12:42:34,252 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2020-01-14 12:42:34,252 [INFO] _________________________________________________________________
2020-01-14 12:42:34,252 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2020-01-14 12:42:34,252 [INFO] _________________________________________________________________
2020-01-14 12:42:34,252 [INFO] dense_6 (Dense)              (None, 122)               4026      
2020-01-14 12:42:34,252 [INFO] =================================================================
2020-01-14 12:42:34,252 [INFO] Total params: 8,090
2020-01-14 12:42:34,252 [INFO] Trainable params: 8,026
2020-01-14 12:42:34,252 [INFO] Non-trainable params: 64
2020-01-14 12:42:34,252 [INFO] _________________________________________________________________
2020-01-14 12:42:34,360 [INFO] _________________________________________________________________
2020-01-14 12:42:34,360 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:42:34,360 [INFO] =================================================================
2020-01-14 12:42:34,360 [INFO] dense_7 (Dense)              (None, 32)                1056      
2020-01-14 12:42:34,360 [INFO] _________________________________________________________________
2020-01-14 12:42:34,361 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2020-01-14 12:42:34,361 [INFO] _________________________________________________________________
2020-01-14 12:42:34,361 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2020-01-14 12:42:34,361 [INFO] _________________________________________________________________
2020-01-14 12:42:34,361 [INFO] dense_8 (Dense)              (None, 5)                 165       
2020-01-14 12:42:34,361 [INFO] =================================================================
2020-01-14 12:42:34,361 [INFO] Total params: 1,349
2020-01-14 12:42:34,361 [INFO] Trainable params: 1,285
2020-01-14 12:42:34,361 [INFO] Non-trainable params: 64
2020-01-14 12:42:34,361 [INFO] _________________________________________________________________
2020-01-14 12:42:34,361 [INFO] Training model
2020-01-14 12:42:34,361 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:42:35,079 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 9520f3af060e5da0b782da6caecda0ea205f332c
2020-01-14 12:42:35,079 [INFO] Training autoencoder
 - val_f1: 0.9870
 - out_of_sample_accuracy: 0.7492
Train on 50389 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.3164 - val_loss: -2.5322e-01
Epoch 2/10
 - 1s - loss: -7.0598e-01 - val_loss: -1.3211e+00
Epoch 3/10
 - 1s - loss: -1.6124e+00 - val_loss: -2.0555e+00
Epoch 4/10
 - 1s - loss: -2.2370e+00 - val_loss: -2.5605e+00
Epoch 5/10
 - 1s - loss: -2.5847e+00 - val_loss: -2.8234e+00
Epoch 6/10
 - 1s - loss: -2.7750e+00 - val_loss: -2.9691e+00
Epoch 7/10
 - 1s - loss: -2.8778e+00 - val_loss: -3.0435e+00
Epoch 8/10
 - 1s - loss: -2.9417e+00 - val_loss: -3.0856e+00
Epoch 9/10
 - 1s - loss: -2.9828e+00 - val_loss: -3.1124e+00
Epoch 10/10
 - 1s - loss: -3.0133e+00 - val_loss: -3.1336e+00
2020-01-14 12:42:44,811 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:42:46,066 [INFO] Last epoch loss evaluation: train_loss = -3.155070, val_loss = -3.133607
2020-01-14 12:42:46,066 [INFO] Training autoencoder complete
2020-01-14 12:42:46,066 [INFO] Encoding data for supervised training
2020-01-14 12:42:47,089 [INFO] Encoding complete
2020-01-14 12:42:47,089 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.2398 - val_loss: 0.0755
 - val_f1: 0.9513
 - out_of_sample_accuracy: 0.6876
Epoch 2/100
 - 0s - loss: 0.0745 - val_loss: 0.0517
 - val_f1: 0.9640
 - out_of_sample_accuracy: 0.7018
Epoch 3/100
 - 0s - loss: 0.0568 - val_loss: 0.0429
 - val_f1: 0.9669
 - out_of_sample_accuracy: 0.7079
Epoch 4/100
 - 0s - loss: 0.0480 - val_loss: 0.0361
 - val_f1: 0.9694
 - out_of_sample_accuracy: 0.7142
Epoch 5/100
 - 0s - loss: 0.0413 - val_loss: 0.0305
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.7216
Epoch 6/100
 - 0s - loss: 0.0365 - val_loss: 0.0259
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.7369
Epoch 7/100
 - 0s - loss: 0.0322 - val_loss: 0.0232
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.7433
Epoch 8/100
 - 0s - loss: 0.0291 - val_loss: 0.0208
2020-01-14 12:42:58,201 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7488, current_metric = 0.7598, num_epochs = 8
2020-01-14 12:42:58,202 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:42:59,321 [INFO] Last epoch loss evaluation: train_loss = 0.021421, val_loss = 0.020783
2020-01-14 12:42:59,322 [INFO] Training complete. time_to_train = 24.96 sec, 0.42 min
2020-01-14 12:42:59,822 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/best_model.pickle
2020-01-14 12:42:59,823 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/training_error_history.csv
2020-01-14 12:42:59,967 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/training_error_history.png
2020-01-14 12:43:00,110 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/training_f1_history.png
2020-01-14 12:43:00,110 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:43:03,671 [INFO] Making predictions complete. time_to_predict = 3.56 sec, 0.06 min
2020-01-14 12:43:03,674 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 12:43:04,162 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:43:04,162 [INFO] 
              precision    recall  f1-score   support

         dos       0.94      0.81      0.87      7458
      normal       0.67      0.97      0.79      9711
       probe       0.84      0.66      0.74      2421
         r2l       0.91      0.05      0.10      2421
         u2r       0.00      0.00      0.00       533

    accuracy                           0.76     22544
   macro avg       0.67      0.50      0.50     22544
weighted avg       0.79      0.76      0.72     22544

2020-01-14 12:43:04,163 [INFO] Overall accuracy (micro avg): 0.7635290986515259
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:43:04,689 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7635         0.7635                       0.7635                0.0591                   0.2365  0.7635
1     Macro avg        0.9054         0.6723                       0.4995                0.0804                   0.5005  0.5012
2  Weighted avg        0.8629         0.7875                       0.7635                0.1656                   0.2365  0.7202
2020-01-14 12:43:05,280 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:43:05,280 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99      9186
      normal       0.98      0.99      0.99     13469
       probe       0.97      0.95      0.96      2331
         r2l       0.88      0.45      0.60       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.98     25195
   macro avg       0.76      0.68      0.71     25195
weighted avg       0.98      0.98      0.98     25195

2020-01-14 12:43:05,280 [INFO] Overall accuracy (micro avg): 0.9823377654296488
2020-01-14 12:43:05,897 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9823         0.9823                       0.9823                0.0044                   0.0177  0.9823
1     Macro avg        0.9929         0.7648                       0.6771                0.0066                   0.3229  0.7071
2  Weighted avg        0.9882         0.9816                       0.9823                0.0151                   0.0177  0.9814
2020-01-14 12:43:08,525 [INFO] Dataset: Training. Classification report below
2020-01-14 12:43:08,525 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99     36741
      normal       0.98      0.99      0.99     53874
       probe       0.97      0.95      0.96      9325
         r2l       0.95      0.44      0.60       796
         u2r       0.00      0.00      0.00        42

    accuracy                           0.98    100778
   macro avg       0.78      0.67      0.71    100778
weighted avg       0.98      0.98      0.98    100778

2020-01-14 12:43:08,525 [INFO] Overall accuracy (micro avg): 0.9823374149119848
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 12:43:11,344 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9823         0.9823                       0.9823                0.0044                   0.0177  0.9823
1     Macro avg        0.9929         0.7781                       0.6743                0.0067                   0.3257  0.7078
2  Weighted avg        0.9883         0.9818                       0.9823                0.0156                   0.0177  0.9813
2020-01-14 12:43:11,383 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep2/train_time_nsl_ae_ann_shallow_rep2_results.xlsx
2020-01-14 12:43:11,383 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 12:43:11,384 [INFO] Created directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3
2020-01-14 12:43:11,384 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/run_log.log
2020-01-14 12:43:11,384 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 12:43:11,384 [INFO] Experiment parameters given below
2020-01-14 12:43:11,384 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.7488, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_shallow_rep3'}
2020-01-14 12:43:11,421 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/tf_logs_run_2020_01_14-12_43_11
2020-01-14 12:43:11,421 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:43:11,421 [INFO] Reading X, y files
2020-01-14 12:43:11,421 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:43:11,664 [INFO] Reading complete. time_to_read=0.24 seconds
2020-01-14 12:43:11,664 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:43:11,730 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 12:43:11,730 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:43:11,790 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:43:11,790 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:43:11,798 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:43:11,798 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:43:11,802 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:43:11,802 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:43:11,806 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:43:11,965 [INFO] Initializing model
2020-01-14 12:43:12,077 [INFO] _________________________________________________________________
2020-01-14 12:43:12,077 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:12,077 [INFO] =================================================================
2020-01-14 12:43:12,077 [INFO] dense_9 (Dense)              (None, 32)                3936      
2020-01-14 12:43:12,077 [INFO] _________________________________________________________________
2020-01-14 12:43:12,077 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2020-01-14 12:43:12,077 [INFO] _________________________________________________________________
2020-01-14 12:43:12,077 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2020-01-14 12:43:12,077 [INFO] _________________________________________________________________
2020-01-14 12:43:12,078 [INFO] dense_10 (Dense)             (None, 122)               4026      
2020-01-14 12:43:12,078 [INFO] =================================================================
2020-01-14 12:43:12,078 [INFO] Total params: 8,090
2020-01-14 12:43:12,078 [INFO] Trainable params: 8,026
2020-01-14 12:43:12,078 [INFO] Non-trainable params: 64
2020-01-14 12:43:12,078 [INFO] _________________________________________________________________
2020-01-14 12:43:12,187 [INFO] _________________________________________________________________
2020-01-14 12:43:12,187 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:12,187 [INFO] =================================================================
2020-01-14 12:43:12,188 [INFO] dense_11 (Dense)             (None, 32)                1056      
2020-01-14 12:43:12,188 [INFO] _________________________________________________________________
2020-01-14 12:43:12,188 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2020-01-14 12:43:12,188 [INFO] _________________________________________________________________
2020-01-14 12:43:12,188 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2020-01-14 12:43:12,188 [INFO] _________________________________________________________________
2020-01-14 12:43:12,188 [INFO] dense_12 (Dense)             (None, 5)                 165       
2020-01-14 12:43:12,188 [INFO] =================================================================
2020-01-14 12:43:12,188 [INFO] Total params: 1,349
2020-01-14 12:43:12,188 [INFO] Trainable params: 1,285
2020-01-14 12:43:12,188 [INFO] Non-trainable params: 64
2020-01-14 12:43:12,188 [INFO] _________________________________________________________________
2020-01-14 12:43:12,188 [INFO] Training model
2020-01-14 12:43:12,188 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:43:12,942 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 7a252d242df3cf90c886d978731486932b1607c3
2020-01-14 12:43:12,943 [INFO] Training autoencoder
 - val_f1: 0.9812
 - out_of_sample_accuracy: 0.7598
Train on 50389 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.3284 - val_loss: -2.2428e-01
Epoch 2/10
 - 1s - loss: -6.8323e-01 - val_loss: -1.2731e+00
Epoch 3/10
 - 1s - loss: -1.5920e+00 - val_loss: -2.0360e+00
Epoch 4/10
 - 1s - loss: -2.2275e+00 - val_loss: -2.5745e+00
Epoch 5/10
 - 1s - loss: -2.5841e+00 - val_loss: -2.8346e+00
Epoch 6/10
 - 1s - loss: -2.7772e+00 - val_loss: -2.9776e+00
Epoch 7/10
 - 1s - loss: -2.8817e+00 - val_loss: -3.0516e+00
Epoch 8/10
 - 1s - loss: -2.9454e+00 - val_loss: -3.0940e+00
Epoch 9/10
 - 1s - loss: -2.9879e+00 - val_loss: -3.1232e+00
Epoch 10/10
 - 1s - loss: -3.0182e+00 - val_loss: -3.1407e+00
2020-01-14 12:43:23,082 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:43:24,491 [INFO] Last epoch loss evaluation: train_loss = -3.156621, val_loss = -3.140662
2020-01-14 12:43:24,491 [INFO] Training autoencoder complete
2020-01-14 12:43:24,491 [INFO] Encoding data for supervised training
2020-01-14 12:43:25,686 [INFO] Encoding complete
2020-01-14 12:43:25,686 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.1821 - val_loss: 0.0603
 - val_f1: 0.9601
 - out_of_sample_accuracy: 0.7159
Epoch 2/100
 - 0s - loss: 0.0630 - val_loss: 0.0464
 - val_f1: 0.9666
 - out_of_sample_accuracy: 0.7248
Epoch 3/100
 - 0s - loss: 0.0515 - val_loss: 0.0399
 - val_f1: 0.9682
 - out_of_sample_accuracy: 0.7316
Epoch 4/100
 - 0s - loss: 0.0448 - val_loss: 0.0346
 - val_f1: 0.9694
 - out_of_sample_accuracy: 0.7425
Epoch 5/100
 - 0s - loss: 0.0397 - val_loss: 0.0304
 - val_f1: 0.9726
 - out_of_sample_accuracy: 0.7407
Epoch 6/100
 - 0s - loss: 0.0353 - val_loss: 0.0271
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.7428
Epoch 7/100
 - 0s - loss: 0.0328 - val_loss: 0.0247
 - val_f1: 0.9783
 - out_of_sample_accuracy: 0.7437
Epoch 8/100
 - 0s - loss: 0.0309 - val_loss: 0.0231
2020-01-14 12:43:37,842 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7488, current_metric = 0.7516, num_epochs = 8
2020-01-14 12:43:37,843 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:43:39,132 [INFO] Last epoch loss evaluation: train_loss = 0.023011, val_loss = 0.023096
2020-01-14 12:43:39,132 [INFO] Training complete. time_to_train = 26.94 sec, 0.45 min
2020-01-14 12:43:39,898 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/best_model.pickle
2020-01-14 12:43:39,899 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/training_error_history.csv
2020-01-14 12:43:40,055 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/training_error_history.png
2020-01-14 12:43:40,205 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/training_f1_history.png
2020-01-14 12:43:40,205 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:43:44,113 [INFO] Making predictions complete. time_to_predict = 3.91 sec, 0.07 min
2020-01-14 12:43:44,116 [INFO] Evaluating predictions (results)
2020-01-14 12:43:44,607 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:43:44,607 [INFO] 
              precision    recall  f1-score   support

         dos       0.93      0.82      0.87      7458
      normal       0.68      0.93      0.78      9711
       probe       0.70      0.68      0.69      2421
         r2l       0.98      0.12      0.21      2421
         u2r       0.44      0.01      0.01       533

    accuracy                           0.76     22544
   macro avg       0.75      0.51      0.51     22544
weighted avg       0.79      0.76      0.72     22544

2020-01-14 12:43:44,607 [INFO] Overall accuracy (micro avg): 0.7560770049680624
2020-01-14 12:43:45,136 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7561         0.7561                       0.7561                0.0610                   0.2439  0.7561
1     Macro avg        0.9024         0.7463                       0.5107                0.0805                   0.4893  0.5141
2  Weighted avg        0.8594         0.7891                       0.7561                0.1588                   0.2439  0.7218
2020-01-14 12:43:45,730 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:43:45,730 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.98      0.98      9186
      normal       0.97      0.99      0.98     13469
       probe       0.97      0.96      0.96      2331
         r2l       0.92      0.54      0.68       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.98     25195
   macro avg       0.77      0.69      0.72     25195
weighted avg       0.98      0.98      0.98     25195

2020-01-14 12:43:45,731 [INFO] Overall accuracy (micro avg): 0.9792816034927565
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 12:43:46,350 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9793         0.9793                       0.9793                0.0052                   0.0207  0.9793
1     Macro avg        0.9917         0.7721                       0.6936                0.0079                   0.3064  0.7229
2  Weighted avg        0.9850         0.9789                       0.9793                0.0188                   0.0207  0.9786
2020-01-14 12:43:48,980 [INFO] Dataset: Training. Classification report below
2020-01-14 12:43:48,980 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.98      0.98     36741
      normal       0.97      0.99      0.98     53874
       probe       0.97      0.94      0.96      9325
         r2l       0.91      0.53      0.67       796
         u2r       0.15      0.05      0.07        42

    accuracy                           0.98    100778
   macro avg       0.80      0.70      0.73    100778
weighted avg       0.98      0.98      0.98    100778

2020-01-14 12:43:48,980 [INFO] Overall accuracy (micro avg): 0.9788445890968267
2020-01-14 12:43:51,801 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9788         0.9788                       0.9788                0.0053                   0.0212  0.9788
1     Macro avg        0.9915         0.7999                       0.6987                0.0081                   0.3013  0.7338
2  Weighted avg        0.9851         0.9784                       0.9788                0.0191                   0.0212  0.9782
2020-01-14 12:43:51,839 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_shallow_rep3/train_time_nsl_ae_ann_shallow_rep3_results.xlsx
2020-01-14 12:43:51,839 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 12:43:51,840 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1
2020-01-14 12:43:51,840 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/run_log.log
2020-01-14 12:43:51,840 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:43:51,840 [INFO] Experiment parameters given below
2020-01-14 12:43:51,840 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.983858128, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_shallow_rep1'}
2020-01-14 12:43:51,840 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/tf_logs_run_2020_01_14-12_43_51
2020-01-14 12:43:51,840 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 12:43:51,850 [INFO] Reading X, y files
2020-01-14 12:43:51,850 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 12:44:03,418 [INFO] Reading complete. time_to_read=11.57 seconds
2020-01-14 12:44:03,418 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 12:44:07,526 [INFO] Reading complete. time_to_read=4.11 seconds
2020-01-14 12:44:07,526 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 12:44:11,649 [INFO] Reading complete. time_to_read=4.12 seconds
2020-01-14 12:44:11,649 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 12:44:12,423 [INFO] Reading complete. time_to_read=0.77 seconds
2020-01-14 12:44:12,423 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 12:44:12,732 [INFO] Reading complete. time_to_read=0.31 seconds
2020-01-14 12:44:12,732 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 12:44:13,021 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-14 12:44:16,039 [INFO] Initializing model
2020-01-14 12:44:16,152 [INFO] _________________________________________________________________
2020-01-14 12:44:16,153 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:44:16,153 [INFO] =================================================================
2020-01-14 12:44:16,153 [INFO] dense_13 (Dense)             (None, 32)                2528      
2020-01-14 12:44:16,153 [INFO] _________________________________________________________________
2020-01-14 12:44:16,153 [INFO] batch_normalization_7 (Batch (None, 32)                128       
2020-01-14 12:44:16,153 [INFO] _________________________________________________________________
2020-01-14 12:44:16,153 [INFO] dropout_7 (Dropout)          (None, 32)                0         
2020-01-14 12:44:16,153 [INFO] _________________________________________________________________
2020-01-14 12:44:16,153 [INFO] dense_14 (Dense)             (None, 78)                2574      
2020-01-14 12:44:16,153 [INFO] =================================================================
2020-01-14 12:44:16,153 [INFO] Total params: 5,230
2020-01-14 12:44:16,153 [INFO] Trainable params: 5,166
2020-01-14 12:44:16,153 [INFO] Non-trainable params: 64
2020-01-14 12:44:16,153 [INFO] _________________________________________________________________
2020-01-14 12:44:16,265 [INFO] _________________________________________________________________
2020-01-14 12:44:16,265 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:44:16,265 [INFO] =================================================================
2020-01-14 12:44:16,265 [INFO] dense_15 (Dense)             (None, 32)                1056      
2020-01-14 12:44:16,265 [INFO] _________________________________________________________________
2020-01-14 12:44:16,265 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2020-01-14 12:44:16,265 [INFO] _________________________________________________________________
2020-01-14 12:44:16,265 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2020-01-14 12:44:16,265 [INFO] _________________________________________________________________
2020-01-14 12:44:16,265 [INFO] dense_16 (Dense)             (None, 12)                396       
2020-01-14 12:44:16,265 [INFO] =================================================================
2020-01-14 12:44:16,266 [INFO] Total params: 1,580
2020-01-14 12:44:16,266 [INFO] Trainable params: 1,516
2020-01-14 12:44:16,266 [INFO] Non-trainable params: 64
2020-01-14 12:44:16,266 [INFO] _________________________________________________________________
2020-01-14 12:44:16,266 [INFO] Training model
2020-01-14 12:44:16,266 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:44:34,945 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 3dedcc180c22d0914dcea1928cb4f9e49083fd46
2020-01-14 12:44:34,946 [INFO] Training autoencoder
 - val_f1: 0.9786
 - out_of_sample_accuracy: 0.7516
Train on 848342 samples, validate on 565562 samples
Epoch 1/10
 - 12s - loss: -3.3899e+00 - val_loss: -4.1001e+00
Epoch 2/10
 - 11s - loss: -4.0276e+00 - val_loss: -4.1259e+00
Epoch 3/10
 - 11s - loss: -4.0545e+00 - val_loss: -4.1314e+00
Epoch 4/10
 - 11s - loss: -4.0664e+00 - val_loss: -4.1350e+00
Epoch 5/10
 - 11s - loss: -4.0726e+00 - val_loss: -4.1365e+00
Epoch 6/10
 - 11s - loss: -4.0769e+00 - val_loss: -4.1380e+00
Epoch 7/10
 - 11s - loss: -4.0806e+00 - val_loss: -4.1401e+00
Epoch 8/10
 - 11s - loss: -4.0826e+00 - val_loss: -4.1404e+00
Epoch 9/10
 - 11s - loss: -4.0850e+00 - val_loss: -4.1416e+00
Epoch 10/10
 - 11s - loss: -4.0869e+00 - val_loss: -4.1412e+00
2020-01-14 12:46:31,412 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:46:56,612 [INFO] Last epoch loss evaluation: train_loss = -4.141483, val_loss = -4.141590
2020-01-14 12:46:56,612 [INFO] Training autoencoder complete
2020-01-14 12:46:56,612 [INFO] Encoding data for supervised training
2020-01-14 12:47:18,460 [INFO] Encoding complete
2020-01-14 12:47:18,460 [INFO] Training neural network layers (after autoencoder)
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 8s - loss: 0.0314 - val_loss: 0.0141
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 9054 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 9056 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 8571 tid 9055 thread 10 bound to OS proc set 2
 - val_f1: 0.9614
 - out_of_sample_accuracy: 0.9627
Epoch 2/100
 - 7s - loss: 0.0150 - val_loss: 0.0119
 - val_f1: 0.9676
 - out_of_sample_accuracy: 0.9689
Epoch 3/100
 - 7s - loss: 0.0134 - val_loss: 0.0112
 - val_f1: 0.9690
 - out_of_sample_accuracy: 0.9695
Epoch 4/100
 - 7s - loss: 0.0127 - val_loss: 0.0123
 - val_f1: 0.9541
 - out_of_sample_accuracy: 0.9578
Epoch 5/100
 - 7s - loss: 0.0122 - val_loss: 0.0108
 - val_f1: 0.9704
 - out_of_sample_accuracy: 0.9709
Epoch 6/100
 - 7s - loss: 0.0118 - val_loss: 0.0107
 - val_f1: 0.9710
 - out_of_sample_accuracy: 0.9713
Epoch 7/100
 - 7s - loss: 0.0115 - val_loss: 0.0130
 - val_f1: 0.9499
 - out_of_sample_accuracy: 0.9545
Epoch 8/100
 - 7s - loss: 0.0113 - val_loss: 0.0101
 - val_f1: 0.9719
 - out_of_sample_accuracy: 0.9724
Epoch 9/100
 - 7s - loss: 0.0112 - val_loss: 0.0092
 - val_f1: 0.9733
 - out_of_sample_accuracy: 0.9735
Epoch 10/100
 - 7s - loss: 0.0111 - val_loss: 0.0116
 - val_f1: 0.9603
 - out_of_sample_accuracy: 0.9630
Epoch 11/100
 - 7s - loss: 0.0109 - val_loss: 0.0093
2020-01-14 12:52:42,807 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9737
 - out_of_sample_accuracy: 0.9743
Epoch 12/100
 - 7s - loss: 0.0108 - val_loss: 0.0106
 - val_f1: 0.9712
 - out_of_sample_accuracy: 0.9720
Epoch 13/100
 - 7s - loss: 0.0108 - val_loss: 0.0096
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9771
Epoch 14/100
 - 7s - loss: 0.0107 - val_loss: 0.0095
 - val_f1: 0.9735
 - out_of_sample_accuracy: 0.9740
Epoch 15/100
 - 7s - loss: 0.0106 - val_loss: 0.0103
 - val_f1: 0.9732
 - out_of_sample_accuracy: 0.9739
Epoch 16/100
 - 7s - loss: 0.0105 - val_loss: 0.0091
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9748
Epoch 17/100
 - 7s - loss: 0.0106 - val_loss: 0.0091
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9745
Epoch 18/100
 - 7s - loss: 0.0105 - val_loss: 0.0091
 - val_f1: 0.9734
 - out_of_sample_accuracy: 0.9741
Epoch 19/100
 - 7s - loss: 0.0105 - val_loss: 0.0099
 - val_f1: 0.9745
 - out_of_sample_accuracy: 0.9753
Epoch 20/100
 - 7s - loss: 0.0104 - val_loss: 0.0090
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9755
Epoch 21/100
 - 7s - loss: 0.0103 - val_loss: 0.0097
2020-01-14 12:57:56,551 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9754
Epoch 22/100
 - 7s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9744
Epoch 23/100
 - 7s - loss: 0.0103 - val_loss: 0.0100
 - val_f1: 0.9732
 - out_of_sample_accuracy: 0.9741
Epoch 24/100
 - 7s - loss: 0.0102 - val_loss: 0.0117
 - val_f1: 0.9580
 - out_of_sample_accuracy: 0.9617
Epoch 25/100
 - 7s - loss: 0.0102 - val_loss: 0.0097
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9751
Epoch 26/100
 - 7s - loss: 0.0102 - val_loss: 0.0105
 - val_f1: 0.9627
 - out_of_sample_accuracy: 0.9655
Epoch 27/100
 - 7s - loss: 0.0103 - val_loss: 0.0089
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9751
Epoch 28/100
 - 7s - loss: 0.0102 - val_loss: 0.0098
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9756
Epoch 29/100
 - 7s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9736
 - out_of_sample_accuracy: 0.9740
Epoch 30/100
 - 7s - loss: 0.0101 - val_loss: 0.0088
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9761
Epoch 31/100
 - 7s - loss: 0.0101 - val_loss: 0.0087
2020-01-14 13:03:10,898 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9758
Epoch 32/100
 - 7s - loss: 0.0101 - val_loss: 0.0098
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9755
Epoch 33/100
 - 7s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9766
Epoch 34/100
 - 7s - loss: 0.0100 - val_loss: 0.0102
 - val_f1: 0.9640
 - out_of_sample_accuracy: 0.9665
Epoch 35/100
 - 7s - loss: 0.0100 - val_loss: 0.0094
 - val_f1: 0.9739
 - out_of_sample_accuracy: 0.9747
Epoch 36/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9785
Epoch 37/100
 - 7s - loss: 0.0099 - val_loss: 0.0091
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9760
Epoch 38/100
 - 7s - loss: 0.0099 - val_loss: 0.0092
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9767
Epoch 39/100
 - 7s - loss: 0.0099 - val_loss: 0.0100
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9748
Epoch 40/100
 - 7s - loss: 0.0099 - val_loss: 0.0083
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9760
Epoch 41/100
 - 7s - loss: 0.0098 - val_loss: 0.0096
2020-01-14 13:08:26,567 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9699
 - out_of_sample_accuracy: 0.9712
Epoch 42/100
 - 7s - loss: 0.0098 - val_loss: 0.0088
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9803
Epoch 43/100
 - 7s - loss: 0.0098 - val_loss: 0.0092
 - val_f1: 0.9736
 - out_of_sample_accuracy: 0.9746
Epoch 44/100
 - 7s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9762
Epoch 45/100
 - 7s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9768
Epoch 46/100
 - 7s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9773
Epoch 47/100
 - 7s - loss: 0.0098 - val_loss: 0.0094
 - val_f1: 0.9747
 - out_of_sample_accuracy: 0.9756
Epoch 48/100
 - 7s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9764
Epoch 49/100
 - 7s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9770
Epoch 50/100
 - 7s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 51/100
 - 7s - loss: 0.0097 - val_loss: 0.0082
2020-01-14 13:13:41,626 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_50.pickle
 - val_f1: 0.9790
 - out_of_sample_accuracy: 0.9793
Epoch 52/100
 - 7s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9765
Epoch 53/100
 - 7s - loss: 0.0097 - val_loss: 0.0091
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9776
Epoch 54/100
 - 7s - loss: 0.0098 - val_loss: 0.0099
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9750
Epoch 55/100
 - 7s - loss: 0.0097 - val_loss: 0.0097
 - val_f1: 0.9733
 - out_of_sample_accuracy: 0.9745
Epoch 56/100
 - 7s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9756
Epoch 57/100
 - 7s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.9803
Epoch 58/100
 - 7s - loss: 0.0097 - val_loss: 0.0099
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9750
Epoch 59/100
 - 7s - loss: 0.0096 - val_loss: 0.0094
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9768
Epoch 60/100
 - 7s - loss: 0.0097 - val_loss: 0.0083
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9795
Epoch 61/100
 - 7s - loss: 0.0096 - val_loss: 0.0095
2020-01-14 13:18:56,745 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 62/100
 - 7s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9792
 - out_of_sample_accuracy: 0.9796
Epoch 63/100
 - 7s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9778
Epoch 64/100
 - 7s - loss: 0.0096 - val_loss: 0.0101
 - val_f1: 0.9734
 - out_of_sample_accuracy: 0.9744
Epoch 65/100
 - 7s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9788
 - out_of_sample_accuracy: 0.9793
Epoch 66/100
 - 7s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9791
 - out_of_sample_accuracy: 0.9795
Epoch 67/100
 - 7s - loss: 0.0096 - val_loss: 0.0098
 - val_f1: 0.9689
 - out_of_sample_accuracy: 0.9703
Epoch 68/100
 - 7s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9764
Epoch 69/100
 - 7s - loss: 0.0096 - val_loss: 0.0093
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9793
Epoch 70/100
 - 7s - loss: 0.0096 - val_loss: 0.0082
 - val_f1: 0.9772
 - out_of_sample_accuracy: 0.9777
Epoch 71/100
 - 7s - loss: 0.0095 - val_loss: 0.0081
2020-01-14 13:24:12,131 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_70.pickle
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9759
Epoch 72/100
 - 7s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9761
Epoch 73/100
 - 7s - loss: 0.0096 - val_loss: 0.0093
 - val_f1: 0.9704
 - out_of_sample_accuracy: 0.9718
Epoch 74/100
 - 7s - loss: 0.0095 - val_loss: 0.0090
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9766
Epoch 75/100
 - 7s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9775
Epoch 76/100
 - 7s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9780
Epoch 77/100
 - 7s - loss: 0.0095 - val_loss: 0.0105
 - val_f1: 0.9678
 - out_of_sample_accuracy: 0.9694
Epoch 78/100
 - 7s - loss: 0.0096 - val_loss: 0.0090
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9765
Epoch 79/100
 - 7s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9764
Epoch 80/100
 - 7s - loss: 0.0095 - val_loss: 0.0079
 - val_f1: 0.9800
 - out_of_sample_accuracy: 0.9805
Epoch 81/100
 - 7s - loss: 0.0095 - val_loss: 0.0093
2020-01-14 13:29:27,447 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9745
Epoch 82/100
 - 7s - loss: 0.0095 - val_loss: 0.0097
 - val_f1: 0.9670
 - out_of_sample_accuracy: 0.9690
Epoch 83/100
 - 7s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9764
Epoch 84/100
 - 7s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9764
Epoch 85/100
 - 7s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9786
 - out_of_sample_accuracy: 0.9791
Epoch 86/100
 - 7s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9806
 - out_of_sample_accuracy: 0.9811
Epoch 87/100
 - 7s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9774
Epoch 88/100
 - 7s - loss: 0.0095 - val_loss: 0.0090
 - val_f1: 0.9714
 - out_of_sample_accuracy: 0.9717
Epoch 89/100
 - 7s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9772
Epoch 90/100
 - 7s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9765
Epoch 91/100
 - 7s - loss: 0.0094 - val_loss: 0.0104
2020-01-14 13:34:42,471 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9683
 - out_of_sample_accuracy: 0.9697
Epoch 92/100
 - 7s - loss: 0.0094 - val_loss: 0.0091
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9771
Epoch 93/100
 - 7s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9765
Epoch 94/100
 - 7s - loss: 0.0094 - val_loss: 0.0114
 - val_f1: 0.9654
 - out_of_sample_accuracy: 0.9677
Epoch 95/100
 - 7s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9782
Epoch 96/100
 - 7s - loss: 0.0094 - val_loss: 0.0089
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9758
Epoch 97/100
 - 7s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9775
Epoch 98/100
 - 7s - loss: 0.0094 - val_loss: 0.0088
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9791
Epoch 99/100
 - 7s - loss: 0.0094 - val_loss: 0.0097
 - val_f1: 0.9696
 - out_of_sample_accuracy: 0.9709
Epoch 100/100
 - 7s - loss: 0.0094 - val_loss: 0.0090
2020-01-14 13:39:51,238 [INFO] StopperOnGoal: did not reach goal, num_epochs = 100
2020-01-14 13:39:51,238 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 13:40:15,538 [INFO] Last epoch loss evaluation: train_loss = 0.007755, val_loss = 0.007941
2020-01-14 13:40:15,544 [INFO] Training complete. time_to_train = 3359.28 sec, 55.99 min
2020-01-14 13:40:16,077 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/best_model.pickle
2020-01-14 13:40:16,079 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/training_error_history.csv
2020-01-14 13:40:16,221 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/training_error_history.png
2020-01-14 13:40:16,364 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/training_f1_history.png
2020-01-14 13:40:16,364 [INFO] Making predictions on training, validation, testing data
2020-01-14 13:41:37,122 [INFO] Making predictions complete. time_to_predict = 80.76 sec, 1.35 min
2020-01-14 13:41:37,182 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 13:41:55,522 [INFO] Dataset: Testing. Classification report below
2020-01-14 13:41:55,523 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99    454265
                   Bot       1.00      0.01      0.01       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.96      0.97      2058
              DoS Hulk       0.95      0.99      0.97     46025
      DoS Slowhttptest       0.87      0.95      0.91      1100
         DoS slowloris       0.98      0.90      0.94      1159
           FTP-Patator       0.97      0.98      0.97      1587
              PortScan       0.87      0.95      0.91     31761
           SSH-Patator       0.93      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.98    565562
             macro avg       0.80      0.72      0.72    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 13:41:55,523 [INFO] Overall accuracy (micro avg): 0.9805962918300735
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 13:42:15,333 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9806         0.9806                       0.9806                0.0018                   0.0194  0.9806
1     Macro avg        0.9968         0.7954                       0.7237                0.0040                   0.2763  0.7180
2  Weighted avg        0.9835         0.9806                       0.9806                0.0280                   0.0194  0.9801
2020-01-14 13:42:33,903 [INFO] Dataset: Validation. Classification report below
2020-01-14 13:42:33,903 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99    454264
                   Bot       1.00      0.01      0.02       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.95      0.96      2059
              DoS Hulk       0.95      0.99      0.97     46025
      DoS Slowhttptest       0.88      0.94      0.91      1099
         DoS slowloris       0.97      0.90      0.93      1159
           FTP-Patator       0.97      0.97      0.97      1587
              PortScan       0.87      0.95      0.91     31761
           SSH-Patator       0.94      0.97      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.98    565562
             macro avg       0.80      0.72      0.72    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 13:42:33,903 [INFO] Overall accuracy (micro avg): 0.9804406943889441
2020-01-14 13:42:53,955 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9804         0.9804                       0.9804                0.0018                   0.0196  0.9804
1     Macro avg        0.9967         0.7953                       0.7202                0.0039                   0.2798  0.7166
2  Weighted avg        0.9833         0.9804                       0.9804                0.0278                   0.0196  0.9800
2020-01-14 13:43:55,824 [INFO] Dataset: Training. Classification report below
2020-01-14 13:43:55,824 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99   1362791
                   Bot       1.00      0.01      0.01      1174
                  DDoS       1.00      0.98      0.99     76815
         DoS GoldenEye       0.98      0.96      0.97      6176
              DoS Hulk       0.95      0.99      0.97    138074
      DoS Slowhttptest       0.88      0.95      0.91      3300
         DoS slowloris       0.97      0.92      0.94      3478
           FTP-Patator       0.97      0.98      0.97      4761
              PortScan       0.87      0.95      0.91     95282
           SSH-Patator       0.94      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.98   1696684
             macro avg       0.80      0.72      0.72   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 13:43:55,824 [INFO] Overall accuracy (micro avg): 0.9807442045778707
2020-01-14 13:45:02,523 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9807         0.9807                       0.9807                0.0018                   0.0193  0.9807
1     Macro avg        0.9968         0.7970                       0.7236                0.0039                   0.2764  0.7190
2  Weighted avg        0.9836         0.9807                       0.9807                0.0274                   0.0193  0.9803
2020-01-14 13:45:02,575 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep1/train_time_ids17_ae_ann_shallow_rep1_results.xlsx
2020-01-14 13:45:02,580 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 13:45:02,618 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2
2020-01-14 13:45:02,618 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/run_log.log
2020-01-14 13:45:02,618 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 13:45:02,618 [INFO] Experiment parameters given below
2020-01-14 13:45:02,618 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.983858128, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_shallow_rep2'}
2020-01-14 13:45:02,618 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/tf_logs_run_2020_01_14-13_45_02
2020-01-14 13:45:02,618 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 13:45:02,618 [INFO] Reading X, y files
2020-01-14 13:45:02,618 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 13:45:08,281 [INFO] Reading complete. time_to_read=5.66 seconds
2020-01-14 13:45:08,282 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 13:45:09,667 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 13:45:09,667 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 13:45:11,057 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 13:45:11,057 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 13:45:11,280 [INFO] Reading complete. time_to_read=0.22 seconds
2020-01-14 13:45:11,280 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 13:45:11,359 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 13:45:11,359 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 13:45:11,437 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 13:45:14,757 [INFO] Initializing model
2020-01-14 13:45:14,956 [INFO] _________________________________________________________________
2020-01-14 13:45:14,956 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 13:45:14,956 [INFO] =================================================================
2020-01-14 13:45:14,956 [INFO] dense_17 (Dense)             (None, 32)                2528      
2020-01-14 13:45:14,956 [INFO] _________________________________________________________________
2020-01-14 13:45:14,956 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2020-01-14 13:45:14,956 [INFO] _________________________________________________________________
2020-01-14 13:45:14,956 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2020-01-14 13:45:14,956 [INFO] _________________________________________________________________
2020-01-14 13:45:14,956 [INFO] dense_18 (Dense)             (None, 78)                2574      
2020-01-14 13:45:14,956 [INFO] =================================================================
2020-01-14 13:45:14,957 [INFO] Total params: 5,230
2020-01-14 13:45:14,957 [INFO] Trainable params: 5,166
2020-01-14 13:45:14,957 [INFO] Non-trainable params: 64
2020-01-14 13:45:14,957 [INFO] _________________________________________________________________
2020-01-14 13:45:15,068 [INFO] _________________________________________________________________
2020-01-14 13:45:15,068 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 13:45:15,068 [INFO] =================================================================
2020-01-14 13:45:15,068 [INFO] dense_19 (Dense)             (None, 32)                1056      
2020-01-14 13:45:15,068 [INFO] _________________________________________________________________
2020-01-14 13:45:15,068 [INFO] batch_normalization_10 (Batc (None, 32)                128       
2020-01-14 13:45:15,068 [INFO] _________________________________________________________________
2020-01-14 13:45:15,068 [INFO] dropout_10 (Dropout)         (None, 32)                0         
2020-01-14 13:45:15,069 [INFO] _________________________________________________________________
2020-01-14 13:45:15,069 [INFO] dense_20 (Dense)             (None, 12)                396       
2020-01-14 13:45:15,069 [INFO] =================================================================
2020-01-14 13:45:15,069 [INFO] Total params: 1,580
2020-01-14 13:45:15,069 [INFO] Trainable params: 1,516
2020-01-14 13:45:15,069 [INFO] Non-trainable params: 64
2020-01-14 13:45:15,069 [INFO] _________________________________________________________________
2020-01-14 13:45:15,069 [INFO] Training model
2020-01-14 13:45:15,069 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 13:45:34,064 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 609509110c4168678d4b2dd4d7b12a60795582ba
2020-01-14 13:45:34,064 [INFO] Training autoencoder
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9767
Train on 848342 samples, validate on 565562 samples
Epoch 1/10
 - 13s - loss: -3.3671e+00 - val_loss: -4.0985e+00
Epoch 2/10
 - 12s - loss: -4.0274e+00 - val_loss: -4.1244e+00
Epoch 3/10
 - 12s - loss: -4.0540e+00 - val_loss: -4.1317e+00
Epoch 4/10
 - 12s - loss: -4.0640e+00 - val_loss: -4.1325e+00
Epoch 5/10
 - 12s - loss: -4.0710e+00 - val_loss: -4.1367e+00
Epoch 6/10
 - 12s - loss: -4.0766e+00 - val_loss: -4.1375e+00
Epoch 7/10
 - 12s - loss: -4.0799e+00 - val_loss: -4.1386e+00
Epoch 8/10
 - 12s - loss: -4.0829e+00 - val_loss: -4.1415e+00
Epoch 9/10
 - 12s - loss: -4.0853e+00 - val_loss: -4.1406e+00
Epoch 10/10
 - 12s - loss: -4.0874e+00 - val_loss: -4.1419e+00
2020-01-14 13:47:33,181 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 13:48:00,858 [INFO] Last epoch loss evaluation: train_loss = -4.142956, val_loss = -4.141921
2020-01-14 13:48:00,858 [INFO] Training autoencoder complete
2020-01-14 13:48:00,858 [INFO] Encoding data for supervised training
2020-01-14 13:48:23,951 [INFO] Encoding complete
2020-01-14 13:48:23,952 [INFO] Training neural network layers (after autoencoder)
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 8s - loss: 0.0327 - val_loss: 0.0139
 - val_f1: 0.9631
 - out_of_sample_accuracy: 0.9649
Epoch 2/100
 - 7s - loss: 0.0155 - val_loss: 0.0117
 - val_f1: 0.9683
 - out_of_sample_accuracy: 0.9692
Epoch 3/100
 - 7s - loss: 0.0138 - val_loss: 0.0115
 - val_f1: 0.9680
 - out_of_sample_accuracy: 0.9693
Epoch 4/100
 - 7s - loss: 0.0128 - val_loss: 0.0108
 - val_f1: 0.9713
 - out_of_sample_accuracy: 0.9720
Epoch 5/100
 - 7s - loss: 0.0123 - val_loss: 0.0098
 - val_f1: 0.9732
 - out_of_sample_accuracy: 0.9733
Epoch 6/100
 - 7s - loss: 0.0120 - val_loss: 0.0109
 - val_f1: 0.9718
 - out_of_sample_accuracy: 0.9725
Epoch 7/100
 - 7s - loss: 0.0118 - val_loss: 0.0097
 - val_f1: 0.9720
 - out_of_sample_accuracy: 0.9726
Epoch 8/100
 - 7s - loss: 0.0115 - val_loss: 0.0104
 - val_f1: 0.9720
 - out_of_sample_accuracy: 0.9730
Epoch 9/100
 - 7s - loss: 0.0113 - val_loss: 0.0096
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9752
Epoch 10/100
 - 7s - loss: 0.0112 - val_loss: 0.0099
 - val_f1: 0.9732
 - out_of_sample_accuracy: 0.9736
Epoch 11/100
 - 7s - loss: 0.0111 - val_loss: 0.0090
2020-01-14 13:54:12,025 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_10.pickle
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9753
Epoch 12/100
 - 7s - loss: 0.0110 - val_loss: 0.0094
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9748
Epoch 13/100
 - 7s - loss: 0.0110 - val_loss: 0.0092
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9751
Epoch 14/100
 - 7s - loss: 0.0109 - val_loss: 0.0100
 - val_f1: 0.9734
 - out_of_sample_accuracy: 0.9740
Epoch 15/100
 - 7s - loss: 0.0108 - val_loss: 0.0091
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9761
Epoch 16/100
 - 7s - loss: 0.0108 - val_loss: 0.0087
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9756
Epoch 17/100
 - 7s - loss: 0.0106 - val_loss: 0.0091
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9752
Epoch 18/100
 - 7s - loss: 0.0106 - val_loss: 0.0097
 - val_f1: 0.9718
 - out_of_sample_accuracy: 0.9727
Epoch 19/100
 - 7s - loss: 0.0105 - val_loss: 0.0088
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9781
Epoch 20/100
 - 7s - loss: 0.0105 - val_loss: 0.0091
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9768
Epoch 21/100
 - 7s - loss: 0.0104 - val_loss: 0.0089
2020-01-14 13:59:50,414 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9766
Epoch 22/100
 - 7s - loss: 0.0104 - val_loss: 0.0086
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9757
Epoch 23/100
 - 7s - loss: 0.0104 - val_loss: 0.0091
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9748
Epoch 24/100
 - 7s - loss: 0.0103 - val_loss: 0.0087
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9768
Epoch 25/100
 - 7s - loss: 0.0103 - val_loss: 0.0090
 - val_f1: 0.9745
 - out_of_sample_accuracy: 0.9751
Epoch 26/100
 - 7s - loss: 0.0103 - val_loss: 0.0095
 - val_f1: 0.9737
 - out_of_sample_accuracy: 0.9743
Epoch 27/100
 - 7s - loss: 0.0102 - val_loss: 0.0095
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9754
Epoch 28/100
 - 7s - loss: 0.0102 - val_loss: 0.0086
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9750
Epoch 29/100
 - 7s - loss: 0.0102 - val_loss: 0.0084
 - val_f1: 0.9788
 - out_of_sample_accuracy: 0.9792
Epoch 30/100
 - 7s - loss: 0.0101 - val_loss: 0.0093
 - val_f1: 0.9739
 - out_of_sample_accuracy: 0.9746
Epoch 31/100
 - 7s - loss: 0.0101 - val_loss: 0.0093
2020-01-14 14:05:29,308 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 32/100
 - 7s - loss: 0.0101 - val_loss: 0.0099
 - val_f1: 0.9734
 - out_of_sample_accuracy: 0.9741
Epoch 33/100
 - 7s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9769
Epoch 34/100
 - 7s - loss: 0.0101 - val_loss: 0.0092
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9759
Epoch 35/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9785
Epoch 36/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9756
Epoch 37/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9751
Epoch 38/100
 - 7s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9751
Epoch 39/100
 - 7s - loss: 0.0100 - val_loss: 0.0092
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9747
Epoch 40/100
 - 7s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9747
 - out_of_sample_accuracy: 0.9750
Epoch 41/100
 - 7s - loss: 0.0099 - val_loss: 0.0083
2020-01-14 14:11:07,847 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9807
 - out_of_sample_accuracy: 0.9810
Epoch 42/100
 - 7s - loss: 0.0099 - val_loss: 0.0098
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9756
Epoch 43/100
 - 7s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9770
Epoch 44/100
 - 7s - loss: 0.0098 - val_loss: 0.0091
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9761
Epoch 45/100
 - 7s - loss: 0.0099 - val_loss: 0.0092
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9754
Epoch 46/100
 - 7s - loss: 0.0098 - val_loss: 0.0092
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 47/100
 - 7s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9757
Epoch 48/100
 - 7s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9764
Epoch 49/100
 - 7s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9778
Epoch 50/100
 - 7s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9772
Epoch 51/100
 - 7s - loss: 0.0098 - val_loss: 0.0101
2020-01-14 14:16:47,101 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_50.pickle
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9745
Epoch 52/100
 - 7s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9747
Epoch 53/100
 - 7s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 54/100
 - 7s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9753
Epoch 55/100
 - 7s - loss: 0.0098 - val_loss: 0.0080
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9772
Epoch 56/100
 - 7s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9759
Epoch 57/100
 - 7s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9761
Epoch 58/100
 - 7s - loss: 0.0097 - val_loss: 0.0081
 - val_f1: 0.9783
 - out_of_sample_accuracy: 0.9786
Epoch 59/100
 - 7s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9759
Epoch 60/100
 - 7s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9767
Epoch 61/100
 - 7s - loss: 0.0097 - val_loss: 0.0090
2020-01-14 14:22:26,759 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9758
Epoch 62/100
 - 7s - loss: 0.0097 - val_loss: 0.0081
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9770
Epoch 63/100
 - 7s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9747
 - out_of_sample_accuracy: 0.9755
Epoch 64/100
 - 7s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9769
Epoch 65/100
 - 7s - loss: 0.0097 - val_loss: 0.0092
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9755
Epoch 66/100
 - 7s - loss: 0.0096 - val_loss: 0.0079
 - val_f1: 0.9815
 - out_of_sample_accuracy: 0.9817
Epoch 67/100
 - 7s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9775
Epoch 68/100
 - 7s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9807
 - out_of_sample_accuracy: 0.9810
Epoch 69/100
 - 7s - loss: 0.0096 - val_loss: 0.0089
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9770
Epoch 70/100
 - 7s - loss: 0.0096 - val_loss: 0.0116
 - val_f1: 0.9745
 - out_of_sample_accuracy: 0.9753
Epoch 71/100
 - 7s - loss: 0.0096 - val_loss: 0.0083
2020-01-14 14:28:06,079 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_70.pickle
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9765
Epoch 72/100
 - 7s - loss: 0.0096 - val_loss: 0.0079
 - val_f1: 0.9816
 - out_of_sample_accuracy: 0.9818
Epoch 73/100
 - 7s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9800
 - out_of_sample_accuracy: 0.9803
Epoch 74/100
 - 7s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9768
Epoch 75/100
 - 7s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9766
Epoch 76/100
 - 7s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 77/100
 - 7s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9768
Epoch 78/100
 - 7s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9769
Epoch 79/100
 - 7s - loss: 0.0096 - val_loss: 0.0082
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9775
Epoch 80/100
 - 7s - loss: 0.0095 - val_loss: 0.0089
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9771
Epoch 81/100
 - 7s - loss: 0.0095 - val_loss: 0.0082
2020-01-14 14:33:44,966 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 82/100
 - 7s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9753
Epoch 83/100
 - 7s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9762
Epoch 84/100
 - 7s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9774
Epoch 85/100
 - 7s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9773
Epoch 86/100
 - 7s - loss: 0.0095 - val_loss: 0.0095
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9759
Epoch 87/100
 - 7s - loss: 0.0094 - val_loss: 0.0098
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9754
Epoch 88/100
 - 7s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9772
 - out_of_sample_accuracy: 0.9776
Epoch 89/100
 - 7s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 90/100
 - 7s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9777
Epoch 91/100
 - 7s - loss: 0.0094 - val_loss: 0.0093
2020-01-14 14:39:24,742 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9771
Epoch 92/100
 - 7s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9773
Epoch 93/100
 - 7s - loss: 0.0094 - val_loss: 0.0090
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 94/100
 - 7s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.9805
Epoch 95/100
 - 7s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9775
Epoch 96/100
 - 7s - loss: 0.0094 - val_loss: 0.0080
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9769
Epoch 97/100
 - 7s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9769
Epoch 98/100
 - 7s - loss: 0.0094 - val_loss: 0.0096
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9763
Epoch 99/100
 - 7s - loss: 0.0094 - val_loss: 0.0080
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9763
Epoch 100/100
 - 7s - loss: 0.0094 - val_loss: 0.0085
2020-01-14 14:44:57,371 [INFO] StopperOnGoal: did not reach goal, num_epochs = 100
2020-01-14 14:44:57,371 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 14:45:23,636 [INFO] Last epoch loss evaluation: train_loss = 0.007718, val_loss = 0.007876
2020-01-14 14:45:23,642 [INFO] Training complete. time_to_train = 3608.57 sec, 60.14 min
2020-01-14 14:45:24,292 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/best_model.pickle
2020-01-14 14:45:24,294 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/training_error_history.csv
2020-01-14 14:45:24,469 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/training_error_history.png
2020-01-14 14:45:24,617 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/training_f1_history.png
2020-01-14 14:45:24,617 [INFO] Making predictions on training, validation, testing data
2020-01-14 14:46:52,629 [INFO] Making predictions complete. time_to_predict = 88.01 sec, 1.47 min
2020-01-14 14:46:52,688 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 14:47:11,005 [INFO] Dataset: Testing. Classification report below
2020-01-14 14:47:11,006 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       1.00      0.35      0.52       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.99      0.94      0.96      2058
              DoS Hulk       0.97      0.98      0.97     46025
      DoS Slowhttptest       0.86      0.95      0.91      1100
         DoS slowloris       0.98      0.90      0.94      1159
           FTP-Patator       0.98      0.98      0.98      1587
              PortScan       0.86      0.95      0.91     31761
           SSH-Patator       0.93      0.93      0.93      1179
Web Attack Brute Force       1.00      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.98    565562
             macro avg       0.88      0.75      0.77    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 14:47:11,006 [INFO] Overall accuracy (micro avg): 0.9818057083043061
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 14:47:30,785 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9818         0.9818                       0.9818                0.0017                   0.0182  0.9818
1     Macro avg        0.9970         0.8801                       0.7526                0.0037                   0.2474  0.7681
2  Weighted avg        0.9846         0.9824                       0.9818                0.0263                   0.0182  0.9816
2020-01-14 14:47:49,538 [INFO] Dataset: Validation. Classification report below
2020-01-14 14:47:49,538 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       1.00      0.31      0.47       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.99      0.93      0.96      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.87      0.94      0.90      1099
         DoS slowloris       0.97      0.91      0.94      1159
           FTP-Patator       0.97      0.97      0.97      1587
              PortScan       0.86      0.96      0.91     31761
           SSH-Patator       0.95      0.94      0.95      1180
Web Attack Brute Force       1.00      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.98    565562
             macro avg       0.88      0.75      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 14:47:49,538 [INFO] Overall accuracy (micro avg): 0.9818339987481478
2020-01-14 14:48:09,725 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9818         0.9818                       0.9818                0.0017                   0.0182  0.9818
1     Macro avg        0.9970         0.8804                       0.7463                0.0037                   0.2537  0.7602
2  Weighted avg        0.9846         0.9825                       0.9818                0.0258                   0.0182  0.9816
2020-01-14 14:49:11,661 [INFO] Dataset: Training. Classification report below
2020-01-14 14:49:11,661 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       1.00      0.35      0.51      1174
                  DDoS       1.00      0.98      0.99     76815
         DoS GoldenEye       0.99      0.94      0.96      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.88      0.95      0.91      3300
         DoS slowloris       0.98      0.92      0.95      3478
           FTP-Patator       0.98      0.98      0.98      4761
              PortScan       0.86      0.96      0.91     95282
           SSH-Patator       0.96      0.94      0.95      3538
Web Attack Brute Force       1.00      0.04      0.08       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.98   1696684
             macro avg       0.88      0.75      0.77   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 14:49:11,661 [INFO] Overall accuracy (micro avg): 0.982164032901825
2020-01-14 14:50:18,355 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9822         0.9822                       0.9822                0.0016                   0.0178  0.9822
1     Macro avg        0.9970         0.8828                       0.7528                0.0036                   0.2472  0.7677
2  Weighted avg        0.9848         0.9828                       0.9822                0.0253                   0.0178  0.9820
2020-01-14 14:50:18,418 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep2/train_time_ids17_ae_ann_shallow_rep2_results.xlsx
2020-01-14 14:50:18,424 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 14:50:18,463 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3
2020-01-14 14:50:18,463 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/run_log.log
2020-01-14 14:50:18,463 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 14:50:18,463 [INFO] Experiment parameters given below
2020-01-14 14:50:18,463 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.983858128, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_shallow_rep3'}
2020-01-14 14:50:18,491 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/tf_logs_run_2020_01_14-14_50_18
2020-01-14 14:50:18,491 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 14:50:18,492 [INFO] Reading X, y files
2020-01-14 14:50:18,492 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 14:50:25,767 [INFO] Reading complete. time_to_read=7.28 seconds
2020-01-14 14:50:25,767 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 14:50:27,392 [INFO] Reading complete. time_to_read=1.62 seconds
2020-01-14 14:50:27,392 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 14:50:29,041 [INFO] Reading complete. time_to_read=1.65 seconds
2020-01-14 14:50:29,041 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 14:50:29,273 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 14:50:29,273 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 14:50:29,384 [INFO] Reading complete. time_to_read=0.11 seconds
2020-01-14 14:50:29,384 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 14:50:29,504 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-14 14:50:33,328 [INFO] Initializing model
2020-01-14 14:50:33,444 [INFO] _________________________________________________________________
2020-01-14 14:50:33,444 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 14:50:33,444 [INFO] =================================================================
2020-01-14 14:50:33,444 [INFO] dense_21 (Dense)             (None, 32)                2528      
2020-01-14 14:50:33,445 [INFO] _________________________________________________________________
2020-01-14 14:50:33,445 [INFO] batch_normalization_11 (Batc (None, 32)                128       
2020-01-14 14:50:33,445 [INFO] _________________________________________________________________
2020-01-14 14:50:33,445 [INFO] dropout_11 (Dropout)         (None, 32)                0         
2020-01-14 14:50:33,445 [INFO] _________________________________________________________________
2020-01-14 14:50:33,445 [INFO] dense_22 (Dense)             (None, 78)                2574      
2020-01-14 14:50:33,445 [INFO] =================================================================
2020-01-14 14:50:33,445 [INFO] Total params: 5,230
2020-01-14 14:50:33,445 [INFO] Trainable params: 5,166
2020-01-14 14:50:33,445 [INFO] Non-trainable params: 64
2020-01-14 14:50:33,445 [INFO] _________________________________________________________________
2020-01-14 14:50:33,557 [INFO] _________________________________________________________________
2020-01-14 14:50:33,557 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 14:50:33,558 [INFO] =================================================================
2020-01-14 14:50:33,558 [INFO] dense_23 (Dense)             (None, 32)                1056      
2020-01-14 14:50:33,558 [INFO] _________________________________________________________________
2020-01-14 14:50:33,558 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2020-01-14 14:50:33,558 [INFO] _________________________________________________________________
2020-01-14 14:50:33,558 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2020-01-14 14:50:33,558 [INFO] _________________________________________________________________
2020-01-14 14:50:33,558 [INFO] dense_24 (Dense)             (None, 12)                396       
2020-01-14 14:50:33,558 [INFO] =================================================================
2020-01-14 14:50:33,558 [INFO] Total params: 1,580
2020-01-14 14:50:33,558 [INFO] Trainable params: 1,516
2020-01-14 14:50:33,558 [INFO] Non-trainable params: 64
2020-01-14 14:50:33,558 [INFO] _________________________________________________________________
2020-01-14 14:50:33,558 [INFO] Training model
2020-01-14 14:50:33,558 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 14:50:52,553 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = c969d90dae5b00d7d68ae9b44952fef4bc153a3c
2020-01-14 14:50:52,553 [INFO] Training autoencoder
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9763
Train on 848342 samples, validate on 565562 samples
Epoch 1/10
 - 13s - loss: -3.3771e+00 - val_loss: -4.1019e+00
Epoch 2/10
 - 12s - loss: -4.0273e+00 - val_loss: -4.1250e+00
Epoch 3/10
 - 12s - loss: -4.0530e+00 - val_loss: -4.1312e+00
Epoch 4/10
 - 12s - loss: -4.0642e+00 - val_loss: -4.1323e+00
Epoch 5/10
 - 12s - loss: -4.0695e+00 - val_loss: -4.1372e+00
Epoch 6/10
 - 12s - loss: -4.0741e+00 - val_loss: -4.1378e+00
Epoch 7/10
 - 12s - loss: -4.0769e+00 - val_loss: -4.1379e+00
Epoch 8/10
 - 12s - loss: -4.0789e+00 - val_loss: -4.1395e+00
Epoch 9/10
 - 12s - loss: -4.0802e+00 - val_loss: -4.1403e+00
Epoch 10/10
 - 12s - loss: -4.0819e+00 - val_loss: -4.1411e+00
2020-01-14 14:52:53,327 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 14:53:24,439 [INFO] Last epoch loss evaluation: train_loss = -4.139708, val_loss = -4.141087
2020-01-14 14:53:24,439 [INFO] Training autoencoder complete
2020-01-14 14:53:24,439 [INFO] Encoding data for supervised training
2020-01-14 14:53:49,031 [INFO] Encoding complete
2020-01-14 14:53:49,031 [INFO] Training neural network layers (after autoencoder)
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 8s - loss: 0.0331 - val_loss: 0.0141
 - val_f1: 0.9634
 - out_of_sample_accuracy: 0.9644
Epoch 2/100
 - 7s - loss: 0.0160 - val_loss: 0.0124
 - val_f1: 0.9674
 - out_of_sample_accuracy: 0.9680
Epoch 3/100
 - 7s - loss: 0.0141 - val_loss: 0.0111
 - val_f1: 0.9708
 - out_of_sample_accuracy: 0.9702
Epoch 4/100
 - 7s - loss: 0.0133 - val_loss: 0.0113
 - val_f1: 0.9711
 - out_of_sample_accuracy: 0.9718
Epoch 5/100
 - 7s - loss: 0.0126 - val_loss: 0.0106
 - val_f1: 0.9725
 - out_of_sample_accuracy: 0.9732
Epoch 6/100
 - 7s - loss: 0.0121 - val_loss: 0.0097
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9758
Epoch 7/100
 - 7s - loss: 0.0119 - val_loss: 0.0098
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9756
Epoch 8/100
 - 7s - loss: 0.0116 - val_loss: 0.0095
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9741
Epoch 9/100
 - 7s - loss: 0.0115 - val_loss: 0.0092
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9766
Epoch 10/100
 - 7s - loss: 0.0113 - val_loss: 0.0104
 - val_f1: 0.9728
 - out_of_sample_accuracy: 0.9734
Epoch 11/100
 - 7s - loss: 0.0112 - val_loss: 0.0092
2020-01-14 15:00:08,846 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9739
 - out_of_sample_accuracy: 0.9742
Epoch 12/100
 - 7s - loss: 0.0112 - val_loss: 0.0092
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9751
Epoch 13/100
 - 7s - loss: 0.0110 - val_loss: 0.0096
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9765
Epoch 14/100
 - 7s - loss: 0.0110 - val_loss: 0.0096
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9760
Epoch 15/100
 - 7s - loss: 0.0109 - val_loss: 0.0092
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9762
Epoch 16/100
 - 7s - loss: 0.0109 - val_loss: 0.0092
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9775
Epoch 17/100
 - 7s - loss: 0.0108 - val_loss: 0.0097
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 18/100
 - 7s - loss: 0.0108 - val_loss: 0.0094
 - val_f1: 0.9743
 - out_of_sample_accuracy: 0.9746
Epoch 19/100
 - 7s - loss: 0.0108 - val_loss: 0.0103
 - val_f1: 0.9728
 - out_of_sample_accuracy: 0.9732
Epoch 20/100
 - 7s - loss: 0.0107 - val_loss: 0.0088
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9746
Epoch 21/100
 - 7s - loss: 0.0107 - val_loss: 0.0097
2020-01-14 15:06:18,186 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9744
 - out_of_sample_accuracy: 0.9746
Epoch 22/100
 - 7s - loss: 0.0106 - val_loss: 0.0085
 - val_f1: 0.9784
 - out_of_sample_accuracy: 0.9789
Epoch 23/100
 - 7s - loss: 0.0106 - val_loss: 0.0093
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9764
Epoch 24/100
 - 7s - loss: 0.0105 - val_loss: 0.0090
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9753
Epoch 25/100
 - 7s - loss: 0.0105 - val_loss: 0.0086
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9779
Epoch 26/100
 - 7s - loss: 0.0105 - val_loss: 0.0093
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9744
Epoch 27/100
 - 7s - loss: 0.0105 - val_loss: 0.0096
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9747
Epoch 28/100
 - 7s - loss: 0.0105 - val_loss: 0.0086
 - val_f1: 0.9791
 - out_of_sample_accuracy: 0.9796
Epoch 29/100
 - 7s - loss: 0.0104 - val_loss: 0.0085
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9751
Epoch 30/100
 - 7s - loss: 0.0103 - val_loss: 0.0087
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9765
Epoch 31/100
 - 7s - loss: 0.0104 - val_loss: 0.0088
2020-01-14 15:12:27,499 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9779
Epoch 32/100
 - 7s - loss: 0.0103 - val_loss: 0.0086
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9774
Epoch 33/100
 - 7s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9781
 - out_of_sample_accuracy: 0.9786
Epoch 34/100
 - 7s - loss: 0.0103 - val_loss: 0.0085
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9772
Epoch 35/100
 - 7s - loss: 0.0103 - val_loss: 0.0086
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9755
Epoch 36/100
 - 7s - loss: 0.0103 - val_loss: 0.0094
 - val_f1: 0.9693
 - out_of_sample_accuracy: 0.9705
Epoch 37/100
 - 7s - loss: 0.0102 - val_loss: 0.0091
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9762
Epoch 38/100
 - 7s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9773
Epoch 39/100
 - 7s - loss: 0.0103 - val_loss: 0.0090
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9758
Epoch 40/100
 - 7s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9770
Epoch 41/100
 - 7s - loss: 0.0102 - val_loss: 0.0089
2020-01-14 15:18:37,583 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9763
Epoch 42/100
 - 7s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9767
Epoch 43/100
 - 7s - loss: 0.0101 - val_loss: 0.0105
 - val_f1: 0.9722
 - out_of_sample_accuracy: 0.9732
Epoch 44/100
 - 7s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9775
Epoch 45/100
 - 7s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9758
Epoch 46/100
 - 7s - loss: 0.0101 - val_loss: 0.0088
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9745
Epoch 47/100
 - 7s - loss: 0.0101 - val_loss: 0.0084
 - val_f1: 0.9743
 - out_of_sample_accuracy: 0.9746
Epoch 48/100
 - 7s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9793
Epoch 49/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9755
Epoch 50/100
 - 7s - loss: 0.0100 - val_loss: 0.0082
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9781
Epoch 51/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
2020-01-14 15:24:47,228 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_50.pickle
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9767
Epoch 52/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9772
Epoch 53/100
 - 7s - loss: 0.0101 - val_loss: 0.0084
 - val_f1: 0.9806
 - out_of_sample_accuracy: 0.9808
Epoch 54/100
 - 7s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9782
Epoch 55/100
 - 7s - loss: 0.0100 - val_loss: 0.0083
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9776
Epoch 56/100
 - 7s - loss: 0.0101 - val_loss: 0.0081
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9771
Epoch 57/100
 - 7s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9757
Epoch 58/100
 - 7s - loss: 0.0099 - val_loss: 0.0100
 - val_f1: 0.9736
 - out_of_sample_accuracy: 0.9741
Epoch 59/100
 - 7s - loss: 0.0100 - val_loss: 0.0080
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9775
Epoch 60/100
 - 7s - loss: 0.0100 - val_loss: 0.0083
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9778
Epoch 61/100
 - 7s - loss: 0.0099 - val_loss: 0.0081
2020-01-14 15:30:56,446 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9807
Epoch 62/100
 - 7s - loss: 0.0100 - val_loss: 0.0081
 - val_f1: 0.9810
 - out_of_sample_accuracy: 0.9815
Epoch 63/100
 - 7s - loss: 0.0099 - val_loss: 0.0079
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9797
Epoch 64/100
 - 7s - loss: 0.0099 - val_loss: 0.0081
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9790
Epoch 65/100
 - 7s - loss: 0.0099 - val_loss: 0.0084
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9755
Epoch 66/100
 - 7s - loss: 0.0099 - val_loss: 0.0083
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9767
Epoch 67/100
 - 7s - loss: 0.0099 - val_loss: 0.0080
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9793
Epoch 68/100
 - 7s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9779
Epoch 69/100
 - 7s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9776
Epoch 70/100
 - 7s - loss: 0.0099 - val_loss: 0.0080
 - val_f1: 0.9792
 - out_of_sample_accuracy: 0.9796
Epoch 71/100
 - 7s - loss: 0.0099 - val_loss: 0.0082
2020-01-14 15:37:05,778 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_70.pickle
 - val_f1: 0.9790
 - out_of_sample_accuracy: 0.9794
Epoch 72/100
 - 7s - loss: 0.0098 - val_loss: 0.0093
 - val_f1: 0.9736
 - out_of_sample_accuracy: 0.9744
Epoch 73/100
 - 7s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9785
Epoch 74/100
 - 7s - loss: 0.0098 - val_loss: 0.0092
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9762
Epoch 75/100
 - 7s - loss: 0.0098 - val_loss: 0.0080
 - val_f1: 0.9786
 - out_of_sample_accuracy: 0.9787
Epoch 76/100
 - 7s - loss: 0.0098 - val_loss: 0.0092
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9757
Epoch 77/100
 - 7s - loss: 0.0098 - val_loss: 0.0090
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9766
Epoch 78/100
 - 7s - loss: 0.0098 - val_loss: 0.0079
 - val_f1: 0.9799
 - out_of_sample_accuracy: 0.9802
Epoch 79/100
 - 7s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9778
Epoch 80/100
 - 7s - loss: 0.0098 - val_loss: 0.0078
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9789
Epoch 81/100
 - 7s - loss: 0.0097 - val_loss: 0.0078
2020-01-14 15:43:14,862 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9763
Epoch 82/100
 - 7s - loss: 0.0098 - val_loss: 0.0096
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9766
Epoch 83/100
 - 7s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9789
Epoch 84/100
 - 7s - loss: 0.0097 - val_loss: 0.0101
 - val_f1: 0.9729
 - out_of_sample_accuracy: 0.9738
Epoch 85/100
 - 7s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9780
Epoch 86/100
 - 7s - loss: 0.0098 - val_loss: 0.0089
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9741
Epoch 87/100
 - 7s - loss: 0.0097 - val_loss: 0.0083
 - val_f1: 0.9814
 - out_of_sample_accuracy: 0.9816
Epoch 88/100
 - 7s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9759
Epoch 89/100
 - 7s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9796
 - out_of_sample_accuracy: 0.9802
Epoch 90/100
 - 7s - loss: 0.0097 - val_loss: 0.0079
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9776
Epoch 91/100
 - 7s - loss: 0.0097 - val_loss: 0.0085
2020-01-14 15:49:21,085 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9755
Epoch 92/100
 - 7s - loss: 0.0097 - val_loss: 0.0079
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9784
Epoch 93/100
 - 7s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9792
Epoch 94/100
 - 7s - loss: 0.0097 - val_loss: 0.0096
 - val_f1: 0.9686
 - out_of_sample_accuracy: 0.9701
Epoch 95/100
 - 7s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9773
Epoch 96/100
 - 7s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9781
Epoch 97/100
 - 7s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9745
Epoch 98/100
 - 7s - loss: 0.0097 - val_loss: 0.0092
 - val_f1: 0.9715
 - out_of_sample_accuracy: 0.9725
Epoch 99/100
 - 7s - loss: 0.0096 - val_loss: 0.0081
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9786
Epoch 100/100
 - 7s - loss: 0.0096 - val_loss: 0.0083
2020-01-14 15:55:19,248 [INFO] StopperOnGoal: did not reach goal, num_epochs = 100
2020-01-14 15:55:19,248 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 15:55:47,713 [INFO] Last epoch loss evaluation: train_loss = 0.007648, val_loss = 0.007792
2020-01-14 15:55:47,720 [INFO] Training complete. time_to_train = 3914.16 sec, 65.24 min
2020-01-14 15:55:48,494 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/best_model.pickle
2020-01-14 15:55:48,496 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/training_error_history.csv
2020-01-14 15:55:48,640 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/training_error_history.png
2020-01-14 15:55:48,782 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/training_f1_history.png
2020-01-14 15:55:48,782 [INFO] Making predictions on training, validation, testing data
2020-01-14 15:57:23,423 [INFO] Making predictions complete. time_to_predict = 94.64 sec, 1.58 min
2020-01-14 15:57:23,482 [INFO] Evaluating predictions (results)
2020-01-14 15:57:41,803 [INFO] Dataset: Testing. Classification report below
2020-01-14 15:57:41,803 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.98      0.99      0.99    454265
                   Bot       0.60      0.03      0.06       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.95      0.96      2058
              DoS Hulk       0.99      0.91      0.95     46025
      DoS Slowhttptest       0.88      0.96      0.92      1100
         DoS slowloris       0.98      0.92      0.95      1159
           FTP-Patator       0.99      0.94      0.96      1587
              PortScan       0.90      0.94      0.92     31761
           SSH-Patator       0.97      0.89      0.93      1179
Web Attack Brute Force       0.80      0.05      0.10       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.98    565562
             macro avg       0.84      0.71      0.73    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 15:57:41,803 [INFO] Overall accuracy (micro avg): 0.9790332448078195
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 15:58:01,537 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9790         0.9790                       0.9790                0.0019                   0.0210  0.9790
1     Macro avg        0.9965         0.8394                       0.7129                0.0064                   0.2871  0.7268
2  Weighted avg        0.9821         0.9788                       0.9790                0.0561                   0.0210  0.9784
2020-01-14 15:58:20,069 [INFO] Dataset: Validation. Classification report below
2020-01-14 15:58:20,069 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.98      0.99      0.99    454264
                   Bot       0.72      0.03      0.06       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.94      0.96      2059
              DoS Hulk       0.99      0.91      0.95     46025
      DoS Slowhttptest       0.88      0.94      0.91      1099
         DoS slowloris       0.98      0.91      0.94      1159
           FTP-Patator       0.99      0.93      0.96      1587
              PortScan       0.90      0.94      0.92     31761
           SSH-Patator       0.97      0.91      0.94      1180
Web Attack Brute Force       0.75      0.02      0.04       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.98    565562
             macro avg       0.85      0.71      0.72    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 15:58:20,069 [INFO] Overall accuracy (micro avg): 0.9791481747359264
2020-01-14 15:58:40,080 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9791         0.9791                       0.9791                0.0019                   0.0209  0.9791
1     Macro avg        0.9965         0.8455                       0.7084                0.0064                   0.2916  0.7213
2  Weighted avg        0.9822         0.9790                       0.9791                0.0554                   0.0209  0.9785
2020-01-14 15:59:41,958 [INFO] Dataset: Training. Classification report below
2020-01-14 15:59:41,958 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.98      0.99      0.99   1362791
                   Bot       0.69      0.03      0.07      1174
                  DDoS       1.00      0.98      0.99     76815
         DoS GoldenEye       0.99      0.94      0.96      6176
              DoS Hulk       0.99      0.91      0.95    138074
      DoS Slowhttptest       0.89      0.95      0.92      3300
         DoS slowloris       0.98      0.93      0.95      3478
           FTP-Patator       0.99      0.94      0.96      4761
              PortScan       0.90      0.94      0.92     95282
           SSH-Patator       0.97      0.91      0.94      3538
Web Attack Brute Force       0.76      0.04      0.07       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.98   1696684
             macro avg       0.85      0.71      0.73   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 15:59:41,958 [INFO] Overall accuracy (micro avg): 0.9794469683217382
2020-01-14 16:00:48,683 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9794         0.9794                       0.9794                0.0019                   0.0206  0.9794
1     Macro avg        0.9966         0.8462                       0.7137                0.0063                   0.2863  0.7274
2  Weighted avg        0.9824         0.9793                       0.9794                0.0548                   0.0206  0.9788
2020-01-14 16:00:48,735 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_shallow_rep3/train_time_ids17_ae_ann_shallow_rep3_results.xlsx
2020-01-14 16:00:48,739 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 16:00:48,779 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1
2020-01-14 16:00:48,779 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/run_log.log
2020-01-14 16:00:48,779 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 16:00:48,779 [INFO] Experiment parameters given below
2020-01-14 16:00:48,779 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982990455, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_shallow_rep1'}
2020-01-14 16:00:48,779 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/tf_logs_run_2020_01_14-16_00_48
2020-01-14 16:00:48,779 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 16:00:48,779 [INFO] Reading X, y files
2020-01-14 16:00:48,780 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 16:01:00,819 [INFO] Reading complete. time_to_read=12.04 seconds
2020-01-14 16:01:00,819 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 16:01:05,177 [INFO] Reading complete. time_to_read=4.36 seconds
2020-01-14 16:01:05,178 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 16:01:09,519 [INFO] Reading complete. time_to_read=4.34 seconds
2020-01-14 16:01:09,519 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 16:01:10,533 [INFO] Reading complete. time_to_read=1.01 seconds
2020-01-14 16:01:10,534 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 16:01:10,909 [INFO] Reading complete. time_to_read=0.38 seconds
2020-01-14 16:01:10,909 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 16:01:11,238 [INFO] Reading complete. time_to_read=0.33 seconds
2020-01-14 16:01:14,575 [INFO] Initializing model
2020-01-14 16:01:14,691 [INFO] _________________________________________________________________
2020-01-14 16:01:14,691 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:01:14,692 [INFO] =================================================================
2020-01-14 16:01:14,692 [INFO] dense_25 (Dense)             (None, 32)                2496      
2020-01-14 16:01:14,692 [INFO] _________________________________________________________________
2020-01-14 16:01:14,692 [INFO] batch_normalization_13 (Batc (None, 32)                128       
2020-01-14 16:01:14,692 [INFO] _________________________________________________________________
2020-01-14 16:01:14,692 [INFO] dropout_13 (Dropout)         (None, 32)                0         
2020-01-14 16:01:14,692 [INFO] _________________________________________________________________
2020-01-14 16:01:14,692 [INFO] dense_26 (Dense)             (None, 77)                2541      
2020-01-14 16:01:14,692 [INFO] =================================================================
2020-01-14 16:01:14,692 [INFO] Total params: 5,165
2020-01-14 16:01:14,692 [INFO] Trainable params: 5,101
2020-01-14 16:01:14,692 [INFO] Non-trainable params: 64
2020-01-14 16:01:14,692 [INFO] _________________________________________________________________
2020-01-14 16:01:14,807 [INFO] _________________________________________________________________
2020-01-14 16:01:14,807 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:01:14,807 [INFO] =================================================================
2020-01-14 16:01:14,807 [INFO] dense_27 (Dense)             (None, 32)                1056      
2020-01-14 16:01:14,807 [INFO] _________________________________________________________________
2020-01-14 16:01:14,807 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2020-01-14 16:01:14,807 [INFO] _________________________________________________________________
2020-01-14 16:01:14,808 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2020-01-14 16:01:14,808 [INFO] _________________________________________________________________
2020-01-14 16:01:14,808 [INFO] dense_28 (Dense)             (None, 15)                495       
2020-01-14 16:01:14,808 [INFO] =================================================================
2020-01-14 16:01:14,808 [INFO] Total params: 1,679
2020-01-14 16:01:14,808 [INFO] Trainable params: 1,615
2020-01-14 16:01:14,808 [INFO] Non-trainable params: 64
2020-01-14 16:01:14,808 [INFO] _________________________________________________________________
2020-01-14 16:01:14,808 [INFO] Training model
2020-01-14 16:01:14,808 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 16:01:39,251 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 009f647bd51a5fdf0ef39d7bf3015e161145baa3
2020-01-14 16:01:39,251 [INFO] Training autoencoder
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9784
Train on 968231 samples, validate on 645487 samples
Epoch 1/10
 - 14s - loss: -3.0349e+00 - val_loss: -3.6240e+00
Epoch 2/10
 - 13s - loss: -3.5553e+00 - val_loss: -3.6406e+00
Epoch 3/10
 - 13s - loss: -3.5767e+00 - val_loss: -3.6462e+00
Epoch 4/10
 - 13s - loss: -3.5876e+00 - val_loss: -3.6486e+00
Epoch 5/10
 - 13s - loss: -3.5939e+00 - val_loss: -3.6479e+00
Epoch 6/10
 - 13s - loss: -3.5985e+00 - val_loss: -3.6514e+00
Epoch 7/10
 - 13s - loss: -3.6012e+00 - val_loss: -3.6533e+00
Epoch 8/10
 - 13s - loss: -3.6033e+00 - val_loss: -3.6531e+00
Epoch 9/10
 - 13s - loss: -3.6052e+00 - val_loss: -3.6528e+00
Epoch 10/10
 - 13s - loss: -3.6069e+00 - val_loss: -3.6524e+00
2020-01-14 16:03:56,783 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:04:35,275 [INFO] Last epoch loss evaluation: train_loss = -3.648988, val_loss = -3.653291
2020-01-14 16:04:35,275 [INFO] Training autoencoder complete
2020-01-14 16:04:35,275 [INFO] Encoding data for supervised training
2020-01-14 16:05:04,466 [INFO] Encoding complete
2020-01-14 16:05:04,466 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 10s - loss: 0.0235 - val_loss: 0.0140
 - val_f1: 0.9586
 - out_of_sample_accuracy: 0.9653
Epoch 2/100
 - 9s - loss: 0.0100 - val_loss: 0.0212
 - val_f1: 0.9030
 - out_of_sample_accuracy: 0.9292
Epoch 3/100
 - 9s - loss: 0.0095 - val_loss: 0.0089
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9805
Epoch 4/100
 - 9s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9822
Epoch 5/100
 - 9s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9825
Epoch 6/100
 - 9s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9807
Epoch 7/100
 - 9s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 8/100
 - 9s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9808
Epoch 9/100
 - 9s - loss: 0.0088 - val_loss: 0.0630
 - val_f1: 0.8162
 - out_of_sample_accuracy: 0.8694
Epoch 10/100
 - 9s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9824
Epoch 11/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
2020-01-14 16:12:40,461 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9827
Epoch 12/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 13/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9827
Epoch 14/100
 - 9s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 15/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
Epoch 16/100
 - 9s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9827
Epoch 17/100
 - 9s - loss: 0.0086 - val_loss: 0.0105
 - val_f1: 0.9713
 - out_of_sample_accuracy: 0.9762
Epoch 18/100
 - 9s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9812
Epoch 19/100
 - 9s - loss: 0.0086 - val_loss: 0.0824
 - val_f1: 0.7707
 - out_of_sample_accuracy: 0.8402
Epoch 20/100
 - 9s - loss: 0.0086 - val_loss: 0.0082
2020-01-14 16:19:55,066 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9830, current_metric = 0.9833, num_epochs = 20
2020-01-14 16:19:55,067 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:20:30,083 [INFO] Last epoch loss evaluation: train_loss = 0.008127, val_loss = 0.008171
2020-01-14 16:20:30,089 [INFO] Training complete. time_to_train = 1155.28 sec, 19.25 min
2020-01-14 16:20:30,989 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/best_model.pickle
2020-01-14 16:20:30,991 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/training_error_history.csv
2020-01-14 16:20:31,147 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/training_error_history.png
2020-01-14 16:20:31,282 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/training_f1_history.png
2020-01-14 16:20:31,283 [INFO] Making predictions on training, validation, testing data
2020-01-14 16:22:25,098 [INFO] Making predictions complete. time_to_predict = 113.82 sec, 1.90 min
2020-01-14 16:22:25,180 [INFO] Evaluating predictions (results)
2020-01-14 16:22:46,715 [INFO] Dataset: Testing. Classification report below
2020-01-14 16:22:46,715 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.75      0.12      0.21        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.98      0.70      0.82       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.42      0.01      0.01      6404
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.88      0.72      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-14 16:22:46,715 [INFO] Overall accuracy (micro avg): 0.9833257938180106
2020-01-14 16:23:09,885 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.8846                       0.7185                0.0045                   0.2815  0.7422
2  Weighted avg        0.9908         0.9778                       0.9833                0.0509                   0.0167  0.9783
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 16:23:31,371 [INFO] Dataset: Validation. Classification report below
2020-01-14 16:23:31,371 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.62      0.20      0.30        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.96      0.75      0.84       439
          FTP-BruteForce       0.72      0.87      0.78      7718
           Infilteration       0.37      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.81      0.73      0.75    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-14 16:23:31,371 [INFO] Overall accuracy (micro avg): 0.9834450577625885
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 16:23:54,539 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8090                       0.7317                0.0045                   0.2683  0.7455
2  Weighted avg        0.9908         0.9774                       0.9834                0.0505                   0.0166  0.9784
2020-01-14 16:25:04,836 [INFO] Dataset: Training. Classification report below
2020-01-14 16:25:04,836 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.75      0.12      0.21        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.97      0.74      0.84      1318
          FTP-BruteForce       0.71      0.86      0.78     23153
           Infilteration       0.44      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.82      0.71      0.73   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-14 16:25:04,836 [INFO] Overall accuracy (micro avg): 0.9833929093367182
2020-01-14 16:26:20,597 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8208                       0.7143                0.0045                   0.2857  0.7289
2  Weighted avg        0.9908         0.9781                       0.9834                0.0507                   0.0166  0.9783
2020-01-14 16:26:20,656 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep1/train_time_ids18_subset_ae_ann_shallow_rep1_results.xlsx
2020-01-14 16:26:20,663 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 16:26:20,713 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2
2020-01-14 16:26:20,714 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/run_log.log
2020-01-14 16:26:20,714 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 16:26:20,714 [INFO] Experiment parameters given below
2020-01-14 16:26:20,714 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982990455, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_shallow_rep2'}
2020-01-14 16:26:20,714 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/tf_logs_run_2020_01_14-16_26_20
2020-01-14 16:26:20,714 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 16:26:20,714 [INFO] Reading X, y files
2020-01-14 16:26:20,714 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 16:26:25,052 [INFO] Reading complete. time_to_read=4.34 seconds
2020-01-14 16:26:25,052 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 16:26:26,549 [INFO] Reading complete. time_to_read=1.50 seconds
2020-01-14 16:26:26,549 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 16:26:28,039 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-14 16:26:28,039 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 16:26:28,316 [INFO] Reading complete. time_to_read=0.28 seconds
2020-01-14 16:26:28,316 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 16:26:28,408 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 16:26:28,408 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 16:26:28,498 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 16:26:32,110 [INFO] Initializing model
2020-01-14 16:26:32,238 [INFO] _________________________________________________________________
2020-01-14 16:26:32,238 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:26:32,238 [INFO] =================================================================
2020-01-14 16:26:32,238 [INFO] dense_29 (Dense)             (None, 32)                2496      
2020-01-14 16:26:32,238 [INFO] _________________________________________________________________
2020-01-14 16:26:32,238 [INFO] batch_normalization_15 (Batc (None, 32)                128       
2020-01-14 16:26:32,238 [INFO] _________________________________________________________________
2020-01-14 16:26:32,238 [INFO] dropout_15 (Dropout)         (None, 32)                0         
2020-01-14 16:26:32,238 [INFO] _________________________________________________________________
2020-01-14 16:26:32,238 [INFO] dense_30 (Dense)             (None, 77)                2541      
2020-01-14 16:26:32,238 [INFO] =================================================================
2020-01-14 16:26:32,238 [INFO] Total params: 5,165
2020-01-14 16:26:32,239 [INFO] Trainable params: 5,101
2020-01-14 16:26:32,239 [INFO] Non-trainable params: 64
2020-01-14 16:26:32,239 [INFO] _________________________________________________________________
2020-01-14 16:26:32,352 [INFO] _________________________________________________________________
2020-01-14 16:26:32,352 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:26:32,352 [INFO] =================================================================
2020-01-14 16:26:32,352 [INFO] dense_31 (Dense)             (None, 32)                1056      
2020-01-14 16:26:32,352 [INFO] _________________________________________________________________
2020-01-14 16:26:32,352 [INFO] batch_normalization_16 (Batc (None, 32)                128       
2020-01-14 16:26:32,352 [INFO] _________________________________________________________________
2020-01-14 16:26:32,352 [INFO] dropout_16 (Dropout)         (None, 32)                0         
2020-01-14 16:26:32,352 [INFO] _________________________________________________________________
2020-01-14 16:26:32,352 [INFO] dense_32 (Dense)             (None, 15)                495       
2020-01-14 16:26:32,352 [INFO] =================================================================
2020-01-14 16:26:32,353 [INFO] Total params: 1,679
2020-01-14 16:26:32,353 [INFO] Trainable params: 1,615
2020-01-14 16:26:32,353 [INFO] Non-trainable params: 64
2020-01-14 16:26:32,353 [INFO] _________________________________________________________________
2020-01-14 16:26:32,353 [INFO] Training model
2020-01-14 16:26:32,353 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 16:26:56,954 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 1939c84a9f4174e207bfdf576458232060e017e1
2020-01-14 16:26:56,954 [INFO] Training autoencoder
 - val_f1: 0.9784
 - out_of_sample_accuracy: 0.9833
Train on 968231 samples, validate on 645487 samples
Epoch 1/10
 - 15s - loss: -3.0382e+00 - val_loss: -3.6241e+00
Epoch 2/10
 - 14s - loss: -3.5566e+00 - val_loss: -3.6387e+00
Epoch 3/10
 - 14s - loss: -3.5775e+00 - val_loss: -3.6443e+00
Epoch 4/10
 - 14s - loss: -3.5860e+00 - val_loss: -3.6468e+00
Epoch 5/10
 - 14s - loss: -3.5908e+00 - val_loss: -3.6315e+00
Epoch 6/10
 - 14s - loss: -3.5965e+00 - val_loss: -3.6521e+00
Epoch 7/10
 - 14s - loss: -3.5998e+00 - val_loss: -3.6529e+00
Epoch 8/10
 - 14s - loss: -3.6024e+00 - val_loss: -3.6539e+00
Epoch 9/10
 - 14s - loss: -3.6032e+00 - val_loss: -3.6546e+00
Epoch 10/10
 - 14s - loss: -3.6043e+00 - val_loss: -3.6555e+00
2020-01-14 16:29:18,797 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:30:00,820 [INFO] Last epoch loss evaluation: train_loss = -3.651869, val_loss = -3.655454
2020-01-14 16:30:00,821 [INFO] Training autoencoder complete
2020-01-14 16:30:00,821 [INFO] Encoding data for supervised training
2020-01-14 16:30:31,446 [INFO] Encoding complete
2020-01-14 16:30:31,447 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 10s - loss: 0.0230 - val_loss: 0.0096
 - val_f1: 0.9743
 - out_of_sample_accuracy: 0.9789
Epoch 2/100
 - 9s - loss: 0.0101 - val_loss: 0.0091
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9806
Epoch 3/100
 - 9s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9825
Epoch 4/100
 - 9s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9828
Epoch 5/100
 - 9s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9824
Epoch 6/100
 - 9s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9772
 - out_of_sample_accuracy: 0.9823
Epoch 7/100
 - 9s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 8/100
 - 9s - loss: 0.0089 - val_loss: 0.0154
 - val_f1: 0.9476
 - out_of_sample_accuracy: 0.9616
Epoch 9/100
 - 9s - loss: 0.0088 - val_loss: 0.0083
2020-01-14 16:37:31,701 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9830, current_metric = 0.9830, num_epochs = 9
2020-01-14 16:37:31,702 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:38:09,924 [INFO] Last epoch loss evaluation: train_loss = 0.008265, val_loss = 0.008307
2020-01-14 16:38:09,932 [INFO] Training complete. time_to_train = 697.58 sec, 11.63 min
2020-01-14 16:38:11,993 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/best_model.pickle
2020-01-14 16:38:11,994 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/training_error_history.csv
2020-01-14 16:38:12,152 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/training_error_history.png
2020-01-14 16:38:12,295 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/training_f1_history.png
2020-01-14 16:38:12,296 [INFO] Making predictions on training, validation, testing data
2020-01-14 16:40:11,501 [INFO] Making predictions complete. time_to_predict = 119.20 sec, 1.99 min
2020-01-14 16:40:11,568 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 16:40:32,981 [INFO] Dataset: Testing. Classification report below
2020-01-14 16:40:32,981 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      0.99      0.98      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.53      0.61      5596
   DoS attacks-Slowloris       0.85      0.94      0.89       440
          FTP-BruteForce       0.71      0.85      0.78      7718
           Infilteration       0.39      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.69      0.69      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-14 16:40:32,981 [INFO] Overall accuracy (micro avg): 0.9830252460154177
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 16:40:56,093 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.6889                       0.6866                0.0045                   0.3134  0.6725
2  Weighted avg        0.9906         0.9772                       0.9830                0.0511                   0.0170  0.9781
2020-01-14 16:41:17,585 [INFO] Dataset: Validation. Classification report below
2020-01-14 16:41:17,585 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23009
   DoS attacks-GoldenEye       0.98      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.86      0.92      0.89       439
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.36      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.69      0.68      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-14 16:41:17,585 [INFO] Overall accuracy (micro avg): 0.983136763404995
2020-01-14 16:41:40,757 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9978         0.6921                       0.6846                0.0045                   0.3154  0.6745
2  Weighted avg        0.9906         0.9770                       0.9831                0.0511                   0.0169  0.9781
2020-01-14 16:42:51,100 [INFO] Dataset: Training. Classification report below
2020-01-14 16:42:51,100 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     69029
   DoS attacks-GoldenEye       0.98      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.72      0.53      0.61     16787
   DoS attacks-Slowloris       0.88      0.95      0.92      1318
          FTP-BruteForce       0.71      0.85      0.78     23153
           Infilteration       0.42      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.70      0.69      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-14 16:42:51,100 [INFO] Overall accuracy (micro avg): 0.9831791173800467
2020-01-14 16:44:06,845 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6953                       0.6866                0.0045                   0.3134  0.6749
2  Weighted avg        0.9907         0.9777                       0.9832                0.0508                   0.0168  0.9782
2020-01-14 16:44:06,904 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep2/train_time_ids18_subset_ae_ann_shallow_rep2_results.xlsx
2020-01-14 16:44:06,909 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 16:44:06,956 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3
2020-01-14 16:44:06,957 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/run_log.log
2020-01-14 16:44:06,957 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 16:44:06,957 [INFO] Experiment parameters given below
2020-01-14 16:44:06,957 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982990455, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_shallow_rep3'}
2020-01-14 16:44:06,957 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/tf_logs_run_2020_01_14-16_44_06
2020-01-14 16:44:06,957 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 16:44:06,957 [INFO] Reading X, y files
2020-01-14 16:44:06,957 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 16:44:16,218 [INFO] Reading complete. time_to_read=9.26 seconds
2020-01-14 16:44:16,218 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 16:44:18,090 [INFO] Reading complete. time_to_read=1.87 seconds
2020-01-14 16:44:18,090 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 16:44:19,722 [INFO] Reading complete. time_to_read=1.63 seconds
2020-01-14 16:44:19,722 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 16:44:20,010 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-14 16:44:20,010 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 16:44:20,135 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-14 16:44:20,135 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 16:44:20,256 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-14 16:44:23,471 [INFO] Initializing model
2020-01-14 16:44:23,588 [INFO] _________________________________________________________________
2020-01-14 16:44:23,588 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:44:23,588 [INFO] =================================================================
2020-01-14 16:44:23,588 [INFO] dense_33 (Dense)             (None, 32)                2496      
2020-01-14 16:44:23,588 [INFO] _________________________________________________________________
2020-01-14 16:44:23,588 [INFO] batch_normalization_17 (Batc (None, 32)                128       
2020-01-14 16:44:23,588 [INFO] _________________________________________________________________
2020-01-14 16:44:23,588 [INFO] dropout_17 (Dropout)         (None, 32)                0         
2020-01-14 16:44:23,588 [INFO] _________________________________________________________________
2020-01-14 16:44:23,588 [INFO] dense_34 (Dense)             (None, 77)                2541      
2020-01-14 16:44:23,588 [INFO] =================================================================
2020-01-14 16:44:23,589 [INFO] Total params: 5,165
2020-01-14 16:44:23,589 [INFO] Trainable params: 5,101
2020-01-14 16:44:23,589 [INFO] Non-trainable params: 64
2020-01-14 16:44:23,589 [INFO] _________________________________________________________________
2020-01-14 16:44:23,706 [INFO] _________________________________________________________________
2020-01-14 16:44:23,706 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:44:23,706 [INFO] =================================================================
2020-01-14 16:44:23,706 [INFO] dense_35 (Dense)             (None, 32)                1056      
2020-01-14 16:44:23,706 [INFO] _________________________________________________________________
2020-01-14 16:44:23,706 [INFO] batch_normalization_18 (Batc (None, 32)                128       
2020-01-14 16:44:23,706 [INFO] _________________________________________________________________
2020-01-14 16:44:23,706 [INFO] dropout_18 (Dropout)         (None, 32)                0         
2020-01-14 16:44:23,706 [INFO] _________________________________________________________________
2020-01-14 16:44:23,706 [INFO] dense_36 (Dense)             (None, 15)                495       
2020-01-14 16:44:23,706 [INFO] =================================================================
2020-01-14 16:44:23,706 [INFO] Total params: 1,679
2020-01-14 16:44:23,707 [INFO] Trainable params: 1,615
2020-01-14 16:44:23,707 [INFO] Non-trainable params: 64
2020-01-14 16:44:23,707 [INFO] _________________________________________________________________
2020-01-14 16:44:23,707 [INFO] Training model
2020-01-14 16:44:23,707 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 16:44:48,155 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 17002b0a54b76b92ee932d88610e1f91a6e5902b
2020-01-14 16:44:48,156 [INFO] Training autoencoder
 - val_f1: 0.9781
 - out_of_sample_accuracy: 0.9830
Train on 968231 samples, validate on 645487 samples
Epoch 1/10
 - 15s - loss: -3.0362e+00 - val_loss: -3.6242e+00
Epoch 2/10
 - 14s - loss: -3.5605e+00 - val_loss: -3.6375e+00
Epoch 3/10
 - 14s - loss: -3.5805e+00 - val_loss: -3.5029e+00
Epoch 4/10
 - 14s - loss: -3.5907e+00 - val_loss: -2.9243e+00
Epoch 5/10
 - 14s - loss: -3.5949e+00 - val_loss: -3.6502e+00
Epoch 6/10
 - 14s - loss: -3.5985e+00 - val_loss: -3.6464e+00
Epoch 7/10
 - 14s - loss: -3.6016e+00 - val_loss: -3.5828e+00
Epoch 8/10
 - 14s - loss: -3.6038e+00 - val_loss: -3.6539e+00
Epoch 9/10
 - 14s - loss: -3.6058e+00 - val_loss: -3.6510e+00
Epoch 10/10
 - 14s - loss: -3.6069e+00 - val_loss: -3.3971e+00
2020-01-14 16:47:11,358 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:47:55,968 [INFO] Last epoch loss evaluation: train_loss = -3.651835, val_loss = -3.653878
2020-01-14 16:47:55,968 [INFO] Training autoencoder complete
2020-01-14 16:47:55,968 [INFO] Encoding data for supervised training
2020-01-14 16:48:28,518 [INFO] Encoding complete
2020-01-14 16:48:28,518 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 11s - loss: 0.0234 - val_loss: 0.0096
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9795
Epoch 2/100
 - 10s - loss: 0.0102 - val_loss: 0.0091
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9814
Epoch 3/100
 - 9s - loss: 0.0096 - val_loss: 0.0090
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9800
Epoch 4/100
 - 9s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9801
Epoch 5/100
 - 9s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9772
 - out_of_sample_accuracy: 0.9824
Epoch 6/100
 - 9s - loss: 0.0089 - val_loss: 0.0086
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9826
Epoch 7/100
 - 9s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9810
Epoch 8/100
 - 9s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9823
Epoch 9/100
 - 9s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9823
Epoch 10/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 11/100
 - 9s - loss: 0.0087 - val_loss: 0.0083
2020-01-14 16:56:48,754 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9827
Epoch 12/100
 - 9s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9821
Epoch 13/100
 - 9s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9826
Epoch 14/100
 - 9s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9825
Epoch 15/100
 - 10s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
Epoch 16/100
 - 9s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 17/100
 - 9s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9827
Epoch 18/100
 - 9s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9828
Epoch 19/100
 - 9s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9813
Epoch 20/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9826
Epoch 21/100
 - 9s - loss: 0.0085 - val_loss: 0.0083
2020-01-14 17:04:54,068 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9827
Epoch 22/100
 - 10s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9829
Epoch 23/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9825
Epoch 24/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9828
Epoch 25/100
 - 9s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9781
 - out_of_sample_accuracy: 0.9829
Epoch 26/100
 - 10s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9827
Epoch 27/100
 - 9s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
Epoch 28/100
 - 10s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9826
Epoch 29/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9828
Epoch 30/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9814
Epoch 31/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
2020-01-14 17:12:59,805 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9829
Epoch 32/100
 - 9s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9827
Epoch 33/100
 - 9s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9811
Epoch 34/100
 - 9s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9829
Epoch 35/100
 - 9s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
Epoch 36/100
 - 9s - loss: 0.0084 - val_loss: 0.0082
2020-01-14 17:17:41,338 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9830, current_metric = 0.9831, num_epochs = 36
2020-01-14 17:17:41,340 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:18:21,393 [INFO] Last epoch loss evaluation: train_loss = 0.008106, val_loss = 0.008142
2020-01-14 17:18:21,400 [INFO] Training complete. time_to_train = 2037.69 sec, 33.96 min
2020-01-14 17:18:22,559 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/best_model.pickle
2020-01-14 17:18:22,560 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/training_error_history.csv
2020-01-14 17:18:22,717 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/training_error_history.png
2020-01-14 17:18:22,867 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/training_f1_history.png
2020-01-14 17:18:22,867 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:20:28,877 [INFO] Making predictions complete. time_to_predict = 126.01 sec, 2.10 min
2020-01-14 17:20:28,941 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 17:20:50,393 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:20:50,394 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.88      0.54      0.67        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.72      0.84       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.27      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.77      0.66      0.69    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-14 17:20:50,394 [INFO] Overall accuracy (micro avg): 0.9828052574176437
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 17:21:13,561 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9828         0.9828                       0.9828                0.0012                   0.0172  0.9828
1     Macro avg        0.9977         0.7698                       0.6604                0.0046                   0.3396  0.6872
2  Weighted avg        0.9907         0.9760                       0.9828                0.0516                   0.0172  0.9775
2020-01-14 17:21:35,023 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:21:35,023 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.89      0.47      0.62        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.78      0.87       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.40      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.78      0.68      0.71    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-14 17:21:35,023 [INFO] Overall accuracy (micro avg): 0.983014375192684
2020-01-14 17:21:58,145 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.7803                       0.6826                0.0045                   0.3174  0.7069
2  Weighted avg        0.9908         0.9776                       0.9830                0.0513                   0.0170  0.9777
2020-01-14 17:23:08,254 [INFO] Dataset: Training. Classification report below
2020-01-14 17:23:08,254 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.46      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.85      0.52      0.64       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.99      0.76      0.86      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.41      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.78      0.67      0.70   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-14 17:23:08,254 [INFO] Overall accuracy (micro avg): 0.982953448092449
2020-01-14 17:24:23,938 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.7771                       0.6702                0.0046                   0.3298  0.6961
2  Weighted avg        0.9908         0.9775                       0.9830                0.0512                   0.0170  0.9777
2020-01-14 17:24:23,996 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_shallow_rep3/train_time_ids18_subset_ae_ann_shallow_rep3_results.xlsx
2020-01-14 17:24:24,001 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 17:24:24,048 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1
2020-01-14 17:24:24,049 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/run_log.log
2020-01-14 17:24:24,049 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 17:24:24,049 [INFO] Experiment parameters given below
2020-01-14 17:24:24,049 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920689445, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_shallow_rep1'}
2020-01-14 17:24:24,049 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/tf_logs_run_2020_01_14-17_24_24
2020-01-14 17:24:24,049 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 17:24:24,065 [INFO] Reading X, y files
2020-01-14 17:24:24,065 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 17:24:36,638 [INFO] Reading complete. time_to_read=12.57 seconds
2020-01-14 17:24:36,638 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 17:24:46,589 [INFO] Reading complete. time_to_read=9.95 seconds
2020-01-14 17:24:46,606 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 17:24:47,956 [INFO] Reading complete. time_to_read=1.35 seconds
2020-01-14 17:24:47,956 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 17:24:48,773 [INFO] Reading complete. time_to_read=0.82 seconds
2020-01-14 17:24:48,773 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 17:24:49,066 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-14 17:24:49,066 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 17:24:49,179 [INFO] Reading complete. time_to_read=0.11 seconds
2020-01-14 17:28:53,060 [INFO] Initializing model
2020-01-14 17:29:40,727 [INFO] _________________________________________________________________
2020-01-14 17:29:40,780 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:29:40,780 [INFO] =================================================================
2020-01-14 17:29:40,827 [INFO] dense_37 (Dense)             (None, 32)                3968      
2020-01-14 17:29:40,827 [INFO] _________________________________________________________________
2020-01-14 17:29:40,828 [INFO] batch_normalization_19 (Batc (None, 32)                128       
2020-01-14 17:29:40,828 [INFO] _________________________________________________________________
2020-01-14 17:29:40,828 [INFO] dropout_19 (Dropout)         (None, 32)                0         
2020-01-14 17:29:40,828 [INFO] _________________________________________________________________
2020-01-14 17:29:40,829 [INFO] dense_38 (Dense)             (None, 123)               4059      
2020-01-14 17:29:40,829 [INFO] =================================================================
2020-01-14 17:29:40,848 [INFO] Total params: 8,155
2020-01-14 17:29:40,849 [INFO] Trainable params: 8,091
2020-01-14 17:29:40,849 [INFO] Non-trainable params: 64
2020-01-14 17:29:40,849 [INFO] _________________________________________________________________
2020-01-14 17:29:46,596 [INFO] _________________________________________________________________
2020-01-14 17:29:46,606 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:29:46,606 [INFO] =================================================================
2020-01-14 17:29:46,606 [INFO] dense_39 (Dense)             (None, 32)                1056      
2020-01-14 17:29:46,606 [INFO] _________________________________________________________________
2020-01-14 17:29:46,606 [INFO] batch_normalization_20 (Batc (None, 32)                128       
2020-01-14 17:29:46,606 [INFO] _________________________________________________________________
2020-01-14 17:29:46,606 [INFO] dropout_20 (Dropout)         (None, 32)                0         
2020-01-14 17:29:46,606 [INFO] _________________________________________________________________
2020-01-14 17:29:46,607 [INFO] dense_40 (Dense)             (None, 5)                 165       
2020-01-14 17:29:46,607 [INFO] =================================================================
2020-01-14 17:29:46,607 [INFO] Total params: 1,349
2020-01-14 17:29:46,607 [INFO] Trainable params: 1,285
2020-01-14 17:29:46,607 [INFO] Non-trainable params: 64
2020-01-14 17:29:46,607 [INFO] _________________________________________________________________
2020-01-14 17:29:46,607 [INFO] Training model
2020-01-14 17:29:46,626 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 18:28:36,289 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 804d928dca04d073eeb584eb1150be0e8f497bca
2020-01-14 18:28:36,697 [INFO] Training autoencoder
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9831
Train on 1959372 samples, validate on 979687 samples
Epoch 1/10
 - 1298s - loss: 0.6242 - val_loss: 0.6656
Epoch 2/10
 - 57s - loss: 0.5277 - val_loss: 0.6555
Epoch 3/10
 - 42s - loss: 0.5110 - val_loss: 0.7148
Epoch 4/10
 - 42s - loss: 0.5039 - val_loss: 0.9024
Epoch 5/10
 - 42s - loss: 0.4905 - val_loss: 0.9577
Epoch 6/10
 - 42s - loss: 0.4857 - val_loss: 0.8513
Epoch 7/10
 - 42s - loss: 0.4832 - val_loss: 0.7539
Epoch 8/10
 - 42s - loss: 0.4715 - val_loss: 0.7591
Epoch 9/10
 - 42s - loss: 0.4611 - val_loss: 0.7070
Epoch 10/10
 - 42s - loss: 0.4537 - val_loss: 0.6769
2020-01-14 18:59:36,254 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:01:02,707 [INFO] Last epoch loss evaluation: train_loss = 0.534262, val_loss = 0.655490
2020-01-14 19:01:02,769 [INFO] Training autoencoder complete
2020-01-14 19:01:02,770 [INFO] Encoding data for supervised training
2020-01-14 19:04:13,120 [INFO] Encoding complete
2020-01-14 19:04:13,278 [INFO] Training neural network layers (after autoencoder)
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 20s - loss: 0.0108 - val_loss: 0.0025
2020-01-14 19:09:20,261 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9207, current_metric = 0.9218, num_epochs = 1
2020-01-14 19:09:20,521 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:10:36,392 [INFO] Last epoch loss evaluation: train_loss = 0.002354, val_loss = 0.002466
2020-01-14 19:10:36,585 [INFO] Training complete. time_to_train = 6049.98 sec, 100.83 min
2020-01-14 19:10:39,566 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/best_model.pickle
2020-01-14 19:10:39,846 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/training_error_history.csv
2020-01-14 19:10:41,143 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/training_error_history.png
2020-01-14 19:10:41,270 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/training_f1_history.png
2020-01-14 19:10:41,270 [INFO] Making predictions on training, validation, testing data
2020-01-14 19:29:05,583 [INFO] Making predictions complete. time_to_predict = 1104.31 sec, 18.41 min
2020-01-14 19:29:06,300 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 19:29:14,564 [INFO] Dataset: Testing. Classification report below
2020-01-14 19:29:14,578 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      1.00      0.84     60593
       probe       0.87      0.67      0.76      4166
         r2l       0.00      0.00      0.00     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.52      0.53      0.52    311029
weighted avg       0.89      0.92      0.90    311029

2020-01-14 19:29:14,578 [INFO] Overall accuracy (micro avg): 0.9219719061566606
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 19:29:23,491 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9220         0.9220                       0.9220                0.0195                   0.0780  0.9220
1     Macro avg        0.9688         0.5182                       0.5280                0.0208                   0.4720  0.5162
2  Weighted avg        0.9664         0.8888                       0.9220                0.0261                   0.0780  0.9010
2020-01-14 19:29:52,735 [INFO] Dataset: Validation. Classification report below
2020-01-14 19:29:52,736 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.98      0.95      0.97      8221
         r2l       0.03      0.01      0.01       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.60      0.59      0.60    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 19:29:52,736 [INFO] Overall accuracy (micro avg): 0.9987302066884628
2020-01-14 19:30:23,320 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9987         0.9987                       0.9987                0.0003                   0.0013  0.9987
1     Macro avg        0.9995         0.6013                       0.5918                0.0005                   0.4082  0.5953
2  Weighted avg        0.9993         0.9986                       0.9987                0.0012                   0.0013  0.9986
2020-01-14 19:32:28,710 [INFO] Dataset: Training. Classification report below
2020-01-14 19:32:28,710 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.98      0.95      0.97     32881
         r2l       0.00      0.00      0.00       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.60      0.59      0.59   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 19:32:28,710 [INFO] Overall accuracy (micro avg): 0.9987427093987257
2020-01-14 19:34:43,271 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9987         0.9987                       0.9987                0.0003                   0.0013  0.9987
1     Macro avg        0.9995         0.5954                       0.5902                0.0005                   0.4098  0.5928
2  Weighted avg        0.9993         0.9986                       0.9987                0.0012                   0.0013  0.9986
2020-01-14 19:34:43,517 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep1/train_time_kdd99_ae_ann_shallow_rep1_results.xlsx
2020-01-14 19:34:43,535 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 19:34:43,890 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2
2020-01-14 19:34:43,906 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/run_log.log
2020-01-14 19:34:43,906 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 19:34:43,906 [INFO] Experiment parameters given below
2020-01-14 19:34:43,907 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920689445, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_shallow_rep2'}
2020-01-14 19:34:43,932 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/tf_logs_run_2020_01_14-19_34_43
2020-01-14 19:34:43,932 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 19:34:43,964 [INFO] Reading X, y files
2020-01-14 19:34:43,964 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 19:34:57,515 [INFO] Reading complete. time_to_read=13.55 seconds
2020-01-14 19:34:57,515 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 19:35:00,377 [INFO] Reading complete. time_to_read=2.86 seconds
2020-01-14 19:35:00,377 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 19:35:01,595 [INFO] Reading complete. time_to_read=1.22 seconds
2020-01-14 19:35:01,595 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 19:35:02,683 [INFO] Reading complete. time_to_read=1.09 seconds
2020-01-14 19:35:02,684 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 19:35:02,934 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-14 19:35:02,934 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 19:35:03,027 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 19:37:49,671 [INFO] Initializing model
2020-01-14 19:38:51,626 [INFO] _________________________________________________________________
2020-01-14 19:38:51,709 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 19:38:51,709 [INFO] =================================================================
2020-01-14 19:38:51,762 [INFO] dense_41 (Dense)             (None, 32)                3968      
2020-01-14 19:38:51,762 [INFO] _________________________________________________________________
2020-01-14 19:38:51,762 [INFO] batch_normalization_21 (Batc (None, 32)                128       
2020-01-14 19:38:51,762 [INFO] _________________________________________________________________
2020-01-14 19:38:51,762 [INFO] dropout_21 (Dropout)         (None, 32)                0         
2020-01-14 19:38:51,762 [INFO] _________________________________________________________________
2020-01-14 19:38:51,762 [INFO] dense_42 (Dense)             (None, 123)               4059      
2020-01-14 19:38:51,762 [INFO] =================================================================
2020-01-14 19:38:51,770 [INFO] Total params: 8,155
2020-01-14 19:38:51,770 [INFO] Trainable params: 8,091
2020-01-14 19:38:51,770 [INFO] Non-trainable params: 64
2020-01-14 19:38:51,770 [INFO] _________________________________________________________________
2020-01-14 19:38:59,361 [INFO] _________________________________________________________________
2020-01-14 19:38:59,361 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 19:38:59,361 [INFO] =================================================================
2020-01-14 19:38:59,361 [INFO] dense_43 (Dense)             (None, 32)                1056      
2020-01-14 19:38:59,361 [INFO] _________________________________________________________________
2020-01-14 19:38:59,361 [INFO] batch_normalization_22 (Batc (None, 32)                128       
2020-01-14 19:38:59,361 [INFO] _________________________________________________________________
2020-01-14 19:38:59,361 [INFO] dropout_22 (Dropout)         (None, 32)                0         
2020-01-14 19:38:59,361 [INFO] _________________________________________________________________
2020-01-14 19:38:59,361 [INFO] dense_44 (Dense)             (None, 5)                 165       
2020-01-14 19:38:59,361 [INFO] =================================================================
2020-01-14 19:38:59,362 [INFO] Total params: 1,349
2020-01-14 19:38:59,362 [INFO] Trainable params: 1,285
2020-01-14 19:38:59,362 [INFO] Non-trainable params: 64
2020-01-14 19:38:59,362 [INFO] _________________________________________________________________
2020-01-14 19:38:59,362 [INFO] Training model
2020-01-14 19:38:59,383 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 20:20:40,514 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 11b393c5a8e51bc36bbb5ce4fc5a322418a3bfcf
2020-01-14 20:20:40,889 [INFO] Training autoencoder
 - val_f1: 0.9986
 - out_of_sample_accuracy: 0.9218
Train on 1959372 samples, validate on 979687 samples
Epoch 1/10
 - 1901s - loss: 0.5550 - val_loss: 0.5178
Epoch 2/10
 - 103s - loss: 0.4628 - val_loss: 0.5889
Epoch 3/10
 - 44s - loss: 0.4483 - val_loss: 0.7055
Epoch 4/10
 - 44s - loss: 0.4398 - val_loss: 0.5970
Epoch 5/10
 - 44s - loss: 0.4334 - val_loss: 0.5534
Epoch 6/10
 - 44s - loss: 0.4275 - val_loss: 0.5251
Epoch 7/10
 - 44s - loss: 0.4265 - val_loss: 0.5209
Epoch 8/10
 - 44s - loss: 0.4252 - val_loss: 0.5125
Epoch 9/10
 - 44s - loss: 0.4238 - val_loss: 0.5194
Epoch 10/10
 - 44s - loss: 0.4219 - val_loss: 0.4963
2020-01-14 21:04:33,275 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 21:06:01,771 [INFO] Last epoch loss evaluation: train_loss = 0.414472, val_loss = 0.496297
2020-01-14 21:06:01,809 [INFO] Training autoencoder complete
2020-01-14 21:06:01,809 [INFO] Encoding data for supervised training
2020-01-14 21:07:26,144 [INFO] Encoding complete
2020-01-14 21:07:26,207 [INFO] Training neural network layers (after autoencoder)
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 21s - loss: 0.0095 - val_loss: 0.0016
2020-01-14 21:11:37,962 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9207, current_metric = 0.9214, num_epochs = 1
2020-01-14 21:11:38,198 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 21:12:57,251 [INFO] Last epoch loss evaluation: train_loss = 0.001560, val_loss = 0.001564
2020-01-14 21:12:57,454 [INFO] Training complete. time_to_train = 5638.08 sec, 93.97 min
2020-01-14 21:13:01,488 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/best_model.pickle
2020-01-14 21:13:03,010 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/training_error_history.csv
/home/nilwala/sunanda/ids_experiments/utility.py:289: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 21:13:11,805 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/training_error_history.png
/home/nilwala/sunanda/ids_experiments/utility.py:306: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 21:13:11,952 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/training_f1_history.png
2020-01-14 21:13:11,989 [INFO] Making predictions on training, validation, testing data
2020-01-14 21:29:31,915 [INFO] Making predictions complete. time_to_predict = 979.93 sec, 16.33 min
2020-01-14 21:29:32,616 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-14 21:29:43,123 [INFO] Dataset: Testing. Classification report below
2020-01-14 21:29:43,135 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      1.00      0.84     60593
       probe       0.82      0.72      0.77      4166
         r2l       0.97      0.00      0.00     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.70      0.54      0.52    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 21:29:43,136 [INFO] Overall accuracy (micro avg): 0.9214542695375673
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 21:29:52,552 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9215         0.9215                       0.9215                0.0196                   0.0785  0.9215
1     Macro avg        0.9686         0.7008                       0.5376                0.0206                   0.4624  0.5183
2  Weighted avg        0.9660         0.9314                       0.9215                0.0243                   0.0785  0.9008
2020-01-14 21:30:22,370 [INFO] Dataset: Validation. Classification report below
2020-01-14 21:30:22,370 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.96      0.98      8221
         r2l       0.82      0.06      0.12       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.76      0.60      0.62    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 21:30:22,370 [INFO] Overall accuracy (micro avg): 0.9991813711930443
2020-01-14 21:30:53,141 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.7624                       0.6041                0.0004                   0.3959  0.6178
2  Weighted avg        0.9996         0.9991                       0.9992                0.0010                   0.0008  0.9991
2020-01-14 21:32:59,142 [INFO] Dataset: Training. Classification report below
2020-01-14 21:32:59,142 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.96      0.98     32881
         r2l       0.80      0.04      0.07       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.76      0.60      0.61   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 21:32:59,142 [INFO] Overall accuracy (micro avg): 0.9991762666813653
2020-01-14 21:35:13,637 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.7589                       0.5990                0.0004                   0.4010  0.6088
2  Weighted avg        0.9996         0.9991                       0.9992                0.0010                   0.0008  0.9991
2020-01-14 21:35:15,202 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep2/train_time_kdd99_ae_ann_shallow_rep2_results.xlsx
2020-01-14 21:35:15,261 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 21:35:15,672 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3
2020-01-14 21:35:15,830 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/run_log.log
2020-01-14 21:35:15,830 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 21:35:15,830 [INFO] Experiment parameters given below
2020-01-14 21:35:15,830 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 10, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920689445, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_shallow_rep3'}
2020-01-14 21:35:15,840 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/tf_logs_run_2020_01_14-21_35_15
2020-01-14 21:35:15,851 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 21:35:15,959 [INFO] Reading X, y files
2020-01-14 21:35:15,983 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 21:35:32,810 [INFO] Reading complete. time_to_read=16.83 seconds
2020-01-14 21:35:32,810 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 21:35:35,454 [INFO] Reading complete. time_to_read=2.64 seconds
2020-01-14 21:35:35,454 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 21:35:37,276 [INFO] Reading complete. time_to_read=1.82 seconds
2020-01-14 21:35:37,277 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 21:35:45,366 [INFO] Reading complete. time_to_read=8.09 seconds
2020-01-14 21:35:45,366 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 21:35:45,735 [INFO] Reading complete. time_to_read=0.37 seconds
2020-01-14 21:35:45,736 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 21:35:45,875 [INFO] Reading complete. time_to_read=0.14 seconds
2020-01-14 21:39:08,228 [INFO] Initializing model
2020-01-14 21:40:05,052 [INFO] _________________________________________________________________
2020-01-14 21:40:05,145 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 21:40:05,145 [INFO] =================================================================
2020-01-14 21:40:05,188 [INFO] dense_45 (Dense)             (None, 32)                3968      
2020-01-14 21:40:05,188 [INFO] _________________________________________________________________
2020-01-14 21:40:05,189 [INFO] batch_normalization_23 (Batc (None, 32)                128       
2020-01-14 21:40:05,189 [INFO] _________________________________________________________________
2020-01-14 21:40:05,189 [INFO] dropout_23 (Dropout)         (None, 32)                0         
2020-01-14 21:40:05,189 [INFO] _________________________________________________________________
2020-01-14 21:40:05,189 [INFO] dense_46 (Dense)             (None, 123)               4059      
2020-01-14 21:40:05,189 [INFO] =================================================================
2020-01-14 21:40:05,213 [INFO] Total params: 8,155
2020-01-14 21:40:05,213 [INFO] Trainable params: 8,091
2020-01-14 21:40:05,213 [INFO] Non-trainable params: 64
2020-01-14 21:40:05,213 [INFO] _________________________________________________________________
2020-01-14 21:40:11,718 [INFO] _________________________________________________________________
2020-01-14 21:40:11,718 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 21:40:11,718 [INFO] =================================================================
2020-01-14 21:40:11,719 [INFO] dense_47 (Dense)             (None, 32)                1056      
2020-01-14 21:40:11,719 [INFO] _________________________________________________________________
2020-01-14 21:40:11,719 [INFO] batch_normalization_24 (Batc (None, 32)                128       
2020-01-14 21:40:11,720 [INFO] _________________________________________________________________
2020-01-14 21:40:11,720 [INFO] dropout_24 (Dropout)         (None, 32)                0         
2020-01-14 21:40:11,720 [INFO] _________________________________________________________________
2020-01-14 21:40:11,720 [INFO] dense_48 (Dense)             (None, 5)                 165       
2020-01-14 21:40:11,721 [INFO] =================================================================
2020-01-14 21:40:11,721 [INFO] Total params: 1,349
2020-01-14 21:40:11,721 [INFO] Trainable params: 1,285
2020-01-14 21:40:11,721 [INFO] Non-trainable params: 64
2020-01-14 21:40:11,722 [INFO] _________________________________________________________________
2020-01-14 21:40:11,722 [INFO] Training model
2020-01-14 21:40:11,743 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 22:28:08,594 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = a635b3327b738d8029434bc3e0f74797c1fa64ad
2020-01-14 22:28:08,828 [INFO] Training autoencoder
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9214
Train on 1959372 samples, validate on 979687 samples
Epoch 1/10
 - 1201s - loss: 0.5546 - val_loss: 0.5553
Epoch 2/10
 - 219s - loss: 0.4437 - val_loss: 0.5273
Epoch 3/10
 - 38s - loss: 0.4318 - val_loss: 0.5372
Epoch 4/10
 - 38s - loss: 0.4227 - val_loss: 0.5803
Epoch 5/10
 - 39s - loss: 0.4170 - val_loss: 0.5960
Epoch 6/10
 - 38s - loss: 0.4133 - val_loss: 0.6100
Epoch 7/10
 - 38s - loss: 0.4112 - val_loss: 0.5873
Epoch 8/10
 - 38s - loss: 0.4075 - val_loss: 0.5169
Epoch 9/10
 - 38s - loss: 0.4001 - val_loss: 0.5114
Epoch 10/10
 - 38s - loss: 0.3993 - val_loss: 0.4918
2020-01-14 23:02:16,981 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 23:03:48,928 [INFO] Last epoch loss evaluation: train_loss = 0.401391, val_loss = 0.491752
2020-01-14 23:03:48,940 [INFO] Training autoencoder complete
2020-01-14 23:03:48,940 [INFO] Encoding data for supervised training
2020-01-14 23:05:23,896 [INFO] Encoding complete
2020-01-14 23:05:23,998 [INFO] Training neural network layers (after autoencoder)
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 24s - loss: 0.0128 - val_loss: 0.0025
2020-01-14 23:09:36,672 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9207, current_metric = 0.9213, num_epochs = 1
2020-01-14 23:09:36,953 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 23:10:59,291 [INFO] Last epoch loss evaluation: train_loss = 0.002685, val_loss = 0.002539
2020-01-14 23:10:59,452 [INFO] Training complete. time_to_train = 5447.72 sec, 90.80 min
2020-01-14 23:11:03,843 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/best_model.pickle
2020-01-14 23:11:05,072 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/training_error_history.csv
/home/nilwala/sunanda/ids_experiments/utility.py:289: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 23:11:11,373 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/training_error_history.png
/home/nilwala/sunanda/ids_experiments/utility.py:306: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 23:11:11,547 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/training_f1_history.png
2020-01-14 23:11:11,576 [INFO] Making predictions on training, validation, testing data
2020-01-14 23:37:19,802 [INFO] Making predictions complete. time_to_predict = 1568.23 sec, 26.14 min
2020-01-14 23:37:20,707 [INFO] Evaluating predictions (results)
2020-01-14 23:37:30,736 [INFO] Dataset: Testing. Classification report below
2020-01-14 23:37:30,736 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.97      0.98    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.90      0.69      0.78      4166
         r2l       0.85      0.05      0.09     13781
         u2r       0.01      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.70      0.54      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 23:37:30,736 [INFO] Overall accuracy (micro avg): 0.921483205746088
2020-01-14 23:37:39,797 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9215         0.9215                       0.9215                0.0196                   0.0785  0.9215
1     Macro avg        0.9686         0.6965                       0.5390                0.0219                   0.4610  0.5385
2  Weighted avg        0.9644         0.9256                       0.9215                0.0312                   0.0785  0.9036
2020-01-14 23:38:09,644 [INFO] Dataset: Validation. Classification report below
2020-01-14 23:38:09,644 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.98      0.96      0.97      8221
         r2l       0.11      0.12      0.11       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.62      0.62      0.62    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 23:38:09,644 [INFO] Overall accuracy (micro avg): 0.9985842417016864
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 23:38:40,248 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9986         0.9986                       0.9986                0.0004                   0.0014  0.9986
1     Macro avg        0.9994         0.6172                       0.6164                0.0005                   0.3836  0.6166
2  Weighted avg        0.9991         0.9986                       0.9986                0.0012                   0.0014  0.9986
2020-01-14 23:40:47,566 [INFO] Dataset: Training. Classification report below
2020-01-14 23:40:47,566 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.98      0.96      0.97     32881
         r2l       0.08      0.11      0.09       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.61      0.61      0.61   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 23:40:47,566 [INFO] Overall accuracy (micro avg): 0.9985518319134906
2020-01-14 23:43:02,637 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9986         0.9986                       0.9986                0.0004                   0.0014  0.9986
1     Macro avg        0.9994         0.6122                       0.6130                0.0005                   0.3870  0.6122
2  Weighted avg        0.9991         0.9987                       0.9986                0.0012                   0.0014  0.9986
2020-01-14 23:43:03,880 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_shallow_rep3/train_time_kdd99_ae_ann_shallow_rep3_results.xlsx
2020-01-14 23:43:03,889 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 23:43:04,299 [INFO] ================= Finished running 12 experiments ================= 

 - val_f1: 0.9986
 - out_of_sample_accuracy: 0.9213
