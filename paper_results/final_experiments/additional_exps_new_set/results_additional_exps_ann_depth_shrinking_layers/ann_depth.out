Using TensorFlow backend.
2019-12-26 23:55:08,023 [INFO] Read 20 experiments from file: experiment_specs/additional_exps/ann_depth.csv
2019-12-26 23:55:08,023 [INFO] ================= Started running experiments ================= 

2019-12-26 23:55:08,023 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_1
2019-12-26 23:55:08,023 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_1/run_log.log
2019-12-26 23:55:08,023 [INFO] ================= Running experiment no. 1  ================= 

2019-12-26 23:55:08,024 [INFO] Experiment parameters given below
2019-12-26 23:55:08,024 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_1'}
2019-12-26 23:55:08,024 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_1/tf_logs_run_2019_12_26-23_55_08
2019-12-26 23:55:08,024 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 23:55:08,024 [INFO] Reading X, y files
2019-12-26 23:55:08,024 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 23:55:08,286 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 23:55:08,286 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 23:55:08,351 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 23:55:08,352 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 23:55:08,411 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 23:55:08,411 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 23:55:08,418 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 23:55:08,418 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 23:55:08,422 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 23:55:08,422 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 23:55:08,425 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 23:55:08,615 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-26 23:55:08,628 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-26 23:55:08,690 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-26 23:55:08,727 [INFO] _________________________________________________________________
2019-12-26 23:55:08,727 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 23:55:08,727 [INFO] =================================================================
2019-12-26 23:55:08,728 [INFO] dense_1 (Dense)              (None, 16)                1968      
2019-12-26 23:55:08,728 [INFO] _________________________________________________________________
2019-12-26 23:55:08,728 [INFO] batch_normalization_1 (Batch (None, 16)                64        
2019-12-26 23:55:08,728 [INFO] _________________________________________________________________
2019-12-26 23:55:08,728 [INFO] dropout_1 (Dropout)          (None, 16)                0         
2019-12-26 23:55:08,728 [INFO] _________________________________________________________________
2019-12-26 23:55:08,728 [INFO] dense_2 (Dense)              (None, 5)                 85        
2019-12-26 23:55:08,728 [INFO] =================================================================
2019-12-26 23:55:08,728 [INFO] Total params: 2,117
2019-12-26 23:55:08,728 [INFO] Trainable params: 2,085
2019-12-26 23:55:08,728 [INFO] Non-trainable params: 32
2019-12-26 23:55:08,728 [INFO] _________________________________________________________________
2019-12-26 23:55:08,728 [INFO] Training model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-26 23:55:09,100 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-26 23:55:09.373243: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-26 23:55:09.392748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2019-12-26 23:55:09.392921: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x14729b0 executing computations on platform Host. Devices:
2019-12-26 23:55:09.392939: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.1518 - val_loss: 0.0432
 - val_f1: 0.9680
Epoch 2/200
 - 1s - loss: 0.0425 - val_loss: 0.0258
 - val_f1: 0.9743
Epoch 3/200
 - 1s - loss: 0.0291 - val_loss: 0.0178
 - val_f1: 0.9859
Epoch 4/200
 - 1s - loss: 0.0229 - val_loss: 0.0149
 - val_f1: 0.9857
Epoch 5/200
 - 1s - loss: 0.0203 - val_loss: 0.0135
 - val_f1: 0.9894
Epoch 6/200
 - 1s - loss: 0.0189 - val_loss: 0.0123
 - val_f1: 0.9889
Epoch 7/200
 - 1s - loss: 0.0171 - val_loss: 0.0116
 - val_f1: 0.9924
Epoch 8/200
 - 1s - loss: 0.0162 - val_loss: 0.0112
 - val_f1: 0.9904
Epoch 9/200
 - 1s - loss: 0.0150 - val_loss: 0.0110
 - val_f1: 0.9928
Epoch 10/200
 - 1s - loss: 0.0145 - val_loss: 0.0106
 - val_f1: 0.9925
Epoch 11/200
 - 1s - loss: 0.0141 - val_loss: 0.0108
 - val_f1: 0.9904
Epoch 12/200
 - 1s - loss: 0.0133 - val_loss: 0.0102
 - val_f1: 0.9924
Epoch 13/200
 - 1s - loss: 0.0134 - val_loss: 0.0095
 - val_f1: 0.9934
Epoch 14/200
 - 1s - loss: 0.0126 - val_loss: 0.0097
 - val_f1: 0.9930
Epoch 15/200
 - 1s - loss: 0.0123 - val_loss: 0.0092
 - val_f1: 0.9932
Epoch 16/200
 - 1s - loss: 0.0121 - val_loss: 0.0089
 - val_f1: 0.9934
Epoch 17/200
 - 1s - loss: 0.0121 - val_loss: 0.0085
 - val_f1: 0.9934
Epoch 18/200
 - 1s - loss: 0.0117 - val_loss: 0.0085
 - val_f1: 0.9935
Epoch 19/200
 - 1s - loss: 0.0117 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 20/200
 - 1s - loss: 0.0114 - val_loss: 0.0085
 - val_f1: 0.9934
Epoch 21/200
 - 1s - loss: 0.0113 - val_loss: 0.0085
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 23:55:28,650 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_20.pickle
 - val_f1: 0.9940
Epoch 22/200
 - 1s - loss: 0.0108 - val_loss: 0.0084
 - val_f1: 0.9937
Epoch 23/200
 - 1s - loss: 0.0107 - val_loss: 0.0083
 - val_f1: 0.9936
Epoch 24/200
 - 1s - loss: 0.0108 - val_loss: 0.0079
 - val_f1: 0.9941
Epoch 25/200
 - 1s - loss: 0.0105 - val_loss: 0.0079
 - val_f1: 0.9941
Epoch 26/200
 - 1s - loss: 0.0102 - val_loss: 0.0081
 - val_f1: 0.9934
Epoch 27/200
 - 1s - loss: 0.0103 - val_loss: 0.0079
 - val_f1: 0.9941
Epoch 28/200
 - 1s - loss: 0.0102 - val_loss: 0.0078
 - val_f1: 0.9943
Epoch 29/200
 - 1s - loss: 0.0104 - val_loss: 0.0081
 - val_f1: 0.9935
Epoch 30/200
 - 1s - loss: 0.0102 - val_loss: 0.0082
 - val_f1: 0.9938
Epoch 31/200
 - 1s - loss: 0.0104 - val_loss: 0.0079
 - val_f1: 0.9948
Epoch 32/200
 - 1s - loss: 0.0101 - val_loss: 0.0078
 - val_f1: 0.9941
Epoch 33/200
 - 1s - loss: 0.0099 - val_loss: 0.0077
 - val_f1: 0.9940
Epoch 34/200
 - 1s - loss: 0.0101 - val_loss: 0.0080
 - val_f1: 0.9942
Epoch 35/200
 - 1s - loss: 0.0099 - val_loss: 0.0078
 - val_f1: 0.9944
Epoch 36/200
 - 1s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 37/200
 - 1s - loss: 0.0096 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 38/200
 - 1s - loss: 0.0098 - val_loss: 0.0082
 - val_f1: 0.9940
Epoch 39/200
 - 1s - loss: 0.0096 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 40/200
 - 1s - loss: 0.0096 - val_loss: 0.0077
 - val_f1: 0.9941
Epoch 41/200
 - 1s - loss: 0.0096 - val_loss: 0.0075
2019-12-26 23:55:46,769 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_40.pickle
 - val_f1: 0.9941
Epoch 42/200
 - 1s - loss: 0.0096 - val_loss: 0.0075
 - val_f1: 0.9941
Epoch 43/200
 - 1s - loss: 0.0093 - val_loss: 0.0078
 - val_f1: 0.9943
Epoch 44/200
 - 1s - loss: 0.0094 - val_loss: 0.0074
 - val_f1: 0.9942
Epoch 45/200
 - 1s - loss: 0.0094 - val_loss: 0.0074
 - val_f1: 0.9945
Epoch 46/200
 - 1s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 47/200
 - 1s - loss: 0.0090 - val_loss: 0.0078
 - val_f1: 0.9942
Epoch 48/200
 - 1s - loss: 0.0093 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 49/200
 - 1s - loss: 0.0091 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 50/200
 - 1s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9955
Epoch 51/200
 - 1s - loss: 0.0091 - val_loss: 0.0080
 - val_f1: 0.9939
Epoch 52/200
 - 1s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9937
Epoch 53/200
 - 1s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 54/200
 - 1s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 55/200
 - 1s - loss: 0.0089 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 56/200
 - 1s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9947
Epoch 57/200
 - 1s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 58/200
 - 1s - loss: 0.0090 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 59/200
 - 1s - loss: 0.0090 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 60/200
 - 1s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 61/200
 - 1s - loss: 0.0088 - val_loss: 0.0081
2019-12-26 23:56:04,840 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_60.pickle
 - val_f1: 0.9938
Epoch 62/200
 - 1s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9947
Epoch 63/200
 - 1s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9946
Epoch 64/200
 - 1s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9948
Epoch 65/200
 - 1s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 66/200
 - 1s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 67/200
 - 1s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 68/200
 - 1s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 69/200
 - 1s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 70/200
 - 1s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 71/200
 - 1s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 72/200
 - 1s - loss: 0.0083 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 73/200
 - 1s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 74/200
 - 1s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 75/200
 - 1s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 76/200
 - 1s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9951
Epoch 77/200
 - 1s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 78/200
 - 1s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 79/200
 - 1s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 80/200
 - 1s - loss: 0.0083 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 81/200
 - 1s - loss: 0.0084 - val_loss: 0.0076
2019-12-26 23:56:23,028 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_80.pickle
 - val_f1: 0.9949
Epoch 82/200
 - 1s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 83/200
 - 1s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 84/200
 - 1s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 85/200
 - 1s - loss: 0.0082 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 86/200
 - 1s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9950
Epoch 87/200
 - 1s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 88/200
 - 1s - loss: 0.0083 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 89/200
 - 1s - loss: 0.0082 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 90/200
 - 1s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 91/200
 - 1s - loss: 0.0080 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 92/200
 - 1s - loss: 0.0081 - val_loss: 0.0074
 - val_f1: 0.9939
Epoch 93/200
 - 1s - loss: 0.0083 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 94/200
 - 1s - loss: 0.0080 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 95/200
 - 1s - loss: 0.0084 - val_loss: 0.0077
 - val_f1: 0.9942
Epoch 96/200
 - 1s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 97/200
 - 1s - loss: 0.0082 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 98/200
 - 1s - loss: 0.0079 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 99/200
 - 1s - loss: 0.0079 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 100/200
 - 1s - loss: 0.0083 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 101/200
 - 1s - loss: 0.0081 - val_loss: 0.0068
2019-12-26 23:56:40,978 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_100.pickle
 - val_f1: 0.9953
Epoch 102/200
 - 1s - loss: 0.0081 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 103/200
 - 1s - loss: 0.0077 - val_loss: 0.0069
 - val_f1: 0.9948
Epoch 104/200
 - 1s - loss: 0.0081 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 105/200
 - 1s - loss: 0.0079 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 106/200
 - 1s - loss: 0.0079 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 107/200
 - 1s - loss: 0.0082 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 108/200
 - 1s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 109/200
 - 1s - loss: 0.0081 - val_loss: 0.0067
 - val_f1: 0.9950
Epoch 110/200
 - 1s - loss: 0.0080 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 111/200
 - 1s - loss: 0.0081 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 112/200
 - 1s - loss: 0.0083 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 113/200
 - 1s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 114/200
 - 1s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 115/200
 - 1s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 116/200
 - 1s - loss: 0.0080 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 117/200
 - 1s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 118/200
 - 1s - loss: 0.0079 - val_loss: 0.0074
 - val_f1: 0.9951
Epoch 119/200
 - 1s - loss: 0.0081 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 120/200
 - 1s - loss: 0.0077 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 121/200
 - 1s - loss: 0.0081 - val_loss: 0.0074
2019-12-26 23:56:59,060 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_120.pickle
 - val_f1: 0.9950
Epoch 122/200
 - 1s - loss: 0.0079 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 123/200
 - 1s - loss: 0.0078 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 124/200
 - 1s - loss: 0.0080 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 125/200
 - 1s - loss: 0.0082 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 126/200
 - 1s - loss: 0.0081 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 127/200
 - 1s - loss: 0.0080 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 128/200
 - 1s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9950
Epoch 129/200
 - 1s - loss: 0.0082 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 130/200
 - 1s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9947
Epoch 131/200
 - 1s - loss: 0.0079 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 132/200
 - 1s - loss: 0.0078 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 133/200
 - 1s - loss: 0.0078 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 134/200
 - 1s - loss: 0.0078 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 135/200
 - 1s - loss: 0.0076 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 136/200
 - 1s - loss: 0.0078 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 137/200
 - 1s - loss: 0.0078 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 138/200
 - 1s - loss: 0.0077 - val_loss: 0.0073
 - val_f1: 0.9953
Epoch 139/200
 - 1s - loss: 0.0081 - val_loss: 0.0075
 - val_f1: 0.9949
Epoch 140/200
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9954
Epoch 141/200
 - 1s - loss: 0.0077 - val_loss: 0.0072
2019-12-26 23:57:17,024 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_1/ann_model_epoch_140.pickle
 - val_f1: 0.9951
Epoch 142/200
 - 1s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9951
Epoch 143/200
 - 1s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9953
Epoch 144/200
 - 1s - loss: 0.0080 - val_loss: 0.0074
 - val_f1: 0.9953
Epoch 145/200
 - 1s - loss: 0.0078 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 146/200
 - 1s - loss: 0.0077 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 147/200
 - 1s - loss: 0.0076 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 148/200
 - 1s - loss: 0.0081 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 149/200
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 150/200
 - 1s - loss: 0.0079 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 151/200
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 152/200
 - 1s - loss: 0.0081 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 153/200
 - 1s - loss: 0.0077 - val_loss: 0.0072
 - val_f1: 0.9952
Epoch 154/200
 - 1s - loss: 0.0076 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 155/200
 - 1s - loss: 0.0080 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 156/200
 - 1s - loss: 0.0078 - val_loss: 0.0074
2019-12-26 23:57:30,781 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 23:57:32,150 [INFO] Last epoch loss evaluation: train_loss = 0.004984, val_loss = 0.006482
2019-12-26 23:57:32,150 [INFO] Training complete. time_to_train = 143.42 sec, 2.39 min
2019-12-26 23:57:32,153 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_1/best_model.pickle
2019-12-26 23:57:32,156 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_1/training_error_history.csv
2019-12-26 23:57:32,354 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_1/training_error_history.png
2019-12-26 23:57:32,527 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_1/training_f1_history.png
2019-12-26 23:57:32,527 [INFO] Making predictions on training, validation, testing data
2019-12-26 23:57:33,655 [INFO] Evaluating predictions (results)
2019-12-26 23:57:34,005 [INFO] Dataset: Testing. Classification report below
2019-12-26 23:57:34,005 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.85      0.91      7458
      normal       0.68      0.96      0.79      9711
       probe       0.80      0.63      0.70      2421
         r2l       0.92      0.09      0.16      2421
         u2r       0.07      0.02      0.03       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.69      0.51      0.52     22544
weighted avg       0.80      0.77      0.73     22544

2019-12-26 23:57:34,005 [INFO] Overall accuracy (micro avg): 0.7707150461320085
2019-12-26 23:57:34,302 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7707         0.7707                       0.7707                0.0573                   0.2293  0.7707
1     Macro avg        0.9083         0.6877                       0.5080                0.0769                   0.4920  0.5180
2  Weighted avg        0.8710         0.7999                       0.7707                0.1550                   0.2293  0.7347
2019-12-26 23:57:34,635 [INFO] Dataset: Validation. Classification report below
2019-12-26 23:57:34,635 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.94      0.87      0.91       199
         u2r       1.00      0.40      0.57        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.98      0.85      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-26 23:57:34,636 [INFO] Overall accuracy (micro avg): 0.9958721968644573
2019-12-26 23:57:34,992 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0010                   0.0041  0.9959
1     Macro avg        0.9983         0.9849                       0.8522                0.0014                   0.1478  0.8926
2  Weighted avg        0.9974         0.9958                       0.9959                0.0029                   0.0041  0.9958
2019-12-26 23:57:36,430 [INFO] Dataset: Training. Classification report below
2019-12-26 23:57:36,430 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.96      0.89      0.93       796
         u2r       0.96      0.55      0.70        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.89      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-26 23:57:36,430 [INFO] Overall accuracy (micro avg): 0.9965369425866757
2019-12-26 23:57:38,046 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9965         0.9965                       0.9965                0.0009                   0.0035  0.9965
1     Macro avg        0.9986         0.9818                       0.8857                0.0012                   0.1143  0.9223
2  Weighted avg        0.9978         0.9965                       0.9965                0.0026                   0.0035  0.9965
2019-12-26 23:57:38,085 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_1/ann_depth_nsl_layers_1_results.xlsx
2019-12-26 23:57:38,085 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-26 23:57:38,088 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_2
2019-12-26 23:57:38,089 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_2/run_log.log
2019-12-26 23:57:38,089 [INFO] ================= Running experiment no. 2  ================= 

2019-12-26 23:57:38,089 [INFO] Experiment parameters given below
2019-12-26 23:57:38,089 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_2'}
2019-12-26 23:57:38,089 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_2/tf_logs_run_2019_12_26-23_57_38
2019-12-26 23:57:38,089 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 23:57:38,089 [INFO] Reading X, y files
2019-12-26 23:57:38,089 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 23:57:38,333 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-26 23:57:38,333 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 23:57:38,397 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 23:57:38,398 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 23:57:38,456 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 23:57:38,456 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 23:57:38,463 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 23:57:38,463 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 23:57:38,467 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 23:57:38,467 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 23:57:38,471 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 23:57:38,656 [INFO] Initializing model
2019-12-26 23:57:38,894 [INFO] _________________________________________________________________
2019-12-26 23:57:38,894 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 23:57:38,894 [INFO] =================================================================
2019-12-26 23:57:38,894 [INFO] dense_3 (Dense)              (None, 32)                3936      
2019-12-26 23:57:38,894 [INFO] _________________________________________________________________
2019-12-26 23:57:38,894 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-26 23:57:38,894 [INFO] _________________________________________________________________
2019-12-26 23:57:38,894 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-26 23:57:38,895 [INFO] _________________________________________________________________
2019-12-26 23:57:38,895 [INFO] dense_4 (Dense)              (None, 16)                528       
2019-12-26 23:57:38,895 [INFO] _________________________________________________________________
2019-12-26 23:57:38,895 [INFO] batch_normalization_3 (Batch (None, 16)                64        
2019-12-26 23:57:38,895 [INFO] _________________________________________________________________
2019-12-26 23:57:38,895 [INFO] dropout_3 (Dropout)          (None, 16)                0         
2019-12-26 23:57:38,895 [INFO] _________________________________________________________________
2019-12-26 23:57:38,895 [INFO] dense_5 (Dense)              (None, 5)                 85        
2019-12-26 23:57:38,895 [INFO] =================================================================
2019-12-26 23:57:38,895 [INFO] Total params: 4,741
2019-12-26 23:57:38,895 [INFO] Trainable params: 4,645
2019-12-26 23:57:38,895 [INFO] Non-trainable params: 96
2019-12-26 23:57:38,895 [INFO] _________________________________________________________________
2019-12-26 23:57:38,895 [INFO] Training model
 - val_f1: 0.9950
Epoch 00156: early stopping
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.1439 - val_loss: 0.0396
 - val_f1: 0.9698
Epoch 2/200
 - 1s - loss: 0.0413 - val_loss: 0.0203
 - val_f1: 0.9745
Epoch 3/200
 - 1s - loss: 0.0284 - val_loss: 0.0155
 - val_f1: 0.9862
Epoch 4/200
 - 1s - loss: 0.0223 - val_loss: 0.0132
 - val_f1: 0.9887
Epoch 5/200
 - 1s - loss: 0.0196 - val_loss: 0.0127
 - val_f1: 0.9898
Epoch 6/200
 - 1s - loss: 0.0180 - val_loss: 0.0116
 - val_f1: 0.9907
Epoch 7/200
 - 1s - loss: 0.0161 - val_loss: 0.0101
 - val_f1: 0.9908
Epoch 8/200
 - 1s - loss: 0.0154 - val_loss: 0.0102
 - val_f1: 0.9911
Epoch 9/200
 - 1s - loss: 0.0149 - val_loss: 0.0100
 - val_f1: 0.9896
Epoch 10/200
 - 1s - loss: 0.0139 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 11/200
 - 1s - loss: 0.0131 - val_loss: 0.0091
 - val_f1: 0.9918
Epoch 12/200
 - 1s - loss: 0.0124 - val_loss: 0.0083
 - val_f1: 0.9940
Epoch 13/200
 - 1s - loss: 0.0123 - val_loss: 0.0080
 - val_f1: 0.9936
Epoch 14/200
 - 1s - loss: 0.0119 - val_loss: 0.0079
 - val_f1: 0.9944
Epoch 15/200
 - 1s - loss: 0.0118 - val_loss: 0.0083
 - val_f1: 0.9929
Epoch 16/200
 - 1s - loss: 0.0115 - val_loss: 0.0077
 - val_f1: 0.9944
Epoch 17/200
 - 1s - loss: 0.0109 - val_loss: 0.0081
 - val_f1: 0.9934
Epoch 18/200
 - 1s - loss: 0.0109 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 19/200
 - 1s - loss: 0.0105 - val_loss: 0.0073
 - val_f1: 0.9944
Epoch 20/200
 - 1s - loss: 0.0107 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 21/200
 - 1s - loss: 0.0103 - val_loss: 0.0070
2019-12-26 23:58:03,372 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_20.pickle
 - val_f1: 0.9953
Epoch 22/200
 - 1s - loss: 0.0099 - val_loss: 0.0068
 - val_f1: 0.9950
Epoch 23/200
 - 1s - loss: 0.0094 - val_loss: 0.0068
 - val_f1: 0.9947
Epoch 24/200
 - 1s - loss: 0.0095 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 25/200
 - 1s - loss: 0.0099 - val_loss: 0.0072
 - val_f1: 0.9944
Epoch 26/200
 - 1s - loss: 0.0095 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 27/200
 - 1s - loss: 0.0094 - val_loss: 0.0064
 - val_f1: 0.9952
Epoch 28/200
 - 1s - loss: 0.0091 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 29/200
 - 1s - loss: 0.0087 - val_loss: 0.0064
 - val_f1: 0.9954
Epoch 30/200
 - 1s - loss: 0.0086 - val_loss: 0.0064
 - val_f1: 0.9953
Epoch 31/200
 - 1s - loss: 0.0092 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 32/200
 - 1s - loss: 0.0088 - val_loss: 0.0065
 - val_f1: 0.9950
Epoch 33/200
 - 1s - loss: 0.0085 - val_loss: 0.0061
 - val_f1: 0.9955
Epoch 34/200
 - 1s - loss: 0.0085 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 35/200
 - 1s - loss: 0.0086 - val_loss: 0.0062
 - val_f1: 0.9955
Epoch 36/200
 - 1s - loss: 0.0082 - val_loss: 0.0064
 - val_f1: 0.9959
Epoch 37/200
 - 1s - loss: 0.0082 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 38/200
 - 1s - loss: 0.0083 - val_loss: 0.0064
 - val_f1: 0.9955
Epoch 39/200
 - 1s - loss: 0.0082 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 40/200
 - 1s - loss: 0.0080 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 41/200
 - 1s - loss: 0.0078 - val_loss: 0.0059
2019-12-26 23:58:25,126 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_40.pickle
 - val_f1: 0.9959
Epoch 42/200
 - 1s - loss: 0.0078 - val_loss: 0.0062
 - val_f1: 0.9953
Epoch 43/200
 - 1s - loss: 0.0079 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 44/200
 - 1s - loss: 0.0074 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 45/200
 - 1s - loss: 0.0076 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 46/200
 - 1s - loss: 0.0075 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 47/200
 - 1s - loss: 0.0077 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 48/200
 - 1s - loss: 0.0075 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 49/200
 - 1s - loss: 0.0075 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 50/200
 - 1s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9957
Epoch 51/200
 - 1s - loss: 0.0073 - val_loss: 0.0055
 - val_f1: 0.9958
Epoch 52/200
 - 1s - loss: 0.0072 - val_loss: 0.0057
 - val_f1: 0.9957
Epoch 53/200
 - 1s - loss: 0.0071 - val_loss: 0.0056
 - val_f1: 0.9963
Epoch 54/200
 - 1s - loss: 0.0070 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 55/200
 - 1s - loss: 0.0071 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 56/200
 - 1s - loss: 0.0071 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 57/200
 - 1s - loss: 0.0071 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 58/200
 - 1s - loss: 0.0073 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 59/200
 - 1s - loss: 0.0067 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 60/200
 - 1s - loss: 0.0071 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 61/200
 - 1s - loss: 0.0068 - val_loss: 0.0052
2019-12-26 23:58:46,799 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_60.pickle
 - val_f1: 0.9960
Epoch 62/200
 - 1s - loss: 0.0066 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 63/200
 - 1s - loss: 0.0070 - val_loss: 0.0059
 - val_f1: 0.9958
Epoch 64/200
 - 1s - loss: 0.0070 - val_loss: 0.0052
 - val_f1: 0.9958
Epoch 65/200
 - 1s - loss: 0.0072 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 66/200
 - 1s - loss: 0.0067 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 67/200
 - 1s - loss: 0.0068 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 68/200
 - 1s - loss: 0.0068 - val_loss: 0.0051
 - val_f1: 0.9958
Epoch 69/200
 - 1s - loss: 0.0069 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 70/200
 - 1s - loss: 0.0069 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 71/200
 - 1s - loss: 0.0069 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 72/200
 - 1s - loss: 0.0066 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 73/200
 - 1s - loss: 0.0068 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 74/200
 - 1s - loss: 0.0067 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 75/200
 - 1s - loss: 0.0063 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 76/200
 - 1s - loss: 0.0066 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 77/200
 - 1s - loss: 0.0071 - val_loss: 0.0058
 - val_f1: 0.9956
Epoch 78/200
 - 1s - loss: 0.0073 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 79/200
 - 1s - loss: 0.0067 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 80/200
 - 1s - loss: 0.0063 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 81/200
 - 1s - loss: 0.0064 - val_loss: 0.0048
2019-12-26 23:59:08,519 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_80.pickle
 - val_f1: 0.9961
Epoch 82/200
 - 1s - loss: 0.0066 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 83/200
 - 1s - loss: 0.0069 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 84/200
 - 1s - loss: 0.0065 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 85/200
 - 1s - loss: 0.0062 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 86/200
 - 1s - loss: 0.0064 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 87/200
 - 1s - loss: 0.0065 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 88/200
 - 1s - loss: 0.0064 - val_loss: 0.0049
 - val_f1: 0.9960
Epoch 89/200
 - 1s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 90/200
 - 1s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 91/200
 - 1s - loss: 0.0064 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 92/200
 - 1s - loss: 0.0062 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 93/200
 - 1s - loss: 0.0064 - val_loss: 0.0047
 - val_f1: 0.9959
Epoch 94/200
 - 1s - loss: 0.0060 - val_loss: 0.0053
 - val_f1: 0.9956
Epoch 95/200
 - 1s - loss: 0.0063 - val_loss: 0.0045
 - val_f1: 0.9963
Epoch 96/200
 - 1s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9960
Epoch 97/200
 - 1s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 98/200
 - 1s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 99/200
 - 1s - loss: 0.0063 - val_loss: 0.0047
 - val_f1: 0.9962
Epoch 100/200
 - 1s - loss: 0.0060 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 101/200
 - 1s - loss: 0.0068 - val_loss: 0.0049
2019-12-26 23:59:30,300 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_100.pickle
 - val_f1: 0.9962
Epoch 102/200
 - 1s - loss: 0.0061 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 103/200
 - 1s - loss: 0.0062 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 104/200
 - 1s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 105/200
 - 1s - loss: 0.0063 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 106/200
 - 1s - loss: 0.0057 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 107/200
 - 1s - loss: 0.0062 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 108/200
 - 1s - loss: 0.0059 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 109/200
 - 1s - loss: 0.0062 - val_loss: 0.0053
 - val_f1: 0.9960
Epoch 110/200
 - 1s - loss: 0.0060 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 111/200
 - 1s - loss: 0.0061 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 112/200
 - 1s - loss: 0.0062 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 113/200
 - 1s - loss: 0.0060 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 114/200
 - 1s - loss: 0.0060 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 115/200
 - 1s - loss: 0.0060 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 116/200
 - 1s - loss: 0.0064 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 117/200
 - 1s - loss: 0.0060 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 118/200
 - 1s - loss: 0.0062 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 119/200
 - 1s - loss: 0.0058 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 120/200
 - 1s - loss: 0.0061 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 121/200
 - 1s - loss: 0.0059 - val_loss: 0.0049
2019-12-26 23:59:52,015 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_120.pickle
 - val_f1: 0.9962
Epoch 122/200
 - 1s - loss: 0.0065 - val_loss: 0.0053
 - val_f1: 0.9954
Epoch 123/200
 - 1s - loss: 0.0060 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 124/200
 - 1s - loss: 0.0058 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 125/200
 - 1s - loss: 0.0056 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 126/200
 - 1s - loss: 0.0063 - val_loss: 0.0052
 - val_f1: 0.9959
Epoch 127/200
 - 1s - loss: 0.0062 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 128/200
 - 1s - loss: 0.0060 - val_loss: 0.0051
 - val_f1: 0.9958
Epoch 129/200
 - 1s - loss: 0.0056 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 130/200
 - 1s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 131/200
 - 1s - loss: 0.0061 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 132/200
 - 1s - loss: 0.0056 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 133/200
 - 1s - loss: 0.0061 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 134/200
 - 1s - loss: 0.0059 - val_loss: 0.0047
 - val_f1: 0.9961
Epoch 135/200
 - 1s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 136/200
 - 1s - loss: 0.0058 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 137/200
 - 1s - loss: 0.0059 - val_loss: 0.0046
 - val_f1: 0.9962
Epoch 138/200
 - 1s - loss: 0.0056 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 139/200
 - 1s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 140/200
 - 1s - loss: 0.0058 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 141/200
 - 1s - loss: 0.0058 - val_loss: 0.0046
2019-12-27 00:00:13,723 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_140.pickle
 - val_f1: 0.9964
Epoch 142/200
 - 1s - loss: 0.0056 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 143/200
 - 1s - loss: 0.0056 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 144/200
 - 1s - loss: 0.0062 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 145/200
 - 1s - loss: 0.0056 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 146/200
 - 1s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 147/200
 - 1s - loss: 0.0057 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 148/200
 - 1s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 149/200
 - 1s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9963
Epoch 150/200
 - 1s - loss: 0.0060 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 151/200
 - 1s - loss: 0.0060 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 152/200
 - 1s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9962
Epoch 153/200
 - 1s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9963
Epoch 154/200
 - 1s - loss: 0.0058 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 155/200
 - 1s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9964
Epoch 156/200
 - 1s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9964
Epoch 157/200
 - 1s - loss: 0.0056 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 158/200
 - 1s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 159/200
 - 1s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 160/200
 - 1s - loss: 0.0056 - val_loss: 0.0043
 - val_f1: 0.9965
Epoch 161/200
 - 1s - loss: 0.0058 - val_loss: 0.0048
2019-12-27 00:00:35,407 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_160.pickle
 - val_f1: 0.9964
Epoch 162/200
 - 1s - loss: 0.0062 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 163/200
 - 1s - loss: 0.0061 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 164/200
 - 1s - loss: 0.0060 - val_loss: 0.0052
 - val_f1: 0.9954
Epoch 165/200
 - 1s - loss: 0.0059 - val_loss: 0.0047
 - val_f1: 0.9961
Epoch 166/200
 - 1s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 167/200
 - 1s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 168/200
 - 1s - loss: 0.0054 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 169/200
 - 1s - loss: 0.0056 - val_loss: 0.0042
 - val_f1: 0.9968
Epoch 170/200
 - 1s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 171/200
 - 1s - loss: 0.0052 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 172/200
 - 1s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 173/200
 - 1s - loss: 0.0057 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 174/200
 - 1s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9960
Epoch 175/200
 - 1s - loss: 0.0057 - val_loss: 0.0046
 - val_f1: 0.9963
Epoch 176/200
 - 1s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9964
Epoch 177/200
 - 1s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 178/200
 - 1s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 179/200
 - 1s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 180/200
 - 1s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 181/200
 - 1s - loss: 0.0057 - val_loss: 0.0045
2019-12-27 00:00:57,124 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_2/ann_model_epoch_180.pickle
 - val_f1: 0.9966
Epoch 182/200
 - 1s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9962
Epoch 183/200
 - 1s - loss: 0.0057 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 184/200
 - 1s - loss: 0.0055 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 185/200
 - 1s - loss: 0.0054 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 186/200
 - 1s - loss: 0.0054 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 187/200
 - 1s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9962
Epoch 188/200
 - 1s - loss: 0.0053 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 189/200
 - 1s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 190/200
 - 1s - loss: 0.0052 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 191/200
 - 1s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9969
Epoch 192/200
 - 1s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 193/200
 - 1s - loss: 0.0056 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 194/200
 - 1s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 195/200
 - 1s - loss: 0.0055 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 196/200
 - 1s - loss: 0.0053 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 197/200
 - 1s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 198/200
 - 1s - loss: 0.0054 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 199/200
 - 1s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 200/200
 - 1s - loss: 0.0056 - val_loss: 0.0045
2019-12-27 00:01:18,017 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:01:19,586 [INFO] Last epoch loss evaluation: train_loss = 0.002831, val_loss = 0.004166
2019-12-27 00:01:19,586 [INFO] Training complete. time_to_train = 220.69 sec, 3.68 min
2019-12-27 00:01:19,591 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_2/best_model.pickle
2019-12-27 00:01:19,594 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_2/training_error_history.csv
2019-12-27 00:01:19,782 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_2/training_error_history.png
2019-12-27 00:01:19,955 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_2/training_f1_history.png
2019-12-27 00:01:19,955 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:01:21,412 [INFO] Evaluating predictions (results)
2019-12-27 00:01:21,669 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:01:21,669 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.89      7458
      normal       0.69      0.97      0.80      9711
       probe       0.85      0.66      0.74      2421
         r2l       0.78      0.10      0.18      2421
         u2r       0.68      0.03      0.05       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.79      0.52      0.54     22544
weighted avg       0.80      0.78      0.74     22544

2019-12-27 00:01:21,669 [INFO] Overall accuracy (micro avg): 0.7787437899219305
2019-12-27 00:01:21,963 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7787         0.7787                       0.7787                0.0553                   0.2213  0.7787
1     Macro avg        0.9115         0.7904                       0.5202                0.0751                   0.4798  0.5356
2  Weighted avg        0.8735         0.8023                       0.7787                0.1540                   0.2213  0.7425
2019-12-27 00:01:22,295 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:01:22,295 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.96      0.90      0.93       199
         u2r       0.80      0.40      0.53        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.95      0.86      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:01:22,295 [INFO] Overall accuracy (micro avg): 0.9971422901369319
2019-12-27 00:01:22,651 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9971         0.9971                       0.9971                0.0007                   0.0029  0.9971
1     Macro avg        0.9989         0.9507                       0.8590                0.0010                   0.1410  0.8913
2  Weighted avg        0.9982         0.9971                       0.9971                0.0022                   0.0029  0.9971
2019-12-27 00:01:24,094 [INFO] Dataset: Training. Classification report below
2019-12-27 00:01:24,094 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.96      0.92      0.94       796
         u2r       0.96      0.57      0.72        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.90      0.93    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:01:24,094 [INFO] Overall accuracy (micro avg): 0.9976979102581913
2019-12-27 00:01:25,716 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9977         0.9977                       0.9977                0.0006                   0.0023  0.9977
1     Macro avg        0.9991         0.9834                       0.8960                0.0009                   0.1040  0.9297
2  Weighted avg        0.9986         0.9977                       0.9977                0.0019                   0.0023  0.9977
2019-12-27 00:01:25,754 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_2/ann_depth_nsl_layers_2_results.xlsx
2019-12-27 00:01:25,754 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-27 00:01:25,757 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_3
2019-12-27 00:01:25,757 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_3/run_log.log
2019-12-27 00:01:25,757 [INFO] ================= Running experiment no. 3  ================= 

2019-12-27 00:01:25,757 [INFO] Experiment parameters given below
2019-12-27 00:01:25,758 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_3'}
2019-12-27 00:01:25,758 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_3/tf_logs_run_2019_12_27-00_01_25
2019-12-27 00:01:25,758 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:01:25,758 [INFO] Reading X, y files
2019-12-27 00:01:25,758 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:01:26,005 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:01:26,006 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:01:26,068 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:01:26,068 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:01:26,125 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:01:26,125 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:01:26,132 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:01:26,132 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:01:26,136 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:01:26,136 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:01:26,139 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:01:26,326 [INFO] Initializing model
2019-12-27 00:01:26,647 [INFO] _________________________________________________________________
2019-12-27 00:01:26,647 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:01:26,647 [INFO] =================================================================
2019-12-27 00:01:26,647 [INFO] dense_6 (Dense)              (None, 64)                7872      
2019-12-27 00:01:26,647 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] dense_7 (Dense)              (None, 32)                2080      
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] dense_8 (Dense)              (None, 16)                528       
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,648 [INFO] batch_normalization_6 (Batch (None, 16)                64        
2019-12-27 00:01:26,648 [INFO] _________________________________________________________________
2019-12-27 00:01:26,649 [INFO] dropout_6 (Dropout)          (None, 16)                0         
2019-12-27 00:01:26,649 [INFO] _________________________________________________________________
2019-12-27 00:01:26,649 [INFO] dense_9 (Dense)              (None, 5)                 85        
2019-12-27 00:01:26,649 [INFO] =================================================================
2019-12-27 00:01:26,649 [INFO] Total params: 11,013
2019-12-27 00:01:26,649 [INFO] Trainable params: 10,789
2019-12-27 00:01:26,649 [INFO] Non-trainable params: 224
2019-12-27 00:01:26,649 [INFO] _________________________________________________________________
2019-12-27 00:01:26,649 [INFO] Training model
 - val_f1: 0.9966
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 2s - loss: 0.1299 - val_loss: 0.0262
 - val_f1: 0.9734
Epoch 2/200
 - 1s - loss: 0.0326 - val_loss: 0.0142
 - val_f1: 0.9849
Epoch 3/200
 - 1s - loss: 0.0238 - val_loss: 0.0127
 - val_f1: 0.9886
Epoch 4/200
 - 1s - loss: 0.0199 - val_loss: 0.0111
 - val_f1: 0.9903
Epoch 5/200
 - 1s - loss: 0.0178 - val_loss: 0.0105
 - val_f1: 0.9920
Epoch 6/200
 - 1s - loss: 0.0161 - val_loss: 0.0105
 - val_f1: 0.9896
Epoch 7/200
 - 1s - loss: 0.0150 - val_loss: 0.0094
 - val_f1: 0.9930
Epoch 8/200
 - 1s - loss: 0.0141 - val_loss: 0.0094
 - val_f1: 0.9915
Epoch 9/200
 - 1s - loss: 0.0130 - val_loss: 0.0084
 - val_f1: 0.9935
Epoch 10/200
 - 1s - loss: 0.0123 - val_loss: 0.0092
 - val_f1: 0.9922
Epoch 11/200
 - 1s - loss: 0.0119 - val_loss: 0.0087
 - val_f1: 0.9941
Epoch 12/200
 - 1s - loss: 0.0115 - val_loss: 0.0082
 - val_f1: 0.9934
Epoch 13/200
 - 1s - loss: 0.0112 - val_loss: 0.0075
 - val_f1: 0.9948
Epoch 14/200
 - 1s - loss: 0.0107 - val_loss: 0.0078
 - val_f1: 0.9944
Epoch 15/200
 - 1s - loss: 0.0102 - val_loss: 0.0076
 - val_f1: 0.9938
Epoch 16/200
 - 1s - loss: 0.0102 - val_loss: 0.0071
 - val_f1: 0.9947
Epoch 17/200
 - 1s - loss: 0.0097 - val_loss: 0.0075
 - val_f1: 0.9946
Epoch 18/200
 - 1s - loss: 0.0095 - val_loss: 0.0071
 - val_f1: 0.9944
Epoch 19/200
 - 1s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9948
Epoch 20/200
 - 1s - loss: 0.0092 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 21/200
 - 1s - loss: 0.0087 - val_loss: 0.0066
2019-12-27 00:01:58,776 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_20.pickle
 - val_f1: 0.9953
Epoch 22/200
 - 1s - loss: 0.0087 - val_loss: 0.0065
 - val_f1: 0.9949
Epoch 23/200
 - 1s - loss: 0.0085 - val_loss: 0.0063
 - val_f1: 0.9950
Epoch 24/200
 - 1s - loss: 0.0087 - val_loss: 0.0067
 - val_f1: 0.9950
Epoch 25/200
 - 1s - loss: 0.0081 - val_loss: 0.0064
 - val_f1: 0.9953
Epoch 26/200
 - 1s - loss: 0.0081 - val_loss: 0.0061
 - val_f1: 0.9955
Epoch 27/200
 - 1s - loss: 0.0079 - val_loss: 0.0060
 - val_f1: 0.9955
Epoch 28/200
 - 1s - loss: 0.0078 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 29/200
 - 1s - loss: 0.0080 - val_loss: 0.0060
 - val_f1: 0.9955
Epoch 30/200
 - 1s - loss: 0.0076 - val_loss: 0.0063
 - val_f1: 0.9948
Epoch 31/200
 - 1s - loss: 0.0073 - val_loss: 0.0063
 - val_f1: 0.9952
Epoch 32/200
 - 1s - loss: 0.0076 - val_loss: 0.0065
 - val_f1: 0.9955
Epoch 33/200
 - 1s - loss: 0.0071 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 34/200
 - 1s - loss: 0.0070 - val_loss: 0.0058
 - val_f1: 0.9960
Epoch 35/200
 - 1s - loss: 0.0072 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 36/200
 - 1s - loss: 0.0068 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 37/200
 - 1s - loss: 0.0066 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 38/200
 - 1s - loss: 0.0069 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 39/200
 - 1s - loss: 0.0069 - val_loss: 0.0058
 - val_f1: 0.9957
Epoch 40/200
 - 1s - loss: 0.0064 - val_loss: 0.0061
 - val_f1: 0.9956
Epoch 41/200
 - 1s - loss: 0.0067 - val_loss: 0.0054
2019-12-27 00:02:27,423 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_40.pickle
 - val_f1: 0.9959
Epoch 42/200
 - 1s - loss: 0.0066 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 43/200
 - 1s - loss: 0.0067 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 44/200
 - 1s - loss: 0.0062 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 45/200
 - 1s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9959
Epoch 46/200
 - 1s - loss: 0.0063 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 47/200
 - 1s - loss: 0.0060 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 48/200
 - 1s - loss: 0.0059 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 49/200
 - 1s - loss: 0.0058 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 50/200
 - 1s - loss: 0.0064 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 51/200
 - 1s - loss: 0.0059 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 52/200
 - 1s - loss: 0.0058 - val_loss: 0.0053
 - val_f1: 0.9959
Epoch 53/200
 - 1s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9960
Epoch 54/200
 - 1s - loss: 0.0061 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 55/200
 - 1s - loss: 0.0057 - val_loss: 0.0046
 - val_f1: 0.9963
Epoch 56/200
 - 1s - loss: 0.0060 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 57/200
 - 1s - loss: 0.0058 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 58/200
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9953
Epoch 59/200
 - 1s - loss: 0.0054 - val_loss: 0.0052
 - val_f1: 0.9961
Epoch 60/200
 - 1s - loss: 0.0058 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 61/200
 - 1s - loss: 0.0056 - val_loss: 0.0054
2019-12-27 00:02:56,216 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_60.pickle
 - val_f1: 0.9960
Epoch 62/200
 - 1s - loss: 0.0058 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 63/200
 - 1s - loss: 0.0055 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 64/200
 - 1s - loss: 0.0057 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 65/200
 - 1s - loss: 0.0053 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 66/200
 - 1s - loss: 0.0053 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 67/200
 - 1s - loss: 0.0053 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 68/200
 - 1s - loss: 0.0055 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 69/200
 - 1s - loss: 0.0053 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 70/200
 - 1s - loss: 0.0055 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 71/200
 - 1s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 72/200
 - 1s - loss: 0.0054 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 73/200
 - 1s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 74/200
 - 1s - loss: 0.0053 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 75/200
 - 1s - loss: 0.0052 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 76/200
 - 1s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 77/200
 - 1s - loss: 0.0053 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 78/200
 - 1s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9968
Epoch 79/200
 - 1s - loss: 0.0053 - val_loss: 0.0043
 - val_f1: 0.9965
Epoch 80/200
 - 1s - loss: 0.0050 - val_loss: 0.0045
 - val_f1: 0.9961
Epoch 81/200
 - 1s - loss: 0.0050 - val_loss: 0.0043
2019-12-27 00:03:24,930 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_80.pickle
 - val_f1: 0.9967
Epoch 82/200
 - 1s - loss: 0.0050 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 83/200
 - 1s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 84/200
 - 1s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9963
Epoch 85/200
 - 1s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9961
Epoch 86/200
 - 1s - loss: 0.0047 - val_loss: 0.0047
 - val_f1: 0.9961
Epoch 87/200
 - 1s - loss: 0.0053 - val_loss: 0.0045
 - val_f1: 0.9963
Epoch 88/200
 - 1s - loss: 0.0052 - val_loss: 0.0048
 - val_f1: 0.9961
Epoch 89/200
 - 1s - loss: 0.0051 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 90/200
 - 1s - loss: 0.0050 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 91/200
 - 1s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 92/200
 - 1s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9965
Epoch 93/200
 - 1s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9966
Epoch 94/200
 - 1s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 95/200
 - 1s - loss: 0.0047 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 96/200
 - 1s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9966
Epoch 97/200
 - 1s - loss: 0.0051 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 98/200
 - 1s - loss: 0.0047 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 99/200
 - 1s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9961
Epoch 100/200
 - 1s - loss: 0.0048 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 101/200
 - 1s - loss: 0.0048 - val_loss: 0.0044
2019-12-27 00:03:53,683 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_100.pickle
 - val_f1: 0.9964
Epoch 102/200
 - 1s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 103/200
 - 1s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9964
Epoch 104/200
 - 1s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9966
Epoch 105/200
 - 1s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9963
Epoch 106/200
 - 1s - loss: 0.0047 - val_loss: 0.0046
 - val_f1: 0.9962
Epoch 107/200
 - 1s - loss: 0.0045 - val_loss: 0.0043
 - val_f1: 0.9966
Epoch 108/200
 - 1s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9962
Epoch 109/200
 - 1s - loss: 0.0051 - val_loss: 0.0042
 - val_f1: 0.9964
Epoch 110/200
 - 1s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9968
Epoch 111/200
 - 1s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 112/200
 - 1s - loss: 0.0045 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 113/200
 - 1s - loss: 0.0048 - val_loss: 0.0046
 - val_f1: 0.9962
Epoch 114/200
 - 1s - loss: 0.0046 - val_loss: 0.0043
 - val_f1: 0.9968
Epoch 115/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 116/200
 - 1s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 117/200
 - 1s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 118/200
 - 1s - loss: 0.0044 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 119/200
 - 1s - loss: 0.0049 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 120/200
 - 1s - loss: 0.0046 - val_loss: 0.0043
 - val_f1: 0.9963
Epoch 121/200
 - 1s - loss: 0.0047 - val_loss: 0.0040
2019-12-27 00:04:22,308 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_120.pickle
 - val_f1: 0.9969
Epoch 122/200
 - 1s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9965
Epoch 123/200
 - 1s - loss: 0.0044 - val_loss: 0.0044
 - val_f1: 0.9963
Epoch 124/200
 - 1s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 125/200
 - 1s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 126/200
 - 1s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 127/200
 - 1s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9966
Epoch 128/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9964
Epoch 129/200
 - 1s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 130/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9964
Epoch 131/200
 - 1s - loss: 0.0045 - val_loss: 0.0043
 - val_f1: 0.9966
Epoch 132/200
 - 1s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 133/200
 - 1s - loss: 0.0045 - val_loss: 0.0042
 - val_f1: 0.9966
Epoch 134/200
 - 1s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 135/200
 - 1s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 136/200
 - 1s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 137/200
 - 1s - loss: 0.0043 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 138/200
 - 1s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9966
Epoch 139/200
 - 1s - loss: 0.0047 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 140/200
 - 1s - loss: 0.0043 - val_loss: 0.0043
 - val_f1: 0.9966
Epoch 141/200
 - 1s - loss: 0.0041 - val_loss: 0.0044
2019-12-27 00:04:50,981 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_140.pickle
 - val_f1: 0.9966
Epoch 142/200
 - 1s - loss: 0.0041 - val_loss: 0.0038
 - val_f1: 0.9971
Epoch 143/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 144/200
 - 1s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 145/200
 - 1s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 146/200
 - 1s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9966
Epoch 147/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9969
Epoch 148/200
 - 1s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9965
Epoch 149/200
 - 1s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9968
Epoch 150/200
 - 1s - loss: 0.0045 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 151/200
 - 1s - loss: 0.0042 - val_loss: 0.0043
 - val_f1: 0.9966
Epoch 152/200
 - 1s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 153/200
 - 1s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 154/200
 - 1s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 155/200
 - 1s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 156/200
 - 1s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9965
Epoch 157/200
 - 1s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9967
Epoch 158/200
 - 1s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9970
Epoch 159/200
 - 1s - loss: 0.0041 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 160/200
 - 1s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 161/200
 - 1s - loss: 0.0043 - val_loss: 0.0037
2019-12-27 00:05:19,660 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_160.pickle
 - val_f1: 0.9967
Epoch 162/200
 - 1s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 163/200
 - 1s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9970
Epoch 164/200
 - 1s - loss: 0.0041 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 165/200
 - 1s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 166/200
 - 1s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9970
Epoch 167/200
 - 1s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 168/200
 - 1s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 169/200
 - 1s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9968
Epoch 170/200
 - 1s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 171/200
 - 1s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9970
Epoch 172/200
 - 1s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9965
Epoch 173/200
 - 1s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9971
Epoch 174/200
 - 1s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9968
Epoch 175/200
 - 1s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 176/200
 - 1s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 177/200
 - 1s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9972
Epoch 178/200
 - 1s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 179/200
 - 1s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 180/200
 - 1s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 181/200
 - 1s - loss: 0.0038 - val_loss: 0.0040
2019-12-27 00:05:48,299 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_3/ann_model_epoch_180.pickle
 - val_f1: 0.9967
Epoch 182/200
 - 1s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9970
Epoch 183/200
 - 1s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 184/200
 - 1s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9970
Epoch 185/200
 - 1s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9970
Epoch 186/200
 - 1s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9969
Epoch 187/200
 - 1s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9968
Epoch 188/200
 - 1s - loss: 0.0042 - val_loss: 0.0042
 - val_f1: 0.9968
Epoch 189/200
 - 1s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9967
Epoch 190/200
 - 1s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 191/200
 - 1s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9971
Epoch 192/200
 - 1s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9974
Epoch 193/200
 - 1s - loss: 0.0037 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 194/200
 - 1s - loss: 0.0039 - val_loss: 0.0041
 - val_f1: 0.9965
Epoch 195/200
 - 1s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9968
Epoch 196/200
 - 1s - loss: 0.0037 - val_loss: 0.0040
 - val_f1: 0.9968
Epoch 197/200
 - 1s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9967
Epoch 198/200
 - 1s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9967
Epoch 199/200
 - 1s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9968
Epoch 200/200
 - 1s - loss: 0.0036 - val_loss: 0.0040
2019-12-27 00:06:15,819 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:06:17,705 [INFO] Last epoch loss evaluation: train_loss = 0.002250, val_loss = 0.003571
2019-12-27 00:06:17,706 [INFO] Training complete. time_to_train = 291.06 sec, 4.85 min
2019-12-27 00:06:17,711 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_3/best_model.pickle
2019-12-27 00:06:17,714 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_3/training_error_history.csv
2019-12-27 00:06:17,900 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_3/training_error_history.png
2019-12-27 00:06:18,069 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_3/training_f1_history.png
2019-12-27 00:06:18,069 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:06:19,799 [INFO] Evaluating predictions (results)
2019-12-27 00:06:20,060 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:06:20,060 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.89      7458
      normal       0.67      0.97      0.79      9711
       probe       0.84      0.71      0.77      2421
         r2l       0.77      0.05      0.10      2421
         u2r       0.96      0.04      0.08       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.84      0.52      0.53     22544
weighted avg       0.81      0.77      0.73     22544

2019-12-27 00:06:20,060 [INFO] Overall accuracy (micro avg): 0.7715578424414479
2019-12-27 00:06:20,355 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7716         0.7716                       0.7716                0.0571                   0.2284  0.7716
1     Macro avg        0.9086         0.8430                       0.5185                0.0778                   0.4815  0.5267
2  Weighted avg        0.8672         0.8067                       0.7716                0.1607                   0.2284  0.7314
2019-12-27 00:06:20,687 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:06:20,687 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.97      0.90      0.94       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.90      0.93     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:06:20,689 [INFO] Overall accuracy (micro avg): 0.9974995038698155
2019-12-27 00:06:21,045 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9637                       0.8989                0.0009                   0.1011  0.9266
2  Weighted avg        0.9985         0.9975                       0.9975                0.0022                   0.0025  0.9975
2019-12-27 00:06:22,483 [INFO] Dataset: Training. Classification report below
2019-12-27 00:06:22,483 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.91      0.94       796
         u2r       0.91      0.71      0.80        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.92      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:06:22,483 [INFO] Overall accuracy (micro avg): 0.9979360574728612
2019-12-27 00:06:24,099 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9979         0.9979                       0.9979                0.0005                   0.0021  0.9979
1     Macro avg        0.9992         0.9761                       0.9233                0.0008                   0.0767  0.9471
2  Weighted avg        0.9987         0.9979                       0.9979                0.0019                   0.0021  0.9979
2019-12-27 00:06:24,138 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_3/ann_depth_nsl_layers_3_results.xlsx
2019-12-27 00:06:24,138 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-27 00:06:24,141 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_4
2019-12-27 00:06:24,141 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_4/run_log.log
2019-12-27 00:06:24,141 [INFO] ================= Running experiment no. 4  ================= 

2019-12-27 00:06:24,141 [INFO] Experiment parameters given below
2019-12-27 00:06:24,141 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_4'}
2019-12-27 00:06:24,141 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_4/tf_logs_run_2019_12_27-00_06_24
2019-12-27 00:06:24,142 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:06:24,142 [INFO] Reading X, y files
2019-12-27 00:06:24,142 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:06:24,389 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:06:24,390 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:06:24,452 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:06:24,452 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:06:24,509 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:06:24,509 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:06:24,516 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:06:24,516 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:06:24,520 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:06:24,520 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:06:24,523 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:06:24,710 [INFO] Initializing model
2019-12-27 00:06:25,036 [INFO] _________________________________________________________________
2019-12-27 00:06:25,037 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:06:25,037 [INFO] =================================================================
2019-12-27 00:06:25,037 [INFO] dense_10 (Dense)             (None, 128)               15744     
2019-12-27 00:06:25,037 [INFO] _________________________________________________________________
2019-12-27 00:06:25,037 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2019-12-27 00:06:25,037 [INFO] _________________________________________________________________
2019-12-27 00:06:25,037 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2019-12-27 00:06:25,037 [INFO] _________________________________________________________________
2019-12-27 00:06:25,037 [INFO] dense_11 (Dense)             (None, 64)                8256      
2019-12-27 00:06:25,037 [INFO] _________________________________________________________________
2019-12-27 00:06:25,037 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dense_12 (Dense)             (None, 32)                2080      
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dense_13 (Dense)             (None, 16)                528       
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] batch_normalization_10 (Batc (None, 16)                64        
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dropout_10 (Dropout)         (None, 16)                0         
2019-12-27 00:06:25,038 [INFO] _________________________________________________________________
2019-12-27 00:06:25,038 [INFO] dense_14 (Dense)             (None, 5)                 85        
2019-12-27 00:06:25,039 [INFO] =================================================================
2019-12-27 00:06:25,039 [INFO] Total params: 27,653
2019-12-27 00:06:25,039 [INFO] Trainable params: 27,173
2019-12-27 00:06:25,039 [INFO] Non-trainable params: 480
2019-12-27 00:06:25,039 [INFO] _________________________________________________________________
2019-12-27 00:06:25,039 [INFO] Training model
 - val_f1: 0.9971
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 2s - loss: 0.1097 - val_loss: 0.0248
 - val_f1: 0.9743
Epoch 2/200
 - 2s - loss: 0.0294 - val_loss: 0.0142
 - val_f1: 0.9882
Epoch 3/200
 - 2s - loss: 0.0213 - val_loss: 0.0118
 - val_f1: 0.9897
Epoch 4/200
 - 2s - loss: 0.0178 - val_loss: 0.0108
 - val_f1: 0.9907
Epoch 5/200
 - 2s - loss: 0.0162 - val_loss: 0.0112
 - val_f1: 0.9907
Epoch 6/200
 - 2s - loss: 0.0145 - val_loss: 0.0097
 - val_f1: 0.9913
Epoch 7/200
 - 2s - loss: 0.0135 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 8/200
 - 2s - loss: 0.0129 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 9/200
 - 2s - loss: 0.0124 - val_loss: 0.0092
 - val_f1: 0.9910
Epoch 10/200
 - 2s - loss: 0.0119 - val_loss: 0.0082
 - val_f1: 0.9946
Epoch 11/200
 - 2s - loss: 0.0109 - val_loss: 0.0083
 - val_f1: 0.9927
Epoch 12/200
 - 2s - loss: 0.0111 - val_loss: 0.0073
 - val_f1: 0.9944
Epoch 13/200
 - 2s - loss: 0.0101 - val_loss: 0.0074
 - val_f1: 0.9951
Epoch 14/200
 - 2s - loss: 0.0098 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 15/200
 - 2s - loss: 0.0096 - val_loss: 0.0071
 - val_f1: 0.9954
Epoch 16/200
 - 2s - loss: 0.0094 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 17/200
 - 2s - loss: 0.0092 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 18/200
 - 2s - loss: 0.0091 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 19/200
 - 2s - loss: 0.0086 - val_loss: 0.0066
 - val_f1: 0.9948
Epoch 20/200
 - 2s - loss: 0.0083 - val_loss: 0.0061
 - val_f1: 0.9961
Epoch 21/200
 - 2s - loss: 0.0083 - val_loss: 0.0064
2019-12-27 00:07:11,177 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_20.pickle
 - val_f1: 0.9949
Epoch 22/200
 - 2s - loss: 0.0078 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 23/200
 - 2s - loss: 0.0075 - val_loss: 0.0061
 - val_f1: 0.9959
Epoch 24/200
 - 2s - loss: 0.0076 - val_loss: 0.0061
 - val_f1: 0.9955
Epoch 25/200
 - 2s - loss: 0.0071 - val_loss: 0.0061
 - val_f1: 0.9954
Epoch 26/200
 - 2s - loss: 0.0071 - val_loss: 0.0059
 - val_f1: 0.9958
Epoch 27/200
 - 2s - loss: 0.0070 - val_loss: 0.0058
 - val_f1: 0.9958
Epoch 28/200
 - 2s - loss: 0.0066 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 29/200
 - 2s - loss: 0.0065 - val_loss: 0.0058
 - val_f1: 0.9961
Epoch 30/200
 - 2s - loss: 0.0064 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 31/200
 - 2s - loss: 0.0064 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 32/200
 - 2s - loss: 0.0062 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 33/200
 - 2s - loss: 0.0062 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 34/200
 - 2s - loss: 0.0061 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 35/200
 - 2s - loss: 0.0059 - val_loss: 0.0055
 - val_f1: 0.9956
Epoch 36/200
 - 2s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 37/200
 - 2s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 38/200
 - 2s - loss: 0.0062 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 39/200
 - 2s - loss: 0.0056 - val_loss: 0.0051
 - val_f1: 0.9960
Epoch 40/200
 - 2s - loss: 0.0057 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 41/200
 - 2s - loss: 0.0056 - val_loss: 0.0052
2019-12-27 00:07:52,558 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_40.pickle
 - val_f1: 0.9965
Epoch 42/200
 - 2s - loss: 0.0056 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 43/200
 - 2s - loss: 0.0055 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 44/200
 - 2s - loss: 0.0055 - val_loss: 0.0052
 - val_f1: 0.9959
Epoch 45/200
 - 2s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 46/200
 - 2s - loss: 0.0054 - val_loss: 0.0049
 - val_f1: 0.9960
Epoch 47/200
 - 2s - loss: 0.0052 - val_loss: 0.0048
 - val_f1: 0.9960
Epoch 48/200
 - 2s - loss: 0.0053 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 49/200
 - 2s - loss: 0.0051 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 50/200
 - 2s - loss: 0.0054 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 51/200
 - 2s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 52/200
 - 2s - loss: 0.0053 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 53/200
 - 2s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 54/200
 - 2s - loss: 0.0052 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 55/200
 - 2s - loss: 0.0051 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 56/200
 - 2s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9959
Epoch 57/200
 - 2s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 58/200
 - 2s - loss: 0.0050 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 59/200
 - 2s - loss: 0.0047 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 60/200
 - 2s - loss: 0.0046 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 61/200
 - 2s - loss: 0.0048 - val_loss: 0.0045
2019-12-27 00:08:33,913 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_60.pickle
 - val_f1: 0.9968
Epoch 62/200
 - 2s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 63/200
 - 2s - loss: 0.0049 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 64/200
 - 2s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 65/200
 - 2s - loss: 0.0045 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 66/200
 - 2s - loss: 0.0048 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 67/200
 - 2s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 68/200
 - 2s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 69/200
 - 2s - loss: 0.0045 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 70/200
 - 2s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 71/200
 - 2s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 72/200
 - 2s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 73/200
 - 2s - loss: 0.0045 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 74/200
 - 2s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 75/200
 - 2s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 76/200
 - 2s - loss: 0.0041 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 77/200
 - 2s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 78/200
 - 2s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 79/200
 - 2s - loss: 0.0042 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 80/200
 - 2s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 81/200
 - 2s - loss: 0.0042 - val_loss: 0.0048
2019-12-27 00:09:15,238 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_80.pickle
 - val_f1: 0.9966
Epoch 82/200
 - 2s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 83/200
 - 2s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 84/200
 - 2s - loss: 0.0041 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 85/200
 - 2s - loss: 0.0039 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 86/200
 - 2s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 87/200
 - 2s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 88/200
 - 2s - loss: 0.0039 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 89/200
 - 2s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 90/200
 - 2s - loss: 0.0038 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 91/200
 - 2s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 92/200
 - 2s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 93/200
 - 2s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 94/200
 - 2s - loss: 0.0039 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 95/200
 - 2s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9969
Epoch 96/200
 - 2s - loss: 0.0042 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 97/200
 - 2s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 98/200
 - 2s - loss: 0.0037 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 99/200
 - 2s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 100/200
 - 2s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 101/200
 - 2s - loss: 0.0036 - val_loss: 0.0048
2019-12-27 00:09:56,560 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_100.pickle
 - val_f1: 0.9969
Epoch 102/200
 - 2s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 103/200
 - 2s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 104/200
 - 2s - loss: 0.0041 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 105/200
 - 2s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9967
Epoch 106/200
 - 2s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 107/200
 - 2s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 108/200
 - 2s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 109/200
 - 2s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 110/200
 - 2s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 111/200
 - 2s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 112/200
 - 2s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 113/200
 - 2s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 114/200
 - 2s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 115/200
 - 2s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 116/200
 - 2s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 117/200
 - 2s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 118/200
 - 2s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 119/200
 - 2s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 120/200
 - 2s - loss: 0.0036 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 121/200
 - 2s - loss: 0.0034 - val_loss: 0.0052
2019-12-27 00:10:37,800 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_120.pickle
 - val_f1: 0.9966
Epoch 122/200
 - 2s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 123/200
 - 2s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 124/200
 - 2s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 125/200
 - 2s - loss: 0.0038 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 126/200
 - 2s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 127/200
 - 2s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 128/200
 - 2s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 129/200
 - 2s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 130/200
 - 2s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 131/200
 - 2s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 132/200
 - 2s - loss: 0.0036 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 133/200
 - 2s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 134/200
 - 2s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 135/200
 - 2s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9975
Epoch 136/200
 - 2s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 137/200
 - 2s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 138/200
 - 2s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 139/200
 - 2s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 140/200
 - 2s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 141/200
 - 2s - loss: 0.0032 - val_loss: 0.0046
2019-12-27 00:11:19,189 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_140.pickle
 - val_f1: 0.9969
Epoch 142/200
 - 2s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 143/200
 - 2s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 144/200
 - 2s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 145/200
 - 2s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 146/200
 - 2s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 147/200
 - 2s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 148/200
 - 2s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 149/200
 - 2s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 150/200
 - 2s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 151/200
 - 2s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 152/200
 - 2s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 153/200
 - 2s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 154/200
 - 2s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 155/200
 - 2s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 156/200
 - 2s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 157/200
 - 2s - loss: 0.0034 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 158/200
 - 2s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 159/200
 - 2s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 160/200
 - 2s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 161/200
 - 2s - loss: 0.0036 - val_loss: 0.0043
2019-12-27 00:12:00,422 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_160.pickle
 - val_f1: 0.9969
Epoch 162/200
 - 2s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 163/200
 - 2s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 164/200
 - 2s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 165/200
 - 2s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9975
Epoch 166/200
 - 2s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 167/200
 - 2s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 168/200
 - 2s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 169/200
 - 2s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 170/200
 - 2s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 171/200
 - 2s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 172/200
 - 2s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 173/200
 - 2s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 174/200
 - 2s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 175/200
 - 2s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 176/200
 - 2s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 177/200
 - 2s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 178/200
 - 2s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 179/200
 - 2s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 180/200
 - 2s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 181/200
 - 2s - loss: 0.0030 - val_loss: 0.0042
2019-12-27 00:12:41,735 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_4/ann_model_epoch_180.pickle
 - val_f1: 0.9971
Epoch 182/200
 - 2s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 183/200
 - 2s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 184/200
 - 2s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 185/200
 - 2s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 186/200
 - 2s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 187/200
 - 2s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 188/200
 - 2s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 189/200
 - 2s - loss: 0.0033 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 190/200
 - 2s - loss: 0.0030 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 191/200
 - 2s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 192/200
 - 2s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 193/200
 - 2s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 194/200
 - 2s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9975
Epoch 195/200
 - 2s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 196/200
 - 2s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 197/200
 - 2s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 198/200
 - 2s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 199/200
 - 2s - loss: 0.0030 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 200/200
 - 2s - loss: 0.0030 - val_loss: 0.0044
2019-12-27 00:13:21,271 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:13:23,640 [INFO] Last epoch loss evaluation: train_loss = 0.002032, val_loss = 0.004068
2019-12-27 00:13:23,640 [INFO] Training complete. time_to_train = 418.60 sec, 6.98 min
2019-12-27 00:13:23,649 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_4/best_model.pickle
2019-12-27 00:13:23,653 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_4/training_error_history.csv
2019-12-27 00:13:23,836 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_4/training_error_history.png
2019-12-27 00:13:24,005 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_4/training_f1_history.png
2019-12-27 00:13:24,005 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:13:26,185 [INFO] Evaluating predictions (results)
2019-12-27 00:13:26,444 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:13:26,444 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.83      0.89      7458
      normal       0.69      0.97      0.80      9711
       probe       0.83      0.70      0.76      2421
         r2l       0.82      0.10      0.18      2421
         u2r       1.00      0.05      0.09       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.86      0.53      0.55     22544
weighted avg       0.81      0.78      0.74     22544

2019-12-27 00:13:26,445 [INFO] Overall accuracy (micro avg): 0.7799414478353442
2019-12-27 00:13:26,741 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7799         0.7799                       0.7799                0.0550                   0.2201  0.7799
1     Macro avg        0.9120         0.8598                       0.5304                0.0744                   0.4696  0.5455
2  Weighted avg        0.8736         0.8135                       0.7799                0.1519                   0.2201  0.7442
2019-12-27 00:13:27,074 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:13:27,074 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.97      0.92      0.95       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.88      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:13:27,074 [INFO] Overall accuracy (micro avg): 0.9974995038698155
2019-12-27 00:13:27,430 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9587                       0.8831                0.0009                   0.1169  0.9125
2  Weighted avg        0.9984         0.9975                       0.9975                0.0019                   0.0025  0.9975
2019-12-27 00:13:28,869 [INFO] Dataset: Training. Classification report below
2019-12-27 00:13:28,871 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.97      0.93      0.95       796
         u2r       0.91      0.76      0.83        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.94      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:13:28,871 [INFO] Overall accuracy (micro avg): 0.9980749766814185
2019-12-27 00:13:30,488 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9981         0.9981                       0.9981                0.0005                   0.0019  0.9981
1     Macro avg        0.9992         0.9759                       0.9365                0.0007                   0.0635  0.9547
2  Weighted avg        0.9988         0.9981                       0.9981                0.0016                   0.0019  0.9981
2019-12-27 00:13:30,525 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_4/ann_depth_nsl_layers_4_results.xlsx
2019-12-27 00:13:30,525 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-27 00:13:30,528 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_5
2019-12-27 00:13:30,529 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_5/run_log.log
2019-12-27 00:13:30,529 [INFO] ================= Running experiment no. 5  ================= 

2019-12-27 00:13:30,529 [INFO] Experiment parameters given below
2019-12-27 00:13:30,529 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_5'}
2019-12-27 00:13:30,529 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_5/tf_logs_run_2019_12_27-00_13_30
2019-12-27 00:13:30,529 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:13:30,529 [INFO] Reading X, y files
2019-12-27 00:13:30,529 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:13:30,778 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:13:30,778 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:13:30,841 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:13:30,841 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:13:30,898 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:13:30,898 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:13:30,905 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:13:30,905 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:13:30,909 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:13:30,909 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:13:30,913 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:13:31,096 [INFO] Initializing model
2019-12-27 00:13:31,505 [INFO] _________________________________________________________________
2019-12-27 00:13:31,505 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:13:31,505 [INFO] =================================================================
2019-12-27 00:13:31,505 [INFO] dense_15 (Dense)             (None, 256)               31488     
2019-12-27 00:13:31,505 [INFO] _________________________________________________________________
2019-12-27 00:13:31,505 [INFO] batch_normalization_11 (Batc (None, 256)               1024      
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] dropout_11 (Dropout)         (None, 256)               0         
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] dense_16 (Dense)             (None, 128)               32896     
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] batch_normalization_12 (Batc (None, 128)               512       
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] dropout_12 (Dropout)         (None, 128)               0         
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] dense_17 (Dense)             (None, 64)                8256      
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2019-12-27 00:13:31,506 [INFO] _________________________________________________________________
2019-12-27 00:13:31,506 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] dense_18 (Dense)             (None, 32)                2080      
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] dense_19 (Dense)             (None, 16)                528       
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] batch_normalization_15 (Batc (None, 16)                64        
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] dropout_15 (Dropout)         (None, 16)                0         
2019-12-27 00:13:31,507 [INFO] _________________________________________________________________
2019-12-27 00:13:31,507 [INFO] dense_20 (Dense)             (None, 5)                 85        
2019-12-27 00:13:31,507 [INFO] =================================================================
2019-12-27 00:13:31,508 [INFO] Total params: 77,317
2019-12-27 00:13:31,508 [INFO] Trainable params: 76,325
2019-12-27 00:13:31,508 [INFO] Non-trainable params: 992
2019-12-27 00:13:31,508 [INFO] _________________________________________________________________
2019-12-27 00:13:31,508 [INFO] Training model
 - val_f1: 0.9971
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 3s - loss: 0.1041 - val_loss: 0.0184
 - val_f1: 0.9823
Epoch 2/200
 - 3s - loss: 0.0265 - val_loss: 0.0128
 - val_f1: 0.9893
Epoch 3/200
 - 3s - loss: 0.0193 - val_loss: 0.0121
 - val_f1: 0.9901
Epoch 4/200
 - 3s - loss: 0.0170 - val_loss: 0.0113
 - val_f1: 0.9896
Epoch 5/200
 - 3s - loss: 0.0155 - val_loss: 0.0099
 - val_f1: 0.9923
Epoch 6/200
 - 3s - loss: 0.0141 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 7/200
 - 3s - loss: 0.0132 - val_loss: 0.0090
 - val_f1: 0.9934
Epoch 8/200
 - 3s - loss: 0.0123 - val_loss: 0.0101
 - val_f1: 0.9911
Epoch 9/200
 - 3s - loss: 0.0122 - val_loss: 0.0081
 - val_f1: 0.9938
Epoch 10/200
 - 3s - loss: 0.0113 - val_loss: 0.0080
 - val_f1: 0.9944
Epoch 11/200
 - 3s - loss: 0.0107 - val_loss: 0.0077
 - val_f1: 0.9943
Epoch 12/200
 - 3s - loss: 0.0099 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 13/200
 - 3s - loss: 0.0099 - val_loss: 0.0080
 - val_f1: 0.9940
Epoch 14/200
 - 3s - loss: 0.0096 - val_loss: 0.0074
 - val_f1: 0.9931
Epoch 15/200
 - 3s - loss: 0.0090 - val_loss: 0.0071
 - val_f1: 0.9947
Epoch 16/200
 - 3s - loss: 0.0085 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 17/200
 - 3s - loss: 0.0086 - val_loss: 0.0063
 - val_f1: 0.9955
Epoch 18/200
 - 3s - loss: 0.0078 - val_loss: 0.0063
 - val_f1: 0.9954
Epoch 19/200
 - 3s - loss: 0.0078 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 20/200
 - 3s - loss: 0.0077 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 21/200
 - 3s - loss: 0.0072 - val_loss: 0.0057
2019-12-27 00:14:42,638 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_20.pickle
 - val_f1: 0.9959
Epoch 22/200
 - 3s - loss: 0.0067 - val_loss: 0.0062
 - val_f1: 0.9962
Epoch 23/200
 - 3s - loss: 0.0070 - val_loss: 0.0059
 - val_f1: 0.9957
Epoch 24/200
 - 3s - loss: 0.0067 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 25/200
 - 3s - loss: 0.0061 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 26/200
 - 3s - loss: 0.0065 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 27/200
 - 3s - loss: 0.0061 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 28/200
 - 3s - loss: 0.0058 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 29/200
 - 3s - loss: 0.0059 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 30/200
 - 3s - loss: 0.0059 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 31/200
 - 3s - loss: 0.0056 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 32/200
 - 3s - loss: 0.0055 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 33/200
 - 3s - loss: 0.0053 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 34/200
 - 3s - loss: 0.0052 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 35/200
 - 3s - loss: 0.0055 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 36/200
 - 3s - loss: 0.0053 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 37/200
 - 3s - loss: 0.0053 - val_loss: 0.0050
 - val_f1: 0.9959
Epoch 38/200
 - 3s - loss: 0.0048 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 39/200
 - 3s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 40/200
 - 3s - loss: 0.0048 - val_loss: 0.0060
 - val_f1: 0.9953
Epoch 41/200
 - 3s - loss: 0.0048 - val_loss: 0.0057
2019-12-27 00:15:45,861 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_40.pickle
 - val_f1: 0.9956
Epoch 42/200
 - 3s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 43/200
 - 3s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 44/200
 - 3s - loss: 0.0049 - val_loss: 0.0049
 - val_f1: 0.9961
Epoch 45/200
 - 3s - loss: 0.0052 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 46/200
 - 3s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 47/200
 - 3s - loss: 0.0045 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 48/200
 - 3s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 49/200
 - 3s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 50/200
 - 3s - loss: 0.0045 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 51/200
 - 3s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 52/200
 - 3s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 53/200
 - 3s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 54/200
 - 3s - loss: 0.0043 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 55/200
 - 3s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 56/200
 - 3s - loss: 0.0046 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 57/200
 - 3s - loss: 0.0042 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 58/200
 - 3s - loss: 0.0040 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 59/200
 - 3s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 60/200
 - 3s - loss: 0.0042 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 61/200
 - 3s - loss: 0.0038 - val_loss: 0.0050
2019-12-27 00:16:49,080 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_60.pickle
 - val_f1: 0.9962
Epoch 62/200
 - 3s - loss: 0.0042 - val_loss: 0.0043
 - val_f1: 0.9968
Epoch 63/200
 - 3s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 64/200
 - 3s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 65/200
 - 3s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 66/200
 - 3s - loss: 0.0039 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 67/200
 - 3s - loss: 0.0042 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 68/200
 - 3s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 69/200
 - 3s - loss: 0.0041 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 70/200
 - 3s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 71/200
 - 3s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 72/200
 - 3s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 73/200
 - 3s - loss: 0.0036 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 74/200
 - 3s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 75/200
 - 3s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 76/200
 - 3s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 77/200
 - 3s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 78/200
 - 3s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9968
Epoch 79/200
 - 3s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 80/200
 - 3s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 81/200
 - 3s - loss: 0.0038 - val_loss: 0.0045
2019-12-27 00:17:52,237 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_80.pickle
 - val_f1: 0.9970
Epoch 82/200
 - 3s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 83/200
 - 3s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 84/200
 - 3s - loss: 0.0037 - val_loss: 0.0043
 - val_f1: 0.9967
Epoch 85/200
 - 3s - loss: 0.0033 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 86/200
 - 3s - loss: 0.0037 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 87/200
 - 3s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9974
Epoch 88/200
 - 3s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 89/200
 - 3s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 90/200
 - 3s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9970
Epoch 91/200
 - 3s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 92/200
 - 3s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 93/200
 - 3s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 94/200
 - 3s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 95/200
 - 3s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 96/200
 - 3s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 97/200
 - 3s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 98/200
 - 3s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 99/200
 - 3s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 100/200
 - 3s - loss: 0.0032 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 101/200
 - 3s - loss: 0.0035 - val_loss: 0.0051
2019-12-27 00:18:55,519 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_100.pickle
 - val_f1: 0.9960
Epoch 102/200
 - 3s - loss: 0.0031 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 103/200
 - 3s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 104/200
 - 3s - loss: 0.0034 - val_loss: 0.0059
 - val_f1: 0.9953
Epoch 105/200
 - 3s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9973
Epoch 106/200
 - 3s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9971
Epoch 107/200
 - 3s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 108/200
 - 3s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 109/200
 - 3s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 110/200
 - 3s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 111/200
 - 3s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 112/200
 - 3s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 113/200
 - 3s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 114/200
 - 3s - loss: 0.0032 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 115/200
 - 3s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 116/200
 - 3s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9971
Epoch 117/200
 - 3s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 118/200
 - 3s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 119/200
 - 3s - loss: 0.0033 - val_loss: 0.0039
 - val_f1: 0.9972
Epoch 120/200
 - 3s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9968
Epoch 121/200
 - 3s - loss: 0.0029 - val_loss: 0.0041
2019-12-27 00:19:58,693 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_120.pickle
 - val_f1: 0.9971
Epoch 122/200
 - 3s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 123/200
 - 3s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9973
Epoch 124/200
 - 3s - loss: 0.0030 - val_loss: 0.0040
 - val_f1: 0.9972
Epoch 125/200
 - 3s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 126/200
 - 3s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 127/200
 - 3s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9971
Epoch 128/200
 - 3s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 129/200
 - 3s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 130/200
 - 3s - loss: 0.0028 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 131/200
 - 3s - loss: 0.0029 - val_loss: 0.0039
 - val_f1: 0.9972
Epoch 132/200
 - 3s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 133/200
 - 3s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 134/200
 - 3s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9975
Epoch 135/200
 - 3s - loss: 0.0028 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 136/200
 - 3s - loss: 0.0031 - val_loss: 0.0040
 - val_f1: 0.9973
Epoch 137/200
 - 3s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 138/200
 - 3s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 139/200
 - 3s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 140/200
 - 3s - loss: 0.0027 - val_loss: 0.0039
 - val_f1: 0.9974
Epoch 141/200
 - 3s - loss: 0.0028 - val_loss: 0.0039
2019-12-27 00:21:01,778 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_140.pickle
 - val_f1: 0.9975
Epoch 142/200
 - 3s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 143/200
 - 3s - loss: 0.0033 - val_loss: 0.0039
 - val_f1: 0.9974
Epoch 144/200
 - 3s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 145/200
 - 3s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9973
Epoch 146/200
 - 3s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 147/200
 - 3s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 148/200
 - 3s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 149/200
 - 3s - loss: 0.0029 - val_loss: 0.0039
 - val_f1: 0.9972
Epoch 150/200
 - 3s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 151/200
 - 3s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 152/200
 - 3s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9974
Epoch 153/200
 - 3s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 154/200
 - 3s - loss: 0.0027 - val_loss: 0.0040
 - val_f1: 0.9975
Epoch 155/200
 - 3s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 156/200
 - 3s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 157/200
 - 3s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 158/200
 - 3s - loss: 0.0028 - val_loss: 0.0040
 - val_f1: 0.9972
Epoch 159/200
 - 3s - loss: 0.0026 - val_loss: 0.0038
 - val_f1: 0.9974
Epoch 160/200
 - 3s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 161/200
 - 3s - loss: 0.0029 - val_loss: 0.0041
2019-12-27 00:22:04,784 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_160.pickle
 - val_f1: 0.9973
Epoch 162/200
 - 3s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 163/200
 - 3s - loss: 0.0029 - val_loss: 0.0039
 - val_f1: 0.9974
Epoch 164/200
 - 3s - loss: 0.0026 - val_loss: 0.0040
 - val_f1: 0.9973
Epoch 165/200
 - 3s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 166/200
 - 3s - loss: 0.0026 - val_loss: 0.0039
 - val_f1: 0.9976
Epoch 167/200
 - 3s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 168/200
 - 3s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 169/200
 - 3s - loss: 0.0026 - val_loss: 0.0038
 - val_f1: 0.9972
Epoch 170/200
 - 3s - loss: 0.0026 - val_loss: 0.0038
 - val_f1: 0.9971
Epoch 171/200
 - 3s - loss: 0.0026 - val_loss: 0.0038
 - val_f1: 0.9972
Epoch 172/200
 - 3s - loss: 0.0026 - val_loss: 0.0037
 - val_f1: 0.9974
Epoch 173/200
 - 3s - loss: 0.0026 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 174/200
 - 3s - loss: 0.0028 - val_loss: 0.0040
 - val_f1: 0.9970
Epoch 175/200
 - 3s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 176/200
 - 3s - loss: 0.0028 - val_loss: 0.0037
 - val_f1: 0.9975
Epoch 177/200
 - 3s - loss: 0.0025 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 178/200
 - 3s - loss: 0.0025 - val_loss: 0.0038
 - val_f1: 0.9973
Epoch 179/200
 - 3s - loss: 0.0028 - val_loss: 0.0036
 - val_f1: 0.9975
Epoch 180/200
 - 3s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9975
Epoch 181/200
 - 3s - loss: 0.0027 - val_loss: 0.0041
2019-12-27 00:23:07,921 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_5/ann_model_epoch_180.pickle
 - val_f1: 0.9973
Epoch 182/200
 - 3s - loss: 0.0025 - val_loss: 0.0039
 - val_f1: 0.9976
Epoch 183/200
 - 3s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 184/200
 - 3s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 185/200
 - 3s - loss: 0.0027 - val_loss: 0.0039
 - val_f1: 0.9975
Epoch 186/200
 - 3s - loss: 0.0025 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 187/200
 - 3s - loss: 0.0027 - val_loss: 0.0037
 - val_f1: 0.9974
Epoch 188/200
 - 3s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 189/200
 - 3s - loss: 0.0024 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 190/200
 - 3s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9975
Epoch 191/200
 - 3s - loss: 0.0026 - val_loss: 0.0038
 - val_f1: 0.9971
Epoch 192/200
 - 3s - loss: 0.0023 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 193/200
 - 3s - loss: 0.0027 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 194/200
 - 3s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 195/200
 - 3s - loss: 0.0025 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 196/200
 - 3s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 197/200
 - 3s - loss: 0.0027 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 198/200
 - 3s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 199/200
 - 3s - loss: 0.0027 - val_loss: 0.0040
 - val_f1: 0.9973
Epoch 200/200
 - 3s - loss: 0.0026 - val_loss: 0.0042
2019-12-27 00:24:08,489 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:24:11,650 [INFO] Last epoch loss evaluation: train_loss = 0.001730, val_loss = 0.003579
2019-12-27 00:24:11,651 [INFO] Training complete. time_to_train = 640.14 sec, 10.67 min
2019-12-27 00:24:11,661 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_5/best_model.pickle
2019-12-27 00:24:11,664 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_5/training_error_history.csv
2019-12-27 00:24:11,846 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_5/training_error_history.png
2019-12-27 00:24:12,031 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_5/training_f1_history.png
2019-12-27 00:24:12,031 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:24:15,066 [INFO] Evaluating predictions (results)
2019-12-27 00:24:15,324 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:24:15,324 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.83      0.89      7458
      normal       0.68      0.95      0.79      9711
       probe       0.77      0.69      0.73      2421
         r2l       0.89      0.12      0.21      2421
         u2r       0.84      0.05      0.09       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.83      0.53      0.54     22544
weighted avg       0.81      0.77      0.74     22544

2019-12-27 00:24:15,325 [INFO] Overall accuracy (micro avg): 0.7720901348474095
2019-12-27 00:24:15,620 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7721         0.7721                       0.7721                0.0570                   0.2279  0.7721
1     Macro avg        0.9088         0.8277                       0.5277                0.0764                   0.4723  0.5419
2  Weighted avg        0.8688         0.8085                       0.7721                0.1539                   0.2279  0.7386
2019-12-27 00:24:15,953 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:24:15,953 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.92      0.95      0.94       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.95      0.91      0.93     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:24:15,954 [INFO] Overall accuracy (micro avg): 0.9974995038698155
2019-12-27 00:24:16,310 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9544                       0.9091                0.0008                   0.0909  0.9272
2  Weighted avg        0.9985         0.9975                       0.9975                0.0015                   0.0025  0.9975
2019-12-27 00:24:17,749 [INFO] Dataset: Training. Classification report below
2019-12-27 00:24:17,749 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      1.00      1.00      9325
         r2l       0.94      0.97      0.96       796
         u2r       0.91      0.76      0.83        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.95      0.96    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:24:17,749 [INFO] Overall accuracy (micro avg): 0.9984123519022009
2019-12-27 00:24:19,370 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9984         0.9984                       0.9984                0.0004                   0.0016  0.9984
1     Macro avg        0.9994         0.9703                       0.9459                0.0005                   0.0541  0.9566
2  Weighted avg        0.9991         0.9984                       0.9984                0.0009                   0.0016  0.9984
2019-12-27 00:24:19,407 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_5/ann_depth_nsl_layers_5_results.xlsx
2019-12-27 00:24:19,407 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-27 00:24:19,410 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_6
2019-12-27 00:24:19,410 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_6/run_log.log
2019-12-27 00:24:19,410 [INFO] ================= Running experiment no. 6  ================= 

2019-12-27 00:24:19,411 [INFO] Experiment parameters given below
2019-12-27 00:24:19,411 [INFO] 
{'experiment_num': 6, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_6', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_6'}
2019-12-27 00:24:19,411 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_6/tf_logs_run_2019_12_27-00_24_19
2019-12-27 00:24:19,411 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:24:19,411 [INFO] Reading X, y files
2019-12-27 00:24:19,411 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:24:19,662 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:24:19,662 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:24:19,725 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:24:19,725 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:24:19,782 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:24:19,783 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:24:19,790 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:24:19,790 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:24:19,794 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:24:19,794 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:24:19,798 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:24:19,984 [INFO] Initializing model
2019-12-27 00:24:20,471 [INFO] _________________________________________________________________
2019-12-27 00:24:20,471 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:24:20,471 [INFO] =================================================================
2019-12-27 00:24:20,471 [INFO] dense_21 (Dense)             (None, 400)               49200     
2019-12-27 00:24:20,471 [INFO] _________________________________________________________________
2019-12-27 00:24:20,471 [INFO] batch_normalization_16 (Batc (None, 400)               1600      
2019-12-27 00:24:20,471 [INFO] _________________________________________________________________
2019-12-27 00:24:20,471 [INFO] dropout_16 (Dropout)         (None, 400)               0         
2019-12-27 00:24:20,471 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] dense_22 (Dense)             (None, 256)               102656    
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] batch_normalization_17 (Batc (None, 256)               1024      
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] dropout_17 (Dropout)         (None, 256)               0         
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] dense_23 (Dense)             (None, 128)               32896     
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] batch_normalization_18 (Batc (None, 128)               512       
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] dropout_18 (Dropout)         (None, 128)               0         
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] dense_24 (Dense)             (None, 64)                8256      
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,472 [INFO] batch_normalization_19 (Batc (None, 64)                256       
2019-12-27 00:24:20,472 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dropout_19 (Dropout)         (None, 64)                0         
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dense_25 (Dense)             (None, 32)                2080      
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] batch_normalization_20 (Batc (None, 32)                128       
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dropout_20 (Dropout)         (None, 32)                0         
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dense_26 (Dense)             (None, 16)                528       
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] batch_normalization_21 (Batc (None, 16)                64        
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dropout_21 (Dropout)         (None, 16)                0         
2019-12-27 00:24:20,473 [INFO] _________________________________________________________________
2019-12-27 00:24:20,473 [INFO] dense_27 (Dense)             (None, 5)                 85        
2019-12-27 00:24:20,473 [INFO] =================================================================
2019-12-27 00:24:20,474 [INFO] Total params: 199,285
2019-12-27 00:24:20,474 [INFO] Trainable params: 197,493
2019-12-27 00:24:20,474 [INFO] Non-trainable params: 1,792
2019-12-27 00:24:20,474 [INFO] _________________________________________________________________
2019-12-27 00:24:20,474 [INFO] Training model
 - val_f1: 0.9972
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 5s - loss: 0.0902 - val_loss: 0.0171
 - val_f1: 0.9820
Epoch 2/200
 - 4s - loss: 0.0250 - val_loss: 0.0138
 - val_f1: 0.9876
Epoch 3/200
 - 4s - loss: 0.0193 - val_loss: 0.0111
 - val_f1: 0.9902
Epoch 4/200
 - 4s - loss: 0.0167 - val_loss: 0.0109
 - val_f1: 0.9909
Epoch 5/200
 - 4s - loss: 0.0148 - val_loss: 0.0105
 - val_f1: 0.9913
Epoch 6/200
 - 4s - loss: 0.0143 - val_loss: 0.0091
 - val_f1: 0.9915
Epoch 7/200
 - 4s - loss: 0.0130 - val_loss: 0.0088
 - val_f1: 0.9918
Epoch 8/200
 - 4s - loss: 0.0123 - val_loss: 0.0083
 - val_f1: 0.9920
Epoch 9/200
 - 4s - loss: 0.0112 - val_loss: 0.0095
 - val_f1: 0.9923
Epoch 10/200
 - 4s - loss: 0.0108 - val_loss: 0.0078
 - val_f1: 0.9944
Epoch 11/200
 - 4s - loss: 0.0105 - val_loss: 0.0082
 - val_f1: 0.9924
Epoch 12/200
 - 4s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9938
Epoch 13/200
 - 4s - loss: 0.0095 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 14/200
 - 4s - loss: 0.0092 - val_loss: 0.0074
 - val_f1: 0.9944
Epoch 15/200
 - 4s - loss: 0.0088 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 16/200
 - 4s - loss: 0.0087 - val_loss: 0.0067
 - val_f1: 0.9950
Epoch 17/200
 - 4s - loss: 0.0083 - val_loss: 0.0063
 - val_f1: 0.9955
Epoch 18/200
 - 4s - loss: 0.0073 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 19/200
 - 4s - loss: 0.0072 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 20/200
 - 4s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 21/200
 - 4s - loss: 0.0070 - val_loss: 0.0094
2019-12-27 00:26:06,627 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_20.pickle
 - val_f1: 0.9928
Epoch 22/200
 - 4s - loss: 0.0065 - val_loss: 0.0053
 - val_f1: 0.9959
Epoch 23/200
 - 4s - loss: 0.0066 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 24/200
 - 4s - loss: 0.0063 - val_loss: 0.0060
 - val_f1: 0.9959
Epoch 25/200
 - 4s - loss: 0.0063 - val_loss: 0.0051
 - val_f1: 0.9959
Epoch 26/200
 - 4s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9958
Epoch 27/200
 - 4s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 28/200
 - 4s - loss: 0.0062 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 29/200
 - 4s - loss: 0.0057 - val_loss: 0.0050
 - val_f1: 0.9959
Epoch 30/200
 - 4s - loss: 0.0051 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 31/200
 - 4s - loss: 0.0055 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 32/200
 - 4s - loss: 0.0054 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 33/200
 - 4s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 34/200
 - 4s - loss: 0.0053 - val_loss: 0.0059
 - val_f1: 0.9957
Epoch 35/200
 - 4s - loss: 0.0048 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 36/200
 - 4s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9957
Epoch 37/200
 - 4s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 38/200
 - 4s - loss: 0.0049 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 39/200
 - 4s - loss: 0.0048 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 40/200
 - 4s - loss: 0.0047 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 41/200
 - 4s - loss: 0.0047 - val_loss: 0.0047
2019-12-27 00:27:42,021 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_40.pickle
 - val_f1: 0.9968
Epoch 42/200
 - 4s - loss: 0.0049 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 43/200
 - 4s - loss: 0.0043 - val_loss: 0.0059
 - val_f1: 0.9962
Epoch 44/200
 - 4s - loss: 0.0048 - val_loss: 0.0047
 - val_f1: 0.9962
Epoch 45/200
 - 4s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 46/200
 - 4s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 47/200
 - 4s - loss: 0.0046 - val_loss: 0.0048
 - val_f1: 0.9961
Epoch 48/200
 - 4s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 49/200
 - 4s - loss: 0.0045 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 50/200
 - 4s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 51/200
 - 4s - loss: 0.0040 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 52/200
 - 4s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 53/200
 - 4s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 54/200
 - 4s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 55/200
 - 4s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 56/200
 - 4s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 57/200
 - 4s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 58/200
 - 4s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 59/200
 - 4s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 60/200
 - 4s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 61/200
 - 4s - loss: 0.0039 - val_loss: 0.0041
2019-12-27 00:29:17,391 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_60.pickle
 - val_f1: 0.9970
Epoch 62/200
 - 4s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 63/200
 - 4s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9971
Epoch 64/200
 - 4s - loss: 0.0037 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 65/200
 - 4s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 66/200
 - 4s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 67/200
 - 4s - loss: 0.0037 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 68/200
 - 4s - loss: 0.0037 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 69/200
 - 4s - loss: 0.0035 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 70/200
 - 4s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 71/200
 - 4s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 72/200
 - 4s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 73/200
 - 4s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 74/200
 - 4s - loss: 0.0037 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 75/200
 - 4s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 76/200
 - 4s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 77/200
 - 4s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 78/200
 - 4s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 79/200
 - 4s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 80/200
 - 4s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 81/200
 - 4s - loss: 0.0036 - val_loss: 0.0045
2019-12-27 00:30:52,615 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_80.pickle
 - val_f1: 0.9969
Epoch 82/200
 - 4s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9974
Epoch 83/200
 - 4s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 84/200
 - 4s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 85/200
 - 4s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 86/200
 - 4s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 87/200
 - 4s - loss: 0.0031 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 88/200
 - 4s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 89/200
 - 4s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 90/200
 - 4s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 91/200
 - 4s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 92/200
 - 4s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 93/200
 - 4s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9973
Epoch 94/200
 - 4s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 95/200
 - 4s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 96/200
 - 4s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 97/200
 - 4s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 98/200
 - 4s - loss: 0.0034 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 99/200
 - 4s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 100/200
 - 4s - loss: 0.0030 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 101/200
 - 4s - loss: 0.0037 - val_loss: 0.0041
2019-12-27 00:32:27,984 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_100.pickle
 - val_f1: 0.9971
Epoch 102/200
 - 4s - loss: 0.0032 - val_loss: 0.0039
 - val_f1: 0.9974
Epoch 103/200
 - 4s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 104/200
 - 4s - loss: 0.0031 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 105/200
 - 4s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 106/200
 - 4s - loss: 0.0028 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 107/200
 - 4s - loss: 0.0030 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 108/200
 - 4s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 109/200
 - 4s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 110/200
 - 4s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 111/200
 - 4s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 112/200
 - 4s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 113/200
 - 4s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 114/200
 - 4s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 115/200
 - 4s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9975
Epoch 116/200
 - 4s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 117/200
 - 4s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 118/200
 - 4s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 119/200
 - 4s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9969
Epoch 120/200
 - 4s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 121/200
 - 4s - loss: 0.0028 - val_loss: 0.0044
2019-12-27 00:34:03,408 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_120.pickle
 - val_f1: 0.9971
Epoch 122/200
 - 4s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 123/200
 - 4s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 124/200
 - 4s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 125/200
 - 4s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 126/200
 - 4s - loss: 0.0028 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 127/200
 - 4s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 128/200
 - 4s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 129/200
 - 4s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 130/200
 - 4s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 131/200
 - 4s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 132/200
 - 4s - loss: 0.0028 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 133/200
 - 4s - loss: 0.0030 - val_loss: 0.0048
 - val_f1: 0.9971
Epoch 134/200
 - 4s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 135/200
 - 4s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 136/200
 - 4s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 137/200
 - 4s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 138/200
 - 4s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 139/200
 - 4s - loss: 0.0026 - val_loss: 0.0050
 - val_f1: 0.9971
Epoch 140/200
 - 4s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 141/200
 - 4s - loss: 0.0026 - val_loss: 0.0047
2019-12-27 00:35:38,983 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_6/ann_model_epoch_140.pickle
 - val_f1: 0.9972
Epoch 142/200
 - 4s - loss: 0.0028 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 143/200
 - 4s - loss: 0.0027 - val_loss: 0.0051
 - val_f1: 0.9971
Epoch 144/200
 - 4s - loss: 0.0026 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 145/200
 - 4s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9975
Epoch 146/200
 - 4s - loss: 0.0025 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 147/200
 - 4s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9975
Epoch 148/200
 - 4s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9975
Epoch 149/200
 - 4s - loss: 0.0026 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 150/200
 - 4s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 151/200
 - 4s - loss: 0.0030 - val_loss: 0.0040
 - val_f1: 0.9972
Epoch 152/200
 - 4s - loss: 0.0028 - val_loss: 0.0040
2019-12-27 00:36:32,374 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:36:36,868 [INFO] Last epoch loss evaluation: train_loss = 0.002105, val_loss = 0.003897
2019-12-27 00:36:36,869 [INFO] Training complete. time_to_train = 736.39 sec, 12.27 min
2019-12-27 00:36:36,881 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_6/best_model.pickle
2019-12-27 00:36:36,884 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_6/training_error_history.csv
2019-12-27 00:36:37,058 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_6/training_error_history.png
2019-12-27 00:36:37,238 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_6/training_f1_history.png
2019-12-27 00:36:37,238 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:36:41,766 [INFO] Evaluating predictions (results)
2019-12-27 00:36:42,029 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:36:42,029 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.89      7458
      normal       0.67      0.97      0.79      9711
       probe       0.86      0.65      0.74      2421
         r2l       0.93      0.09      0.17      2421
         u2r       0.90      0.05      0.10       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.87      0.52      0.54     22544
weighted avg       0.82      0.77      0.74     22544

2019-12-27 00:36:42,029 [INFO] Overall accuracy (micro avg): 0.7742193044712562
2019-12-27 00:36:42,325 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7742         0.7742                       0.7742                0.0564                   0.2258  0.7742
1     Macro avg        0.9097         0.8657                       0.5197                0.0772                   0.4803  0.5394
2  Weighted avg        0.8689         0.8227                       0.7742                0.1603                   0.2258  0.7379
2019-12-27 00:36:42,658 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:36:42,658 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.97      0.91      0.94       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.90      0.93     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:36:42,658 [INFO] Overall accuracy (micro avg): 0.9974598134550506
2019-12-27 00:36:43,015 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9636                       0.8998                0.0009                   0.1002  0.9270
2  Weighted avg        0.9984         0.9974                       0.9975                0.0022                   0.0025  0.9974
2019-12-27 00:36:44,458 [INFO] Dataset: Training. Classification report below
2019-12-27 00:36:44,458 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.92      0.95       796
         u2r       0.91      0.76      0.83        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.93      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:36:44,458 [INFO] Overall accuracy (micro avg): 0.9980650538808074
2019-12-27 00:36:46,080 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9981         0.9981                       0.9981                0.0005                   0.0019  0.9981
1     Macro avg        0.9992         0.9774                       0.9345                0.0007                   0.0655  0.9544
2  Weighted avg        0.9988         0.9981                       0.9981                0.0018                   0.0019  0.9980
2019-12-27 00:36:46,118 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_6/ann_depth_nsl_layers_6_results.xlsx
2019-12-27 00:36:46,119 [INFO] ================= Finished running experiment no. 6 ================= 

2019-12-27 00:36:46,122 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_7
2019-12-27 00:36:46,122 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_7/run_log.log
2019-12-27 00:36:46,122 [INFO] ================= Running experiment no. 7  ================= 

2019-12-27 00:36:46,122 [INFO] Experiment parameters given below
2019-12-27 00:36:46,122 [INFO] 
{'experiment_num': 7, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_7', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_7'}
2019-12-27 00:36:46,122 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_7/tf_logs_run_2019_12_27-00_36_46
2019-12-27 00:36:46,122 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:36:46,123 [INFO] Reading X, y files
2019-12-27 00:36:46,123 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:36:46,375 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:36:46,375 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:36:46,440 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:36:46,440 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:36:46,500 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:36:46,501 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:36:46,508 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:36:46,508 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:36:46,512 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:36:46,512 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:36:46,516 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:36:46,704 [INFO] Initializing model
2019-12-27 00:36:47,279 [INFO] _________________________________________________________________
2019-12-27 00:36:47,279 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:36:47,279 [INFO] =================================================================
2019-12-27 00:36:47,279 [INFO] dense_28 (Dense)             (None, 500)               61500     
2019-12-27 00:36:47,279 [INFO] _________________________________________________________________
2019-12-27 00:36:47,279 [INFO] batch_normalization_22 (Batc (None, 500)               2000      
2019-12-27 00:36:47,279 [INFO] _________________________________________________________________
2019-12-27 00:36:47,279 [INFO] dropout_22 (Dropout)         (None, 500)               0         
2019-12-27 00:36:47,279 [INFO] _________________________________________________________________
2019-12-27 00:36:47,279 [INFO] dense_29 (Dense)             (None, 400)               200400    
2019-12-27 00:36:47,279 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] batch_normalization_23 (Batc (None, 400)               1600      
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] dropout_23 (Dropout)         (None, 400)               0         
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] dense_30 (Dense)             (None, 256)               102656    
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] batch_normalization_24 (Batc (None, 256)               1024      
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] dropout_24 (Dropout)         (None, 256)               0         
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] dense_31 (Dense)             (None, 128)               32896     
2019-12-27 00:36:47,280 [INFO] _________________________________________________________________
2019-12-27 00:36:47,280 [INFO] batch_normalization_25 (Batc (None, 128)               512       
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] dropout_25 (Dropout)         (None, 128)               0         
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] dense_32 (Dense)             (None, 64)                8256      
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] dense_33 (Dense)             (None, 32)                2080      
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] batch_normalization_27 (Batc (None, 32)                128       
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,281 [INFO] dropout_27 (Dropout)         (None, 32)                0         
2019-12-27 00:36:47,281 [INFO] _________________________________________________________________
2019-12-27 00:36:47,282 [INFO] dense_34 (Dense)             (None, 16)                528       
2019-12-27 00:36:47,282 [INFO] _________________________________________________________________
2019-12-27 00:36:47,282 [INFO] batch_normalization_28 (Batc (None, 16)                64        
2019-12-27 00:36:47,282 [INFO] _________________________________________________________________
2019-12-27 00:36:47,282 [INFO] dropout_28 (Dropout)         (None, 16)                0         
2019-12-27 00:36:47,282 [INFO] _________________________________________________________________
2019-12-27 00:36:47,282 [INFO] dense_35 (Dense)             (None, 5)                 85        
2019-12-27 00:36:47,282 [INFO] =================================================================
2019-12-27 00:36:47,282 [INFO] Total params: 413,985
2019-12-27 00:36:47,282 [INFO] Trainable params: 411,193
2019-12-27 00:36:47,282 [INFO] Non-trainable params: 2,792
2019-12-27 00:36:47,282 [INFO] _________________________________________________________________
2019-12-27 00:36:47,282 [INFO] Training model
 - val_f1: 0.9973
Epoch 00152: early stopping
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 7s - loss: 0.0957 - val_loss: 0.0213
 - val_f1: 0.9815
Epoch 2/200
 - 6s - loss: 0.0266 - val_loss: 0.0142
 - val_f1: 0.9836
Epoch 3/200
 - 6s - loss: 0.0208 - val_loss: 0.0122
 - val_f1: 0.9897
Epoch 4/200
 - 6s - loss: 0.0179 - val_loss: 0.0119
 - val_f1: 0.9894
Epoch 5/200
 - 6s - loss: 0.0154 - val_loss: 0.0106
 - val_f1: 0.9907
Epoch 6/200
 - 6s - loss: 0.0147 - val_loss: 0.0091
 - val_f1: 0.9918
Epoch 7/200
 - 6s - loss: 0.0130 - val_loss: 0.0088
 - val_f1: 0.9918
Epoch 8/200
 - 6s - loss: 0.0125 - val_loss: 0.0092
 - val_f1: 0.9940
Epoch 9/200
 - 6s - loss: 0.0114 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 10/200
 - 6s - loss: 0.0108 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 11/200
 - 6s - loss: 0.0103 - val_loss: 0.0094
 - val_f1: 0.9927
Epoch 12/200
 - 6s - loss: 0.0095 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 13/200
 - 6s - loss: 0.0094 - val_loss: 0.0063
 - val_f1: 0.9953
Epoch 14/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9935
Epoch 15/200
 - 6s - loss: 0.0083 - val_loss: 0.0064
 - val_f1: 0.9951
Epoch 16/200
 - 6s - loss: 0.0082 - val_loss: 0.0064
 - val_f1: 0.9955
Epoch 17/200
 - 6s - loss: 0.0080 - val_loss: 0.0091
 - val_f1: 0.9919
Epoch 18/200
 - 6s - loss: 0.0076 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 19/200
 - 6s - loss: 0.0074 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 20/200
 - 6s - loss: 0.0070 - val_loss: 0.0057
 - val_f1: 0.9953
Epoch 21/200
 - 6s - loss: 0.0071 - val_loss: 0.0061
2019-12-27 00:39:27,131 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_20.pickle
 - val_f1: 0.9955
Epoch 22/200
 - 6s - loss: 0.0065 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 23/200
 - 6s - loss: 0.0059 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 24/200
 - 6s - loss: 0.0064 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 25/200
 - 6s - loss: 0.0063 - val_loss: 0.0063
 - val_f1: 0.9953
Epoch 26/200
 - 6s - loss: 0.0060 - val_loss: 0.0051
 - val_f1: 0.9959
Epoch 27/200
 - 6s - loss: 0.0058 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 28/200
 - 6s - loss: 0.0062 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 29/200
 - 6s - loss: 0.0056 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 30/200
 - 6s - loss: 0.0053 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 31/200
 - 6s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9959
Epoch 32/200
 - 6s - loss: 0.0053 - val_loss: 0.0052
 - val_f1: 0.9958
Epoch 33/200
 - 6s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 34/200
 - 6s - loss: 0.0052 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 35/200
 - 6s - loss: 0.0048 - val_loss: 0.0075
 - val_f1: 0.9939
Epoch 36/200
 - 6s - loss: 0.0046 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 37/200
 - 6s - loss: 0.0049 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 38/200
 - 6s - loss: 0.0046 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 39/200
 - 6s - loss: 0.0049 - val_loss: 0.0061
 - val_f1: 0.9962
Epoch 40/200
 - 6s - loss: 0.0046 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 41/200
 - 6s - loss: 0.0048 - val_loss: 0.0052
2019-12-27 00:41:51,709 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_40.pickle
 - val_f1: 0.9966
Epoch 42/200
 - 6s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 43/200
 - 6s - loss: 0.0045 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 44/200
 - 6s - loss: 0.0046 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 45/200
 - 6s - loss: 0.0041 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 46/200
 - 6s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9959
Epoch 47/200
 - 6s - loss: 0.0045 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 48/200
 - 6s - loss: 0.0042 - val_loss: 0.0058
 - val_f1: 0.9960
Epoch 49/200
 - 6s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 50/200
 - 6s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 51/200
 - 6s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 52/200
 - 6s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 53/200
 - 6s - loss: 0.0037 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 54/200
 - 6s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 55/200
 - 6s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 56/200
 - 6s - loss: 0.0042 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 57/200
 - 6s - loss: 0.0039 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 58/200
 - 6s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 59/200
 - 6s - loss: 0.0037 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 60/200
 - 6s - loss: 0.0038 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 61/200
 - 6s - loss: 0.0034 - val_loss: 0.0051
2019-12-27 00:44:16,135 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_60.pickle
 - val_f1: 0.9969
Epoch 62/200
 - 6s - loss: 0.0038 - val_loss: 0.0055
 - val_f1: 0.9958
Epoch 63/200
 - 6s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 64/200
 - 6s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 65/200
 - 6s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 66/200
 - 6s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 67/200
 - 6s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 68/200
 - 6s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 69/200
 - 6s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 70/200
 - 6s - loss: 0.0032 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 71/200
 - 6s - loss: 0.0038 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 72/200
 - 6s - loss: 0.0034 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 73/200
 - 6s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 74/200
 - 6s - loss: 0.0032 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 75/200
 - 6s - loss: 0.0038 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 76/200
 - 6s - loss: 0.0037 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 77/200
 - 6s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9970
Epoch 78/200
 - 6s - loss: 0.0032 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 79/200
 - 6s - loss: 0.0031 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 80/200
 - 6s - loss: 0.0032 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 81/200
 - 6s - loss: 0.0035 - val_loss: 0.0046
2019-12-27 00:46:40,632 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_80.pickle
 - val_f1: 0.9968
Epoch 82/200
 - 6s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 83/200
 - 6s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 84/200
 - 6s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 85/200
 - 6s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 86/200
 - 6s - loss: 0.0033 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 87/200
 - 6s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 88/200
 - 6s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 89/200
 - 6s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 90/200
 - 6s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9965
Epoch 91/200
 - 6s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 92/200
 - 6s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9964
Epoch 93/200
 - 6s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 94/200
 - 6s - loss: 0.0031 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 95/200
 - 6s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 96/200
 - 6s - loss: 0.0030 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 97/200
 - 6s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 98/200
 - 6s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 99/200
 - 6s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9962
Epoch 100/200
 - 6s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 101/200
 - 6s - loss: 0.0029 - val_loss: 0.0046
2019-12-27 00:49:05,072 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_100.pickle
 - val_f1: 0.9972
Epoch 102/200
 - 6s - loss: 0.0030 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 103/200
 - 6s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 104/200
 - 6s - loss: 0.0029 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 105/200
 - 6s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 106/200
 - 6s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 107/200
 - 6s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 108/200
 - 6s - loss: 0.0030 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 109/200
 - 6s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 110/200
 - 6s - loss: 0.0030 - val_loss: 0.0038
 - val_f1: 0.9973
Epoch 111/200
 - 6s - loss: 0.0025 - val_loss: 0.0040
 - val_f1: 0.9973
Epoch 112/200
 - 6s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 113/200
 - 6s - loss: 0.0027 - val_loss: 0.0048
 - val_f1: 0.9974
Epoch 114/200
 - 6s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 115/200
 - 6s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 116/200
 - 6s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9969
Epoch 117/200
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 118/200
 - 6s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 119/200
 - 6s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 120/200
 - 6s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 121/200
 - 6s - loss: 0.0026 - val_loss: 0.0045
2019-12-27 00:51:29,501 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_120.pickle
 - val_f1: 0.9971
Epoch 122/200
 - 6s - loss: 0.0026 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 123/200
 - 6s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 124/200
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 125/200
 - 6s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 126/200
 - 6s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 127/200
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 128/200
 - 6s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 129/200
 - 6s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 130/200
 - 6s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 131/200
 - 6s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9971
Epoch 132/200
 - 6s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9969
Epoch 133/200
 - 6s - loss: 0.0024 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 134/200
 - 6s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 135/200
 - 6s - loss: 0.0028 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 136/200
 - 6s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 137/200
 - 6s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 138/200
 - 6s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 139/200
 - 6s - loss: 0.0026 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 140/200
 - 6s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9976
Epoch 141/200
 - 6s - loss: 0.0027 - val_loss: 0.0043
2019-12-27 00:53:53,969 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_7/ann_model_epoch_140.pickle
 - val_f1: 0.9972
Epoch 142/200
 - 6s - loss: 0.0025 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 143/200
 - 6s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 144/200
 - 6s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9969
Epoch 145/200
 - 6s - loss: 0.0024 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 146/200
 - 6s - loss: 0.0023 - val_loss: 0.0040
 - val_f1: 0.9975
Epoch 147/200
 - 6s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 148/200
 - 6s - loss: 0.0025 - val_loss: 0.0040
 - val_f1: 0.9976
Epoch 149/200
 - 6s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 150/200
 - 6s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 151/200
 - 6s - loss: 0.0024 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 152/200
 - 6s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9974
Epoch 153/200
 - 6s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 154/200
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 155/200
 - 6s - loss: 0.0023 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 156/200
 - 6s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 157/200
 - 6s - loss: 0.0022 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 158/200
 - 6s - loss: 0.0024 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 159/200
 - 6s - loss: 0.0025 - val_loss: 0.0048
 - val_f1: 0.9973
Epoch 160/200
 - 6s - loss: 0.0025 - val_loss: 0.0044
2019-12-27 00:56:12,365 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 00:56:18,920 [INFO] Last epoch loss evaluation: train_loss = 0.001948, val_loss = 0.003811
2019-12-27 00:56:18,921 [INFO] Training complete. time_to_train = 1171.64 sec, 19.53 min
2019-12-27 00:56:18,939 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_7/best_model.pickle
2019-12-27 00:56:18,942 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_7/training_error_history.csv
2019-12-27 00:56:19,123 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_7/training_error_history.png
2019-12-27 00:56:19,307 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_7/training_f1_history.png
2019-12-27 00:56:19,307 [INFO] Making predictions on training, validation, testing data
2019-12-27 00:56:25,956 [INFO] Evaluating predictions (results)
2019-12-27 00:56:26,221 [INFO] Dataset: Testing. Classification report below
2019-12-27 00:56:26,221 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.83      0.89      7458
      normal       0.68      0.97      0.80      9711
       probe       0.85      0.66      0.74      2421
         r2l       0.71      0.10      0.18      2421
         u2r       0.90      0.05      0.10       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.82      0.52      0.54     22544
weighted avg       0.80      0.77      0.74     22544

2019-12-27 00:56:26,221 [INFO] Overall accuracy (micro avg): 0.7743967352732435
2019-12-27 00:56:26,517 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7744         0.7744                       0.7744                0.0564                   0.2256  0.7744
1     Macro avg        0.9098         0.8192                       0.5221                0.0764                   0.4779  0.5410
2  Weighted avg        0.8703         0.7984                       0.7744                0.1563                   0.2256  0.7394
2019-12-27 00:56:26,850 [INFO] Dataset: Validation. Classification report below
2019-12-27 00:56:26,850 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.97      0.92      0.94       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.90      0.93     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 00:56:26,850 [INFO] Overall accuracy (micro avg): 0.9973804326255209
2019-12-27 00:56:27,207 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9974         0.9974                       0.9974                0.0007                   0.0026  0.9974
1     Macro avg        0.9990         0.9635                       0.9018                0.0009                   0.0982  0.9280
2  Weighted avg        0.9984         0.9974                       0.9974                0.0020                   0.0026  0.9974
2019-12-27 00:56:28,652 [INFO] Dataset: Training. Classification report below
2019-12-27 00:56:28,655 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.92      0.95       796
         u2r       0.94      0.79      0.86        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.94      0.96    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 00:56:28,655 [INFO] Overall accuracy (micro avg): 0.9980154398777511
2019-12-27 00:56:30,282 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9980         0.9980                       0.9980                0.0005                   0.0020  0.9980
1     Macro avg        0.9992         0.9839                       0.9404                0.0008                   0.0596  0.9606
2  Weighted avg        0.9987         0.9980                       0.9980                0.0018                   0.0020  0.9980
2019-12-27 00:56:30,320 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_7/ann_depth_nsl_layers_7_results.xlsx
2019-12-27 00:56:30,320 [INFO] ================= Finished running experiment no. 7 ================= 

2019-12-27 00:56:30,323 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_8
2019-12-27 00:56:30,323 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_8/run_log.log
2019-12-27 00:56:30,323 [INFO] ================= Running experiment no. 8  ================= 

2019-12-27 00:56:30,323 [INFO] Experiment parameters given below
2019-12-27 00:56:30,323 [INFO] 
{'experiment_num': 8, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_8', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_8'}
2019-12-27 00:56:30,324 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_8/tf_logs_run_2019_12_27-00_56_30
2019-12-27 00:56:30,324 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 00:56:30,324 [INFO] Reading X, y files
2019-12-27 00:56:30,324 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 00:56:30,575 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 00:56:30,575 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 00:56:30,639 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:56:30,639 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 00:56:30,696 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 00:56:30,697 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 00:56:30,704 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 00:56:30,704 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 00:56:30,708 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:56:30,708 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 00:56:30,712 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 00:56:30,899 [INFO] Initializing model
2019-12-27 00:56:31,573 [INFO] _________________________________________________________________
2019-12-27 00:56:31,573 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 00:56:31,573 [INFO] =================================================================
2019-12-27 00:56:31,573 [INFO] dense_36 (Dense)             (None, 600)               73800     
2019-12-27 00:56:31,573 [INFO] _________________________________________________________________
2019-12-27 00:56:31,573 [INFO] batch_normalization_29 (Batc (None, 600)               2400      
2019-12-27 00:56:31,573 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dropout_29 (Dropout)         (None, 600)               0         
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dense_37 (Dense)             (None, 500)               300500    
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] batch_normalization_30 (Batc (None, 500)               2000      
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dropout_30 (Dropout)         (None, 500)               0         
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dense_38 (Dense)             (None, 400)               200400    
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] batch_normalization_31 (Batc (None, 400)               1600      
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dropout_31 (Dropout)         (None, 400)               0         
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] dense_39 (Dense)             (None, 256)               102656    
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,574 [INFO] batch_normalization_32 (Batc (None, 256)               1024      
2019-12-27 00:56:31,574 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dropout_32 (Dropout)         (None, 256)               0         
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dense_40 (Dense)             (None, 128)               32896     
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] batch_normalization_33 (Batc (None, 128)               512       
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dropout_33 (Dropout)         (None, 128)               0         
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dense_41 (Dense)             (None, 64)                8256      
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] batch_normalization_34 (Batc (None, 64)                256       
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dropout_34 (Dropout)         (None, 64)                0         
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] dense_42 (Dense)             (None, 32)                2080      
2019-12-27 00:56:31,575 [INFO] _________________________________________________________________
2019-12-27 00:56:31,575 [INFO] batch_normalization_35 (Batc (None, 32)                128       
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,576 [INFO] dropout_35 (Dropout)         (None, 32)                0         
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,576 [INFO] dense_43 (Dense)             (None, 16)                528       
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,576 [INFO] batch_normalization_36 (Batc (None, 16)                64        
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,576 [INFO] dropout_36 (Dropout)         (None, 16)                0         
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,576 [INFO] dense_44 (Dense)             (None, 5)                 85        
2019-12-27 00:56:31,576 [INFO] =================================================================
2019-12-27 00:56:31,576 [INFO] Total params: 729,185
2019-12-27 00:56:31,576 [INFO] Trainable params: 725,193
2019-12-27 00:56:31,576 [INFO] Non-trainable params: 3,992
2019-12-27 00:56:31,576 [INFO] _________________________________________________________________
2019-12-27 00:56:31,577 [INFO] Training model
 - val_f1: 0.9969
Epoch 00160: early stopping
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 11s - loss: 0.0878 - val_loss: 0.0164
 - val_f1: 0.9869
Epoch 2/200
 - 9s - loss: 0.0247 - val_loss: 0.0151
 - val_f1: 0.9893
Epoch 3/200
 - 9s - loss: 0.0204 - val_loss: 0.0130
 - val_f1: 0.9879
Epoch 4/200
 - 9s - loss: 0.0172 - val_loss: 0.0115
 - val_f1: 0.9913
Epoch 5/200
 - 9s - loss: 0.0154 - val_loss: 0.0118
 - val_f1: 0.9899
Epoch 6/200
 - 9s - loss: 0.0143 - val_loss: 0.0111
 - val_f1: 0.9917
Epoch 7/200
 - 9s - loss: 0.0130 - val_loss: 0.0096
 - val_f1: 0.9919
Epoch 8/200
 - 9s - loss: 0.0128 - val_loss: 0.0108
 - val_f1: 0.9910
Epoch 9/200
 - 9s - loss: 0.0118 - val_loss: 0.0110
 - val_f1: 0.9914
Epoch 10/200
 - 9s - loss: 0.0115 - val_loss: 0.0087
 - val_f1: 0.9930
Epoch 11/200
 - 9s - loss: 0.0107 - val_loss: 0.0076
 - val_f1: 0.9944
Epoch 12/200
 - 9s - loss: 0.0099 - val_loss: 0.0092
 - val_f1: 0.9932
Epoch 13/200
 - 9s - loss: 0.0100 - val_loss: 0.0083
 - val_f1: 0.9939
Epoch 14/200
 - 9s - loss: 0.0093 - val_loss: 0.0092
 - val_f1: 0.9916
Epoch 15/200
 - 9s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9941
Epoch 16/200
 - 9s - loss: 0.0093 - val_loss: 0.0066
 - val_f1: 0.9949
Epoch 17/200
 - 9s - loss: 0.0085 - val_loss: 0.0077
 - val_f1: 0.9950
Epoch 18/200
 - 9s - loss: 0.0083 - val_loss: 0.0066
 - val_f1: 0.9948
Epoch 19/200
 - 9s - loss: 0.0080 - val_loss: 0.0067
 - val_f1: 0.9947
Epoch 20/200
 - 9s - loss: 0.0079 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 21/200
 - 9s - loss: 0.0072 - val_loss: 0.0066
2019-12-27 01:00:24,541 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_20.pickle
 - val_f1: 0.9954
Epoch 22/200
 - 9s - loss: 0.0072 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 23/200
 - 9s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 24/200
 - 9s - loss: 0.0068 - val_loss: 0.0072
 - val_f1: 0.9945
Epoch 25/200
 - 9s - loss: 0.0065 - val_loss: 0.0070
 - val_f1: 0.9941
Epoch 26/200
 - 9s - loss: 0.0060 - val_loss: 0.0056
 - val_f1: 0.9955
Epoch 27/200
 - 9s - loss: 0.0067 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 28/200
 - 9s - loss: 0.0061 - val_loss: 0.0064
 - val_f1: 0.9949
Epoch 29/200
 - 9s - loss: 0.0060 - val_loss: 0.0078
 - val_f1: 0.9932
Epoch 30/200
 - 9s - loss: 0.0057 - val_loss: 0.0072
 - val_f1: 0.9952
Epoch 31/200
 - 9s - loss: 0.0055 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 32/200
 - 9s - loss: 0.0062 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 33/200
 - 9s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 34/200
 - 9s - loss: 0.0055 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 35/200
 - 9s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 36/200
 - 9s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9956
Epoch 37/200
 - 9s - loss: 0.0049 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 38/200
 - 9s - loss: 0.0048 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 39/200
 - 9s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 40/200
 - 9s - loss: 0.0049 - val_loss: 0.0050
 - val_f1: 0.9961
Epoch 41/200
 - 9s - loss: 0.0050 - val_loss: 0.0057
2019-12-27 01:03:56,817 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_40.pickle
 - val_f1: 0.9960
Epoch 42/200
 - 9s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 43/200
 - 9s - loss: 0.0043 - val_loss: 0.0059
 - val_f1: 0.9962
Epoch 44/200
 - 9s - loss: 0.0046 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 45/200
 - 9s - loss: 0.0048 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 46/200
 - 9s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 47/200
 - 9s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 48/200
 - 9s - loss: 0.0045 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 49/200
 - 9s - loss: 0.0043 - val_loss: 0.0054
 - val_f1: 0.9958
Epoch 50/200
 - 9s - loss: 0.0045 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 51/200
 - 9s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 52/200
 - 9s - loss: 0.0046 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 53/200
 - 9s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 54/200
 - 9s - loss: 0.0045 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 55/200
 - 9s - loss: 0.0040 - val_loss: 0.0072
 - val_f1: 0.9943
Epoch 56/200
 - 9s - loss: 0.0042 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 57/200
 - 9s - loss: 0.0039 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 58/200
 - 9s - loss: 0.0041 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 59/200
 - 9s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 60/200
 - 9s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 61/200
 - 9s - loss: 0.0038 - val_loss: 0.0049
2019-12-27 01:07:29,372 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_60.pickle
 - val_f1: 0.9967
Epoch 62/200
 - 9s - loss: 0.0040 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 63/200
 - 9s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 64/200
 - 9s - loss: 0.0041 - val_loss: 0.0055
 - val_f1: 0.9967
Epoch 65/200
 - 9s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 66/200
 - 9s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 67/200
 - 9s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 68/200
 - 9s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 69/200
 - 9s - loss: 0.0035 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 70/200
 - 9s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 71/200
 - 9s - loss: 0.0035 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 72/200
 - 9s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9971
Epoch 73/200
 - 9s - loss: 0.0035 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 74/200
 - 9s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 75/200
 - 9s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9969
Epoch 76/200
 - 9s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 77/200
 - 9s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 78/200
 - 9s - loss: 0.0031 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 79/200
 - 9s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 80/200
 - 9s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 81/200
 - 9s - loss: 0.0033 - val_loss: 0.0049
2019-12-27 01:11:01,761 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_80.pickle
 - val_f1: 0.9968
Epoch 82/200
 - 9s - loss: 0.0031 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 83/200
 - 9s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 84/200
 - 9s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9974
Epoch 85/200
 - 9s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 86/200
 - 9s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 87/200
 - 9s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 88/200
 - 9s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 89/200
 - 9s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 90/200
 - 9s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9969
Epoch 91/200
 - 9s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 92/200
 - 9s - loss: 0.0031 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 93/200
 - 9s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 94/200
 - 9s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 95/200
 - 9s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 96/200
 - 9s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 97/200
 - 9s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 98/200
 - 9s - loss: 0.0030 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 99/200
 - 9s - loss: 0.0032 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 100/200
 - 9s - loss: 0.0030 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 101/200
 - 9s - loss: 0.0034 - val_loss: 0.0047
2019-12-27 01:14:33,990 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_100.pickle
 - val_f1: 0.9971
Epoch 102/200
 - 9s - loss: 0.0029 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 103/200
 - 9s - loss: 0.0029 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 104/200
 - 9s - loss: 0.0032 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 105/200
 - 9s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 106/200
 - 9s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 107/200
 - 9s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 108/200
 - 9s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 109/200
 - 9s - loss: 0.0031 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 110/200
 - 9s - loss: 0.0028 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 111/200
 - 9s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 112/200
 - 9s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 113/200
 - 9s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 114/200
 - 9s - loss: 0.0028 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 115/200
 - 9s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9973
Epoch 116/200
 - 9s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 117/200
 - 9s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 118/200
 - 9s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9974
Epoch 119/200
 - 9s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9973
Epoch 120/200
 - 9s - loss: 0.0026 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 121/200
 - 9s - loss: 0.0027 - val_loss: 0.0046
2019-12-27 01:18:06,485 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_120.pickle
 - val_f1: 0.9970
Epoch 122/200
 - 9s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 123/200
 - 9s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 124/200
 - 9s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9970
Epoch 125/200
 - 9s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 126/200
 - 9s - loss: 0.0028 - val_loss: 0.0051
 - val_f1: 0.9971
Epoch 127/200
 - 9s - loss: 0.0030 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 128/200
 - 9s - loss: 0.0027 - val_loss: 0.0048
 - val_f1: 0.9971
Epoch 129/200
 - 9s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 130/200
 - 9s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 131/200
 - 9s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 132/200
 - 9s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 133/200
 - 9s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 134/200
 - 9s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9973
Epoch 135/200
 - 9s - loss: 0.0025 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 136/200
 - 9s - loss: 0.0029 - val_loss: 0.0057
 - val_f1: 0.9955
Epoch 137/200
 - 9s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 138/200
 - 9s - loss: 0.0027 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 139/200
 - 9s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 140/200
 - 9s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 141/200
 - 9s - loss: 0.0024 - val_loss: 0.0047
2019-12-27 01:21:38,984 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_140.pickle
 - val_f1: 0.9973
Epoch 142/200
 - 9s - loss: 0.0028 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 143/200
 - 9s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 144/200
 - 9s - loss: 0.0030 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 145/200
 - 9s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 146/200
 - 9s - loss: 0.0027 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 147/200
 - 9s - loss: 0.0026 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 148/200
 - 9s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 149/200
 - 9s - loss: 0.0025 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 150/200
 - 9s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 151/200
 - 9s - loss: 0.0023 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 152/200
 - 9s - loss: 0.0023 - val_loss: 0.0053
 - val_f1: 0.9970
Epoch 153/200
 - 9s - loss: 0.0026 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 154/200
 - 9s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 155/200
 - 9s - loss: 0.0024 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 156/200
 - 9s - loss: 0.0025 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 157/200
 - 9s - loss: 0.0028 - val_loss: 0.0040
 - val_f1: 0.9977
Epoch 158/200
 - 9s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9974
Epoch 159/200
 - 9s - loss: 0.0024 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 160/200
 - 9s - loss: 0.0023 - val_loss: 0.0038
 - val_f1: 0.9976
Epoch 161/200
 - 9s - loss: 0.0025 - val_loss: 0.0042
2019-12-27 01:25:11,510 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_160.pickle
 - val_f1: 0.9971
Epoch 162/200
 - 9s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 163/200
 - 9s - loss: 0.0024 - val_loss: 0.0053
 - val_f1: 0.9971
Epoch 164/200
 - 9s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 165/200
 - 9s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 166/200
 - 9s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 167/200
 - 9s - loss: 0.0023 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 168/200
 - 9s - loss: 0.0023 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 169/200
 - 9s - loss: 0.0024 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 170/200
 - 9s - loss: 0.0023 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 171/200
 - 9s - loss: 0.0021 - val_loss: 0.0049
 - val_f1: 0.9973
Epoch 172/200
 - 9s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 173/200
 - 9s - loss: 0.0030 - val_loss: 0.0052
 - val_f1: 0.9969
Epoch 174/200
 - 9s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 175/200
 - 9s - loss: 0.0023 - val_loss: 0.0050
 - val_f1: 0.9972
Epoch 176/200
 - 9s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 177/200
 - 9s - loss: 0.0024 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 178/200
 - 9s - loss: 0.0026 - val_loss: 0.0048
 - val_f1: 0.9969
Epoch 179/200
 - 9s - loss: 0.0023 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 180/200
 - 9s - loss: 0.0023 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 181/200
 - 9s - loss: 0.0024 - val_loss: 0.0047
2019-12-27 01:28:43,875 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_8/ann_model_epoch_180.pickle
 - val_f1: 0.9968
Epoch 182/200
 - 9s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 183/200
 - 9s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 184/200
 - 9s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 185/200
 - 9s - loss: 0.0021 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 186/200
 - 9s - loss: 0.0023 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 187/200
 - 9s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 188/200
 - 9s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 189/200
 - 9s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 190/200
 - 9s - loss: 0.0023 - val_loss: 0.0048
 - val_f1: 0.9971
Epoch 191/200
 - 9s - loss: 0.0022 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 192/200
 - 9s - loss: 0.0022 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 193/200
 - 9s - loss: 0.0023 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 194/200
 - 9s - loss: 0.0023 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 195/200
 - 9s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 196/200
 - 9s - loss: 0.0023 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 197/200
 - 9s - loss: 0.0022 - val_loss: 0.0045
 - val_f1: 0.9975
Epoch 198/200
 - 9s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 199/200
 - 9s - loss: 0.0023 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 200/200
 - 9s - loss: 0.0022 - val_loss: 0.0046
2019-12-27 01:32:07,344 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 01:32:16,770 [INFO] Last epoch loss evaluation: train_loss = 0.001792, val_loss = 0.003801
2019-12-27 01:32:16,771 [INFO] Training complete. time_to_train = 2145.19 sec, 35.75 min
2019-12-27 01:32:16,795 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_8/best_model.pickle
2019-12-27 01:32:16,797 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_8/training_error_history.csv
2019-12-27 01:32:16,977 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_8/training_error_history.png
2019-12-27 01:32:17,151 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_8/training_f1_history.png
2019-12-27 01:32:17,151 [INFO] Making predictions on training, validation, testing data
2019-12-27 01:32:26,981 [INFO] Evaluating predictions (results)
2019-12-27 01:32:27,248 [INFO] Dataset: Testing. Classification report below
2019-12-27 01:32:27,249 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.82      0.88      7458
      normal       0.67      0.95      0.79      9711
       probe       0.76      0.67      0.71      2421
         r2l       0.84      0.10      0.18      2421
         u2r       0.90      0.05      0.09       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.83      0.52      0.53     22544
weighted avg       0.80      0.76      0.73     22544

2019-12-27 01:32:27,249 [INFO] Overall accuracy (micro avg): 0.7648598296664301
2019-12-27 01:32:27,545 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7649         0.7649                       0.7649                0.0588                   0.2351  0.7649
1     Macro avg        0.9059         0.8255                       0.5174                0.0788                   0.4826  0.5303
2  Weighted avg        0.8647         0.8003                       0.7649                0.1589                   0.2351  0.7298
2019-12-27 01:32:27,878 [INFO] Dataset: Validation. Classification report below
2019-12-27 01:32:27,878 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.97      0.91      0.94       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.90      0.93     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 01:32:27,878 [INFO] Overall accuracy (micro avg): 0.9976185751141099
2019-12-27 01:32:28,235 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9976         0.9976                       0.9976                0.0006                   0.0024  0.9976
1     Macro avg        0.9990         0.9646                       0.9012                0.0009                   0.0988  0.9282
2  Weighted avg        0.9985         0.9976                       0.9976                0.0019                   0.0024  0.9976
2019-12-27 01:32:29,678 [INFO] Dataset: Training. Classification report below
2019-12-27 01:32:29,678 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      1.00      1.00      9325
         r2l       0.98      0.93      0.95       796
         u2r       0.94      0.76      0.84        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.94      0.96    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 01:32:29,678 [INFO] Overall accuracy (micro avg): 0.9982833554942547
2019-12-27 01:32:31,301 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9983         0.9983                       0.9983                0.0004                   0.0017  0.9983
1     Macro avg        0.9993         0.9825                       0.9373                0.0006                   0.0627  0.9579
2  Weighted avg        0.9989         0.9983                       0.9983                0.0015                   0.0017  0.9983
2019-12-27 01:32:31,339 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_8/ann_depth_nsl_layers_8_results.xlsx
2019-12-27 01:32:31,339 [INFO] ================= Finished running experiment no. 8 ================= 

2019-12-27 01:32:31,342 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_9
2019-12-27 01:32:31,342 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_9/run_log.log
2019-12-27 01:32:31,342 [INFO] ================= Running experiment no. 9  ================= 

2019-12-27 01:32:31,342 [INFO] Experiment parameters given below
2019-12-27 01:32:31,342 [INFO] 
{'experiment_num': 9, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_9', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_9'}
2019-12-27 01:32:31,342 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_9/tf_logs_run_2019_12_27-01_32_31
2019-12-27 01:32:31,342 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 01:32:31,342 [INFO] Reading X, y files
2019-12-27 01:32:31,342 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 01:32:31,594 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 01:32:31,594 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 01:32:31,658 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 01:32:31,658 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 01:32:31,716 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 01:32:31,716 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 01:32:31,723 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 01:32:31,723 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 01:32:31,727 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 01:32:31,728 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 01:32:31,731 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 01:32:31,916 [INFO] Initializing model
2019-12-27 01:32:32,687 [INFO] _________________________________________________________________
2019-12-27 01:32:32,687 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 01:32:32,687 [INFO] =================================================================
2019-12-27 01:32:32,687 [INFO] dense_45 (Dense)             (None, 700)               86100     
2019-12-27 01:32:32,687 [INFO] _________________________________________________________________
2019-12-27 01:32:32,687 [INFO] batch_normalization_37 (Batc (None, 700)               2800      
2019-12-27 01:32:32,687 [INFO] _________________________________________________________________
2019-12-27 01:32:32,687 [INFO] dropout_37 (Dropout)         (None, 700)               0         
2019-12-27 01:32:32,687 [INFO] _________________________________________________________________
2019-12-27 01:32:32,687 [INFO] dense_46 (Dense)             (None, 600)               420600    
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] batch_normalization_38 (Batc (None, 600)               2400      
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] dropout_38 (Dropout)         (None, 600)               0         
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] dense_47 (Dense)             (None, 500)               300500    
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] batch_normalization_39 (Batc (None, 500)               2000      
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] dropout_39 (Dropout)         (None, 500)               0         
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] dense_48 (Dense)             (None, 400)               200400    
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] batch_normalization_40 (Batc (None, 400)               1600      
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,688 [INFO] dropout_40 (Dropout)         (None, 400)               0         
2019-12-27 01:32:32,688 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dense_49 (Dense)             (None, 256)               102656    
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] batch_normalization_41 (Batc (None, 256)               1024      
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dropout_41 (Dropout)         (None, 256)               0         
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dense_50 (Dense)             (None, 128)               32896     
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] batch_normalization_42 (Batc (None, 128)               512       
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dropout_42 (Dropout)         (None, 128)               0         
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dense_51 (Dense)             (None, 64)                8256      
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] batch_normalization_43 (Batc (None, 64)                256       
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dropout_43 (Dropout)         (None, 64)                0         
2019-12-27 01:32:32,689 [INFO] _________________________________________________________________
2019-12-27 01:32:32,689 [INFO] dense_52 (Dense)             (None, 32)                2080      
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] batch_normalization_44 (Batc (None, 32)                128       
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] dropout_44 (Dropout)         (None, 32)                0         
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] dense_53 (Dense)             (None, 16)                528       
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] batch_normalization_45 (Batc (None, 16)                64        
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] dropout_45 (Dropout)         (None, 16)                0         
2019-12-27 01:32:32,690 [INFO] _________________________________________________________________
2019-12-27 01:32:32,690 [INFO] dense_54 (Dense)             (None, 5)                 85        
2019-12-27 01:32:32,690 [INFO] =================================================================
2019-12-27 01:32:32,691 [INFO] Total params: 1,164,885
2019-12-27 01:32:32,691 [INFO] Trainable params: 1,159,493
2019-12-27 01:32:32,691 [INFO] Non-trainable params: 5,392
2019-12-27 01:32:32,691 [INFO] _________________________________________________________________
2019-12-27 01:32:32,691 [INFO] Training model
 - val_f1: 0.9973
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 15s - loss: 0.0874 - val_loss: 0.0192
 - val_f1: 0.9867
Epoch 2/200
 - 13s - loss: 0.0256 - val_loss: 0.0147
 - val_f1: 0.9895
Epoch 3/200
 - 13s - loss: 0.0209 - val_loss: 0.0120
 - val_f1: 0.9900
Epoch 4/200
 - 13s - loss: 0.0173 - val_loss: 0.0109
 - val_f1: 0.9911
Epoch 5/200
 - 13s - loss: 0.0154 - val_loss: 0.0108
 - val_f1: 0.9902
Epoch 6/200
 - 13s - loss: 0.0146 - val_loss: 0.0106
 - val_f1: 0.9909
Epoch 7/200
 - 13s - loss: 0.0142 - val_loss: 0.0102
 - val_f1: 0.9917
Epoch 8/200
 - 13s - loss: 0.0130 - val_loss: 0.0096
 - val_f1: 0.9918
Epoch 9/200
 - 13s - loss: 0.0122 - val_loss: 0.0102
 - val_f1: 0.9915
Epoch 10/200
 - 13s - loss: 0.0114 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 11/200
 - 13s - loss: 0.0117 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 12/200
 - 13s - loss: 0.0111 - val_loss: 0.0088
 - val_f1: 0.9926
Epoch 13/200
 - 13s - loss: 0.0104 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 14/200
 - 13s - loss: 0.0099 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 15/200
 - 13s - loss: 0.0094 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 16/200
 - 13s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9934
Epoch 17/200
 - 13s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 18/200
 - 13s - loss: 0.0083 - val_loss: 0.0070
 - val_f1: 0.9946
Epoch 19/200
 - 13s - loss: 0.0074 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 20/200
 - 13s - loss: 0.0075 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 21/200
 - 13s - loss: 0.0074 - val_loss: 0.0083
2019-12-27 01:37:58,453 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_20.pickle
 - val_f1: 0.9924
Epoch 22/200
 - 13s - loss: 0.0070 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 23/200
 - 13s - loss: 0.0065 - val_loss: 0.0058
 - val_f1: 0.9953
Epoch 24/200
 - 13s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9944
Epoch 25/200
 - 13s - loss: 0.0068 - val_loss: 0.0078
 - val_f1: 0.9941
Epoch 26/200
 - 13s - loss: 0.0073 - val_loss: 0.0065
 - val_f1: 0.9956
Epoch 27/200
 - 13s - loss: 0.0063 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 28/200
 - 13s - loss: 0.0061 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 29/200
 - 13s - loss: 0.0053 - val_loss: 0.0054
 - val_f1: 0.9952
Epoch 30/200
 - 13s - loss: 0.0057 - val_loss: 0.0058
 - val_f1: 0.9954
Epoch 31/200
 - 13s - loss: 0.0058 - val_loss: 0.0051
 - val_f1: 0.9959
Epoch 32/200
 - 13s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 33/200
 - 13s - loss: 0.0056 - val_loss: 0.0051
 - val_f1: 0.9960
Epoch 34/200
 - 13s - loss: 0.0053 - val_loss: 0.0062
 - val_f1: 0.9958
Epoch 35/200
 - 13s - loss: 0.0052 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 36/200
 - 13s - loss: 0.0048 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 37/200
 - 13s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9954
Epoch 38/200
 - 13s - loss: 0.0052 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 39/200
 - 13s - loss: 0.0050 - val_loss: 0.0055
 - val_f1: 0.9957
Epoch 40/200
 - 13s - loss: 0.0051 - val_loss: 0.0052
 - val_f1: 0.9961
Epoch 41/200
 - 13s - loss: 0.0045 - val_loss: 0.0045
2019-12-27 01:42:56,629 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_40.pickle
 - val_f1: 0.9964
Epoch 42/200
 - 13s - loss: 0.0049 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 43/200
 - 13s - loss: 0.0052 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 44/200
 - 13s - loss: 0.0049 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 45/200
 - 13s - loss: 0.0046 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 46/200
 - 13s - loss: 0.0044 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 47/200
 - 13s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9962
Epoch 48/200
 - 13s - loss: 0.0046 - val_loss: 0.0061
 - val_f1: 0.9948
Epoch 49/200
 - 13s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 50/200
 - 13s - loss: 0.0043 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 51/200
 - 13s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 52/200
 - 13s - loss: 0.0045 - val_loss: 0.0105
 - val_f1: 0.9932
Epoch 53/200
 - 13s - loss: 0.0054 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 54/200
 - 13s - loss: 0.0043 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 55/200
 - 13s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 56/200
 - 13s - loss: 0.0041 - val_loss: 0.0044
 - val_f1: 0.9966
Epoch 57/200
 - 13s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 58/200
 - 13s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 59/200
 - 13s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 60/200
 - 13s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9968
Epoch 61/200
 - 13s - loss: 0.0043 - val_loss: 0.0046
2019-12-27 01:47:54,415 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_60.pickle
 - val_f1: 0.9968
Epoch 62/200
 - 13s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 63/200
 - 13s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 64/200
 - 13s - loss: 0.0041 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 65/200
 - 13s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 66/200
 - 13s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 67/200
 - 13s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 68/200
 - 13s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 69/200
 - 13s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 70/200
 - 13s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 71/200
 - 13s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 72/200
 - 13s - loss: 0.0037 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 73/200
 - 13s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 74/200
 - 13s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 75/200
 - 13s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 76/200
 - 13s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 77/200
 - 13s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 78/200
 - 13s - loss: 0.0040 - val_loss: 0.0062
 - val_f1: 0.9947
Epoch 79/200
 - 13s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 80/200
 - 13s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 81/200
 - 13s - loss: 0.0033 - val_loss: 0.0048
2019-12-27 01:52:52,612 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_80.pickle
 - val_f1: 0.9973
Epoch 82/200
 - 13s - loss: 0.0033 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 83/200
 - 13s - loss: 0.0036 - val_loss: 0.0052
 - val_f1: 0.9961
Epoch 84/200
 - 13s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 85/200
 - 13s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 86/200
 - 13s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 87/200
 - 13s - loss: 0.0031 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 88/200
 - 13s - loss: 0.0030 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 89/200
 - 13s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9973
Epoch 90/200
 - 13s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 91/200
 - 13s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 92/200
 - 13s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 93/200
 - 13s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 94/200
 - 13s - loss: 0.0033 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 95/200
 - 13s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 96/200
 - 13s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 97/200
 - 13s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 98/200
 - 13s - loss: 0.0031 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 99/200
 - 13s - loss: 0.0031 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 100/200
 - 13s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 101/200
 - 13s - loss: 0.0032 - val_loss: 0.0044
2019-12-27 01:57:50,885 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_100.pickle
 - val_f1: 0.9972
Epoch 102/200
 - 13s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 103/200
 - 13s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 104/200
 - 13s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 105/200
 - 13s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 106/200
 - 13s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 107/200
 - 13s - loss: 0.0030 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 108/200
 - 13s - loss: 0.0030 - val_loss: 0.0046
 - val_f1: 0.9975
Epoch 109/200
 - 13s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9973
Epoch 110/200
 - 13s - loss: 0.0029 - val_loss: 0.0052
 - val_f1: 0.9967
Epoch 111/200
 - 13s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 112/200
 - 13s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 113/200
 - 13s - loss: 0.0031 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 114/200
 - 13s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 115/200
 - 13s - loss: 0.0028 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 116/200
 - 13s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9973
Epoch 117/200
 - 13s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 118/200
 - 13s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 119/200
 - 13s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 120/200
 - 13s - loss: 0.0029 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 121/200
 - 13s - loss: 0.0026 - val_loss: 0.0048
2019-12-27 02:02:48,946 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_120.pickle
 - val_f1: 0.9969
Epoch 122/200
 - 13s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 123/200
 - 13s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 124/200
 - 13s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 125/200
 - 13s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 126/200
 - 13s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9971
Epoch 127/200
 - 13s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9971
Epoch 128/200
 - 13s - loss: 0.0026 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 129/200
 - 13s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 130/200
 - 13s - loss: 0.0027 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 131/200
 - 13s - loss: 0.0025 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 132/200
 - 13s - loss: 0.0027 - val_loss: 0.0060
 - val_f1: 0.9972
Epoch 133/200
 - 13s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 134/200
 - 13s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9973
Epoch 135/200
 - 13s - loss: 0.0028 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 136/200
 - 13s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 137/200
 - 13s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 138/200
 - 13s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 139/200
 - 13s - loss: 0.0028 - val_loss: 0.0040
 - val_f1: 0.9974
Epoch 140/200
 - 13s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 141/200
 - 13s - loss: 0.0026 - val_loss: 0.0047
2019-12-27 02:07:47,310 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_140.pickle
 - val_f1: 0.9969
Epoch 142/200
 - 13s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9974
Epoch 143/200
 - 13s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 144/200
 - 13s - loss: 0.0024 - val_loss: 0.0043
 - val_f1: 0.9975
Epoch 145/200
 - 13s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 146/200
 - 13s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9975
Epoch 147/200
 - 13s - loss: 0.0026 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 148/200
 - 13s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 149/200
 - 13s - loss: 0.0027 - val_loss: 0.0048
 - val_f1: 0.9971
Epoch 150/200
 - 13s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 151/200
 - 13s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 152/200
 - 13s - loss: 0.0025 - val_loss: 0.0051
 - val_f1: 0.9972
Epoch 153/200
 - 13s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 154/200
 - 13s - loss: 0.0025 - val_loss: 0.0048
 - val_f1: 0.9971
Epoch 155/200
 - 13s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 156/200
 - 13s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9971
Epoch 157/200
 - 13s - loss: 0.0026 - val_loss: 0.0042
 - val_f1: 0.9977
Epoch 158/200
 - 13s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9974
Epoch 159/200
 - 13s - loss: 0.0025 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 160/200
 - 13s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 161/200
 - 13s - loss: 0.0025 - val_loss: 0.0044
2019-12-27 02:12:46,015 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_160.pickle
 - val_f1: 0.9974
Epoch 162/200
 - 13s - loss: 0.0026 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 163/200
 - 13s - loss: 0.0026 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 164/200
 - 13s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 165/200
 - 13s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9972
Epoch 166/200
 - 13s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9973
Epoch 167/200
 - 13s - loss: 0.0025 - val_loss: 0.0053
 - val_f1: 0.9969
Epoch 168/200
 - 13s - loss: 0.0025 - val_loss: 0.0052
 - val_f1: 0.9970
Epoch 169/200
 - 13s - loss: 0.0024 - val_loss: 0.0054
 - val_f1: 0.9971
Epoch 170/200
 - 13s - loss: 0.0023 - val_loss: 0.0053
 - val_f1: 0.9972
Epoch 171/200
 - 13s - loss: 0.0023 - val_loss: 0.0060
 - val_f1: 0.9964
Epoch 172/200
 - 13s - loss: 0.0025 - val_loss: 0.0063
 - val_f1: 0.9966
Epoch 173/200
 - 13s - loss: 0.0025 - val_loss: 0.0067
 - val_f1: 0.9962
Epoch 174/200
 - 13s - loss: 0.0026 - val_loss: 0.0050
 - val_f1: 0.9971
Epoch 175/200
 - 13s - loss: 0.0022 - val_loss: 0.0051
 - val_f1: 0.9972
Epoch 176/200
 - 13s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 177/200
 - 13s - loss: 0.0024 - val_loss: 0.0058
 - val_f1: 0.9962
Epoch 178/200
 - 13s - loss: 0.0026 - val_loss: 0.0051
 - val_f1: 0.9972
Epoch 179/200
 - 13s - loss: 0.0026 - val_loss: 0.0050
 - val_f1: 0.9973
Epoch 180/200
 - 13s - loss: 0.0024 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 181/200
 - 13s - loss: 0.0023 - val_loss: 0.0054
2019-12-27 02:17:44,481 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_9/ann_model_epoch_180.pickle
 - val_f1: 0.9969
Epoch 182/200
 - 13s - loss: 0.0025 - val_loss: 0.0052
 - val_f1: 0.9969
Epoch 183/200
 - 13s - loss: 0.0023 - val_loss: 0.0057
 - val_f1: 0.9970
Epoch 184/200
 - 13s - loss: 0.0023 - val_loss: 0.0050
 - val_f1: 0.9973
Epoch 185/200
 - 13s - loss: 0.0024 - val_loss: 0.0053
 - val_f1: 0.9973
Epoch 186/200
 - 13s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 187/200
 - 13s - loss: 0.0024 - val_loss: 0.0048
 - val_f1: 0.9974
Epoch 188/200
 - 13s - loss: 0.0024 - val_loss: 0.0049
 - val_f1: 0.9972
Epoch 189/200
 - 13s - loss: 0.0024 - val_loss: 0.0050
2019-12-27 02:19:45,992 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 02:19:58,951 [INFO] Last epoch loss evaluation: train_loss = 0.001926, val_loss = 0.003979
2019-12-27 02:19:58,951 [INFO] Training complete. time_to_train = 2846.26 sec, 47.44 min
2019-12-27 02:19:58,984 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_9/best_model.pickle
2019-12-27 02:19:58,987 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_9/training_error_history.csv
2019-12-27 02:19:59,162 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_9/training_error_history.png
2019-12-27 02:19:59,334 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_9/training_f1_history.png
2019-12-27 02:19:59,334 [INFO] Making predictions on training, validation, testing data
2019-12-27 02:20:13,000 [INFO] Evaluating predictions (results)
2019-12-27 02:20:13,267 [INFO] Dataset: Testing. Classification report below
2019-12-27 02:20:13,267 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.83      0.89      7458
      normal       0.68      0.94      0.79      9711
       probe       0.74      0.73      0.73      2421
         r2l       0.84      0.11      0.20      2421
         u2r       0.96      0.04      0.08       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.84      0.53      0.54     22544
weighted avg       0.80      0.77      0.74     22544

2019-12-27 02:20:13,267 [INFO] Overall accuracy (micro avg): 0.7689850958126331
2019-12-27 02:20:13,565 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7690         0.7690                       0.7690                0.0578                   0.2310  0.7690
1     Macro avg        0.9076         0.8367                       0.5292                0.0768                   0.4708  0.5379
2  Weighted avg        0.8669         0.8041                       0.7690                0.1532                   0.2310  0.7358
2019-12-27 02:20:13,898 [INFO] Dataset: Validation. Classification report below
2019-12-27 02:20:13,898 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      1.00      1.00      2331
         r2l       0.95      0.92      0.94       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.88      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 02:20:13,898 [INFO] Overall accuracy (micro avg): 0.9974995038698155
2019-12-27 02:20:14,254 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9557                       0.8835                0.0009                   0.1165  0.9112
2  Weighted avg        0.9984         0.9975                       0.9975                0.0018                   0.0025  0.9975
2019-12-27 02:20:15,696 [INFO] Dataset: Training. Classification report below
2019-12-27 02:20:15,696 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      1.00      1.00      9325
         r2l       0.96      0.96      0.96       796
         u2r       0.91      0.76      0.83        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.94      0.96    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 02:20:15,696 [INFO] Overall accuracy (micro avg): 0.9983428922979222
2019-12-27 02:20:17,317 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9983         0.9983                       0.9983                0.0004                   0.0017  0.9983
1     Macro avg        0.9993         0.9738                       0.9426                0.0006                   0.0574  0.9568
2  Weighted avg        0.9990         0.9983                       0.9983                0.0012                   0.0017  0.9983
2019-12-27 02:20:17,355 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_9/ann_depth_nsl_layers_9_results.xlsx
2019-12-27 02:20:17,355 [INFO] ================= Finished running experiment no. 9 ================= 

2019-12-27 02:20:17,358 [INFO] Created directory: results_additional_exps/ann_depth_nsl_layers_10
2019-12-27 02:20:17,358 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_nsl_layers_10/run_log.log
2019-12-27 02:20:17,358 [INFO] ================= Running experiment no. 10  ================= 

2019-12-27 02:20:17,358 [INFO] Experiment parameters given below
2019-12-27 02:20:17,358 [INFO] 
{'experiment_num': 10, 'results_dir': 'results_additional_exps/ann_depth_nsl_layers_10', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [800, 700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'ann_depth_nsl_layers_10'}
2019-12-27 02:20:17,358 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_nsl_layers_10/tf_logs_run_2019_12_27-02_20_17
2019-12-27 02:20:17,358 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-27 02:20:17,359 [INFO] Reading X, y files
2019-12-27 02:20:17,359 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-27 02:20:17,613 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-27 02:20:17,613 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-27 02:20:17,678 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 02:20:17,678 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-27 02:20:17,738 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 02:20:17,738 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-27 02:20:17,746 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-27 02:20:17,746 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-27 02:20:17,750 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 02:20:17,750 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-27 02:20:17,754 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-27 02:20:17,940 [INFO] Initializing model
2019-12-27 02:20:18,828 [INFO] _________________________________________________________________
2019-12-27 02:20:18,828 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 02:20:18,828 [INFO] =================================================================
2019-12-27 02:20:18,828 [INFO] dense_55 (Dense)             (None, 800)               98400     
2019-12-27 02:20:18,828 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] batch_normalization_46 (Batc (None, 800)               3200      
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dropout_46 (Dropout)         (None, 800)               0         
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dense_56 (Dense)             (None, 700)               560700    
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] batch_normalization_47 (Batc (None, 700)               2800      
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dropout_47 (Dropout)         (None, 700)               0         
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dense_57 (Dense)             (None, 600)               420600    
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] batch_normalization_48 (Batc (None, 600)               2400      
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dropout_48 (Dropout)         (None, 600)               0         
2019-12-27 02:20:18,829 [INFO] _________________________________________________________________
2019-12-27 02:20:18,829 [INFO] dense_58 (Dense)             (None, 500)               300500    
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] batch_normalization_49 (Batc (None, 500)               2000      
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dropout_49 (Dropout)         (None, 500)               0         
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dense_59 (Dense)             (None, 400)               200400    
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] batch_normalization_50 (Batc (None, 400)               1600      
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dropout_50 (Dropout)         (None, 400)               0         
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dense_60 (Dense)             (None, 256)               102656    
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] batch_normalization_51 (Batc (None, 256)               1024      
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dropout_51 (Dropout)         (None, 256)               0         
2019-12-27 02:20:18,830 [INFO] _________________________________________________________________
2019-12-27 02:20:18,830 [INFO] dense_61 (Dense)             (None, 128)               32896     
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] batch_normalization_52 (Batc (None, 128)               512       
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dropout_52 (Dropout)         (None, 128)               0         
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dense_62 (Dense)             (None, 64)                8256      
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] batch_normalization_53 (Batc (None, 64)                256       
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dropout_53 (Dropout)         (None, 64)                0         
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dense_63 (Dense)             (None, 32)                2080      
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] batch_normalization_54 (Batc (None, 32)                128       
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dropout_54 (Dropout)         (None, 32)                0         
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,831 [INFO] dense_64 (Dense)             (None, 16)                528       
2019-12-27 02:20:18,831 [INFO] _________________________________________________________________
2019-12-27 02:20:18,832 [INFO] batch_normalization_55 (Batc (None, 16)                64        
2019-12-27 02:20:18,832 [INFO] _________________________________________________________________
2019-12-27 02:20:18,832 [INFO] dropout_55 (Dropout)         (None, 16)                0         
2019-12-27 02:20:18,832 [INFO] _________________________________________________________________
2019-12-27 02:20:18,832 [INFO] dense_65 (Dense)             (None, 5)                 85        
2019-12-27 02:20:18,832 [INFO] =================================================================
2019-12-27 02:20:18,832 [INFO] Total params: 1,741,085
2019-12-27 02:20:18,832 [INFO] Trainable params: 1,734,093
2019-12-27 02:20:18,832 [INFO] Non-trainable params: 6,992
2019-12-27 02:20:18,832 [INFO] _________________________________________________________________
2019-12-27 02:20:18,832 [INFO] Training model
 - val_f1: 0.9974
Epoch 00189: early stopping
Train on 100778 samples, validate on 25195 samples
Epoch 1/200
 - 20s - loss: 0.1190 - val_loss: 0.0242
 - val_f1: 0.9794
Epoch 2/200
 - 18s - loss: 0.0277 - val_loss: 0.0160
 - val_f1: 0.9889
Epoch 3/200
 - 18s - loss: 0.0219 - val_loss: 0.0140
 - val_f1: 0.9891
Epoch 4/200
 - 18s - loss: 0.0190 - val_loss: 0.0118
 - val_f1: 0.9912
Epoch 5/200
 - 18s - loss: 0.0178 - val_loss: 0.0140
 - val_f1: 0.9886
Epoch 6/200
 - 18s - loss: 0.0160 - val_loss: 0.0107
 - val_f1: 0.9903
Epoch 7/200
 - 18s - loss: 0.0147 - val_loss: 0.0093
 - val_f1: 0.9929
Epoch 8/200
 - 18s - loss: 0.0142 - val_loss: 0.0091
 - val_f1: 0.9935
Epoch 9/200
 - 18s - loss: 0.0130 - val_loss: 0.0092
 - val_f1: 0.9937
Epoch 10/200
 - 18s - loss: 0.0122 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 11/200
 - 18s - loss: 0.0117 - val_loss: 0.0090
 - val_f1: 0.9934
Epoch 12/200
 - 18s - loss: 0.0112 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 13/200
 - 18s - loss: 0.0107 - val_loss: 0.0078
 - val_f1: 0.9941
Epoch 14/200
 - 18s - loss: 0.0103 - val_loss: 0.0084
 - val_f1: 0.9941
Epoch 15/200
 - 18s - loss: 0.0101 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 16/200
 - 18s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9943
Epoch 17/200
 - 18s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9941
Epoch 18/200
 - 18s - loss: 0.0096 - val_loss: 0.0074
 - val_f1: 0.9941
Epoch 19/200
 - 18s - loss: 0.0081 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 20/200
 - 18s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9949
Epoch 21/200
 - 18s - loss: 0.0077 - val_loss: 0.0059
2019-12-27 02:27:48,807 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_20.pickle
 - val_f1: 0.9954
Epoch 22/200
 - 18s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9954
Epoch 23/200
 - 18s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 24/200
 - 18s - loss: 0.0071 - val_loss: 0.0085
 - val_f1: 0.9926
Epoch 25/200
 - 18s - loss: 0.0068 - val_loss: 0.0059
 - val_f1: 0.9955
Epoch 26/200
 - 18s - loss: 0.0066 - val_loss: 0.0057
 - val_f1: 0.9956
Epoch 27/200
 - 18s - loss: 0.0067 - val_loss: 0.0058
 - val_f1: 0.9958
Epoch 28/200
 - 18s - loss: 0.0061 - val_loss: 0.0053
 - val_f1: 0.9960
Epoch 29/200
 - 18s - loss: 0.0055 - val_loss: 0.0060
 - val_f1: 0.9947
Epoch 30/200
 - 18s - loss: 0.0056 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 31/200
 - 18s - loss: 0.0059 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 32/200
 - 18s - loss: 0.0063 - val_loss: 0.0059
 - val_f1: 0.9955
Epoch 33/200
 - 18s - loss: 0.0057 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 34/200
 - 18s - loss: 0.0052 - val_loss: 0.0053
 - val_f1: 0.9960
Epoch 35/200
 - 18s - loss: 0.0054 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 36/200
 - 18s - loss: 0.0050 - val_loss: 0.0058
 - val_f1: 0.9960
Epoch 37/200
 - 18s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 38/200
 - 18s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 39/200
 - 18s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 40/200
 - 18s - loss: 0.0058 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 41/200
 - 18s - loss: 0.0049 - val_loss: 0.0045
2019-12-27 02:34:48,534 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_40.pickle
 - val_f1: 0.9967
Epoch 42/200
 - 18s - loss: 0.0046 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 43/200
 - 18s - loss: 0.0054 - val_loss: 0.0053
 - val_f1: 0.9957
Epoch 44/200
 - 18s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 45/200
 - 18s - loss: 0.0048 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 46/200
 - 18s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 47/200
 - 18s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 48/200
 - 18s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 49/200
 - 18s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9962
Epoch 50/200
 - 18s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 51/200
 - 18s - loss: 0.0046 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 52/200
 - 18s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9959
Epoch 53/200
 - 18s - loss: 0.0041 - val_loss: 0.0052
 - val_f1: 0.9961
Epoch 54/200
 - 18s - loss: 0.0042 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 55/200
 - 18s - loss: 0.0043 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 56/200
 - 18s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 57/200
 - 18s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9965
Epoch 58/200
 - 18s - loss: 0.0046 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 59/200
 - 18s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 60/200
 - 18s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 61/200
 - 18s - loss: 0.0037 - val_loss: 0.0047
2019-12-27 02:41:47,944 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_60.pickle
 - val_f1: 0.9965
Epoch 62/200
 - 18s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 63/200
 - 18s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 64/200
 - 18s - loss: 0.0036 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 65/200
 - 18s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 66/200
 - 18s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 67/200
 - 18s - loss: 0.0041 - val_loss: 0.0057
 - val_f1: 0.9967
Epoch 68/200
 - 18s - loss: 0.0037 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 69/200
 - 18s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 70/200
 - 18s - loss: 0.0037 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 71/200
 - 18s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9960
Epoch 72/200
 - 18s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 73/200
 - 18s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 74/200
 - 18s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 75/200
 - 18s - loss: 0.0039 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 76/200
 - 18s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 77/200
 - 18s - loss: 0.0035 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 78/200
 - 18s - loss: 0.0033 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 79/200
 - 18s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 80/200
 - 18s - loss: 0.0035 - val_loss: 0.0061
 - val_f1: 0.9964
Epoch 81/200
 - 18s - loss: 0.0032 - val_loss: 0.0050
2019-12-27 02:48:47,919 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_80.pickle
 - val_f1: 0.9968
Epoch 82/200
 - 18s - loss: 0.0030 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 83/200
 - 18s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 84/200
 - 18s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9969
Epoch 85/200
 - 18s - loss: 0.0036 - val_loss: 0.0043
 - val_f1: 0.9968
Epoch 86/200
 - 18s - loss: 0.0032 - val_loss: 0.0058
 - val_f1: 0.9945
Epoch 87/200
 - 18s - loss: 0.0032 - val_loss: 0.0052
 - val_f1: 0.9967
Epoch 88/200
 - 18s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9970
Epoch 89/200
 - 18s - loss: 0.0031 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 90/200
 - 18s - loss: 0.0032 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 91/200
 - 18s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 92/200
 - 18s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 93/200
 - 18s - loss: 0.0030 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 94/200
 - 18s - loss: 0.0031 - val_loss: 0.0056
 - val_f1: 0.9968
Epoch 95/200
 - 18s - loss: 0.0030 - val_loss: 0.0054
 - val_f1: 0.9958
Epoch 96/200
 - 18s - loss: 0.0030 - val_loss: 0.0053
 - val_f1: 0.9971
Epoch 97/200
 - 18s - loss: 0.0033 - val_loss: 0.0056
 - val_f1: 0.9966
Epoch 98/200
 - 18s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9962
Epoch 99/200
 - 18s - loss: 0.0029 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 100/200
 - 18s - loss: 0.0029 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 101/200
 - 18s - loss: 0.0031 - val_loss: 0.0050
2019-12-27 02:55:47,577 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_100.pickle
 - val_f1: 0.9966
Epoch 102/200
 - 18s - loss: 0.0032 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 103/200
 - 18s - loss: 0.0030 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 104/200
 - 18s - loss: 0.0029 - val_loss: 0.0053
 - val_f1: 0.9969
Epoch 105/200
 - 18s - loss: 0.0030 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 106/200
 - 18s - loss: 0.0030 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 107/200
 - 18s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9970
Epoch 108/200
 - 18s - loss: 0.0029 - val_loss: 0.0056
 - val_f1: 0.9967
Epoch 109/200
 - 18s - loss: 0.0028 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 110/200
 - 18s - loss: 0.0029 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 111/200
 - 18s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 112/200
 - 18s - loss: 0.0027 - val_loss: 0.0060
 - val_f1: 0.9967
Epoch 113/200
 - 18s - loss: 0.0031 - val_loss: 0.0056
 - val_f1: 0.9969
Epoch 114/200
 - 18s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 115/200
 - 18s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 116/200
 - 18s - loss: 0.0027 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 117/200
 - 18s - loss: 0.0028 - val_loss: 0.0050
 - val_f1: 0.9970
Epoch 118/200
 - 18s - loss: 0.0027 - val_loss: 0.0053
 - val_f1: 0.9969
Epoch 119/200
 - 18s - loss: 0.0029 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 120/200
 - 18s - loss: 0.0029 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 121/200
 - 18s - loss: 0.0032 - val_loss: 0.0057
2019-12-27 03:02:47,035 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_120.pickle
 - val_f1: 0.9968
Epoch 122/200
 - 18s - loss: 0.0028 - val_loss: 0.0048
 - val_f1: 0.9973
Epoch 123/200
 - 18s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 124/200
 - 18s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9971
Epoch 125/200
 - 18s - loss: 0.0026 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 126/200
 - 18s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9974
Epoch 127/200
 - 18s - loss: 0.0024 - val_loss: 0.0049
 - val_f1: 0.9972
Epoch 128/200
 - 18s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 129/200
 - 18s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 130/200
 - 18s - loss: 0.0027 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 131/200
 - 18s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 132/200
 - 18s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 133/200
 - 18s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 134/200
 - 18s - loss: 0.0025 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 135/200
 - 18s - loss: 0.0025 - val_loss: 0.0042
 - val_f1: 0.9970
Epoch 136/200
 - 18s - loss: 0.0026 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 137/200
 - 18s - loss: 0.0028 - val_loss: 0.0043
 - val_f1: 0.9974
Epoch 138/200
 - 18s - loss: 0.0026 - val_loss: 0.0053
 - val_f1: 0.9969
Epoch 139/200
 - 18s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 140/200
 - 18s - loss: 0.0024 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 141/200
 - 18s - loss: 0.0027 - val_loss: 0.0047
2019-12-27 03:09:46,562 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_140.pickle
 - val_f1: 0.9971
Epoch 142/200
 - 18s - loss: 0.0024 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 143/200
 - 18s - loss: 0.0026 - val_loss: 0.0049
 - val_f1: 0.9972
Epoch 144/200
 - 18s - loss: 0.0026 - val_loss: 0.0049
 - val_f1: 0.9972
Epoch 145/200
 - 18s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 146/200
 - 18s - loss: 0.0026 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 147/200
 - 18s - loss: 0.0027 - val_loss: 0.0046
 - val_f1: 0.9971
Epoch 148/200
 - 18s - loss: 0.0024 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 149/200
 - 18s - loss: 0.0023 - val_loss: 0.0058
 - val_f1: 0.9966
Epoch 150/200
 - 18s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 151/200
 - 18s - loss: 0.0028 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 152/200
 - 18s - loss: 0.0024 - val_loss: 0.0044
 - val_f1: 0.9975
Epoch 153/200
 - 18s - loss: 0.0026 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 154/200
 - 18s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9970
Epoch 155/200
 - 18s - loss: 0.0026 - val_loss: 0.0042
 - val_f1: 0.9974
Epoch 156/200
 - 18s - loss: 0.0025 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 157/200
 - 18s - loss: 0.0024 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 158/200
 - 18s - loss: 0.0024 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 159/200
 - 18s - loss: 0.0024 - val_loss: 0.0074
 - val_f1: 0.9948
Epoch 160/200
 - 18s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9972
Epoch 161/200
 - 18s - loss: 0.0024 - val_loss: 0.0039
2019-12-27 03:16:45,875 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_160.pickle
 - val_f1: 0.9970
Epoch 162/200
 - 18s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 163/200
 - 18s - loss: 0.0023 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 164/200
 - 18s - loss: 0.0023 - val_loss: 0.0045
 - val_f1: 0.9972
Epoch 165/200
 - 18s - loss: 0.0024 - val_loss: 0.0044
 - val_f1: 0.9969
Epoch 166/200
 - 18s - loss: 0.0024 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 167/200
 - 18s - loss: 0.0024 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 168/200
 - 18s - loss: 0.0023 - val_loss: 0.0046
 - val_f1: 0.9973
Epoch 169/200
 - 18s - loss: 0.0025 - val_loss: 0.0044
 - val_f1: 0.9973
Epoch 170/200
 - 18s - loss: 0.0025 - val_loss: 0.0041
 - val_f1: 0.9974
Epoch 171/200
 - 18s - loss: 0.0023 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 172/200
 - 18s - loss: 0.0022 - val_loss: 0.0044
 - val_f1: 0.9972
Epoch 173/200
 - 18s - loss: 0.0025 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 174/200
 - 18s - loss: 0.0024 - val_loss: 0.0040
 - val_f1: 0.9970
Epoch 175/200
 - 18s - loss: 0.0024 - val_loss: 0.0042
 - val_f1: 0.9968
Epoch 176/200
 - 18s - loss: 0.0023 - val_loss: 0.0040
 - val_f1: 0.9969
Epoch 177/200
 - 18s - loss: 0.0023 - val_loss: 0.0041
 - val_f1: 0.9975
Epoch 178/200
 - 18s - loss: 0.0024 - val_loss: 0.0042
 - val_f1: 0.9972
Epoch 179/200
 - 18s - loss: 0.0023 - val_loss: 0.0044
 - val_f1: 0.9975
Epoch 180/200
 - 18s - loss: 0.0024 - val_loss: 0.0043
 - val_f1: 0.9972
Epoch 181/200
 - 18s - loss: 0.0023 - val_loss: 0.0045
2019-12-27 03:23:44,676 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_nsl_layers_10/ann_model_epoch_180.pickle
 - val_f1: 0.9967
Epoch 182/200
 - 18s - loss: 0.0022 - val_loss: 0.0047
 - val_f1: 0.9971
Epoch 183/200
 - 18s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9974
Epoch 184/200
 - 18s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 185/200
 - 18s - loss: 0.0022 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 186/200
 - 18s - loss: 0.0023 - val_loss: 0.0042
 - val_f1: 0.9971
Epoch 187/200
 - 18s - loss: 0.0022 - val_loss: 0.0045
 - val_f1: 0.9971
Epoch 188/200
 - 18s - loss: 0.0022 - val_loss: 0.0046
 - val_f1: 0.9974
Epoch 189/200
 - 18s - loss: 0.0027 - val_loss: 0.0047
 - val_f1: 0.9972
Epoch 190/200
 - 18s - loss: 0.0023 - val_loss: 0.0049
 - val_f1: 0.9970
Epoch 191/200
 - 18s - loss: 0.0021 - val_loss: 0.0046
 - val_f1: 0.9976
Epoch 192/200
 - 18s - loss: 0.0023 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 193/200
 - 18s - loss: 0.0021 - val_loss: 0.0047
 - val_f1: 0.9975
Epoch 194/200
 - 18s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9973
Epoch 195/200
 - 18s - loss: 0.0021 - val_loss: 0.0042
 - val_f1: 0.9976
Epoch 196/200
 - 18s - loss: 0.0023 - val_loss: 0.0046
 - val_f1: 0.9974
Epoch 197/200
 - 18s - loss: 0.0023 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 198/200
 - 18s - loss: 0.0025 - val_loss: 0.0046
 - val_f1: 0.9972
Epoch 199/200
 - 18s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9974
Epoch 200/200
 - 18s - loss: 0.0023 - val_loss: 0.0047
2019-12-27 03:30:24,953 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 03:30:43,282 [INFO] Last epoch loss evaluation: train_loss = 0.001810, val_loss = 0.003862
2019-12-27 03:30:43,282 [INFO] Training complete. time_to_train = 4224.45 sec, 70.41 min
2019-12-27 03:30:43,328 [INFO] Model saved to results_additional_exps/ann_depth_nsl_layers_10/best_model.pickle
2019-12-27 03:30:43,330 [INFO] Training history saved to: results_additional_exps/ann_depth_nsl_layers_10/training_error_history.csv
2019-12-27 03:30:43,516 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_10/training_error_history.png
2019-12-27 03:30:43,700 [INFO] Plot saved to: results_additional_exps/ann_depth_nsl_layers_10/training_f1_history.png
2019-12-27 03:30:43,701 [INFO] Making predictions on training, validation, testing data
2019-12-27 03:31:02,123 [INFO] Evaluating predictions (results)
2019-12-27 03:31:02,382 [INFO] Dataset: Testing. Classification report below
2019-12-27 03:31:02,382 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.82      0.89      7458
      normal       0.68      0.94      0.79      9711
       probe       0.70      0.67      0.68      2421
         r2l       0.64      0.11      0.18      2421
         u2r       0.84      0.05      0.09       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.76      0.52      0.53     22544
weighted avg       0.77      0.76      0.73     22544

2019-12-27 03:31:02,382 [INFO] Overall accuracy (micro avg): 0.759847409510291
2019-12-27 03:31:02,679 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7598         0.7598                       0.7598                0.0600                   0.2402  0.7598
1     Macro avg        0.9039         0.7638                       0.5165                0.0791                   0.4835  0.5265
2  Weighted avg        0.8637         0.7745                       0.7598                0.1555                   0.2402  0.7274
2019-12-27 03:31:03,012 [INFO] Dataset: Validation. Classification report below
2019-12-27 03:31:03,012 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.89      0.95      0.92       199
         u2r       0.86      0.60      0.71        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.95      0.91      0.92     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-27 03:31:03,012 [INFO] Overall accuracy (micro avg): 0.9970629093074023
2019-12-27 03:31:03,369 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9971         0.9971                       0.9971                0.0007                   0.0029  0.9971
1     Macro avg        0.9988         0.9474                       0.9089                0.0009                   0.0911  0.9233
2  Weighted avg        0.9982         0.9971                       0.9971                0.0016                   0.0029  0.9971
2019-12-27 03:31:04,810 [INFO] Dataset: Training. Classification report below
2019-12-27 03:31:04,810 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      1.00      1.00      9325
         r2l       0.93      0.98      0.95       796
         u2r       0.92      0.79      0.85        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.95      0.96    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-27 03:31:04,810 [INFO] Overall accuracy (micro avg): 0.9982932782948659
2019-12-27 03:31:06,431 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9983         0.9983                       0.9983                0.0004                   0.0017  0.9983
1     Macro avg        0.9993         0.9680                       0.9513                0.0005                   0.0487  0.9585
2  Weighted avg        0.9990         0.9983                       0.9983                0.0010                   0.0017  0.9983
2019-12-27 03:31:06,470 [INFO] Results saved to: results_additional_exps/ann_depth_nsl_layers_10/ann_depth_nsl_layers_10_results.xlsx
2019-12-27 03:31:06,470 [INFO] ================= Finished running experiment no. 10 ================= 

2019-12-27 03:31:06,473 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_1
2019-12-27 03:31:06,473 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_1/run_log.log
2019-12-27 03:31:06,473 [INFO] ================= Running experiment no. 1  ================= 

2019-12-27 03:31:06,473 [INFO] Experiment parameters given below
2019-12-27 03:31:06,473 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_1'}
2019-12-27 03:31:06,473 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_1/tf_logs_run_2019_12_27-03_31_06
2019-12-27 03:31:06,473 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 03:31:06,474 [INFO] Reading X, y files
2019-12-27 03:31:06,474 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 03:31:10,582 [INFO] Reading complete. time_to_read=4.11 seconds
2019-12-27 03:31:10,583 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 03:31:11,983 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 03:31:11,983 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 03:31:13,385 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 03:31:13,385 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 03:31:13,590 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-27 03:31:13,590 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 03:31:13,657 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 03:31:13,657 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 03:31:13,725 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 03:31:16,874 [INFO] Initializing model
2019-12-27 03:31:16,995 [INFO] _________________________________________________________________
2019-12-27 03:31:16,995 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 03:31:16,997 [INFO] =================================================================
2019-12-27 03:31:16,997 [INFO] dense_66 (Dense)             (None, 16)                1264      
2019-12-27 03:31:16,997 [INFO] _________________________________________________________________
2019-12-27 03:31:16,997 [INFO] batch_normalization_56 (Batc (None, 16)                64        
2019-12-27 03:31:16,997 [INFO] _________________________________________________________________
2019-12-27 03:31:16,997 [INFO] dropout_56 (Dropout)         (None, 16)                0         
2019-12-27 03:31:16,997 [INFO] _________________________________________________________________
2019-12-27 03:31:16,997 [INFO] dense_67 (Dense)             (None, 12)                204       
2019-12-27 03:31:16,997 [INFO] =================================================================
2019-12-27 03:31:16,997 [INFO] Total params: 1,532
2019-12-27 03:31:16,997 [INFO] Trainable params: 1,500
2019-12-27 03:31:16,997 [INFO] Non-trainable params: 32
2019-12-27 03:31:16,997 [INFO] _________________________________________________________________
2019-12-27 03:31:16,998 [INFO] Training model
 - val_f1: 0.9973
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 18s - loss: 0.0298 - val_loss: 0.0138
 - val_f1: 0.9719
Epoch 2/200
 - 17s - loss: 0.0154 - val_loss: 0.0164
 - val_f1: 0.9365
Epoch 3/200
 - 17s - loss: 0.0126 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 4/200
 - 17s - loss: 0.0114 - val_loss: 0.0068
 - val_f1: 0.9845
Epoch 5/200
 - 17s - loss: 0.0107 - val_loss: 0.0070
 - val_f1: 0.9851
Epoch 6/200
 - 17s - loss: 0.0103 - val_loss: 0.0074
 - val_f1: 0.9844
Epoch 7/200
 - 17s - loss: 0.0099 - val_loss: 0.0072
 - val_f1: 0.9870
Epoch 8/200
 - 17s - loss: 0.0097 - val_loss: 0.0078
 - val_f1: 0.9855
Epoch 9/200
 - 17s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9813
Epoch 10/200
 - 17s - loss: 0.0092 - val_loss: 0.0056
 - val_f1: 0.9865
Epoch 11/200
 - 17s - loss: 0.0091 - val_loss: 0.0055
 - val_f1: 0.9889
Epoch 12/200
 - 17s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9610
Epoch 13/200
 - 17s - loss: 0.0089 - val_loss: 0.0065
 - val_f1: 0.9882
Epoch 14/200
 - 17s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9825
Epoch 15/200
 - 17s - loss: 0.0087 - val_loss: 0.0061
 - val_f1: 0.9858
Epoch 16/200
 - 17s - loss: 0.0087 - val_loss: 0.0059
 - val_f1: 0.9877
Epoch 17/200
 - 17s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9827
Epoch 18/200
 - 17s - loss: 0.0086 - val_loss: 0.0056
 - val_f1: 0.9883
Epoch 19/200
 - 17s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9850
Epoch 20/200
 - 17s - loss: 0.0084 - val_loss: 0.0056
 - val_f1: 0.9880
Epoch 21/200
 - 17s - loss: 0.0082 - val_loss: 0.0050
2019-12-27 03:42:57,133 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_20.pickle
 - val_f1: 0.9912
Epoch 22/200
 - 17s - loss: 0.0081 - val_loss: 0.0061
 - val_f1: 0.9897
Epoch 23/200
 - 17s - loss: 0.0081 - val_loss: 0.0049
 - val_f1: 0.9910
Epoch 24/200
 - 17s - loss: 0.0080 - val_loss: 0.0058
 - val_f1: 0.9865
Epoch 25/200
 - 17s - loss: 0.0079 - val_loss: 0.0052
 - val_f1: 0.9901
Epoch 26/200
 - 17s - loss: 0.0079 - val_loss: 0.0048
 - val_f1: 0.9912
Epoch 27/200
 - 17s - loss: 0.0079 - val_loss: 0.0048
 - val_f1: 0.9908
Epoch 28/200
 - 17s - loss: 0.0078 - val_loss: 0.0067
 - val_f1: 0.9824
Epoch 29/200
 - 17s - loss: 0.0078 - val_loss: 0.0047
 - val_f1: 0.9901
Epoch 30/200
 - 17s - loss: 0.0077 - val_loss: 0.0051
 - val_f1: 0.9900
Epoch 31/200
 - 17s - loss: 0.0077 - val_loss: 0.0051
 - val_f1: 0.9894
Epoch 32/200
 - 17s - loss: 0.0076 - val_loss: 0.0045
 - val_f1: 0.9921
Epoch 33/200
 - 17s - loss: 0.0075 - val_loss: 0.0062
 - val_f1: 0.9870
Epoch 34/200
 - 17s - loss: 0.0075 - val_loss: 0.0046
 - val_f1: 0.9916
Epoch 35/200
 - 17s - loss: 0.0075 - val_loss: 0.0047
 - val_f1: 0.9909
Epoch 36/200
 - 17s - loss: 0.0074 - val_loss: 0.0061
 - val_f1: 0.9866
Epoch 37/200
 - 17s - loss: 0.0074 - val_loss: 0.0045
 - val_f1: 0.9921
Epoch 38/200
 - 17s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9909
Epoch 39/200
 - 17s - loss: 0.0073 - val_loss: 0.0049
 - val_f1: 0.9920
Epoch 40/200
 - 17s - loss: 0.0072 - val_loss: 0.0048
 - val_f1: 0.9918
Epoch 41/200
 - 17s - loss: 0.0072 - val_loss: 0.0051
2019-12-27 03:54:08,191 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_40.pickle
 - val_f1: 0.9911
Epoch 42/200
 - 17s - loss: 0.0072 - val_loss: 0.0050
 - val_f1: 0.9894
Epoch 43/200
 - 17s - loss: 0.0071 - val_loss: 0.0059
 - val_f1: 0.9884
Epoch 44/200
 - 17s - loss: 0.0071 - val_loss: 0.0074
 - val_f1: 0.9871
Epoch 45/200
 - 17s - loss: 0.0071 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 46/200
 - 17s - loss: 0.0070 - val_loss: 0.0063
 - val_f1: 0.9902
Epoch 47/200
 - 17s - loss: 0.0071 - val_loss: 0.0061
 - val_f1: 0.9871
Epoch 48/200
 - 17s - loss: 0.0070 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 49/200
 - 17s - loss: 0.0071 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 50/200
 - 17s - loss: 0.0070 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 51/200
 - 17s - loss: 0.0071 - val_loss: 0.0051
 - val_f1: 0.9915
Epoch 52/200
 - 17s - loss: 0.0070 - val_loss: 0.0050
 - val_f1: 0.9913
Epoch 53/200
 - 17s - loss: 0.0069 - val_loss: 0.0047
 - val_f1: 0.9909
Epoch 54/200
 - 17s - loss: 0.0069 - val_loss: 0.0043
 - val_f1: 0.9922
Epoch 55/200
 - 17s - loss: 0.0069 - val_loss: 0.0049
 - val_f1: 0.9913
Epoch 56/200
 - 17s - loss: 0.0069 - val_loss: 0.0051
 - val_f1: 0.9914
Epoch 57/200
 - 17s - loss: 0.0069 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 58/200
 - 17s - loss: 0.0069 - val_loss: 0.0043
 - val_f1: 0.9919
Epoch 59/200
 - 17s - loss: 0.0069 - val_loss: 0.0058
 - val_f1: 0.9889
Epoch 60/200
 - 17s - loss: 0.0068 - val_loss: 0.0049
 - val_f1: 0.9908
Epoch 61/200
 - 17s - loss: 0.0068 - val_loss: 0.0049
2019-12-27 04:05:19,752 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_60.pickle
 - val_f1: 0.9923
Epoch 62/200
 - 17s - loss: 0.0068 - val_loss: 0.0043
 - val_f1: 0.9922
Epoch 63/200
 - 17s - loss: 0.0068 - val_loss: 0.0049
 - val_f1: 0.9903
Epoch 64/200
 - 17s - loss: 0.0068 - val_loss: 0.0050
 - val_f1: 0.9906
Epoch 65/200
 - 17s - loss: 0.0069 - val_loss: 0.0047
 - val_f1: 0.9921
Epoch 66/200
 - 17s - loss: 0.0070 - val_loss: 0.0049
 - val_f1: 0.9895
Epoch 67/200
 - 17s - loss: 0.0070 - val_loss: 0.0048
 - val_f1: 0.9894
Epoch 68/200
 - 17s - loss: 0.0070 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 69/200
 - 17s - loss: 0.0069 - val_loss: 0.0109
 - val_f1: 0.9694
Epoch 70/200
 - 17s - loss: 0.0069 - val_loss: 0.0052
 - val_f1: 0.9912
Epoch 71/200
 - 17s - loss: 0.0068 - val_loss: 0.0043
 - val_f1: 0.9920
Epoch 72/200
 - 17s - loss: 0.0069 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 73/200
 - 17s - loss: 0.0069 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 74/200
 - 17s - loss: 0.0068 - val_loss: 0.0046
 - val_f1: 0.9913
Epoch 75/200
 - 17s - loss: 0.0068 - val_loss: 0.0046
 - val_f1: 0.9922
Epoch 76/200
 - 17s - loss: 0.0069 - val_loss: 0.0046
 - val_f1: 0.9922
Epoch 77/200
 - 17s - loss: 0.0069 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 78/200
 - 17s - loss: 0.0068 - val_loss: 0.0047
 - val_f1: 0.9919
Epoch 79/200
 - 17s - loss: 0.0068 - val_loss: 0.0053
 - val_f1: 0.9875
Epoch 80/200
 - 17s - loss: 0.0068 - val_loss: 0.0040
 - val_f1: 0.9927
Epoch 81/200
 - 17s - loss: 0.0068 - val_loss: 0.0045
2019-12-27 04:16:30,975 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_80.pickle
 - val_f1: 0.9899
Epoch 82/200
 - 17s - loss: 0.0068 - val_loss: 0.0053
 - val_f1: 0.9887
Epoch 83/200
 - 17s - loss: 0.0068 - val_loss: 0.0047
 - val_f1: 0.9905
Epoch 84/200
 - 17s - loss: 0.0068 - val_loss: 0.0046
 - val_f1: 0.9912
Epoch 85/200
 - 17s - loss: 0.0067 - val_loss: 0.0053
 - val_f1: 0.9923
Epoch 86/200
 - 17s - loss: 0.0068 - val_loss: 0.0064
 - val_f1: 0.9875
Epoch 87/200
 - 17s - loss: 0.0068 - val_loss: 0.0045
 - val_f1: 0.9902
Epoch 88/200
 - 17s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9910
Epoch 89/200
 - 17s - loss: 0.0067 - val_loss: 0.0057
 - val_f1: 0.9883
Epoch 90/200
 - 17s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 91/200
 - 17s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 92/200
 - 17s - loss: 0.0067 - val_loss: 0.0043
 - val_f1: 0.9921
Epoch 93/200
 - 17s - loss: 0.0067 - val_loss: 0.0058
 - val_f1: 0.9874
Epoch 94/200
 - 17s - loss: 0.0067 - val_loss: 0.0054
 - val_f1: 0.9897
Epoch 95/200
 - 17s - loss: 0.0067 - val_loss: 0.0045
 - val_f1: 0.9925
Epoch 96/200
 - 17s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9917
Epoch 97/200
 - 17s - loss: 0.0067 - val_loss: 0.0066
 - val_f1: 0.9866
Epoch 98/200
 - 17s - loss: 0.0066 - val_loss: 0.0051
 - val_f1: 0.9912
Epoch 99/200
 - 17s - loss: 0.0067 - val_loss: 0.0080
 - val_f1: 0.9842
Epoch 100/200
 - 17s - loss: 0.0066 - val_loss: 0.0044
 - val_f1: 0.9916
Epoch 101/200
 - 17s - loss: 0.0067 - val_loss: 0.0045
2019-12-27 04:27:41,962 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_100.pickle
 - val_f1: 0.9917
Epoch 102/200
 - 17s - loss: 0.0066 - val_loss: 0.0040
 - val_f1: 0.9929
Epoch 103/200
 - 17s - loss: 0.0066 - val_loss: 0.0046
 - val_f1: 0.9922
Epoch 104/200
 - 17s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9898
Epoch 105/200
 - 17s - loss: 0.0067 - val_loss: 0.0047
 - val_f1: 0.9909
Epoch 106/200
 - 17s - loss: 0.0067 - val_loss: 0.0041
 - val_f1: 0.9923
Epoch 107/200
 - 17s - loss: 0.0066 - val_loss: 0.0043
2019-12-27 04:31:19,654 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 04:32:30,025 [INFO] Last epoch loss evaluation: train_loss = 0.003932, val_loss = 0.003965
2019-12-27 04:32:30,025 [INFO] Training complete. time_to_train = 3673.03 sec, 61.22 min
2019-12-27 04:32:30,031 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_1/best_model.pickle
2019-12-27 04:32:30,035 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_1/training_error_history.csv
/home/sunanda/test/ml_env/lib/python3.6/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-27 04:32:30,216 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_1/training_error_history.png
2019-12-27 04:32:30,380 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_1/training_f1_history.png
2019-12-27 04:32:30,380 [INFO] Making predictions on training, validation, testing data
2019-12-27 04:33:53,303 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-27 04:34:03,440 [INFO] Dataset: Testing. Classification report below
2019-12-27 04:34:03,440 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.00      0.00      0.00       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.95      0.97      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.85      0.39      0.53      1100
         DoS slowloris       0.95      0.86      0.90      1159
           FTP-Patator       0.98      0.98      0.98      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.96      0.96      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.72      0.68      0.69    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 04:34:03,440 [INFO] Overall accuracy (micro avg): 0.9924765100908477
/home/sunanda/test/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-27 04:34:14,977 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9925         0.9925                       0.9925                0.0007                   0.0075  0.9925
1     Macro avg        0.9987         0.7242                       0.6768                0.0020                   0.3232  0.6929
2  Weighted avg        0.9939         0.9909                       0.9925                0.0165                   0.0075  0.9915
2019-12-27 04:34:25,273 [INFO] Dataset: Validation. Classification report below
2019-12-27 04:34:25,273 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.00      0.00      0.00       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.94      0.97      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.86      0.40      0.55      1099
         DoS slowloris       0.96      0.87      0.91      1159
           FTP-Patator       0.98      0.97      0.98      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.96      0.96      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.73      0.68      0.69    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 04:34:25,274 [INFO] Overall accuracy (micro avg): 0.9926462527538978
2019-12-27 04:34:36,954 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9926         0.9926                       0.9926                0.0007                   0.0074  0.9926
1     Macro avg        0.9988         0.7262                       0.6772                0.0020                   0.3228  0.6943
2  Weighted avg        0.9940         0.9911                       0.9926                0.0162                   0.0074  0.9917
2019-12-27 04:35:10,956 [INFO] Dataset: Training. Classification report below
2019-12-27 04:35:10,956 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.00      0.00      0.00      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.95      0.97      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.85      0.39      0.53      3300
         DoS slowloris       0.96      0.88      0.92      3478
           FTP-Patator       0.99      0.98      0.98      4761
              PortScan       0.99      0.99      0.99     95282
           SSH-Patator       0.97      0.96      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.73      0.68      0.69   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-27 04:35:10,956 [INFO] Overall accuracy (micro avg): 0.9926197217631568
2019-12-27 04:35:49,554 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9926         0.9926                       0.9926                0.0007                   0.0074  0.9926
1     Macro avg        0.9988         0.7257                       0.6776                0.0020                   0.3224  0.6941
2  Weighted avg        0.9940         0.9911                       0.9926                0.0162                   0.0074  0.9917
2019-12-27 04:35:49,606 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_1/ann_depth_ids17_layers_1_results.xlsx
2019-12-27 04:35:49,610 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-27 04:35:49,675 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_2
2019-12-27 04:35:49,675 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_2/run_log.log
2019-12-27 04:35:49,675 [INFO] ================= Running experiment no. 2  ================= 

2019-12-27 04:35:49,675 [INFO] Experiment parameters given below
2019-12-27 04:35:49,675 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_2'}
2019-12-27 04:35:49,675 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_2/tf_logs_run_2019_12_27-04_35_49
2019-12-27 04:35:49,675 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 04:35:49,676 [INFO] Reading X, y files
2019-12-27 04:35:49,676 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 04:35:53,790 [INFO] Reading complete. time_to_read=4.11 seconds
2019-12-27 04:35:53,790 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 04:35:55,189 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 04:35:55,189 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 04:35:56,585 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 04:35:56,585 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 04:35:56,779 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 04:35:56,779 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 04:35:56,847 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 04:35:56,847 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 04:35:56,915 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 04:36:00,068 [INFO] Initializing model
2019-12-27 04:36:00,277 [INFO] _________________________________________________________________
2019-12-27 04:36:00,277 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 04:36:00,279 [INFO] =================================================================
2019-12-27 04:36:00,279 [INFO] dense_68 (Dense)             (None, 32)                2528      
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,279 [INFO] batch_normalization_57 (Batc (None, 32)                128       
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,279 [INFO] dropout_57 (Dropout)         (None, 32)                0         
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,279 [INFO] dense_69 (Dense)             (None, 16)                528       
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,279 [INFO] batch_normalization_58 (Batc (None, 16)                64        
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,279 [INFO] dropout_58 (Dropout)         (None, 16)                0         
2019-12-27 04:36:00,279 [INFO] _________________________________________________________________
2019-12-27 04:36:00,280 [INFO] dense_70 (Dense)             (None, 12)                204       
2019-12-27 04:36:00,280 [INFO] =================================================================
2019-12-27 04:36:00,280 [INFO] Total params: 3,452
2019-12-27 04:36:00,280 [INFO] Trainable params: 3,356
2019-12-27 04:36:00,280 [INFO] Non-trainable params: 96
2019-12-27 04:36:00,280 [INFO] _________________________________________________________________
2019-12-27 04:36:00,280 [INFO] Training model
 - val_f1: 0.9919
Epoch 00107: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 22s - loss: 0.0266 - val_loss: 0.0104
 - val_f1: 0.9682
Epoch 2/200
 - 21s - loss: 0.0114 - val_loss: 0.0152
 - val_f1: 0.9539
Epoch 3/200
 - 21s - loss: 0.0096 - val_loss: 0.0092
 - val_f1: 0.9761
Epoch 4/200
 - 21s - loss: 0.0087 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 5/200
 - 21s - loss: 0.0082 - val_loss: 0.0064
 - val_f1: 0.9853
Epoch 6/200
 - 21s - loss: 0.0081 - val_loss: 0.0041
 - val_f1: 0.9922
Epoch 7/200
 - 21s - loss: 0.0075 - val_loss: 0.0044
 - val_f1: 0.9887
Epoch 8/200
 - 21s - loss: 0.0073 - val_loss: 0.0055
 - val_f1: 0.9852
Epoch 9/200
 - 21s - loss: 0.0070 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 10/200
 - 21s - loss: 0.0071 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 11/200
 - 21s - loss: 0.0067 - val_loss: 0.0046
 - val_f1: 0.9904
Epoch 12/200
 - 21s - loss: 0.0070 - val_loss: 0.0048
 - val_f1: 0.9895
Epoch 13/200
 - 21s - loss: 0.0074 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 14/200
 - 21s - loss: 0.0083 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 15/200
 - 21s - loss: 0.0080 - val_loss: 0.0058
 - val_f1: 0.9882
Epoch 16/200
 - 21s - loss: 0.0076 - val_loss: 0.0045
 - val_f1: 0.9896
Epoch 17/200
 - 21s - loss: 0.0071 - val_loss: 0.0036
 - val_f1: 0.9928
Epoch 18/200
 - 21s - loss: 0.0073 - val_loss: 0.0045
 - val_f1: 0.9910
Epoch 19/200
 - 21s - loss: 0.0068 - val_loss: 0.0038
 - val_f1: 0.9906
Epoch 20/200
 - 21s - loss: 0.0065 - val_loss: 0.0041
 - val_f1: 0.9898
Epoch 21/200
 - 21s - loss: 0.0067 - val_loss: 0.0034
2019-12-27 04:48:53,325 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_20.pickle
 - val_f1: 0.9929
Epoch 22/200
 - 21s - loss: 0.0068 - val_loss: 0.0040
 - val_f1: 0.9902
Epoch 23/200
 - 21s - loss: 0.0071 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 24/200
 - 21s - loss: 0.0074 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 25/200
 - 21s - loss: 0.0068 - val_loss: 0.0091
 - val_f1: 0.9792
Epoch 26/200
 - 21s - loss: 0.0070 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 27/200
 - 21s - loss: 0.0068 - val_loss: 0.0037
 - val_f1: 0.9904
Epoch 28/200
 - 21s - loss: 0.0066 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 29/200
 - 21s - loss: 0.0064 - val_loss: 0.0037
 - val_f1: 0.9906
Epoch 30/200
 - 21s - loss: 0.0072 - val_loss: 0.0042
 - val_f1: 0.9897
Epoch 31/200
 - 21s - loss: 0.0068 - val_loss: 0.0042
 - val_f1: 0.9917
Epoch 32/200
 - 21s - loss: 0.0068 - val_loss: 0.0045
 - val_f1: 0.9894
Epoch 33/200
 - 21s - loss: 0.0071 - val_loss: 0.0049
 - val_f1: 0.9894
Epoch 34/200
 - 21s - loss: 0.0068 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 35/200
 - 21s - loss: 0.0068 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 36/200
 - 21s - loss: 0.0069 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 37/200
 - 21s - loss: 0.0071 - val_loss: 0.0041
 - val_f1: 0.9886
Epoch 38/200
 - 21s - loss: 0.0067 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 39/200
 - 21s - loss: 0.0067 - val_loss: 0.0145
 - val_f1: 0.9686
Epoch 40/200
 - 21s - loss: 0.0068 - val_loss: 0.0040
 - val_f1: 0.9922
Epoch 41/200
 - 21s - loss: 0.0075 - val_loss: 0.0042
2019-12-27 05:01:13,930 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_40.pickle
 - val_f1: 0.9902
Epoch 42/200
 - 21s - loss: 0.0069 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 43/200
 - 21s - loss: 0.0068 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 44/200
 - 21s - loss: 0.0066 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 45/200
 - 21s - loss: 0.0062 - val_loss: 0.0034
 - val_f1: 0.9913
Epoch 46/200
 - 21s - loss: 0.0064 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 47/200
 - 21s - loss: 0.0063 - val_loss: 0.0037
 - val_f1: 0.9915
Epoch 48/200
 - 21s - loss: 0.0067 - val_loss: 0.0057
 - val_f1: 0.9862
Epoch 49/200
 - 21s - loss: 0.0065 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 50/200
 - 21s - loss: 0.0063 - val_loss: 0.0045
 - val_f1: 0.9896
Epoch 51/200
 - 21s - loss: 0.0072 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 52/200
 - 21s - loss: 0.0084 - val_loss: 0.0040
 - val_f1: 0.9905
Epoch 53/200
 - 21s - loss: 0.0071 - val_loss: 0.0039
 - val_f1: 0.9912
Epoch 54/200
 - 21s - loss: 0.0068 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 55/200
 - 21s - loss: 0.0066 - val_loss: 0.0036
 - val_f1: 0.9910
Epoch 56/200
 - 21s - loss: 0.0064 - val_loss: 0.0039
 - val_f1: 0.9912
Epoch 57/200
 - 21s - loss: 0.0068 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 58/200
 - 21s - loss: 0.0071 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 59/200
 - 21s - loss: 0.0063 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 60/200
 - 21s - loss: 0.0062 - val_loss: 0.0032
 - val_f1: 0.9914
Epoch 61/200
 - 21s - loss: 0.0062 - val_loss: 0.0037
2019-12-27 05:13:35,206 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_60.pickle
 - val_f1: 0.9912
Epoch 62/200
 - 21s - loss: 0.0064 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 63/200
 - 21s - loss: 0.0062 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 64/200
 - 21s - loss: 0.0065 - val_loss: 0.0034
 - val_f1: 0.9910
Epoch 65/200
 - 21s - loss: 0.0062 - val_loss: 0.0112
 - val_f1: 0.9691
Epoch 66/200
 - 21s - loss: 0.0063 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 67/200
 - 21s - loss: 0.0062 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 68/200
 - 21s - loss: 0.0061 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 69/200
 - 21s - loss: 0.0064 - val_loss: 0.0036
 - val_f1: 0.9915
Epoch 70/200
 - 21s - loss: 0.0060 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 71/200
 - 21s - loss: 0.0061 - val_loss: 0.0042
 - val_f1: 0.9912
Epoch 72/200
 - 21s - loss: 0.0061 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 73/200
 - 21s - loss: 0.0061 - val_loss: 0.0037
 - val_f1: 0.9897
Epoch 74/200
 - 21s - loss: 0.0060 - val_loss: 0.0042
 - val_f1: 0.9897
Epoch 75/200
 - 21s - loss: 0.0057 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 76/200
 - 21s - loss: 0.0056 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 77/200
 - 21s - loss: 0.0061 - val_loss: 0.0041
 - val_f1: 0.9900
Epoch 78/200
 - 21s - loss: 0.0056 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 79/200
 - 21s - loss: 0.0061 - val_loss: 0.0052
 - val_f1: 0.9846
Epoch 80/200
 - 21s - loss: 0.0054 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 81/200
 - 21s - loss: 0.0054 - val_loss: 0.0031
2019-12-27 05:25:57,267 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_80.pickle
 - val_f1: 0.9934
Epoch 82/200
 - 21s - loss: 0.0057 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 83/200
 - 21s - loss: 0.0054 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 84/200
 - 21s - loss: 0.0058 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 85/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 86/200
 - 21s - loss: 0.0059 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 87/200
 - 21s - loss: 0.0057 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 88/200
 - 21s - loss: 0.0059 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 89/200
 - 21s - loss: 0.0066 - val_loss: 0.0033
 - val_f1: 0.9912
Epoch 90/200
 - 21s - loss: 0.0055 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 91/200
 - 21s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 92/200
 - 21s - loss: 0.0054 - val_loss: 0.0035
 - val_f1: 0.9902
Epoch 93/200
 - 21s - loss: 0.0054 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 94/200
 - 21s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9902
Epoch 95/200
 - 21s - loss: 0.0056 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 96/200
 - 21s - loss: 0.0054 - val_loss: 0.0034
 - val_f1: 0.9905
Epoch 97/200
 - 21s - loss: 0.0053 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 98/200
 - 21s - loss: 0.0052 - val_loss: 0.0031
 - val_f1: 0.9917
Epoch 99/200
 - 21s - loss: 0.0056 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 100/200
 - 21s - loss: 0.0054 - val_loss: 0.0035
 - val_f1: 0.9914
Epoch 101/200
 - 21s - loss: 0.0055 - val_loss: 0.0033
2019-12-27 05:38:19,242 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_100.pickle
 - val_f1: 0.9926
Epoch 102/200
 - 21s - loss: 0.0056 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 103/200
 - 21s - loss: 0.0057 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 104/200
 - 21s - loss: 0.0052 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 105/200
 - 21s - loss: 0.0053 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 106/200
 - 21s - loss: 0.0057 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 107/200
 - 21s - loss: 0.0052 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 108/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 109/200
 - 21s - loss: 0.0055 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 110/200
 - 21s - loss: 0.0055 - val_loss: 0.0035
 - val_f1: 0.9900
Epoch 111/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 112/200
 - 21s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 113/200
 - 21s - loss: 0.0055 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 114/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 115/200
 - 21s - loss: 0.0054 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 116/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 117/200
 - 21s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 118/200
 - 21s - loss: 0.0053 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 119/200
 - 21s - loss: 0.0057 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 120/200
 - 21s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 121/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
2019-12-27 05:50:40,573 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_120.pickle
 - val_f1: 0.9935
Epoch 122/200
 - 21s - loss: 0.0055 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 123/200
 - 21s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9825
Epoch 124/200
 - 21s - loss: 0.0054 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 125/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 126/200
 - 21s - loss: 0.0055 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 127/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 128/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 129/200
 - 21s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 130/200
 - 21s - loss: 0.0052 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 131/200
 - 21s - loss: 0.0052 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 132/200
 - 21s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9825
Epoch 133/200
 - 21s - loss: 0.0058 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 134/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 135/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 136/200
 - 21s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 137/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 138/200
 - 21s - loss: 0.0055 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 139/200
 - 21s - loss: 0.0055 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 140/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 141/200
 - 21s - loss: 0.0052 - val_loss: 0.0032
2019-12-27 06:03:02,929 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_140.pickle
 - val_f1: 0.9921
Epoch 142/200
 - 21s - loss: 0.0052 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 143/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 144/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9913
Epoch 145/200
 - 21s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9914
Epoch 146/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 147/200
 - 21s - loss: 0.0053 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 148/200
 - 21s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9895
Epoch 149/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 150/200
 - 21s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 151/200
 - 21s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 152/200
 - 21s - loss: 0.0064 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 153/200
 - 21s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 154/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 155/200
 - 21s - loss: 0.0051 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 156/200
 - 21s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 157/200
 - 21s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 158/200
 - 21s - loss: 0.0051 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 159/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 160/200
 - 21s - loss: 0.0053 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 161/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
2019-12-27 06:15:23,632 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_160.pickle
 - val_f1: 0.9926
Epoch 162/200
 - 21s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 163/200
 - 21s - loss: 0.0050 - val_loss: 0.0057
 - val_f1: 0.9814
Epoch 164/200
 - 21s - loss: 0.0050 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 165/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9917
Epoch 166/200
 - 21s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 167/200
 - 21s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9912
Epoch 168/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 169/200
 - 21s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 170/200
 - 21s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 171/200
 - 21s - loss: 0.0051 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 172/200
 - 21s - loss: 0.0052 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 173/200
 - 21s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 174/200
 - 21s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 175/200
 - 21s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 176/200
 - 21s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 177/200
 - 21s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 178/200
 - 21s - loss: 0.0049 - val_loss: 0.0069
 - val_f1: 0.9852
Epoch 179/200
 - 21s - loss: 0.0050 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 180/200
 - 21s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9915
Epoch 181/200
 - 21s - loss: 0.0053 - val_loss: 0.0029
2019-12-27 06:27:44,270 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_180.pickle
 - val_f1: 0.9938
Epoch 182/200
 - 21s - loss: 0.0053 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 183/200
 - 21s - loss: 0.0052 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 184/200
 - 21s - loss: 0.0061 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 185/200
 - 21s - loss: 0.0050 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 186/200
 - 21s - loss: 0.0050 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 187/200
 - 21s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 188/200
 - 21s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 189/200
 - 21s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 190/200
 - 21s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 191/200
 - 21s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9906
Epoch 192/200
 - 21s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 193/200
 - 21s - loss: 0.0049 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 194/200
 - 21s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9900
Epoch 195/200
 - 21s - loss: 0.0055 - val_loss: 0.0030
 - val_f1: 0.9917
Epoch 196/200
 - 21s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 197/200
 - 21s - loss: 0.0048 - val_loss: 0.0031
 - val_f1: 0.9917
Epoch 198/200
 - 21s - loss: 0.0053 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 199/200
 - 21s - loss: 0.0048 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 200/200
 - 21s - loss: 0.0047 - val_loss: 0.0028
2019-12-27 06:39:44,937 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 06:40:57,691 [INFO] Last epoch loss evaluation: train_loss = 0.002808, val_loss = 0.002814
2019-12-27 06:40:57,691 [INFO] Training complete. time_to_train = 7497.41 sec, 124.96 min
2019-12-27 06:40:57,700 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_2/best_model.pickle
2019-12-27 06:40:57,703 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_2/training_error_history.csv
2019-12-27 06:40:57,889 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_2/training_error_history.png
2019-12-27 06:40:58,078 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_2/training_f1_history.png
2019-12-27 06:40:58,078 [INFO] Making predictions on training, validation, testing data
2019-12-27 06:42:20,123 [INFO] Evaluating predictions (results)
2019-12-27 06:42:30,255 [INFO] Dataset: Testing. Classification report below
2019-12-27 06:42:30,255 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.86      0.02      0.03       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.99      0.98      0.98     46025
      DoS Slowhttptest       0.88      0.96      0.92      1100
         DoS slowloris       0.96      0.94      0.95      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.80      0.74      0.73    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 06:42:30,255 [INFO] Overall accuracy (micro avg): 0.9944868997563485
2019-12-27 06:42:41,786 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9945         0.9945                       0.9945                0.0005                   0.0055  0.9945
1     Macro avg        0.9991         0.8004                       0.7358                0.0017                   0.2642  0.7341
2  Weighted avg        0.9955         0.9936                       0.9945                0.0150                   0.0055  0.9938
2019-12-27 06:42:52,096 [INFO] Dataset: Validation. Classification report below
2019-12-27 06:42:52,096 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.86      0.02      0.03       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.98      2059
              DoS Hulk       0.99      0.98      0.98     46025
      DoS Slowhttptest       0.88      0.95      0.91      1099
         DoS slowloris       0.96      0.94      0.95      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.80      0.73      0.73    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 06:42:52,096 [INFO] Overall accuracy (micro avg): 0.9947450500564041
2019-12-27 06:43:03,798 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8000                       0.7336                0.0016                   0.2664  0.7328
2  Weighted avg        0.9957         0.9939                       0.9947                0.0143                   0.0053  0.9940
2019-12-27 06:43:37,876 [INFO] Dataset: Training. Classification report below
2019-12-27 06:43:37,876 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.90      0.01      0.02      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.99      0.98      0.98    138074
      DoS Slowhttptest       0.90      0.95      0.92      3300
         DoS slowloris       0.96      0.95      0.96      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.81      0.74      0.73   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-27 06:43:37,876 [INFO] Overall accuracy (micro avg): 0.9946631193551657
2019-12-27 06:44:16,587 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8065                       0.7356                0.0017                   0.2644  0.7344
2  Weighted avg        0.9956         0.9938                       0.9947                0.0147                   0.0053  0.9939
2019-12-27 06:44:16,638 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_2/ann_depth_ids17_layers_2_results.xlsx
2019-12-27 06:44:16,642 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-27 06:44:16,708 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_3
2019-12-27 06:44:16,708 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_3/run_log.log
2019-12-27 06:44:16,708 [INFO] ================= Running experiment no. 3  ================= 

2019-12-27 06:44:16,708 [INFO] Experiment parameters given below
2019-12-27 06:44:16,708 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_3'}
2019-12-27 06:44:16,708 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_3/tf_logs_run_2019_12_27-06_44_16
2019-12-27 06:44:16,708 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 06:44:16,709 [INFO] Reading X, y files
2019-12-27 06:44:16,709 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 06:44:20,795 [INFO] Reading complete. time_to_read=4.09 seconds
2019-12-27 06:44:20,795 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 06:44:22,193 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 06:44:22,193 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 06:44:23,592 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 06:44:23,592 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 06:44:23,786 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 06:44:23,786 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 06:44:23,854 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 06:44:23,854 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 06:44:23,922 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 06:44:27,082 [INFO] Initializing model
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 06:44:27,383 [INFO] =================================================================
2019-12-27 06:44:27,383 [INFO] dense_71 (Dense)             (None, 64)                5056      
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] batch_normalization_59 (Batc (None, 64)                256       
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] dropout_59 (Dropout)         (None, 64)                0         
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] dense_72 (Dense)             (None, 32)                2080      
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] batch_normalization_60 (Batc (None, 32)                128       
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] dropout_60 (Dropout)         (None, 32)                0         
2019-12-27 06:44:27,383 [INFO] _________________________________________________________________
2019-12-27 06:44:27,383 [INFO] dense_73 (Dense)             (None, 16)                528       
2019-12-27 06:44:27,384 [INFO] _________________________________________________________________
2019-12-27 06:44:27,384 [INFO] batch_normalization_61 (Batc (None, 16)                64        
2019-12-27 06:44:27,384 [INFO] _________________________________________________________________
2019-12-27 06:44:27,384 [INFO] dropout_61 (Dropout)         (None, 16)                0         
2019-12-27 06:44:27,384 [INFO] _________________________________________________________________
2019-12-27 06:44:27,384 [INFO] dense_74 (Dense)             (None, 12)                204       
2019-12-27 06:44:27,384 [INFO] =================================================================
2019-12-27 06:44:27,384 [INFO] Total params: 8,316
2019-12-27 06:44:27,384 [INFO] Trainable params: 8,092
2019-12-27 06:44:27,384 [INFO] Non-trainable params: 224
2019-12-27 06:44:27,384 [INFO] _________________________________________________________________
2019-12-27 06:44:27,384 [INFO] Training model
 - val_f1: 0.9938
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 29s - loss: 0.0257 - val_loss: 0.0184
 - val_f1: 0.9369
Epoch 2/200
 - 27s - loss: 0.0109 - val_loss: 0.0101
 - val_f1: 0.9749
Epoch 3/200
 - 27s - loss: 0.0085 - val_loss: 0.0047
 - val_f1: 0.9883
Epoch 4/200
 - 27s - loss: 0.0078 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 5/200
 - 27s - loss: 0.0076 - val_loss: 0.0048
 - val_f1: 0.9883
Epoch 6/200
 - 27s - loss: 0.0079 - val_loss: 0.0064
 - val_f1: 0.9870
Epoch 7/200
 - 27s - loss: 0.0079 - val_loss: 0.0042
 - val_f1: 0.9915
Epoch 8/200
 - 27s - loss: 0.0067 - val_loss: 0.0042
 - val_f1: 0.9894
Epoch 9/200
 - 27s - loss: 0.0072 - val_loss: 0.0070
 - val_f1: 0.9835
Epoch 10/200
 - 27s - loss: 0.0076 - val_loss: 0.0068
 - val_f1: 0.9818
Epoch 11/200
 - 27s - loss: 0.0069 - val_loss: 0.0041
 - val_f1: 0.9904
Epoch 12/200
 - 27s - loss: 0.0065 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 13/200
 - 27s - loss: 0.0066 - val_loss: 0.0045
 - val_f1: 0.9900
Epoch 14/200
 - 27s - loss: 0.0061 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 15/200
 - 27s - loss: 0.0061 - val_loss: 0.0040
 - val_f1: 0.9907
Epoch 16/200
 - 27s - loss: 0.0056 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 17/200
 - 27s - loss: 0.0053 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 18/200
 - 27s - loss: 0.0067 - val_loss: 0.0054
 - val_f1: 0.9868
Epoch 19/200
 - 27s - loss: 0.0067 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 20/200
 - 27s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9894
Epoch 21/200
 - 27s - loss: 0.0056 - val_loss: 0.0047
2019-12-27 07:00:00,658 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_20.pickle
 - val_f1: 0.9872
Epoch 22/200
 - 27s - loss: 0.0056 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 23/200
 - 27s - loss: 0.0053 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 24/200
 - 27s - loss: 0.0053 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 25/200
 - 27s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 26/200
 - 27s - loss: 0.0053 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 27/200
 - 27s - loss: 0.0053 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 28/200
 - 27s - loss: 0.0052 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 29/200
 - 27s - loss: 0.0054 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 30/200
 - 27s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 31/200
 - 27s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 32/200
 - 27s - loss: 0.0054 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 33/200
 - 27s - loss: 0.0053 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 34/200
 - 27s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9896
Epoch 35/200
 - 28s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 36/200
 - 27s - loss: 0.0050 - val_loss: 0.0033
 - val_f1: 0.9914
Epoch 37/200
 - 27s - loss: 0.0051 - val_loss: 0.0041
 - val_f1: 0.9905
Epoch 38/200
 - 27s - loss: 0.0050 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 39/200
 - 27s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9909
Epoch 40/200
 - 27s - loss: 0.0054 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 41/200
 - 27s - loss: 0.0050 - val_loss: 0.0029
2019-12-27 07:14:55,540 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_40.pickle
 - val_f1: 0.9937
Epoch 42/200
 - 27s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 43/200
 - 27s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 44/200
 - 27s - loss: 0.0048 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 45/200
 - 27s - loss: 0.0049 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 46/200
 - 27s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 47/200
 - 27s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 48/200
 - 27s - loss: 0.0046 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 49/200
 - 27s - loss: 0.0051 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 50/200
 - 27s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 51/200
 - 27s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9911
Epoch 52/200
 - 27s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 53/200
 - 27s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 54/200
 - 27s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 55/200
 - 27s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 56/200
 - 27s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 57/200
 - 27s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 58/200
 - 27s - loss: 0.0043 - val_loss: 0.0059
 - val_f1: 0.9846
Epoch 59/200
 - 27s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 60/200
 - 27s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 61/200
 - 27s - loss: 0.0043 - val_loss: 0.0031
2019-12-27 07:29:44,607 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_60.pickle
 - val_f1: 0.9927
Epoch 62/200
 - 27s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 63/200
 - 27s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 64/200
 - 27s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9938
Epoch 65/200
 - 27s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 66/200
 - 27s - loss: 0.0046 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 67/200
 - 27s - loss: 0.0046 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 68/200
 - 27s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 69/200
 - 27s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 70/200
 - 27s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 71/200
 - 27s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 72/200
 - 27s - loss: 0.0045 - val_loss: 0.0027
 - val_f1: 0.9925
Epoch 73/200
 - 27s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 74/200
 - 27s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9919
Epoch 75/200
 - 27s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 76/200
 - 27s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9883
Epoch 77/200
 - 27s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 78/200
 - 27s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 79/200
 - 27s - loss: 0.0043 - val_loss: 0.0067
 - val_f1: 0.9833
Epoch 80/200
 - 27s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 81/200
 - 27s - loss: 0.0046 - val_loss: 0.0038
2019-12-27 07:44:32,989 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_80.pickle
 - val_f1: 0.9928
Epoch 82/200
 - 27s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9919
Epoch 83/200
 - 27s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 84/200
 - 27s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 85/200
 - 27s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 86/200
 - 27s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 87/200
 - 27s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 88/200
 - 27s - loss: 0.0044 - val_loss: 0.0059
 - val_f1: 0.9826
Epoch 89/200
 - 27s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 90/200
 - 27s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 91/200
 - 27s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9920
Epoch 92/200
 - 27s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 93/200
 - 27s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 94/200
 - 27s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 95/200
 - 27s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 96/200
 - 27s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 97/200
 - 27s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9881
Epoch 98/200
 - 27s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 99/200
 - 27s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 100/200
 - 27s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 101/200
 - 27s - loss: 0.0043 - val_loss: 0.0027
2019-12-27 07:59:21,688 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_100.pickle
 - val_f1: 0.9946
Epoch 102/200
 - 27s - loss: 0.0041 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 103/200
 - 27s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9909
Epoch 104/200
 - 27s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 105/200
 - 27s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 106/200
 - 27s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9923
Epoch 107/200
 - 27s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 108/200
 - 27s - loss: 0.0045 - val_loss: 0.0086
 - val_f1: 0.9651
Epoch 109/200
 - 27s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 110/200
 - 27s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 111/200
 - 27s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9910
Epoch 112/200
 - 27s - loss: 0.0046 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 113/200
 - 27s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 114/200
 - 27s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 115/200
 - 27s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 116/200
 - 27s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 117/200
 - 27s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 118/200
 - 27s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 119/200
 - 28s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 120/200
 - 27s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 121/200
 - 27s - loss: 0.0043 - val_loss: 0.0027
2019-12-27 08:14:16,087 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_120.pickle
 - val_f1: 0.9937
Epoch 122/200
 - 27s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 123/200
 - 27s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 124/200
 - 27s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9895
Epoch 125/200
 - 27s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 126/200
 - 27s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 127/200
 - 27s - loss: 0.0044 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 128/200
 - 27s - loss: 0.0044 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 129/200
 - 27s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 130/200
 - 27s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 131/200
 - 27s - loss: 0.0044 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 132/200
 - 27s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 133/200
 - 27s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9916
Epoch 134/200
 - 27s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 135/200
 - 27s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9911
Epoch 136/200
 - 27s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 137/200
 - 27s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 138/200
 - 27s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 139/200
 - 27s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9920
Epoch 140/200
 - 27s - loss: 0.0044 - val_loss: 0.0048
 - val_f1: 0.9834
Epoch 141/200
 - 27s - loss: 0.0042 - val_loss: 0.0034
2019-12-27 08:29:05,274 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_140.pickle
 - val_f1: 0.9919
Epoch 142/200
 - 27s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 143/200
 - 27s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 144/200
 - 27s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 145/200
 - 27s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 146/200
 - 27s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 147/200
 - 27s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 148/200
 - 27s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 149/200
 - 27s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 150/200
 - 27s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 151/200
 - 27s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 152/200
 - 27s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 153/200
 - 27s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 154/200
 - 27s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 155/200
 - 27s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 156/200
 - 27s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9920
Epoch 157/200
 - 27s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 158/200
 - 27s - loss: 0.0041 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 159/200
 - 27s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 160/200
 - 27s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 161/200
 - 27s - loss: 0.0041 - val_loss: 0.0030
2019-12-27 08:43:55,025 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_160.pickle
 - val_f1: 0.9939
Epoch 162/200
 - 27s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9910
Epoch 163/200
 - 27s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 164/200
 - 27s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 165/200
 - 27s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 166/200
 - 27s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 167/200
 - 27s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 168/200
 - 27s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 169/200
 - 27s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 170/200
 - 27s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9924
Epoch 171/200
 - 27s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 172/200
 - 27s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9920
Epoch 173/200
 - 27s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 174/200
 - 27s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 175/200
 - 27s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 176/200
 - 27s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 177/200
 - 27s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9911
Epoch 178/200
 - 27s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 179/200
 - 27s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 180/200
 - 27s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9921
Epoch 181/200
 - 27s - loss: 0.0038 - val_loss: 0.0032
2019-12-27 08:58:44,397 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_180.pickle
 - val_f1: 0.9925
Epoch 182/200
 - 27s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 183/200
 - 27s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 184/200
 - 27s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9912
Epoch 185/200
 - 27s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 186/200
 - 27s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9913
Epoch 187/200
 - 27s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9920
Epoch 188/200
 - 27s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9928
Epoch 189/200
 - 27s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 190/200
 - 27s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9926
Epoch 191/200
 - 27s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 192/200
 - 27s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 193/200
 - 27s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 194/200
 - 27s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 195/200
 - 27s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9919
Epoch 196/200
 - 27s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 197/200
 - 27s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 198/200
 - 27s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 199/200
 - 27s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 200/200
 - 27s - loss: 0.0039 - val_loss: 0.0026
2019-12-27 09:13:05,734 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 09:14:21,588 [INFO] Last epoch loss evaluation: train_loss = 0.002516, val_loss = 0.002537
2019-12-27 09:14:21,588 [INFO] Training complete. time_to_train = 8994.20 sec, 149.90 min
2019-12-27 09:14:21,596 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_3/best_model.pickle
2019-12-27 09:14:21,598 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_3/training_error_history.csv
2019-12-27 09:14:21,782 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_3/training_error_history.png
2019-12-27 09:14:21,956 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_3/training_f1_history.png
2019-12-27 09:14:21,957 [INFO] Making predictions on training, validation, testing data
2019-12-27 09:15:48,101 [INFO] Evaluating predictions (results)
2019-12-27 09:15:58,227 [INFO] Dataset: Testing. Classification report below
2019-12-27 09:15:58,227 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.67      0.01      0.01       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.86      0.99      0.92      1100
         DoS slowloris       0.98      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.82      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.85      0.75      0.74    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 09:15:58,227 [INFO] Overall accuracy (micro avg): 0.9946920054742009
2019-12-27 09:16:09,750 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8511                       0.7473                0.0012                   0.2527  0.7443
2  Weighted avg        0.9956         0.9942                       0.9947                0.0090                   0.0053  0.9940
2019-12-27 09:16:20,056 [INFO] Dataset: Validation. Classification report below
2019-12-27 09:16:20,056 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.80      0.01      0.02       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.87      0.98      0.92      1099
         DoS slowloris       0.98      0.96      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.85      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.86      0.74      0.74    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-27 09:16:20,056 [INFO] Overall accuracy (micro avg): 0.9948546755262907
2019-12-27 09:16:31,748 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8646                       0.7439                0.0012                   0.2561  0.7409
2  Weighted avg        0.9958         0.9945                       0.9949                0.0087                   0.0051  0.9942
2019-12-27 09:17:05,746 [INFO] Dataset: Training. Classification report below
2019-12-27 09:17:05,746 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.75      0.01      0.02      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.88      0.99      0.93      3300
         DoS slowloris       0.98      0.97      0.98      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.85      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.86      0.75      0.74   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-27 09:17:05,746 [INFO] Overall accuracy (micro avg): 0.9948705828545563
2019-12-27 09:17:44,348 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8639                       0.7461                0.0012                   0.2539  0.7442
2  Weighted avg        0.9958         0.9945                       0.9949                0.0088                   0.0051  0.9942
2019-12-27 09:17:44,399 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_3/ann_depth_ids17_layers_3_results.xlsx
2019-12-27 09:17:44,403 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-27 09:17:44,469 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_4
2019-12-27 09:17:44,470 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_4/run_log.log
2019-12-27 09:17:44,470 [INFO] ================= Running experiment no. 4  ================= 

2019-12-27 09:17:44,470 [INFO] Experiment parameters given below
2019-12-27 09:17:44,470 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_4'}
2019-12-27 09:17:44,470 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_4/tf_logs_run_2019_12_27-09_17_44
2019-12-27 09:17:44,470 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 09:17:44,470 [INFO] Reading X, y files
2019-12-27 09:17:44,471 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 09:17:48,817 [INFO] Reading complete. time_to_read=4.35 seconds
2019-12-27 09:17:48,820 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 09:17:50,220 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 09:17:50,221 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 09:17:51,645 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-27 09:17:51,645 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 09:17:51,838 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 09:17:51,838 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 09:17:51,908 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 09:17:51,909 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 09:17:51,977 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 09:17:55,128 [INFO] Initializing model
2019-12-27 09:17:55,521 [INFO] _________________________________________________________________
2019-12-27 09:17:55,521 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 09:17:55,521 [INFO] =================================================================
2019-12-27 09:17:55,522 [INFO] dense_75 (Dense)             (None, 128)               10112     
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,522 [INFO] batch_normalization_62 (Batc (None, 128)               512       
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,522 [INFO] dropout_62 (Dropout)         (None, 128)               0         
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,522 [INFO] dense_76 (Dense)             (None, 64)                8256      
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,522 [INFO] batch_normalization_63 (Batc (None, 64)                256       
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,522 [INFO] dropout_63 (Dropout)         (None, 64)                0         
2019-12-27 09:17:55,522 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] dense_77 (Dense)             (None, 32)                2080      
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] batch_normalization_64 (Batc (None, 32)                128       
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] dropout_64 (Dropout)         (None, 32)                0         
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] dense_78 (Dense)             (None, 16)                528       
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] batch_normalization_65 (Batc (None, 16)                64        
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] dropout_65 (Dropout)         (None, 16)                0         
2019-12-27 09:17:55,523 [INFO] _________________________________________________________________
2019-12-27 09:17:55,523 [INFO] dense_79 (Dense)             (None, 12)                204       
2019-12-27 09:17:55,523 [INFO] =================================================================
2019-12-27 09:17:55,524 [INFO] Total params: 22,140
2019-12-27 09:17:55,524 [INFO] Trainable params: 21,660
2019-12-27 09:17:55,524 [INFO] Non-trainable params: 480
2019-12-27 09:17:55,524 [INFO] _________________________________________________________________
2019-12-27 09:17:55,524 [INFO] Training model
 - val_f1: 0.9941
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 41s - loss: 0.0239 - val_loss: 0.0138
 - val_f1: 0.9657
Epoch 2/200
 - 39s - loss: 0.0115 - val_loss: 0.0121
 - val_f1: 0.9697
Epoch 3/200
 - 39s - loss: 0.0098 - val_loss: 0.0074
 - val_f1: 0.9791
Epoch 4/200
 - 39s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9803
Epoch 5/200
 - 39s - loss: 0.0067 - val_loss: 0.0051
 - val_f1: 0.9898
Epoch 6/200
 - 39s - loss: 0.0065 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 7/200
 - 40s - loss: 0.0061 - val_loss: 0.0034
 - val_f1: 0.9931
Epoch 8/200
 - 39s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9896
Epoch 9/200
 - 40s - loss: 0.0052 - val_loss: 0.0050
 - val_f1: 0.9874
Epoch 10/200
 - 39s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9911
Epoch 11/200
 - 40s - loss: 0.0053 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 12/200
 - 39s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9887
Epoch 13/200
 - 40s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 14/200
 - 40s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 15/200
 - 39s - loss: 0.0049 - val_loss: 0.0047
 - val_f1: 0.9898
Epoch 16/200
 - 39s - loss: 0.0048 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 17/200
 - 40s - loss: 0.0045 - val_loss: 0.0108
 - val_f1: 0.9857
Epoch 18/200
 - 39s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 19/200
 - 39s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9892
Epoch 20/200
 - 39s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 21/200
 - 39s - loss: 0.0046 - val_loss: 0.0034
2019-12-27 09:38:08,959 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_20.pickle
 - val_f1: 0.9918
Epoch 22/200
 - 40s - loss: 0.0045 - val_loss: 0.0238
 - val_f1: 0.9597
Epoch 23/200
 - 39s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9884
Epoch 24/200
 - 39s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9904
Epoch 25/200
 - 39s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 26/200
 - 39s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 27/200
 - 39s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 28/200
 - 39s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9917
Epoch 29/200
 - 39s - loss: 0.0041 - val_loss: 0.0060
 - val_f1: 0.9865
Epoch 30/200
 - 39s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 31/200
 - 40s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9886
Epoch 32/200
 - 40s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 33/200
 - 39s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9887
Epoch 34/200
 - 40s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9907
Epoch 35/200
 - 40s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 36/200
 - 39s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9945
Epoch 37/200
 - 39s - loss: 0.0040 - val_loss: 0.0070
 - val_f1: 0.9856
Epoch 38/200
 - 39s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9894
Epoch 39/200
 - 40s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9911
Epoch 40/200
 - 39s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 41/200
 - 39s - loss: 0.0040 - val_loss: 0.0027
2019-12-27 09:57:25,238 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_40.pickle
 - val_f1: 0.9948
Epoch 42/200
 - 39s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9905
Epoch 43/200
 - 39s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 44/200
 - 39s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9924
Epoch 45/200
 - 39s - loss: 0.0041 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 46/200
 - 39s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 47/200
 - 40s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 48/200
 - 39s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 49/200
 - 39s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 50/200
 - 39s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 51/200
 - 40s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9887
Epoch 52/200
 - 39s - loss: 0.0037 - val_loss: 0.0071
 - val_f1: 0.9858
Epoch 53/200
 - 39s - loss: 0.0039 - val_loss: 0.0061
 - val_f1: 0.9785
Epoch 54/200
 - 40s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 55/200
 - 39s - loss: 0.0037 - val_loss: 0.0084
 - val_f1: 0.9856
Epoch 56/200
 - 40s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9920
Epoch 57/200
 - 39s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 58/200
 - 39s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 59/200
 - 39s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 60/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 61/200
 - 40s - loss: 0.0036 - val_loss: 0.0035
2019-12-27 10:16:42,043 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_60.pickle
 - val_f1: 0.9922
Epoch 62/200
 - 40s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 63/200
 - 40s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 64/200
 - 40s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 65/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 66/200
 - 39s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 67/200
 - 39s - loss: 0.0035 - val_loss: 0.0102
 - val_f1: 0.9845
Epoch 68/200
 - 40s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 69/200
 - 39s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 70/200
 - 39s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 71/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 72/200
 - 39s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 73/200
 - 39s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 74/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 75/200
 - 39s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9912
Epoch 76/200
 - 40s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 77/200
 - 39s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 78/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 79/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9926
Epoch 80/200
 - 39s - loss: 0.0036 - val_loss: 0.0052
 - val_f1: 0.9907
Epoch 81/200
 - 40s - loss: 0.0035 - val_loss: 0.0027
2019-12-27 10:35:58,682 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_80.pickle
 - val_f1: 0.9922
Epoch 82/200
 - 39s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 83/200
 - 39s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 84/200
 - 39s - loss: 0.0034 - val_loss: 0.0036
 - val_f1: 0.9915
Epoch 85/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 86/200
 - 39s - loss: 0.0034 - val_loss: 0.0047
 - val_f1: 0.9897
Epoch 87/200
 - 39s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 88/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 89/200
 - 39s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 90/200
 - 39s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9906
Epoch 91/200
 - 40s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9917
Epoch 92/200
 - 40s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 93/200
 - 39s - loss: 0.0033 - val_loss: 0.0040
 - val_f1: 0.9891
Epoch 94/200
 - 39s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 95/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 96/200
 - 40s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 97/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 98/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 99/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 100/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 101/200
 - 40s - loss: 0.0033 - val_loss: 0.0028
2019-12-27 10:55:15,126 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_100.pickle
 - val_f1: 0.9926
Epoch 102/200
 - 40s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 103/200
 - 40s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9929
Epoch 104/200
 - 40s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9924
Epoch 105/200
 - 40s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 106/200
 - 39s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 107/200
 - 40s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 108/200
 - 39s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 109/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 110/200
 - 40s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 111/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 112/200
 - 39s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 113/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 114/200
 - 39s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9886
Epoch 115/200
 - 39s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 116/200
 - 40s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9883
Epoch 117/200
 - 39s - loss: 0.0032 - val_loss: 0.0073
 - val_f1: 0.9844
Epoch 118/200
 - 40s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 119/200
 - 39s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 120/200
 - 39s - loss: 0.0032 - val_loss: 0.0086
 - val_f1: 0.9779
Epoch 121/200
 - 40s - loss: 0.0032 - val_loss: 0.0026
2019-12-27 11:14:31,953 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_120.pickle
 - val_f1: 0.9947
Epoch 122/200
 - 40s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 123/200
 - 39s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 124/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 125/200
 - 40s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 126/200
 - 40s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 127/200
 - 39s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9953
Epoch 128/200
 - 39s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9925
Epoch 129/200
 - 40s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 130/200
 - 40s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 131/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 132/200
 - 40s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 133/200
 - 39s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 134/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9927
Epoch 135/200
 - 40s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 136/200
 - 40s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 137/200
 - 40s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 138/200
 - 39s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 139/200
 - 40s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 140/200
 - 40s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 141/200
 - 39s - loss: 0.0033 - val_loss: 0.0023
2019-12-27 11:33:48,258 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_140.pickle
 - val_f1: 0.9949
Epoch 142/200
 - 39s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9916
Epoch 143/200
 - 40s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 144/200
 - 40s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 145/200
 - 40s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 146/200
 - 40s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 147/200
 - 40s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9940
Epoch 148/200
 - 40s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9928
Epoch 149/200
 - 40s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 150/200
 - 40s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9918
Epoch 151/200
 - 40s - loss: 0.0032 - val_loss: 0.0071
 - val_f1: 0.9889
Epoch 152/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 153/200
 - 39s - loss: 0.0034 - val_loss: 0.0081
 - val_f1: 0.9844
Epoch 154/200
 - 39s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 155/200
 - 39s - loss: 0.0034 - val_loss: 0.0040
 - val_f1: 0.9914
Epoch 156/200
 - 40s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 157/200
 - 40s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 158/200
 - 39s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 159/200
 - 39s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 160/200
 - 40s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 161/200
 - 39s - loss: 0.0035 - val_loss: 0.0023
2019-12-27 11:53:06,460 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_160.pickle
 - val_f1: 0.9953
Epoch 162/200
 - 39s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 163/200
 - 39s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 164/200
 - 39s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 165/200
 - 39s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 166/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 167/200
 - 40s - loss: 0.0033 - val_loss: 0.0077
 - val_f1: 0.9861
Epoch 168/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 169/200
 - 40s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 170/200
 - 40s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 171/200
 - 39s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 172/200
 - 39s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 173/200
 - 39s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 174/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 175/200
 - 39s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 176/200
 - 39s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 177/200
 - 39s - loss: 0.0032 - val_loss: 0.0057
 - val_f1: 0.9844
Epoch 178/200
 - 40s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 179/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 180/200
 - 40s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 181/200
 - 40s - loss: 0.0032 - val_loss: 0.0029
2019-12-27 12:12:22,553 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_180.pickle
 - val_f1: 0.9940
Epoch 182/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9926
Epoch 183/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 184/200
 - 39s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9908
Epoch 185/200
 - 40s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 186/200
 - 40s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9931
Epoch 187/200
 - 39s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 188/200
 - 39s - loss: 0.0032 - val_loss: 0.0048
 - val_f1: 0.9893
Epoch 189/200
 - 39s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9926
Epoch 190/200
 - 40s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 191/200
 - 39s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 192/200
 - 39s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 193/200
 - 40s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 194/200
 - 40s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 195/200
 - 40s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 196/200
 - 39s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 197/200
 - 39s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 198/200
 - 39s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 199/200
 - 40s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 200/200
 - 40s - loss: 0.0034 - val_loss: 0.0028
2019-12-27 12:30:59,479 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 12:32:20,645 [INFO] Last epoch loss evaluation: train_loss = 0.002196, val_loss = 0.002230
2019-12-27 12:32:20,646 [INFO] Training complete. time_to_train = 11665.12 sec, 194.42 min
2019-12-27 12:32:20,657 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_4/best_model.pickle
2019-12-27 12:32:20,661 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_4/training_error_history.csv
2019-12-27 12:32:20,848 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_4/training_error_history.png
2019-12-27 12:32:21,036 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_4/training_f1_history.png
2019-12-27 12:32:21,036 [INFO] Making predictions on training, validation, testing data
2019-12-27 12:33:52,227 [INFO] Evaluating predictions (results)
2019-12-27 12:34:02,369 [INFO] Dataset: Testing. Classification report below
2019-12-27 12:34:02,369 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1179
Web Attack Brute Force       1.00      0.08      0.15       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-27 12:34:02,369 [INFO] Overall accuracy (micro avg): 0.9954558474579268
2019-12-27 12:34:13,907 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9992         0.8952                       0.7802                0.0010                   0.2198  0.7939
2  Weighted avg        0.9962         0.9953                       0.9955                0.0079                   0.0045  0.9951
2019-12-27 12:34:24,268 [INFO] Dataset: Validation. Classification report below
2019-12-27 12:34:24,268 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.96      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.97      0.97      1180
Web Attack Brute Force       0.81      0.04      0.08       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.77      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-27 12:34:24,269 [INFO] Overall accuracy (micro avg): 0.9955389506367118
2019-12-27 12:34:36,028 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8791                       0.7732                0.0010                   0.2268  0.7850
2  Weighted avg        0.9963         0.9953                       0.9955                0.0077                   0.0045  0.9951
2019-12-27 12:35:10,101 [INFO] Dataset: Training. Classification report below
2019-12-27 12:35:10,101 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.98      0.94      3300
         DoS slowloris       0.98      0.98      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.82      0.07      0.12       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.79   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-27 12:35:10,101 [INFO] Overall accuracy (micro avg): 0.9956079034163109
2019-12-27 12:35:48,785 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8828                       0.7783                0.0010                   0.2217  0.7923
2  Weighted avg        0.9964         0.9953                       0.9956                0.0077                   0.0044  0.9952
2019-12-27 12:35:48,835 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_4/ann_depth_ids17_layers_4_results.xlsx
2019-12-27 12:35:48,839 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-27 12:35:48,903 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_5
2019-12-27 12:35:48,904 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_5/run_log.log
2019-12-27 12:35:48,904 [INFO] ================= Running experiment no. 5  ================= 

2019-12-27 12:35:48,904 [INFO] Experiment parameters given below
2019-12-27 12:35:48,904 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_5'}
2019-12-27 12:35:48,904 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_5/tf_logs_run_2019_12_27-12_35_48
2019-12-27 12:35:48,904 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 12:35:48,904 [INFO] Reading X, y files
2019-12-27 12:35:48,904 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 12:35:53,032 [INFO] Reading complete. time_to_read=4.13 seconds
2019-12-27 12:35:53,032 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 12:35:54,423 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-27 12:35:54,423 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 12:35:55,813 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-27 12:35:55,813 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 12:35:56,004 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 12:35:56,004 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 12:35:56,072 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 12:35:56,072 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 12:35:56,139 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 12:35:59,285 [INFO] Initializing model
2019-12-27 12:35:59,776 [INFO] _________________________________________________________________
2019-12-27 12:35:59,778 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 12:35:59,778 [INFO] =================================================================
2019-12-27 12:35:59,779 [INFO] dense_80 (Dense)             (None, 256)               20224     
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,779 [INFO] batch_normalization_66 (Batc (None, 256)               1024      
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,779 [INFO] dropout_66 (Dropout)         (None, 256)               0         
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,779 [INFO] dense_81 (Dense)             (None, 128)               32896     
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,779 [INFO] batch_normalization_67 (Batc (None, 128)               512       
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,779 [INFO] dropout_67 (Dropout)         (None, 128)               0         
2019-12-27 12:35:59,779 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] dense_82 (Dense)             (None, 64)                8256      
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] batch_normalization_68 (Batc (None, 64)                256       
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] dropout_68 (Dropout)         (None, 64)                0         
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] dense_83 (Dense)             (None, 32)                2080      
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] batch_normalization_69 (Batc (None, 32)                128       
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] dropout_69 (Dropout)         (None, 32)                0         
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] dense_84 (Dense)             (None, 16)                528       
2019-12-27 12:35:59,780 [INFO] _________________________________________________________________
2019-12-27 12:35:59,780 [INFO] batch_normalization_70 (Batc (None, 16)                64        
2019-12-27 12:35:59,781 [INFO] _________________________________________________________________
2019-12-27 12:35:59,781 [INFO] dropout_70 (Dropout)         (None, 16)                0         
2019-12-27 12:35:59,781 [INFO] _________________________________________________________________
2019-12-27 12:35:59,781 [INFO] dense_85 (Dense)             (None, 12)                204       
2019-12-27 12:35:59,781 [INFO] =================================================================
2019-12-27 12:35:59,781 [INFO] Total params: 66,172
2019-12-27 12:35:59,781 [INFO] Trainable params: 65,180
2019-12-27 12:35:59,781 [INFO] Non-trainable params: 992
2019-12-27 12:35:59,781 [INFO] _________________________________________________________________
2019-12-27 12:35:59,781 [INFO] Training model
 - val_f1: 0.9927
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 61s - loss: 0.0227 - val_loss: 0.0107
 - val_f1: 0.9757
Epoch 2/200
 - 59s - loss: 0.0106 - val_loss: 0.0121
 - val_f1: 0.9693
Epoch 3/200
 - 59s - loss: 0.0074 - val_loss: 0.0060
 - val_f1: 0.9892
Epoch 4/200
 - 59s - loss: 0.0062 - val_loss: 0.0039
 - val_f1: 0.9901
Epoch 5/200
 - 59s - loss: 0.0057 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 6/200
 - 59s - loss: 0.0055 - val_loss: 0.0054
 - val_f1: 0.9917
Epoch 7/200
 - 59s - loss: 0.0058 - val_loss: 0.0090
 - val_f1: 0.9773
Epoch 8/200
 - 59s - loss: 0.0052 - val_loss: 0.0039
 - val_f1: 0.9898
Epoch 9/200
 - 59s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9902
Epoch 10/200
 - 59s - loss: 0.0052 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 11/200
 - 59s - loss: 0.0050 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 12/200
 - 59s - loss: 0.0050 - val_loss: 0.0063
 - val_f1: 0.9874
Epoch 13/200
 - 59s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9917
Epoch 14/200
 - 59s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9907
Epoch 15/200
 - 59s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 16/200
 - 59s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 17/200
 - 59s - loss: 0.0047 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 18/200
 - 59s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 19/200
 - 59s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 20/200
 - 59s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 21/200
 - 59s - loss: 0.0042 - val_loss: 0.0031
2019-12-27 13:03:46,490 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_20.pickle
 - val_f1: 0.9934
Epoch 22/200
 - 59s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 23/200
 - 59s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 24/200
 - 59s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 25/200
 - 59s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 26/200
 - 59s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 27/200
 - 59s - loss: 0.0041 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 28/200
 - 59s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 29/200
 - 59s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 30/200
 - 59s - loss: 0.0039 - val_loss: 0.0077
 - val_f1: 0.9709
Epoch 31/200
 - 59s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 32/200
 - 59s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9886
Epoch 33/200
 - 59s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 34/200
 - 59s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9926
Epoch 35/200
 - 59s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 36/200
 - 59s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 37/200
 - 59s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 38/200
 - 59s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 39/200
 - 59s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 40/200
 - 59s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9953
Epoch 41/200
 - 59s - loss: 0.0039 - val_loss: 0.0028
2019-12-27 13:30:15,968 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_40.pickle
 - val_f1: 0.9924
Epoch 42/200
 - 59s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 43/200
 - 59s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 44/200
 - 59s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 45/200
 - 59s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 46/200
 - 59s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 47/200
 - 59s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 48/200
 - 59s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9891
Epoch 49/200
 - 59s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 50/200
 - 59s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9910
Epoch 51/200
 - 59s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 52/200
 - 59s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 53/200
 - 59s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 54/200
 - 59s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 55/200
 - 59s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 56/200
 - 59s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 57/200
 - 59s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 58/200
 - 59s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 59/200
 - 59s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 60/200
 - 59s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 61/200
 - 59s - loss: 0.0036 - val_loss: 0.0030
2019-12-27 13:56:44,745 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_60.pickle
 - val_f1: 0.9940
Epoch 62/200
 - 59s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 63/200
 - 59s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 64/200
 - 59s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 65/200
 - 59s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 66/200
 - 59s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 67/200
 - 59s - loss: 0.0034 - val_loss: 0.0070
 - val_f1: 0.9825
Epoch 68/200
 - 59s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 69/200
 - 59s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 70/200
 - 59s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9895
Epoch 71/200
 - 59s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9948
Epoch 72/200
 - 59s - loss: 0.0034 - val_loss: 0.0056
 - val_f1: 0.9847
Epoch 73/200
 - 59s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 74/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 75/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 76/200
 - 59s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 77/200
 - 59s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9915
Epoch 78/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 79/200
 - 59s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 80/200
 - 59s - loss: 0.0032 - val_loss: 0.0062
 - val_f1: 0.9872
Epoch 81/200
 - 59s - loss: 0.0033 - val_loss: 0.0030
2019-12-27 14:23:13,875 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_80.pickle
 - val_f1: 0.9915
Epoch 82/200
 - 59s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 83/200
 - 59s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9859
Epoch 84/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 85/200
 - 59s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 86/200
 - 59s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 87/200
 - 59s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 88/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 89/200
 - 59s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 90/200
 - 59s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 91/200
 - 59s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 92/200
 - 59s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 93/200
 - 59s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9910
Epoch 94/200
 - 59s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 95/200
 - 59s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 96/200
 - 59s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 97/200
 - 59s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 98/200
 - 59s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 99/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 100/200
 - 59s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9909
Epoch 101/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
2019-12-27 14:49:42,629 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_100.pickle
 - val_f1: 0.9945
Epoch 102/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 103/200
 - 59s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 104/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 105/200
 - 59s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 106/200
 - 59s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9889
Epoch 107/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 108/200
 - 59s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 109/200
 - 59s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 110/200
 - 59s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9929
Epoch 111/200
 - 59s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 112/200
 - 59s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 113/200
 - 59s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 114/200
 - 59s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 115/200
 - 59s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 116/200
 - 59s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 117/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 118/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 119/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 120/200
 - 59s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 121/200
 - 59s - loss: 0.0036 - val_loss: 0.0026
2019-12-27 15:16:11,064 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_120.pickle
 - val_f1: 0.9939
Epoch 122/200
 - 59s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 123/200
 - 59s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 124/200
 - 59s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 125/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 126/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 127/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 128/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 129/200
 - 59s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 130/200
 - 59s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 131/200
 - 59s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9926
Epoch 132/200
 - 59s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 133/200
 - 59s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 134/200
 - 59s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 135/200
 - 59s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 136/200
 - 59s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 137/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 138/200
 - 59s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 139/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 140/200
 - 59s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 141/200
 - 59s - loss: 0.0035 - val_loss: 0.0032
2019-12-27 15:42:39,006 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_140.pickle
 - val_f1: 0.9917
Epoch 142/200
 - 59s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 143/200
 - 59s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 144/200
 - 59s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 145/200
 - 59s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 146/200
 - 59s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 147/200
 - 59s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 148/200
 - 59s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 149/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 150/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 151/200
 - 59s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 152/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 153/200
 - 59s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 154/200
 - 59s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 155/200
 - 59s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 156/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 157/200
 - 59s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 158/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 159/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 160/200
 - 59s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 161/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
2019-12-27 16:09:07,271 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_160.pickle
 - val_f1: 0.9949
Epoch 162/200
 - 59s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 163/200
 - 59s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 164/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 165/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 166/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 167/200
 - 59s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 168/200
 - 59s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9919
Epoch 169/200
 - 59s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9912
Epoch 170/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 171/200
 - 59s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 172/200
 - 59s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 173/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 174/200
 - 59s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 175/200
 - 59s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 176/200
 - 59s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 177/200
 - 58s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 178/200
 - 59s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 179/200
 - 59s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 180/200
 - 59s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 181/200
 - 59s - loss: 0.0033 - val_loss: 0.0025
2019-12-27 16:35:32,050 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_180.pickle
 - val_f1: 0.9943
Epoch 182/200
 - 59s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 183/200
 - 59s - loss: 0.0033 - val_loss: 0.0027
2019-12-27 16:38:31,785 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 16:40:00,322 [INFO] Last epoch loss evaluation: train_loss = 0.002265, val_loss = 0.002288
2019-12-27 16:40:00,323 [INFO] Training complete. time_to_train = 14640.54 sec, 244.01 min
2019-12-27 16:40:00,335 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_5/best_model.pickle
2019-12-27 16:40:00,337 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_5/training_error_history.csv
2019-12-27 16:40:00,536 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_5/training_error_history.png
2019-12-27 16:40:00,711 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_5/training_f1_history.png
2019-12-27 16:40:00,711 [INFO] Making predictions on training, validation, testing data
2019-12-27 16:41:43,066 [INFO] Evaluating predictions (results)
2019-12-27 16:41:53,221 [INFO] Dataset: Testing. Classification report below
2019-12-27 16:41:53,222 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.39      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.99      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.78      0.80    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-27 16:41:53,222 [INFO] Overall accuracy (micro avg): 0.9950969124516852
2019-12-27 16:42:04,765 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0004                   0.0049  0.9951
1     Macro avg        0.9992         0.8963                       0.7847                0.0009                   0.2153  0.7992
2  Weighted avg        0.9959         0.9950                       0.9951                0.0065                   0.0049  0.9947
2019-12-27 16:42:15,095 [INFO] Dataset: Validation. Classification report below
2019-12-27 16:42:15,095 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.91      0.07      0.12       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-27 16:42:15,095 [INFO] Overall accuracy (micro avg): 0.9951906245469109
2019-12-27 16:42:26,821 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.8889                       0.7791                0.0009                   0.2209  0.7918
2  Weighted avg        0.9960         0.9950                       0.9952                0.0063                   0.0048  0.9948
2019-12-27 16:43:00,994 [INFO] Dataset: Training. Classification report below
2019-12-27 16:43:00,995 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.97      1.00      0.98    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.99      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.90      0.78      0.80   1696684
          weighted avg       1.00      1.00      0.99   1696684

2019-12-27 16:43:00,996 [INFO] Overall accuracy (micro avg): 0.9952631132255624
2019-12-27 16:43:39,781 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0004                   0.0047  0.9953
1     Macro avg        0.9992         0.8979                       0.7823                0.0009                   0.2177  0.7972
2  Weighted avg        0.9960         0.9951                       0.9953                0.0064                   0.0047  0.9949
2019-12-27 16:43:39,833 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_5/ann_depth_ids17_layers_5_results.xlsx
2019-12-27 16:43:39,837 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-27 16:43:39,905 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_6
2019-12-27 16:43:39,906 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_6/run_log.log
2019-12-27 16:43:39,906 [INFO] ================= Running experiment no. 6  ================= 

2019-12-27 16:43:39,906 [INFO] Experiment parameters given below
2019-12-27 16:43:39,906 [INFO] 
{'experiment_num': 6, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_6', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_6'}
2019-12-27 16:43:39,906 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_6/tf_logs_run_2019_12_27-16_43_39
2019-12-27 16:43:39,906 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 16:43:39,906 [INFO] Reading X, y files
2019-12-27 16:43:39,906 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 16:43:44,007 [INFO] Reading complete. time_to_read=4.10 seconds
2019-12-27 16:43:44,007 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 16:43:45,404 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 16:43:45,404 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 16:43:46,801 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-27 16:43:46,802 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 16:43:46,996 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 16:43:46,996 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 16:43:47,064 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 16:43:47,064 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 16:43:47,131 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 16:43:50,296 [INFO] Initializing model
2019-12-27 16:43:50,891 [INFO] _________________________________________________________________
2019-12-27 16:43:50,893 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 16:43:50,893 [INFO] =================================================================
2019-12-27 16:43:50,893 [INFO] dense_86 (Dense)             (None, 400)               31600     
2019-12-27 16:43:50,893 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] batch_normalization_71 (Batc (None, 400)               1600      
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] dropout_71 (Dropout)         (None, 400)               0         
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] dense_87 (Dense)             (None, 256)               102656    
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] batch_normalization_72 (Batc (None, 256)               1024      
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] dropout_72 (Dropout)         (None, 256)               0         
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] dense_88 (Dense)             (None, 128)               32896     
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] batch_normalization_73 (Batc (None, 128)               512       
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,894 [INFO] dropout_73 (Dropout)         (None, 128)               0         
2019-12-27 16:43:50,894 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dense_89 (Dense)             (None, 64)                8256      
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] batch_normalization_74 (Batc (None, 64)                256       
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dropout_74 (Dropout)         (None, 64)                0         
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dense_90 (Dense)             (None, 32)                2080      
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] batch_normalization_75 (Batc (None, 32)                128       
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dropout_75 (Dropout)         (None, 32)                0         
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dense_91 (Dense)             (None, 16)                528       
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] batch_normalization_76 (Batc (None, 16)                64        
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,895 [INFO] dropout_76 (Dropout)         (None, 16)                0         
2019-12-27 16:43:50,895 [INFO] _________________________________________________________________
2019-12-27 16:43:50,896 [INFO] dense_92 (Dense)             (None, 12)                204       
2019-12-27 16:43:50,896 [INFO] =================================================================
2019-12-27 16:43:50,896 [INFO] Total params: 181,804
2019-12-27 16:43:50,896 [INFO] Trainable params: 180,012
2019-12-27 16:43:50,896 [INFO] Non-trainable params: 1,792
2019-12-27 16:43:50,896 [INFO] _________________________________________________________________
2019-12-27 16:43:50,896 [INFO] Training model
 - val_f1: 0.9949
Epoch 00183: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 80s - loss: 0.0220 - val_loss: 0.0093
 - val_f1: 0.9753
Epoch 2/200
 - 79s - loss: 0.0102 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 3/200
 - 80s - loss: 0.0083 - val_loss: 0.0053
 - val_f1: 0.9856
Epoch 4/200
 - 80s - loss: 0.0060 - val_loss: 0.0124
 - val_f1: 0.9647
Epoch 5/200
 - 80s - loss: 0.0056 - val_loss: 0.0065
 - val_f1: 0.9818
Epoch 6/200
 - 80s - loss: 0.0052 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 7/200
 - 80s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9893
Epoch 8/200
 - 80s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9901
Epoch 9/200
 - 80s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 10/200
 - 80s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 11/200
 - 80s - loss: 0.0041 - val_loss: 0.0039
 - val_f1: 0.9908
Epoch 12/200
 - 80s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9825
Epoch 13/200
 - 80s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9924
Epoch 14/200
 - 80s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9913
Epoch 15/200
 - 80s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9904
Epoch 16/200
 - 80s - loss: 0.0042 - val_loss: 0.0074
 - val_f1: 0.9797
Epoch 17/200
 - 80s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 18/200
 - 80s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 19/200
 - 80s - loss: 0.0038 - val_loss: 0.0061
 - val_f1: 0.9811
Epoch 20/200
 - 80s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9935
Epoch 21/200
 - 80s - loss: 0.0036 - val_loss: 0.0035
2019-12-27 17:20:56,426 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_20.pickle
 - val_f1: 0.9920
Epoch 22/200
 - 78s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 23/200
 - 78s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9912
Epoch 24/200
 - 78s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 25/200
 - 79s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9888
Epoch 26/200
 - 79s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 27/200
 - 79s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 28/200
 - 78s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9865
Epoch 29/200
 - 78s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 30/200
 - 78s - loss: 0.0036 - val_loss: 0.0061
 - val_f1: 0.9765
Epoch 31/200
 - 78s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9917
Epoch 32/200
 - 78s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 33/200
 - 78s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 34/200
 - 78s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9926
Epoch 35/200
 - 79s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 36/200
 - 78s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 37/200
 - 78s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 38/200
 - 78s - loss: 0.0032 - val_loss: 0.0079
 - val_f1: 0.9642
Epoch 39/200
 - 78s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 40/200
 - 78s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 41/200
 - 78s - loss: 0.0033 - val_loss: 0.0024
2019-12-27 17:55:47,203 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_40.pickle
 - val_f1: 0.9947
Epoch 42/200
 - 78s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 43/200
 - 79s - loss: 0.0032 - val_loss: 0.0416
 - val_f1: 0.9618
Epoch 44/200
 - 80s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 45/200
 - 80s - loss: 0.0031 - val_loss: 0.0040
 - val_f1: 0.9887
Epoch 46/200
 - 81s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 47/200
 - 80s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 48/200
 - 80s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 49/200
 - 79s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 50/200
 - 80s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 51/200
 - 79s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 52/200
 - 79s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 53/200
 - 79s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 54/200
 - 79s - loss: 0.0031 - val_loss: 0.0068
 - val_f1: 0.9714
Epoch 55/200
 - 79s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 56/200
 - 79s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 57/200
 - 79s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 58/200
 - 80s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9866
Epoch 59/200
 - 80s - loss: 0.0032 - val_loss: 0.0165
 - val_f1: 0.9625
Epoch 60/200
 - 80s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 61/200
 - 79s - loss: 0.0033 - val_loss: 0.0028
2019-12-27 18:31:04,217 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_60.pickle
 - val_f1: 0.9931
Epoch 62/200
 - 79s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9892
Epoch 63/200
 - 79s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 64/200
 - 79s - loss: 0.0031 - val_loss: 0.0035
 - val_f1: 0.9909
Epoch 65/200
 - 79s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 66/200
 - 79s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 67/200
 - 79s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 68/200
 - 79s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 69/200
 - 79s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 70/200
 - 78s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 71/200
 - 79s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 72/200
 - 78s - loss: 0.0030 - val_loss: 0.0052
 - val_f1: 0.9849
Epoch 73/200
 - 79s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 74/200
 - 79s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 75/200
 - 79s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 76/200
 - 79s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 77/200
 - 80s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 78/200
 - 80s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 79/200
 - 80s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 80/200
 - 80s - loss: 0.0030 - val_loss: 0.0037
 - val_f1: 0.9894
Epoch 81/200
 - 79s - loss: 0.0030 - val_loss: 0.0028
2019-12-27 19:06:12,636 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_80.pickle
 - val_f1: 0.9931
Epoch 82/200
 - 79s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 83/200
 - 79s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 84/200
 - 79s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 85/200
 - 79s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 86/200
 - 79s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 87/200
 - 79s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 88/200
 - 79s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 89/200
 - 79s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 90/200
 - 79s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 91/200
 - 79s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 92/200
 - 79s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 93/200
 - 79s - loss: 0.0028 - val_loss: 0.0036
 - val_f1: 0.9897
Epoch 94/200
 - 79s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 95/200
 - 79s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 96/200
 - 79s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 97/200
 - 79s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 98/200
 - 79s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9912
Epoch 99/200
 - 79s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 100/200
 - 79s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 101/200
 - 79s - loss: 0.0029 - val_loss: 0.0025
2019-12-27 19:41:18,021 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_100.pickle
 - val_f1: 0.9944
Epoch 102/200
 - 79s - loss: 0.0028 - val_loss: 0.0034
 - val_f1: 0.9900
Epoch 103/200
 - 80s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 104/200
 - 79s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 105/200
 - 79s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 106/200
 - 80s - loss: 0.0028 - val_loss: 0.0033
 - val_f1: 0.9912
Epoch 107/200
 - 79s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 108/200
 - 79s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 109/200
 - 79s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 110/200
 - 79s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 111/200
 - 79s - loss: 0.0028 - val_loss: 0.0046
 - val_f1: 0.9878
Epoch 112/200
 - 79s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 113/200
 - 79s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 114/200
 - 79s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 115/200
 - 79s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 116/200
 - 79s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 117/200
 - 79s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 118/200
 - 79s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 119/200
 - 79s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 120/200
 - 79s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 121/200
 - 79s - loss: 0.0028 - val_loss: 0.0024
2019-12-27 20:16:26,000 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_120.pickle
 - val_f1: 0.9938
Epoch 122/200
 - 80s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9946
Epoch 123/200
 - 79s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 124/200
 - 79s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 125/200
 - 79s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 126/200
 - 79s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 127/200
 - 79s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9946
Epoch 128/200
 - 79s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 129/200
 - 79s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 130/200
 - 79s - loss: 0.0027 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 131/200
 - 80s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9952
Epoch 132/200
 - 80s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 133/200
 - 81s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 134/200
 - 80s - loss: 0.0026 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 135/200
 - 81s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 136/200
 - 80s - loss: 0.0026 - val_loss: 0.0020
 - val_f1: 0.9954
Epoch 137/200
 - 80s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 138/200
 - 80s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 139/200
 - 80s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 140/200
 - 80s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 141/200
 - 81s - loss: 0.0026 - val_loss: 0.0024
2019-12-27 20:51:49,899 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_140.pickle
 - val_f1: 0.9946
Epoch 142/200
 - 80s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 143/200
 - 80s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 144/200
 - 80s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 145/200
 - 80s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 146/200
 - 80s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 147/200
 - 80s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 148/200
 - 81s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 149/200
 - 82s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 150/200
 - 81s - loss: 0.0025 - val_loss: 0.0029
 - val_f1: 0.9917
Epoch 151/200
 - 80s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 152/200
 - 81s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 153/200
 - 80s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 154/200
 - 80s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 155/200
 - 80s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9957
Epoch 156/200
 - 79s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 157/200
 - 79s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 158/200
 - 80s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 159/200
 - 79s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 160/200
 - 79s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 161/200
 - 79s - loss: 0.0025 - val_loss: 0.0034
2019-12-27 21:27:20,128 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_160.pickle
 - val_f1: 0.9912
Epoch 162/200
 - 80s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 163/200
 - 80s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 164/200
 - 80s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 165/200
 - 80s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 166/200
 - 80s - loss: 0.0025 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 167/200
 - 80s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 168/200
 - 79s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 169/200
 - 79s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 170/200
 - 79s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 171/200
 - 79s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9935
Epoch 172/200
 - 80s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 173/200
 - 79s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 174/200
 - 79s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 175/200
 - 79s - loss: 0.0025 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 176/200
 - 79s - loss: 0.0025 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 177/200
 - 79s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 178/200
 - 79s - loss: 0.0024 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 179/200
 - 80s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 180/200
 - 79s - loss: 0.0024 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 181/200
 - 80s - loss: 0.0024 - val_loss: 0.0025
2019-12-27 22:02:39,461 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_180.pickle
 - val_f1: 0.9939
Epoch 182/200
 - 80s - loss: 0.0024 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 183/200
 - 80s - loss: 0.0025 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 184/200
 - 80s - loss: 0.0028 - val_loss: 0.0207
 - val_f1: 0.9603
Epoch 185/200
 - 80s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 186/200
 - 80s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9935
Epoch 187/200
 - 79s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9958
Epoch 188/200
 - 80s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 189/200
 - 79s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 190/200
 - 80s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 191/200
 - 80s - loss: 0.0026 - val_loss: 0.0035
 - val_f1: 0.9908
Epoch 192/200
 - 80s - loss: 0.0026 - val_loss: 0.0082
 - val_f1: 0.9845
Epoch 193/200
 - 80s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 194/200
 - 81s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 195/200
 - 80s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9948
Epoch 196/200
 - 80s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9950
Epoch 197/200
 - 80s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 198/200
 - 80s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 199/200
 - 80s - loss: 0.0026 - val_loss: 0.0036
 - val_f1: 0.9905
Epoch 200/200
 - 80s - loss: 0.0026 - val_loss: 0.0027
2019-12-27 22:36:42,404 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 22:38:34,162 [INFO] Last epoch loss evaluation: train_loss = 0.001888, val_loss = 0.001959
2019-12-27 22:38:34,163 [INFO] Training complete. time_to_train = 21283.27 sec, 354.72 min
2019-12-27 22:38:34,182 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_6/best_model.pickle
2019-12-27 22:38:34,185 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_6/training_error_history.csv
2019-12-27 22:38:34,381 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_6/training_error_history.png
2019-12-27 22:38:34,569 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_6/training_f1_history.png
2019-12-27 22:38:34,569 [INFO] Making predictions on training, validation, testing data
2019-12-27 22:40:43,657 [INFO] Evaluating predictions (results)
2019-12-27 22:40:53,834 [INFO] Dataset: Testing. Classification report below
2019-12-27 22:40:53,834 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       1.00      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.98      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.98      0.99      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.99      0.97      1179
Web Attack Brute Force       1.00      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-27 22:40:53,834 [INFO] Overall accuracy (micro avg): 0.9961365862628677
2019-12-27 22:41:05,393 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9994         0.8982                       0.7864                0.0008                   0.2136  0.8013
2  Weighted avg        0.9968         0.9960                       0.9961                0.0061                   0.0039  0.9958
2019-12-27 22:41:15,729 [INFO] Dataset: Validation. Classification report below
2019-12-27 22:41:15,729 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.79      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-27 22:41:15,729 [INFO] Overall accuracy (micro avg): 0.9961224410409468
2019-12-27 22:41:27,462 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9994         0.8801                       0.7797                0.0008                   0.2203  0.7927
2  Weighted avg        0.9968         0.9958                       0.9961                0.0061                   0.0039  0.9957
2019-12-27 22:42:01,565 [INFO] Dataset: Training. Classification report below
2019-12-27 22:42:01,565 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       1.00      0.37      0.55      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       1.00      0.98      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.95      3300
         DoS slowloris       0.98      0.99      0.99      3478
           FTP-Patator       0.99      1.00      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.99      0.97      3538
Web Attack Brute Force       0.87      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-27 22:42:01,565 [INFO] Overall accuracy (micro avg): 0.9962780340947401
2019-12-27 22:42:40,285 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9963         0.9963                       0.9963                0.0003                   0.0037  0.9963
1     Macro avg        0.9994         0.8897                       0.7840                0.0008                   0.2160  0.7988
2  Weighted avg        0.9969         0.9960                       0.9963                0.0060                   0.0037  0.9959
2019-12-27 22:42:40,336 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_6/ann_depth_ids17_layers_6_results.xlsx
2019-12-27 22:42:40,340 [INFO] ================= Finished running experiment no. 6 ================= 

2019-12-27 22:42:40,405 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_7
2019-12-27 22:42:40,405 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_7/run_log.log
2019-12-27 22:42:40,405 [INFO] ================= Running experiment no. 7  ================= 

2019-12-27 22:42:40,405 [INFO] Experiment parameters given below
2019-12-27 22:42:40,405 [INFO] 
{'experiment_num': 7, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_7', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_7'}
2019-12-27 22:42:40,405 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_7/tf_logs_run_2019_12_27-22_42_40
2019-12-27 22:42:40,405 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-27 22:42:40,406 [INFO] Reading X, y files
2019-12-27 22:42:40,406 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-27 22:42:44,527 [INFO] Reading complete. time_to_read=4.12 seconds
2019-12-27 22:42:44,528 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-27 22:42:45,918 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-27 22:42:45,918 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-27 22:42:47,308 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-27 22:42:47,308 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-27 22:42:47,499 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-27 22:42:47,499 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-27 22:42:47,567 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 22:42:47,567 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-27 22:42:47,636 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-27 22:42:50,773 [INFO] Initializing model
2019-12-27 22:42:51,477 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 22:42:51,478 [INFO] =================================================================
2019-12-27 22:42:51,478 [INFO] dense_93 (Dense)             (None, 500)               39500     
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] batch_normalization_77 (Batc (None, 500)               2000      
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] dropout_77 (Dropout)         (None, 500)               0         
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] dense_94 (Dense)             (None, 400)               200400    
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] batch_normalization_78 (Batc (None, 400)               1600      
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] dropout_78 (Dropout)         (None, 400)               0         
2019-12-27 22:42:51,478 [INFO] _________________________________________________________________
2019-12-27 22:42:51,478 [INFO] dense_95 (Dense)             (None, 256)               102656    
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] batch_normalization_79 (Batc (None, 256)               1024      
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dropout_79 (Dropout)         (None, 256)               0         
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dense_96 (Dense)             (None, 128)               32896     
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] batch_normalization_80 (Batc (None, 128)               512       
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dropout_80 (Dropout)         (None, 128)               0         
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dense_97 (Dense)             (None, 64)                8256      
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] batch_normalization_81 (Batc (None, 64)                256       
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dropout_81 (Dropout)         (None, 64)                0         
2019-12-27 22:42:51,479 [INFO] _________________________________________________________________
2019-12-27 22:42:51,479 [INFO] dense_98 (Dense)             (None, 32)                2080      
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] batch_normalization_82 (Batc (None, 32)                128       
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] dropout_82 (Dropout)         (None, 32)                0         
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] dense_99 (Dense)             (None, 16)                528       
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] batch_normalization_83 (Batc (None, 16)                64        
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] dropout_83 (Dropout)         (None, 16)                0         
2019-12-27 22:42:51,480 [INFO] _________________________________________________________________
2019-12-27 22:42:51,480 [INFO] dense_100 (Dense)            (None, 12)                204       
2019-12-27 22:42:51,480 [INFO] =================================================================
2019-12-27 22:42:51,480 [INFO] Total params: 392,104
2019-12-27 22:42:51,481 [INFO] Trainable params: 389,312
2019-12-27 22:42:51,481 [INFO] Non-trainable params: 2,792
2019-12-27 22:42:51,481 [INFO] _________________________________________________________________
2019-12-27 22:42:51,481 [INFO] Training model
 - val_f1: 0.9938
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 115s - loss: 0.0222 - val_loss: 0.0123
 - val_f1: 0.9714
Epoch 2/200
 - 112s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9756
Epoch 3/200
 - 112s - loss: 0.0081 - val_loss: 0.0055
 - val_f1: 0.9852
Epoch 4/200
 - 112s - loss: 0.0063 - val_loss: 0.0053
 - val_f1: 0.9861
Epoch 5/200
 - 112s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9895
Epoch 6/200
 - 112s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 7/200
 - 112s - loss: 0.0049 - val_loss: 0.0086
 - val_f1: 0.9735
Epoch 8/200
 - 112s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 9/200
 - 112s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 10/200
 - 112s - loss: 0.0043 - val_loss: 0.0070
 - val_f1: 0.9823
Epoch 11/200
 - 112s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 12/200
 - 112s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 13/200
 - 112s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 14/200
 - 112s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9912
Epoch 15/200
 - 112s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9876
Epoch 16/200
 - 112s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9839
Epoch 17/200
 - 112s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 18/200
 - 112s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9891
Epoch 19/200
 - 112s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9866
Epoch 20/200
 - 112s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9881
Epoch 21/200
 - 112s - loss: 0.0038 - val_loss: 0.0056
2019-12-27 23:35:08,669 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_20.pickle
 - val_f1: 0.9855
Epoch 22/200
 - 113s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 23/200
 - 113s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 24/200
 - 113s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9898
Epoch 25/200
 - 113s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 26/200
 - 113s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 27/200
 - 113s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9912
Epoch 28/200
 - 113s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 29/200
 - 113s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 30/200
 - 112s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 31/200
 - 112s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 32/200
 - 113s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9880
Epoch 33/200
 - 113s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 34/200
 - 113s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 35/200
 - 113s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 36/200
 - 113s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 37/200
 - 113s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 38/200
 - 113s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 39/200
 - 113s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 40/200
 - 113s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 41/200
 - 113s - loss: 0.0031 - val_loss: 0.0027
2019-12-28 00:25:13,718 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_40.pickle
 - val_f1: 0.9936
Epoch 42/200
 - 113s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 43/200
 - 113s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 44/200
 - 113s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 45/200
 - 112s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 46/200
 - 113s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 47/200
 - 113s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 48/200
 - 113s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 49/200
 - 113s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 50/200
 - 112s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 51/200
 - 113s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 52/200
 - 113s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 53/200
 - 113s - loss: 0.0029 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 54/200
 - 113s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 55/200
 - 112s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9897
Epoch 56/200
 - 112s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9911
Epoch 57/200
 - 113s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 58/200
 - 113s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 59/200
 - 113s - loss: 0.0032 - val_loss: 0.0072
 - val_f1: 0.9779
Epoch 60/200
 - 112s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 61/200
 - 112s - loss: 0.0030 - val_loss: 0.0024
2019-12-28 01:15:16,504 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_60.pickle
 - val_f1: 0.9948
Epoch 62/200
 - 113s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 63/200
 - 113s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 64/200
 - 113s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 65/200
 - 113s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9886
Epoch 66/200
 - 113s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 67/200
 - 113s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 68/200
 - 113s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 69/200
 - 113s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 70/200
 - 113s - loss: 0.0028 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 71/200
 - 113s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 72/200
 - 113s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9953
Epoch 73/200
 - 113s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 74/200
 - 113s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 75/200
 - 113s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 76/200
 - 113s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 77/200
 - 113s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 78/200
 - 113s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 79/200
 - 113s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 80/200
 - 113s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 81/200
 - 113s - loss: 0.0028 - val_loss: 0.0026
2019-12-28 02:05:21,074 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_80.pickle
 - val_f1: 0.9941
Epoch 82/200
 - 113s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 83/200
 - 113s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 84/200
 - 113s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 85/200
 - 113s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 86/200
 - 113s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9931
Epoch 87/200
 - 113s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9957
Epoch 88/200
 - 113s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 89/200
 - 113s - loss: 0.0027 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 90/200
 - 113s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 91/200
 - 113s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 92/200
 - 113s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 93/200
 - 113s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 94/200
 - 113s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 95/200
 - 113s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9909
Epoch 96/200
 - 113s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 97/200
 - 113s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 98/200
 - 113s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 99/200
 - 113s - loss: 0.0026 - val_loss: 0.0036
 - val_f1: 0.9928
Epoch 100/200
 - 113s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9941
Epoch 101/200
 - 113s - loss: 0.0025 - val_loss: 0.0022
2019-12-28 02:55:25,584 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_100.pickle
 - val_f1: 0.9942
Epoch 102/200
 - 113s - loss: 0.0025 - val_loss: 0.0023
2019-12-28 02:58:33,589 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-28 03:01:13,560 [INFO] Last epoch loss evaluation: train_loss = 0.002077, val_loss = 0.002119
2019-12-28 03:01:13,561 [INFO] Training complete. time_to_train = 15502.08 sec, 258.37 min
2019-12-28 03:01:13,584 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_7/best_model.pickle
2019-12-28 03:01:13,586 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_7/training_error_history.csv
2019-12-28 03:01:13,773 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_7/training_error_history.png
2019-12-28 03:01:13,938 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_7/training_f1_history.png
2019-12-28 03:01:13,938 [INFO] Making predictions on training, validation, testing data
2019-12-28 03:04:21,047 [INFO] Evaluating predictions (results)
2019-12-28 03:04:31,201 [INFO] Dataset: Testing. Classification report below
2019-12-28 03:04:31,202 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.96      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.95      0.95      1179
Web Attack Brute Force       1.00      0.08      0.15       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 03:04:31,202 [INFO] Overall accuracy (micro avg): 0.9958377684497898
2019-12-28 03:04:42,762 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8949                       0.7793                0.0010                   0.2207  0.7944
2  Weighted avg        0.9966         0.9956                       0.9958                0.0082                   0.0042  0.9954
2019-12-28 03:04:53,097 [INFO] Dataset: Validation. Classification report below
2019-12-28 03:04:53,097 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.95      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.93      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.96      0.95      1180
Web Attack Brute Force       1.00      0.05      0.09       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.77      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 03:04:53,097 [INFO] Overall accuracy (micro avg): 0.9959951340436592
2019-12-28 03:05:04,824 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8937                       0.7741                0.0010                   0.2259  0.7865
2  Weighted avg        0.9968         0.9958                       0.9960                0.0078                   0.0040  0.9956
2019-12-28 03:05:38,975 [INFO] Dataset: Training. Classification report below
2019-12-28 03:05:38,975 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.96      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.99      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.97      0.98      0.98      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.95      0.96      3538
Web Attack Brute Force       1.00      0.07      0.12       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.90      0.78      0.79   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-28 03:05:38,975 [INFO] Overall accuracy (micro avg): 0.9960340287289796
2019-12-28 03:06:17,755 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8960                       0.7767                0.0010                   0.2233  0.7914
2  Weighted avg        0.9968         0.9958                       0.9960                0.0080                   0.0040  0.9956
2019-12-28 03:06:17,807 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_7/ann_depth_ids17_layers_7_results.xlsx
2019-12-28 03:06:17,811 [INFO] ================= Finished running experiment no. 7 ================= 

2019-12-28 03:06:17,877 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_8
2019-12-28 03:06:17,877 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_8/run_log.log
2019-12-28 03:06:17,877 [INFO] ================= Running experiment no. 8  ================= 

2019-12-28 03:06:17,877 [INFO] Experiment parameters given below
2019-12-28 03:06:17,877 [INFO] 
{'experiment_num': 8, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_8', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_8'}
2019-12-28 03:06:17,878 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_8/tf_logs_run_2019_12_28-03_06_17
2019-12-28 03:06:17,878 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-28 03:06:17,878 [INFO] Reading X, y files
2019-12-28 03:06:17,878 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-28 03:06:21,993 [INFO] Reading complete. time_to_read=4.11 seconds
2019-12-28 03:06:21,993 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-28 03:06:23,395 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-28 03:06:23,396 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-28 03:06:24,798 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-28 03:06:24,799 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-28 03:06:24,991 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-28 03:06:24,991 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-28 03:06:25,059 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 03:06:25,059 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-28 03:06:25,127 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 03:06:28,289 [INFO] Initializing model
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-28 03:06:29,116 [INFO] =================================================================
2019-12-28 03:06:29,116 [INFO] dense_101 (Dense)            (None, 600)               47400     
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] batch_normalization_84 (Batc (None, 600)               2400      
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] dropout_84 (Dropout)         (None, 600)               0         
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] dense_102 (Dense)            (None, 500)               300500    
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] batch_normalization_85 (Batc (None, 500)               2000      
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,116 [INFO] dropout_85 (Dropout)         (None, 500)               0         
2019-12-28 03:06:29,116 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dense_103 (Dense)            (None, 400)               200400    
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] batch_normalization_86 (Batc (None, 400)               1600      
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dropout_86 (Dropout)         (None, 400)               0         
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dense_104 (Dense)            (None, 256)               102656    
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] batch_normalization_87 (Batc (None, 256)               1024      
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dropout_87 (Dropout)         (None, 256)               0         
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dense_105 (Dense)            (None, 128)               32896     
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] batch_normalization_88 (Batc (None, 128)               512       
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,117 [INFO] dropout_88 (Dropout)         (None, 128)               0         
2019-12-28 03:06:29,117 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dense_106 (Dense)            (None, 64)                8256      
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] batch_normalization_89 (Batc (None, 64)                256       
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dropout_89 (Dropout)         (None, 64)                0         
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dense_107 (Dense)            (None, 32)                2080      
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] batch_normalization_90 (Batc (None, 32)                128       
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dropout_90 (Dropout)         (None, 32)                0         
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dense_108 (Dense)            (None, 16)                528       
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] batch_normalization_91 (Batc (None, 16)                64        
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,118 [INFO] dropout_91 (Dropout)         (None, 16)                0         
2019-12-28 03:06:29,118 [INFO] _________________________________________________________________
2019-12-28 03:06:29,119 [INFO] dense_109 (Dense)            (None, 12)                204       
2019-12-28 03:06:29,119 [INFO] =================================================================
2019-12-28 03:06:29,119 [INFO] Total params: 702,904
2019-12-28 03:06:29,119 [INFO] Trainable params: 698,912
2019-12-28 03:06:29,119 [INFO] Non-trainable params: 3,992
2019-12-28 03:06:29,119 [INFO] _________________________________________________________________
2019-12-28 03:06:29,119 [INFO] Training model
 - val_f1: 0.9952
Epoch 00102: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 164s - loss: 0.0222 - val_loss: 0.0101
 - val_f1: 0.9719
Epoch 2/200
 - 162s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9778
Epoch 3/200
 - 162s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 4/200
 - 162s - loss: 0.0066 - val_loss: 0.0052
 - val_f1: 0.9869
Epoch 5/200
 - 162s - loss: 0.0054 - val_loss: 0.0108
 - val_f1: 0.9762
Epoch 6/200
 - 162s - loss: 0.0051 - val_loss: 0.0040
 - val_f1: 0.9912
Epoch 7/200
 - 162s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9903
Epoch 8/200
 - 162s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9902
Epoch 9/200
 - 162s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9912
Epoch 10/200
 - 162s - loss: 0.0047 - val_loss: 0.0074
 - val_f1: 0.9732
Epoch 11/200
 - 162s - loss: 0.0044 - val_loss: 0.0054
 - val_f1: 0.9865
Epoch 12/200
 - 162s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9911
Epoch 13/200
 - 162s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9911
Epoch 14/200
 - 162s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 15/200
 - 162s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 16/200
 - 162s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 17/200
 - 162s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 18/200
 - 162s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 19/200
 - 162s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 20/200
 - 162s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9904
Epoch 21/200
 - 162s - loss: 0.0035 - val_loss: 0.0031
2019-12-28 04:21:47,320 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_20.pickle
 - val_f1: 0.9939
Epoch 22/200
 - 162s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 23/200
 - 162s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 24/200
 - 162s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 25/200
 - 162s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 26/200
 - 162s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 27/200
 - 162s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 28/200
 - 162s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 29/200
 - 162s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 30/200
 - 162s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 31/200
 - 162s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 32/200
 - 162s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 33/200
 - 162s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 34/200
 - 162s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 35/200
 - 162s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 36/200
 - 162s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 37/200
 - 162s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 38/200
 - 162s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9907
Epoch 39/200
 - 162s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9901
Epoch 40/200
 - 162s - loss: 0.0036 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 41/200
 - 162s - loss: 0.0033 - val_loss: 0.0030
2019-12-28 05:34:02,473 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_40.pickle
 - val_f1: 0.9938
Epoch 42/200
 - 162s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9914
Epoch 43/200
 - 162s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 44/200
 - 162s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 45/200
 - 162s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 46/200
 - 162s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 47/200
 - 162s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 48/200
 - 162s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 49/200
 - 162s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 50/200
 - 162s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 51/200
 - 162s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 52/200
 - 162s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 53/200
 - 162s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 54/200
 - 162s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9869
Epoch 55/200
 - 162s - loss: 0.0029 - val_loss: 0.0051
 - val_f1: 0.9875
Epoch 56/200
 - 162s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9882
Epoch 57/200
 - 162s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9917
Epoch 58/200
 - 162s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 59/200
 - 162s - loss: 0.0029 - val_loss: 0.0037
 - val_f1: 0.9917
Epoch 60/200
 - 162s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 61/200
 - 162s - loss: 0.0030 - val_loss: 0.0064
2019-12-28 06:46:14,803 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_60.pickle
 - val_f1: 0.9799
Epoch 62/200
 - 162s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 63/200
 - 162s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9891
Epoch 64/200
 - 162s - loss: 0.0029 - val_loss: 0.0153
 - val_f1: 0.9642
Epoch 65/200
 - 162s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 66/200
 - 162s - loss: 0.0030 - val_loss: 0.0047
 - val_f1: 0.9906
Epoch 67/200
 - 162s - loss: 0.0032 - val_loss: 0.0139
 - val_f1: 0.9574
Epoch 68/200
 - 162s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9911
Epoch 69/200
 - 162s - loss: 0.0031 - val_loss: 0.0067
 - val_f1: 0.9746
Epoch 70/200
 - 162s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 71/200
 - 162s - loss: 0.0030 - val_loss: 0.0044
 - val_f1: 0.9934
Epoch 72/200
 - 162s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 73/200
 - 162s - loss: 0.0029 - val_loss: 0.0045
 - val_f1: 0.9899
Epoch 74/200
 - 162s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 75/200
 - 162s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 76/200
 - 162s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 77/200
 - 162s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 78/200
 - 162s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 79/200
 - 162s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 80/200
 - 162s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 81/200
 - 162s - loss: 0.0029 - val_loss: 0.0029
2019-12-28 07:58:29,545 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_80.pickle
 - val_f1: 0.9935
Epoch 82/200
 - 162s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 83/200
 - 162s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 84/200
 - 162s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 85/200
 - 162s - loss: 0.0028 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 86/200
 - 162s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 87/200
 - 162s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 88/200
 - 162s - loss: 0.0028 - val_loss: 0.0055
 - val_f1: 0.9831
Epoch 89/200
 - 162s - loss: 0.0029 - val_loss: 0.0039
 - val_f1: 0.9923
Epoch 90/200
 - 162s - loss: 0.0027 - val_loss: 0.0028
2019-12-28 08:31:53,978 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-28 08:35:40,536 [INFO] Last epoch loss evaluation: train_loss = 0.002252, val_loss = 0.002288
2019-12-28 08:35:40,536 [INFO] Training complete. time_to_train = 19751.42 sec, 329.19 min
2019-12-28 08:35:40,568 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_8/best_model.pickle
2019-12-28 08:35:40,571 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_8/training_error_history.csv
2019-12-28 08:35:40,755 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_8/training_error_history.png
2019-12-28 08:35:40,925 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_8/training_f1_history.png
2019-12-28 08:35:40,925 [INFO] Making predictions on training, validation, testing data
2019-12-28 08:40:12,628 [INFO] Evaluating predictions (results)
2019-12-28 08:40:22,770 [INFO] Dataset: Testing. Classification report below
2019-12-28 08:40:22,770 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.93      1100
         DoS slowloris       0.98      0.99      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.99      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 08:40:22,770 [INFO] Overall accuracy (micro avg): 0.9956432716483781
2019-12-28 08:40:34,305 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8952                       0.7846                0.0010                   0.2154  0.7985
2  Weighted avg        0.9964         0.9955                       0.9956                0.0080                   0.0044  0.9953
2019-12-28 08:40:44,668 [INFO] Dataset: Validation. Classification report below
2019-12-28 08:40:44,668 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1180
Web Attack Brute Force       0.81      0.07      0.13       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 08:40:44,668 [INFO] Overall accuracy (micro avg): 0.9958041735477278
2019-12-28 08:40:56,431 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8793                       0.7787                0.0010                   0.2213  0.7911
2  Weighted avg        0.9966         0.9955                       0.9958                0.0077                   0.0042  0.9954
2019-12-28 08:41:30,650 [INFO] Dataset: Training. Classification report below
2019-12-28 08:41:30,650 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.99      0.97      3538
Web Attack Brute Force       0.85      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-28 08:41:30,650 [INFO] Overall accuracy (micro avg): 0.9958849143387926
2019-12-28 08:42:09,513 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0004                   0.0041  0.9959
1     Macro avg        0.9993         0.8856                       0.7823                0.0010                   0.2177  0.7966
2  Weighted avg        0.9966         0.9956                       0.9959                0.0077                   0.0041  0.9955
2019-12-28 08:42:09,566 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_8/ann_depth_ids17_layers_8_results.xlsx
2019-12-28 08:42:09,570 [INFO] ================= Finished running experiment no. 8 ================= 

2019-12-28 08:42:09,632 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_9
2019-12-28 08:42:09,632 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_9/run_log.log
2019-12-28 08:42:09,632 [INFO] ================= Running experiment no. 9  ================= 

2019-12-28 08:42:09,632 [INFO] Experiment parameters given below
2019-12-28 08:42:09,632 [INFO] 
{'experiment_num': 9, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_9', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_9'}
2019-12-28 08:42:09,632 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_9/tf_logs_run_2019_12_28-08_42_09
2019-12-28 08:42:09,632 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-28 08:42:09,635 [INFO] Reading X, y files
2019-12-28 08:42:09,635 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-28 08:42:13,733 [INFO] Reading complete. time_to_read=4.10 seconds
2019-12-28 08:42:13,733 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-28 08:42:15,129 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-28 08:42:15,130 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-28 08:42:16,525 [INFO] Reading complete. time_to_read=1.40 seconds
2019-12-28 08:42:16,525 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-28 08:42:16,716 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-28 08:42:16,716 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-28 08:42:16,785 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 08:42:16,785 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-28 08:42:16,853 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 08:42:19,987 [INFO] Initializing model
2019-12-28 08:42:20,931 [INFO] _________________________________________________________________
2019-12-28 08:42:20,931 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-28 08:42:20,931 [INFO] =================================================================
2019-12-28 08:42:20,932 [INFO] dense_110 (Dense)            (None, 700)               55300     
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] batch_normalization_92 (Batc (None, 700)               2800      
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] dropout_92 (Dropout)         (None, 700)               0         
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] dense_111 (Dense)            (None, 600)               420600    
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] batch_normalization_93 (Batc (None, 600)               2400      
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] dropout_93 (Dropout)         (None, 600)               0         
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] dense_112 (Dense)            (None, 500)               300500    
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,932 [INFO] batch_normalization_94 (Batc (None, 500)               2000      
2019-12-28 08:42:20,932 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dropout_94 (Dropout)         (None, 500)               0         
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dense_113 (Dense)            (None, 400)               200400    
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] batch_normalization_95 (Batc (None, 400)               1600      
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dropout_95 (Dropout)         (None, 400)               0         
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dense_114 (Dense)            (None, 256)               102656    
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] batch_normalization_96 (Batc (None, 256)               1024      
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dropout_96 (Dropout)         (None, 256)               0         
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] dense_115 (Dense)            (None, 128)               32896     
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,933 [INFO] batch_normalization_97 (Batc (None, 128)               512       
2019-12-28 08:42:20,933 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dropout_97 (Dropout)         (None, 128)               0         
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dense_116 (Dense)            (None, 64)                8256      
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] batch_normalization_98 (Batc (None, 64)                256       
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dropout_98 (Dropout)         (None, 64)                0         
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dense_117 (Dense)            (None, 32)                2080      
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] batch_normalization_99 (Batc (None, 32)                128       
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dropout_99 (Dropout)         (None, 32)                0         
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] dense_118 (Dense)            (None, 16)                528       
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,934 [INFO] batch_normalization_100 (Bat (None, 16)                64        
2019-12-28 08:42:20,934 [INFO] _________________________________________________________________
2019-12-28 08:42:20,935 [INFO] dropout_100 (Dropout)        (None, 16)                0         
2019-12-28 08:42:20,935 [INFO] _________________________________________________________________
2019-12-28 08:42:20,935 [INFO] dense_119 (Dense)            (None, 12)                204       
2019-12-28 08:42:20,935 [INFO] =================================================================
2019-12-28 08:42:20,935 [INFO] Total params: 1,134,204
2019-12-28 08:42:20,935 [INFO] Trainable params: 1,128,812
2019-12-28 08:42:20,935 [INFO] Non-trainable params: 5,392
2019-12-28 08:42:20,935 [INFO] _________________________________________________________________
2019-12-28 08:42:20,935 [INFO] Training model
 - val_f1: 0.9949
Epoch 00090: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 232s - loss: 0.0218 - val_loss: 0.0111
 - val_f1: 0.9727
Epoch 2/200
 - 229s - loss: 0.0103 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 3/200
 - 228s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 4/200
 - 229s - loss: 0.0062 - val_loss: 0.0041
 - val_f1: 0.9886
Epoch 5/200
 - 229s - loss: 0.0054 - val_loss: 0.0087
 - val_f1: 0.9743
Epoch 6/200
 - 229s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9885
Epoch 7/200
 - 229s - loss: 0.0048 - val_loss: 0.0066
 - val_f1: 0.9805
Epoch 8/200
 - 229s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9883
Epoch 9/200
 - 229s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9877
Epoch 10/200
 - 229s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9896
Epoch 11/200
 - 229s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 12/200
 - 229s - loss: 0.0041 - val_loss: 0.0076
 - val_f1: 0.9832
Epoch 13/200
 - 229s - loss: 0.0039 - val_loss: 0.0037
 - val_f1: 0.9894
Epoch 14/200
 - 229s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 15/200
 - 229s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 16/200
 - 229s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9891
Epoch 17/200
 - 229s - loss: 0.0039 - val_loss: 0.0071
 - val_f1: 0.9824
Epoch 18/200
 - 229s - loss: 0.0036 - val_loss: 0.0182
 - val_f1: 0.9615
Epoch 19/200
 - 229s - loss: 0.0035 - val_loss: 0.0049
 - val_f1: 0.9907
Epoch 20/200
 - 229s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 21/200
 - 229s - loss: 0.0033 - val_loss: 0.0025
2019-12-28 10:29:33,038 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_20.pickle
 - val_f1: 0.9928
Epoch 22/200
 - 230s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 23/200
 - 230s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 24/200
 - 229s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 25/200
 - 230s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9924
Epoch 26/200
 - 229s - loss: 0.0035 - val_loss: 0.0040
 - val_f1: 0.9905
Epoch 27/200
 - 230s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9881
Epoch 28/200
 - 229s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 29/200
 - 230s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 30/200
 - 229s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 31/200
 - 230s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 32/200
 - 229s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 33/200
 - 230s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 34/200
 - 230s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9929
Epoch 35/200
 - 230s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 36/200
 - 230s - loss: 0.0031 - val_loss: 0.0137
 - val_f1: 0.9630
Epoch 37/200
 - 230s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 38/200
 - 230s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 39/200
 - 229s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 40/200
 - 230s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 41/200
 - 230s - loss: 0.0029 - val_loss: 0.0022
2019-12-28 12:12:40,986 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_40.pickle
 - val_f1: 0.9948
Epoch 42/200
 - 229s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 43/200
 - 229s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 44/200
 - 229s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 45/200
 - 229s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 46/200
 - 229s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 47/200
 - 229s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 48/200
 - 229s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 49/200
 - 229s - loss: 0.0028 - val_loss: 0.0073
 - val_f1: 0.9687
Epoch 50/200
 - 230s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 51/200
 - 230s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 52/200
 - 229s - loss: 0.0028 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 53/200
 - 229s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 54/200
 - 229s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 55/200
 - 229s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 56/200
 - 229s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 57/200
 - 229s - loss: 0.0027 - val_loss: 0.0040
 - val_f1: 0.9902
Epoch 58/200
 - 229s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 59/200
 - 229s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 60/200
 - 229s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 61/200
 - 229s - loss: 0.0027 - val_loss: 0.0036
2019-12-28 13:55:41,518 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_60.pickle
 - val_f1: 0.9892
Epoch 62/200
 - 229s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 63/200
 - 229s - loss: 0.0028 - val_loss: 0.0114
 - val_f1: 0.9632
Epoch 64/200
 - 229s - loss: 0.0028 - val_loss: 0.0074
 - val_f1: 0.9680
Epoch 65/200
 - 229s - loss: 0.0027 - val_loss: 0.0119
 - val_f1: 0.9628
Epoch 66/200
 - 230s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9892
Epoch 67/200
 - 229s - loss: 0.0027 - val_loss: 0.0124
 - val_f1: 0.9637
Epoch 68/200
 - 230s - loss: 0.0026 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 69/200
 - 230s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 70/200
 - 229s - loss: 0.0026 - val_loss: 0.0115
 - val_f1: 0.9657
Epoch 71/200
 - 229s - loss: 0.0026 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 72/200
 - 229s - loss: 0.0026 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 73/200
 - 229s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9890
Epoch 74/200
 - 230s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 75/200
 - 229s - loss: 0.0026 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 76/200
 - 230s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9905
Epoch 77/200
 - 230s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9890
Epoch 78/200
 - 230s - loss: 0.0026 - val_loss: 0.0087
 - val_f1: 0.9644
Epoch 79/200
 - 230s - loss: 0.0026 - val_loss: 0.0163
 - val_f1: 0.9559
Epoch 80/200
 - 230s - loss: 0.0026 - val_loss: 0.0036
 - val_f1: 0.9939
Epoch 81/200
 - 230s - loss: 0.0025 - val_loss: 0.0092
2019-12-28 15:38:48,121 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_80.pickle
 - val_f1: 0.9628
Epoch 82/200
 - 229s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 83/200
 - 230s - loss: 0.0026 - val_loss: 0.0115
 - val_f1: 0.9820
Epoch 84/200
 - 229s - loss: 0.0026 - val_loss: 0.0048
 - val_f1: 0.9887
Epoch 85/200
 - 230s - loss: 0.0025 - val_loss: 0.0196
 - val_f1: 0.9619
Epoch 86/200
 - 230s - loss: 0.0026 - val_loss: 0.0079
 - val_f1: 0.9730
Epoch 87/200
 - 230s - loss: 0.0025 - val_loss: 0.0203
 - val_f1: 0.9550
Epoch 88/200
 - 229s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 89/200
 - 230s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 90/200
 - 229s - loss: 0.0025 - val_loss: 0.0077
 - val_f1: 0.9647
Epoch 91/200
 - 230s - loss: 0.0025 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 92/200
 - 230s - loss: 0.0025 - val_loss: 0.0044
 - val_f1: 0.9866
Epoch 93/200
 - 229s - loss: 0.0025 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 94/200
 - 229s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 95/200
 - 229s - loss: 0.0025 - val_loss: 0.0164
 - val_f1: 0.9579
Epoch 96/200
 - 229s - loss: 0.0024 - val_loss: 0.0061
 - val_f1: 0.9881
Epoch 97/200
 - 230s - loss: 0.0026 - val_loss: 0.0124
 - val_f1: 0.9631
Epoch 98/200
 - 229s - loss: 0.0026 - val_loss: 0.0082
 - val_f1: 0.9673
Epoch 99/200
 - 230s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9924
Epoch 100/200
 - 229s - loss: 0.0024 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 101/200
 - 230s - loss: 0.0025 - val_loss: 0.0036
2019-12-28 17:21:55,224 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_100.pickle
 - val_f1: 0.9929
Epoch 102/200
 - 229s - loss: 0.0025 - val_loss: 0.0154
 - val_f1: 0.9619
Epoch 103/200
 - 229s - loss: 0.0025 - val_loss: 0.0135
 - val_f1: 0.9643
Epoch 104/200
 - 229s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 105/200
 - 229s - loss: 0.0024 - val_loss: 0.0024
 - val_f1: 0.9956
Epoch 106/200
 - 230s - loss: 0.0024 - val_loss: 0.0027
 - val_f1: 0.9953
Epoch 107/200
 - 230s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 108/200
 - 229s - loss: 0.0025 - val_loss: 0.0039
 - val_f1: 0.9914
Epoch 109/200
 - 229s - loss: 0.0025 - val_loss: 0.0071
 - val_f1: 0.9831
Epoch 110/200
 - 229s - loss: 0.0025 - val_loss: 0.0061
 - val_f1: 0.9861
Epoch 111/200
 - 230s - loss: 0.0024 - val_loss: 0.0125
 - val_f1: 0.9593
Epoch 112/200
 - 230s - loss: 0.0024 - val_loss: 0.0027
2019-12-28 18:19:59,904 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-28 18:25:29,695 [INFO] Last epoch loss evaluation: train_loss = 0.002187, val_loss = 0.002230
2019-12-28 18:25:29,696 [INFO] Training complete. time_to_train = 34988.76 sec, 583.15 min
2019-12-28 18:25:29,736 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_9/best_model.pickle
2019-12-28 18:25:29,738 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_9/training_error_history.csv
2019-12-28 18:25:29,933 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_9/training_error_history.png
2019-12-28 18:25:30,118 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_9/training_f1_history.png
2019-12-28 18:25:30,118 [INFO] Making predictions on training, validation, testing data
2019-12-28 18:32:08,832 [INFO] Evaluating predictions (results)
2019-12-28 18:32:18,980 [INFO] Dataset: Testing. Classification report below
2019-12-28 18:32:18,980 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.99      0.99      2058
              DoS Hulk       0.97      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.97      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 18:32:18,980 [INFO] Overall accuracy (micro avg): 0.9955548640113727
2019-12-28 18:32:30,533 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8925                       0.7869                0.0008                   0.2131  0.8006
2  Weighted avg        0.9963         0.9954                       0.9956                0.0054                   0.0044  0.9952
2019-12-28 18:32:40,867 [INFO] Dataset: Validation. Classification report below
2019-12-28 18:32:40,867 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.99      0.99      2059
              DoS Hulk       0.97      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.93      1099
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.96      1180
Web Attack Brute Force       0.82      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-28 18:32:40,868 [INFO] Overall accuracy (micro avg): 0.9955000512764295
2019-12-28 18:32:52,598 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8786                       0.7805                0.0008                   0.2195  0.7918
2  Weighted avg        0.9963         0.9953                       0.9955                0.0055                   0.0045  0.9951
2019-12-28 18:33:26,796 [INFO] Dataset: Training. Classification report below
2019-12-28 18:33:26,796 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.97      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.95      0.99      0.97      3538
Web Attack Brute Force       0.87      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-28 18:33:26,796 [INFO] Overall accuracy (micro avg): 0.995648570977271
2019-12-28 18:34:05,627 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8858                       0.7841                0.0008                   0.2159  0.7975
2  Weighted avg        0.9964         0.9954                       0.9956                0.0055                   0.0044  0.9953
2019-12-28 18:34:05,679 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_9/ann_depth_ids17_layers_9_results.xlsx
2019-12-28 18:34:05,683 [INFO] ================= Finished running experiment no. 9 ================= 

2019-12-28 18:34:05,747 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_10
2019-12-28 18:34:05,747 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_10/run_log.log
2019-12-28 18:34:05,747 [INFO] ================= Running experiment no. 10  ================= 

2019-12-28 18:34:05,748 [INFO] Experiment parameters given below
2019-12-28 18:34:05,748 [INFO] 
{'experiment_num': 10, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_10', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [800, 700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_10'}
2019-12-28 18:34:05,748 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_10/tf_logs_run_2019_12_28-18_34_05
2019-12-28 18:34:05,748 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-28 18:34:05,748 [INFO] Reading X, y files
2019-12-28 18:34:05,748 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-28 18:34:09,825 [INFO] Reading complete. time_to_read=4.08 seconds
2019-12-28 18:34:09,825 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-28 18:34:11,214 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-28 18:34:11,214 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-28 18:34:12,602 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-28 18:34:12,602 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-28 18:34:12,793 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-28 18:34:12,793 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-28 18:34:12,862 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 18:34:12,862 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-28 18:34:12,931 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-28 18:34:16,083 [INFO] Initializing model
2019-12-28 18:34:17,176 [INFO] _________________________________________________________________
2019-12-28 18:34:17,176 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-28 18:34:17,176 [INFO] =================================================================
2019-12-28 18:34:17,176 [INFO] dense_120 (Dense)            (None, 800)               63200     
2019-12-28 18:34:17,176 [INFO] _________________________________________________________________
2019-12-28 18:34:17,176 [INFO] batch_normalization_101 (Bat (None, 800)               3200      
2019-12-28 18:34:17,176 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] dropout_101 (Dropout)        (None, 800)               0         
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] dense_121 (Dense)            (None, 700)               560700    
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] batch_normalization_102 (Bat (None, 700)               2800      
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] dropout_102 (Dropout)        (None, 700)               0         
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] dense_122 (Dense)            (None, 600)               420600    
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] batch_normalization_103 (Bat (None, 600)               2400      
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,177 [INFO] dropout_103 (Dropout)        (None, 600)               0         
2019-12-28 18:34:17,177 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] dense_123 (Dense)            (None, 500)               300500    
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] batch_normalization_104 (Bat (None, 500)               2000      
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] dropout_104 (Dropout)        (None, 500)               0         
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] dense_124 (Dense)            (None, 400)               200400    
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] batch_normalization_105 (Bat (None, 400)               1600      
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] dropout_105 (Dropout)        (None, 400)               0         
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] dense_125 (Dense)            (None, 256)               102656    
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,178 [INFO] batch_normalization_106 (Bat (None, 256)               1024      
2019-12-28 18:34:17,178 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dropout_106 (Dropout)        (None, 256)               0         
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dense_126 (Dense)            (None, 128)               32896     
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] batch_normalization_107 (Bat (None, 128)               512       
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dropout_107 (Dropout)        (None, 128)               0         
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dense_127 (Dense)            (None, 64)                8256      
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] batch_normalization_108 (Bat (None, 64)                256       
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dropout_108 (Dropout)        (None, 64)                0         
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,179 [INFO] dense_128 (Dense)            (None, 32)                2080      
2019-12-28 18:34:17,179 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] batch_normalization_109 (Bat (None, 32)                128       
2019-12-28 18:34:17,180 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] dropout_109 (Dropout)        (None, 32)                0         
2019-12-28 18:34:17,180 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] dense_129 (Dense)            (None, 16)                528       
2019-12-28 18:34:17,180 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] batch_normalization_110 (Bat (None, 16)                64        
2019-12-28 18:34:17,180 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] dropout_110 (Dropout)        (None, 16)                0         
2019-12-28 18:34:17,180 [INFO] _________________________________________________________________
2019-12-28 18:34:17,180 [INFO] dense_130 (Dense)            (None, 12)                204       
2019-12-28 18:34:17,180 [INFO] =================================================================
2019-12-28 18:34:17,181 [INFO] Total params: 1,706,004
2019-12-28 18:34:17,181 [INFO] Trainable params: 1,699,012
2019-12-28 18:34:17,181 [INFO] Non-trainable params: 6,992
2019-12-28 18:34:17,181 [INFO] _________________________________________________________________
2019-12-28 18:34:17,181 [INFO] Training model
 - val_f1: 0.9944
Epoch 00112: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 317s - loss: 0.0222 - val_loss: 0.0105
 - val_f1: 0.9690
Epoch 2/200
 - 314s - loss: 0.0106 - val_loss: 0.0082
 - val_f1: 0.9815
Epoch 3/200
 - 314s - loss: 0.0088 - val_loss: 0.0105
 - val_f1: 0.9659
Epoch 4/200
 - 314s - loss: 0.0064 - val_loss: 0.0074
 - val_f1: 0.9783
Epoch 5/200
 - 314s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9875
Epoch 6/200
 - 314s - loss: 0.0051 - val_loss: 0.0044
 - val_f1: 0.9891
Epoch 7/200
 - 314s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9912
Epoch 8/200
 - 315s - loss: 0.0045 - val_loss: 0.0052
 - val_f1: 0.9863
Epoch 9/200
 - 314s - loss: 0.0044 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 10/200
 - 314s - loss: 0.0042 - val_loss: 0.0135
 - val_f1: 0.9680
Epoch 11/200
 - 315s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9905
Epoch 12/200
 - 314s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 13/200
 - 314s - loss: 0.0039 - val_loss: 0.0197
 - val_f1: 0.9633
Epoch 14/200
 - 315s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 15/200
 - 314s - loss: 0.0036 - val_loss: 0.0057
 - val_f1: 0.9876
Epoch 16/200
 - 314s - loss: 0.0035 - val_loss: 0.0348
 - val_f1: 0.9610
Epoch 17/200
 - 314s - loss: 0.0035 - val_loss: 0.0063
 - val_f1: 0.9807
Epoch 18/200
 - 314s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 19/200
 - 314s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 20/200
 - 314s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 21/200
 - 314s - loss: 0.0033 - val_loss: 0.0026
2019-12-28 20:57:15,828 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_20.pickle
 - val_f1: 0.9948
Epoch 22/200
 - 315s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 23/200
 - 315s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 24/200
 - 314s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 25/200
 - 314s - loss: 0.0032 - val_loss: 0.0226
 - val_f1: 0.9652
Epoch 26/200
 - 315s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9924
Epoch 27/200
 - 314s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 28/200
 - 315s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9894
Epoch 29/200
 - 314s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9914
Epoch 30/200
 - 315s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 31/200
 - 314s - loss: 0.0034 - val_loss: 0.0052
 - val_f1: 0.9876
Epoch 32/200
 - 315s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 33/200
 - 315s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9910
Epoch 34/200
 - 315s - loss: 0.0030 - val_loss: 0.0037
 - val_f1: 0.9907
Epoch 35/200
 - 315s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 36/200
 - 315s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 37/200
 - 314s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 38/200
 - 314s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 39/200
 - 315s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 40/200
 - 315s - loss: 0.0029 - val_loss: 0.0079
 - val_f1: 0.9692
Epoch 41/200
 - 314s - loss: 0.0030 - val_loss: 0.0030
2019-12-28 23:14:30,693 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_40.pickle
 - val_f1: 0.9930
Epoch 42/200
 - 314s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 43/200
 - 315s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9941
Epoch 44/200
 - 314s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 45/200
 - 314s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 46/200
 - 314s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 47/200
 - 314s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 48/200
 - 315s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 49/200
 - 314s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 50/200
 - 314s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 51/200
 - 314s - loss: 0.0030 - val_loss: 0.0037
 - val_f1: 0.9905
Epoch 52/200
 - 314s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 53/200
 - 314s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 54/200
 - 314s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9955
Epoch 55/200
 - 314s - loss: 0.0028 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 56/200
 - 314s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 57/200
 - 314s - loss: 0.0029 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 58/200
 - 314s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 59/200
 - 315s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 60/200
 - 314s - loss: 0.0028 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 61/200
 - 314s - loss: 0.0028 - val_loss: 0.0025
2019-12-29 01:31:38,235 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_60.pickle
 - val_f1: 0.9942
Epoch 62/200
 - 314s - loss: 0.0028 - val_loss: 0.0036
 - val_f1: 0.9910
Epoch 63/200
 - 315s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 64/200
 - 314s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 65/200
 - 314s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 66/200
 - 314s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 67/200
 - 314s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 68/200
 - 314s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 69/200
 - 314s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 70/200
 - 314s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 71/200
 - 314s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 72/200
 - 314s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 73/200
 - 314s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 74/200
 - 314s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 75/200
 - 314s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 76/200
 - 315s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 77/200
 - 314s - loss: 0.0027 - val_loss: 0.0035
 - val_f1: 0.9900
Epoch 78/200
 - 314s - loss: 0.0026 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 79/200
 - 314s - loss: 0.0028 - val_loss: 0.0035
 - val_f1: 0.9899
Epoch 80/200
 - 314s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9894
Epoch 81/200
 - 314s - loss: 0.0028 - val_loss: 0.0025
2019-12-29 03:48:40,209 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_80.pickle
 - val_f1: 0.9939
Epoch 82/200
 - 314s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 83/200
 - 314s - loss: 0.0028 - val_loss: 0.0053
 - val_f1: 0.9826
Epoch 84/200
 - 314s - loss: 0.0027 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 85/200
 - 314s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 86/200
 - 314s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 87/200
 - 314s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 88/200
 - 314s - loss: 0.0027 - val_loss: 0.0044
 - val_f1: 0.9901
Epoch 89/200
 - 314s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 90/200
 - 314s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 91/200
 - 315s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 92/200
 - 314s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9946
Epoch 93/200
 - 315s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 94/200
 - 314s - loss: 0.0025 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 95/200
 - 314s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 96/200
 - 314s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 97/200
 - 314s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9950
Epoch 98/200
 - 315s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9951
Epoch 99/200
 - 315s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 100/200
 - 314s - loss: 0.0025 - val_loss: 0.0040
 - val_f1: 0.9895
Epoch 101/200
 - 314s - loss: 0.0024 - val_loss: 0.0023
2019-12-29 06:05:42,913 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_100.pickle
 - val_f1: 0.9947
Epoch 102/200
 - 314s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 103/200
 - 314s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9956
Epoch 104/200
 - 314s - loss: 0.0025 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 105/200
 - 314s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 106/200
 - 315s - loss: 0.0024 - val_loss: 0.0171
 - val_f1: 0.9643
Epoch 107/200
 - 314s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9889
Epoch 108/200
 - 314s - loss: 0.0025 - val_loss: 0.0288
 - val_f1: 0.9639
Epoch 109/200
 - 314s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 110/200
 - 314s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 111/200
 - 314s - loss: 0.0025 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 112/200
 - 314s - loss: 0.0024 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 113/200
 - 314s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 114/200
 - 315s - loss: 0.0024 - val_loss: 0.0028
 - val_f1: 0.9955
Epoch 115/200
 - 314s - loss: 0.0024 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 116/200
 - 314s - loss: 0.0024 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 117/200
 - 314s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 118/200
 - 315s - loss: 0.0024 - val_loss: 0.0042
 - val_f1: 0.9899
Epoch 119/200
 - 314s - loss: 0.0023 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 120/200
 - 315s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 121/200
 - 315s - loss: 0.0024 - val_loss: 0.0025
2019-12-29 08:22:51,092 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_120.pickle
 - val_f1: 0.9942
Epoch 122/200
 - 315s - loss: 0.0023 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 123/200
 - 314s - loss: 0.0023 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 124/200
 - 314s - loss: 0.0023 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 125/200
 - 314s - loss: 0.0023 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 126/200
 - 314s - loss: 0.0023 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 127/200
 - 314s - loss: 0.0023 - val_loss: 0.0029
 - val_f1: 0.9955
Epoch 128/200
 - 314s - loss: 0.0023 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 129/200
 - 314s - loss: 0.0023 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 130/200
 - 314s - loss: 0.0023 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 131/200
 - 314s - loss: 0.0023 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 132/200
 - 314s - loss: 0.0023 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 133/200
 - 314s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 134/200
 - 314s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9949
Epoch 135/200
 - 315s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9954
Epoch 136/200
 - 314s - loss: 0.0023 - val_loss: 0.0019
 - val_f1: 0.9958
Epoch 137/200
 - 314s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 138/200
 - 315s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 139/200
 - 315s - loss: 0.0023 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 140/200
 - 315s - loss: 0.0023 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 141/200
 - 315s - loss: 0.0022 - val_loss: 0.0021
2019-12-29 10:39:55,551 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_140.pickle
 - val_f1: 0.9954
Epoch 142/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9956
Epoch 143/200
 - 315s - loss: 0.0022 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 144/200
 - 315s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 145/200
 - 315s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 146/200
 - 315s - loss: 0.0023 - val_loss: 0.0019
 - val_f1: 0.9963
Epoch 147/200
 - 315s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 148/200
 - 315s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 149/200
 - 315s - loss: 0.0023 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 150/200
 - 314s - loss: 0.0023 - val_loss: 0.0019
 - val_f1: 0.9961
Epoch 151/200
 - 315s - loss: 0.0022 - val_loss: 0.0026
 - val_f1: 0.9956
Epoch 152/200
 - 314s - loss: 0.0023 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 153/200
 - 315s - loss: 0.0023 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 154/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9955
Epoch 155/200
 - 314s - loss: 0.0022 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 156/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 157/200
 - 315s - loss: 0.0022 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 158/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9959
Epoch 159/200
 - 314s - loss: 0.0022 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 160/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 161/200
 - 315s - loss: 0.0022 - val_loss: 0.0031
2019-12-29 12:57:08,335 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_160.pickle
 - val_f1: 0.9933
Epoch 162/200
 - 315s - loss: 0.0022 - val_loss: 0.0021
 - val_f1: 0.9949
Epoch 163/200
 - 314s - loss: 0.0022 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 164/200
 - 314s - loss: 0.0022 - val_loss: 0.0019
 - val_f1: 0.9962
Epoch 165/200
 - 315s - loss: 0.0022 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 166/200
 - 314s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 167/200
 - 315s - loss: 0.0022 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 168/200
 - 314s - loss: 0.0021 - val_loss: 0.0020
 - val_f1: 0.9959
Epoch 169/200
 - 315s - loss: 0.0022 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 170/200
 - 315s - loss: 0.0022 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 171/200
 - 314s - loss: 0.0022 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 172/200
 - 314s - loss: 0.0022 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 173/200
 - 314s - loss: 0.0021 - val_loss: 0.0018
 - val_f1: 0.9963
Epoch 174/200
 - 314s - loss: 0.0021 - val_loss: 0.0021
 - val_f1: 0.9952
Epoch 175/200
 - 315s - loss: 0.0021 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 176/200
 - 315s - loss: 0.0022 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 177/200
 - 315s - loss: 0.0023 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 178/200
 - 314s - loss: 0.0023 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 179/200
 - 314s - loss: 0.0022 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 180/200
 - 315s - loss: 0.0022 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 181/200
 - 314s - loss: 0.0022 - val_loss: 0.0030
2019-12-29 15:14:17,142 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_180.pickle
 - val_f1: 0.9949
Epoch 182/200
 - 314s - loss: 0.0022 - val_loss: 0.0021
 - val_f1: 0.9953
Epoch 183/200
 - 315s - loss: 0.0023 - val_loss: 0.0021
 - val_f1: 0.9957
Epoch 184/200
 - 315s - loss: 0.0022 - val_loss: 0.0019
 - val_f1: 0.9960
Epoch 185/200
 - 315s - loss: 0.0023 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 186/200
 - 315s - loss: 0.0023 - val_loss: 0.0019
 - val_f1: 0.9960
Epoch 187/200
 - 315s - loss: 0.0023 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 188/200
 - 315s - loss: 0.0022 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 189/200
 - 315s - loss: 0.0022 - val_loss: 0.0019
 - val_f1: 0.9958
Epoch 190/200
 - 315s - loss: 0.0023 - val_loss: 0.0022
 - val_f1: 0.9948
Epoch 191/200
 - 315s - loss: 0.0022 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 192/200
 - 315s - loss: 0.0022 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 193/200
 - 315s - loss: 0.0022 - val_loss: 0.0019
 - val_f1: 0.9956
Epoch 194/200
 - 315s - loss: 0.0022 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 195/200
 - 315s - loss: 0.0022 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 196/200
 - 315s - loss: 0.0022 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 197/200
 - 315s - loss: 0.0023 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 198/200
 - 315s - loss: 0.0022 - val_loss: 0.0019
 - val_f1: 0.9961
Epoch 199/200
 - 315s - loss: 0.0023 - val_loss: 0.0020
 - val_f1: 0.9959
Epoch 200/200
 - 315s - loss: 0.0022 - val_loss: 0.0023
2019-12-29 17:26:15,588 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-29 17:33:00,131 [INFO] Last epoch loss evaluation: train_loss = 0.001750, val_loss = 0.001841
2019-12-29 17:33:00,131 [INFO] Training complete. time_to_train = 82722.95 sec, 1378.72 min
2019-12-29 17:33:00,185 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_10/best_model.pickle
2019-12-29 17:33:00,188 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_10/training_error_history.csv
2019-12-29 17:33:00,378 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_10/training_error_history.png
2019-12-29 17:33:00,565 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_10/training_f1_history.png
2019-12-29 17:33:00,565 [INFO] Making predictions on training, validation, testing data
2019-12-29 17:41:11,417 [INFO] Evaluating predictions (results)
2019-12-29 17:41:21,564 [INFO] Dataset: Testing. Classification report below
2019-12-29 17:41:21,564 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       1.00      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.99      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       1.00      0.99      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       0.90      0.15      0.26       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.79      0.81    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-29 17:41:21,564 [INFO] Overall accuracy (micro avg): 0.9966776410013403
2019-12-29 17:41:33,111 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9967         0.9967                       0.9967                0.0003                   0.0033  0.9967
1     Macro avg        0.9994         0.8925                       0.7904                0.0008                   0.2096  0.8078
2  Weighted avg        0.9973         0.9964                       0.9967                0.0059                   0.0033  0.9963
2019-12-29 17:41:43,428 [INFO] Dataset: Validation. Classification report below
2019-12-29 17:41:43,429 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.99      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.75      0.14      0.24       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-29 17:41:43,429 [INFO] Overall accuracy (micro avg): 0.996656423168459
2019-12-29 17:41:55,133 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9967         0.9967                       0.9967                0.0003                   0.0033  0.9967
1     Macro avg        0.9994         0.8792                       0.7862                0.0008                   0.2138  0.8031
2  Weighted avg        0.9973         0.9964                       0.9967                0.0059                   0.0033  0.9963
2019-12-29 17:42:29,361 [INFO] Dataset: Training. Classification report below
2019-12-29 17:42:29,361 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       1.00      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.99      1.00      0.99    138074
      DoS Slowhttptest       0.91      0.99      0.95      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.99      0.98      3538
Web Attack Brute Force       0.89      0.13      0.23       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.79      0.81   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-29 17:42:29,361 [INFO] Overall accuracy (micro avg): 0.9967678129810854
2019-12-29 17:43:08,227 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9968         0.9968                       0.9968                0.0003                   0.0032  0.9968
1     Macro avg        0.9995         0.8934                       0.7883                0.0008                   0.2117  0.8058
2  Weighted avg        0.9974         0.9965                       0.9968                0.0058                   0.0032  0.9964
2019-12-29 17:43:08,279 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_10/ann_depth_ids17_layers_10_results.xlsx
2019-12-29 17:43:08,283 [INFO] ================= Finished running experiment no. 10 ================= 

2019-12-29 17:43:08,344 [INFO] ================= Finished running 20 experiments ================= 

 - val_f1: 0.9944
Using TensorFlow backend.
2019-12-30 16:33:52,881 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_1/run_log.log
2019-12-30 16:33:52,881 [INFO] ================= Running experiment no. 1  ================= 

2019-12-30 16:33:52,881 [INFO] Experiment parameters given below
2019-12-30 16:33:52,881 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_1'}
2019-12-30 16:33:52,882 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_1/tf_logs_run_2019_12_30-16_33_52
2019-12-30 16:33:52,882 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-30 16:33:52,882 [INFO] Reading X, y files
2019-12-30 16:33:52,883 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-30 16:33:57,900 [INFO] Reading complete. time_to_read=5.02 seconds
2019-12-30 16:33:57,900 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-30 16:33:59,436 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-30 16:33:59,436 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-30 16:34:01,040 [INFO] Reading complete. time_to_read=1.60 seconds
2019-12-30 16:34:01,040 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-30 16:34:01,529 [INFO] Reading complete. time_to_read=0.49 seconds
2019-12-30 16:34:01,530 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-30 16:34:01,711 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-30 16:34:01,712 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-30 16:34:01,888 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-30 16:34:05,825 [INFO] Initializing model
2019-12-30 16:34:05,826 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-30 16:34:05,872 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-30 16:34:05,874 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-30 16:34:05,932 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-30 16:34:05,947 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-30 16:34:05,966 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-30 16:34:05,980 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-30 16:34:05,982 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-30 16:34:05,993 [INFO] _________________________________________________________________
2019-12-30 16:34:05,993 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 16:34:05,993 [INFO] =================================================================
2019-12-30 16:34:05,993 [INFO] dense_1 (Dense)              (None, 16)                1248      
2019-12-30 16:34:05,993 [INFO] _________________________________________________________________
2019-12-30 16:34:05,993 [INFO] batch_normalization_1 (Batch (None, 16)                64        
2019-12-30 16:34:05,993 [INFO] _________________________________________________________________
2019-12-30 16:34:05,993 [INFO] dropout_1 (Dropout)          (None, 16)                0         
2019-12-30 16:34:05,993 [INFO] _________________________________________________________________
2019-12-30 16:34:05,993 [INFO] dense_2 (Dense)              (None, 15)                255       
2019-12-30 16:34:05,994 [INFO] =================================================================
2019-12-30 16:34:05,994 [INFO] Total params: 1,567
2019-12-30 16:34:05,994 [INFO] Trainable params: 1,535
2019-12-30 16:34:05,994 [INFO] Non-trainable params: 32
2019-12-30 16:34:05,994 [INFO] _________________________________________________________________
2019-12-30 16:34:05,994 [INFO] Training model
2019-12-30 16:34:08.564917: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-30 16:34:08.748994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2019-12-30 16:34:08.749322: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5634a48250d0 executing computations on platform Host. Devices:
2019-12-30 16:34:08.749356: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-30 16:34:08.876274: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-30 16:34:08,880 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-30 16:34:08,880 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 19s - loss: 0.0211 - val_loss: 0.0094
 - val_f1: 0.9767
Epoch 2/200
 - 20s - loss: 0.0103 - val_loss: 0.0089
 - val_f1: 0.9773
Epoch 3/200
 - 20s - loss: 0.0099 - val_loss: 0.1071
 - val_f1: 0.8038
Epoch 4/200
 - 20s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 5/200
 - 20s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9774
Epoch 6/200
 - 20s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9752
Epoch 7/200
 - 20s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 8/200
 - 20s - loss: 0.0094 - val_loss: 0.0204
 - val_f1: 0.9180
Epoch 9/200
 - 20s - loss: 0.0094 - val_loss: 0.1423
 - val_f1: 0.7645
Epoch 10/200
 - 20s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 11/200
 - 20s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 12/200
 - 20s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 13/200
 - 20s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9759
Epoch 14/200
 - 20s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9749
Epoch 15/200
 - 20s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 16/200
 - 20s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9754
Epoch 17/200
 - 20s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 18/200
 - 20s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 19/200
 - 20s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 20/200
 - 20s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 21/200
 - 20s - loss: 0.0091 - val_loss: 0.0085
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 16:43:20,781 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_20.pickle
 - val_f1: 0.9772
Epoch 22/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 23/200
 - 20s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 24/200
 - 20s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 25/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 26/200
 - 20s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9751
Epoch 27/200
 - 20s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9773
Epoch 28/200
 - 20s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 29/200
 - 20s - loss: 0.0091 - val_loss: 0.0774
 - val_f1: 0.8468
Epoch 30/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 31/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 32/200
 - 20s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 33/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 34/200
 - 20s - loss: 0.0091 - val_loss: 0.1207
 - val_f1: 0.8079
Epoch 35/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 36/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 37/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 38/200
 - 20s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 39/200
 - 20s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 40/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 41/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
2019-12-30 16:52:12,743 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_40.pickle
 - val_f1: 0.9774
Epoch 42/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 43/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 44/200
 - 20s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 45/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 46/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 47/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 48/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 49/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 50/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 51/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 52/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 53/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 54/200
 - 20s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9764
Epoch 55/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9760
Epoch 56/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 57/200
 - 20s - loss: 0.0090 - val_loss: 0.1622
 - val_f1: 0.7687
Epoch 58/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 59/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 60/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 61/200
 - 20s - loss: 0.0090 - val_loss: 0.0084
2019-12-30 17:01:05,768 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_60.pickle
 - val_f1: 0.9776
Epoch 62/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 63/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 64/200
 - 20s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 65/200
 - 20s - loss: 0.0090 - val_loss: 0.1479
 - val_f1: 0.7634
Epoch 66/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 67/200
 - 20s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 68/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 69/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 70/200
 - 20s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 71/200
 - 20s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9741
Epoch 72/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 73/200
 - 20s - loss: 0.0090 - val_loss: 0.1456
 - val_f1: 0.7645
Epoch 74/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 75/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 76/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 77/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 78/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 79/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 80/200
 - 20s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 81/200
 - 20s - loss: 0.0090 - val_loss: 0.1450
2019-12-30 17:09:58,249 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_80.pickle
 - val_f1: 0.7631
Epoch 82/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 83/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 84/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 85/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 86/200
 - 20s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 87/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 88/200
 - 20s - loss: 0.0090 - val_loss: 0.0376
 - val_f1: 0.8760
Epoch 89/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 90/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 91/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 92/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9753
Epoch 93/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 94/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9759
Epoch 95/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 96/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 97/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 98/200
 - 20s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 99/200
 - 20s - loss: 0.0089 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 100/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 101/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
2019-12-30 17:18:51,421 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_100.pickle
 - val_f1: 0.9776
Epoch 102/200
 - 20s - loss: 0.0089 - val_loss: 0.1329
 - val_f1: 0.8092
Epoch 103/200
 - 20s - loss: 0.0089 - val_loss: 0.0099
 - val_f1: 0.9739
Epoch 104/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 105/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 106/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 107/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 108/200
 - 20s - loss: 0.0089 - val_loss: 0.1045
 - val_f1: 0.8404
Epoch 109/200
 - 20s - loss: 0.0089 - val_loss: 0.1288
 - val_f1: 0.8103
Epoch 110/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 111/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 112/200
 - 20s - loss: 0.0089 - val_loss: 0.1299
 - val_f1: 0.8055
Epoch 113/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 114/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 115/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 116/200
 - 20s - loss: 0.0089 - val_loss: 0.1240
 - val_f1: 0.8083
Epoch 117/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 118/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 119/200
 - 20s - loss: 0.0089 - val_loss: 0.1274
 - val_f1: 0.8085
Epoch 120/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 121/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
2019-12-30 17:27:42,953 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_120.pickle
 - val_f1: 0.9776
Epoch 122/200
 - 20s - loss: 0.0089 - val_loss: 0.0274
 - val_f1: 0.8768
Epoch 123/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 124/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 125/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 126/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 127/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 128/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 129/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 130/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 131/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 132/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 133/200
 - 20s - loss: 0.0089 - val_loss: 0.1349
 - val_f1: 0.8094
Epoch 134/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 135/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 136/200
 - 20s - loss: 0.0088 - val_loss: 0.1236
 - val_f1: 0.8104
Epoch 137/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 138/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 139/200
 - 20s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 140/200
 - 20s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 141/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
2019-12-30 17:36:37,581 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_140.pickle
 - val_f1: 0.9776
Epoch 142/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 143/200
 - 20s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 144/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 145/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 146/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 147/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 148/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 149/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 150/200
 - 20s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 151/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 152/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 153/200
 - 20s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 154/200
 - 20s - loss: 0.0089 - val_loss: 0.1389
 - val_f1: 0.8009
Epoch 155/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 156/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 157/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 158/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 159/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 160/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 161/200
 - 20s - loss: 0.0088 - val_loss: 0.0084
2019-12-30 17:45:28,995 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_160.pickle
 - val_f1: 0.9776
Epoch 162/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 163/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 164/200
 - 20s - loss: 0.0088 - val_loss: 0.1431
 - val_f1: 0.8013
Epoch 165/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 166/200
 - 20s - loss: 0.0088 - val_loss: 0.1415
 - val_f1: 0.8084
Epoch 167/200
 - 20s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 168/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 169/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 170/200
 - 20s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 171/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 172/200
 - 20s - loss: 0.0088 - val_loss: 0.0502
 - val_f1: 0.8664
Epoch 173/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 174/200
 - 20s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 175/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 176/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 177/200
 - 20s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9771
Epoch 178/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 179/200
 - 20s - loss: 0.0088 - val_loss: 0.1432
 - val_f1: 0.8078
Epoch 180/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 181/200
 - 19s - loss: 0.0088 - val_loss: 0.0082
2019-12-30 17:54:17,983 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_180.pickle
 - val_f1: 0.9776
Epoch 182/200
 - 19s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 183/200
 - 20s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 184/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 185/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 186/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 187/200
 - 19s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 188/200
 - 20s - loss: 0.0088 - val_loss: 0.0087
 - val_f1: 0.9767
Epoch 189/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 190/200
 - 19s - loss: 0.0088 - val_loss: 0.1394
 - val_f1: 0.8016
Epoch 191/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 192/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 193/200
 - 20s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 194/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 195/200
 - 20s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 196/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 197/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 198/200
 - 20s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 199/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 200/200
 - 20s - loss: 0.0088 - val_loss: 0.0082
2019-12-30 18:02:42,698 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 18:03:20,089 [INFO] Last epoch loss evaluation: train_loss = 0.008121, val_loss = 0.008117
2019-12-30 18:03:20,089 [INFO] Training complete. time_to_train = 5354.10 sec, 89.23 min
2019-12-30 18:03:20,093 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/best_model.pickle
2019-12-30 18:03:20,107 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_error_history.csv
2019-12-30 18:03:20,311 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_error_history.png
2019-12-30 18:03:20,443 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_f1_history.png
2019-12-30 18:03:20,443 [INFO] Making predictions on training, validation, testing data
2019-12-30 18:03:49,389 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 18:04:01,577 [INFO] Dataset: Testing. Classification report below
2019-12-30 18:04:01,577 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.00      0.00      0.00        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.64      0.55      0.59      5596
   DoS attacks-Slowloris       0.99      0.72      0.84       440
          FTP-BruteForce       0.70      0.78      0.74      7718
           Infilteration       0.51      0.01      0.01      6404
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.79      0.64      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-30 18:04:01,577 [INFO] Overall accuracy (micro avg): 0.9825837196043923
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-30 18:04:15,377 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9826         0.9826                       0.9826                0.0012                   0.0174  0.9826
1     Macro avg        0.9977         0.7875                       0.6422                0.0046                   0.3578  0.6705
2  Weighted avg        0.9907         0.9777                       0.9826                0.0510                   0.0174  0.9776
2019-12-30 18:04:27,511 [INFO] Dataset: Validation. Classification report below
2019-12-30 18:04:27,511 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.00      0.00      0.00        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.65      0.54      0.59      5596
   DoS attacks-Slowloris       0.99      0.77      0.86       439
          FTP-BruteForce       0.70      0.79      0.74      7718
           Infilteration       0.36      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.71      0.65      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-30 18:04:27,511 [INFO] Overall accuracy (micro avg): 0.9826410136842415
2019-12-30 18:04:41,293 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9826         0.9826                       0.9826                0.0012                   0.0174  0.9826
1     Macro avg        0.9977         0.7109                       0.6504                0.0045                   0.3496  0.6655
2  Weighted avg        0.9908         0.9763                       0.9826                0.0507                   0.0174  0.9776
2019-12-30 18:05:20,817 [INFO] Dataset: Training. Classification report below
2019-12-30 18:05:20,817 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.46      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       1.00      0.01      0.02       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.64      0.54      0.59     16787
   DoS attacks-Slowloris       1.00      0.76      0.86      1318
          FTP-BruteForce       0.70      0.78      0.74     23153
           Infilteration       0.46      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.78      0.64      0.66   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-30 18:05:20,817 [INFO] Overall accuracy (micro avg): 0.9825831852109672
2019-12-30 18:06:05,722 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9826         0.9826                       0.9826                0.0012                   0.0174  0.9826
1     Macro avg        0.9977         0.7840                       0.6367                0.0046                   0.3633  0.6552
2  Weighted avg        0.9908         0.9773                       0.9826                0.0509                   0.0174  0.9776
2019-12-30 18:06:05,767 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/ann_depth_ids18_subset_layers_1_results.xlsx
2019-12-30 18:06:05,774 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-30 18:06:05,856 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_2
2019-12-30 18:06:05,856 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_2/run_log.log
2019-12-30 18:06:05,856 [INFO] ================= Running experiment no. 2  ================= 

2019-12-30 18:06:05,856 [INFO] Experiment parameters given below
2019-12-30 18:06:05,856 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_2'}
2019-12-30 18:06:05,856 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_2/tf_logs_run_2019_12_30-18_06_05
2019-12-30 18:06:05,856 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-30 18:06:05,857 [INFO] Reading X, y files
2019-12-30 18:06:05,857 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-30 18:06:10,303 [INFO] Reading complete. time_to_read=4.45 seconds
2019-12-30 18:06:10,303 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-30 18:06:11,836 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 18:06:11,836 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-30 18:06:13,362 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 18:06:13,362 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-30 18:06:13,618 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-30 18:06:13,618 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-30 18:06:13,702 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 18:06:13,702 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-30 18:06:13,786 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 18:06:17,687 [INFO] Initializing model
2019-12-30 18:06:17,959 [INFO] _________________________________________________________________
2019-12-30 18:06:17,959 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 18:06:17,959 [INFO] =================================================================
2019-12-30 18:06:17,960 [INFO] dense_3 (Dense)              (None, 32)                2496      
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] dense_4 (Dense)              (None, 16)                528       
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] batch_normalization_3 (Batch (None, 16)                64        
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] dropout_3 (Dropout)          (None, 16)                0         
2019-12-30 18:06:17,960 [INFO] _________________________________________________________________
2019-12-30 18:06:17,960 [INFO] dense_5 (Dense)              (None, 15)                255       
2019-12-30 18:06:17,960 [INFO] =================================================================
2019-12-30 18:06:17,960 [INFO] Total params: 3,471
2019-12-30 18:06:17,960 [INFO] Trainable params: 3,375
2019-12-30 18:06:17,961 [INFO] Non-trainable params: 96
2019-12-30 18:06:17,961 [INFO] _________________________________________________________________
2019-12-30 18:06:17,961 [INFO] Training model
 - val_f1: 0.9775
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 22s - loss: 0.0188 - val_loss: 0.0088
 - val_f1: 0.9753
Epoch 2/200
 - 23s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9748
Epoch 3/200
 - 23s - loss: 0.0095 - val_loss: 0.1357
 - val_f1: 0.7534
Epoch 4/200
 - 23s - loss: 0.0093 - val_loss: 0.0088
 - val_f1: 0.9769
Epoch 5/200
 - 23s - loss: 0.0092 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 6/200
 - 23s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 7/200
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 8/200
 - 23s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 9/200
 - 23s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9770
Epoch 10/200
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 11/200
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 12/200
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 13/200
 - 23s - loss: 0.0088 - val_loss: 0.1526
 - val_f1: 0.7534
Epoch 14/200
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 15/200
 - 22s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 16/200
 - 23s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 17/200
 - 23s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 18/200
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 19/200
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 20/200
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 21/200
 - 23s - loss: 0.0087 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 18:17:29,222 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_20.pickle
 - val_f1: 0.9777
Epoch 22/200
 - 22s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 23/200
 - 22s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 24/200
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 25/200
 - 22s - loss: 0.0087 - val_loss: 0.1473
 - val_f1: 0.7536
Epoch 26/200
 - 22s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 27/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 28/200
 - 22s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 29/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 30/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 31/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 32/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 33/200
 - 22s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 34/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 35/200
 - 22s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 36/200
 - 22s - loss: 0.0086 - val_loss: 0.1601
 - val_f1: 0.7535
Epoch 37/200
 - 22s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 38/200
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 39/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 40/200
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 41/200
 - 22s - loss: 0.0086 - val_loss: 0.0082
2019-12-30 18:28:05,285 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_40.pickle
 - val_f1: 0.9773
Epoch 42/200
 - 22s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 43/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 44/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 45/200
 - 22s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 46/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 47/200
 - 22s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 48/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 49/200
 - 22s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 50/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 51/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 52/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 53/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9762
Epoch 54/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 55/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 56/200
 - 22s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 57/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 58/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 59/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 60/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 61/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
2019-12-30 18:38:40,688 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_60.pickle
 - val_f1: 0.9777
Epoch 62/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 63/200
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 64/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 65/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 66/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 67/200
 - 22s - loss: 0.0085 - val_loss: 0.1127
 - val_f1: 0.7552
Epoch 68/200
 - 22s - loss: 0.0085 - val_loss: 0.1288
 - val_f1: 0.7547
Epoch 69/200
 - 22s - loss: 0.0085 - val_loss: 0.1190
 - val_f1: 0.7550
Epoch 70/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 71/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 72/200
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 73/200
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 74/200
 - 22s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 75/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 76/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 77/200
 - 23s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 78/200
 - 23s - loss: 0.0085 - val_loss: 0.1208
 - val_f1: 0.7537
Epoch 79/200
 - 22s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 80/200
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 81/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
2019-12-30 18:49:17,448 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_80.pickle
 - val_f1: 0.9777
Epoch 82/200
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 83/200
 - 22s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 84/200
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 85/200
 - 23s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9769
Epoch 86/200
 - 22s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9767
Epoch 87/200
 - 23s - loss: 0.0085 - val_loss: 0.0081
2019-12-30 18:52:38,689 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 18:53:24,459 [INFO] Last epoch loss evaluation: train_loss = 0.007922, val_loss = 0.007923
2019-12-30 18:53:24,459 [INFO] Training complete. time_to_train = 2826.50 sec, 47.11 min
2019-12-30 18:53:24,464 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/best_model.pickle
2019-12-30 18:53:24,466 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_error_history.csv
2019-12-30 18:53:24,602 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_error_history.png
2019-12-30 18:53:24,715 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_f1_history.png
2019-12-30 18:53:24,716 [INFO] Making predictions on training, validation, testing data
2019-12-30 18:54:08,764 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 18:54:20,915 [INFO] Dataset: Testing. Classification report below
2019-12-30 18:54:20,915 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.93      0.96      0.94       440
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.67      0.68      0.67    645488
            weighted avg       0.97      0.98      0.98    645488

2019-12-30 18:54:20,915 [INFO] Overall accuracy (micro avg): 0.9831522816845549
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-30 18:54:34,729 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6674                       0.6848                0.0045                   0.3152  0.6702
2  Weighted avg        0.9909         0.9736                       0.9832                0.0503                   0.0168  0.9778
2019-12-30 18:54:46,856 [INFO] Dataset: Validation. Classification report below
2019-12-30 18:54:46,857 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.73      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.93      0.96      0.94       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.68      0.67    645487
            weighted avg       0.97      0.98      0.98    645487

2019-12-30 18:54:46,857 [INFO] Overall accuracy (micro avg): 0.9832637992709381
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-30 18:55:00,650 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.6722                       0.6845                0.0045                   0.3155  0.6728
2  Weighted avg        0.9909         0.9737                       0.9833                0.0503                   0.0167  0.9779
2019-12-30 18:55:40,233 [INFO] Dataset: Training. Classification report below
2019-12-30 18:55:40,234 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.94      0.98      0.96      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.67      0.69      0.67   1936462
            weighted avg       0.97      0.98      0.98   1936462

2019-12-30 18:55:40,234 [INFO] Overall accuracy (micro avg): 0.9832183642126724
2019-12-30 18:56:25,183 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6709                       0.6863                0.0045                   0.3137  0.6729
2  Weighted avg        0.9910         0.9737                       0.9832                0.0502                   0.0168  0.9778
2019-12-30 18:56:25,219 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/ann_depth_ids18_subset_layers_2_results.xlsx
2019-12-30 18:56:25,224 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-30 18:56:25,304 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_3
2019-12-30 18:56:25,304 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_3/run_log.log
2019-12-30 18:56:25,304 [INFO] ================= Running experiment no. 3  ================= 

2019-12-30 18:56:25,304 [INFO] Experiment parameters given below
2019-12-30 18:56:25,304 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_3'}
2019-12-30 18:56:25,304 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_3/tf_logs_run_2019_12_30-18_56_25
2019-12-30 18:56:25,304 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-30 18:56:25,305 [INFO] Reading X, y files
2019-12-30 18:56:25,305 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-30 18:56:29,746 [INFO] Reading complete. time_to_read=4.44 seconds
2019-12-30 18:56:29,746 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-30 18:56:31,281 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 18:56:31,281 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-30 18:56:32,813 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 18:56:32,813 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-30 18:56:33,063 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-30 18:56:33,063 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-30 18:56:33,148 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 18:56:33,148 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-30 18:56:33,233 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 18:56:37,104 [INFO] Initializing model
2019-12-30 18:56:37,460 [INFO] _________________________________________________________________
2019-12-30 18:56:37,460 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 18:56:37,460 [INFO] =================================================================
2019-12-30 18:56:37,460 [INFO] dense_6 (Dense)              (None, 64)                4992      
2019-12-30 18:56:37,460 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dense_7 (Dense)              (None, 32)                2080      
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dense_8 (Dense)              (None, 16)                528       
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] batch_normalization_6 (Batch (None, 16)                64        
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dropout_6 (Dropout)          (None, 16)                0         
2019-12-30 18:56:37,461 [INFO] _________________________________________________________________
2019-12-30 18:56:37,461 [INFO] dense_9 (Dense)              (None, 15)                255       
2019-12-30 18:56:37,462 [INFO] =================================================================
2019-12-30 18:56:37,462 [INFO] Total params: 8,303
2019-12-30 18:56:37,462 [INFO] Trainable params: 8,079
2019-12-30 18:56:37,462 [INFO] Non-trainable params: 224
2019-12-30 18:56:37,462 [INFO] _________________________________________________________________
2019-12-30 18:56:37,462 [INFO] Training model
 - val_f1: 0.9775
Epoch 00087: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 27s - loss: 0.0174 - val_loss: 0.0093
 - val_f1: 0.9757
Epoch 2/200
 - 27s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 3/200
 - 27s - loss: 0.0092 - val_loss: 0.0908
 - val_f1: 0.7620
Epoch 4/200
 - 27s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 5/200
 - 28s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 6/200
 - 28s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 7/200
 - 28s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 8/200
 - 28s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 9/200
 - 28s - loss: 0.0086 - val_loss: 0.0707
 - val_f1: 0.7640
Epoch 10/200
 - 28s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 11/200
 - 28s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 12/200
 - 28s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 13/200
 - 28s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 14/200
 - 28s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 15/200
 - 28s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 16/200
 - 28s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 17/200
 - 28s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 18/200
 - 28s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 19/200
 - 28s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 20/200
 - 28s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 21/200
 - 28s - loss: 0.0083 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 19:09:51,616 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_20.pickle
 - val_f1: 0.9779
Epoch 22/200
 - 28s - loss: 0.0083 - val_loss: 0.0869
 - val_f1: 0.7562
Epoch 23/200
 - 28s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 24/200
 - 28s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 25/200
 - 28s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 26/200
 - 28s - loss: 0.0083 - val_loss: 0.0845
 - val_f1: 0.7627
Epoch 27/200
 - 28s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 28/200
 - 28s - loss: 0.0083 - val_loss: 0.0841
 - val_f1: 0.7611
Epoch 29/200
 - 28s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 30/200
 - 28s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 31/200
 - 28s - loss: 0.0083 - val_loss: 0.0239
 - val_f1: 0.9180
Epoch 32/200
 - 28s - loss: 0.0083 - val_loss: 0.0646
 - val_f1: 0.7663
Epoch 33/200
 - 28s - loss: 0.0083 - val_loss: 0.0742
 - val_f1: 0.7837
Epoch 34/200
 - 28s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 35/200
 - 28s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 36/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 37/200
 - 28s - loss: 0.0083 - val_loss: 0.0956
 - val_f1: 0.7618
Epoch 38/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 39/200
 - 28s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 40/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 41/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
2019-12-30 19:22:40,217 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_40.pickle
 - val_f1: 0.9780
Epoch 42/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 43/200
 - 28s - loss: 0.0082 - val_loss: 0.0742
 - val_f1: 0.7612
Epoch 44/200
 - 28s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 45/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 46/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 47/200
 - 28s - loss: 0.0082 - val_loss: 0.0724
 - val_f1: 0.7615
Epoch 48/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 49/200
 - 28s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9772
Epoch 50/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 51/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 52/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 53/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 54/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 55/200
 - 28s - loss: 0.0082 - val_loss: 0.0970
 - val_f1: 0.7531
Epoch 56/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 57/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 58/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 59/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 60/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 61/200
 - 28s - loss: 0.0082 - val_loss: 0.0940
2019-12-30 19:35:31,863 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_60.pickle
 - val_f1: 0.7610
Epoch 62/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 63/200
 - 28s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 64/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 65/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 66/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 67/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 68/200
 - 28s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 69/200
 - 28s - loss: 0.0082 - val_loss: 0.0923
 - val_f1: 0.7606
Epoch 70/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 71/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 72/200
 - 28s - loss: 0.0082 - val_loss: 0.0117
 - val_f1: 0.9650
Epoch 73/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 74/200
 - 28s - loss: 0.0081 - val_loss: 0.1032
 - val_f1: 0.7609
Epoch 75/200
 - 28s - loss: 0.0082 - val_loss: 0.0751
 - val_f1: 0.7630
Epoch 76/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 77/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 78/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 79/200
 - 28s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 80/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 81/200
 - 28s - loss: 0.0082 - val_loss: 0.0326
2019-12-30 19:48:22,984 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_80.pickle
 - val_f1: 0.8562
Epoch 82/200
 - 28s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 83/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 84/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 85/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 86/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 87/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 88/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 89/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 90/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 91/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 92/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 93/200
 - 28s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9773
Epoch 94/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 95/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 96/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 97/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 98/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 99/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 100/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 101/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
2019-12-30 20:01:14,462 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_100.pickle
 - val_f1: 0.9781
Epoch 102/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 103/200
 - 28s - loss: 0.0081 - val_loss: 0.0891
 - val_f1: 0.7609
Epoch 104/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 105/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 106/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 107/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 108/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 109/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 110/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 111/200
 - 28s - loss: 0.0081 - val_loss: 0.0786
 - val_f1: 0.7548
Epoch 112/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 113/200
 - 28s - loss: 0.0081 - val_loss: 0.0235
 - val_f1: 0.8839
Epoch 114/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 115/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 116/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 117/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 118/200
 - 28s - loss: 0.0081 - val_loss: 0.0856
 - val_f1: 0.7528
Epoch 119/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 120/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 121/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
2019-12-30 20:14:05,985 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_120.pickle
 - val_f1: 0.9781
Epoch 122/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 123/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 124/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 125/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 126/200
 - 28s - loss: 0.0081 - val_loss: 0.1023
 - val_f1: 0.7606
Epoch 127/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 128/200
 - 28s - loss: 0.0081 - val_loss: 0.0657
 - val_f1: 0.8113
Epoch 129/200
 - 28s - loss: 0.0081 - val_loss: 0.0554
 - val_f1: 0.8198
Epoch 130/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 131/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 132/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 133/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 134/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 135/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 136/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 137/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 138/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 139/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 140/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 141/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
2019-12-30 20:26:58,392 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_140.pickle
 - val_f1: 0.9781
Epoch 142/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 143/200
 - 28s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9772
Epoch 144/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 145/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 146/200
 - 28s - loss: 0.0081 - val_loss: 0.0222
 - val_f1: 0.9219
Epoch 147/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 148/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 149/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 150/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 151/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 152/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 153/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 154/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 155/200
 - 28s - loss: 0.0081 - val_loss: 0.0769
 - val_f1: 0.7614
Epoch 156/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 157/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 158/200
 - 28s - loss: 0.0081 - val_loss: 0.0830
 - val_f1: 0.7535
Epoch 159/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 160/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 161/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
2019-12-30 20:39:50,753 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_160.pickle
 - val_f1: 0.9780
Epoch 162/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 163/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 164/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 165/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 166/200
 - 28s - loss: 0.0081 - val_loss: 0.0948
 - val_f1: 0.7613
Epoch 167/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 168/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 169/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 170/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 171/200
 - 28s - loss: 0.0081 - val_loss: 0.0636
 - val_f1: 0.7894
Epoch 172/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 173/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 174/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 175/200
 - 28s - loss: 0.0081 - val_loss: 0.0632
 - val_f1: 0.7615
Epoch 176/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 177/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 178/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 179/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 180/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 181/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
2019-12-30 20:52:43,285 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_180.pickle
 - val_f1: 0.9781
Epoch 182/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 183/200
 - 28s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9716
Epoch 184/200
 - 28s - loss: 0.0081 - val_loss: 0.0404
 - val_f1: 0.8159
Epoch 185/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 186/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 187/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 188/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9772
Epoch 189/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 190/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 191/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 192/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 193/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 194/200
 - 28s - loss: 0.0081 - val_loss: 0.0841
 - val_f1: 0.7617
Epoch 195/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 196/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 197/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 198/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9774
Epoch 199/200
 - 28s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 200/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
2019-12-30 21:05:05,664 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 21:05:54,021 [INFO] Last epoch loss evaluation: train_loss = 0.007710, val_loss = 0.007724
2019-12-30 21:05:54,021 [INFO] Training complete. time_to_train = 7756.56 sec, 129.28 min
2019-12-30 21:05:54,027 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/best_model.pickle
2019-12-30 21:05:54,030 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_error_history.csv
2019-12-30 21:05:54,176 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_error_history.png
2019-12-30 21:05:54,319 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_f1_history.png
2019-12-30 21:05:54,319 [INFO] Making predictions on training, validation, testing data
2019-12-30 21:06:43,574 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 21:06:55,730 [INFO] Dataset: Testing. Classification report below
2019-12-30 21:06:55,730 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       440
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.44      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.77      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-30 21:06:55,731 [INFO] Overall accuracy (micro avg): 0.9832560791215329
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-30 21:07:09,536 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7671                       0.7087                0.0044                   0.2913  0.7075
2  Weighted avg        0.9910         0.9782                       0.9833                0.0493                   0.0167  0.9781
2019-12-30 21:07:21,700 [INFO] Dataset: Validation. Classification report below
2019-12-30 21:07:21,700 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.85        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.41      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.73      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-30 21:07:21,700 [INFO] Overall accuracy (micro avg): 0.9833877367011264
2019-12-30 21:07:35,517 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7698                       0.7310                0.0044                   0.2690  0.7301
2  Weighted avg        0.9910         0.9781                       0.9834                0.0492                   0.0166  0.9782
2019-12-30 21:08:15,255 [INFO] Dataset: Training. Classification report below
2019-12-30 21:08:15,255 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.46      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.69      0.90      0.78     23153
           Infilteration       0.48      0.01      0.03     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.77      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-30 21:08:15,255 [INFO] Overall accuracy (micro avg): 0.9833490148528605
2019-12-30 21:09:00,368 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7725                       0.7177                0.0044                   0.2823  0.7181
2  Weighted avg        0.9911         0.9787                       0.9833                0.0492                   0.0167  0.9782
2019-12-30 21:09:00,394 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/ann_depth_ids18_subset_layers_3_results.xlsx
2019-12-30 21:09:00,399 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-30 21:09:00,479 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_4
2019-12-30 21:09:00,479 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_4/run_log.log
2019-12-30 21:09:00,479 [INFO] ================= Running experiment no. 4  ================= 

2019-12-30 21:09:00,479 [INFO] Experiment parameters given below
2019-12-30 21:09:00,479 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_4'}
2019-12-30 21:09:00,480 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_4/tf_logs_run_2019_12_30-21_09_00
2019-12-30 21:09:00,480 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-30 21:09:00,480 [INFO] Reading X, y files
2019-12-30 21:09:00,480 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-30 21:09:04,950 [INFO] Reading complete. time_to_read=4.47 seconds
2019-12-30 21:09:04,950 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-30 21:09:06,483 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 21:09:06,484 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-30 21:09:08,013 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-30 21:09:08,013 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-30 21:09:08,268 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-30 21:09:08,268 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-30 21:09:08,353 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 21:09:08,353 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-30 21:09:08,437 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-30 21:09:12,334 [INFO] Initializing model
2019-12-30 21:09:12,779 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 21:09:12,780 [INFO] =================================================================
2019-12-30 21:09:12,780 [INFO] dense_10 (Dense)             (None, 128)               9984      
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] dense_11 (Dense)             (None, 64)                8256      
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,780 [INFO] dense_12 (Dense)             (None, 32)                2080      
2019-12-30 21:09:12,780 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-30 21:09:12,781 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-30 21:09:12,781 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] dense_13 (Dense)             (None, 16)                528       
2019-12-30 21:09:12,781 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] batch_normalization_10 (Batc (None, 16)                64        
2019-12-30 21:09:12,781 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] dropout_10 (Dropout)         (None, 16)                0         
2019-12-30 21:09:12,781 [INFO] _________________________________________________________________
2019-12-30 21:09:12,781 [INFO] dense_14 (Dense)             (None, 15)                255       
2019-12-30 21:09:12,781 [INFO] =================================================================
2019-12-30 21:09:12,781 [INFO] Total params: 22,063
2019-12-30 21:09:12,781 [INFO] Trainable params: 21,583
2019-12-30 21:09:12,781 [INFO] Non-trainable params: 480
2019-12-30 21:09:12,782 [INFO] _________________________________________________________________
2019-12-30 21:09:12,782 [INFO] Training model
 - val_f1: 0.9781
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 39s - loss: 0.0172 - val_loss: 0.0087
 - val_f1: 0.9748
Epoch 2/200
 - 39s - loss: 0.0093 - val_loss: 0.0153
 - val_f1: 0.9441
Epoch 3/200
 - 39s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 4/200
 - 39s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 5/200
 - 39s - loss: 0.0086 - val_loss: 0.0098
 - val_f1: 0.9751
Epoch 6/200
 - 39s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 7/200
 - 39s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 8/200
 - 39s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 9/200
 - 39s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 10/200
 - 39s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 11/200
 - 39s - loss: 0.0083 - val_loss: 0.0485
 - val_f1: 0.8496
Epoch 12/200
 - 39s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 13/200
 - 39s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 14/200
 - 39s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 15/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 16/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 17/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 18/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 19/200
 - 39s - loss: 0.0082 - val_loss: 0.0182
 - val_f1: 0.9462
Epoch 20/200
 - 39s - loss: 0.0082 - val_loss: 0.0134
 - val_f1: 0.9525
Epoch 21/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 21:26:44,414 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_20.pickle
 - val_f1: 0.9778
Epoch 22/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 23/200
 - 39s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 24/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 25/200
 - 39s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 26/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 27/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 28/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 29/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 30/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 31/200
 - 39s - loss: 0.0081 - val_loss: 0.0139
 - val_f1: 0.9475
Epoch 32/200
 - 39s - loss: 0.0081 - val_loss: 0.0138
 - val_f1: 0.9487
Epoch 33/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 34/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 35/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9802
Epoch 36/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 37/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 38/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 39/200
 - 39s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 40/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 41/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
2019-12-30 21:43:36,018 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_40.pickle
 - val_f1: 0.9780
Epoch 42/200
 - 39s - loss: 0.0080 - val_loss: 0.0121
 - val_f1: 0.9546
Epoch 43/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 44/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 45/200
 - 39s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 46/200
 - 39s - loss: 0.0080 - val_loss: 0.0102
 - val_f1: 0.9759
Epoch 47/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 48/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 49/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 50/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 51/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 52/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 53/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 54/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 55/200
 - 39s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 56/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 57/200
 - 39s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 58/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 59/200
 - 39s - loss: 0.0080 - val_loss: 0.0088
 - val_f1: 0.9749
Epoch 60/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 61/200
 - 39s - loss: 0.0080 - val_loss: 0.0094
2019-12-30 22:00:27,966 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_60.pickle
 - val_f1: 0.9784
Epoch 62/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 63/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 64/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 65/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 66/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 67/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 68/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 69/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 70/200
 - 39s - loss: 0.0080 - val_loss: 0.0097
 - val_f1: 0.9760
Epoch 71/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 72/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 73/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 74/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 75/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 76/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 77/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 78/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 79/200
 - 39s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 80/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 81/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
2019-12-30 22:17:20,391 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_80.pickle
 - val_f1: 0.9788
Epoch 82/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 83/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 84/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 85/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 86/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 87/200
 - 39s - loss: 0.0079 - val_loss: 0.0087
 - val_f1: 0.9785
Epoch 88/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 89/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 90/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 91/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 92/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 93/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 94/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 95/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 96/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 97/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 98/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 99/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 100/200
 - 39s - loss: 0.0079 - val_loss: 0.0139
 - val_f1: 0.9538
Epoch 101/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
2019-12-30 22:34:13,713 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_100.pickle
 - val_f1: 0.9788
Epoch 102/200
 - 39s - loss: 0.0079 - val_loss: 0.0119
 - val_f1: 0.9720
Epoch 103/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 104/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 105/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 106/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 107/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 108/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 109/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 110/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 111/200
 - 39s - loss: 0.0079 - val_loss: 0.0266
 - val_f1: 0.8888
Epoch 112/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 113/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 114/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 115/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 116/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 117/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 118/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 119/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 120/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 121/200
 - 39s - loss: 0.0079 - val_loss: 0.0079
2019-12-30 22:51:09,069 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_120.pickle
 - val_f1: 0.9778
Epoch 122/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 123/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 124/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 125/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 126/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 127/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 128/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 129/200
 - 39s - loss: 0.0079 - val_loss: 0.0176
 - val_f1: 0.9317
Epoch 130/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 131/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 132/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 133/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 134/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 135/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 136/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 137/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 138/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 139/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 140/200
 - 39s - loss: 0.0079 - val_loss: 0.0116
 - val_f1: 0.9705
Epoch 141/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
2019-12-30 23:08:04,069 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_140.pickle
 - val_f1: 0.9787
Epoch 142/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 143/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 144/200
 - 39s - loss: 0.0079 - val_loss: 0.0377
 - val_f1: 0.8408
Epoch 145/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 146/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 147/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 148/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 149/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 150/200
 - 39s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9781
Epoch 151/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 152/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 153/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 154/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 155/200
 - 39s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 156/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 157/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 158/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 159/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 160/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 161/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
2019-12-30 23:24:59,542 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_160.pickle
 - val_f1: 0.9789
Epoch 162/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 163/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 164/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 165/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 166/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 167/200
 - 39s - loss: 0.0079 - val_loss: 0.0103
 - val_f1: 0.9724
Epoch 168/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 169/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 170/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 171/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 172/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 173/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 174/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 175/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 176/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 177/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 178/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 179/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 180/200
 - 39s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 181/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
2019-12-30 23:41:54,607 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_180.pickle
 - val_f1: 0.9790
Epoch 182/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 183/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 184/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 185/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 186/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 187/200
 - 39s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 188/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 189/200
 - 39s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 190/200
 - 39s - loss: 0.0078 - val_loss: 0.0095
 - val_f1: 0.9732
Epoch 191/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 192/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 193/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 194/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 195/200
 - 39s - loss: 0.0078 - val_loss: 0.0111
 - val_f1: 0.9696
Epoch 196/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 197/200
 - 39s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 198/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 199/200
 - 39s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 200/200
 - 39s - loss: 0.0079 - val_loss: 0.0076
2019-12-30 23:58:11,264 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 23:59:02,334 [INFO] Last epoch loss evaluation: train_loss = 0.007550, val_loss = 0.007585
2019-12-30 23:59:02,334 [INFO] Training complete. time_to_train = 10189.55 sec, 169.83 min
2019-12-30 23:59:02,343 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/best_model.pickle
2019-12-30 23:59:02,346 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_error_history.csv
2019-12-30 23:59:02,485 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_error_history.png
2019-12-30 23:59:02,621 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_f1_history.png
2019-12-30 23:59:02,621 [INFO] Making predictions on training, validation, testing data
2019-12-30 23:59:58,976 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 00:00:11,122 [INFO] Dataset: Testing. Classification report below
2019-12-31 00:00:11,122 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.75      0.33      0.46         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.46      0.02      0.03      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.75      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-31 00:00:11,122 [INFO] Overall accuracy (micro avg): 0.983674367300399
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-31 00:00:24,921 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7522                       0.7137                0.0043                   0.2863  0.7104
2  Weighted avg        0.9911         0.9787                       0.9837                0.0489                   0.0163  0.9789
2019-12-31 00:00:37,083 [INFO] Dataset: Validation. Classification report below
2019-12-31 00:00:37,084 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.98      0.96       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.44      0.02      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.74      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-31 00:00:37,084 [INFO] Overall accuracy (micro avg): 0.9837502536844274
2019-12-31 00:00:50,913 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7703                       0.7353                0.0043                   0.2647  0.7345
2  Weighted avg        0.9911         0.9785                       0.9838                0.0488                   0.0162  0.9789
2019-12-31 00:01:30,501 [INFO] Dataset: Training. Classification report below
2019-12-31 00:01:30,501 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.52      0.02      0.04     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.77      0.72      0.73   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-31 00:01:30,501 [INFO] Overall accuracy (micro avg): 0.9837745331434338
2019-12-31 00:02:15,480 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7745                       0.7248                0.0043                   0.2752  0.7255
2  Weighted avg        0.9911         0.9793                       0.9838                0.0487                   0.0162  0.9790
2019-12-31 00:02:15,519 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/ann_depth_ids18_subset_layers_4_results.xlsx
2019-12-31 00:02:15,524 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-31 00:02:15,603 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_5
2019-12-31 00:02:15,603 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_5/run_log.log
2019-12-31 00:02:15,603 [INFO] ================= Running experiment no. 5  ================= 

2019-12-31 00:02:15,603 [INFO] Experiment parameters given below
2019-12-31 00:02:15,603 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_5'}
2019-12-31 00:02:15,603 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_5/tf_logs_run_2019_12_31-00_02_15
2019-12-31 00:02:15,604 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-31 00:02:15,604 [INFO] Reading X, y files
2019-12-31 00:02:15,604 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-31 00:02:20,038 [INFO] Reading complete. time_to_read=4.43 seconds
2019-12-31 00:02:20,038 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-31 00:02:21,575 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-31 00:02:21,576 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-31 00:02:23,111 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-31 00:02:23,111 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-31 00:02:23,352 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-31 00:02:23,353 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-31 00:02:23,437 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-31 00:02:23,437 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-31 00:02:23,523 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 00:02:27,411 [INFO] Initializing model
2019-12-31 00:02:27,938 [INFO] _________________________________________________________________
2019-12-31 00:02:27,938 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 00:02:27,938 [INFO] =================================================================
2019-12-31 00:02:27,938 [INFO] dense_15 (Dense)             (None, 256)               19968     
2019-12-31 00:02:27,938 [INFO] _________________________________________________________________
2019-12-31 00:02:27,938 [INFO] batch_normalization_11 (Batc (None, 256)               1024      
2019-12-31 00:02:27,938 [INFO] _________________________________________________________________
2019-12-31 00:02:27,938 [INFO] dropout_11 (Dropout)         (None, 256)               0         
2019-12-31 00:02:27,938 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dense_16 (Dense)             (None, 128)               32896     
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] batch_normalization_12 (Batc (None, 128)               512       
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dropout_12 (Dropout)         (None, 128)               0         
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dense_17 (Dense)             (None, 64)                8256      
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dense_18 (Dense)             (None, 32)                2080      
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2019-12-31 00:02:27,939 [INFO] _________________________________________________________________
2019-12-31 00:02:27,939 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2019-12-31 00:02:27,940 [INFO] _________________________________________________________________
2019-12-31 00:02:27,940 [INFO] dense_19 (Dense)             (None, 16)                528       
2019-12-31 00:02:27,940 [INFO] _________________________________________________________________
2019-12-31 00:02:27,940 [INFO] batch_normalization_15 (Batc (None, 16)                64        
2019-12-31 00:02:27,940 [INFO] _________________________________________________________________
2019-12-31 00:02:27,940 [INFO] dropout_15 (Dropout)         (None, 16)                0         
2019-12-31 00:02:27,940 [INFO] _________________________________________________________________
2019-12-31 00:02:27,940 [INFO] dense_20 (Dense)             (None, 15)                255       
2019-12-31 00:02:27,940 [INFO] =================================================================
2019-12-31 00:02:27,940 [INFO] Total params: 65,967
2019-12-31 00:02:27,940 [INFO] Trainable params: 64,975
2019-12-31 00:02:27,940 [INFO] Non-trainable params: 992
2019-12-31 00:02:27,940 [INFO] _________________________________________________________________
2019-12-31 00:02:27,940 [INFO] Training model
 - val_f1: 0.9789
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 57s - loss: 0.0161 - val_loss: 0.0086
 - val_f1: 0.9751
Epoch 2/200
 - 56s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 3/200
 - 56s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 4/200
 - 56s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 5/200
 - 56s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 6/200
 - 56s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 7/200
 - 56s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 8/200
 - 56s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 9/200
 - 57s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 10/200
 - 56s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 11/200
 - 56s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 12/200
 - 56s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 13/200
 - 57s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 14/200
 - 57s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 15/200
 - 57s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 16/200
 - 57s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 17/200
 - 57s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9794
Epoch 18/200
 - 57s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 19/200
 - 57s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 20/200
 - 57s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 21/200
 - 57s - loss: 0.0081 - val_loss: 0.0085
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 00:27:00,341 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_20.pickle
 - val_f1: 0.9766
Epoch 22/200
 - 57s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 23/200
 - 57s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 24/200
 - 56s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 25/200
 - 57s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 26/200
 - 57s - loss: 0.0080 - val_loss: 0.0135
 - val_f1: 0.9695
Epoch 27/200
 - 56s - loss: 0.0080 - val_loss: 0.0089
 - val_f1: 0.9781
Epoch 28/200
 - 56s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 29/200
 - 56s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 30/200
 - 57s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 31/200
 - 57s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 32/200
 - 57s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 33/200
 - 57s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 34/200
 - 56s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 35/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 36/200
 - 57s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 37/200
 - 57s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 38/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 39/200
 - 57s - loss: 0.0079 - val_loss: 0.0087
 - val_f1: 0.9771
Epoch 40/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 41/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
2019-12-31 00:50:31,698 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_40.pickle
 - val_f1: 0.9787
Epoch 42/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 43/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 44/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 45/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 46/200
 - 57s - loss: 0.0079 - val_loss: 0.0088
 - val_f1: 0.9739
Epoch 47/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 48/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 49/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 50/200
 - 57s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 51/200
 - 56s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 52/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 53/200
 - 57s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 54/200
 - 57s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 55/200
 - 57s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 56/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 57/200
 - 56s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 58/200
 - 56s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 59/200
 - 57s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 60/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 61/200
 - 56s - loss: 0.0079 - val_loss: 0.0076
2019-12-31 01:14:02,533 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_60.pickle
 - val_f1: 0.9787
Epoch 62/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 63/200
 - 56s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 64/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 65/200
 - 57s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 66/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 67/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 68/200
 - 57s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 69/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 70/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 71/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 72/200
 - 56s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 73/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 74/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 75/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 76/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 77/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 78/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 79/200
 - 57s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 80/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 81/200
 - 57s - loss: 0.0078 - val_loss: 0.0100
2019-12-31 01:37:34,201 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_80.pickle
 - val_f1: 0.9735
Epoch 82/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 83/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 84/200
 - 56s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9775
Epoch 85/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 86/200
 - 57s - loss: 0.0078 - val_loss: 0.0090
 - val_f1: 0.9772
Epoch 87/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 88/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 89/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 90/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 91/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 92/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 93/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 94/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 95/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 96/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 97/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 98/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 99/200
 - 56s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9691
Epoch 100/200
 - 56s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9743
Epoch 101/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
2019-12-31 02:01:04,593 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_100.pickle
 - val_f1: 0.9790
Epoch 102/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 103/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 104/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 105/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 106/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 107/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 108/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 109/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 110/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9803
Epoch 111/200
 - 57s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 112/200
 - 57s - loss: 0.0077 - val_loss: 0.0088
 - val_f1: 0.9743
Epoch 113/200
 - 56s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 114/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 115/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 116/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 117/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 118/200
 - 57s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 119/200
 - 57s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9733
Epoch 120/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 121/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 02:24:37,882 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_120.pickle
 - val_f1: 0.9787
Epoch 122/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 123/200
 - 57s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 124/200
 - 57s - loss: 0.0077 - val_loss: 0.0095
 - val_f1: 0.9773
Epoch 125/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 126/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 127/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 128/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 129/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 130/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 131/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 132/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 133/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 134/200
 - 57s - loss: 0.0077 - val_loss: 0.0112
 - val_f1: 0.9562
Epoch 135/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 136/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 137/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 138/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 139/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 140/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 141/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
2019-12-31 02:48:12,623 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_140.pickle
 - val_f1: 0.9790
Epoch 142/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 143/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 144/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 145/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 146/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 147/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 148/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 149/200
 - 56s - loss: 0.0077 - val_loss: 0.0087
 - val_f1: 0.9776
Epoch 150/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 151/200
 - 56s - loss: 0.0077 - val_loss: 0.0087
 - val_f1: 0.9743
Epoch 152/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 153/200
 - 56s - loss: 0.0077 - val_loss: 0.0100
 - val_f1: 0.9784
Epoch 154/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 155/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 156/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 157/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 158/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 159/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 160/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 161/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
2019-12-31 03:11:39,418 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_160.pickle
 - val_f1: 0.9790
Epoch 162/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 163/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 164/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 165/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 166/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 167/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 168/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 169/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 170/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 171/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 172/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 173/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 174/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 175/200
 - 57s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 176/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 177/200
 - 57s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 178/200
 - 57s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 179/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 180/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 181/200
 - 57s - loss: 0.0077 - val_loss: 0.0079
2019-12-31 03:35:10,797 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_180.pickle
 - val_f1: 0.9783
Epoch 182/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 183/200
 - 57s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9747
Epoch 184/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 185/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 186/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 187/200
 - 57s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 188/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 189/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 190/200
 - 56s - loss: 0.0077 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 191/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 192/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 193/200
 - 56s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 194/200
 - 56s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 195/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 196/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 197/200
 - 57s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 198/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 199/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 200/200
 - 57s - loss: 0.0077 - val_loss: 0.0075
2019-12-31 03:57:46,972 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 03:58:46,652 [INFO] Last epoch loss evaluation: train_loss = 0.007450, val_loss = 0.007505
2019-12-31 03:58:46,652 [INFO] Training complete. time_to_train = 14178.71 sec, 236.31 min
2019-12-31 03:58:46,662 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/best_model.pickle
2019-12-31 03:58:46,665 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_error_history.csv
2019-12-31 03:58:46,808 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_error_history.png
2019-12-31 03:58:46,938 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_f1_history.png
2019-12-31 03:58:46,938 [INFO] Making predictions on training, validation, testing data
2019-12-31 03:59:54,047 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 04:00:06,258 [INFO] Dataset: Testing. Classification report below
2019-12-31 04:00:06,258 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.00      0.00      0.00        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.53      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.79      0.67      0.69    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-31 04:00:06,258 [INFO] Overall accuracy (micro avg): 0.983734786704013
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-31 04:00:20,113 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7863                       0.6686                0.0044                   0.3314  0.6892
2  Weighted avg        0.9912         0.9791                       0.9837                0.0491                   0.0163  0.9786
2019-12-31 04:00:32,283 [INFO] Dataset: Validation. Classification report below
2019-12-31 04:00:32,284 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.48      0.65        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.00      0.00      0.00        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.47      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.79      0.70      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-31 04:00:32,284 [INFO] Overall accuracy (micro avg): 0.9838122223995216
2019-12-31 04:00:46,123 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7901                       0.7016                0.0043                   0.2984  0.7204
2  Weighted avg        0.9912         0.9787                       0.9838                0.0489                   0.0162  0.9787
2019-12-31 04:01:25,735 [INFO] Dataset: Training. Classification report below
2019-12-31 04:01:25,735 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.00      0.00      0.00       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.96      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.59      0.00      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.79      0.68      0.70   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-31 04:01:25,735 [INFO] Overall accuracy (micro avg): 0.9838039682679031
2019-12-31 04:02:10,736 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7938                       0.6836                0.0043                   0.3164  0.7043
2  Weighted avg        0.9912         0.9798                       0.9838                0.0489                   0.0162  0.9787
2019-12-31 04:02:10,762 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/ann_depth_ids18_subset_layers_5_results.xlsx
2019-12-31 04:02:10,767 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-31 04:02:10,846 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_6
2019-12-31 04:02:10,847 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_6/run_log.log
2019-12-31 04:02:10,847 [INFO] ================= Running experiment no. 6  ================= 

2019-12-31 04:02:10,847 [INFO] Experiment parameters given below
2019-12-31 04:02:10,847 [INFO] 
{'experiment_num': 6, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_6', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_6'}
2019-12-31 04:02:10,847 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_6/tf_logs_run_2019_12_31-04_02_10
2019-12-31 04:02:10,847 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-31 04:02:10,847 [INFO] Reading X, y files
2019-12-31 04:02:10,847 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-31 04:02:15,333 [INFO] Reading complete. time_to_read=4.49 seconds
2019-12-31 04:02:15,333 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-31 04:02:16,884 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 04:02:16,884 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-31 04:02:18,435 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 04:02:18,435 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-31 04:02:18,689 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-31 04:02:18,690 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-31 04:02:18,775 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 04:02:18,775 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-31 04:02:18,860 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 04:02:22,725 [INFO] Initializing model
2019-12-31 04:02:23,352 [INFO] _________________________________________________________________
2019-12-31 04:02:23,352 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 04:02:23,352 [INFO] =================================================================
2019-12-31 04:02:23,352 [INFO] dense_21 (Dense)             (None, 400)               31200     
2019-12-31 04:02:23,352 [INFO] _________________________________________________________________
2019-12-31 04:02:23,352 [INFO] batch_normalization_16 (Batc (None, 400)               1600      
2019-12-31 04:02:23,352 [INFO] _________________________________________________________________
2019-12-31 04:02:23,352 [INFO] dropout_16 (Dropout)         (None, 400)               0         
2019-12-31 04:02:23,352 [INFO] _________________________________________________________________
2019-12-31 04:02:23,352 [INFO] dense_22 (Dense)             (None, 256)               102656    
2019-12-31 04:02:23,352 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] batch_normalization_17 (Batc (None, 256)               1024      
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dropout_17 (Dropout)         (None, 256)               0         
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dense_23 (Dense)             (None, 128)               32896     
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] batch_normalization_18 (Batc (None, 128)               512       
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dropout_18 (Dropout)         (None, 128)               0         
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dense_24 (Dense)             (None, 64)                8256      
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] batch_normalization_19 (Batc (None, 64)                256       
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dropout_19 (Dropout)         (None, 64)                0         
2019-12-31 04:02:23,353 [INFO] _________________________________________________________________
2019-12-31 04:02:23,353 [INFO] dense_25 (Dense)             (None, 32)                2080      
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] batch_normalization_20 (Batc (None, 32)                128       
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] dropout_20 (Dropout)         (None, 32)                0         
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] dense_26 (Dense)             (None, 16)                528       
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] batch_normalization_21 (Batc (None, 16)                64        
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] dropout_21 (Dropout)         (None, 16)                0         
2019-12-31 04:02:23,354 [INFO] _________________________________________________________________
2019-12-31 04:02:23,354 [INFO] dense_27 (Dense)             (None, 15)                255       
2019-12-31 04:02:23,354 [INFO] =================================================================
2019-12-31 04:02:23,354 [INFO] Total params: 181,455
2019-12-31 04:02:23,354 [INFO] Trainable params: 179,663
2019-12-31 04:02:23,355 [INFO] Non-trainable params: 1,792
2019-12-31 04:02:23,355 [INFO] _________________________________________________________________
2019-12-31 04:02:23,355 [INFO] Training model
 - val_f1: 0.9788
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 79s - loss: 0.0149 - val_loss: 0.0087
 - val_f1: 0.9748
Epoch 2/200
 - 79s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 3/200
 - 79s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 4/200
 - 79s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 5/200
 - 79s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 6/200
 - 79s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 7/200
 - 79s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 8/200
 - 79s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 9/200
 - 79s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 10/200
 - 79s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 11/200
 - 79s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 12/200
 - 79s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 13/200
 - 79s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 14/200
 - 79s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 15/200
 - 79s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 16/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 17/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 18/200
 - 79s - loss: 0.0080 - val_loss: 0.0117
 - val_f1: 0.9668
Epoch 19/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 20/200
 - 79s - loss: 0.0080 - val_loss: 0.0089
 - val_f1: 0.9776
Epoch 21/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 04:36:10,036 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_20.pickle
 - val_f1: 0.9779
Epoch 22/200
 - 79s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 23/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 24/200
 - 79s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 25/200
 - 79s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 26/200
 - 79s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 27/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 28/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 29/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 30/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 31/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 32/200
 - 79s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9711
Epoch 33/200
 - 79s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 34/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 35/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 36/200
 - 79s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 37/200
 - 79s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 38/200
 - 79s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9753
Epoch 39/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 40/200
 - 79s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 41/200
 - 79s - loss: 0.0079 - val_loss: 0.0077
2019-12-31 05:08:31,233 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_40.pickle
 - val_f1: 0.9787
Epoch 42/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 43/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 44/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 45/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9804
Epoch 46/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 47/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 48/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 49/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 50/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 51/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 52/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 53/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 54/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 55/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 56/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 57/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 58/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 59/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 60/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 61/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
2019-12-31 05:40:52,580 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_60.pickle
 - val_f1: 0.9787
Epoch 62/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 63/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 64/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 65/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 66/200
 - 79s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9785
Epoch 67/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 68/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 69/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 70/200
 - 79s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 71/200
 - 79s - loss: 0.0078 - val_loss: 0.0102
 - val_f1: 0.9720
Epoch 72/200
 - 79s - loss: 0.0077 - val_loss: 0.0091
 - val_f1: 0.9776
Epoch 73/200
 - 79s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 74/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 75/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 76/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 77/200
 - 79s - loss: 0.0077 - val_loss: 0.0108
 - val_f1: 0.9728
Epoch 78/200
 - 79s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9738
Epoch 79/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 80/200
 - 79s - loss: 0.0077 - val_loss: 0.0097
 - val_f1: 0.9746
Epoch 81/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 06:13:14,114 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_80.pickle
 - val_f1: 0.9787
Epoch 82/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 83/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 84/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 85/200
 - 79s - loss: 0.0077 - val_loss: 0.0096
 - val_f1: 0.9743
Epoch 86/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 87/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 88/200
 - 79s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 89/200
 - 79s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 90/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 91/200
 - 79s - loss: 0.0077 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 92/200
 - 79s - loss: 0.0077 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 93/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 94/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 95/200
 - 79s - loss: 0.0077 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 96/200
 - 79s - loss: 0.0077 - val_loss: 0.0118
 - val_f1: 0.9780
Epoch 97/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 98/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 99/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 100/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9794
Epoch 101/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
2019-12-31 06:45:36,518 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_100.pickle
 - val_f1: 0.9791
Epoch 102/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 103/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 104/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 105/200
 - 79s - loss: 0.0077 - val_loss: 0.0093
 - val_f1: 0.9753
Epoch 106/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 107/200
 - 79s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 108/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 109/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 110/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 111/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 112/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 113/200
 - 79s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9774
Epoch 114/200
 - 79s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9727
Epoch 115/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 116/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 117/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 118/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 119/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 120/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 121/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 07:18:00,215 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_120.pickle
 - val_f1: 0.9793
Epoch 122/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 123/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 124/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 125/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 126/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 127/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 128/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 129/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 130/200
 - 79s - loss: 0.0077 - val_loss: 0.0088
 - val_f1: 0.9776
Epoch 131/200
 - 79s - loss: 0.0077 - val_loss: 0.0113
 - val_f1: 0.9743
Epoch 132/200
 - 79s - loss: 0.0077 - val_loss: 0.0083
 - val_f1: 0.9722
Epoch 133/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 134/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 135/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 136/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 137/200
 - 79s - loss: 0.0077 - val_loss: 0.0090
 - val_f1: 0.9751
Epoch 138/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 139/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 140/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 141/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 07:50:29,067 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_140.pickle
 - val_f1: 0.9788
Epoch 142/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 143/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 144/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 145/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 146/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 147/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 148/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 149/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 150/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 151/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 152/200
 - 79s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 153/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 154/200
 - 79s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 155/200
 - 79s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 156/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 157/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 158/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 159/200
 - 79s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 160/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 161/200
 - 79s - loss: 0.0076 - val_loss: 0.0099
2019-12-31 08:22:51,811 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_160.pickle
 - val_f1: 0.9738
Epoch 162/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 163/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 164/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 165/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 166/200
 - 79s - loss: 0.0076 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 167/200
 - 79s - loss: 0.0076 - val_loss: 0.0103
 - val_f1: 0.9778
Epoch 168/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 169/200
 - 79s - loss: 0.0076 - val_loss: 0.0083
 - val_f1: 0.9785
Epoch 170/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 171/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 172/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 173/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 174/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 175/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 176/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 177/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 178/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 179/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 180/200
 - 79s - loss: 0.0076 - val_loss: 0.0100
 - val_f1: 0.9782
Epoch 181/200
 - 79s - loss: 0.0076 - val_loss: 0.0086
2019-12-31 08:55:15,177 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_180.pickle
 - val_f1: 0.9758
Epoch 182/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 183/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 184/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 185/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 186/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 187/200
 - 79s - loss: 0.0076 - val_loss: 0.0103
 - val_f1: 0.9737
Epoch 188/200
 - 79s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 189/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 190/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 191/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 192/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 193/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 194/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 195/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 196/200
 - 79s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 197/200
 - 79s - loss: 0.0076 - val_loss: 0.1183
 - val_f1: 0.7683
Epoch 198/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 199/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 200/200
 - 79s - loss: 0.0076 - val_loss: 0.0075
2019-12-31 09:26:18,662 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 09:27:37,183 [INFO] Last epoch loss evaluation: train_loss = 0.007406, val_loss = 0.007470
2019-12-31 09:27:37,183 [INFO] Training complete. time_to_train = 19513.83 sec, 325.23 min
2019-12-31 09:27:37,196 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/best_model.pickle
2019-12-31 09:27:37,199 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_error_history.csv
2019-12-31 09:27:37,335 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_error_history.png
2019-12-31 09:27:37,456 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_f1_history.png
2019-12-31 09:27:37,456 [INFO] Making predictions on training, validation, testing data
2019-12-31 09:29:05,667 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 09:29:17,866 [INFO] Dataset: Testing. Classification report below
2019-12-31 09:29:17,866 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.52      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.83      0.74      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-31 09:29:17,866 [INFO] Overall accuracy (micro avg): 0.9839392831470144
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-31 09:29:31,732 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.8317                       0.7362                0.0043                   0.2638  0.7433
2  Weighted avg        0.9912         0.9794                       0.9839                0.0489                   0.0161  0.9788
2019-12-31 09:29:43,880 [INFO] Dataset: Validation. Classification report below
2019-12-31 09:29:43,881 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.92      0.48      0.63        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.94      0.99      0.97       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.46      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.83      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-31 09:29:43,881 [INFO] Overall accuracy (micro avg): 0.9840043254163136
2019-12-31 09:29:57,692 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8334                       0.7685                0.0043                   0.2315  0.7752
2  Weighted avg        0.9912         0.9789                       0.9840                0.0488                   0.0160  0.9789
2019-12-31 09:30:37,520 [INFO] Dataset: Training. Classification report below
2019-12-31 09:30:37,520 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.95      1.00      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.61      0.00      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-31 09:30:37,520 [INFO] Overall accuracy (micro avg): 0.9839945219684145
2019-12-31 09:31:22,749 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8435                       0.7505                0.0043                   0.2495  0.7594
2  Weighted avg        0.9912         0.9804                       0.9840                0.0487                   0.0160  0.9789
2019-12-31 09:31:22,775 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/ann_depth_ids18_subset_layers_6_results.xlsx
2019-12-31 09:31:22,782 [INFO] ================= Finished running experiment no. 6 ================= 

2019-12-31 09:31:22,862 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_7
2019-12-31 09:31:22,862 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_7/run_log.log
2019-12-31 09:31:22,862 [INFO] ================= Running experiment no. 7  ================= 

2019-12-31 09:31:22,862 [INFO] Experiment parameters given below
2019-12-31 09:31:22,862 [INFO] 
{'experiment_num': 7, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_7', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_7'}
2019-12-31 09:31:22,862 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_7/tf_logs_run_2019_12_31-09_31_22
2019-12-31 09:31:22,862 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-31 09:31:22,863 [INFO] Reading X, y files
2019-12-31 09:31:22,863 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-31 09:31:27,370 [INFO] Reading complete. time_to_read=4.51 seconds
2019-12-31 09:31:27,370 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-31 09:31:28,924 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 09:31:28,924 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-31 09:31:30,476 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 09:31:30,476 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-31 09:31:30,740 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-31 09:31:30,740 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-31 09:31:30,827 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 09:31:30,827 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-31 09:31:30,913 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 09:31:34,896 [INFO] Initializing model
2019-12-31 09:31:35,469 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 09:31:35,470 [INFO] =================================================================
2019-12-31 09:31:35,470 [INFO] dense_28 (Dense)             (None, 500)               39000     
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] batch_normalization_22 (Batc (None, 500)               2000      
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] dropout_22 (Dropout)         (None, 500)               0         
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] dense_29 (Dense)             (None, 400)               200400    
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] batch_normalization_23 (Batc (None, 400)               1600      
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] dropout_23 (Dropout)         (None, 400)               0         
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,470 [INFO] dense_30 (Dense)             (None, 256)               102656    
2019-12-31 09:31:35,470 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] batch_normalization_24 (Batc (None, 256)               1024      
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dropout_24 (Dropout)         (None, 256)               0         
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dense_31 (Dense)             (None, 128)               32896     
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] batch_normalization_25 (Batc (None, 128)               512       
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dropout_25 (Dropout)         (None, 128)               0         
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dense_32 (Dense)             (None, 64)                8256      
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2019-12-31 09:31:35,471 [INFO] _________________________________________________________________
2019-12-31 09:31:35,471 [INFO] dense_33 (Dense)             (None, 32)                2080      
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] batch_normalization_27 (Batc (None, 32)                128       
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] dropout_27 (Dropout)         (None, 32)                0         
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] dense_34 (Dense)             (None, 16)                528       
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] batch_normalization_28 (Batc (None, 16)                64        
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] dropout_28 (Dropout)         (None, 16)                0         
2019-12-31 09:31:35,472 [INFO] _________________________________________________________________
2019-12-31 09:31:35,472 [INFO] dense_35 (Dense)             (None, 15)                255       
2019-12-31 09:31:35,472 [INFO] =================================================================
2019-12-31 09:31:35,473 [INFO] Total params: 391,655
2019-12-31 09:31:35,473 [INFO] Trainable params: 388,863
2019-12-31 09:31:35,473 [INFO] Non-trainable params: 2,792
2019-12-31 09:31:35,473 [INFO] _________________________________________________________________
2019-12-31 09:31:35,473 [INFO] Training model
 - val_f1: 0.9788
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 117s - loss: 0.0153 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 2/200
 - 116s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 3/200
 - 116s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 4/200
 - 116s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 5/200
 - 117s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9731
Epoch 6/200
 - 117s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 7/200
 - 116s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 8/200
 - 116s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 9/200
 - 116s - loss: 0.0082 - val_loss: 0.0090
 - val_f1: 0.9738
Epoch 10/200
 - 116s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 11/200
 - 116s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 12/200
 - 116s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 13/200
 - 116s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 14/200
 - 116s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 15/200
 - 116s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 16/200
 - 116s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 17/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 18/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 19/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 20/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 21/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 10:21:30,487 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_20.pickle
 - val_f1: 0.9779
Epoch 22/200
 - 116s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9769
Epoch 23/200
 - 116s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 24/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 25/200
 - 116s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 26/200
 - 116s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 27/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 28/200
 - 116s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 29/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 30/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 31/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 32/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 33/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 34/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 35/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9777
Epoch 36/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 37/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 38/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 39/200
 - 116s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 40/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 41/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
2019-12-31 11:09:25,016 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_40.pickle
 - val_f1: 0.9781
Epoch 42/200
 - 116s - loss: 0.0078 - val_loss: 0.0103
 - val_f1: 0.9725
Epoch 43/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 44/200
 - 116s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9773
Epoch 45/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 46/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 47/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 48/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 49/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 50/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 51/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 52/200
 - 116s - loss: 0.0078 - val_loss: 0.0103
 - val_f1: 0.9682
Epoch 53/200
 - 116s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9732
Epoch 54/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 55/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 56/200
 - 116s - loss: 0.0078 - val_loss: 0.0095
 - val_f1: 0.9742
Epoch 57/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 58/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 59/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 60/200
 - 116s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 61/200
 - 116s - loss: 0.0078 - val_loss: 0.0077
2019-12-31 11:57:14,200 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_60.pickle
 - val_f1: 0.9786
Epoch 62/200
 - 116s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9796
Epoch 63/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 64/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 65/200
 - 116s - loss: 0.0077 - val_loss: 0.0114
 - val_f1: 0.9726
Epoch 66/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 67/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 68/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 69/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 70/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 71/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 72/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 73/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 74/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 75/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 76/200
 - 116s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 77/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 78/200
 - 116s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 79/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 80/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 81/200
 - 116s - loss: 0.0077 - val_loss: 0.0105
2019-12-31 12:45:04,044 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_80.pickle
 - val_f1: 0.9682
Epoch 82/200
 - 116s - loss: 0.0077 - val_loss: 0.0104
 - val_f1: 0.9706
Epoch 83/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 84/200
 - 116s - loss: 0.0077 - val_loss: 0.0100
 - val_f1: 0.9739
Epoch 85/200
 - 116s - loss: 0.0077 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 86/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 87/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 88/200
 - 116s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 89/200
 - 116s - loss: 0.0077 - val_loss: 0.0080
 - val_f1: 0.9736
Epoch 90/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 91/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 92/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 93/200
 - 116s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 94/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 95/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 96/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 97/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 98/200
 - 116s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 99/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 100/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 101/200
 - 116s - loss: 0.0077 - val_loss: 0.0091
2019-12-31 13:32:57,800 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_100.pickle
 - val_f1: 0.9775
Epoch 102/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 103/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 104/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 105/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 106/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 107/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 108/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 109/200
 - 116s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 110/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 111/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 112/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 113/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 114/200
 - 116s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9797
Epoch 115/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 116/200
 - 116s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 117/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 118/200
 - 116s - loss: 0.0076 - val_loss: 0.0130
 - val_f1: 0.9626
Epoch 119/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 120/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 121/200
 - 116s - loss: 0.0076 - val_loss: 0.0077
2019-12-31 14:20:47,764 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_120.pickle
 - val_f1: 0.9786
Epoch 122/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 123/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 124/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 125/200
 - 116s - loss: 0.0076 - val_loss: 0.0092
 - val_f1: 0.9769
Epoch 126/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 127/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 128/200
 - 116s - loss: 0.0076 - val_loss: 0.0193
 - val_f1: 0.9440
Epoch 129/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 130/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 131/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 132/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 133/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 134/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 135/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 136/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 137/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 138/200
 - 116s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 139/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 140/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 141/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
2019-12-31 15:08:38,525 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_140.pickle
 - val_f1: 0.9786
Epoch 142/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 143/200
 - 116s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 144/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 145/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 146/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 147/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 148/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 149/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 150/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 151/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 152/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 153/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 154/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 155/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9804
Epoch 156/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9806
Epoch 157/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 158/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 159/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 160/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 161/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
2019-12-31 15:56:32,003 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_160.pickle
 - val_f1: 0.9789
Epoch 162/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 163/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 164/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 165/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 166/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 167/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 168/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 169/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 170/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 171/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 172/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 173/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 174/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 175/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9795
Epoch 176/200
 - 116s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9790
Epoch 177/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 178/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 179/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 180/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 181/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
2019-12-31 16:44:25,342 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_180.pickle
 - val_f1: 0.9788
Epoch 182/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 183/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 184/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 185/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9797
Epoch 186/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 187/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 188/200
 - 116s - loss: 0.0076 - val_loss: 0.0124
 - val_f1: 0.9639
Epoch 189/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 190/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 191/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 192/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 193/200
 - 116s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 194/200
 - 116s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 195/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 196/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 197/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9803
Epoch 198/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 199/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 200/200
 - 116s - loss: 0.0076 - val_loss: 0.0075
2019-12-31 17:30:22,112 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 17:32:17,405 [INFO] Last epoch loss evaluation: train_loss = 0.007356, val_loss = 0.007426
2019-12-31 17:32:17,405 [INFO] Training complete. time_to_train = 28841.93 sec, 480.70 min
2019-12-31 17:32:17,420 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/best_model.pickle
2019-12-31 17:32:17,423 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_error_history.csv
2019-12-31 17:32:17,563 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_error_history.png
2019-12-31 17:32:17,699 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_f1_history.png
2019-12-31 17:32:17,699 [INFO] Making predictions on training, validation, testing data
2019-12-31 17:34:30,942 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 17:34:43,108 [INFO] Dataset: Testing. Classification report below
2019-12-31 17:34:43,108 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.99      0.83        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.96      1.00      0.98       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.47      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.83      0.74      0.75    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-31 17:34:43,109 [INFO] Overall accuracy (micro avg): 0.9838726668814912
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-31 17:34:56,931 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0012                   0.0161  0.9839
1     Macro avg        0.9978         0.8315                       0.7361                0.0043                   0.2639  0.7458
2  Weighted avg        0.9912         0.9790                       0.9839                0.0491                   0.0161  0.9789
2019-12-31 17:35:09,087 [INFO] Dataset: Validation. Classification report below
2019-12-31 17:35:09,087 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.86      0.48      0.62        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.78      0.97      0.86        68
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      1.00      0.97       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.46      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.83      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-31 17:35:09,087 [INFO] Overall accuracy (micro avg): 0.9839826363660306
2019-12-31 17:35:22,899 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8333                       0.7672                0.0043                   0.2328  0.7769
2  Weighted avg        0.9912         0.9790                       0.9840                0.0489                   0.0160  0.9790
2019-12-31 17:36:02,564 [INFO] Dataset: Training. Classification report below
2019-12-31 17:36:02,564 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.97      1.00      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.55      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-31 17:36:02,564 [INFO] Overall accuracy (micro avg): 0.9839826446374884
2019-12-31 17:36:47,623 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8418                       0.7496                0.0043                   0.2504  0.7613
2  Weighted avg        0.9912         0.9799                       0.9840                0.0488                   0.0160  0.9790
2019-12-31 17:36:47,649 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/ann_depth_ids18_subset_layers_7_results.xlsx
2019-12-31 17:36:47,656 [INFO] ================= Finished running experiment no. 7 ================= 

2019-12-31 17:36:47,735 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_8
2019-12-31 17:36:47,736 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_8/run_log.log
2019-12-31 17:36:47,736 [INFO] ================= Running experiment no. 8  ================= 

2019-12-31 17:36:47,736 [INFO] Experiment parameters given below
2019-12-31 17:36:47,736 [INFO] 
{'experiment_num': 8, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_8', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_8'}
2019-12-31 17:36:47,736 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_8/tf_logs_run_2019_12_31-17_36_47
2019-12-31 17:36:47,736 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-31 17:36:47,736 [INFO] Reading X, y files
2019-12-31 17:36:47,736 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-31 17:36:52,262 [INFO] Reading complete. time_to_read=4.53 seconds
2019-12-31 17:36:52,262 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-31 17:36:53,811 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 17:36:53,811 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-31 17:36:55,359 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-31 17:36:55,359 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-31 17:36:55,626 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-31 17:36:55,626 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-31 17:36:55,711 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 17:36:55,712 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-31 17:36:55,798 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-31 17:36:59,698 [INFO] Initializing model
2019-12-31 17:37:00,353 [INFO] _________________________________________________________________
2019-12-31 17:37:00,353 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 17:37:00,353 [INFO] =================================================================
2019-12-31 17:37:00,353 [INFO] dense_36 (Dense)             (None, 600)               46800     
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] batch_normalization_29 (Batc (None, 600)               2400      
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] dropout_29 (Dropout)         (None, 600)               0         
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] dense_37 (Dense)             (None, 500)               300500    
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] batch_normalization_30 (Batc (None, 500)               2000      
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] dropout_30 (Dropout)         (None, 500)               0         
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] dense_38 (Dense)             (None, 400)               200400    
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] batch_normalization_31 (Batc (None, 400)               1600      
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,354 [INFO] dropout_31 (Dropout)         (None, 400)               0         
2019-12-31 17:37:00,354 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dense_39 (Dense)             (None, 256)               102656    
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] batch_normalization_32 (Batc (None, 256)               1024      
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dropout_32 (Dropout)         (None, 256)               0         
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dense_40 (Dense)             (None, 128)               32896     
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] batch_normalization_33 (Batc (None, 128)               512       
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dropout_33 (Dropout)         (None, 128)               0         
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dense_41 (Dense)             (None, 64)                8256      
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] batch_normalization_34 (Batc (None, 64)                256       
2019-12-31 17:37:00,355 [INFO] _________________________________________________________________
2019-12-31 17:37:00,355 [INFO] dropout_34 (Dropout)         (None, 64)                0         
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] dense_42 (Dense)             (None, 32)                2080      
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] batch_normalization_35 (Batc (None, 32)                128       
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] dropout_35 (Dropout)         (None, 32)                0         
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] dense_43 (Dense)             (None, 16)                528       
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] batch_normalization_36 (Batc (None, 16)                64        
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] dropout_36 (Dropout)         (None, 16)                0         
2019-12-31 17:37:00,356 [INFO] _________________________________________________________________
2019-12-31 17:37:00,356 [INFO] dense_44 (Dense)             (None, 15)                255       
2019-12-31 17:37:00,356 [INFO] =================================================================
2019-12-31 17:37:00,357 [INFO] Total params: 702,355
2019-12-31 17:37:00,357 [INFO] Trainable params: 698,363
2019-12-31 17:37:00,357 [INFO] Non-trainable params: 3,992
2019-12-31 17:37:00,357 [INFO] _________________________________________________________________
2019-12-31 17:37:00,357 [INFO] Training model
 - val_f1: 0.9787
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 169s - loss: 0.0157 - val_loss: 0.0104
 - val_f1: 0.9771
Epoch 2/200
 - 169s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9724
Epoch 3/200
 - 168s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 4/200
 - 169s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 5/200
 - 169s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 6/200
 - 168s - loss: 0.0083 - val_loss: 0.0200
 - val_f1: 0.9249
Epoch 7/200
 - 169s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9702
Epoch 8/200
 - 169s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 9/200
 - 169s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 10/200
 - 169s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 11/200
 - 169s - loss: 0.0081 - val_loss: 0.0232
 - val_f1: 0.9497
Epoch 12/200
 - 169s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 13/200
 - 169s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 14/200
 - 169s - loss: 0.0080 - val_loss: 0.0381
 - val_f1: 0.8530
Epoch 15/200
 - 168s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 16/200
 - 169s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 17/200
 - 169s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 18/200
 - 169s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 19/200
 - 169s - loss: 0.0080 - val_loss: 0.0408
 - val_f1: 0.8571
Epoch 20/200
 - 169s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 21/200
 - 168s - loss: 0.0080 - val_loss: 0.0138
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 18:49:51,863 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_20.pickle
 - val_f1: 0.9648
Epoch 22/200
 - 169s - loss: 0.0079 - val_loss: 0.0470
 - val_f1: 0.8507
Epoch 23/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 24/200
 - 169s - loss: 0.0079 - val_loss: 0.0221
 - val_f1: 0.8914
Epoch 25/200
 - 169s - loss: 0.0079 - val_loss: 0.0250
 - val_f1: 0.9239
Epoch 26/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 27/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 28/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 29/200
 - 168s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 30/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 31/200
 - 169s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 32/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 33/200
 - 168s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 34/200
 - 168s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 35/200
 - 169s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 36/200
 - 169s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 37/200
 - 169s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 38/200
 - 168s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 39/200
 - 168s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 40/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 41/200
 - 169s - loss: 0.0078 - val_loss: 0.0078
2019-12-31 19:59:33,441 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_40.pickle
 - val_f1: 0.9779
Epoch 42/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 43/200
 - 169s - loss: 0.0078 - val_loss: 0.0155
 - val_f1: 0.9344
Epoch 44/200
 - 168s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 45/200
 - 168s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 46/200
 - 169s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 47/200
 - 169s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 48/200
 - 168s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 49/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 50/200
 - 168s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 51/200
 - 168s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 52/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 53/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 54/200
 - 169s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 55/200
 - 169s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 56/200
 - 168s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 57/200
 - 168s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 58/200
 - 169s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 59/200
 - 169s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 60/200
 - 168s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 61/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 21:09:15,717 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_60.pickle
 - val_f1: 0.9782
Epoch 62/200
 - 168s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 63/200
 - 169s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 64/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 65/200
 - 168s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 66/200
 - 169s - loss: 0.0077 - val_loss: 0.0108
 - val_f1: 0.9643
Epoch 67/200
 - 169s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 68/200
 - 168s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 69/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 70/200
 - 168s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 71/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 72/200
 - 169s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 73/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 74/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 75/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 76/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 77/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 78/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 79/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 80/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 81/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
2019-12-31 22:18:58,284 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_80.pickle
 - val_f1: 0.9784
Epoch 82/200
 - 169s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 83/200
 - 168s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 84/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 85/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 86/200
 - 169s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 87/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 88/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 89/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 90/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 91/200
 - 169s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 92/200
 - 169s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 93/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 94/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 95/200
 - 168s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 96/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 97/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 98/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 99/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 100/200
 - 169s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 101/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
2019-12-31 23:28:40,466 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_100.pickle
 - val_f1: 0.9789
Epoch 102/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 103/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 104/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 105/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 106/200
 - 169s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 107/200
 - 168s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 108/200
 - 169s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 109/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 110/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 111/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 112/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 113/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 114/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 115/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 116/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 117/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 118/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 119/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 120/200
 - 169s - loss: 0.0076 - val_loss: 0.0118
 - val_f1: 0.9736
Epoch 121/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
2020-01-01 00:38:22,709 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_120.pickle
 - val_f1: 0.9787
Epoch 122/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 123/200
 - 168s - loss: 0.0076 - val_loss: 0.0336
 - val_f1: 0.8864
Epoch 124/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 125/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 126/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 127/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 128/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 129/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 130/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 131/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 132/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 133/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 134/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 135/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 136/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 137/200
 - 169s - loss: 0.0076 - val_loss: 0.0448
 - val_f1: 0.8863
Epoch 138/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 139/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 140/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 141/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
2020-01-01 01:48:05,645 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_140.pickle
 - val_f1: 0.9786
Epoch 142/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 143/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 144/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 145/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 146/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 147/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 148/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 149/200
 - 169s - loss: 0.0076 - val_loss: 0.0252
 - val_f1: 0.9332
Epoch 150/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 151/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 152/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 153/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 154/200
 - 168s - loss: 0.0076 - val_loss: 0.0088
 - val_f1: 0.9734
Epoch 155/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 156/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 157/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 158/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 159/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 160/200
 - 168s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9793
Epoch 161/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
2020-01-01 02:57:47,461 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_160.pickle
 - val_f1: 0.9789
Epoch 162/200
 - 169s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9790
Epoch 163/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 164/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 165/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 166/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 167/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 168/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 169/200
 - 168s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9794
Epoch 170/200
 - 168s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 171/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 172/200
 - 168s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 173/200
 - 168s - loss: 0.0076 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 174/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 175/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 176/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 177/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 178/200
 - 169s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 179/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 180/200
 - 168s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 181/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
2020-01-01 04:07:30,085 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_180.pickle
 - val_f1: 0.9787
Epoch 182/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 183/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 184/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 185/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 186/200
 - 168s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 187/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 188/200
 - 169s - loss: 0.0076 - val_loss: 0.0096
 - val_f1: 0.9713
Epoch 189/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 190/200
 - 169s - loss: 0.0076 - val_loss: 0.0142
 - val_f1: 0.9628
Epoch 191/200
 - 169s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9790
Epoch 192/200
 - 169s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9793
Epoch 193/200
 - 168s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 194/200
 - 169s - loss: 0.0076 - val_loss: 0.0147
 - val_f1: 0.9628
Epoch 195/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 196/200
 - 169s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 197/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 198/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9784
Epoch 199/200
 - 169s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 200/200
 - 169s - loss: 0.0076 - val_loss: 0.0077
2020-01-01 05:14:25,936 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-01 05:17:17,601 [INFO] Last epoch loss evaluation: train_loss = 0.007359, val_loss = 0.007430
2020-01-01 05:17:17,601 [INFO] Training complete. time_to_train = 42017.24 sec, 700.29 min
2020-01-01 05:17:17,621 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/best_model.pickle
2020-01-01 05:17:17,624 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_error_history.csv
2020-01-01 05:17:17,773 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_error_history.png
2020-01-01 05:17:17,910 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_f1_history.png
2020-01-01 05:17:17,911 [INFO] Making predictions on training, validation, testing data
2020-01-01 05:20:39,701 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 05:20:51,884 [INFO] Dataset: Testing. Classification report below
2020-01-01 05:20:51,884 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.80      0.33      0.47        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.96      1.00      0.98       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.48      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.82      0.74      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-01 05:20:51,884 [INFO] Overall accuracy (micro avg): 0.9839454800089235
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-01 05:21:05,720 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.8239                       0.7372                0.0043                   0.2628  0.7438
2  Weighted avg        0.9912         0.9791                       0.9839                0.0485                   0.0161  0.9789
2020-01-01 05:21:17,885 [INFO] Dataset: Validation. Classification report below
2020-01-01 05:21:17,885 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.86      0.48      0.62        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      1.00      0.97       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.46      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.83      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-01 05:21:17,885 [INFO] Overall accuracy (micro avg): 0.9839872840196626
2020-01-01 05:21:31,716 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8299                       0.7684                0.0043                   0.2316  0.7753
2  Weighted avg        0.9912         0.9790                       0.9840                0.0484                   0.0160  0.9789
2020-01-01 05:22:11,492 [INFO] Dataset: Training. Classification report below
2020-01-01 05:22:11,492 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.82      0.37      0.51        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.97      1.00      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.58      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.83      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-01 05:22:11,492 [INFO] Overall accuracy (micro avg): 0.9840094977334954
2020-01-01 05:22:56,687 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8344                       0.7509                0.0043                   0.2491  0.7594
2  Weighted avg        0.9913         0.9801                       0.9840                0.0483                   0.0160  0.9790
2020-01-01 05:22:56,714 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/ann_depth_ids18_subset_layers_8_results.xlsx
2020-01-01 05:22:56,719 [INFO] ================= Finished running experiment no. 8 ================= 

2020-01-01 05:22:56,796 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_9
2020-01-01 05:22:56,796 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_9/run_log.log
2020-01-01 05:22:56,796 [INFO] ================= Running experiment no. 9  ================= 

2020-01-01 05:22:56,796 [INFO] Experiment parameters given below
2020-01-01 05:22:56,796 [INFO] 
{'experiment_num': 9, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_9', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_9'}
2020-01-01 05:22:56,796 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_9/tf_logs_run_2020_01_01-05_22_56
2020-01-01 05:22:56,797 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-01 05:22:56,797 [INFO] Reading X, y files
2020-01-01 05:22:56,797 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-01 05:23:01,352 [INFO] Reading complete. time_to_read=4.56 seconds
2020-01-01 05:23:01,352 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-01 05:23:02,918 [INFO] Reading complete. time_to_read=1.57 seconds
2020-01-01 05:23:02,918 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-01 05:23:04,486 [INFO] Reading complete. time_to_read=1.57 seconds
2020-01-01 05:23:04,486 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-01 05:23:04,746 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-01 05:23:04,746 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-01 05:23:04,832 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-01 05:23:04,832 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-01 05:23:04,919 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-01 05:23:08,795 [INFO] Initializing model
2020-01-01 05:23:09,541 [INFO] _________________________________________________________________
2020-01-01 05:23:09,541 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-01 05:23:09,541 [INFO] =================================================================
2020-01-01 05:23:09,542 [INFO] dense_45 (Dense)             (None, 700)               54600     
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] batch_normalization_37 (Batc (None, 700)               2800      
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] dropout_37 (Dropout)         (None, 700)               0         
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] dense_46 (Dense)             (None, 600)               420600    
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] batch_normalization_38 (Batc (None, 600)               2400      
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] dropout_38 (Dropout)         (None, 600)               0         
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] dense_47 (Dense)             (None, 500)               300500    
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,542 [INFO] batch_normalization_39 (Batc (None, 500)               2000      
2020-01-01 05:23:09,542 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dropout_39 (Dropout)         (None, 500)               0         
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dense_48 (Dense)             (None, 400)               200400    
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] batch_normalization_40 (Batc (None, 400)               1600      
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dropout_40 (Dropout)         (None, 400)               0         
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dense_49 (Dense)             (None, 256)               102656    
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] batch_normalization_41 (Batc (None, 256)               1024      
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dropout_41 (Dropout)         (None, 256)               0         
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] dense_50 (Dense)             (None, 128)               32896     
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,543 [INFO] batch_normalization_42 (Batc (None, 128)               512       
2020-01-01 05:23:09,543 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dropout_42 (Dropout)         (None, 128)               0         
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dense_51 (Dense)             (None, 64)                8256      
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] batch_normalization_43 (Batc (None, 64)                256       
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dropout_43 (Dropout)         (None, 64)                0         
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dense_52 (Dense)             (None, 32)                2080      
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] batch_normalization_44 (Batc (None, 32)                128       
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dropout_44 (Dropout)         (None, 32)                0         
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] dense_53 (Dense)             (None, 16)                528       
2020-01-01 05:23:09,544 [INFO] _________________________________________________________________
2020-01-01 05:23:09,544 [INFO] batch_normalization_45 (Batc (None, 16)                64        
2020-01-01 05:23:09,545 [INFO] _________________________________________________________________
2020-01-01 05:23:09,545 [INFO] dropout_45 (Dropout)         (None, 16)                0         
2020-01-01 05:23:09,545 [INFO] _________________________________________________________________
2020-01-01 05:23:09,545 [INFO] dense_54 (Dense)             (None, 15)                255       
2020-01-01 05:23:09,545 [INFO] =================================================================
2020-01-01 05:23:09,545 [INFO] Total params: 1,133,555
2020-01-01 05:23:09,545 [INFO] Trainable params: 1,128,163
2020-01-01 05:23:09,545 [INFO] Non-trainable params: 5,392
2020-01-01 05:23:09,545 [INFO] _________________________________________________________________
2020-01-01 05:23:09,545 [INFO] Training model
 - val_f1: 0.9788
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 236s - loss: 0.0164 - val_loss: 0.0092
 - val_f1: 0.9744
Epoch 2/200
 - 234s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 3/200
 - 235s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9763
Epoch 4/200
 - 235s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 5/200
 - 235s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 6/200
 - 235s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 7/200
 - 235s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 8/200
 - 235s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 9/200
 - 235s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 10/200
 - 235s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9737
Epoch 11/200
 - 235s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 12/200
 - 235s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 13/200
 - 235s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 14/200
 - 235s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 15/200
 - 235s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 16/200
 - 235s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 17/200
 - 235s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 18/200
 - 235s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 19/200
 - 235s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 20/200
 - 235s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 21/200
 - 235s - loss: 0.0080 - val_loss: 0.0078
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 07:03:10,425 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_20.pickle
 - val_f1: 0.9780
Epoch 22/200
 - 235s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 23/200
 - 235s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 24/200
 - 235s - loss: 0.0079 - val_loss: 0.0287
 - val_f1: 0.9261
Epoch 25/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 26/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 27/200
 - 235s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 28/200
 - 235s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 29/200
 - 235s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 30/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 31/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 32/200
 - 235s - loss: 0.0079 - val_loss: 0.0128
 - val_f1: 0.9565
Epoch 33/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 34/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 35/200
 - 235s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 36/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 37/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 38/200
 - 235s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9775
Epoch 39/200
 - 235s - loss: 0.0078 - val_loss: 0.0470
 - val_f1: 0.8820
Epoch 40/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 41/200
 - 235s - loss: 0.0078 - val_loss: 0.0078
2020-01-01 08:39:05,254 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_40.pickle
 - val_f1: 0.9779
Epoch 42/200
 - 236s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 43/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 44/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 45/200
 - 236s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 46/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 47/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 48/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 49/200
 - 236s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 50/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 51/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 52/200
 - 235s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 53/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 54/200
 - 235s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9761
Epoch 55/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 56/200
 - 235s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9769
Epoch 57/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 58/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 59/200
 - 235s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 60/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 61/200
 - 235s - loss: 0.0078 - val_loss: 0.0464
2020-01-01 10:15:01,552 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_60.pickle
 - val_f1: 0.9021
Epoch 62/200
 - 236s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 63/200
 - 235s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 64/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 65/200
 - 235s - loss: 0.0078 - val_loss: 0.0138
 - val_f1: 0.9697
Epoch 66/200
 - 235s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 67/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 68/200
 - 235s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 69/200
 - 235s - loss: 0.0077 - val_loss: 0.0082
 - val_f1: 0.9723
Epoch 70/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 71/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 72/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 73/200
 - 235s - loss: 0.0077 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 74/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 75/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 76/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 77/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 78/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 79/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 80/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 81/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
2020-01-01 11:50:54,914 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_80.pickle
 - val_f1: 0.9784
Epoch 82/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 83/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 84/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 85/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 86/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 87/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 88/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 89/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 90/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 91/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9799
Epoch 92/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 93/200
 - 235s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 94/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 95/200
 - 235s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 96/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 97/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 98/200
 - 235s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 99/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 100/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 101/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
2020-01-01 13:26:48,680 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_100.pickle
 - val_f1: 0.9785
Epoch 102/200
 - 235s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 103/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 104/200
 - 236s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 105/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 106/200
 - 235s - loss: 0.0076 - val_loss: 0.0124
 - val_f1: 0.9706
Epoch 107/200
 - 236s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 108/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 109/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 110/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 111/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 112/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 113/200
 - 236s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 114/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 115/200
 - 236s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 116/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 117/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 118/200
 - 236s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 119/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 120/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 121/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
2020-01-01 15:02:47,301 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_120.pickle
 - val_f1: 0.9792
Epoch 122/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 123/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 124/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 125/200
 - 236s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 126/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 127/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 128/200
 - 236s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 129/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 130/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 131/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 132/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 133/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 134/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 135/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 136/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 137/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 138/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 139/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 140/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 141/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
2020-01-01 16:38:43,145 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 235s - loss: 0.0076 - val_loss: 0.0244
 - val_f1: 0.9364
Epoch 143/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 144/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 145/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 146/200
 - 236s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 147/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 148/200
 - 235s - loss: 0.0076 - val_loss: 0.0376
 - val_f1: 0.9217
Epoch 149/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 150/200
 - 236s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 151/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 152/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 153/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9792
Epoch 154/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 155/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9806
Epoch 156/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 157/200
 - 236s - loss: 0.0076 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 158/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 159/200
 - 235s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 160/200
 - 235s - loss: 0.0076 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 161/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
2020-01-01 18:14:39,880 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_160.pickle
 - val_f1: 0.9791
Epoch 162/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9794
Epoch 163/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 164/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 165/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 166/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 167/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 168/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 169/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 170/200
 - 235s - loss: 0.0076 - val_loss: 0.0084
 - val_f1: 0.9769
Epoch 171/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 172/200
 - 235s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9790
Epoch 173/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 174/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9795
Epoch 175/200
 - 235s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9805
Epoch 176/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 177/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 178/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 179/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 180/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 181/200
 - 236s - loss: 0.0076 - val_loss: 0.0075
2020-01-01 19:50:35,102 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_180.pickle
 - val_f1: 0.9790
Epoch 182/200
 - 235s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 183/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 184/200
 - 235s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 185/200
 - 235s - loss: 0.0076 - val_loss: 0.0259
 - val_f1: 0.9508
Epoch 186/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 187/200
 - 235s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 188/200
 - 236s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 189/200
 - 236s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9792
Epoch 190/200
 - 236s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 191/200
 - 236s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 192/200
 - 236s - loss: 0.0075 - val_loss: 0.0074
 - val_f1: 0.9791
Epoch 193/200
 - 236s - loss: 0.0075 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 194/200
 - 236s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 195/200
 - 236s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 196/200
 - 236s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 197/200
 - 235s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 198/200
 - 236s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 199/200
 - 235s - loss: 0.0075 - val_loss: 0.0105
 - val_f1: 0.9743
Epoch 200/200
 - 236s - loss: 0.0076 - val_loss: 0.0077
2020-01-01 21:22:38,481 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-01 21:26:23,475 [INFO] Last epoch loss evaluation: train_loss = 0.007336, val_loss = 0.007417
2020-01-01 21:26:23,475 [INFO] Training complete. time_to_train = 57793.93 sec, 963.23 min
2020-01-01 21:26:23,502 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/best_model.pickle
2020-01-01 21:26:23,505 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_error_history.csv
2020-01-01 21:26:23,650 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_error_history.png
2020-01-01 21:26:23,779 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_f1_history.png
2020-01-01 21:26:23,779 [INFO] Making predictions on training, validation, testing data
2020-01-01 21:30:45,021 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 21:30:57,267 [INFO] Dataset: Testing. Classification report below
2020-01-01 21:30:57,267 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.53      0.42      0.47        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.50      0.60      5596
   DoS attacks-Slowloris       0.96      1.00      0.98       440
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.52      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.82      0.70      0.72    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-01 21:30:57,267 [INFO] Overall accuracy (micro avg): 0.9839067496219914
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-01 21:31:11,161 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.8230                       0.6982                0.0043                   0.3018  0.7218
2  Weighted avg        0.9913         0.9795                       0.9839                0.0487                   0.0161  0.9789
2020-01-01 21:31:23,344 [INFO] Dataset: Validation. Classification report below
2020-01-01 21:31:23,344 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.86      0.48      0.62        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.65      0.51      0.57        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.49      0.60      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.90      0.79      7718
           Infilteration       0.54      0.01      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.83      0.74      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-01 21:31:23,344 [INFO] Overall accuracy (micro avg): 0.9840167191593324
2020-01-01 21:31:37,191 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8303                       0.7367                0.0043                   0.2633  0.7578
2  Weighted avg        0.9913         0.9798                       0.9840                0.0486                   0.0160  0.9790
2020-01-01 21:32:17,104 [INFO] Dataset: Training. Classification report below
2020-01-01 21:32:17,105 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.79      0.37      0.50        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.61      0.45      0.52       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.77      0.49      0.60     16787
   DoS attacks-Slowloris       0.97      1.00      0.98      1318
          FTP-BruteForce       0.71      0.89      0.79     23153
           Infilteration       0.59      0.02      0.03     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.83      0.71      0.74   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-01 21:32:17,105 [INFO] Overall accuracy (micro avg): 0.9840198258473443
2020-01-01 21:33:02,406 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8274                       0.7147                0.0043                   0.2853  0.7388
2  Weighted avg        0.9913         0.9804                       0.9840                0.0484                   0.0160  0.9791
2020-01-01 21:33:02,433 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/ann_depth_ids18_subset_layers_9_results.xlsx
2020-01-01 21:33:02,438 [INFO] ================= Finished running experiment no. 9 ================= 

2020-01-01 21:33:02,518 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_10
2020-01-01 21:33:02,519 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_10/run_log.log
2020-01-01 21:33:02,519 [INFO] ================= Running experiment no. 10  ================= 

2020-01-01 21:33:02,519 [INFO] Experiment parameters given below
2020-01-01 21:33:02,519 [INFO] 
{'experiment_num': 10, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_10', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [800, 700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_10'}
2020-01-01 21:33:02,519 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_10/tf_logs_run_2020_01_01-21_33_02
2020-01-01 21:33:02,519 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-01 21:33:02,519 [INFO] Reading X, y files
2020-01-01 21:33:02,519 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-01 21:33:07,099 [INFO] Reading complete. time_to_read=4.58 seconds
2020-01-01 21:33:07,100 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-01 21:33:08,665 [INFO] Reading complete. time_to_read=1.57 seconds
2020-01-01 21:33:08,666 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-01 21:33:10,230 [INFO] Reading complete. time_to_read=1.56 seconds
2020-01-01 21:33:10,231 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-01 21:33:10,495 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-01 21:33:10,495 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-01 21:33:10,582 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-01 21:33:10,582 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-01 21:33:10,669 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-01 21:33:14,648 [INFO] Initializing model
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-01 21:33:15,478 [INFO] =================================================================
2020-01-01 21:33:15,478 [INFO] dense_55 (Dense)             (None, 800)               62400     
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] batch_normalization_46 (Batc (None, 800)               3200      
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] dropout_46 (Dropout)         (None, 800)               0         
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] dense_56 (Dense)             (None, 700)               560700    
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] batch_normalization_47 (Batc (None, 700)               2800      
2020-01-01 21:33:15,478 [INFO] _________________________________________________________________
2020-01-01 21:33:15,478 [INFO] dropout_47 (Dropout)         (None, 700)               0         
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] dense_57 (Dense)             (None, 600)               420600    
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] batch_normalization_48 (Batc (None, 600)               2400      
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] dropout_48 (Dropout)         (None, 600)               0         
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] dense_58 (Dense)             (None, 500)               300500    
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] batch_normalization_49 (Batc (None, 500)               2000      
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] dropout_49 (Dropout)         (None, 500)               0         
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] dense_59 (Dense)             (None, 400)               200400    
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,479 [INFO] batch_normalization_50 (Batc (None, 400)               1600      
2020-01-01 21:33:15,479 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dropout_50 (Dropout)         (None, 400)               0         
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dense_60 (Dense)             (None, 256)               102656    
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] batch_normalization_51 (Batc (None, 256)               1024      
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dropout_51 (Dropout)         (None, 256)               0         
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dense_61 (Dense)             (None, 128)               32896     
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] batch_normalization_52 (Batc (None, 128)               512       
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dropout_52 (Dropout)         (None, 128)               0         
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] dense_62 (Dense)             (None, 64)                8256      
2020-01-01 21:33:15,480 [INFO] _________________________________________________________________
2020-01-01 21:33:15,480 [INFO] batch_normalization_53 (Batc (None, 64)                256       
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dropout_53 (Dropout)         (None, 64)                0         
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dense_63 (Dense)             (None, 32)                2080      
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] batch_normalization_54 (Batc (None, 32)                128       
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dropout_54 (Dropout)         (None, 32)                0         
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dense_64 (Dense)             (None, 16)                528       
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] batch_normalization_55 (Batc (None, 16)                64        
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dropout_55 (Dropout)         (None, 16)                0         
2020-01-01 21:33:15,481 [INFO] _________________________________________________________________
2020-01-01 21:33:15,481 [INFO] dense_65 (Dense)             (None, 15)                255       
2020-01-01 21:33:15,481 [INFO] =================================================================
2020-01-01 21:33:15,482 [INFO] Total params: 1,705,255
2020-01-01 21:33:15,482 [INFO] Trainable params: 1,698,263
2020-01-01 21:33:15,482 [INFO] Non-trainable params: 6,992
2020-01-01 21:33:15,482 [INFO] _________________________________________________________________
2020-01-01 21:33:15,482 [INFO] Training model
 - val_f1: 0.9793
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 325s - loss: 0.0155 - val_loss: 0.0094
 - val_f1: 0.9757
Epoch 2/200
 - 324s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9747
Epoch 3/200
 - 324s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 4/200
 - 324s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 5/200
 - 324s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 6/200
 - 324s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 7/200
 - 324s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 8/200
 - 325s - loss: 0.0082 - val_loss: 0.0153
 - val_f1: 0.9639
Epoch 9/200
 - 325s - loss: 0.0082 - val_loss: 0.0700
 - val_f1: 0.8729
Epoch 10/200
 - 325s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 11/200
 - 325s - loss: 0.0082 - val_loss: 0.0102
 - val_f1: 0.9672
Epoch 12/200
 - 325s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9763
Epoch 13/200
 - 325s - loss: 0.0081 - val_loss: 0.0299
 - val_f1: 0.9039
Epoch 14/200
 - 325s - loss: 0.0081 - val_loss: 0.0090
 - val_f1: 0.9777
Epoch 15/200
 - 325s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 16/200
 - 325s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 17/200
 - 325s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 18/200
 - 325s - loss: 0.0080 - val_loss: 0.0217
 - val_f1: 0.9305
Epoch 19/200
 - 325s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 20/200
 - 324s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 21/200
 - 324s - loss: 0.0080 - val_loss: 0.0078
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 23:49:21,586 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_20.pickle
 - val_f1: 0.9776
Epoch 22/200
 - 324s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 23/200
 - 324s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 24/200
 - 325s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 25/200
 - 325s - loss: 0.0079 - val_loss: 0.0352
 - val_f1: 0.9248
Epoch 26/200
 - 325s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 27/200
 - 324s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 28/200
 - 324s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 29/200
 - 325s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 30/200
 - 325s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 31/200
 - 324s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 32/200
 - 324s - loss: 0.0079 - val_loss: 0.0510
 - val_f1: 0.8726
Epoch 33/200
 - 324s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 34/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 35/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 36/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 37/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 38/200
 - 325s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9775
Epoch 39/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 40/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 41/200
 - 325s - loss: 0.0078 - val_loss: 0.0078
2020-01-02 01:59:47,917 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_40.pickle
 - val_f1: 0.9744
Epoch 42/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 43/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 44/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 45/200
 - 325s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 46/200
 - 325s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 47/200
 - 324s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 48/200
 - 324s - loss: 0.0078 - val_loss: 0.0136
 - val_f1: 0.9458
Epoch 49/200
 - 325s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 50/200
 - 324s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 51/200
 - 324s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 52/200
 - 324s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 53/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 54/200
 - 324s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 55/200
 - 324s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 56/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 57/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 58/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 59/200
 - 325s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 60/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 61/200
 - 325s - loss: 0.0077 - val_loss: 0.0077
2020-01-02 04:10:13,406 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_60.pickle
 - val_f1: 0.9786
Epoch 62/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 63/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 64/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 65/200
 - 324s - loss: 0.0077 - val_loss: 0.0082
 - val_f1: 0.9743
Epoch 66/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 67/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 68/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 69/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 70/200
 - 324s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 71/200
 - 324s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 72/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 73/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 74/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 75/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 76/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 77/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 78/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 79/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 80/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 81/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
2020-01-02 06:20:38,290 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_80.pickle
 - val_f1: 0.9788
Epoch 82/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 83/200
 - 325s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 84/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 85/200
 - 324s - loss: 0.0076 - val_loss: 0.0088
 - val_f1: 0.9746
Epoch 86/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 87/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 88/200
 - 324s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 89/200
 - 325s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 90/200
 - 324s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 91/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 92/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 93/200
 - 324s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9779
Epoch 94/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 95/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 96/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 97/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 98/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 99/200
 - 325s - loss: 0.0076 - val_loss: 0.0091
 - val_f1: 0.9771
Epoch 100/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 101/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
2020-01-02 08:31:04,201 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_100.pickle
 - val_f1: 0.9788
Epoch 102/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 103/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 104/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 105/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 106/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 107/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 108/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 109/200
 - 324s - loss: 0.0076 - val_loss: 0.0218
 - val_f1: 0.9080
Epoch 110/200
 - 325s - loss: 0.0076 - val_loss: 0.0110
 - val_f1: 0.9680
Epoch 111/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 112/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 113/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 114/200
 - 324s - loss: 0.0076 - val_loss: 0.0120
 - val_f1: 0.9513
Epoch 115/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 116/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 117/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 118/200
 - 324s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 119/200
 - 324s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 120/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 121/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
2020-01-02 10:41:28,876 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_120.pickle
 - val_f1: 0.9794
Epoch 122/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 123/200
 - 325s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 124/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 125/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 126/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 127/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 128/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 129/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 130/200
 - 325s - loss: 0.0076 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 131/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 132/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 133/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 134/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 135/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 136/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 137/200
 - 324s - loss: 0.0076 - val_loss: 0.0822
 - val_f1: 0.8123
Epoch 138/200
 - 325s - loss: 0.0076 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 139/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 140/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9797
Epoch 141/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
2020-01-02 12:51:56,437 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_140.pickle
 - val_f1: 0.9789
Epoch 142/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 143/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 144/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 145/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 146/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 147/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 148/200
 - 325s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9794
Epoch 149/200
 - 325s - loss: 0.0076 - val_loss: 0.0153
 - val_f1: 0.9453
Epoch 150/200
 - 325s - loss: 0.0076 - val_loss: 0.0074
 - val_f1: 0.9795
Epoch 151/200
 - 324s - loss: 0.0076 - val_loss: 0.0155
 - val_f1: 0.9433
Epoch 152/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 153/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 154/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 155/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 156/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 157/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 158/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 159/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 160/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 161/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
2020-01-02 15:02:21,945 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_160.pickle
 - val_f1: 0.9791
Epoch 162/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 163/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 164/200
 - 325s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 165/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 166/200
 - 324s - loss: 0.0076 - val_loss: 0.0089
 - val_f1: 0.9780
Epoch 167/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 168/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 169/200
 - 324s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 170/200
 - 324s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9794
Epoch 171/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 172/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 173/200
 - 324s - loss: 0.0075 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 174/200
 - 325s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9805
Epoch 175/200
 - 325s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 176/200
 - 325s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 177/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 178/200
 - 324s - loss: 0.0075 - val_loss: 0.1129
 - val_f1: 0.8055
Epoch 179/200
 - 325s - loss: 0.0075 - val_loss: 0.0204
 - val_f1: 0.9427
Epoch 180/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 181/200
 - 325s - loss: 0.0075 - val_loss: 0.0075
2020-01-02 17:12:44,354 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_180.pickle
 - val_f1: 0.9786
Epoch 182/200
 - 324s - loss: 0.0075 - val_loss: 0.0576
 - val_f1: 0.8508
Epoch 183/200
 - 324s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 184/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9796
Epoch 185/200
 - 324s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9795
Epoch 186/200
 - 324s - loss: 0.0075 - val_loss: 0.0858
 - val_f1: 0.8352
Epoch 187/200
 - 324s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 188/200
 - 324s - loss: 0.0075 - val_loss: 0.0074
 - val_f1: 0.9793
Epoch 189/200
 - 324s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 190/200
 - 324s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 191/200
 - 325s - loss: 0.0075 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 192/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 193/200
 - 324s - loss: 0.0075 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 194/200
 - 324s - loss: 0.0075 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 195/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 196/200
 - 325s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 197/200
 - 324s - loss: 0.0075 - val_loss: 0.0074
 - val_f1: 0.9789
Epoch 198/200
 - 324s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9795
Epoch 199/200
 - 325s - loss: 0.0075 - val_loss: 0.0074
 - val_f1: 0.9792
Epoch 200/200
 - 324s - loss: 0.0075 - val_loss: 0.0074
2020-01-02 19:17:42,642 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-02 19:22:18,309 [INFO] Last epoch loss evaluation: train_loss = 0.007336, val_loss = 0.007433
2020-01-02 19:22:18,309 [INFO] Training complete. time_to_train = 78542.83 sec, 1309.05 min
2020-01-02 19:22:18,343 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/best_model.pickle
2020-01-02 19:22:18,346 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_error_history.csv
2020-01-02 19:22:18,486 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_error_history.png
2020-01-02 19:22:18,624 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_f1_history.png
2020-01-02 19:22:18,624 [INFO] Making predictions on training, validation, testing data
2020-01-02 19:27:52,351 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-02 19:28:04,539 [INFO] Dataset: Testing. Classification report below
2020-01-02 19:28:04,539 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.96      0.99      0.97       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.51      0.02      0.03      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.83      0.74      0.75    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-02 19:28:04,539 [INFO] Overall accuracy (micro avg): 0.9840028009815829
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-02 19:28:18,358 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8332                       0.7371                0.0043                   0.2629  0.7463
2  Weighted avg        0.9913         0.9795                       0.9840                0.0481                   0.0160  0.9791
2020-01-02 19:28:30,517 [INFO] Dataset: Validation. Classification report below
2020-01-02 19:28:30,517 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.92      0.48      0.63        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      1.00      0.87        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.98      0.97       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.48      0.02      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.84      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-02 19:28:30,517 [INFO] Overall accuracy (micro avg): 0.9840972784889549
2020-01-02 19:28:44,318 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9841         0.9841                       0.9841                0.0011                   0.0159  0.9841
1     Macro avg        0.9979         0.8384                       0.7695                0.0043                   0.2305  0.7791
2  Weighted avg        0.9912         0.9794                       0.9841                0.0481                   0.0159  0.9792
2020-01-02 19:29:24,101 [INFO] Dataset: Training. Classification report below
2020-01-02 19:29:24,101 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      1.00      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.97      1.00      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.60      0.02      0.04     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.85      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-02 19:29:24,101 [INFO] Overall accuracy (micro avg): 0.9840936718613637
2020-01-02 19:30:09,294 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9841         0.9841                       0.9841                0.0011                   0.0159  0.9841
1     Macro avg        0.9979         0.8451                       0.7514                0.0042                   0.2486  0.7629
2  Weighted avg        0.9913         0.9805                       0.9841                0.0478                   0.0159  0.9793
2020-01-02 19:30:09,333 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/ann_depth_ids18_subset_layers_10_results.xlsx
2020-01-02 19:30:09,338 [INFO] ================= Finished running experiment no. 10 ================= 

2020-01-02 19:30:09,417 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_11
2020-01-02 19:30:09,417 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_11/run_log.log
2020-01-02 19:30:09,417 [INFO] ================= Running experiment no. 11  ================= 

2020-01-02 19:30:09,417 [INFO] Experiment parameters given below
2020-01-02 19:30:09,417 [INFO] 
{'experiment_num': 11, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_11', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [900, 800, 700, 600, 500, 400, 256, 128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_11'}
2020-01-02 19:30:09,418 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_11/tf_logs_run_2020_01_02-19_30_09
2020-01-02 19:30:09,418 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-02 19:30:09,418 [INFO] Reading X, y files
2020-01-02 19:30:09,418 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-02 19:30:13,959 [INFO] Reading complete. time_to_read=4.54 seconds
2020-01-02 19:30:13,959 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-02 19:30:15,535 [INFO] Reading complete. time_to_read=1.58 seconds
2020-01-02 19:30:15,535 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-02 19:30:17,109 [INFO] Reading complete. time_to_read=1.57 seconds
2020-01-02 19:30:17,109 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-02 19:30:17,359 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-02 19:30:17,359 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-02 19:30:17,446 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-02 19:30:17,446 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-02 19:30:17,532 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-02 19:30:21,435 [INFO] Initializing model
2020-01-02 19:30:22,611 [INFO] _________________________________________________________________
2020-01-02 19:30:22,611 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-02 19:30:22,611 [INFO] =================================================================
2020-01-02 19:30:22,611 [INFO] dense_66 (Dense)             (None, 900)               70200     
2020-01-02 19:30:22,611 [INFO] _________________________________________________________________
2020-01-02 19:30:22,611 [INFO] batch_normalization_56 (Batc (None, 900)               3600      
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dropout_56 (Dropout)         (None, 900)               0         
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dense_67 (Dense)             (None, 800)               720800    
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] batch_normalization_57 (Batc (None, 800)               3200      
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dropout_57 (Dropout)         (None, 800)               0         
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dense_68 (Dense)             (None, 700)               560700    
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] batch_normalization_58 (Batc (None, 700)               2800      
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dropout_58 (Dropout)         (None, 700)               0         
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,612 [INFO] dense_69 (Dense)             (None, 600)               420600    
2020-01-02 19:30:22,612 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] batch_normalization_59 (Batc (None, 600)               2400      
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dropout_59 (Dropout)         (None, 600)               0         
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dense_70 (Dense)             (None, 500)               300500    
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] batch_normalization_60 (Batc (None, 500)               2000      
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dropout_60 (Dropout)         (None, 500)               0         
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dense_71 (Dense)             (None, 400)               200400    
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] batch_normalization_61 (Batc (None, 400)               1600      
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dropout_61 (Dropout)         (None, 400)               0         
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,613 [INFO] dense_72 (Dense)             (None, 256)               102656    
2020-01-02 19:30:22,613 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] batch_normalization_62 (Batc (None, 256)               1024      
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dropout_62 (Dropout)         (None, 256)               0         
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dense_73 (Dense)             (None, 128)               32896     
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] batch_normalization_63 (Batc (None, 128)               512       
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dropout_63 (Dropout)         (None, 128)               0         
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dense_74 (Dense)             (None, 64)                8256      
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] batch_normalization_64 (Batc (None, 64)                256       
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dropout_64 (Dropout)         (None, 64)                0         
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,614 [INFO] dense_75 (Dense)             (None, 32)                2080      
2020-01-02 19:30:22,614 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] batch_normalization_65 (Batc (None, 32)                128       
2020-01-02 19:30:22,615 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] dropout_65 (Dropout)         (None, 32)                0         
2020-01-02 19:30:22,615 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] dense_76 (Dense)             (None, 16)                528       
2020-01-02 19:30:22,615 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] batch_normalization_66 (Batc (None, 16)                64        
2020-01-02 19:30:22,615 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] dropout_66 (Dropout)         (None, 16)                0         
2020-01-02 19:30:22,615 [INFO] _________________________________________________________________
2020-01-02 19:30:22,615 [INFO] dense_77 (Dense)             (None, 15)                255       
2020-01-02 19:30:22,615 [INFO] =================================================================
2020-01-02 19:30:22,616 [INFO] Total params: 2,437,455
2020-01-02 19:30:22,616 [INFO] Trainable params: 2,428,663
2020-01-02 19:30:22,616 [INFO] Non-trainable params: 8,792
2020-01-02 19:30:22,616 [INFO] _________________________________________________________________
2020-01-02 19:30:22,616 [INFO] Training model
 - val_f1: 0.9794
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 439s - loss: 0.0155 - val_loss: 0.0090
 - val_f1: 0.9745
Epoch 2/200
 - 437s - loss: 0.0094 - val_loss: 0.0207
 - val_f1: 0.9377
Epoch 3/200
 - 437s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 4/200
 - 436s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 5/200
 - 437s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 6/200
 - 437s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 7/200
 - 437s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 8/200
 - 437s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 9/200
 - 437s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 10/200
 - 437s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 11/200
 - 437s - loss: 0.0081 - val_loss: 0.0117
 - val_f1: 0.9711
Epoch 12/200
 - 436s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 13/200
 - 437s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 14/200
 - 437s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 15/200
 - 437s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 16/200
 - 437s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 17/200
 - 437s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 18/200
 - 437s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 19/200
 - 437s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 20/200
 - 438s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 21/200
 - 437s - loss: 0.0080 - val_loss: 0.0085
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-02 22:31:33,357 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_20.pickle
 - val_f1: 0.9722
Epoch 22/200
 - 437s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 23/200
 - 437s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9773
Epoch 24/200
 - 438s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 25/200
 - 437s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 26/200
 - 438s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 27/200
 - 438s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 28/200
 - 437s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 29/200
 - 437s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 30/200
 - 437s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 31/200
 - 438s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 32/200
 - 437s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9756
Epoch 33/200
 - 437s - loss: 0.0079 - val_loss: 0.0344
 - val_f1: 0.9346
Epoch 34/200
 - 437s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 35/200
 - 437s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 36/200
 - 437s - loss: 0.0079 - val_loss: 0.0159
 - val_f1: 0.9520
Epoch 37/200
 - 437s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 38/200
 - 437s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9797
Epoch 39/200
 - 437s - loss: 0.0078 - val_loss: 0.0319
 - val_f1: 0.9090
Epoch 40/200
 - 438s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 41/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
2020-01-03 01:25:15,533 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_40.pickle
 - val_f1: 0.9781
Epoch 42/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 43/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 44/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 45/200
 - 437s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9770
Epoch 46/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 47/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 48/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 49/200
 - 437s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9764
Epoch 50/200
 - 437s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9752
Epoch 51/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 52/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 53/200
 - 437s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 54/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 55/200
 - 437s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 56/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 57/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 58/200
 - 437s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 59/200
 - 437s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 60/200
 - 437s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 61/200
 - 438s - loss: 0.0078 - val_loss: 0.0077
2020-01-03 04:18:55,347 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_60.pickle
 - val_f1: 0.9784
Epoch 62/200
 - 438s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 63/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 64/200
 - 437s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9780
Epoch 65/200
 - 437s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 66/200
 - 437s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 67/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 68/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 69/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 70/200
 - 437s - loss: 0.0077 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 71/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 72/200
 - 438s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 73/200
 - 438s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 74/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 75/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 76/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 77/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 78/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 79/200
 - 437s - loss: 0.0077 - val_loss: 0.0218
 - val_f1: 0.9583
Epoch 80/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 81/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
2020-01-03 07:12:36,369 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_80.pickle
 - val_f1: 0.9790
Epoch 82/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 83/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 84/200
 - 437s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 85/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 86/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 87/200
 - 437s - loss: 0.0077 - val_loss: 0.0120
 - val_f1: 0.9712
Epoch 88/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 89/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 90/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 91/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 92/200
 - 437s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 93/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 94/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 95/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 96/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 97/200
 - 437s - loss: 0.0077 - val_loss: 0.0172
 - val_f1: 0.9472
Epoch 98/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 99/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 100/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 101/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
2020-01-03 10:06:15,071 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_100.pickle
 - val_f1: 0.9789
Epoch 102/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9800
Epoch 103/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 104/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9785
Epoch 105/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 106/200
 - 437s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 107/200
 - 437s - loss: 0.0076 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 108/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 109/200
 - 437s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 110/200
 - 437s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9780
Epoch 111/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 112/200
 - 438s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 113/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 114/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 115/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 116/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9783
Epoch 117/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 118/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9786
Epoch 119/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 120/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 121/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
2020-01-03 12:59:56,017 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_120.pickle
 - val_f1: 0.9799
Epoch 122/200
 - 437s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 123/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 124/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 125/200
 - 437s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 126/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9789
Epoch 127/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 128/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 129/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 130/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 131/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 132/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 133/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 134/200
 - 437s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 135/200
 - 437s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 136/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 137/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 138/200
 - 438s - loss: 0.0076 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 139/200
 - 438s - loss: 0.0077 - val_loss: 0.0075
 - val_f1: 0.9788
Epoch 140/200
 - 438s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9779
Epoch 141/200
 - 438s - loss: 0.0076 - val_loss: 0.0075
2020-01-03 15:53:45,431 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_11/ann_model_epoch_140.pickle
 - val_f1: 0.9788
Epoch 142/200
 - 437s - loss: 0.0076 - val_loss: 0.0105
 - val_f1: 0.9726
Epoch 143/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 144/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 145/200
 - 438s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 146/200
 - 437s - loss: 0.0076 - val_loss: 0.0084
