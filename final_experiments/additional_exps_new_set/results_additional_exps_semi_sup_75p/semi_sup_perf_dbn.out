Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-06 14:41:17,347 [INFO] Read 6 experiments from file: experiment_specs/additional_exps/semi_sup_perf_dbn.csv
2020-01-06 14:41:17,348 [INFO] ================= Started running experiments ================= 

2020-01-06 14:41:17,348 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep1
2020-01-06 14:41:17,348 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep1/run_log.log
2020-01-06 14:41:17,348 [INFO] ================= Running experiment no. 1  ================= 

2020-01-06 14:41:17,348 [INFO] Experiment parameters given below
2020-01-06 14:41:17,348 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep1'}
2020-01-06 14:41:17,348 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/tf_logs_run_2020_01_06-14_41_17
2020-01-06 14:41:17,348 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-06 14:41:17,349 [INFO] Reading X, y files
2020-01-06 14:41:17,349 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-06 14:41:17,358 [INFO] NumExpr defaulting to 8 threads.
2020-01-06 14:41:17,596 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-06 14:41:17,596 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-06 14:41:17,658 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:41:17,658 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-06 14:41:17,714 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:41:17,714 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-06 14:41:17,722 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-06 14:41:17,722 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-06 14:41:17,727 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:41:17,727 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-06 14:41:17,731 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:41:17,847 [INFO] Initializing model
2020-01-06 14:41:17,847 [INFO] Training model
2020-01-06 14:41:17,847 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25238 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25249 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25250 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25251 thread 3 bound to OS proc set 3
2020-01-06 14:41:18,919 [INFO] Split sizes (instances). total = 100778, unsupervised = 75583, supervised = 25195, unsupervised dataset hash = 8b072afc9fe70a05a122da272177505315f7982c
2020-01-06 14:41:18,919 [INFO] Pretraining Deep Belief Network
2020-01-06 14:42:20,937 [INFO] Pretraining Complete
2020-01-06 14:42:20,937 [INFO] Getting pretrained weights
2020-01-06 14:42:20,937 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-06 14:42:20,952 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-06 14:42:21,027 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-06 14:42:21,072 [INFO] _________________________________________________________________
2020-01-06 14:42:21,072 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 14:42:21,072 [INFO] =================================================================
2020-01-06 14:42:21,073 [INFO] dense_1 (Dense)              (None, 64)                7872      
2020-01-06 14:42:21,073 [INFO] _________________________________________________________________
2020-01-06 14:42:21,073 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-06 14:42:21,073 [INFO] _________________________________________________________________
2020-01-06 14:42:21,073 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-06 14:42:21,073 [INFO] _________________________________________________________________
2020-01-06 14:42:21,073 [INFO] dense_2 (Dense)              (None, 5)                 325       
2020-01-06 14:42:21,073 [INFO] =================================================================
2020-01-06 14:42:21,073 [INFO] Total params: 8,453
2020-01-06 14:42:21,073 [INFO] Trainable params: 8,325
2020-01-06 14:42:21,074 [INFO] Non-trainable params: 128
2020-01-06 14:42:21,074 [INFO] _________________________________________________________________
2020-01-06 14:42:21.074205: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-06 14:42:21.095621: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-06 14:42:21.095863: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5582cd6f5580 executing computations on platform Host. Devices:
2020-01-06 14:42:21.095905: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-06 14:42:21.096068: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2020-01-06 14:42:21,182 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-06 14:42:21,607 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25262 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25300 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25301 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25302 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25303 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25263 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25304 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25306 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25307 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25305 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25308 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25309 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25310 thread 16 bound to OS proc set 0
[BernoulliRBM] Iteration 1, pseudo-likelihood = -73.36, time = 0.79s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -66.80, time = 1.26s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -62.52, time = 1.26s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -59.60, time = 1.26s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -57.58, time = 1.26s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.18, time = 1.26s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.25, time = 1.25s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -54.66, time = 1.25s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.34, time = 1.25s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.22, time = 1.25s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.28, time = 1.25s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.46, time = 1.25s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -54.75, time = 1.25s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -55.13, time = 1.25s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -55.58, time = 1.25s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -56.09, time = 1.25s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -56.64, time = 1.25s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -57.22, time = 1.25s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -57.83, time = 1.24s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -58.46, time = 1.25s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -59.11, time = 1.25s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -59.76, time = 1.25s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -60.42, time = 1.24s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -61.09, time = 1.24s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -61.77, time = 1.23s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -62.46, time = 1.24s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -63.16, time = 1.23s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -63.89, time = 1.23s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -64.66, time = 1.23s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -65.46, time = 1.23s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -66.29, time = 1.23s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -67.15, time = 1.23s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -68.01, time = 1.23s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -68.83, time = 1.23s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -69.61, time = 1.23s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -70.34, time = 1.23s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -71.03, time = 1.23s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -71.67, time = 1.23s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -72.28, time = 1.23s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -72.87, time = 1.23s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -73.42, time = 1.23s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -73.96, time = 1.24s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -74.46, time = 1.23s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -74.94, time = 1.23s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -75.39, time = 1.23s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -75.82, time = 1.23s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -76.23, time = 1.23s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -76.60, time = 1.23s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -76.95, time = 1.23s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -77.28, time = 1.23s
Train on 25195 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.2541 - val_loss: 0.1227
 - val_f1: 0.8945
Epoch 2/200
 - 0s - loss: 0.1134 - val_loss: 0.0784
 - val_f1: 0.9199
Epoch 3/200
 - 0s - loss: 0.0750 - val_loss: 0.0560
 - val_f1: 0.9623
Epoch 4/200
 - 0s - loss: 0.0530 - val_loss: 0.0416
 - val_f1: 0.9699
Epoch 5/200
 - 0s - loss: 0.0400 - val_loss: 0.0329
 - val_f1: 0.9725
Epoch 6/200
 - 0s - loss: 0.0308 - val_loss: 0.0253
 - val_f1: 0.9777
Epoch 7/200
 - 0s - loss: 0.0255 - val_loss: 0.0192
 - val_f1: 0.9850
Epoch 8/200
 - 0s - loss: 0.0220 - val_loss: 0.0168
 - val_f1: 0.9876
Epoch 9/200
 - 0s - loss: 0.0201 - val_loss: 0.0157
 - val_f1: 0.9864
Epoch 10/200
 - 0s - loss: 0.0184 - val_loss: 0.0153
 - val_f1: 0.9890
Epoch 11/200
 - 0s - loss: 0.0174 - val_loss: 0.0145
 - val_f1: 0.9892
Epoch 12/200
 - 0s - loss: 0.0159 - val_loss: 0.0142
 - val_f1: 0.9897
Epoch 13/200
 - 0s - loss: 0.0149 - val_loss: 0.0135
 - val_f1: 0.9903
Epoch 14/200
 - 0s - loss: 0.0138 - val_loss: 0.0134
 - val_f1: 0.9909
Epoch 15/200
 - 0s - loss: 0.0141 - val_loss: 0.0135
 - val_f1: 0.9898
Epoch 16/200
 - 0s - loss: 0.0132 - val_loss: 0.0125
 - val_f1: 0.9921
Epoch 17/200
 - 0s - loss: 0.0129 - val_loss: 0.0128
 - val_f1: 0.9906
Epoch 18/200
 - 0s - loss: 0.0125 - val_loss: 0.0127
 - val_f1: 0.9915
Epoch 19/200
 - 0s - loss: 0.0126 - val_loss: 0.0130
 - val_f1: 0.9896
Epoch 20/200
 - 0s - loss: 0.0122 - val_loss: 0.0134
 - val_f1: 0.9911
Epoch 21/200
 - 0s - loss: 0.0121 - val_loss: 0.0125
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 14:42:37,454 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9911
Epoch 22/200
 - 0s - loss: 0.0116 - val_loss: 0.0126
 - val_f1: 0.9917
Epoch 23/200
 - 0s - loss: 0.0115 - val_loss: 0.0120
 - val_f1: 0.9921
Epoch 24/200
 - 0s - loss: 0.0108 - val_loss: 0.0116
 - val_f1: 0.9923
Epoch 25/200
 - 0s - loss: 0.0110 - val_loss: 0.0121
 - val_f1: 0.9919
Epoch 26/200
 - 0s - loss: 0.0110 - val_loss: 0.0120
 - val_f1: 0.9929
Epoch 27/200
 - 0s - loss: 0.0108 - val_loss: 0.0117
 - val_f1: 0.9928
Epoch 28/200
 - 0s - loss: 0.0103 - val_loss: 0.0116
 - val_f1: 0.9922
Epoch 29/200
 - 0s - loss: 0.0102 - val_loss: 0.0117
 - val_f1: 0.9927
Epoch 30/200
 - 0s - loss: 0.0103 - val_loss: 0.0125
 - val_f1: 0.9911
Epoch 31/200
 - 0s - loss: 0.0099 - val_loss: 0.0116
 - val_f1: 0.9916
Epoch 32/200
 - 0s - loss: 0.0098 - val_loss: 0.0113
 - val_f1: 0.9921
Epoch 33/200
 - 0s - loss: 0.0096 - val_loss: 0.0116
 - val_f1: 0.9926
Epoch 34/200
 - 0s - loss: 0.0093 - val_loss: 0.0110
 - val_f1: 0.9933
Epoch 35/200
 - 0s - loss: 0.0093 - val_loss: 0.0111
 - val_f1: 0.9926
Epoch 36/200
 - 0s - loss: 0.0094 - val_loss: 0.0118
 - val_f1: 0.9919
Epoch 37/200
 - 0s - loss: 0.0091 - val_loss: 0.0109
 - val_f1: 0.9932
Epoch 38/200
 - 0s - loss: 0.0091 - val_loss: 0.0111
 - val_f1: 0.9926
Epoch 39/200
 - 0s - loss: 0.0093 - val_loss: 0.0104
 - val_f1: 0.9936
Epoch 40/200
 - 0s - loss: 0.0088 - val_loss: 0.0109
 - val_f1: 0.9929
Epoch 41/200
 - 0s - loss: 0.0089 - val_loss: 0.0109
2020-01-06 14:42:51,607 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9927
Epoch 42/200
 - 0s - loss: 0.0084 - val_loss: 0.0103
 - val_f1: 0.9936
Epoch 43/200
 - 0s - loss: 0.0087 - val_loss: 0.0106
 - val_f1: 0.9929
Epoch 44/200
 - 0s - loss: 0.0088 - val_loss: 0.0104
 - val_f1: 0.9936
Epoch 45/200
 - 0s - loss: 0.0085 - val_loss: 0.0104
 - val_f1: 0.9935
Epoch 46/200
 - 0s - loss: 0.0089 - val_loss: 0.0104
 - val_f1: 0.9930
Epoch 47/200
 - 0s - loss: 0.0081 - val_loss: 0.0102
 - val_f1: 0.9933
Epoch 48/200
 - 0s - loss: 0.0081 - val_loss: 0.0102
 - val_f1: 0.9940
Epoch 49/200
 - 0s - loss: 0.0083 - val_loss: 0.0102
 - val_f1: 0.9938
Epoch 50/200
 - 0s - loss: 0.0081 - val_loss: 0.0102
 - val_f1: 0.9939
Epoch 51/200
 - 0s - loss: 0.0082 - val_loss: 0.0118
 - val_f1: 0.9904
Epoch 52/200
 - 0s - loss: 0.0081 - val_loss: 0.0105
 - val_f1: 0.9940
Epoch 53/200
 - 0s - loss: 0.0076 - val_loss: 0.0106
 - val_f1: 0.9928
Epoch 54/200
 - 0s - loss: 0.0078 - val_loss: 0.0103
 - val_f1: 0.9935
Epoch 55/200
 - 0s - loss: 0.0077 - val_loss: 0.0108
 - val_f1: 0.9920
Epoch 56/200
 - 0s - loss: 0.0084 - val_loss: 0.0106
 - val_f1: 0.9921
Epoch 57/200
 - 0s - loss: 0.0073 - val_loss: 0.0098
 - val_f1: 0.9952
Epoch 58/200
 - 0s - loss: 0.0077 - val_loss: 0.0101
 - val_f1: 0.9939
Epoch 59/200
 - 0s - loss: 0.0075 - val_loss: 0.0096
 - val_f1: 0.9943
Epoch 60/200
 - 0s - loss: 0.0073 - val_loss: 0.0108
 - val_f1: 0.9924
Epoch 61/200
 - 0s - loss: 0.0077 - val_loss: 0.0096
2020-01-06 14:43:05,791 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9951
Epoch 62/200
 - 0s - loss: 0.0073 - val_loss: 0.0101
 - val_f1: 0.9942
Epoch 63/200
 - 0s - loss: 0.0071 - val_loss: 0.0102
 - val_f1: 0.9930
Epoch 64/200
 - 0s - loss: 0.0077 - val_loss: 0.0097
 - val_f1: 0.9940
Epoch 65/200
 - 0s - loss: 0.0071 - val_loss: 0.0097
 - val_f1: 0.9941
Epoch 66/200
 - 0s - loss: 0.0069 - val_loss: 0.0100
 - val_f1: 0.9927
Epoch 67/200
 - 0s - loss: 0.0067 - val_loss: 0.0094
 - val_f1: 0.9947
Epoch 68/200
 - 0s - loss: 0.0068 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 69/200
 - 0s - loss: 0.0071 - val_loss: 0.0098
 - val_f1: 0.9945
Epoch 70/200
 - 0s - loss: 0.0070 - val_loss: 0.0107
 - val_f1: 0.9932
Epoch 71/200
 - 0s - loss: 0.0070 - val_loss: 0.0100
 - val_f1: 0.9934
Epoch 72/200
 - 0s - loss: 0.0069 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 73/200
 - 0s - loss: 0.0068 - val_loss: 0.0100
 - val_f1: 0.9944
Epoch 74/200
 - 0s - loss: 0.0071 - val_loss: 0.0102
 - val_f1: 0.9938
Epoch 75/200
 - 0s - loss: 0.0066 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 76/200
 - 0s - loss: 0.0069 - val_loss: 0.0097
 - val_f1: 0.9939
Epoch 77/200
 - 0s - loss: 0.0060 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 78/200
 - 0s - loss: 0.0066 - val_loss: 0.0094
 - val_f1: 0.9947
Epoch 79/200
 - 0s - loss: 0.0066 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 80/200
 - 0s - loss: 0.0068 - val_loss: 0.0094
 - val_f1: 0.9948
Epoch 81/200
 - 0s - loss: 0.0069 - val_loss: 0.0098
2020-01-06 14:43:19,996 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9943
Epoch 82/200
 - 0s - loss: 0.0067 - val_loss: 0.0095
 - val_f1: 0.9945
Epoch 83/200
 - 0s - loss: 0.0062 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 84/200
 - 0s - loss: 0.0065 - val_loss: 0.0096
 - val_f1: 0.9952
Epoch 85/200
 - 0s - loss: 0.0066 - val_loss: 0.0097
 - val_f1: 0.9952
Epoch 86/200
 - 0s - loss: 0.0069 - val_loss: 0.0099
 - val_f1: 0.9945
Epoch 87/200
 - 0s - loss: 0.0062 - val_loss: 0.0100
 - val_f1: 0.9952
Epoch 88/200
 - 0s - loss: 0.0065 - val_loss: 0.0101
 - val_f1: 0.9949
Epoch 89/200
 - 0s - loss: 0.0063 - val_loss: 0.0098
 - val_f1: 0.9948
Epoch 90/200
 - 0s - loss: 0.0064 - val_loss: 0.0096
 - val_f1: 0.9954
Epoch 91/200
 - 0s - loss: 0.0060 - val_loss: 0.0100
 - val_f1: 0.9943
Epoch 92/200
 - 0s - loss: 0.0056 - val_loss: 0.0099
 - val_f1: 0.9954
Epoch 93/200
 - 0s - loss: 0.0064 - val_loss: 0.0097
 - val_f1: 0.9949
Epoch 94/200
 - 0s - loss: 0.0058 - val_loss: 0.0102
 - val_f1: 0.9940
Epoch 95/200
 - 0s - loss: 0.0063 - val_loss: 0.0096
 - val_f1: 0.9948
Epoch 96/200
 - 0s - loss: 0.0060 - val_loss: 0.0094
 - val_f1: 0.9951
Epoch 97/200
 - 0s - loss: 0.0063 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 98/200
 - 0s - loss: 0.0065 - val_loss: 0.0098
 - val_f1: 0.9951
Epoch 99/200
 - 0s - loss: 0.0059 - val_loss: 0.0099
 - val_f1: 0.9947
Epoch 100/200
 - 0s - loss: 0.0064 - val_loss: 0.0103
 - val_f1: 0.9939
Epoch 101/200
 - 0s - loss: 0.0062 - val_loss: 0.0094
2020-01-06 14:43:34,158 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9953
Epoch 102/200
 - 0s - loss: 0.0058 - val_loss: 0.0100
 - val_f1: 0.9948
Epoch 103/200
 - 0s - loss: 0.0059 - val_loss: 0.0101
 - val_f1: 0.9939
Epoch 104/200
 - 0s - loss: 0.0058 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 105/200
 - 0s - loss: 0.0060 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 106/200
 - 0s - loss: 0.0059 - val_loss: 0.0095
 - val_f1: 0.9951
Epoch 107/200
 - 0s - loss: 0.0060 - val_loss: 0.0097
 - val_f1: 0.9949
Epoch 108/200
 - 0s - loss: 0.0062 - val_loss: 0.0095
 - val_f1: 0.9952
Epoch 109/200
 - 0s - loss: 0.0057 - val_loss: 0.0096
 - val_f1: 0.9954
Epoch 110/200
 - 0s - loss: 0.0057 - val_loss: 0.0095
 - val_f1: 0.9951
Epoch 111/200
 - 0s - loss: 0.0059 - val_loss: 0.0098
 - val_f1: 0.9952
Epoch 112/200
 - 0s - loss: 0.0054 - val_loss: 0.0096
 - val_f1: 0.9943
Epoch 113/200
 - 0s - loss: 0.0060 - val_loss: 0.0102
 - val_f1: 0.9945
Epoch 114/200
 - 0s - loss: 0.0056 - val_loss: 0.0095
 - val_f1: 0.9955
Epoch 115/200
 - 0s - loss: 0.0060 - val_loss: 0.0099
 - val_f1: 0.9942
Epoch 116/200
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9952
Epoch 117/200
 - 0s - loss: 0.0058 - val_loss: 0.0095
 - val_f1: 0.9955
Epoch 118/200
 - 0s - loss: 0.0059 - val_loss: 0.0099
 - val_f1: 0.9943
Epoch 119/200
 - 0s - loss: 0.0055 - val_loss: 0.0097
 - val_f1: 0.9953
Epoch 120/200
 - 0s - loss: 0.0060 - val_loss: 0.0097
 - val_f1: 0.9952
Epoch 121/200
 - 0s - loss: 0.0058 - val_loss: 0.0098
2020-01-06 14:43:48,330 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9951
Epoch 122/200
 - 0s - loss: 0.0057 - val_loss: 0.0097
 - val_f1: 0.9952
Epoch 123/200
 - 0s - loss: 0.0055 - val_loss: 0.0094
 - val_f1: 0.9952
Epoch 124/200
 - 0s - loss: 0.0054 - val_loss: 0.0097
 - val_f1: 0.9955
Epoch 125/200
 - 0s - loss: 0.0057 - val_loss: 0.0099
 - val_f1: 0.9952
Epoch 126/200
 - 0s - loss: 0.0063 - val_loss: 0.0094
 - val_f1: 0.9954
Epoch 127/200
 - 0s - loss: 0.0056 - val_loss: 0.0102
 - val_f1: 0.9943
Epoch 128/200
 - 0s - loss: 0.0050 - val_loss: 0.0098
2020-01-06 14:43:53,629 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 14:43:54,545 [INFO] Last epoch loss evaluation: train_loss = 0.004716, val_loss = 0.009378
2020-01-06 14:43:54,546 [INFO] Training complete. time_to_train = 156.70 sec, 2.61 min
2020-01-06 14:43:54,550 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/best_model.pickle
2020-01-06 14:43:54,553 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/training_error_history.csv
2020-01-06 14:43:54,740 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/training_error_history.png
2020-01-06 14:43:54,908 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/training_f1_history.png
2020-01-06 14:43:54,908 [INFO] Making predictions on training, validation, testing data
2020-01-06 14:43:56,950 [INFO] Evaluating predictions (results)
2020-01-06 14:43:57,608 [INFO] Dataset: Testing. Classification report below
2020-01-06 14:43:57,608 [INFO] 
              precision    recall  f1-score   support

         dos       0.91      0.84      0.88      7458
      normal       0.68      0.93      0.78      9711
       probe       0.86      0.69      0.77      2421
         r2l       0.97      0.11      0.20      2421
         u2r       0.96      0.05      0.09       533

    accuracy                           0.77     22544
   macro avg       0.88      0.52      0.54     22544
weighted avg       0.81      0.77      0.73     22544

2020-01-06 14:43:57,608 [INFO] Overall accuracy (micro avg): 0.7671220723917672
2020-01-06 14:43:58,208 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7671         0.7671                       0.7671                0.0582                   0.2329  0.7671
1     Macro avg        0.9068         0.8758                       0.5249                0.0788                   0.4751  0.5424
2  Weighted avg        0.8621         0.8116                       0.7671                0.1609                   0.2329  0.7324
2020-01-06 14:43:58,950 [INFO] Dataset: Validation. Classification report below
2020-01-06 14:43:58,950 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      1.00      1.00     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.96      0.86      0.91       199
         u2r       0.75      0.30      0.43        10

    accuracy                           0.99     25195
   macro avg       0.94      0.83      0.86     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-06 14:43:58,950 [INFO] Overall accuracy (micro avg): 0.9947608652510419
2020-01-06 14:43:59,618 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0013                   0.0052  0.9948
1     Macro avg        0.9979         0.9374                       0.8281                0.0018                   0.1719  0.8629
2  Weighted avg        0.9967         0.9947                       0.9948                0.0037                   0.0052  0.9947
2020-01-06 14:44:02,455 [INFO] Dataset: Training. Classification report below
2020-01-06 14:44:02,455 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.95      0.86      0.90       796
         u2r       0.79      0.62      0.69        42

    accuracy                           1.00    100778
   macro avg       0.94      0.89      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2020-01-06 14:44:02,455 [INFO] Overall accuracy (micro avg): 0.9952370557066026
2020-01-06 14:44:05,488 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0012                   0.0048  0.9952
1     Macro avg        0.9981         0.9447                       0.8916                0.0017                   0.1084  0.9156
2  Weighted avg        0.9970         0.9952                       0.9952                0.0036                   0.0048  0.9952
2020-01-06 14:44:05,536 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/semi_sup_perf_nsl_dbn_rep1_results.xlsx
2020-01-06 14:44:05,536 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-06 14:44:05,537 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep2
2020-01-06 14:44:05,537 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep2/run_log.log
2020-01-06 14:44:05,537 [INFO] ================= Running experiment no. 2  ================= 

2020-01-06 14:44:05,537 [INFO] Experiment parameters given below
2020-01-06 14:44:05,537 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep2'}
2020-01-06 14:44:05,537 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/tf_logs_run_2020_01_06-14_44_05
2020-01-06 14:44:05,538 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-06 14:44:05,538 [INFO] Reading X, y files
2020-01-06 14:44:05,538 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-06 14:44:05,762 [INFO] Reading complete. time_to_read=0.22 seconds
2020-01-06 14:44:05,762 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-06 14:44:05,824 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:44:05,824 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-06 14:44:05,881 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:44:05,881 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-06 14:44:05,890 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-06 14:44:05,890 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-06 14:44:05,895 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:44:05,895 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-06 14:44:05,899 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:44:06,010 [INFO] Initializing model
2020-01-06 14:44:06,010 [INFO] Training model
2020-01-06 14:44:06,010 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-06 14:44:07,041 [INFO] Split sizes (instances). total = 100778, unsupervised = 75583, supervised = 25195, unsupervised dataset hash = fa2c869da32838df2ed8c355d0aea5fbbc432574
2020-01-06 14:44:07,041 [INFO] Pretraining Deep Belief Network
2020-01-06 14:45:14,345 [INFO] Pretraining Complete
2020-01-06 14:45:14,345 [INFO] Getting pretrained weights
2020-01-06 14:45:14,345 [INFO] Creating and initializing feed forward neural network
2020-01-06 14:45:14,464 [INFO] _________________________________________________________________
2020-01-06 14:45:14,464 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 14:45:14,465 [INFO] =================================================================
2020-01-06 14:45:14,465 [INFO] dense_3 (Dense)              (None, 64)                7872      
2020-01-06 14:45:14,465 [INFO] _________________________________________________________________
2020-01-06 14:45:14,465 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-06 14:45:14,465 [INFO] _________________________________________________________________
2020-01-06 14:45:14,465 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-06 14:45:14,465 [INFO] _________________________________________________________________
2020-01-06 14:45:14,465 [INFO] dense_4 (Dense)              (None, 5)                 325       
2020-01-06 14:45:14,465 [INFO] =================================================================
2020-01-06 14:45:14,465 [INFO] Total params: 8,453
2020-01-06 14:45:14,465 [INFO] Trainable params: 8,325
2020-01-06 14:45:14,466 [INFO] Non-trainable params: 128
2020-01-06 14:45:14,466 [INFO] _________________________________________________________________
2020-01-06 14:45:14,593 [INFO] Fine-tuning final neural network
 - val_f1: 0.9951
Epoch 00128: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -73.50, time = 0.83s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -67.02, time = 1.37s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -62.78, time = 1.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -59.90, time = 1.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -57.91, time = 1.36s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.54, time = 1.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.62, time = 1.36s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.05, time = 1.36s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.74, time = 1.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.63, time = 1.36s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.70, time = 1.36s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.89, time = 1.36s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -55.19, time = 1.35s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -55.57, time = 1.35s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -56.03, time = 1.35s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -56.53, time = 1.35s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -57.08, time = 1.35s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -57.67, time = 1.35s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.28, time = 1.35s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -58.91, time = 1.35s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -59.55, time = 1.35s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -60.20, time = 1.35s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -60.85, time = 1.35s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -61.50, time = 1.35s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -62.16, time = 1.34s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -62.83, time = 1.34s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -63.51, time = 1.34s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -64.21, time = 1.34s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -64.94, time = 1.34s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -65.70, time = 1.33s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -66.50, time = 1.34s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -67.33, time = 1.34s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -68.15, time = 1.33s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -68.95, time = 1.34s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -69.71, time = 1.34s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -70.43, time = 1.34s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -71.10, time = 1.34s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -71.73, time = 1.34s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -72.32, time = 1.34s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -72.88, time = 1.34s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -73.42, time = 1.34s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -73.93, time = 1.34s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -74.41, time = 1.34s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -74.86, time = 1.34s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -75.28, time = 1.34s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -75.68, time = 1.34s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -76.05, time = 1.34s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -76.39, time = 1.34s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -76.70, time = 1.34s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -76.99, time = 1.33s
Train on 25195 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3186 - val_loss: 0.1234
 - val_f1: 0.8932
Epoch 2/200
 - 0s - loss: 0.1111 - val_loss: 0.0731
 - val_f1: 0.9426
Epoch 3/200
 - 0s - loss: 0.0725 - val_loss: 0.0529
 - val_f1: 0.9602
Epoch 4/200
 - 0s - loss: 0.0508 - val_loss: 0.0421
 - val_f1: 0.9716
Epoch 5/200
 - 0s - loss: 0.0398 - val_loss: 0.0350
 - val_f1: 0.9775
Epoch 6/200
 - 0s - loss: 0.0306 - val_loss: 0.0280
 - val_f1: 0.9810
Epoch 7/200
 - 0s - loss: 0.0243 - val_loss: 0.0228
 - val_f1: 0.9859
Epoch 8/200
 - 0s - loss: 0.0210 - val_loss: 0.0204
 - val_f1: 0.9880
Epoch 9/200
 - 0s - loss: 0.0194 - val_loss: 0.0191
 - val_f1: 0.9860
Epoch 10/200
 - 0s - loss: 0.0174 - val_loss: 0.0181
 - val_f1: 0.9893
Epoch 11/200
 - 0s - loss: 0.0174 - val_loss: 0.0174
 - val_f1: 0.9888
Epoch 12/200
 - 0s - loss: 0.0164 - val_loss: 0.0166
 - val_f1: 0.9903
Epoch 13/200
 - 0s - loss: 0.0149 - val_loss: 0.0166
 - val_f1: 0.9906
Epoch 14/200
 - 0s - loss: 0.0146 - val_loss: 0.0158
 - val_f1: 0.9894
Epoch 15/200
 - 0s - loss: 0.0139 - val_loss: 0.0164
 - val_f1: 0.9901
Epoch 16/200
 - 0s - loss: 0.0131 - val_loss: 0.0165
 - val_f1: 0.9899
Epoch 17/200
 - 0s - loss: 0.0130 - val_loss: 0.0152
 - val_f1: 0.9903
Epoch 18/200
 - 0s - loss: 0.0125 - val_loss: 0.0147
 - val_f1: 0.9910
Epoch 19/200
 - 0s - loss: 0.0122 - val_loss: 0.0148
 - val_f1: 0.9898
Epoch 20/200
 - 0s - loss: 0.0112 - val_loss: 0.0146
 - val_f1: 0.9899
Epoch 21/200
 - 0s - loss: 0.0120 - val_loss: 0.0149
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 14:45:31,284 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9901
Epoch 22/200
 - 0s - loss: 0.0112 - val_loss: 0.0142
 - val_f1: 0.9913
Epoch 23/200
 - 0s - loss: 0.0110 - val_loss: 0.0142
 - val_f1: 0.9914
Epoch 24/200
 - 0s - loss: 0.0100 - val_loss: 0.0143
 - val_f1: 0.9903
Epoch 25/200
 - 0s - loss: 0.0107 - val_loss: 0.0136
 - val_f1: 0.9920
Epoch 26/200
 - 0s - loss: 0.0105 - val_loss: 0.0137
 - val_f1: 0.9912
Epoch 27/200
 - 0s - loss: 0.0105 - val_loss: 0.0136
 - val_f1: 0.9922
Epoch 28/200
 - 0s - loss: 0.0100 - val_loss: 0.0134
 - val_f1: 0.9919
Epoch 29/200
 - 0s - loss: 0.0099 - val_loss: 0.0135
 - val_f1: 0.9914
Epoch 30/200
 - 0s - loss: 0.0093 - val_loss: 0.0131
 - val_f1: 0.9924
Epoch 31/200
 - 0s - loss: 0.0096 - val_loss: 0.0131
 - val_f1: 0.9922
Epoch 32/200
 - 0s - loss: 0.0097 - val_loss: 0.0135
 - val_f1: 0.9922
Epoch 33/200
 - 0s - loss: 0.0089 - val_loss: 0.0133
 - val_f1: 0.9923
Epoch 34/200
 - 0s - loss: 0.0089 - val_loss: 0.0130
 - val_f1: 0.9928
Epoch 35/200
 - 0s - loss: 0.0091 - val_loss: 0.0138
 - val_f1: 0.9899
Epoch 36/200
 - 0s - loss: 0.0090 - val_loss: 0.0129
 - val_f1: 0.9926
Epoch 37/200
 - 0s - loss: 0.0087 - val_loss: 0.0130
 - val_f1: 0.9923
Epoch 38/200
 - 0s - loss: 0.0084 - val_loss: 0.0139
 - val_f1: 0.9918
Epoch 39/200
 - 0s - loss: 0.0085 - val_loss: 0.0131
 - val_f1: 0.9906
Epoch 40/200
 - 0s - loss: 0.0082 - val_loss: 0.0125
 - val_f1: 0.9929
Epoch 41/200
 - 0s - loss: 0.0079 - val_loss: 0.0131
2020-01-06 14:45:46,130 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9918
Epoch 42/200
 - 0s - loss: 0.0085 - val_loss: 0.0126
 - val_f1: 0.9927
Epoch 43/200
 - 0s - loss: 0.0084 - val_loss: 0.0125
 - val_f1: 0.9935
Epoch 44/200
 - 0s - loss: 0.0080 - val_loss: 0.0127
 - val_f1: 0.9928
Epoch 45/200
 - 0s - loss: 0.0082 - val_loss: 0.0129
 - val_f1: 0.9915
Epoch 46/200
 - 0s - loss: 0.0078 - val_loss: 0.0128
 - val_f1: 0.9931
Epoch 47/200
 - 0s - loss: 0.0074 - val_loss: 0.0132
 - val_f1: 0.9912
Epoch 48/200
 - 0s - loss: 0.0079 - val_loss: 0.0125
 - val_f1: 0.9916
Epoch 49/200
 - 0s - loss: 0.0073 - val_loss: 0.0124
 - val_f1: 0.9933
Epoch 50/200
 - 0s - loss: 0.0075 - val_loss: 0.0125
 - val_f1: 0.9932
Epoch 51/200
 - 0s - loss: 0.0073 - val_loss: 0.0124
 - val_f1: 0.9929
Epoch 52/200
 - 0s - loss: 0.0074 - val_loss: 0.0123
 - val_f1: 0.9933
Epoch 53/200
 - 0s - loss: 0.0073 - val_loss: 0.0125
 - val_f1: 0.9930
Epoch 54/200
 - 0s - loss: 0.0073 - val_loss: 0.0123
 - val_f1: 0.9933
Epoch 55/200
 - 0s - loss: 0.0072 - val_loss: 0.0126
 - val_f1: 0.9920
Epoch 56/200
 - 0s - loss: 0.0070 - val_loss: 0.0123
 - val_f1: 0.9938
Epoch 57/200
 - 0s - loss: 0.0067 - val_loss: 0.0122
 - val_f1: 0.9934
Epoch 58/200
 - 0s - loss: 0.0068 - val_loss: 0.0120
 - val_f1: 0.9936
Epoch 59/200
 - 0s - loss: 0.0070 - val_loss: 0.0120
 - val_f1: 0.9940
Epoch 60/200
 - 0s - loss: 0.0068 - val_loss: 0.0120
 - val_f1: 0.9938
Epoch 61/200
 - 0s - loss: 0.0064 - val_loss: 0.0121
2020-01-06 14:46:00,967 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9935
Epoch 62/200
 - 0s - loss: 0.0065 - val_loss: 0.0121
 - val_f1: 0.9938
Epoch 63/200
 - 0s - loss: 0.0069 - val_loss: 0.0124
 - val_f1: 0.9934
Epoch 64/200
 - 0s - loss: 0.0066 - val_loss: 0.0123
 - val_f1: 0.9933
Epoch 65/200
 - 0s - loss: 0.0072 - val_loss: 0.0124
 - val_f1: 0.9940
Epoch 66/200
 - 0s - loss: 0.0068 - val_loss: 0.0128
 - val_f1: 0.9928
Epoch 67/200
 - 0s - loss: 0.0072 - val_loss: 0.0124
 - val_f1: 0.9934
Epoch 68/200
 - 0s - loss: 0.0063 - val_loss: 0.0122
 - val_f1: 0.9935
Epoch 69/200
 - 0s - loss: 0.0064 - val_loss: 0.0121
 - val_f1: 0.9940
Epoch 70/200
 - 0s - loss: 0.0069 - val_loss: 0.0121
 - val_f1: 0.9937
Epoch 71/200
 - 0s - loss: 0.0069 - val_loss: 0.0122
 - val_f1: 0.9934
Epoch 72/200
 - 0s - loss: 0.0067 - val_loss: 0.0120
 - val_f1: 0.9944
Epoch 73/200
 - 0s - loss: 0.0064 - val_loss: 0.0137
 - val_f1: 0.9926
Epoch 74/200
 - 0s - loss: 0.0066 - val_loss: 0.0121
 - val_f1: 0.9936
Epoch 75/200
 - 0s - loss: 0.0063 - val_loss: 0.0122
 - val_f1: 0.9942
Epoch 76/200
 - 0s - loss: 0.0063 - val_loss: 0.0122
 - val_f1: 0.9944
Epoch 77/200
 - 0s - loss: 0.0064 - val_loss: 0.0121
 - val_f1: 0.9938
Epoch 78/200
 - 0s - loss: 0.0061 - val_loss: 0.0118
 - val_f1: 0.9944
Epoch 79/200
 - 0s - loss: 0.0061 - val_loss: 0.0124
 - val_f1: 0.9942
Epoch 80/200
 - 0s - loss: 0.0059 - val_loss: 0.0117
 - val_f1: 0.9946
Epoch 81/200
 - 0s - loss: 0.0062 - val_loss: 0.0121
2020-01-06 14:46:15,906 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9944
Epoch 82/200
 - 0s - loss: 0.0060 - val_loss: 0.0137
 - val_f1: 0.9924
Epoch 83/200
 - 0s - loss: 0.0063 - val_loss: 0.0128
 - val_f1: 0.9939
Epoch 84/200
 - 0s - loss: 0.0060 - val_loss: 0.0125
 - val_f1: 0.9943
Epoch 85/200
 - 0s - loss: 0.0062 - val_loss: 0.0128
 - val_f1: 0.9921
Epoch 86/200
 - 0s - loss: 0.0061 - val_loss: 0.0125
 - val_f1: 0.9937
Epoch 87/200
 - 0s - loss: 0.0059 - val_loss: 0.0128
 - val_f1: 0.9934
Epoch 88/200
 - 0s - loss: 0.0062 - val_loss: 0.0127
 - val_f1: 0.9943
Epoch 89/200
 - 0s - loss: 0.0059 - val_loss: 0.0125
 - val_f1: 0.9946
Epoch 90/200
 - 0s - loss: 0.0059 - val_loss: 0.0127
 - val_f1: 0.9942
Epoch 91/200
 - 0s - loss: 0.0052 - val_loss: 0.0125
 - val_f1: 0.9948
Epoch 92/200
 - 0s - loss: 0.0061 - val_loss: 0.0128
 - val_f1: 0.9940
Epoch 93/200
 - 0s - loss: 0.0060 - val_loss: 0.0126
 - val_f1: 0.9943
Epoch 94/200
 - 0s - loss: 0.0054 - val_loss: 0.0126
 - val_f1: 0.9945
Epoch 95/200
 - 0s - loss: 0.0051 - val_loss: 0.0121
 - val_f1: 0.9946
Epoch 96/200
 - 0s - loss: 0.0057 - val_loss: 0.0125
 - val_f1: 0.9943
Epoch 97/200
 - 0s - loss: 0.0053 - val_loss: 0.0122
 - val_f1: 0.9943
Epoch 98/200
 - 0s - loss: 0.0053 - val_loss: 0.0125
 - val_f1: 0.9942
Epoch 99/200
 - 0s - loss: 0.0054 - val_loss: 0.0122
 - val_f1: 0.9950
Epoch 100/200
 - 0s - loss: 0.0054 - val_loss: 0.0124
 - val_f1: 0.9947
Epoch 101/200
 - 0s - loss: 0.0058 - val_loss: 0.0123
2020-01-06 14:46:30,741 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9942
Epoch 102/200
 - 0s - loss: 0.0052 - val_loss: 0.0122
 - val_f1: 0.9949
Epoch 103/200
 - 0s - loss: 0.0051 - val_loss: 0.0125
 - val_f1: 0.9943
Epoch 104/200
 - 0s - loss: 0.0055 - val_loss: 0.0123
 - val_f1: 0.9947
Epoch 105/200
 - 0s - loss: 0.0055 - val_loss: 0.0128
 - val_f1: 0.9943
Epoch 106/200
 - 0s - loss: 0.0056 - val_loss: 0.0129
 - val_f1: 0.9944
Epoch 107/200
 - 0s - loss: 0.0054 - val_loss: 0.0123
 - val_f1: 0.9948
Epoch 108/200
 - 0s - loss: 0.0051 - val_loss: 0.0124
 - val_f1: 0.9945
Epoch 109/200
 - 0s - loss: 0.0050 - val_loss: 0.0127
 - val_f1: 0.9947
Epoch 110/200
 - 0s - loss: 0.0050 - val_loss: 0.0128
 - val_f1: 0.9942
Epoch 111/200
 - 0s - loss: 0.0048 - val_loss: 0.0124
 - val_f1: 0.9949
Epoch 112/200
 - 0s - loss: 0.0054 - val_loss: 0.0126
 - val_f1: 0.9946
Epoch 113/200
 - 0s - loss: 0.0052 - val_loss: 0.0126
 - val_f1: 0.9946
Epoch 114/200
 - 0s - loss: 0.0052 - val_loss: 0.0125
 - val_f1: 0.9947
Epoch 115/200
 - 0s - loss: 0.0047 - val_loss: 0.0124
 - val_f1: 0.9953
Epoch 116/200
 - 0s - loss: 0.0047 - val_loss: 0.0125
 - val_f1: 0.9949
Epoch 117/200
 - 0s - loss: 0.0048 - val_loss: 0.0125
 - val_f1: 0.9952
Epoch 118/200
 - 0s - loss: 0.0053 - val_loss: 0.0124
 - val_f1: 0.9947
Epoch 119/200
 - 0s - loss: 0.0049 - val_loss: 0.0130
 - val_f1: 0.9944
Epoch 120/200
 - 0s - loss: 0.0056 - val_loss: 0.0132
 - val_f1: 0.9925
Epoch 121/200
 - 0s - loss: 0.0051 - val_loss: 0.0123
2020-01-06 14:46:45,580 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9952
Epoch 122/200
 - 0s - loss: 0.0049 - val_loss: 0.0126
 - val_f1: 0.9946
Epoch 123/200
 - 0s - loss: 0.0048 - val_loss: 0.0125
 - val_f1: 0.9948
Epoch 124/200
 - 0s - loss: 0.0050 - val_loss: 0.0128
 - val_f1: 0.9946
Epoch 125/200
 - 0s - loss: 0.0051 - val_loss: 0.0130
 - val_f1: 0.9940
Epoch 126/200
 - 0s - loss: 0.0046 - val_loss: 0.0131
 - val_f1: 0.9944
Epoch 127/200
 - 0s - loss: 0.0044 - val_loss: 0.0127
 - val_f1: 0.9948
Epoch 128/200
 - 0s - loss: 0.0051 - val_loss: 0.0134
 - val_f1: 0.9944
Epoch 129/200
 - 0s - loss: 0.0046 - val_loss: 0.0132
 - val_f1: 0.9946
Epoch 130/200
 - 0s - loss: 0.0048 - val_loss: 0.0130
2020-01-06 14:46:52,635 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 14:46:53,617 [INFO] Last epoch loss evaluation: train_loss = 0.004233, val_loss = 0.011689
2020-01-06 14:46:53,621 [INFO] Training complete. time_to_train = 167.61 sec, 2.79 min
2020-01-06 14:46:53,625 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/best_model.pickle
2020-01-06 14:46:53,628 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/training_error_history.csv
2020-01-06 14:46:53,813 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/training_error_history.png
2020-01-06 14:46:53,981 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/training_f1_history.png
2020-01-06 14:46:53,981 [INFO] Making predictions on training, validation, testing data
2020-01-06 14:46:56,216 [INFO] Evaluating predictions (results)
2020-01-06 14:46:56,766 [INFO] Dataset: Testing. Classification report below
2020-01-06 14:46:56,766 [INFO] 
              precision    recall  f1-score   support

         dos       0.92      0.85      0.88      7458
      normal       0.68      0.93      0.79      9711
       probe       0.85      0.72      0.78      2421
         r2l       0.91      0.11      0.19      2421
         u2r       0.63      0.03      0.06       533

    accuracy                           0.77     22544
   macro avg       0.80      0.53      0.54     22544
weighted avg       0.80      0.77      0.74     22544

2020-01-06 14:46:56,766 [INFO] Overall accuracy (micro avg): 0.7728442157558553
2020-01-06 14:46:57,362 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7728         0.7728                       0.7728                0.0568                   0.2272  0.7728
1     Macro avg        0.9091         0.7968                       0.5286                0.0765                   0.4714  0.5404
2  Weighted avg        0.8669         0.8008                       0.7728                0.1551                   0.2272  0.7374
2020-01-06 14:46:58,035 [INFO] Dataset: Validation. Classification report below
2020-01-06 14:46:58,035 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.98      0.99      0.98      2331
         r2l       0.93      0.88      0.90       199
         u2r       0.50      0.30      0.37        10

    accuracy                           0.99     25195
   macro avg       0.88      0.83      0.85     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-06 14:46:58,035 [INFO] Overall accuracy (micro avg): 0.9946021035919825
2020-01-06 14:46:58,706 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0013                   0.0054  0.9946
1     Macro avg        0.9978         0.8809                       0.8323                0.0017                   0.1677  0.8515
2  Weighted avg        0.9967         0.9945                       0.9946                0.0031                   0.0054  0.9945
2020-01-06 14:47:01,540 [INFO] Dataset: Training. Classification report below
2020-01-06 14:47:01,540 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.91      0.86      0.88       796
         u2r       0.83      0.48      0.61        42

    accuracy                           0.99    100778
   macro avg       0.94      0.86      0.89    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-06 14:47:01,540 [INFO] Overall accuracy (micro avg): 0.9946913016729841
2020-01-06 14:47:04,575 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0013                   0.0053  0.9947
1     Macro avg        0.9979         0.9443                       0.8637                0.0018                   0.1363  0.8941
2  Weighted avg        0.9967         0.9946                       0.9947                0.0035                   0.0053  0.9946
2020-01-06 14:47:04,623 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/semi_sup_perf_nsl_dbn_rep2_results.xlsx
2020-01-06 14:47:04,624 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-06 14:47:04,625 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep3
2020-01-06 14:47:04,625 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep3/run_log.log
2020-01-06 14:47:04,625 [INFO] ================= Running experiment no. 3  ================= 

2020-01-06 14:47:04,625 [INFO] Experiment parameters given below
2020-01-06 14:47:04,625 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep3'}
2020-01-06 14:47:04,625 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/tf_logs_run_2020_01_06-14_47_04
2020-01-06 14:47:04,625 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-06 14:47:04,626 [INFO] Reading X, y files
2020-01-06 14:47:04,626 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-06 14:47:04,852 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-06 14:47:04,853 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-06 14:47:04,915 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:47:04,916 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-06 14:47:04,972 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-06 14:47:04,972 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-06 14:47:04,981 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-06 14:47:04,981 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-06 14:47:04,986 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:47:04,986 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-06 14:47:04,990 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-06 14:47:05,101 [INFO] Initializing model
2020-01-06 14:47:05,101 [INFO] Training model
2020-01-06 14:47:05,101 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-06 14:47:06,138 [INFO] Split sizes (instances). total = 100778, unsupervised = 75583, supervised = 25195, unsupervised dataset hash = 48720e8cdf11e442c33e6eac2b98c9f72d4e31bf
2020-01-06 14:47:06,138 [INFO] Pretraining Deep Belief Network
2020-01-06 14:48:13,540 [INFO] Pretraining Complete
2020-01-06 14:48:13,540 [INFO] Getting pretrained weights
2020-01-06 14:48:13,540 [INFO] Creating and initializing feed forward neural network
2020-01-06 14:48:13,659 [INFO] _________________________________________________________________
2020-01-06 14:48:13,659 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 14:48:13,659 [INFO] =================================================================
2020-01-06 14:48:13,660 [INFO] dense_5 (Dense)              (None, 64)                7872      
2020-01-06 14:48:13,660 [INFO] _________________________________________________________________
2020-01-06 14:48:13,660 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-06 14:48:13,660 [INFO] _________________________________________________________________
2020-01-06 14:48:13,660 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-06 14:48:13,660 [INFO] _________________________________________________________________
2020-01-06 14:48:13,660 [INFO] dense_6 (Dense)              (None, 5)                 325       
2020-01-06 14:48:13,660 [INFO] =================================================================
2020-01-06 14:48:13,660 [INFO] Total params: 8,453
2020-01-06 14:48:13,660 [INFO] Trainable params: 8,325
2020-01-06 14:48:13,661 [INFO] Non-trainable params: 128
2020-01-06 14:48:13,661 [INFO] _________________________________________________________________
2020-01-06 14:48:13,845 [INFO] Fine-tuning final neural network
 - val_f1: 0.9951
Epoch 00130: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -73.05, time = 0.83s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -66.22, time = 1.38s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -61.68, time = 1.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -58.54, time = 1.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.30, time = 1.36s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -54.72, time = 1.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -53.60, time = 1.36s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -52.84, time = 1.36s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -52.36, time = 1.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -52.09, time = 1.36s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -52.00, time = 1.36s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -52.04, time = 1.36s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -52.20, time = 1.36s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -52.45, time = 1.36s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -52.77, time = 1.36s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -53.15, time = 1.35s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -53.58, time = 1.35s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -54.05, time = 1.35s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -54.55, time = 1.35s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -55.07, time = 1.35s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -55.60, time = 1.35s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.15, time = 1.35s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -56.70, time = 1.35s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -57.26, time = 1.35s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.83, time = 1.35s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -58.41, time = 1.34s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -59.01, time = 1.34s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -59.63, time = 1.34s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -60.28, time = 1.34s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -60.96, time = 1.34s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -61.68, time = 1.34s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -62.42, time = 1.34s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -63.16, time = 1.34s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -63.87, time = 1.34s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -64.55, time = 1.34s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -65.18, time = 1.34s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -65.77, time = 1.34s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -66.32, time = 1.34s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -66.84, time = 1.34s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -67.33, time = 1.34s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -67.80, time = 1.34s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -68.25, time = 1.34s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -68.67, time = 1.34s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -69.07, time = 1.34s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -69.43, time = 1.34s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -69.78, time = 1.34s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -70.11, time = 1.34s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -70.41, time = 1.34s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -70.69, time = 1.34s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -70.94, time = 1.34s
Train on 25195 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.2900 - val_loss: 0.1257
 - val_f1: 0.8949
Epoch 2/200
 - 0s - loss: 0.1139 - val_loss: 0.0744
 - val_f1: 0.9362
Epoch 3/200
 - 0s - loss: 0.0692 - val_loss: 0.0519
 - val_f1: 0.9622
Epoch 4/200
 - 0s - loss: 0.0483 - val_loss: 0.0388
 - val_f1: 0.9715
Epoch 5/200
 - 0s - loss: 0.0365 - val_loss: 0.0291
 - val_f1: 0.9747
Epoch 6/200
 - 0s - loss: 0.0274 - val_loss: 0.0222
 - val_f1: 0.9818
Epoch 7/200
 - 0s - loss: 0.0224 - val_loss: 0.0180
 - val_f1: 0.9865
Epoch 8/200
 - 0s - loss: 0.0205 - val_loss: 0.0162
 - val_f1: 0.9890
Epoch 9/200
 - 0s - loss: 0.0175 - val_loss: 0.0145
 - val_f1: 0.9908
Epoch 10/200
 - 0s - loss: 0.0164 - val_loss: 0.0136
 - val_f1: 0.9902
Epoch 11/200
 - 0s - loss: 0.0158 - val_loss: 0.0132
 - val_f1: 0.9889
Epoch 12/200
 - 0s - loss: 0.0142 - val_loss: 0.0126
 - val_f1: 0.9906
Epoch 13/200
 - 0s - loss: 0.0140 - val_loss: 0.0126
 - val_f1: 0.9876
Epoch 14/200
 - 0s - loss: 0.0137 - val_loss: 0.0121
 - val_f1: 0.9906
Epoch 15/200
 - 0s - loss: 0.0135 - val_loss: 0.0117
 - val_f1: 0.9922
Epoch 16/200
 - 0s - loss: 0.0125 - val_loss: 0.0118
 - val_f1: 0.9918
Epoch 17/200
 - 0s - loss: 0.0120 - val_loss: 0.0113
 - val_f1: 0.9923
Epoch 18/200
 - 0s - loss: 0.0115 - val_loss: 0.0111
 - val_f1: 0.9921
Epoch 19/200
 - 0s - loss: 0.0115 - val_loss: 0.0113
 - val_f1: 0.9926
Epoch 20/200
 - 0s - loss: 0.0110 - val_loss: 0.0108
 - val_f1: 0.9925
Epoch 21/200
 - 0s - loss: 0.0109 - val_loss: 0.0109
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 14:48:31,380 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9920
Epoch 22/200
 - 0s - loss: 0.0104 - val_loss: 0.0106
 - val_f1: 0.9925
Epoch 23/200
 - 0s - loss: 0.0102 - val_loss: 0.0104
 - val_f1: 0.9923
Epoch 24/200
 - 0s - loss: 0.0097 - val_loss: 0.0106
 - val_f1: 0.9923
Epoch 25/200
 - 0s - loss: 0.0096 - val_loss: 0.0104
 - val_f1: 0.9925
Epoch 26/200
 - 0s - loss: 0.0103 - val_loss: 0.0112
 - val_f1: 0.9921
Epoch 27/200
 - 0s - loss: 0.0094 - val_loss: 0.0102
 - val_f1: 0.9927
Epoch 28/200
 - 0s - loss: 0.0095 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 29/200
 - 0s - loss: 0.0086 - val_loss: 0.0101
 - val_f1: 0.9923
Epoch 30/200
 - 0s - loss: 0.0089 - val_loss: 0.0108
 - val_f1: 0.9903
Epoch 31/200
 - 0s - loss: 0.0090 - val_loss: 0.0100
 - val_f1: 0.9932
Epoch 32/200
 - 0s - loss: 0.0092 - val_loss: 0.0107
 - val_f1: 0.9926
Epoch 33/200
 - 0s - loss: 0.0089 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 34/200
 - 0s - loss: 0.0089 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 35/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9930
Epoch 36/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 37/200
 - 0s - loss: 0.0083 - val_loss: 0.0107
 - val_f1: 0.9930
Epoch 38/200
 - 0s - loss: 0.0082 - val_loss: 0.0106
 - val_f1: 0.9918
Epoch 39/200
 - 0s - loss: 0.0089 - val_loss: 0.0099
 - val_f1: 0.9929
Epoch 40/200
 - 0s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9938
Epoch 41/200
 - 0s - loss: 0.0081 - val_loss: 0.0104
2020-01-06 14:48:46,779 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9925
Epoch 42/200
 - 0s - loss: 0.0075 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 43/200
 - 0s - loss: 0.0079 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 44/200
 - 0s - loss: 0.0080 - val_loss: 0.0097
 - val_f1: 0.9930
Epoch 45/200
 - 0s - loss: 0.0076 - val_loss: 0.0103
 - val_f1: 0.9930
Epoch 46/200
 - 0s - loss: 0.0076 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 47/200
 - 0s - loss: 0.0079 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 48/200
 - 0s - loss: 0.0077 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 49/200
 - 0s - loss: 0.0075 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 50/200
 - 0s - loss: 0.0076 - val_loss: 0.0109
 - val_f1: 0.9927
Epoch 51/200
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9937
Epoch 52/200
 - 0s - loss: 0.0078 - val_loss: 0.0102
 - val_f1: 0.9936
Epoch 53/200
 - 0s - loss: 0.0072 - val_loss: 0.0098
 - val_f1: 0.9935
Epoch 54/200
 - 0s - loss: 0.0069 - val_loss: 0.0099
 - val_f1: 0.9930
Epoch 55/200
 - 0s - loss: 0.0069 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 56/200
 - 0s - loss: 0.0072 - val_loss: 0.0097
 - val_f1: 0.9937
Epoch 57/200
 - 0s - loss: 0.0069 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 58/200
 - 0s - loss: 0.0068 - val_loss: 0.0094
 - val_f1: 0.9947
Epoch 59/200
 - 0s - loss: 0.0065 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 60/200
 - 0s - loss: 0.0069 - val_loss: 0.0096
 - val_f1: 0.9941
Epoch 61/200
 - 0s - loss: 0.0068 - val_loss: 0.0096
2020-01-06 14:49:02,201 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9938
Epoch 62/200
 - 0s - loss: 0.0069 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 63/200
 - 0s - loss: 0.0068 - val_loss: 0.0095
 - val_f1: 0.9941
Epoch 64/200
 - 0s - loss: 0.0066 - val_loss: 0.0099
 - val_f1: 0.9937
Epoch 65/200
 - 0s - loss: 0.0064 - val_loss: 0.0095
 - val_f1: 0.9938
Epoch 66/200
 - 0s - loss: 0.0071 - val_loss: 0.0093
 - val_f1: 0.9937
Epoch 67/200
 - 0s - loss: 0.0067 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 68/200
 - 0s - loss: 0.0060 - val_loss: 0.0092
 - val_f1: 0.9944
Epoch 69/200
 - 0s - loss: 0.0064 - val_loss: 0.0094
 - val_f1: 0.9941
Epoch 70/200
 - 0s - loss: 0.0055 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 71/200
 - 0s - loss: 0.0062 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 72/200
 - 0s - loss: 0.0063 - val_loss: 0.0098
 - val_f1: 0.9939
Epoch 73/200
 - 0s - loss: 0.0064 - val_loss: 0.0099
 - val_f1: 0.9940
Epoch 74/200
 - 0s - loss: 0.0060 - val_loss: 0.0095
 - val_f1: 0.9948
Epoch 75/200
 - 0s - loss: 0.0056 - val_loss: 0.0099
 - val_f1: 0.9935
Epoch 76/200
 - 0s - loss: 0.0062 - val_loss: 0.0095
 - val_f1: 0.9943
Epoch 77/200
 - 0s - loss: 0.0061 - val_loss: 0.0096
 - val_f1: 0.9943
Epoch 78/200
 - 0s - loss: 0.0062 - val_loss: 0.0096
 - val_f1: 0.9940
Epoch 79/200
 - 0s - loss: 0.0062 - val_loss: 0.0092
 - val_f1: 0.9944
Epoch 80/200
 - 0s - loss: 0.0057 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 81/200
 - 0s - loss: 0.0052 - val_loss: 0.0091
2020-01-06 14:49:17,637 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9942
Epoch 82/200
 - 0s - loss: 0.0055 - val_loss: 0.0092
 - val_f1: 0.9949
Epoch 83/200
 - 0s - loss: 0.0063 - val_loss: 0.0098
 - val_f1: 0.9947
Epoch 84/200
 - 0s - loss: 0.0057 - val_loss: 0.0090
 - val_f1: 0.9946
Epoch 85/200
 - 0s - loss: 0.0055 - val_loss: 0.0092
 - val_f1: 0.9944
Epoch 86/200
 - 0s - loss: 0.0052 - val_loss: 0.0092
 - val_f1: 0.9947
Epoch 87/200
 - 0s - loss: 0.0054 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 88/200
 - 0s - loss: 0.0057 - val_loss: 0.0093
 - val_f1: 0.9946
Epoch 89/200
 - 0s - loss: 0.0061 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 90/200
 - 0s - loss: 0.0057 - val_loss: 0.0106
 - val_f1: 0.9939
Epoch 91/200
 - 0s - loss: 0.0057 - val_loss: 0.0097
 - val_f1: 0.9945
Epoch 92/200
 - 0s - loss: 0.0061 - val_loss: 0.0101
 - val_f1: 0.9939
Epoch 93/200
 - 0s - loss: 0.0058 - val_loss: 0.0097
 - val_f1: 0.9941
Epoch 94/200
 - 0s - loss: 0.0059 - val_loss: 0.0096
 - val_f1: 0.9942
Epoch 95/200
 - 0s - loss: 0.0055 - val_loss: 0.0096
 - val_f1: 0.9946
Epoch 96/200
 - 0s - loss: 0.0054 - val_loss: 0.0097
 - val_f1: 0.9939
Epoch 97/200
 - 0s - loss: 0.0059 - val_loss: 0.0098
 - val_f1: 0.9945
Epoch 98/200
 - 0s - loss: 0.0050 - val_loss: 0.0100
 - val_f1: 0.9944
Epoch 99/200
 - 0s - loss: 0.0052 - val_loss: 0.0097
 - val_f1: 0.9949
Epoch 100/200
 - 0s - loss: 0.0052 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 101/200
 - 0s - loss: 0.0051 - val_loss: 0.0095
2020-01-06 14:49:33,067 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9950
Epoch 102/200
 - 0s - loss: 0.0053 - val_loss: 0.0097
 - val_f1: 0.9947
Epoch 103/200
 - 0s - loss: 0.0049 - val_loss: 0.0101
 - val_f1: 0.9943
Epoch 104/200
 - 0s - loss: 0.0047 - val_loss: 0.0097
 - val_f1: 0.9949
Epoch 105/200
 - 0s - loss: 0.0054 - val_loss: 0.0105
 - val_f1: 0.9938
Epoch 106/200
 - 0s - loss: 0.0050 - val_loss: 0.0100
 - val_f1: 0.9947
Epoch 107/200
 - 0s - loss: 0.0056 - val_loss: 0.0107
 - val_f1: 0.9943
Epoch 108/200
 - 0s - loss: 0.0054 - val_loss: 0.0100
 - val_f1: 0.9947
Epoch 109/200
 - 0s - loss: 0.0053 - val_loss: 0.0102
 - val_f1: 0.9950
Epoch 110/200
 - 0s - loss: 0.0050 - val_loss: 0.0107
 - val_f1: 0.9938
Epoch 111/200
 - 0s - loss: 0.0052 - val_loss: 0.0101
 - val_f1: 0.9945
Epoch 112/200
 - 0s - loss: 0.0047 - val_loss: 0.0101
 - val_f1: 0.9948
Epoch 113/200
 - 0s - loss: 0.0048 - val_loss: 0.0107
 - val_f1: 0.9940
Epoch 114/200
 - 0s - loss: 0.0047 - val_loss: 0.0098
 - val_f1: 0.9950
Epoch 115/200
 - 0s - loss: 0.0046 - val_loss: 0.0103
 - val_f1: 0.9947
Epoch 116/200
 - 0s - loss: 0.0051 - val_loss: 0.0114
 - val_f1: 0.9940
Epoch 117/200
 - 0s - loss: 0.0053 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 118/200
 - 0s - loss: 0.0049 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 119/200
 - 0s - loss: 0.0051 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 120/200
 - 0s - loss: 0.0045 - val_loss: 0.0099
 - val_f1: 0.9952
Epoch 121/200
 - 0s - loss: 0.0045 - val_loss: 0.0097
2020-01-06 14:49:48,461 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9948
Epoch 122/200
 - 0s - loss: 0.0044 - val_loss: 0.0098
 - val_f1: 0.9951
Epoch 123/200
 - 0s - loss: 0.0047 - val_loss: 0.0108
 - val_f1: 0.9943
Epoch 124/200
 - 0s - loss: 0.0050 - val_loss: 0.0098
 - val_f1: 0.9948
Epoch 125/200
 - 0s - loss: 0.0047 - val_loss: 0.0101
 - val_f1: 0.9950
Epoch 126/200
 - 0s - loss: 0.0045 - val_loss: 0.0105
 - val_f1: 0.9941
Epoch 127/200
 - 0s - loss: 0.0049 - val_loss: 0.0100
 - val_f1: 0.9951
Epoch 128/200
 - 0s - loss: 0.0044 - val_loss: 0.0103
 - val_f1: 0.9942
Epoch 129/200
 - 0s - loss: 0.0048 - val_loss: 0.0096
 - val_f1: 0.9952
Epoch 130/200
 - 0s - loss: 0.0044 - val_loss: 0.0115
 - val_f1: 0.9920
Epoch 131/200
 - 0s - loss: 0.0047 - val_loss: 0.0101
 - val_f1: 0.9944
Epoch 132/200
 - 0s - loss: 0.0049 - val_loss: 0.0098
 - val_f1: 0.9942
Epoch 133/200
 - 0s - loss: 0.0044 - val_loss: 0.0109
 - val_f1: 0.9944
Epoch 134/200
 - 0s - loss: 0.0042 - val_loss: 0.0104
2020-01-06 14:49:58,931 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 14:49:59,987 [INFO] Last epoch loss evaluation: train_loss = 0.003525, val_loss = 0.009024
2020-01-06 14:49:59,988 [INFO] Training complete. time_to_train = 174.89 sec, 2.91 min
2020-01-06 14:49:59,992 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/best_model.pickle
2020-01-06 14:49:59,995 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/training_error_history.csv
2020-01-06 14:50:00,178 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/training_error_history.png
2020-01-06 14:50:00,346 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/training_f1_history.png
2020-01-06 14:50:00,347 [INFO] Making predictions on training, validation, testing data
2020-01-06 14:50:02,659 [INFO] Evaluating predictions (results)
2020-01-06 14:50:03,210 [INFO] Dataset: Testing. Classification report below
2020-01-06 14:50:03,210 [INFO] 
              precision    recall  f1-score   support

         dos       0.92      0.84      0.88      7458
      normal       0.68      0.93      0.79      9711
       probe       0.87      0.69      0.77      2421
         r2l       0.56      0.09      0.15      2421
         u2r       0.21      0.03      0.05       533

    accuracy                           0.77     22544
   macro avg       0.65      0.52      0.53     22544
weighted avg       0.76      0.77      0.73     22544

2020-01-06 14:50:03,210 [INFO] Overall accuracy (micro avg): 0.7659244144783535
2020-01-06 14:50:03,807 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7659         0.7659                       0.7659                0.0585                   0.2341  0.7659
1     Macro avg        0.9064         0.6467                       0.5167                0.0782                   0.4833  0.5280
2  Weighted avg        0.8648         0.7557                       0.7659                0.1570                   0.2341  0.7309
2020-01-06 14:50:04,484 [INFO] Dataset: Validation. Classification report below
2020-01-06 14:50:04,484 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.91      0.88      0.90       199
         u2r       0.23      0.30      0.26        10

    accuracy                           0.99     25195
   macro avg       0.82      0.83      0.83     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-06 14:50:04,484 [INFO] Overall accuracy (micro avg): 0.9945624131772177
2020-01-06 14:50:05,155 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0014                   0.0054  0.9946
1     Macro avg        0.9978         0.8236                       0.8330                0.0017                   0.1670  0.8274
2  Weighted avg        0.9967         0.9946                       0.9946                0.0032                   0.0054  0.9946
2020-01-06 14:50:07,995 [INFO] Dataset: Training. Classification report below
2020-01-06 14:50:07,997 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.93      0.89      0.91       796
         u2r       0.50      0.43      0.46        42

    accuracy                           1.00    100778
   macro avg       0.88      0.86      0.87    100778
weighted avg       1.00      1.00      1.00    100778

2020-01-06 14:50:07,997 [INFO] Overall accuracy (micro avg): 0.995167596102324
2020-01-06 14:50:11,039 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0012                   0.0048  0.9952
1     Macro avg        0.9981         0.8826                       0.8602                0.0016                   0.1398  0.8708
2  Weighted avg        0.9970         0.9951                       0.9952                0.0033                   0.0048  0.9951
2020-01-06 14:50:11,086 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/semi_sup_perf_nsl_dbn_rep3_results.xlsx
2020-01-06 14:50:11,086 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-06 14:50:11,087 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep1
2020-01-06 14:50:11,087 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep1/run_log.log
2020-01-06 14:50:11,087 [INFO] ================= Running experiment no. 1  ================= 

2020-01-06 14:50:11,087 [INFO] Experiment parameters given below
2020-01-06 14:50:11,087 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep1'}
2020-01-06 14:50:11,087 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/tf_logs_run_2020_01_06-14_50_11
2020-01-06 14:50:11,088 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-06 14:50:11,088 [INFO] Reading X, y files
2020-01-06 14:50:11,088 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-06 14:50:15,864 [INFO] Reading complete. time_to_read=4.78 seconds
2020-01-06 14:50:15,864 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-06 14:50:17,194 [INFO] Reading complete. time_to_read=1.33 seconds
2020-01-06 14:50:17,194 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-06 14:50:18,520 [INFO] Reading complete. time_to_read=1.33 seconds
2020-01-06 14:50:18,520 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-06 14:50:18,848 [INFO] Reading complete. time_to_read=0.33 seconds
2020-01-06 14:50:18,848 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-06 14:50:18,961 [INFO] Reading complete. time_to_read=0.11 seconds
2020-01-06 14:50:18,961 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-06 14:50:19,077 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-06 14:50:22,037 [INFO] Initializing model
2020-01-06 14:50:22,037 [INFO] Training model
2020-01-06 14:50:22,037 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-06 14:50:46,142 [INFO] Split sizes (instances). total = 1696684, unsupervised = 1272513, supervised = 424171, unsupervised dataset hash = 80eaae5411c9a846aabf96459ca07e8d1db2b25e
2020-01-06 14:50:46,142 [INFO] Pretraining Deep Belief Network
2020-01-06 15:06:12,534 [INFO] Pretraining Complete
2020-01-06 15:06:12,534 [INFO] Getting pretrained weights
2020-01-06 15:06:12,534 [INFO] Creating and initializing feed forward neural network
2020-01-06 15:06:12,654 [INFO] _________________________________________________________________
2020-01-06 15:06:12,654 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 15:06:12,654 [INFO] =================================================================
2020-01-06 15:06:12,654 [INFO] dense_7 (Dense)              (None, 64)                5056      
2020-01-06 15:06:12,654 [INFO] _________________________________________________________________
2020-01-06 15:06:12,654 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-06 15:06:12,654 [INFO] _________________________________________________________________
2020-01-06 15:06:12,654 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-06 15:06:12,654 [INFO] _________________________________________________________________
2020-01-06 15:06:12,655 [INFO] dense_8 (Dense)              (None, 12)                780       
2020-01-06 15:06:12,655 [INFO] =================================================================
2020-01-06 15:06:12,655 [INFO] Total params: 6,092
2020-01-06 15:06:12,655 [INFO] Trainable params: 5,964
2020-01-06 15:06:12,655 [INFO] Non-trainable params: 128
2020-01-06 15:06:12,655 [INFO] _________________________________________________________________
2020-01-06 15:06:12,901 [INFO] Fine-tuning final neural network
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25575 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25576 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25238 tid 25577 thread 19 bound to OS proc set 3
 - val_f1: 0.9947
Epoch 00134: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.30, time = 11.28s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.65, time = 19.47s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -41.46, time = 19.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -44.69, time = 19.32s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -47.60, time = 19.28s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -50.55, time = 19.24s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -53.60, time = 19.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -56.72, time = 19.18s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -59.88, time = 19.16s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -63.08, time = 19.16s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -66.31, time = 19.13s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -69.56, time = 19.12s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -72.83, time = 19.10s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -76.11, time = 19.09s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -79.40, time = 18.99s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -82.71, time = 18.85s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -86.04, time = 18.59s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -89.38, time = 18.49s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -92.72, time = 18.39s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -96.08, time = 18.36s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -99.44, time = 18.32s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -102.81, time = 18.29s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -106.20, time = 18.28s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -109.60, time = 18.26s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -112.99, time = 18.25s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -116.38, time = 18.25s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -119.79, time = 18.26s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -123.20, time = 18.26s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -126.62, time = 18.24s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -130.02, time = 18.25s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -133.45, time = 18.23s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -136.87, time = 18.22s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -140.29, time = 18.22s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -143.72, time = 18.21s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -147.14, time = 18.22s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -150.57, time = 18.21s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -153.99, time = 18.21s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -157.41, time = 18.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -160.83, time = 18.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -164.26, time = 18.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -167.68, time = 18.20s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -171.09, time = 18.18s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -174.51, time = 18.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -177.94, time = 18.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -181.35, time = 18.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -184.77, time = 18.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -188.18, time = 18.18s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -191.60, time = 18.18s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -195.03, time = 18.17s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -198.46, time = 18.18s
Train on 424171 samples, validate on 565562 samples
Epoch 1/200
 - 8s - loss: 0.1004 - val_loss: 0.0672
 - val_f1: 0.7875
Epoch 2/200
 - 7s - loss: 0.0678 - val_loss: 0.0591
 - val_f1: 0.7979
Epoch 3/200
 - 7s - loss: 0.0609 - val_loss: 0.0547
 - val_f1: 0.8083
Epoch 4/200
 - 7s - loss: 0.0571 - val_loss: 0.0527
 - val_f1: 0.8150
Epoch 5/200
 - 7s - loss: 0.0548 - val_loss: 0.0508
 - val_f1: 0.8169
Epoch 6/200
 - 7s - loss: 0.0527 - val_loss: 0.0485
 - val_f1: 0.8233
Epoch 7/200
 - 7s - loss: 0.0505 - val_loss: 0.0464
 - val_f1: 0.8388
Epoch 8/200
 - 7s - loss: 0.0485 - val_loss: 0.0445
 - val_f1: 0.8465
Epoch 9/200
 - 7s - loss: 0.0463 - val_loss: 0.0407
 - val_f1: 0.8611
Epoch 10/200
 - 7s - loss: 0.0415 - val_loss: 0.0348
 - val_f1: 0.8740
Epoch 11/200
 - 7s - loss: 0.0374 - val_loss: 0.0311
 - val_f1: 0.9138
Epoch 12/200
 - 7s - loss: 0.0351 - val_loss: 0.0297
 - val_f1: 0.9169
Epoch 13/200
 - 7s - loss: 0.0339 - val_loss: 0.0287
 - val_f1: 0.9182
Epoch 14/200
 - 7s - loss: 0.0332 - val_loss: 0.0286
 - val_f1: 0.9189
Epoch 15/200
 - 7s - loss: 0.0323 - val_loss: 0.0275
 - val_f1: 0.9208
Epoch 16/200
 - 7s - loss: 0.0316 - val_loss: 0.0271
 - val_f1: 0.9210
Epoch 17/200
 - 7s - loss: 0.0309 - val_loss: 0.0265
 - val_f1: 0.9223
Epoch 18/200
 - 7s - loss: 0.0301 - val_loss: 0.0259
 - val_f1: 0.9243
Epoch 19/200
 - 7s - loss: 0.0296 - val_loss: 0.0256
 - val_f1: 0.9250
Epoch 20/200
 - 7s - loss: 0.0290 - val_loss: 0.0252
 - val_f1: 0.9264
Epoch 21/200
 - 7s - loss: 0.0283 - val_loss: 0.0244
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 15:12:07,318 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9314
Epoch 22/200
 - 7s - loss: 0.0251 - val_loss: 0.0186
 - val_f1: 0.9568
Epoch 23/200
 - 7s - loss: 0.0225 - val_loss: 0.0171
 - val_f1: 0.9584
Epoch 24/200
 - 7s - loss: 0.0214 - val_loss: 0.0163
 - val_f1: 0.9607
Epoch 25/200
 - 7s - loss: 0.0207 - val_loss: 0.0160
 - val_f1: 0.9617
Epoch 26/200
 - 7s - loss: 0.0200 - val_loss: 0.0153
 - val_f1: 0.9618
Epoch 27/200
 - 7s - loss: 0.0194 - val_loss: 0.0148
 - val_f1: 0.9626
Epoch 28/200
 - 7s - loss: 0.0188 - val_loss: 0.0142
 - val_f1: 0.9645
Epoch 29/200
 - 7s - loss: 0.0182 - val_loss: 0.0145
 - val_f1: 0.9649
Epoch 30/200
 - 7s - loss: 0.0176 - val_loss: 0.0136
 - val_f1: 0.9669
Epoch 31/200
 - 7s - loss: 0.0173 - val_loss: 0.0132
 - val_f1: 0.9682
Epoch 32/200
 - 7s - loss: 0.0169 - val_loss: 0.0130
 - val_f1: 0.9682
Epoch 33/200
 - 7s - loss: 0.0164 - val_loss: 0.0127
 - val_f1: 0.9691
Epoch 34/200
 - 7s - loss: 0.0162 - val_loss: 0.0124
 - val_f1: 0.9692
Epoch 35/200
 - 7s - loss: 0.0158 - val_loss: 0.0123
 - val_f1: 0.9684
Epoch 36/200
 - 7s - loss: 0.0154 - val_loss: 0.0121
 - val_f1: 0.9694
Epoch 37/200
 - 7s - loss: 0.0151 - val_loss: 0.0120
 - val_f1: 0.9703
Epoch 38/200
 - 7s - loss: 0.0150 - val_loss: 0.0117
 - val_f1: 0.9694
Epoch 39/200
 - 7s - loss: 0.0147 - val_loss: 0.0115
 - val_f1: 0.9709
Epoch 40/200
 - 7s - loss: 0.0143 - val_loss: 0.0114
 - val_f1: 0.9696
Epoch 41/200
 - 7s - loss: 0.0142 - val_loss: 0.0113
2020-01-06 15:17:52,617 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9715
Epoch 42/200
 - 7s - loss: 0.0140 - val_loss: 0.0111
 - val_f1: 0.9710
Epoch 43/200
 - 7s - loss: 0.0138 - val_loss: 0.0111
 - val_f1: 0.9701
Epoch 44/200
 - 7s - loss: 0.0136 - val_loss: 0.0105
 - val_f1: 0.9720
Epoch 45/200
 - 7s - loss: 0.0134 - val_loss: 0.0107
 - val_f1: 0.9770
Epoch 46/200
 - 7s - loss: 0.0133 - val_loss: 0.0106
 - val_f1: 0.9727
Epoch 47/200
 - 7s - loss: 0.0131 - val_loss: 0.0101
 - val_f1: 0.9721
Epoch 48/200
 - 7s - loss: 0.0129 - val_loss: 0.0099
 - val_f1: 0.9727
Epoch 49/200
 - 7s - loss: 0.0127 - val_loss: 0.0100
 - val_f1: 0.9825
Epoch 50/200
 - 7s - loss: 0.0125 - val_loss: 0.0096
 - val_f1: 0.9833
Epoch 51/200
 - 7s - loss: 0.0123 - val_loss: 0.0094
 - val_f1: 0.9736
Epoch 52/200
 - 7s - loss: 0.0122 - val_loss: 0.0096
 - val_f1: 0.9827
Epoch 53/200
 - 7s - loss: 0.0119 - val_loss: 0.0091
 - val_f1: 0.9834
Epoch 54/200
 - 7s - loss: 0.0117 - val_loss: 0.0088
 - val_f1: 0.9833
Epoch 55/200
 - 7s - loss: 0.0115 - val_loss: 0.0085
 - val_f1: 0.9835
Epoch 56/200
 - 7s - loss: 0.0114 - val_loss: 0.0084
 - val_f1: 0.9833
Epoch 57/200
 - 7s - loss: 0.0111 - val_loss: 0.0081
 - val_f1: 0.9874
Epoch 58/200
 - 7s - loss: 0.0110 - val_loss: 0.0083
 - val_f1: 0.9871
Epoch 59/200
 - 7s - loss: 0.0108 - val_loss: 0.0080
 - val_f1: 0.9872
Epoch 60/200
 - 7s - loss: 0.0105 - val_loss: 0.0075
 - val_f1: 0.9838
Epoch 61/200
 - 7s - loss: 0.0103 - val_loss: 0.0074
2020-01-06 15:23:37,942 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9838
Epoch 62/200
 - 7s - loss: 0.0103 - val_loss: 0.0074
 - val_f1: 0.9839
Epoch 63/200
 - 7s - loss: 0.0101 - val_loss: 0.0072
 - val_f1: 0.9841
Epoch 64/200
 - 7s - loss: 0.0099 - val_loss: 0.0074
 - val_f1: 0.9839
Epoch 65/200
 - 7s - loss: 0.0098 - val_loss: 0.0069
 - val_f1: 0.9840
Epoch 66/200
 - 7s - loss: 0.0097 - val_loss: 0.0070
 - val_f1: 0.9841
Epoch 67/200
 - 7s - loss: 0.0095 - val_loss: 0.0068
 - val_f1: 0.9875
Epoch 68/200
 - 7s - loss: 0.0093 - val_loss: 0.0069
 - val_f1: 0.9843
Epoch 69/200
 - 7s - loss: 0.0092 - val_loss: 0.0066
 - val_f1: 0.9844
Epoch 70/200
 - 7s - loss: 0.0091 - val_loss: 0.0067
 - val_f1: 0.9847
Epoch 71/200
 - 7s - loss: 0.0091 - val_loss: 0.0066
 - val_f1: 0.9840
Epoch 72/200
 - 7s - loss: 0.0090 - val_loss: 0.0065
 - val_f1: 0.9845
Epoch 73/200
 - 7s - loss: 0.0088 - val_loss: 0.0065
 - val_f1: 0.9843
Epoch 74/200
 - 7s - loss: 0.0088 - val_loss: 0.0064
 - val_f1: 0.9845
Epoch 75/200
 - 7s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9844
Epoch 76/200
 - 7s - loss: 0.0086 - val_loss: 0.0062
 - val_f1: 0.9852
Epoch 77/200
 - 7s - loss: 0.0085 - val_loss: 0.0062
 - val_f1: 0.9847
Epoch 78/200
 - 7s - loss: 0.0085 - val_loss: 0.0063
 - val_f1: 0.9848
Epoch 79/200
 - 7s - loss: 0.0084 - val_loss: 0.0061
 - val_f1: 0.9848
Epoch 80/200
 - 7s - loss: 0.0082 - val_loss: 0.0061
 - val_f1: 0.9847
Epoch 81/200
 - 7s - loss: 0.0083 - val_loss: 0.0060
2020-01-06 15:29:23,658 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9844
Epoch 82/200
 - 7s - loss: 0.0082 - val_loss: 0.0059
 - val_f1: 0.9868
Epoch 83/200
 - 7s - loss: 0.0081 - val_loss: 0.0060
 - val_f1: 0.9848
Epoch 84/200
 - 7s - loss: 0.0081 - val_loss: 0.0061
 - val_f1: 0.9850
Epoch 85/200
 - 7s - loss: 0.0080 - val_loss: 0.0058
 - val_f1: 0.9857
Epoch 86/200
 - 7s - loss: 0.0079 - val_loss: 0.0059
 - val_f1: 0.9855
Epoch 87/200
 - 7s - loss: 0.0078 - val_loss: 0.0059
 - val_f1: 0.9857
Epoch 88/200
 - 7s - loss: 0.0078 - val_loss: 0.0056
 - val_f1: 0.9858
Epoch 89/200
 - 7s - loss: 0.0078 - val_loss: 0.0056
 - val_f1: 0.9877
Epoch 90/200
 - 7s - loss: 0.0077 - val_loss: 0.0055
 - val_f1: 0.9879
Epoch 91/200
 - 7s - loss: 0.0076 - val_loss: 0.0055
 - val_f1: 0.9861
Epoch 92/200
 - 7s - loss: 0.0076 - val_loss: 0.0058
 - val_f1: 0.9888
Epoch 93/200
 - 7s - loss: 0.0075 - val_loss: 0.0053
 - val_f1: 0.9883
Epoch 94/200
 - 7s - loss: 0.0074 - val_loss: 0.0055
 - val_f1: 0.9869
Epoch 95/200
 - 7s - loss: 0.0074 - val_loss: 0.0055
 - val_f1: 0.9864
Epoch 96/200
 - 7s - loss: 0.0073 - val_loss: 0.0057
 - val_f1: 0.9863
Epoch 97/200
 - 7s - loss: 0.0073 - val_loss: 0.0054
 - val_f1: 0.9867
Epoch 98/200
 - 7s - loss: 0.0073 - val_loss: 0.0050
 - val_f1: 0.9892
Epoch 99/200
 - 7s - loss: 0.0072 - val_loss: 0.0054
 - val_f1: 0.9862
Epoch 100/200
 - 7s - loss: 0.0072 - val_loss: 0.0051
 - val_f1: 0.9915
Epoch 101/200
 - 7s - loss: 0.0070 - val_loss: 0.0050
2020-01-06 15:35:09,412 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9917
Epoch 102/200
 - 7s - loss: 0.0070 - val_loss: 0.0049
 - val_f1: 0.9886
Epoch 103/200
 - 7s - loss: 0.0068 - val_loss: 0.0049
 - val_f1: 0.9890
Epoch 104/200
 - 7s - loss: 0.0068 - val_loss: 0.0047
 - val_f1: 0.9893
Epoch 105/200
 - 7s - loss: 0.0067 - val_loss: 0.0048
 - val_f1: 0.9892
Epoch 106/200
 - 7s - loss: 0.0067 - val_loss: 0.0049
 - val_f1: 0.9887
Epoch 107/200
 - 7s - loss: 0.0067 - val_loss: 0.0046
 - val_f1: 0.9894
Epoch 108/200
 - 7s - loss: 0.0065 - val_loss: 0.0048
 - val_f1: 0.9893
Epoch 109/200
 - 7s - loss: 0.0064 - val_loss: 0.0049
 - val_f1: 0.9911
Epoch 110/200
 - 7s - loss: 0.0064 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 111/200
 - 7s - loss: 0.0064 - val_loss: 0.0045
 - val_f1: 0.9920
Epoch 112/200
 - 7s - loss: 0.0063 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 113/200
 - 7s - loss: 0.0062 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 114/200
 - 7s - loss: 0.0062 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 115/200
 - 7s - loss: 0.0062 - val_loss: 0.0049
 - val_f1: 0.9897
Epoch 116/200
 - 7s - loss: 0.0061 - val_loss: 0.0043
 - val_f1: 0.9916
Epoch 117/200
 - 7s - loss: 0.0061 - val_loss: 0.0044
 - val_f1: 0.9920
Epoch 118/200
 - 7s - loss: 0.0060 - val_loss: 0.0043
 - val_f1: 0.9897
Epoch 119/200
 - 7s - loss: 0.0059 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 120/200
 - 7s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9919
Epoch 121/200
 - 7s - loss: 0.0060 - val_loss: 0.0042
2020-01-06 15:40:55,701 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9919
Epoch 122/200
 - 7s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9890
Epoch 123/200
 - 7s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9917
Epoch 124/200
 - 7s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9896
Epoch 125/200
 - 7s - loss: 0.0059 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 126/200
 - 7s - loss: 0.0058 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 127/200
 - 7s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9900
Epoch 128/200
 - 7s - loss: 0.0058 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 129/200
 - 7s - loss: 0.0058 - val_loss: 0.0041
 - val_f1: 0.9924
Epoch 130/200
 - 7s - loss: 0.0058 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 131/200
 - 7s - loss: 0.0056 - val_loss: 0.0046
 - val_f1: 0.9893
Epoch 132/200
 - 7s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9919
Epoch 133/200
 - 7s - loss: 0.0057 - val_loss: 0.0041
 - val_f1: 0.9924
Epoch 134/200
 - 7s - loss: 0.0057 - val_loss: 0.0042
 - val_f1: 0.9903
Epoch 135/200
 - 7s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 136/200
 - 7s - loss: 0.0055 - val_loss: 0.0044
 - val_f1: 0.9900
Epoch 137/200
 - 7s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 138/200
 - 7s - loss: 0.0055 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 139/200
 - 7s - loss: 0.0055 - val_loss: 0.0042
 - val_f1: 0.9898
Epoch 140/200
 - 7s - loss: 0.0054 - val_loss: 0.0048
 - val_f1: 0.9898
Epoch 141/200
 - 7s - loss: 0.0054 - val_loss: 0.0042
2020-01-06 15:46:41,658 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9918
Epoch 142/200
 - 7s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9901
Epoch 143/200
 - 7s - loss: 0.0054 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 144/200
 - 7s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 145/200
 - 7s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9924
Epoch 146/200
 - 7s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 147/200
 - 7s - loss: 0.0054 - val_loss: 0.0044
 - val_f1: 0.9918
Epoch 148/200
 - 7s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9922
Epoch 149/200
 - 7s - loss: 0.0053 - val_loss: 0.0042
 - val_f1: 0.9927
Epoch 150/200
 - 7s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9900
Epoch 151/200
 - 7s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 152/200
 - 7s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 153/200
 - 7s - loss: 0.0053 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 154/200
 - 7s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 155/200
 - 7s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 156/200
 - 7s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9924
Epoch 157/200
 - 7s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9920
Epoch 158/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9906
Epoch 159/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9909
Epoch 160/200
 - 7s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9897
Epoch 161/200
 - 7s - loss: 0.0050 - val_loss: 0.0045
2020-01-06 15:52:27,059 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9921
Epoch 162/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9909
Epoch 163/200
 - 7s - loss: 0.0051 - val_loss: 0.0051
 - val_f1: 0.9887
Epoch 164/200
 - 7s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9908
Epoch 165/200
 - 7s - loss: 0.0050 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 166/200
 - 7s - loss: 0.0050 - val_loss: 0.0040
 - val_f1: 0.9926
Epoch 167/200
 - 7s - loss: 0.0050 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 168/200
 - 7s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9908
Epoch 169/200
 - 7s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 170/200
 - 7s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9926
Epoch 171/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 172/200
 - 7s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9925
Epoch 173/200
 - 7s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9905
Epoch 174/200
 - 7s - loss: 0.0050 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 175/200
 - 7s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9908
Epoch 176/200
 - 7s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 177/200
 - 7s - loss: 0.0049 - val_loss: 0.0045
 - val_f1: 0.9909
Epoch 178/200
 - 7s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9924
Epoch 179/200
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9908
Epoch 180/200
 - 7s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9925
Epoch 181/200
 - 7s - loss: 0.0048 - val_loss: 0.0040
2020-01-06 15:58:12,876 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9902
Epoch 182/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9925
Epoch 183/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 184/200
 - 7s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 185/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 186/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 187/200
 - 7s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9910
Epoch 188/200
 - 7s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9904
Epoch 189/200
 - 7s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9911
Epoch 190/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 191/200
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9926
Epoch 192/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 193/200
 - 7s - loss: 0.0047 - val_loss: 0.0038
 - val_f1: 0.9903
Epoch 194/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9911
Epoch 195/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9911
Epoch 196/200
 - 7s - loss: 0.0046 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 197/200
 - 7s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 198/200
 - 7s - loss: 0.0046 - val_loss: 0.0043
 - val_f1: 0.9911
Epoch 199/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9910
Epoch 200/200
 - 7s - loss: 0.0046 - val_loss: 0.0039
2020-01-06 16:03:52,619 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 16:04:11,632 [INFO] Last epoch loss evaluation: train_loss = 0.003576, val_loss = 0.003776
2020-01-06 16:04:11,636 [INFO] Training complete. time_to_train = 4429.60 sec, 73.83 min
2020-01-06 16:04:11,641 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/best_model.pickle
2020-01-06 16:04:11,644 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/training_error_history.csv
2020-01-06 16:04:11,830 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/training_error_history.png
2020-01-06 16:04:12,003 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/training_f1_history.png
2020-01-06 16:04:12,003 [INFO] Making predictions on training, validation, testing data
2020-01-06 16:04:58,847 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 16:05:18,676 [INFO] Dataset: Testing. Classification report below
2020-01-06 16:05:18,676 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      0.99    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.95      0.97      2058
              DoS Hulk       0.97      0.95      0.96     46025
      DoS Slowhttptest       0.86      0.97      0.91      1100
         DoS slowloris       0.95      0.91      0.93      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.93      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.80      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 16:05:18,676 [INFO] Overall accuracy (micro avg): 0.9907065891980013
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-06 16:05:39,964 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9907         0.9907                       0.9907                0.0008                   0.0093  0.9907
1     Macro avg        0.9985         0.8040                       0.7591                0.0029                   0.2409  0.7698
2  Weighted avg        0.9922         0.9899                       0.9907                0.0252                   0.0093  0.9902
2020-01-06 16:05:59,981 [INFO] Dataset: Validation. Classification report below
2020-01-06 16:05:59,982 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      0.99    454264
                   Bot       0.98      0.33      0.50       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.94      0.96      2059
              DoS Hulk       0.97      0.95      0.96     46025
      DoS Slowhttptest       0.86      0.96      0.91      1099
         DoS slowloris       0.94      0.91      0.92      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.93      0.97      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.99    565562
             macro avg       0.81      0.75      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 16:05:59,982 [INFO] Overall accuracy (micro avg): 0.990819750973368
2020-01-06 16:06:21,547 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9908         0.9908                       0.9908                0.0008                   0.0092  0.9908
1     Macro avg        0.9985         0.8052                       0.7535                0.0028                   0.2465  0.7656
2  Weighted avg        0.9923         0.9901                       0.9908                0.0248                   0.0092  0.9903
2020-01-06 16:07:28,293 [INFO] Dataset: Training. Classification report below
2020-01-06 16:07:28,293 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      0.99   1362791
                   Bot       0.98      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.95      0.97      6176
              DoS Hulk       0.97      0.95      0.96    138074
      DoS Slowhttptest       0.87      0.96      0.91      3300
         DoS slowloris       0.95      0.92      0.93      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      0.99      0.99     95282
           SSH-Patator       0.95      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.99   1696684
             macro avg       0.81      0.76      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-06 16:07:28,293 [INFO] Overall accuracy (micro avg): 0.9908038267585478
2020-01-06 16:08:40,214 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9908         0.9908                       0.9908                0.0008                   0.0092  0.9908
1     Macro avg        0.9985         0.8063                       0.7585                0.0028                   0.2415  0.7703
2  Weighted avg        0.9923         0.9900                       0.9908                0.0250                   0.0092  0.9903
2020-01-06 16:08:40,278 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/semi_sup_perf_ids17_dbn_rep1_results.xlsx
2020-01-06 16:08:40,282 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-06 16:08:40,323 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep2
2020-01-06 16:08:40,324 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep2/run_log.log
2020-01-06 16:08:40,324 [INFO] ================= Running experiment no. 2  ================= 

2020-01-06 16:08:40,324 [INFO] Experiment parameters given below
2020-01-06 16:08:40,324 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep2'}
2020-01-06 16:08:40,324 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/tf_logs_run_2020_01_06-16_08_40
2020-01-06 16:08:40,324 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-06 16:08:40,325 [INFO] Reading X, y files
2020-01-06 16:08:40,325 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-06 16:08:44,097 [INFO] Reading complete. time_to_read=3.77 seconds
2020-01-06 16:08:44,098 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-06 16:08:45,376 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-06 16:08:45,379 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-06 16:08:46,657 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-06 16:08:46,658 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-06 16:08:46,922 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-06 16:08:46,922 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-06 16:08:47,006 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-06 16:08:47,006 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-06 16:08:47,088 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-06 16:08:50,036 [INFO] Initializing model
2020-01-06 16:08:50,036 [INFO] Training model
2020-01-06 16:08:50,037 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-06 16:09:14,679 [INFO] Split sizes (instances). total = 1696684, unsupervised = 1272513, supervised = 424171, unsupervised dataset hash = 96ad2dc5f36aa874a7843f0a18384e37e8e163ae
2020-01-06 16:09:14,679 [INFO] Pretraining Deep Belief Network
2020-01-06 16:24:41,397 [INFO] Pretraining Complete
2020-01-06 16:24:41,397 [INFO] Getting pretrained weights
2020-01-06 16:24:41,397 [INFO] Creating and initializing feed forward neural network
2020-01-06 16:24:41,518 [INFO] _________________________________________________________________
2020-01-06 16:24:41,518 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 16:24:41,518 [INFO] =================================================================
2020-01-06 16:24:41,518 [INFO] dense_9 (Dense)              (None, 64)                5056      
2020-01-06 16:24:41,518 [INFO] _________________________________________________________________
2020-01-06 16:24:41,518 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-06 16:24:41,518 [INFO] _________________________________________________________________
2020-01-06 16:24:41,518 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-06 16:24:41,519 [INFO] _________________________________________________________________
2020-01-06 16:24:41,519 [INFO] dense_10 (Dense)             (None, 12)                780       
2020-01-06 16:24:41,519 [INFO] =================================================================
2020-01-06 16:24:41,519 [INFO] Total params: 6,092
2020-01-06 16:24:41,519 [INFO] Trainable params: 5,964
2020-01-06 16:24:41,519 [INFO] Non-trainable params: 128
2020-01-06 16:24:41,519 [INFO] _________________________________________________________________
2020-01-06 16:24:41,828 [INFO] Fine-tuning final neural network
 - val_f1: 0.9907
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.12, time = 11.29s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.43, time = 19.49s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -41.29, time = 19.39s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -44.60, time = 19.35s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -47.58, time = 19.28s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -50.60, time = 19.25s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -53.72, time = 19.20s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -56.89, time = 19.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -60.11, time = 19.16s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -63.37, time = 19.14s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -66.65, time = 19.13s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -69.95, time = 19.12s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -73.27, time = 19.11s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -76.60, time = 19.10s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -79.94, time = 19.01s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -83.29, time = 18.85s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -86.67, time = 18.60s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -90.05, time = 18.50s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -93.44, time = 18.40s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -96.84, time = 18.36s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -100.25, time = 18.32s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -103.67, time = 18.31s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -107.10, time = 18.28s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -110.54, time = 18.27s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -113.98, time = 18.28s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -117.42, time = 18.26s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -120.87, time = 18.27s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -124.33, time = 18.26s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -127.79, time = 18.25s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -131.24, time = 18.24s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -134.71, time = 18.23s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -138.17, time = 18.22s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -141.63, time = 18.23s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -145.11, time = 18.23s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -148.58, time = 18.21s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -152.05, time = 18.22s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -155.52, time = 18.20s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -159.00, time = 18.20s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -162.48, time = 18.21s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -165.96, time = 18.20s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -169.44, time = 18.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -172.91, time = 18.20s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -176.39, time = 18.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -179.88, time = 18.20s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -183.36, time = 18.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -186.85, time = 18.20s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -190.33, time = 18.18s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -193.82, time = 18.18s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -197.31, time = 18.18s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -200.80, time = 18.19s
Train on 424171 samples, validate on 565562 samples
Epoch 1/200
 - 8s - loss: 0.1008 - val_loss: 0.0672
 - val_f1: 0.7804
Epoch 2/200
 - 7s - loss: 0.0680 - val_loss: 0.0593
 - val_f1: 0.7992
Epoch 3/200
 - 7s - loss: 0.0611 - val_loss: 0.0549
 - val_f1: 0.8081
Epoch 4/200
 - 7s - loss: 0.0571 - val_loss: 0.0525
 - val_f1: 0.8146
Epoch 5/200
 - 7s - loss: 0.0546 - val_loss: 0.0506
 - val_f1: 0.8266
Epoch 6/200
 - 7s - loss: 0.0528 - val_loss: 0.0489
 - val_f1: 0.8357
Epoch 7/200
 - 7s - loss: 0.0507 - val_loss: 0.0467
 - val_f1: 0.8357
Epoch 8/200
 - 7s - loss: 0.0494 - val_loss: 0.0456
 - val_f1: 0.8400
Epoch 9/200
 - 7s - loss: 0.0480 - val_loss: 0.0443
 - val_f1: 0.8403
Epoch 10/200
 - 7s - loss: 0.0457 - val_loss: 0.0401
 - val_f1: 0.8652
Epoch 11/200
 - 7s - loss: 0.0413 - val_loss: 0.0347
 - val_f1: 0.9065
Epoch 12/200
 - 7s - loss: 0.0369 - val_loss: 0.0316
 - val_f1: 0.9169
Epoch 13/200
 - 7s - loss: 0.0346 - val_loss: 0.0294
 - val_f1: 0.9186
Epoch 14/200
 - 7s - loss: 0.0333 - val_loss: 0.0283
 - val_f1: 0.9200
Epoch 15/200
 - 7s - loss: 0.0324 - val_loss: 0.0279
 - val_f1: 0.9201
Epoch 16/200
 - 7s - loss: 0.0311 - val_loss: 0.0264
 - val_f1: 0.9268
Epoch 17/200
 - 7s - loss: 0.0263 - val_loss: 0.0197
 - val_f1: 0.9530
Epoch 18/200
 - 7s - loss: 0.0236 - val_loss: 0.0179
 - val_f1: 0.9566
Epoch 19/200
 - 7s - loss: 0.0222 - val_loss: 0.0171
 - val_f1: 0.9592
Epoch 20/200
 - 7s - loss: 0.0210 - val_loss: 0.0164
 - val_f1: 0.9617
Epoch 21/200
 - 7s - loss: 0.0203 - val_loss: 0.0155
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 16:30:47,320 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9620
Epoch 22/200
 - 7s - loss: 0.0195 - val_loss: 0.0148
 - val_f1: 0.9651
Epoch 23/200
 - 7s - loss: 0.0188 - val_loss: 0.0142
 - val_f1: 0.9659
Epoch 24/200
 - 7s - loss: 0.0182 - val_loss: 0.0138
 - val_f1: 0.9676
Epoch 25/200
 - 7s - loss: 0.0177 - val_loss: 0.0137
 - val_f1: 0.9693
Epoch 26/200
 - 7s - loss: 0.0173 - val_loss: 0.0130
 - val_f1: 0.9694
Epoch 27/200
 - 7s - loss: 0.0170 - val_loss: 0.0128
 - val_f1: 0.9698
Epoch 28/200
 - 7s - loss: 0.0167 - val_loss: 0.0127
 - val_f1: 0.9701
Epoch 29/200
 - 7s - loss: 0.0164 - val_loss: 0.0124
 - val_f1: 0.9699
Epoch 30/200
 - 7s - loss: 0.0161 - val_loss: 0.0124
 - val_f1: 0.9692
Epoch 31/200
 - 7s - loss: 0.0158 - val_loss: 0.0120
 - val_f1: 0.9710
Epoch 32/200
 - 7s - loss: 0.0156 - val_loss: 0.0119
 - val_f1: 0.9710
Epoch 33/200
 - 7s - loss: 0.0153 - val_loss: 0.0117
 - val_f1: 0.9710
Epoch 34/200
 - 7s - loss: 0.0152 - val_loss: 0.0116
 - val_f1: 0.9714
Epoch 35/200
 - 7s - loss: 0.0149 - val_loss: 0.0117
 - val_f1: 0.9719
Epoch 36/200
 - 7s - loss: 0.0146 - val_loss: 0.0112
 - val_f1: 0.9714
Epoch 37/200
 - 7s - loss: 0.0144 - val_loss: 0.0111
 - val_f1: 0.9701
Epoch 38/200
 - 7s - loss: 0.0142 - val_loss: 0.0113
 - val_f1: 0.9718
Epoch 39/200
 - 7s - loss: 0.0139 - val_loss: 0.0110
 - val_f1: 0.9714
Epoch 40/200
 - 7s - loss: 0.0138 - val_loss: 0.0110
 - val_f1: 0.9738
Epoch 41/200
 - 7s - loss: 0.0135 - val_loss: 0.0110
2020-01-06 16:36:43,813 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9778
Epoch 42/200
 - 7s - loss: 0.0134 - val_loss: 0.0107
 - val_f1: 0.9724
Epoch 43/200
 - 7s - loss: 0.0132 - val_loss: 0.0106
 - val_f1: 0.9785
Epoch 44/200
 - 7s - loss: 0.0130 - val_loss: 0.0108
 - val_f1: 0.9798
Epoch 45/200
 - 7s - loss: 0.0129 - val_loss: 0.0102
 - val_f1: 0.9719
Epoch 46/200
 - 7s - loss: 0.0128 - val_loss: 0.0099
 - val_f1: 0.9772
Epoch 47/200
 - 7s - loss: 0.0126 - val_loss: 0.0099
 - val_f1: 0.9792
Epoch 48/200
 - 7s - loss: 0.0124 - val_loss: 0.0099
 - val_f1: 0.9829
Epoch 49/200
 - 7s - loss: 0.0122 - val_loss: 0.0101
 - val_f1: 0.9801
Epoch 50/200
 - 7s - loss: 0.0121 - val_loss: 0.0092
 - val_f1: 0.9826
Epoch 51/200
 - 7s - loss: 0.0120 - val_loss: 0.0090
 - val_f1: 0.9820
Epoch 52/200
 - 7s - loss: 0.0117 - val_loss: 0.0090
 - val_f1: 0.9831
Epoch 53/200
 - 7s - loss: 0.0115 - val_loss: 0.0088
 - val_f1: 0.9836
Epoch 54/200
 - 7s - loss: 0.0113 - val_loss: 0.0094
 - val_f1: 0.9799
Epoch 55/200
 - 7s - loss: 0.0111 - val_loss: 0.0086
 - val_f1: 0.9836
Epoch 56/200
 - 7s - loss: 0.0109 - val_loss: 0.0085
 - val_f1: 0.9831
Epoch 57/200
 - 7s - loss: 0.0108 - val_loss: 0.0086
 - val_f1: 0.9830
Epoch 58/200
 - 7s - loss: 0.0106 - val_loss: 0.0077
 - val_f1: 0.9840
Epoch 59/200
 - 7s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9814
Epoch 60/200
 - 7s - loss: 0.0101 - val_loss: 0.0074
 - val_f1: 0.9838
Epoch 61/200
 - 7s - loss: 0.0098 - val_loss: 0.0072
2020-01-06 16:42:40,598 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9877
Epoch 62/200
 - 7s - loss: 0.0098 - val_loss: 0.0068
 - val_f1: 0.9852
Epoch 63/200
 - 7s - loss: 0.0096 - val_loss: 0.0067
 - val_f1: 0.9840
Epoch 64/200
 - 7s - loss: 0.0095 - val_loss: 0.0067
 - val_f1: 0.9842
Epoch 65/200
 - 7s - loss: 0.0094 - val_loss: 0.0067
 - val_f1: 0.9889
Epoch 66/200
 - 7s - loss: 0.0092 - val_loss: 0.0066
 - val_f1: 0.9867
Epoch 67/200
 - 7s - loss: 0.0092 - val_loss: 0.0064
 - val_f1: 0.9843
Epoch 68/200
 - 7s - loss: 0.0089 - val_loss: 0.0104
 - val_f1: 0.9574
Epoch 69/200
 - 7s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 70/200
 - 7s - loss: 0.0086 - val_loss: 0.0062
 - val_f1: 0.9895
Epoch 71/200
 - 7s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9862
Epoch 72/200
 - 7s - loss: 0.0083 - val_loss: 0.0065
 - val_f1: 0.9897
Epoch 73/200
 - 7s - loss: 0.0083 - val_loss: 0.0062
 - val_f1: 0.9850
Epoch 74/200
 - 7s - loss: 0.0083 - val_loss: 0.0070
 - val_f1: 0.9865
Epoch 75/200
 - 7s - loss: 0.0081 - val_loss: 0.0064
 - val_f1: 0.9845
Epoch 76/200
 - 7s - loss: 0.0079 - val_loss: 0.0060
 - val_f1: 0.9882
Epoch 77/200
 - 7s - loss: 0.0078 - val_loss: 0.0061
 - val_f1: 0.9898
Epoch 78/200
 - 7s - loss: 0.0080 - val_loss: 0.0063
 - val_f1: 0.9847
Epoch 79/200
 - 7s - loss: 0.0078 - val_loss: 0.0065
 - val_f1: 0.9847
Epoch 80/200
 - 7s - loss: 0.0076 - val_loss: 0.0061
 - val_f1: 0.9852
Epoch 81/200
 - 7s - loss: 0.0076 - val_loss: 0.0065
2020-01-06 16:48:37,960 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9846
Epoch 82/200
 - 7s - loss: 0.0075 - val_loss: 0.0061
 - val_f1: 0.9863
Epoch 83/200
 - 7s - loss: 0.0075 - val_loss: 0.0061
 - val_f1: 0.9864
Epoch 84/200
 - 7s - loss: 0.0075 - val_loss: 0.0069
 - val_f1: 0.9880
Epoch 85/200
 - 7s - loss: 0.0073 - val_loss: 0.0064
 - val_f1: 0.9852
Epoch 86/200
 - 7s - loss: 0.0073 - val_loss: 0.0062
 - val_f1: 0.9872
Epoch 87/200
 - 7s - loss: 0.0072 - val_loss: 0.0062
 - val_f1: 0.9900
Epoch 88/200
 - 7s - loss: 0.0072 - val_loss: 0.0059
 - val_f1: 0.9913
Epoch 89/200
 - 7s - loss: 0.0072 - val_loss: 0.0058
 - val_f1: 0.9892
Epoch 90/200
 - 7s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9890
Epoch 91/200
 - 7s - loss: 0.0070 - val_loss: 0.0060
 - val_f1: 0.9875
Epoch 92/200
 - 7s - loss: 0.0070 - val_loss: 0.0062
 - val_f1: 0.9855
Epoch 93/200
 - 7s - loss: 0.0069 - val_loss: 0.0058
 - val_f1: 0.9894
Epoch 94/200
 - 7s - loss: 0.0070 - val_loss: 0.0054
 - val_f1: 0.9894
Epoch 95/200
 - 7s - loss: 0.0068 - val_loss: 0.0056
 - val_f1: 0.9895
Epoch 96/200
 - 7s - loss: 0.0067 - val_loss: 0.0059
 - val_f1: 0.9855
Epoch 97/200
 - 7s - loss: 0.0068 - val_loss: 0.0063
 - val_f1: 0.9854
Epoch 98/200
 - 7s - loss: 0.0068 - val_loss: 0.0062
 - val_f1: 0.9856
Epoch 99/200
 - 7s - loss: 0.0068 - val_loss: 0.0057
 - val_f1: 0.9891
Epoch 100/200
 - 7s - loss: 0.0067 - val_loss: 0.0056
 - val_f1: 0.9880
Epoch 101/200
 - 7s - loss: 0.0066 - val_loss: 0.0054
2020-01-06 16:54:35,221 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9892
Epoch 102/200
 - 7s - loss: 0.0066 - val_loss: 0.0054
 - val_f1: 0.9899
Epoch 103/200
 - 7s - loss: 0.0065 - val_loss: 0.0058
 - val_f1: 0.9895
Epoch 104/200
 - 7s - loss: 0.0065 - val_loss: 0.0062
 - val_f1: 0.9859
Epoch 105/200
 - 7s - loss: 0.0064 - val_loss: 0.0056
 - val_f1: 0.9872
Epoch 106/200
 - 7s - loss: 0.0064 - val_loss: 0.0054
 - val_f1: 0.9896
Epoch 107/200
 - 7s - loss: 0.0064 - val_loss: 0.0054
 - val_f1: 0.9891
Epoch 108/200
 - 7s - loss: 0.0064 - val_loss: 0.0054
 - val_f1: 0.9893
Epoch 109/200
 - 7s - loss: 0.0064 - val_loss: 0.0059
 - val_f1: 0.9867
Epoch 110/200
 - 7s - loss: 0.0063 - val_loss: 0.0054
 - val_f1: 0.9919
Epoch 111/200
 - 7s - loss: 0.0063 - val_loss: 0.0053
 - val_f1: 0.9895
Epoch 112/200
 - 7s - loss: 0.0063 - val_loss: 0.0053
 - val_f1: 0.9890
Epoch 113/200
 - 7s - loss: 0.0062 - val_loss: 0.0052
 - val_f1: 0.9900
Epoch 114/200
 - 7s - loss: 0.0062 - val_loss: 0.0055
 - val_f1: 0.9900
Epoch 115/200
 - 7s - loss: 0.0062 - val_loss: 0.0056
 - val_f1: 0.9859
Epoch 116/200
 - 7s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9854
Epoch 117/200
 - 7s - loss: 0.0062 - val_loss: 0.0055
 - val_f1: 0.9915
Epoch 118/200
 - 7s - loss: 0.0061 - val_loss: 0.0060
 - val_f1: 0.9861
Epoch 119/200
 - 7s - loss: 0.0061 - val_loss: 0.0061
 - val_f1: 0.9864
Epoch 120/200
 - 7s - loss: 0.0061 - val_loss: 0.0050
 - val_f1: 0.9915
Epoch 121/200
 - 7s - loss: 0.0061 - val_loss: 0.0054
2020-01-06 17:00:32,486 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9874
Epoch 122/200
 - 7s - loss: 0.0060 - val_loss: 0.0054
 - val_f1: 0.9887
Epoch 123/200
 - 7s - loss: 0.0059 - val_loss: 0.0051
 - val_f1: 0.9915
Epoch 124/200
 - 7s - loss: 0.0060 - val_loss: 0.0059
 - val_f1: 0.9864
Epoch 125/200
 - 7s - loss: 0.0059 - val_loss: 0.0051
 - val_f1: 0.9891
Epoch 126/200
 - 7s - loss: 0.0059 - val_loss: 0.0051
 - val_f1: 0.9892
Epoch 127/200
 - 7s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9892
Epoch 128/200
 - 7s - loss: 0.0060 - val_loss: 0.0051
 - val_f1: 0.9892
Epoch 129/200
 - 7s - loss: 0.0059 - val_loss: 0.0055
 - val_f1: 0.9877
Epoch 130/200
 - 7s - loss: 0.0059 - val_loss: 0.0053
 - val_f1: 0.9891
Epoch 131/200
 - 7s - loss: 0.0058 - val_loss: 0.0051
 - val_f1: 0.9912
Epoch 132/200
 - 7s - loss: 0.0058 - val_loss: 0.0048
 - val_f1: 0.9899
Epoch 133/200
 - 7s - loss: 0.0058 - val_loss: 0.0049
 - val_f1: 0.9898
Epoch 134/200
 - 7s - loss: 0.0057 - val_loss: 0.0051
 - val_f1: 0.9891
Epoch 135/200
 - 7s - loss: 0.0056 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 136/200
 - 7s - loss: 0.0058 - val_loss: 0.0047
 - val_f1: 0.9919
Epoch 137/200
 - 7s - loss: 0.0056 - val_loss: 0.0048
 - val_f1: 0.9917
Epoch 138/200
 - 7s - loss: 0.0056 - val_loss: 0.0053
 - val_f1: 0.9868
Epoch 139/200
 - 7s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9923
Epoch 140/200
 - 7s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9900
Epoch 141/200
 - 7s - loss: 0.0056 - val_loss: 0.0054
2020-01-06 17:06:30,021 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9877
Epoch 142/200
 - 7s - loss: 0.0056 - val_loss: 0.0052
 - val_f1: 0.9881
Epoch 143/200
 - 7s - loss: 0.0056 - val_loss: 0.0049
 - val_f1: 0.9889
Epoch 144/200
 - 7s - loss: 0.0055 - val_loss: 0.0047
 - val_f1: 0.9901
Epoch 145/200
 - 7s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 146/200
 - 7s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9899
Epoch 147/200
 - 7s - loss: 0.0054 - val_loss: 0.0051
 - val_f1: 0.9889
Epoch 148/200
 - 7s - loss: 0.0054 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 149/200
 - 7s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9903
Epoch 150/200
 - 7s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9924
Epoch 151/200
 - 7s - loss: 0.0055 - val_loss: 0.0047
 - val_f1: 0.9901
Epoch 152/200
 - 7s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9922
Epoch 153/200
 - 7s - loss: 0.0054 - val_loss: 0.0049
 - val_f1: 0.9900
Epoch 154/200
 - 7s - loss: 0.0053 - val_loss: 0.0049
 - val_f1: 0.9894
Epoch 155/200
 - 7s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 156/200
 - 7s - loss: 0.0053 - val_loss: 0.0053
 - val_f1: 0.9874
Epoch 157/200
 - 7s - loss: 0.0053 - val_loss: 0.0049
 - val_f1: 0.9896
Epoch 158/200
 - 7s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9900
Epoch 159/200
 - 7s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 160/200
 - 7s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9925
Epoch 161/200
 - 7s - loss: 0.0053 - val_loss: 0.0043
2020-01-06 17:12:27,262 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9923
Epoch 162/200
 - 7s - loss: 0.0051 - val_loss: 0.0051
 - val_f1: 0.9893
Epoch 163/200
 - 7s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9899
Epoch 164/200
 - 7s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9925
Epoch 165/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9926
Epoch 166/200
 - 7s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9896
Epoch 167/200
 - 7s - loss: 0.0051 - val_loss: 0.0050
 - val_f1: 0.9897
Epoch 168/200
 - 7s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9894
Epoch 169/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9921
Epoch 170/200
 - 7s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9921
Epoch 171/200
 - 7s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9922
Epoch 172/200
 - 7s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9896
Epoch 173/200
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9911
Epoch 174/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9903
Epoch 175/200
 - 7s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9903
Epoch 176/200
 - 7s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 177/200
 - 7s - loss: 0.0050 - val_loss: 0.0044
 - val_f1: 0.9902
Epoch 178/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9924
Epoch 179/200
 - 7s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 180/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 181/200
 - 7s - loss: 0.0048 - val_loss: 0.0046
2020-01-06 17:18:24,321 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9905
Epoch 182/200
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9904
Epoch 183/200
 - 7s - loss: 0.0049 - val_loss: 0.0045
 - val_f1: 0.9923
Epoch 184/200
 - 7s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9903
Epoch 185/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 186/200
 - 7s - loss: 0.0048 - val_loss: 0.0043
 - val_f1: 0.9906
Epoch 187/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 188/200
 - 7s - loss: 0.0048 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 189/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9925
Epoch 190/200
 - 7s - loss: 0.0048 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 191/200
 - 7s - loss: 0.0048 - val_loss: 0.0049
 - val_f1: 0.9904
Epoch 192/200
 - 7s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 193/200
 - 7s - loss: 0.0048 - val_loss: 0.0044
 - val_f1: 0.9899
Epoch 194/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9907
Epoch 195/200
 - 7s - loss: 0.0047 - val_loss: 0.0045
 - val_f1: 0.9905
Epoch 196/200
 - 7s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9889
Epoch 197/200
 - 7s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 198/200
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 199/200
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9931
Epoch 200/200
 - 7s - loss: 0.0047 - val_loss: 0.0041
2020-01-06 17:24:14,492 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 17:24:34,633 [INFO] Last epoch loss evaluation: train_loss = 0.003811, val_loss = 0.004033
2020-01-06 17:24:34,637 [INFO] Training complete. time_to_train = 4544.60 sec, 75.74 min
2020-01-06 17:24:34,642 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/best_model.pickle
2020-01-06 17:24:34,646 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/training_error_history.csv
2020-01-06 17:24:34,833 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/training_error_history.png
2020-01-06 17:24:35,006 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/training_f1_history.png
2020-01-06 17:24:35,006 [INFO] Making predictions on training, validation, testing data
2020-01-06 17:25:24,565 [INFO] Evaluating predictions (results)
2020-01-06 17:25:44,399 [INFO] Dataset: Testing. Classification report below
2020-01-06 17:25:44,399 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      1.00    454265
                   Bot       0.93      0.29      0.44       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.96      0.97      2058
              DoS Hulk       0.99      0.95      0.97     46025
      DoS Slowhttptest       0.87      0.92      0.90      1100
         DoS slowloris       0.97      0.89      0.93      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.95      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.88      0.75      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 17:25:44,399 [INFO] Overall accuracy (micro avg): 0.9917321177872629
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-06 17:26:05,699 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9917         0.9917                       0.9917                0.0008                   0.0083  0.9917
1     Macro avg        0.9986         0.8835                       0.7523                0.0028                   0.2477  0.7709
2  Weighted avg        0.9931         0.9915                       0.9917                0.0257                   0.0083  0.9912
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 17:26:25,671 [INFO] Dataset: Validation. Classification report below
2020-01-06 17:26:25,671 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      1.00    454264
                   Bot       0.89      0.26      0.40       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.95      0.97      2059
              DoS Hulk       0.99      0.95      0.97     46025
      DoS Slowhttptest       0.88      0.92      0.90      1099
         DoS slowloris       0.97      0.89      0.93      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      0.99      0.99     31761
           SSH-Patator       0.94      0.97      0.95      1180
Web Attack Brute Force       0.79      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.99    565562
             macro avg       0.87      0.75      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 17:26:25,671 [INFO] Overall accuracy (micro avg): 0.9918222935770084
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-06 17:26:47,200 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9918         0.9918                       0.9918                0.0007                   0.0082  0.9918
1     Macro avg        0.9986         0.8686                       0.7462                0.0028                   0.2538  0.7640
2  Weighted avg        0.9931         0.9914                       0.9918                0.0256                   0.0082  0.9913
2020-01-06 17:27:54,085 [INFO] Dataset: Training. Classification report below
2020-01-06 17:27:54,085 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      1.00      1.00   1362791
                   Bot       0.94      0.27      0.42      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.96      0.97      6176
              DoS Hulk       0.99      0.95      0.97    138074
      DoS Slowhttptest       0.89      0.93      0.91      3300
         DoS slowloris       0.97      0.90      0.94      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      0.99      0.99     95282
           SSH-Patator       0.95      0.97      0.96      3538
Web Attack Brute Force       0.95      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.99   1696684
             macro avg       0.89      0.75      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-06 17:27:54,085 [INFO] Overall accuracy (micro avg): 0.9919042084442359
2020-01-06 17:29:06,127 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9919         0.9919                       0.9919                0.0007                   0.0081  0.9919
1     Macro avg        0.9987         0.8879                       0.7510                0.0028                   0.2490  0.7695
2  Weighted avg        0.9932         0.9916                       0.9919                0.0256                   0.0081  0.9914
2020-01-06 17:29:06,191 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/semi_sup_perf_ids17_dbn_rep2_results.xlsx
2020-01-06 17:29:06,195 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-06 17:29:06,235 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep3
2020-01-06 17:29:06,236 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep3/run_log.log
2020-01-06 17:29:06,236 [INFO] ================= Running experiment no. 3  ================= 

2020-01-06 17:29:06,236 [INFO] Experiment parameters given below
2020-01-06 17:29:06,236 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep3'}
2020-01-06 17:29:06,236 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/tf_logs_run_2020_01_06-17_29_06
2020-01-06 17:29:06,236 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-06 17:29:06,236 [INFO] Reading X, y files
2020-01-06 17:29:06,236 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-06 17:29:10,009 [INFO] Reading complete. time_to_read=3.77 seconds
2020-01-06 17:29:10,009 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-06 17:29:11,288 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-06 17:29:11,288 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-06 17:29:12,569 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-06 17:29:12,569 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-06 17:29:12,816 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-06 17:29:12,816 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-06 17:29:12,902 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-06 17:29:12,902 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-06 17:29:12,986 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-06 17:29:15,935 [INFO] Initializing model
2020-01-06 17:29:15,935 [INFO] Training model
2020-01-06 17:29:15,935 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-06 17:29:39,975 [INFO] Split sizes (instances). total = 1696684, unsupervised = 1272513, supervised = 424171, unsupervised dataset hash = e31b18a1e6e6297a5eb1ef3cd596462a3af9f42b
2020-01-06 17:29:39,975 [INFO] Pretraining Deep Belief Network
2020-01-06 17:45:05,337 [INFO] Pretraining Complete
2020-01-06 17:45:05,337 [INFO] Getting pretrained weights
2020-01-06 17:45:05,337 [INFO] Creating and initializing feed forward neural network
2020-01-06 17:45:05,464 [INFO] _________________________________________________________________
2020-01-06 17:45:05,464 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-06 17:45:05,464 [INFO] =================================================================
2020-01-06 17:45:05,464 [INFO] dense_11 (Dense)             (None, 64)                5056      
2020-01-06 17:45:05,464 [INFO] _________________________________________________________________
2020-01-06 17:45:05,464 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-06 17:45:05,464 [INFO] _________________________________________________________________
2020-01-06 17:45:05,464 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-06 17:45:05,464 [INFO] _________________________________________________________________
2020-01-06 17:45:05,465 [INFO] dense_12 (Dense)             (None, 12)                780       
2020-01-06 17:45:05,465 [INFO] =================================================================
2020-01-06 17:45:05,465 [INFO] Total params: 6,092
2020-01-06 17:45:05,465 [INFO] Trainable params: 5,964
2020-01-06 17:45:05,465 [INFO] Non-trainable params: 128
2020-01-06 17:45:05,465 [INFO] _________________________________________________________________
2020-01-06 17:45:05,845 [INFO] Fine-tuning final neural network
 - val_f1: 0.9905
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.23, time = 11.25s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.49, time = 19.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -41.26, time = 19.33s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -44.49, time = 19.29s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -47.41, time = 19.22s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -50.38, time = 19.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -53.44, time = 19.17s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -56.58, time = 19.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -59.75, time = 19.13s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -62.97, time = 19.11s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -66.21, time = 19.10s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -69.47, time = 19.08s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -72.75, time = 19.07s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -76.03, time = 19.05s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -79.33, time = 18.96s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -82.64, time = 18.82s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -85.98, time = 18.57s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -89.31, time = 18.47s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -92.65, time = 18.36s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -96.02, time = 18.32s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -99.38, time = 18.29s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -102.75, time = 18.26s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -106.14, time = 18.24s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -109.53, time = 18.24s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -112.92, time = 18.22s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -116.31, time = 18.21s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -119.72, time = 18.22s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -123.13, time = 18.22s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -126.54, time = 18.21s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -129.94, time = 18.20s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -133.36, time = 18.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -136.78, time = 18.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -140.19, time = 18.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -143.62, time = 18.17s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -147.04, time = 18.18s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -150.46, time = 18.21s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -153.87, time = 18.22s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -157.29, time = 18.22s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -160.71, time = 18.21s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -164.13, time = 18.21s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -167.54, time = 18.21s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -170.95, time = 18.20s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -174.36, time = 18.20s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -177.77, time = 18.20s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -181.18, time = 18.20s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -184.59, time = 18.20s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -188.00, time = 18.20s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -191.41, time = 18.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -194.82, time = 18.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -198.24, time = 18.19s
Train on 424171 samples, validate on 565562 samples
Epoch 1/200
 - 8s - loss: 0.1029 - val_loss: 0.0670
 - val_f1: 0.7813
Epoch 2/200
 - 7s - loss: 0.0682 - val_loss: 0.0594
 - val_f1: 0.7984
Epoch 3/200
 - 7s - loss: 0.0611 - val_loss: 0.0547
 - val_f1: 0.8069
Epoch 4/200
 - 7s - loss: 0.0571 - val_loss: 0.0525
 - val_f1: 0.8116
Epoch 5/200
 - 7s - loss: 0.0546 - val_loss: 0.0500
 - val_f1: 0.8123
Epoch 6/200
 - 7s - loss: 0.0518 - val_loss: 0.0480
 - val_f1: 0.8354
Epoch 7/200
 - 7s - loss: 0.0500 - val_loss: 0.0460
 - val_f1: 0.8400
Epoch 8/200
 - 7s - loss: 0.0484 - val_loss: 0.0444
 - val_f1: 0.8420
Epoch 9/200
 - 7s - loss: 0.0462 - val_loss: 0.0412
 - val_f1: 0.8585
Epoch 10/200
 - 7s - loss: 0.0422 - val_loss: 0.0357
 - val_f1: 0.8741
Epoch 11/200
 - 7s - loss: 0.0384 - val_loss: 0.0314
 - val_f1: 0.9148
Epoch 12/200
 - 7s - loss: 0.0349 - val_loss: 0.0286
 - val_f1: 0.9243
Epoch 13/200
 - 7s - loss: 0.0298 - val_loss: 0.0215
 - val_f1: 0.9495
Epoch 14/200
 - 7s - loss: 0.0266 - val_loss: 0.0206
 - val_f1: 0.9541
Epoch 15/200
 - 7s - loss: 0.0253 - val_loss: 0.0190
 - val_f1: 0.9556
Epoch 16/200
 - 7s - loss: 0.0240 - val_loss: 0.0179
 - val_f1: 0.9585
Epoch 17/200
 - 7s - loss: 0.0231 - val_loss: 0.0178
 - val_f1: 0.9591
Epoch 18/200
 - 7s - loss: 0.0222 - val_loss: 0.0167
 - val_f1: 0.9606
Epoch 19/200
 - 7s - loss: 0.0216 - val_loss: 0.0160
 - val_f1: 0.9611
Epoch 20/200
 - 7s - loss: 0.0211 - val_loss: 0.0158
 - val_f1: 0.9604
Epoch 21/200
 - 7s - loss: 0.0205 - val_loss: 0.0155
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 17:51:24,639 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9613
Epoch 22/200
 - 7s - loss: 0.0200 - val_loss: 0.0148
 - val_f1: 0.9627
Epoch 23/200
 - 7s - loss: 0.0196 - val_loss: 0.0143
 - val_f1: 0.9628
Epoch 24/200
 - 7s - loss: 0.0191 - val_loss: 0.0140
 - val_f1: 0.9645
Epoch 25/200
 - 7s - loss: 0.0184 - val_loss: 0.0133
 - val_f1: 0.9656
Epoch 26/200
 - 7s - loss: 0.0174 - val_loss: 0.0131
 - val_f1: 0.9682
Epoch 27/200
 - 7s - loss: 0.0167 - val_loss: 0.0128
 - val_f1: 0.9680
Epoch 28/200
 - 7s - loss: 0.0164 - val_loss: 0.0126
 - val_f1: 0.9675
Epoch 29/200
 - 7s - loss: 0.0159 - val_loss: 0.0122
 - val_f1: 0.9688
Epoch 30/200
 - 7s - loss: 0.0157 - val_loss: 0.0119
 - val_f1: 0.9693
Epoch 31/200
 - 7s - loss: 0.0153 - val_loss: 0.0119
 - val_f1: 0.9697
Epoch 32/200
 - 7s - loss: 0.0150 - val_loss: 0.0114
 - val_f1: 0.9698
Epoch 33/200
 - 7s - loss: 0.0148 - val_loss: 0.0113
 - val_f1: 0.9705
Epoch 34/200
 - 7s - loss: 0.0145 - val_loss: 0.0115
 - val_f1: 0.9712
Epoch 35/200
 - 7s - loss: 0.0143 - val_loss: 0.0109
 - val_f1: 0.9733
Epoch 36/200
 - 7s - loss: 0.0142 - val_loss: 0.0112
 - val_f1: 0.9717
Epoch 37/200
 - 7s - loss: 0.0140 - val_loss: 0.0112
 - val_f1: 0.9699
Epoch 38/200
 - 7s - loss: 0.0137 - val_loss: 0.0105
 - val_f1: 0.9733
Epoch 39/200
 - 7s - loss: 0.0135 - val_loss: 0.0106
 - val_f1: 0.9727
Epoch 40/200
 - 7s - loss: 0.0133 - val_loss: 0.0105
 - val_f1: 0.9721
Epoch 41/200
 - 7s - loss: 0.0132 - val_loss: 0.0102
2020-01-06 17:57:33,272 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9786
Epoch 42/200
 - 7s - loss: 0.0129 - val_loss: 0.0100
 - val_f1: 0.9734
Epoch 43/200
 - 7s - loss: 0.0128 - val_loss: 0.0101
 - val_f1: 0.9752
Epoch 44/200
 - 7s - loss: 0.0126 - val_loss: 0.0098
 - val_f1: 0.9744
Epoch 45/200
 - 7s - loss: 0.0124 - val_loss: 0.0098
 - val_f1: 0.9751
Epoch 46/200
 - 7s - loss: 0.0122 - val_loss: 0.0100
 - val_f1: 0.9802
Epoch 47/200
 - 7s - loss: 0.0122 - val_loss: 0.0095
 - val_f1: 0.9795
Epoch 48/200
 - 7s - loss: 0.0121 - val_loss: 0.0093
 - val_f1: 0.9762
Epoch 49/200
 - 7s - loss: 0.0118 - val_loss: 0.0101
 - val_f1: 0.9753
Epoch 50/200
 - 7s - loss: 0.0116 - val_loss: 0.0093
 - val_f1: 0.9800
Epoch 51/200
 - 7s - loss: 0.0115 - val_loss: 0.0092
 - val_f1: 0.9806
Epoch 52/200
 - 7s - loss: 0.0114 - val_loss: 0.0092
 - val_f1: 0.9861
Epoch 53/200
 - 7s - loss: 0.0112 - val_loss: 0.0090
 - val_f1: 0.9837
Epoch 54/200
 - 7s - loss: 0.0110 - val_loss: 0.0086
 - val_f1: 0.9815
Epoch 55/200
 - 7s - loss: 0.0108 - val_loss: 0.0093
 - val_f1: 0.9817
Epoch 56/200
 - 7s - loss: 0.0107 - val_loss: 0.0083
 - val_f1: 0.9796
Epoch 57/200
 - 7s - loss: 0.0104 - val_loss: 0.0091
 - val_f1: 0.9833
Epoch 58/200
 - 7s - loss: 0.0102 - val_loss: 0.0082
 - val_f1: 0.9895
Epoch 59/200
 - 7s - loss: 0.0100 - val_loss: 0.0079
 - val_f1: 0.9818
Epoch 60/200
 - 7s - loss: 0.0096 - val_loss: 0.0078
 - val_f1: 0.9842
Epoch 61/200
 - 7s - loss: 0.0094 - val_loss: 0.0072
2020-01-06 18:03:42,605 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9840
Epoch 62/200
 - 7s - loss: 0.0094 - val_loss: 0.0078
 - val_f1: 0.9845
Epoch 63/200
 - 7s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9841
Epoch 64/200
 - 7s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9843
Epoch 65/200
 - 7s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9844
Epoch 66/200
 - 7s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9846
Epoch 67/200
 - 7s - loss: 0.0085 - val_loss: 0.0064
 - val_f1: 0.9863
Epoch 68/200
 - 7s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9850
Epoch 69/200
 - 7s - loss: 0.0081 - val_loss: 0.0067
 - val_f1: 0.9874
Epoch 70/200
 - 7s - loss: 0.0080 - val_loss: 0.0074
 - val_f1: 0.9832
Epoch 71/200
 - 7s - loss: 0.0079 - val_loss: 0.0088
 - val_f1: 0.9827
Epoch 72/200
 - 7s - loss: 0.0078 - val_loss: 0.0073
 - val_f1: 0.9847
Epoch 73/200
 - 7s - loss: 0.0077 - val_loss: 0.0059
 - val_f1: 0.9875
Epoch 74/200
 - 7s - loss: 0.0077 - val_loss: 0.0060
 - val_f1: 0.9883
Epoch 75/200
 - 7s - loss: 0.0076 - val_loss: 0.0073
 - val_f1: 0.9847
Epoch 76/200
 - 7s - loss: 0.0075 - val_loss: 0.0058
 - val_f1: 0.9869
Epoch 77/200
 - 7s - loss: 0.0074 - val_loss: 0.0061
 - val_f1: 0.9853
Epoch 78/200
 - 7s - loss: 0.0073 - val_loss: 0.0061
 - val_f1: 0.9849
Epoch 79/200
 - 7s - loss: 0.0074 - val_loss: 0.0070
 - val_f1: 0.9848
Epoch 80/200
 - 7s - loss: 0.0072 - val_loss: 0.0064
 - val_f1: 0.9850
Epoch 81/200
 - 7s - loss: 0.0071 - val_loss: 0.0057
2020-01-06 18:09:52,791 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9907
Epoch 82/200
 - 7s - loss: 0.0071 - val_loss: 0.0071
 - val_f1: 0.9827
Epoch 83/200
 - 7s - loss: 0.0070 - val_loss: 0.0057
 - val_f1: 0.9874
Epoch 84/200
 - 7s - loss: 0.0070 - val_loss: 0.0056
 - val_f1: 0.9881
Epoch 85/200
 - 7s - loss: 0.0070 - val_loss: 0.0061
 - val_f1: 0.9852
Epoch 86/200
 - 7s - loss: 0.0069 - val_loss: 0.0057
 - val_f1: 0.9874
Epoch 87/200
 - 7s - loss: 0.0068 - val_loss: 0.0057
 - val_f1: 0.9878
Epoch 88/200
 - 7s - loss: 0.0067 - val_loss: 0.0062
 - val_f1: 0.9852
Epoch 89/200
 - 7s - loss: 0.0068 - val_loss: 0.0062
 - val_f1: 0.9853
Epoch 90/200
 - 7s - loss: 0.0066 - val_loss: 0.0063
 - val_f1: 0.9853
Epoch 91/200
 - 7s - loss: 0.0066 - val_loss: 0.0053
 - val_f1: 0.9896
Epoch 92/200
 - 7s - loss: 0.0066 - val_loss: 0.0058
 - val_f1: 0.9860
Epoch 93/200
 - 7s - loss: 0.0064 - val_loss: 0.0058
 - val_f1: 0.9855
Epoch 94/200
 - 7s - loss: 0.0065 - val_loss: 0.0062
 - val_f1: 0.9854
Epoch 95/200
 - 7s - loss: 0.0064 - val_loss: 0.0059
 - val_f1: 0.9859
Epoch 96/200
 - 7s - loss: 0.0064 - val_loss: 0.0055
 - val_f1: 0.9875
Epoch 97/200
 - 7s - loss: 0.0064 - val_loss: 0.0064
 - val_f1: 0.9851
Epoch 98/200
 - 7s - loss: 0.0062 - val_loss: 0.0058
 - val_f1: 0.9858
Epoch 99/200
 - 7s - loss: 0.0063 - val_loss: 0.0057
 - val_f1: 0.9859
Epoch 100/200
 - 7s - loss: 0.0062 - val_loss: 0.0054
 - val_f1: 0.9868
Epoch 101/200
 - 7s - loss: 0.0062 - val_loss: 0.0057
2020-01-06 18:16:01,516 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9862
Epoch 102/200
 - 7s - loss: 0.0060 - val_loss: 0.0056
 - val_f1: 0.9914
Epoch 103/200
 - 7s - loss: 0.0060 - val_loss: 0.0050
 - val_f1: 0.9913
Epoch 104/200
 - 7s - loss: 0.0060 - val_loss: 0.0058
 - val_f1: 0.9884
Epoch 105/200
 - 7s - loss: 0.0060 - val_loss: 0.0053
 - val_f1: 0.9880
Epoch 106/200
 - 7s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9893
Epoch 107/200
 - 7s - loss: 0.0059 - val_loss: 0.0063
 - val_f1: 0.9860
Epoch 108/200
 - 7s - loss: 0.0059 - val_loss: 0.0059
 - val_f1: 0.9865
Epoch 109/200
 - 7s - loss: 0.0059 - val_loss: 0.0054
 - val_f1: 0.9875
Epoch 110/200
 - 7s - loss: 0.0058 - val_loss: 0.0052
 - val_f1: 0.9893
Epoch 111/200
 - 7s - loss: 0.0057 - val_loss: 0.0056
 - val_f1: 0.9883
Epoch 112/200
 - 7s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9884
Epoch 113/200
 - 7s - loss: 0.0057 - val_loss: 0.0051
 - val_f1: 0.9918
Epoch 114/200
 - 7s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9892
Epoch 115/200
 - 7s - loss: 0.0056 - val_loss: 0.0050
 - val_f1: 0.9889
Epoch 116/200
 - 7s - loss: 0.0056 - val_loss: 0.0050
 - val_f1: 0.9895
Epoch 117/200
 - 7s - loss: 0.0055 - val_loss: 0.0049
 - val_f1: 0.9894
Epoch 118/200
 - 7s - loss: 0.0056 - val_loss: 0.0049
 - val_f1: 0.9916
Epoch 119/200
 - 7s - loss: 0.0055 - val_loss: 0.0051
 - val_f1: 0.9889
Epoch 120/200
 - 7s - loss: 0.0055 - val_loss: 0.0067
 - val_f1: 0.9866
Epoch 121/200
 - 7s - loss: 0.0055 - val_loss: 0.0050
2020-01-06 18:22:13,022 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9884
Epoch 122/200
 - 7s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9905
Epoch 123/200
 - 7s - loss: 0.0055 - val_loss: 0.0048
 - val_f1: 0.9894
Epoch 124/200
 - 7s - loss: 0.0055 - val_loss: 0.0059
 - val_f1: 0.9869
Epoch 125/200
 - 7s - loss: 0.0053 - val_loss: 0.0045
 - val_f1: 0.9917
Epoch 126/200
 - 7s - loss: 0.0054 - val_loss: 0.0061
 - val_f1: 0.9858
Epoch 127/200
 - 7s - loss: 0.0053 - val_loss: 0.0061
 - val_f1: 0.9894
Epoch 128/200
 - 7s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9875
Epoch 129/200
 - 7s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9896
Epoch 130/200
 - 7s - loss: 0.0053 - val_loss: 0.0067
 - val_f1: 0.9854
Epoch 131/200
 - 7s - loss: 0.0052 - val_loss: 0.0052
 - val_f1: 0.9891
Epoch 132/200
 - 7s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9905
Epoch 133/200
 - 7s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 134/200
 - 7s - loss: 0.0052 - val_loss: 0.0056
 - val_f1: 0.9889
Epoch 135/200
 - 7s - loss: 0.0052 - val_loss: 0.0050
 - val_f1: 0.9897
Epoch 136/200
 - 7s - loss: 0.0052 - val_loss: 0.0053
 - val_f1: 0.9885
Epoch 137/200
 - 7s - loss: 0.0052 - val_loss: 0.0052
 - val_f1: 0.9887
Epoch 138/200
 - 7s - loss: 0.0051 - val_loss: 0.0048
 - val_f1: 0.9896
Epoch 139/200
 - 7s - loss: 0.0052 - val_loss: 0.0052
 - val_f1: 0.9890
Epoch 140/200
 - 7s - loss: 0.0051 - val_loss: 0.0060
 - val_f1: 0.9882
Epoch 141/200
 - 7s - loss: 0.0051 - val_loss: 0.0053
2020-01-06 18:28:23,459 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9893
Epoch 142/200
 - 7s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9892
Epoch 143/200
 - 7s - loss: 0.0051 - val_loss: 0.0051
 - val_f1: 0.9891
Epoch 144/200
 - 7s - loss: 0.0051 - val_loss: 0.0059
 - val_f1: 0.9874
Epoch 145/200
 - 7s - loss: 0.0051 - val_loss: 0.0047
 - val_f1: 0.9895
Epoch 146/200
 - 7s - loss: 0.0051 - val_loss: 0.0066
 - val_f1: 0.9875
Epoch 147/200
 - 7s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9904
Epoch 148/200
 - 7s - loss: 0.0050 - val_loss: 0.0044
 - val_f1: 0.9903
Epoch 149/200
 - 7s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9896
Epoch 150/200
 - 7s - loss: 0.0050 - val_loss: 0.0044
 - val_f1: 0.9904
Epoch 151/200
 - 7s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9890
Epoch 152/200
 - 7s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9925
Epoch 153/200
 - 7s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9905
Epoch 154/200
 - 7s - loss: 0.0049 - val_loss: 0.0055
 - val_f1: 0.9887
Epoch 155/200
 - 7s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9902
Epoch 156/200
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9911
Epoch 157/200
 - 7s - loss: 0.0049 - val_loss: 0.0049
 - val_f1: 0.9908
Epoch 158/200
 - 7s - loss: 0.0049 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 159/200
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9922
Epoch 160/200
 - 7s - loss: 0.0048 - val_loss: 0.0043
 - val_f1: 0.9926
Epoch 161/200
 - 7s - loss: 0.0048 - val_loss: 0.0043
2020-01-06 18:34:34,148 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9924
Epoch 162/200
 - 7s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9919
Epoch 163/200
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9923
Epoch 164/200
 - 7s - loss: 0.0049 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 165/200
 - 7s - loss: 0.0048 - val_loss: 0.0046
 - val_f1: 0.9929
Epoch 166/200
 - 7s - loss: 0.0049 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 167/200
 - 7s - loss: 0.0048 - val_loss: 0.0045
 - val_f1: 0.9902
Epoch 168/200
 - 7s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9906
Epoch 169/200
 - 7s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 170/200
 - 7s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 171/200
 - 7s - loss: 0.0047 - val_loss: 0.0048
 - val_f1: 0.9901
Epoch 172/200
 - 7s - loss: 0.0048 - val_loss: 0.0045
 - val_f1: 0.9907
Epoch 173/200
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9906
Epoch 174/200
 - 7s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9912
Epoch 175/200
 - 7s - loss: 0.0048 - val_loss: 0.0047
 - val_f1: 0.9899
Epoch 176/200
 - 7s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9907
Epoch 177/200
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9924
Epoch 178/200
 - 7s - loss: 0.0047 - val_loss: 0.0046
 - val_f1: 0.9903
Epoch 179/200
 - 7s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 180/200
 - 7s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9906
Epoch 181/200
 - 7s - loss: 0.0046 - val_loss: 0.0045
2020-01-06 18:40:44,097 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9926
Epoch 182/200
 - 7s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9929
Epoch 183/200
 - 7s - loss: 0.0046 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 184/200
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9911
Epoch 185/200
 - 7s - loss: 0.0046 - val_loss: 0.0049
 - val_f1: 0.9906
Epoch 186/200
 - 7s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 187/200
 - 7s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9911
Epoch 188/200
 - 7s - loss: 0.0046 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 189/200
 - 7s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9908
Epoch 190/200
 - 7s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 191/200
 - 7s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 192/200
 - 7s - loss: 0.0045 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 193/200
 - 7s - loss: 0.0045 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 194/200
 - 7s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9907
Epoch 195/200
 - 7s - loss: 0.0045 - val_loss: 0.0046
 - val_f1: 0.9927
Epoch 196/200
 - 7s - loss: 0.0045 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 197/200
 - 7s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 198/200
 - 7s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9907
Epoch 199/200
 - 7s - loss: 0.0045 - val_loss: 0.0047
 - val_f1: 0.9899
Epoch 200/200
 - 7s - loss: 0.0045 - val_loss: 0.0044
2020-01-06 18:46:46,547 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-06 18:47:07,865 [INFO] Last epoch loss evaluation: train_loss = 0.003688, val_loss = 0.003969
2020-01-06 18:47:07,868 [INFO] Training complete. time_to_train = 4671.93 sec, 77.87 min
2020-01-06 18:47:07,873 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/best_model.pickle
2020-01-06 18:47:07,876 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/training_error_history.csv
2020-01-06 18:47:08,063 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/training_error_history.png
2020-01-06 18:47:08,236 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/training_f1_history.png
2020-01-06 18:47:08,236 [INFO] Making predictions on training, validation, testing data
2020-01-06 18:48:00,899 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-06 18:48:20,727 [INFO] Dataset: Testing. Classification report below
2020-01-06 18:48:20,728 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      1.00    454265
                   Bot       0.94      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.95      0.97      2058
              DoS Hulk       0.96      1.00      0.98     46025
      DoS Slowhttptest       0.87      0.96      0.91      1100
         DoS slowloris       0.98      0.90      0.94      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.96      0.95      0.95      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 18:48:20,728 [INFO] Overall accuracy (micro avg): 0.9935285609712109
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-06 18:48:42,033 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9935         0.9935                       0.9935                0.0006                   0.0065  0.9935
1     Macro avg        0.9989         0.8063                       0.7586                0.0012                   0.2414  0.7713
2  Weighted avg        0.9946         0.9929                       0.9935                0.0085                   0.0065  0.9931
2020-01-06 18:49:02,014 [INFO] Dataset: Validation. Classification report below
2020-01-06 18:49:02,014 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      1.00    454264
                   Bot       0.95      0.32      0.48       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.94      0.96      2059
              DoS Hulk       0.96      1.00      0.98     46025
      DoS Slowhttptest       0.87      0.95      0.91      1099
         DoS slowloris       0.99      0.90      0.94      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.96      0.96      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.99    565562
             macro avg       0.81      0.75      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-06 18:49:02,014 [INFO] Overall accuracy (micro avg): 0.9934772845417479
2020-01-06 18:49:23,532 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9935         0.9935                       0.9935                0.0006                   0.0065  0.9935
1     Macro avg        0.9989         0.8075                       0.7546                0.0013                   0.2454  0.7677
2  Weighted avg        0.9946         0.9929                       0.9935                0.0087                   0.0065  0.9930
2020-01-06 18:50:30,188 [INFO] Dataset: Training. Classification report below
2020-01-06 18:50:30,188 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      1.00   1362791
                   Bot       0.95      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.95      0.97      6176
              DoS Hulk       0.96      1.00      0.98    138074
      DoS Slowhttptest       0.89      0.96      0.92      3300
         DoS slowloris       0.98      0.91      0.95      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      0.99     95282
           SSH-Patator       0.97      0.95      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.99   1696684
             macro avg       0.81      0.76      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-06 18:50:30,188 [INFO] Overall accuracy (micro avg): 0.9936405364817491
2020-01-06 18:51:42,027 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9936         0.9936                       0.9936                0.0006                   0.0064  0.9936
1     Macro avg        0.9989         0.8096                       0.7593                0.0012                   0.2407  0.7729
2  Weighted avg        0.9947         0.9930                       0.9936                0.0085                   0.0064  0.9932
2020-01-06 18:51:42,092 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/semi_sup_perf_ids17_dbn_rep3_results.xlsx
2020-01-06 18:51:42,096 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-06 18:51:42,139 [INFO] ================= Finished running 6 experiments ================= 

 - val_f1: 0.9924
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-08 10:22:17,336 [INFO] Read 3 experiments from file: experiment_specs/additional_exps/semi_sup_perf_dbn.csv
2020-01-08 10:22:17,336 [INFO] ================= Started running experiments ================= 

2020-01-08 10:22:17,336 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1
2020-01-08 10:22:17,336 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/run_log.log
2020-01-08 10:22:17,336 [INFO] ================= Running experiment no. 1  ================= 

2020-01-08 10:22:17,336 [INFO] Experiment parameters given below
2020-01-08 10:22:17,336 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep1'}
2020-01-08 10:22:17,336 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/tf_logs_run_2020_01_08-10_22_17
2020-01-08 10:22:17,336 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 10:22:17,341 [INFO] Reading X, y files
2020-01-08 10:22:17,341 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 10:22:17,350 [INFO] NumExpr defaulting to 8 threads.
2020-01-08 10:22:22,370 [INFO] Reading complete. time_to_read=5.03 seconds
2020-01-08 10:22:22,371 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 10:22:23,834 [INFO] Reading complete. time_to_read=1.46 seconds
2020-01-08 10:22:23,834 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 10:22:25,274 [INFO] Reading complete. time_to_read=1.44 seconds
2020-01-08 10:22:25,274 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 10:22:25,682 [INFO] Reading complete. time_to_read=0.41 seconds
2020-01-08 10:22:25,683 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 10:22:25,816 [INFO] Reading complete. time_to_read=0.13 seconds
2020-01-08 10:22:25,816 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 10:22:25,946 [INFO] Reading complete. time_to_read=0.13 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 688 tid 688 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 688 tid 705 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 688 tid 706 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 688 tid 707 thread 3 bound to OS proc set 3
2020-01-08 10:22:29,404 [INFO] Initializing model
2020-01-08 10:22:29,405 [INFO] Training model
2020-01-08 10:22:29,405 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-08 10:22:58,741 [INFO] Split sizes (instances). total = 1936462, unsupervised = 1452346, supervised = 484116, unsupervised dataset hash = 263977417d04133c563ce973abc26bd2a7c2f804
2020-01-08 10:22:58,741 [INFO] Pretraining Deep Belief Network
2020-01-08 10:39:32,331 [INFO] Pretraining Complete
2020-01-08 10:39:32,332 [INFO] Getting pretrained weights
2020-01-08 10:39:32,332 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-08 10:39:32,346 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 10:39:32,418 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 10:39:32,460 [INFO] _________________________________________________________________
2020-01-08 10:39:32,461 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 10:39:32,461 [INFO] =================================================================
2020-01-08 10:39:32,461 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-08 10:39:32,461 [INFO] _________________________________________________________________
2020-01-08 10:39:32,461 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 10:39:32,461 [INFO] _________________________________________________________________
2020-01-08 10:39:32,461 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 10:39:32,461 [INFO] _________________________________________________________________
2020-01-08 10:39:32,461 [INFO] dense_2 (Dense)              (None, 15)                975       
2020-01-08 10:39:32,461 [INFO] =================================================================
2020-01-08 10:39:32,461 [INFO] Total params: 6,223
2020-01-08 10:39:32,462 [INFO] Trainable params: 6,095
2020-01-08 10:39:32,462 [INFO] Non-trainable params: 128
2020-01-08 10:39:32,462 [INFO] _________________________________________________________________
2020-01-08 10:39:32.462282: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-08 10:39:32.483617: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-08 10:39:32.483760: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55e27fe2ada0 executing computations on platform Host. Devices:
2020-01-08 10:39:32.483781: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-08 10:39:32.483916: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2020-01-08 10:39:32,566 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 10:39:32,968 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 688 tid 731 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 688 tid 770 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 688 tid 771 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 688 tid 773 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 688 tid 772 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 688 tid 733 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 688 tid 774 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 688 tid 777 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 688 tid 775 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 688 tid 776 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 688 tid 778 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 688 tid 779 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 688 tid 780 thread 16 bound to OS proc set 0
[BernoulliRBM] Iteration 1, pseudo-likelihood = -36.98, time = 12.72s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -45.57, time = 20.98s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -52.13, time = 20.86s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -57.94, time = 20.83s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -63.69, time = 20.81s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -69.48, time = 20.77s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -75.23, time = 20.68s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -80.94, time = 20.55s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -86.58, time = 20.52s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -92.19, time = 20.50s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -97.83, time = 20.25s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -103.46, time = 20.20s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -109.12, time = 20.04s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -114.79, time = 19.92s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -120.47, time = 19.82s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -126.17, time = 19.78s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -131.86, time = 19.74s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -137.54, time = 19.75s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -143.22, time = 19.72s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -148.89, time = 19.68s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -154.55, time = 19.68s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -160.22, time = 19.68s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -165.89, time = 19.64s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -171.58, time = 19.63s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -177.27, time = 19.66s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -182.96, time = 19.67s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -188.67, time = 19.65s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -194.39, time = 19.65s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -200.12, time = 19.64s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -205.86, time = 19.63s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -211.61, time = 19.63s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -217.35, time = 19.64s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -223.12, time = 19.62s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -228.89, time = 19.62s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -234.67, time = 19.62s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -240.45, time = 19.61s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -246.25, time = 19.62s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -252.04, time = 19.61s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -257.86, time = 19.60s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -263.67, time = 19.61s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -269.49, time = 19.60s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -275.31, time = 19.59s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -281.14, time = 19.62s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -286.97, time = 19.59s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -292.82, time = 19.59s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -298.66, time = 19.58s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -304.51, time = 19.58s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -310.37, time = 19.59s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -316.22, time = 19.58s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -322.07, time = 19.58s
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 8s - loss: 0.0844 - val_loss: 0.0611
OMP: Info #250: KMP_AFFINITY: pid 688 tid 795 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 688 tid 796 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 688 tid 797 thread 19 bound to OS proc set 3
 - val_f1: 0.7794
Epoch 2/200
 - 8s - loss: 0.0613 - val_loss: 0.0535
 - val_f1: 0.7956
Epoch 3/200
 - 8s - loss: 0.0545 - val_loss: 0.0475
 - val_f1: 0.8713
Epoch 4/200
 - 8s - loss: 0.0496 - val_loss: 0.0447
 - val_f1: 0.8731
Epoch 5/200
 - 8s - loss: 0.0469 - val_loss: 0.0430
 - val_f1: 0.8809
Epoch 6/200
 - 8s - loss: 0.0444 - val_loss: 0.0408
 - val_f1: 0.8899
Epoch 7/200
 - 8s - loss: 0.0428 - val_loss: 0.0397
 - val_f1: 0.8935
Epoch 8/200
 - 8s - loss: 0.0412 - val_loss: 0.0383
 - val_f1: 0.8960
Epoch 9/200
 - 8s - loss: 0.0393 - val_loss: 0.0360
 - val_f1: 0.8951
Epoch 10/200
 - 8s - loss: 0.0380 - val_loss: 0.0350
 - val_f1: 0.8999
Epoch 11/200
 - 8s - loss: 0.0374 - val_loss: 0.0347
 - val_f1: 0.9018
Epoch 12/200
 - 8s - loss: 0.0367 - val_loss: 0.0338
 - val_f1: 0.9199
Epoch 13/200
 - 8s - loss: 0.0359 - val_loss: 0.0318
 - val_f1: 0.9195
Epoch 14/200
 - 8s - loss: 0.0301 - val_loss: 0.0235
 - val_f1: 0.9048
Epoch 15/200
 - 8s - loss: 0.0267 - val_loss: 0.0245
 - val_f1: 0.9043
Epoch 16/200
 - 8s - loss: 0.0247 - val_loss: 0.0181
 - val_f1: 0.9430
Epoch 17/200
 - 8s - loss: 0.0221 - val_loss: 0.0158
 - val_f1: 0.9570
Epoch 18/200
 - 8s - loss: 0.0206 - val_loss: 0.0140
 - val_f1: 0.9634
Epoch 19/200
 - 8s - loss: 0.0194 - val_loss: 0.0135
 - val_f1: 0.9675
Epoch 20/200
 - 8s - loss: 0.0185 - val_loss: 0.0127
 - val_f1: 0.9719
Epoch 21/200
 - 8s - loss: 0.0180 - val_loss: 0.0125
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 10:45:40,442 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9719
Epoch 22/200
 - 8s - loss: 0.0176 - val_loss: 0.0121
 - val_f1: 0.9726
Epoch 23/200
 - 8s - loss: 0.0173 - val_loss: 0.0117
 - val_f1: 0.9727
Epoch 24/200
 - 7s - loss: 0.0168 - val_loss: 0.0260
 - val_f1: 0.9117
Epoch 25/200
 - 8s - loss: 0.0166 - val_loss: 0.0113
 - val_f1: 0.9729
Epoch 26/200
 - 8s - loss: 0.0163 - val_loss: 0.0110
 - val_f1: 0.9730
Epoch 27/200
 - 8s - loss: 0.0160 - val_loss: 0.0110
 - val_f1: 0.9733
Epoch 28/200
 - 8s - loss: 0.0158 - val_loss: 0.0107
 - val_f1: 0.9733
Epoch 29/200
 - 8s - loss: 0.0156 - val_loss: 0.0109
 - val_f1: 0.9731
Epoch 30/200
 - 8s - loss: 0.0156 - val_loss: 0.0116
 - val_f1: 0.9725
Epoch 31/200
 - 8s - loss: 0.0149 - val_loss: 0.0103
 - val_f1: 0.9739
Epoch 32/200
 - 8s - loss: 0.0143 - val_loss: 0.0117
 - val_f1: 0.9645
Epoch 33/200
 - 8s - loss: 0.0141 - val_loss: 0.0102
 - val_f1: 0.9740
Epoch 34/200
 - 8s - loss: 0.0138 - val_loss: 0.0099
 - val_f1: 0.9745
Epoch 35/200
 - 8s - loss: 0.0136 - val_loss: 0.0097
 - val_f1: 0.9751
Epoch 36/200
 - 8s - loss: 0.0134 - val_loss: 0.0097
 - val_f1: 0.9752
Epoch 37/200
 - 8s - loss: 0.0131 - val_loss: 0.0096
 - val_f1: 0.9753
Epoch 38/200
 - 8s - loss: 0.0129 - val_loss: 0.0095
 - val_f1: 0.9756
Epoch 39/200
 - 8s - loss: 0.0128 - val_loss: 0.0095
 - val_f1: 0.9753
Epoch 40/200
 - 8s - loss: 0.0127 - val_loss: 0.0094
 - val_f1: 0.9760
Epoch 41/200
 - 7s - loss: 0.0126 - val_loss: 0.0096
2020-01-08 10:51:36,039 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9751
Epoch 42/200
 - 8s - loss: 0.0123 - val_loss: 0.0092
 - val_f1: 0.9747
Epoch 43/200
 - 8s - loss: 0.0120 - val_loss: 0.0091
 - val_f1: 0.9762
Epoch 44/200
 - 8s - loss: 0.0118 - val_loss: 0.0092
 - val_f1: 0.9752
Epoch 45/200
 - 8s - loss: 0.0117 - val_loss: 0.0090
 - val_f1: 0.9768
Epoch 46/200
 - 8s - loss: 0.0115 - val_loss: 0.0090
 - val_f1: 0.9764
Epoch 47/200
 - 8s - loss: 0.0114 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 48/200
 - 8s - loss: 0.0113 - val_loss: 0.0090
 - val_f1: 0.9762
Epoch 49/200
 - 8s - loss: 0.0112 - val_loss: 0.0089
 - val_f1: 0.9740
Epoch 50/200
 - 8s - loss: 0.0109 - val_loss: 0.0089
 - val_f1: 0.9766
Epoch 51/200
 - 8s - loss: 0.0108 - val_loss: 0.0090
 - val_f1: 0.9766
Epoch 52/200
 - 8s - loss: 0.0107 - val_loss: 0.0089
 - val_f1: 0.9765
Epoch 53/200
 - 8s - loss: 0.0107 - val_loss: 0.0126
 - val_f1: 0.9636
Epoch 54/200
 - 8s - loss: 0.0105 - val_loss: 0.0090
 - val_f1: 0.9765
Epoch 55/200
 - 7s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9741
Epoch 56/200
 - 8s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9765
Epoch 57/200
 - 8s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9765
Epoch 58/200
 - 8s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9765
Epoch 59/200
 - 8s - loss: 0.0101 - val_loss: 0.0088
 - val_f1: 0.9767
Epoch 60/200
 - 8s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9767
Epoch 61/200
 - 8s - loss: 0.0100 - val_loss: 0.0088
2020-01-08 10:57:32,363 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9767
Epoch 62/200
 - 8s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 63/200
 - 8s - loss: 0.0098 - val_loss: 0.0090
 - val_f1: 0.9763
Epoch 64/200
 - 8s - loss: 0.0098 - val_loss: 0.0089
 - val_f1: 0.9765
Epoch 65/200
 - 8s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9752
Epoch 66/200
 - 8s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 67/200
 - 8s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 68/200
 - 8s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9765
Epoch 69/200
 - 8s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9769
Epoch 70/200
 - 8s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9769
Epoch 71/200
 - 8s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9743
Epoch 72/200
 - 8s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 73/200
 - 8s - loss: 0.0095 - val_loss: 0.0104
 - val_f1: 0.9654
Epoch 74/200
 - 8s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9770
Epoch 75/200
 - 8s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9769
Epoch 76/200
 - 8s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 77/200
 - 8s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 78/200
 - 8s - loss: 0.0094 - val_loss: 0.0087
 - val_f1: 0.9745
Epoch 79/200
 - 8s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9779
Epoch 80/200
 - 8s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 81/200
 - 8s - loss: 0.0093 - val_loss: 0.0087
2020-01-08 11:03:28,999 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9775
Epoch 82/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 83/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 84/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 85/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 86/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 87/200
 - 8s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9772
Epoch 88/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9778
Epoch 89/200
 - 8s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 90/200
 - 8s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 91/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9779
Epoch 92/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 93/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 94/200
 - 8s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9762
Epoch 95/200
 - 8s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 96/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 97/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9782
Epoch 98/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 99/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 100/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 101/200
 - 8s - loss: 0.0090 - val_loss: 0.0092
2020-01-08 11:09:25,735 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9762
Epoch 102/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 103/200
 - 8s - loss: 0.0089 - val_loss: 0.0092
 - val_f1: 0.9762
Epoch 104/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9762
Epoch 105/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 106/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 107/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 108/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 109/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9754
Epoch 110/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 111/200
 - 8s - loss: 0.0088 - val_loss: 0.0096
 - val_f1: 0.9736
Epoch 112/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9762
Epoch 113/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 114/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 115/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 116/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 117/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 118/200
 - 8s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 119/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 120/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 121/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
2020-01-08 11:15:22,845 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9774
Epoch 122/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 123/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 124/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 125/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 126/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 127/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 128/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 129/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 130/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 131/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 132/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 133/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 134/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 135/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 136/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 137/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 138/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 139/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 140/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 141/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
2020-01-08 11:21:20,298 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9778
Epoch 142/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9764
Epoch 143/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 144/200
 - 8s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9761
Epoch 145/200
 - 8s - loss: 0.0086 - val_loss: 0.0087
 - val_f1: 0.9765
Epoch 146/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 147/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 148/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 149/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 150/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 151/200
 - 8s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9772
Epoch 152/200
 - 8s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 153/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 154/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 155/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 156/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 157/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 158/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 159/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 160/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 161/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
2020-01-08 11:27:17,910 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9780
Epoch 162/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 163/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 164/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 165/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 166/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 167/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 168/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 169/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 170/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 171/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 172/200
 - 8s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 173/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 174/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 175/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9761
Epoch 176/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 177/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 178/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 179/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9762
Epoch 180/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 181/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
2020-01-08 11:33:15,299 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9765
Epoch 182/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 183/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 184/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9766
Epoch 185/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 186/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 187/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 188/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 189/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 190/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 191/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 192/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 193/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 194/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 195/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 196/200
 - 8s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 197/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9755
Epoch 198/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 199/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 200/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
2020-01-08 11:39:05,610 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 11:39:24,429 [INFO] Last epoch loss evaluation: train_loss = 0.008080, val_loss = 0.008147
2020-01-08 11:39:24,433 [INFO] Training complete. time_to_train = 4615.03 sec, 76.92 min
2020-01-08 11:39:24,437 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/best_model.pickle
2020-01-08 11:39:24,441 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_error_history.csv
2020-01-08 11:39:24,642 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_error_history.png
2020-01-08 11:39:24,830 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_f1_history.png
2020-01-08 11:39:24,831 [INFO] Making predictions on training, validation, testing data
2020-01-08 11:40:09,489 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 11:40:32,769 [INFO] Dataset: Testing. Classification report below
2020-01-08 11:40:32,770 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.84      0.64      0.73        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.57      5596
   DoS attacks-Slowloris       0.97      0.96      0.96       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.39      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.71      0.66      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 11:40:32,770 [INFO] Overall accuracy (micro avg): 0.9830794685571227
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-08 11:40:57,696 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.7058                       0.6621                0.0045                   0.3379  0.6681
2  Weighted avg        0.9909         0.9774                       0.9831                0.0500                   0.0169  0.9780
2020-01-08 11:41:20,819 [INFO] Dataset: Validation. Classification report below
2020-01-08 11:41:20,819 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.93      0.59      0.72        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.56      5596
   DoS attacks-Slowloris       0.95      0.96      0.96       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.35      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.71      0.66      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 11:41:20,819 [INFO] Overall accuracy (micro avg): 0.9830964837401838
2020-01-08 11:41:45,734 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.7087                       0.6584                0.0045                   0.3416  0.6669
2  Weighted avg        0.9909         0.9770                       0.9831                0.0499                   0.0169  0.9780
2020-01-08 11:43:01,392 [INFO] Dataset: Training. Classification report below
2020-01-08 11:43:01,392 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.89      0.67      0.77       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.46      0.56     16787
   DoS attacks-Slowloris       0.97      0.97      0.97      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.43      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.71      0.67      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 11:43:01,392 [INFO] Overall accuracy (micro avg): 0.9831367721132663
2020-01-08 11:44:22,972 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9978         0.7120                       0.6651                0.0044                   0.3349  0.6712
2  Weighted avg        0.9909         0.9778                       0.9831                0.0498                   0.0169  0.9780
2020-01-08 11:44:23,047 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/semi_sup_perf_ids18_subset_dbn_rep1_results.xlsx
2020-01-08 11:44:23,052 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-08 11:44:23,101 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2
2020-01-08 11:44:23,101 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/run_log.log
2020-01-08 11:44:23,101 [INFO] ================= Running experiment no. 2  ================= 

2020-01-08 11:44:23,101 [INFO] Experiment parameters given below
2020-01-08 11:44:23,101 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep2'}
2020-01-08 11:44:23,101 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/tf_logs_run_2020_01_08-11_44_23
2020-01-08 11:44:23,101 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 11:44:23,102 [INFO] Reading X, y files
2020-01-08 11:44:23,102 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 11:44:27,108 [INFO] Reading complete. time_to_read=4.01 seconds
2020-01-08 11:44:27,108 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 11:44:28,480 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 11:44:28,483 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 11:44:29,849 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 11:44:29,850 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 11:44:30,131 [INFO] Reading complete. time_to_read=0.28 seconds
2020-01-08 11:44:30,132 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 11:44:30,227 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 11:44:30,227 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 11:44:30,323 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 11:44:33,730 [INFO] Initializing model
2020-01-08 11:44:33,730 [INFO] Training model
2020-01-08 11:44:33,732 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-08 11:45:03,313 [INFO] Split sizes (instances). total = 1936462, unsupervised = 1452346, supervised = 484116, unsupervised dataset hash = e96f7f59ec7285e804b188a14c51a497d1a22c07
2020-01-08 11:45:03,313 [INFO] Pretraining Deep Belief Network
2020-01-08 12:02:26,429 [INFO] Pretraining Complete
2020-01-08 12:02:26,429 [INFO] Getting pretrained weights
2020-01-08 12:02:26,429 [INFO] Creating and initializing feed forward neural network
2020-01-08 12:02:26,548 [INFO] _________________________________________________________________
2020-01-08 12:02:26,548 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 12:02:26,548 [INFO] =================================================================
2020-01-08 12:02:26,548 [INFO] dense_3 (Dense)              (None, 64)                4992      
2020-01-08 12:02:26,548 [INFO] _________________________________________________________________
2020-01-08 12:02:26,548 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 12:02:26,548 [INFO] _________________________________________________________________
2020-01-08 12:02:26,548 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 12:02:26,549 [INFO] _________________________________________________________________
2020-01-08 12:02:26,549 [INFO] dense_4 (Dense)              (None, 15)                975       
2020-01-08 12:02:26,549 [INFO] =================================================================
2020-01-08 12:02:26,549 [INFO] Total params: 6,223
2020-01-08 12:02:26,549 [INFO] Trainable params: 6,095
2020-01-08 12:02:26,549 [INFO] Non-trainable params: 128
2020-01-08 12:02:26,549 [INFO] _________________________________________________________________
2020-01-08 12:02:26,677 [INFO] Fine-tuning final neural network
 - val_f1: 0.9781
[BernoulliRBM] Iteration 1, pseudo-likelihood = -37.31, time = 12.74s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -46.02, time = 22.01s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -52.56, time = 21.87s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -58.32, time = 21.84s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -64.03, time = 21.81s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -69.79, time = 21.78s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -75.55, time = 21.66s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -81.29, time = 21.58s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -86.98, time = 21.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -92.64, time = 21.50s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -98.33, time = 21.26s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -104.02, time = 21.20s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -109.73, time = 21.04s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -115.45, time = 20.93s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -121.19, time = 20.83s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -126.93, time = 20.78s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -132.66, time = 20.74s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -138.39, time = 20.74s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -144.11, time = 20.74s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -149.82, time = 20.68s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -155.51, time = 20.68s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -161.22, time = 20.68s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -166.92, time = 20.66s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -172.64, time = 20.65s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -178.37, time = 20.65s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -184.10, time = 20.65s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -189.85, time = 20.63s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -195.60, time = 20.61s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -201.37, time = 20.61s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -207.14, time = 20.61s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -212.92, time = 20.61s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -218.70, time = 20.60s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -224.50, time = 20.60s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -230.30, time = 20.59s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -236.11, time = 20.60s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -241.93, time = 20.59s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -247.76, time = 20.58s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -253.58, time = 20.58s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -259.43, time = 20.57s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -265.27, time = 20.57s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -271.12, time = 20.58s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -276.97, time = 20.57s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -282.84, time = 20.58s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -288.70, time = 20.57s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -294.57, time = 20.56s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -300.44, time = 20.57s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -306.32, time = 20.56s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -312.21, time = 20.57s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -318.09, time = 20.56s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -323.97, time = 20.56s
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 8s - loss: 0.0852 - val_loss: 0.0617
 - val_f1: 0.7938
Epoch 2/200
 - 8s - loss: 0.0620 - val_loss: 0.0543
 - val_f1: 0.7957
Epoch 3/200
 - 8s - loss: 0.0552 - val_loss: 0.0483
 - val_f1: 0.8678
Epoch 4/200
 - 8s - loss: 0.0501 - val_loss: 0.0454
 - val_f1: 0.8722
Epoch 5/200
 - 8s - loss: 0.0475 - val_loss: 0.0435
 - val_f1: 0.8775
Epoch 6/200
 - 8s - loss: 0.0455 - val_loss: 0.0422
 - val_f1: 0.8838
Epoch 7/200
 - 8s - loss: 0.0431 - val_loss: 0.0397
 - val_f1: 0.8909
Epoch 8/200
 - 8s - loss: 0.0412 - val_loss: 0.0388
 - val_f1: 0.8967
Epoch 9/200
 - 8s - loss: 0.0401 - val_loss: 0.0379
 - val_f1: 0.8984
Epoch 10/200
 - 8s - loss: 0.0394 - val_loss: 0.0372
 - val_f1: 0.9014
Epoch 11/200
 - 8s - loss: 0.0389 - val_loss: 0.0367
 - val_f1: 0.9020
Epoch 12/200
 - 8s - loss: 0.0385 - val_loss: 0.0366
 - val_f1: 0.9022
Epoch 13/200
 - 8s - loss: 0.0381 - val_loss: 0.0358
 - val_f1: 0.9028
Epoch 14/200
 - 8s - loss: 0.0375 - val_loss: 0.0350
 - val_f1: 0.9034
Epoch 15/200
 - 8s - loss: 0.0365 - val_loss: 0.0337
 - val_f1: 0.9032
Epoch 16/200
 - 8s - loss: 0.0337 - val_loss: 0.0297
 - val_f1: 0.9196
Epoch 17/200
 - 8s - loss: 0.0316 - val_loss: 0.0293
 - val_f1: 0.9050
Epoch 18/200
 - 8s - loss: 0.0305 - val_loss: 0.0286
 - val_f1: 0.9061
Epoch 19/200
 - 8s - loss: 0.0296 - val_loss: 0.0285
 - val_f1: 0.9058
Epoch 20/200
 - 8s - loss: 0.0236 - val_loss: 0.0170
 - val_f1: 0.9396
Epoch 21/200
 - 8s - loss: 0.0202 - val_loss: 0.0175
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 12:08:46,665 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9542
Epoch 22/200
 - 8s - loss: 0.0189 - val_loss: 0.0139
 - val_f1: 0.9656
Epoch 23/200
 - 8s - loss: 0.0174 - val_loss: 0.0132
 - val_f1: 0.9666
Epoch 24/200
 - 8s - loss: 0.0169 - val_loss: 0.0143
 - val_f1: 0.9542
Epoch 25/200
 - 8s - loss: 0.0163 - val_loss: 0.0137
 - val_f1: 0.9557
Epoch 26/200
 - 8s - loss: 0.0159 - val_loss: 0.0145
 - val_f1: 0.9551
Epoch 27/200
 - 8s - loss: 0.0152 - val_loss: 0.0110
 - val_f1: 0.9707
Epoch 28/200
 - 8s - loss: 0.0143 - val_loss: 0.0106
 - val_f1: 0.9731
Epoch 29/200
 - 8s - loss: 0.0138 - val_loss: 0.0100
 - val_f1: 0.9737
Epoch 30/200
 - 8s - loss: 0.0133 - val_loss: 0.0098
 - val_f1: 0.9734
Epoch 31/200
 - 8s - loss: 0.0130 - val_loss: 0.0103
 - val_f1: 0.9731
Epoch 32/200
 - 8s - loss: 0.0128 - val_loss: 0.0096
 - val_f1: 0.9716
Epoch 33/200
 - 8s - loss: 0.0125 - val_loss: 0.0095
 - val_f1: 0.9740
Epoch 34/200
 - 8s - loss: 0.0124 - val_loss: 0.0104
 - val_f1: 0.9731
Epoch 35/200
 - 8s - loss: 0.0121 - val_loss: 0.0095
 - val_f1: 0.9740
Epoch 36/200
 - 8s - loss: 0.0119 - val_loss: 0.0094
 - val_f1: 0.9741
Epoch 37/200
 - 8s - loss: 0.0117 - val_loss: 0.0093
 - val_f1: 0.9742
Epoch 38/200
 - 8s - loss: 0.0115 - val_loss: 0.0092
 - val_f1: 0.9752
Epoch 39/200
 - 8s - loss: 0.0114 - val_loss: 0.0104
 - val_f1: 0.9727
Epoch 40/200
 - 8s - loss: 0.0112 - val_loss: 0.0092
 - val_f1: 0.9747
Epoch 41/200
 - 8s - loss: 0.0111 - val_loss: 0.0090
2020-01-08 12:14:57,242 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9755
Epoch 42/200
 - 8s - loss: 0.0110 - val_loss: 0.0090
 - val_f1: 0.9754
Epoch 43/200
 - 8s - loss: 0.0109 - val_loss: 0.0107
 - val_f1: 0.9727
Epoch 44/200
 - 8s - loss: 0.0106 - val_loss: 0.0091
 - val_f1: 0.9749
Epoch 45/200
 - 8s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9738
Epoch 46/200
 - 8s - loss: 0.0104 - val_loss: 0.0088
 - val_f1: 0.9764
Epoch 47/200
 - 8s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9760
Epoch 48/200
 - 8s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9761
Epoch 49/200
 - 8s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9763
Epoch 50/200
 - 8s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9766
Epoch 51/200
 - 8s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9765
Epoch 52/200
 - 8s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 53/200
 - 8s - loss: 0.0099 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 54/200
 - 8s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9772
Epoch 55/200
 - 8s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 56/200
 - 8s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 57/200
 - 8s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 58/200
 - 8s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9778
Epoch 59/200
 - 8s - loss: 0.0096 - val_loss: 0.0088
 - val_f1: 0.9769
Epoch 60/200
 - 8s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9774
Epoch 61/200
 - 8s - loss: 0.0095 - val_loss: 0.0086
2020-01-08 12:21:08,200 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9775
Epoch 62/200
 - 8s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9776
Epoch 63/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 64/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9777
Epoch 65/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 66/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 67/200
 - 8s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9773
Epoch 68/200
 - 8s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 69/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 70/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 71/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 72/200
 - 8s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9751
Epoch 73/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9762
Epoch 74/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 75/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9779
Epoch 76/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 77/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 78/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 79/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 80/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 81/200
 - 8s - loss: 0.0090 - val_loss: 0.0085
2020-01-08 12:27:19,604 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9753
Epoch 82/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 83/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 84/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 85/200
 - 8s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 86/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 87/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 88/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9782
Epoch 89/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 90/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 91/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 92/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 93/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 94/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 95/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 96/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 97/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 98/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 99/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9753
Epoch 100/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 101/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
2020-01-08 12:33:31,552 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9778
Epoch 102/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 103/200
 - 8s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 104/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 105/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 106/200
 - 8s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 107/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 108/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 109/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 110/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 111/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9784
Epoch 112/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 113/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 114/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 115/200
 - 8s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9762
Epoch 116/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9763
Epoch 117/200
 - 8s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 118/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 119/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 120/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 121/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
2020-01-08 12:39:43,273 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9779
Epoch 122/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 123/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 124/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 125/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 126/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 127/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 128/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 129/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 130/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 131/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 132/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 133/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 134/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 135/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 136/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 137/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 138/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 139/200
 - 8s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 140/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 141/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
2020-01-08 12:45:54,901 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9758
Epoch 142/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 143/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 144/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 145/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 146/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 147/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 148/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 149/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 150/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 151/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 152/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 153/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9783
Epoch 154/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 155/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 156/200
 - 8s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 157/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 158/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 159/200
 - 8s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 160/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 161/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
2020-01-08 12:52:10,208 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9784
Epoch 162/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 163/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 164/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9763
Epoch 165/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 166/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 167/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 168/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 169/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 170/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9765
Epoch 171/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 172/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 173/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 174/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9759
Epoch 175/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 176/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 177/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 178/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 179/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 180/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9764
Epoch 181/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
2020-01-08 12:58:25,566 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9780
Epoch 182/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 183/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 184/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 185/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 186/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 187/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 188/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 189/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 190/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 191/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 192/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 193/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 194/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 195/200
 - 8s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 196/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 197/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 198/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 199/200
 - 8s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 200/200
 - 8s - loss: 0.0084 - val_loss: 0.0082
2020-01-08 13:04:32,901 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 13:04:53,036 [INFO] Last epoch loss evaluation: train_loss = 0.008069, val_loss = 0.008169
2020-01-08 13:04:53,040 [INFO] Training complete. time_to_train = 4819.31 sec, 80.32 min
2020-01-08 13:04:53,045 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/best_model.pickle
2020-01-08 13:04:53,047 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_error_history.csv
2020-01-08 13:04:53,242 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_error_history.png
2020-01-08 13:04:53,426 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_f1_history.png
2020-01-08 13:04:53,426 [INFO] Making predictions on training, validation, testing data
2020-01-08 13:05:41,662 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 13:06:04,865 [INFO] Dataset: Testing. Classification report below
2020-01-08 13:06:04,865 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.85      0.76      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.45      0.56      5596
   DoS attacks-Slowloris       0.94      0.95      0.95       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.30      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.70      0.67      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 13:06:04,865 [INFO] Overall accuracy (micro avg): 0.9830515826785315
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 13:06:29,816 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.6987                       0.6686                0.0045                   0.3314  0.6708
2  Weighted avg        0.9909         0.9764                       0.9831                0.0502                   0.0169  0.9778
2020-01-08 13:06:52,936 [INFO] Dataset: Validation. Classification report below
2020-01-08 13:06:52,936 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.91      0.72      0.80        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.45      0.56      5596
   DoS attacks-Slowloris       0.93      0.95      0.94       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.30      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.70      0.67      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 13:06:52,936 [INFO] Overall accuracy (micro avg): 0.9831228204440988
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-08 13:07:17,866 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.7023                       0.6656                0.0045                   0.3344  0.6702
2  Weighted avg        0.9909         0.9765                       0.9831                0.0501                   0.0169  0.9779
2020-01-08 13:08:33,575 [INFO] Dataset: Training. Classification report below
2020-01-08 13:08:33,576 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.88      0.80      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.45      0.56     16787
   DoS attacks-Slowloris       0.95      0.97      0.96      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.37      0.00      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.71      0.67      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 13:08:33,576 [INFO] Overall accuracy (micro avg): 0.9831316080563419
2020-01-08 13:09:55,199 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9978         0.7063                       0.6725                0.0045                   0.3275  0.6741
2  Weighted avg        0.9909         0.9772                       0.9831                0.0500                   0.0169  0.9779
2020-01-08 13:09:55,273 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/semi_sup_perf_ids18_subset_dbn_rep2_results.xlsx
2020-01-08 13:09:55,278 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-08 13:09:55,326 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3
2020-01-08 13:09:55,326 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/run_log.log
2020-01-08 13:09:55,327 [INFO] ================= Running experiment no. 3  ================= 

2020-01-08 13:09:55,327 [INFO] Experiment parameters given below
2020-01-08 13:09:55,327 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.75, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep3'}
2020-01-08 13:09:55,327 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/tf_logs_run_2020_01_08-13_09_55
2020-01-08 13:09:55,327 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 13:09:55,327 [INFO] Reading X, y files
2020-01-08 13:09:55,327 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 13:09:59,337 [INFO] Reading complete. time_to_read=4.01 seconds
2020-01-08 13:09:59,337 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 13:10:00,704 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 13:10:00,704 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 13:10:02,073 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 13:10:02,073 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 13:10:02,346 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-08 13:10:02,346 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 13:10:02,440 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-08 13:10:02,440 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 13:10:02,535 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-08 13:10:05,938 [INFO] Initializing model
2020-01-08 13:10:05,940 [INFO] Training model
2020-01-08 13:10:05,940 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-08 13:10:35,701 [INFO] Split sizes (instances). total = 1936462, unsupervised = 1452346, supervised = 484116, unsupervised dataset hash = 4b58ec54610aa6fab9c2e34ff129680f9e45f4bd
2020-01-08 13:10:35,701 [INFO] Pretraining Deep Belief Network
2020-01-08 13:28:02,027 [INFO] Pretraining Complete
2020-01-08 13:28:02,027 [INFO] Getting pretrained weights
2020-01-08 13:28:02,027 [INFO] Creating and initializing feed forward neural network
2020-01-08 13:28:02,147 [INFO] _________________________________________________________________
2020-01-08 13:28:02,147 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 13:28:02,148 [INFO] =================================================================
2020-01-08 13:28:02,148 [INFO] dense_5 (Dense)              (None, 64)                4992      
2020-01-08 13:28:02,148 [INFO] _________________________________________________________________
2020-01-08 13:28:02,148 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 13:28:02,148 [INFO] _________________________________________________________________
2020-01-08 13:28:02,148 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 13:28:02,148 [INFO] _________________________________________________________________
2020-01-08 13:28:02,148 [INFO] dense_6 (Dense)              (None, 15)                975       
2020-01-08 13:28:02,148 [INFO] =================================================================
2020-01-08 13:28:02,148 [INFO] Total params: 6,223
2020-01-08 13:28:02,149 [INFO] Trainable params: 6,095
2020-01-08 13:28:02,149 [INFO] Non-trainable params: 128
2020-01-08 13:28:02,149 [INFO] _________________________________________________________________
2020-01-08 13:28:02,332 [INFO] Fine-tuning final neural network
 - val_f1: 0.9780
[BernoulliRBM] Iteration 1, pseudo-likelihood = -36.98, time = 12.79s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -45.55, time = 22.07s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -52.08, time = 21.92s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -57.88, time = 21.89s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -63.63, time = 21.88s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -69.42, time = 21.83s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -75.19, time = 21.72s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -80.94, time = 21.64s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -86.63, time = 21.59s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -92.30, time = 21.58s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -98.00, time = 21.32s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -103.70, time = 21.26s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -109.42, time = 21.10s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -115.15, time = 20.99s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -120.90, time = 20.90s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -126.66, time = 20.85s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -132.41, time = 20.81s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -138.15, time = 20.81s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -143.89, time = 20.81s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -149.62, time = 20.76s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -155.35, time = 20.75s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -161.08, time = 20.74s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -166.81, time = 20.72s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -172.55, time = 20.71s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -178.30, time = 20.70s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -184.06, time = 20.70s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -189.83, time = 20.69s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -195.61, time = 20.68s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -201.40, time = 20.67s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -207.19, time = 20.68s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -213.00, time = 20.68s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -218.81, time = 20.67s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -224.64, time = 20.67s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -230.47, time = 20.66s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -236.30, time = 20.66s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -242.15, time = 20.65s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -248.00, time = 20.64s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -253.86, time = 20.64s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -259.73, time = 20.64s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -265.60, time = 20.65s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -271.48, time = 20.64s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -277.35, time = 20.63s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -283.25, time = 20.63s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -289.14, time = 20.63s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -295.03, time = 20.63s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -300.93, time = 20.64s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -306.84, time = 20.63s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -312.75, time = 20.63s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -318.66, time = 20.62s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -324.57, time = 20.62s
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 9s - loss: 0.0846 - val_loss: 0.0612
 - val_f1: 0.7939
Epoch 2/200
 - 8s - loss: 0.0617 - val_loss: 0.0541
 - val_f1: 0.7966
Epoch 3/200
 - 8s - loss: 0.0550 - val_loss: 0.0479
 - val_f1: 0.8709
Epoch 4/200
 - 8s - loss: 0.0501 - val_loss: 0.0451
 - val_f1: 0.8724
Epoch 5/200
 - 8s - loss: 0.0473 - val_loss: 0.0433
 - val_f1: 0.8838
Epoch 6/200
 - 8s - loss: 0.0451 - val_loss: 0.0411
 - val_f1: 0.8904
Epoch 7/200
 - 8s - loss: 0.0426 - val_loss: 0.0396
 - val_f1: 0.8920
Epoch 8/200
 - 8s - loss: 0.0412 - val_loss: 0.0386
 - val_f1: 0.8947
Epoch 9/200
 - 8s - loss: 0.0404 - val_loss: 0.0388
 - val_f1: 0.8971
Epoch 10/200
 - 8s - loss: 0.0396 - val_loss: 0.0371
 - val_f1: 0.8994
Epoch 11/200
 - 8s - loss: 0.0387 - val_loss: 0.0366
 - val_f1: 0.9014
Epoch 12/200
 - 8s - loss: 0.0371 - val_loss: 0.0318
 - val_f1: 0.9021
Epoch 13/200
 - 8s - loss: 0.0304 - val_loss: 0.0238
 - val_f1: 0.9040
Epoch 14/200
 - 8s - loss: 0.0271 - val_loss: 0.0208
 - val_f1: 0.9333
Epoch 15/200
 - 8s - loss: 0.0239 - val_loss: 0.0173
 - val_f1: 0.9392
Epoch 16/200
 - 8s - loss: 0.0220 - val_loss: 0.0406
 - val_f1: 0.8256
Epoch 17/200
 - 8s - loss: 0.0207 - val_loss: 0.0146
 - val_f1: 0.9657
Epoch 18/200
 - 8s - loss: 0.0198 - val_loss: 0.0171
 - val_f1: 0.9415
Epoch 19/200
 - 8s - loss: 0.0191 - val_loss: 0.0135
 - val_f1: 0.9659
Epoch 20/200
 - 8s - loss: 0.0186 - val_loss: 0.0132
 - val_f1: 0.9660
Epoch 21/200
 - 8s - loss: 0.0181 - val_loss: 0.0192
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 13:34:39,937 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9259
Epoch 22/200
 - 8s - loss: 0.0169 - val_loss: 0.0121
 - val_f1: 0.9715
Epoch 23/200
 - 8s - loss: 0.0164 - val_loss: 0.0112
 - val_f1: 0.9729
Epoch 24/200
 - 8s - loss: 0.0161 - val_loss: 0.0136
 - val_f1: 0.9612
Epoch 25/200
 - 8s - loss: 0.0159 - val_loss: 0.0137
 - val_f1: 0.9614
Epoch 26/200
 - 8s - loss: 0.0156 - val_loss: 0.0451
 - val_f1: 0.8253
Epoch 27/200
 - 8s - loss: 0.0152 - val_loss: 0.0106
 - val_f1: 0.9729
Epoch 28/200
 - 8s - loss: 0.0150 - val_loss: 0.0106
 - val_f1: 0.9734
Epoch 29/200
 - 8s - loss: 0.0148 - val_loss: 0.0103
 - val_f1: 0.9734
Epoch 30/200
 - 8s - loss: 0.0146 - val_loss: 0.0106
 - val_f1: 0.9710
Epoch 31/200
 - 8s - loss: 0.0144 - val_loss: 0.0164
 - val_f1: 0.9383
Epoch 32/200
 - 8s - loss: 0.0142 - val_loss: 0.0103
 - val_f1: 0.9735
Epoch 33/200
 - 8s - loss: 0.0141 - val_loss: 0.0099
 - val_f1: 0.9740
Epoch 34/200
 - 8s - loss: 0.0139 - val_loss: 0.0097
 - val_f1: 0.9746
Epoch 35/200
 - 8s - loss: 0.0134 - val_loss: 0.0095
 - val_f1: 0.9752
Epoch 36/200
 - 8s - loss: 0.0129 - val_loss: 0.0094
 - val_f1: 0.9753
Epoch 37/200
 - 8s - loss: 0.0124 - val_loss: 0.0093
 - val_f1: 0.9756
Epoch 38/200
 - 8s - loss: 0.0122 - val_loss: 0.0183
 - val_f1: 0.9575
Epoch 39/200
 - 8s - loss: 0.0118 - val_loss: 0.0092
 - val_f1: 0.9748
Epoch 40/200
 - 8s - loss: 0.0116 - val_loss: 0.0092
 - val_f1: 0.9757
Epoch 41/200
 - 8s - loss: 0.0115 - val_loss: 0.0091
2020-01-08 13:41:14,089 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9757
Epoch 42/200
 - 8s - loss: 0.0113 - val_loss: 0.0091
 - val_f1: 0.9758
Epoch 43/200
 - 8s - loss: 0.0112 - val_loss: 0.0093
 - val_f1: 0.9748
Epoch 44/200
 - 8s - loss: 0.0111 - val_loss: 0.0090
 - val_f1: 0.9762
Epoch 45/200
 - 8s - loss: 0.0110 - val_loss: 0.0103
 - val_f1: 0.9718
Epoch 46/200
 - 8s - loss: 0.0110 - val_loss: 0.0090
 - val_f1: 0.9737
Epoch 47/200
 - 8s - loss: 0.0109 - val_loss: 0.0254
 - val_f1: 0.9270
Epoch 48/200
 - 8s - loss: 0.0109 - val_loss: 0.0090
 - val_f1: 0.9758
Epoch 49/200
 - 8s - loss: 0.0108 - val_loss: 0.0483
 - val_f1: 0.8259
Epoch 50/200
 - 8s - loss: 0.0107 - val_loss: 0.0089
 - val_f1: 0.9759
Epoch 51/200
 - 8s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9762
Epoch 52/200
 - 8s - loss: 0.0106 - val_loss: 0.0125
 - val_f1: 0.9633
Epoch 53/200
 - 8s - loss: 0.0106 - val_loss: 0.0512
 - val_f1: 0.8152
Epoch 54/200
 - 8s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9767
Epoch 55/200
 - 8s - loss: 0.0104 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 56/200
 - 8s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9740
Epoch 57/200
 - 8s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9770
Epoch 58/200
 - 8s - loss: 0.0101 - val_loss: 0.0106
 - val_f1: 0.9642
Epoch 59/200
 - 8s - loss: 0.0101 - val_loss: 0.0472
 - val_f1: 0.8576
Epoch 60/200
 - 8s - loss: 0.0100 - val_loss: 0.0126
 - val_f1: 0.9631
Epoch 61/200
 - 8s - loss: 0.0100 - val_loss: 0.0087
2020-01-08 13:47:43,170 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9769
Epoch 62/200
 - 8s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9768
Epoch 63/200
 - 8s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9766
Epoch 64/200
 - 8s - loss: 0.0098 - val_loss: 0.0091
 - val_f1: 0.9753
Epoch 65/200
 - 8s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9771
Epoch 66/200
 - 8s - loss: 0.0098 - val_loss: 0.0302
 - val_f1: 0.9092
Epoch 67/200
 - 8s - loss: 0.0098 - val_loss: 0.0109
 - val_f1: 0.9643
Epoch 68/200
 - 8s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9766
Epoch 69/200
 - 8s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9771
Epoch 70/200
 - 8s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9766
Epoch 71/200
 - 8s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9769
Epoch 72/200
 - 8s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 73/200
 - 8s - loss: 0.0097 - val_loss: 0.0237
 - val_f1: 0.9170
Epoch 74/200
 - 8s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9773
Epoch 75/200
 - 8s - loss: 0.0097 - val_loss: 0.0092
 - val_f1: 0.9756
Epoch 76/200
 - 8s - loss: 0.0096 - val_loss: 0.0111
 - val_f1: 0.9644
Epoch 77/200
 - 8s - loss: 0.0096 - val_loss: 0.0089
 - val_f1: 0.9756
Epoch 78/200
 - 8s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9771
Epoch 79/200
 - 8s - loss: 0.0096 - val_loss: 0.0094
 - val_f1: 0.9740
Epoch 80/200
 - 8s - loss: 0.0096 - val_loss: 0.0093
 - val_f1: 0.9742
Epoch 81/200
 - 8s - loss: 0.0096 - val_loss: 0.0085
2020-01-08 13:54:12,482 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9771
Epoch 82/200
 - 8s - loss: 0.0096 - val_loss: 0.0105
 - val_f1: 0.9656
Epoch 83/200
 - 8s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 84/200
 - 8s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 85/200
 - 8s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9761
Epoch 86/200
 - 8s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 87/200
 - 8s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 88/200
 - 8s - loss: 0.0095 - val_loss: 0.0123
 - val_f1: 0.9634
Epoch 89/200
 - 8s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 90/200
 - 8s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9771
Epoch 91/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 92/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 93/200
 - 8s - loss: 0.0094 - val_loss: 0.0357
 - val_f1: 0.9164
Epoch 94/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 95/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 96/200
 - 8s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 97/200
 - 8s - loss: 0.0093 - val_loss: 0.0130
 - val_f1: 0.9638
Epoch 98/200
 - 8s - loss: 0.0093 - val_loss: 0.0126
 - val_f1: 0.9630
Epoch 99/200
 - 8s - loss: 0.0093 - val_loss: 0.0314
 - val_f1: 0.9163
Epoch 100/200
 - 8s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 101/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
2020-01-08 14:00:42,188 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9776
Epoch 102/200
 - 8s - loss: 0.0092 - val_loss: 0.0138
 - val_f1: 0.9633
Epoch 103/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 104/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 105/200
 - 8s - loss: 0.0093 - val_loss: 0.0097
 - val_f1: 0.9755
Epoch 106/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 107/200
 - 8s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 108/200
 - 8s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 109/200
 - 8s - loss: 0.0093 - val_loss: 0.0122
 - val_f1: 0.9635
Epoch 110/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 111/200
 - 8s - loss: 0.0092 - val_loss: 0.0092
 - val_f1: 0.9763
Epoch 112/200
 - 8s - loss: 0.0092 - val_loss: 0.0111
 - val_f1: 0.9652
Epoch 113/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 114/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 115/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 116/200
 - 8s - loss: 0.0092 - val_loss: 0.0254
 - val_f1: 0.9200
Epoch 117/200
 - 8s - loss: 0.0092 - val_loss: 0.0293
 - val_f1: 0.9188
Epoch 118/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 119/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 120/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 121/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
2020-01-08 14:07:11,611 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9777
Epoch 122/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9771
Epoch 123/200
 - 8s - loss: 0.0092 - val_loss: 0.0103
 - val_f1: 0.9749
Epoch 124/200
 - 8s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 125/200
 - 8s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 126/200
 - 8s - loss: 0.0091 - val_loss: 0.0090
 - val_f1: 0.9761
Epoch 127/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 128/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 129/200
 - 8s - loss: 0.0091 - val_loss: 0.0097
 - val_f1: 0.9755
Epoch 130/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 131/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 132/200
 - 8s - loss: 0.0090 - val_loss: 0.0201
 - val_f1: 0.9201
Epoch 133/200
 - 8s - loss: 0.0091 - val_loss: 0.0096
 - val_f1: 0.9757
Epoch 134/200
 - 8s - loss: 0.0091 - val_loss: 0.0094
 - val_f1: 0.9762
Epoch 135/200
 - 8s - loss: 0.0090 - val_loss: 0.0096
 - val_f1: 0.9758
Epoch 136/200
 - 8s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9766
Epoch 137/200
 - 8s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 138/200
 - 8s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9762
Epoch 139/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 140/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 141/200
 - 8s - loss: 0.0090 - val_loss: 0.0139
2020-01-08 14:13:41,019 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9632
Epoch 142/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 143/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 144/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 145/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 146/200
 - 8s - loss: 0.0090 - val_loss: 0.0087
 - val_f1: 0.9764
Epoch 147/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9754
Epoch 148/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 149/200
 - 8s - loss: 0.0090 - val_loss: 0.0157
 - val_f1: 0.9628
Epoch 150/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 151/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 152/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 153/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 154/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 155/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 156/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 157/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 158/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 159/200
 - 8s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 160/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 161/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
2020-01-08 14:20:10,359 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9775
Epoch 162/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 163/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 164/200
 - 8s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 165/200
 - 8s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9772
Epoch 166/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 167/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 168/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 169/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 170/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 171/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 172/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 173/200
 - 8s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 174/200
 - 8s - loss: 0.0089 - val_loss: 0.0119
 - val_f1: 0.9663
Epoch 175/200
 - 8s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9766
Epoch 176/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 177/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 178/200
 - 8s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9765
Epoch 179/200
 - 8s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9766
Epoch 180/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 181/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
2020-01-08 14:26:39,760 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9777
Epoch 182/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9771
Epoch 183/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 184/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 185/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 186/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 187/200
 - 8s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 188/200
 - 8s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 189/200
 - 8s - loss: 0.0088 - val_loss: 0.0109
 - val_f1: 0.9666
Epoch 190/200
 - 8s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 191/200
 - 8s - loss: 0.0088 - val_loss: 0.0123
 - val_f1: 0.9666
Epoch 192/200
 - 8s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 193/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 194/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 195/200
 - 8s - loss: 0.0087 - val_loss: 0.0117
 - val_f1: 0.9668
Epoch 196/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 197/200
 - 8s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 198/200
 - 8s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 199/200
 - 8s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 200/200
 - 8s - loss: 0.0087 - val_loss: 0.0101
2020-01-08 14:33:01,688 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 14:33:22,769 [INFO] Last epoch loss evaluation: train_loss = 0.008142, val_loss = 0.008211
2020-01-08 14:33:22,774 [INFO] Training complete. time_to_train = 4996.83 sec, 83.28 min
2020-01-08 14:33:22,779 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/best_model.pickle
2020-01-08 14:33:22,782 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_error_history.csv
2020-01-08 14:33:22,981 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_error_history.png
2020-01-08 14:33:23,170 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_f1_history.png
2020-01-08 14:33:23,170 [INFO] Making predictions on training, validation, testing data
2020-01-08 14:34:14,432 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 14:34:37,641 [INFO] Dataset: Testing. Classification report below
2020-01-08 14:34:37,641 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.97      0.45      0.61        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.98      0.98      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.44      0.55      5596
   DoS attacks-Slowloris       0.99      0.73      0.84       440
          FTP-BruteForce       0.69      0.89      0.77      7718
           Infilteration       0.44      0.01      0.03      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.72      0.63      0.65    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 14:34:37,642 [INFO] Overall accuracy (micro avg): 0.9828300448652803
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 14:35:02,603 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9828         0.9828                       0.9828                0.0012                   0.0172  0.9828
1     Macro avg        0.9977         0.7194                       0.6324                0.0045                   0.3676  0.6515
2  Weighted avg        0.9907         0.9777                       0.9828                0.0507                   0.0172  0.9778
2020-01-08 14:35:25,720 [INFO] Dataset: Validation. Classification report below
2020-01-08 14:35:25,721 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.89      0.37      0.52        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.44      0.56      5596
   DoS attacks-Slowloris       0.99      0.78      0.87       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.42      0.01      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.71      0.63      0.65    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 14:35:25,721 [INFO] Overall accuracy (micro avg): 0.9829648002206086
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-08 14:35:50,637 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.7138                       0.6317                0.0045                   0.3683  0.6483
2  Weighted avg        0.9908         0.9777                       0.9830                0.0504                   0.0170  0.9779
2020-01-08 14:37:06,423 [INFO] Dataset: Training. Classification report below
2020-01-08 14:37:06,424 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.85      0.43      0.57       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.44      0.55     16787
   DoS attacks-Slowloris       0.99      0.76      0.86      1318
          FTP-BruteForce       0.69      0.89      0.77     23153
           Infilteration       0.49      0.02      0.03     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.72      0.63      0.65   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 14:37:06,424 [INFO] Overall accuracy (micro avg): 0.9829338246761362
2020-01-08 14:38:28,123 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.7156                       0.6340                0.0045                   0.3660  0.6506
2  Weighted avg        0.9908         0.9783                       0.9829                0.0503                   0.0171  0.9779
2020-01-08 14:38:28,288 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/semi_sup_perf_ids18_subset_dbn_rep3_results.xlsx
2020-01-08 14:38:28,294 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-08 14:38:28,342 [INFO] ================= Finished running 3 experiments ================= 

 - val_f1: 0.9669
