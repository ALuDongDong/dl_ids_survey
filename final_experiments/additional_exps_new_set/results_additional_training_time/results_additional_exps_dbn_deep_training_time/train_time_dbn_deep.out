Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-14 12:21:51,319 [INFO] Read 12 experiments from file: experiment_specs/additional_exps/training_time/train_time_dbn.csv
2020-01-14 12:21:51,319 [INFO] ================= Started running experiments ================= 

2020-01-14 12:21:51,319 [INFO] Created directory: results_additional_exps/train_time_nsl_dbn_deep_rep1
2020-01-14 12:21:51,319 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_dbn_deep_rep1/run_log.log
2020-01-14 12:21:51,319 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:21:51,319 [INFO] Experiment parameters given below
2020-01-14 12:21:51,319 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_nsl_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.740772514, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_dbn_deep_rep1'}
2020-01-14 12:21:51,319 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_dbn_deep_rep1/tf_logs_run_2020_01_14-12_21_51
2020-01-14 12:21:51,319 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:21:51,320 [INFO] Reading X, y files
2020-01-14 12:21:51,320 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:21:51,329 [INFO] NumExpr defaulting to 8 threads.
2020-01-14 12:21:51,566 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-14 12:21:51,566 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:21:51,627 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:21:51,627 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:21:51,683 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:21:51,683 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:21:51,691 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:21:51,691 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:21:51,696 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:21:51,696 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:21:51,700 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:21:51,820 [INFO] Initializing model
2020-01-14 12:21:51,821 [INFO] Training model
2020-01-14 12:21:51,821 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16375 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16386 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16387 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16388 thread 3 bound to OS proc set 3
2020-01-14 12:21:52,869 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = a5039bcf5af08b73e8acb2f2a61a872a189c06e9
2020-01-14 12:21:52,869 [INFO] Pretraining Deep Belief Network
2020-01-14 12:22:05,904 [INFO] Pretraining Complete
2020-01-14 12:22:05,904 [INFO] Getting pretrained weights
2020-01-14 12:22:05,904 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-14 12:22:05,919 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-14 12:22:05,995 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-14 12:22:06,214 [INFO] _________________________________________________________________
2020-01-14 12:22:06,214 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:22:06,214 [INFO] =================================================================
2020-01-14 12:22:06,215 [INFO] dense_1 (Dense)              (None, 128)               15744     
2020-01-14 12:22:06,215 [INFO] _________________________________________________________________
2020-01-14 12:22:06,215 [INFO] batch_normalization_1 (Batch (None, 128)               512       
2020-01-14 12:22:06,215 [INFO] _________________________________________________________________
2020-01-14 12:22:06,215 [INFO] dropout_1 (Dropout)          (None, 128)               0         
2020-01-14 12:22:06,215 [INFO] _________________________________________________________________
2020-01-14 12:22:06,215 [INFO] dense_2 (Dense)              (None, 64)                8256      
2020-01-14 12:22:06,215 [INFO] _________________________________________________________________
2020-01-14 12:22:06,215 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-14 12:22:06,215 [INFO] _________________________________________________________________
2020-01-14 12:22:06,215 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-14 12:22:06,216 [INFO] _________________________________________________________________
2020-01-14 12:22:06,216 [INFO] dense_3 (Dense)              (None, 32)                2080      
2020-01-14 12:22:06,216 [INFO] _________________________________________________________________
2020-01-14 12:22:06,216 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2020-01-14 12:22:06,216 [INFO] _________________________________________________________________
2020-01-14 12:22:06,216 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2020-01-14 12:22:06,216 [INFO] _________________________________________________________________
2020-01-14 12:22:06,216 [INFO] dense_4 (Dense)              (None, 5)                 165       
2020-01-14 12:22:06,216 [INFO] =================================================================
2020-01-14 12:22:06,217 [INFO] Total params: 27,141
2020-01-14 12:22:06,217 [INFO] Trainable params: 26,693
2020-01-14 12:22:06,217 [INFO] Non-trainable params: 448
2020-01-14 12:22:06,217 [INFO] _________________________________________________________________
2020-01-14 12:22:06.217351: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-14 12:22:06.239614: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-14 12:22:06.239835: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56361c72b890 executing computations on platform Host. Devices:
2020-01-14 12:22:06.239872: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-14 12:22:06.240018: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2020-01-14 12:22:06,451 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-14 12:22:06,869 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16405 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16461 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16462 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16463 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16464 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16406 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16465 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16467 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16466 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16468 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16469 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16470 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16471 thread 16 bound to OS proc set 0
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.11, time = 0.37s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -59.94, time = 0.66s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -66.98, time = 0.66s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -74.29, time = 0.67s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -80.58, time = 0.67s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.61, time = 0.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -89.64, time = 0.67s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -92.83, time = 0.67s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -95.37, time = 0.67s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -97.37, time = 0.68s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -88.59, time = 0.26s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -88.46, time = 0.41s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -88.37, time = 0.41s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -88.31, time = 0.41s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -88.26, time = 0.41s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -88.22, time = 0.41s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -88.20, time = 0.41s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -88.18, time = 0.41s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -88.15, time = 0.41s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -88.14, time = 0.41s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -44.13, time = 0.14s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -43.94, time = 0.21s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -43.79, time = 0.21s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -43.66, time = 0.21s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -43.57, time = 0.21s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -43.50, time = 0.22s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -43.45, time = 0.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.42, time = 0.21s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -43.39, time = 0.21s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -43.37, time = 0.21s
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 3s - loss: 0.1055 - val_loss: 0.0232
 - val_f1: 0.9806
 - out_of_sample_accuracy: 0.7221
Epoch 2/100
 - 1s - loss: 0.0232 - val_loss: 0.0121
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:22:14,586 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7408, current_metric = 0.7594, num_epochs = 2
2020-01-14 12:22:14,587 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:22:16,972 [INFO] Last epoch loss evaluation: train_loss = 0.011964, val_loss = 0.012137
2020-01-14 12:22:16,972 [INFO] Training complete. time_to_train = 25.15 sec, 0.42 min
2020-01-14 12:22:17,145 [INFO] Model saved to results_additional_exps/train_time_nsl_dbn_deep_rep1/best_model.pickle
2020-01-14 12:22:17,147 [INFO] Training history saved to: results_additional_exps/train_time_nsl_dbn_deep_rep1/training_error_history.csv
2020-01-14 12:22:17,325 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep1/training_error_history.png
2020-01-14 12:22:17,487 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep1/training_f1_history.png
2020-01-14 12:22:17,487 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:22:20,439 [INFO] Making predictions complete. time_to_predict = 2.95 sec, 0.05 min
2020-01-14 12:22:20,442 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:22:21,099 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:22:21,100 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.84      0.89      7458
      normal       0.69      0.95      0.80      9711
       probe       0.76      0.76      0.76      2421
         r2l       0.92      0.09      0.16      2421
         u2r       0.00      0.00      0.00       533

    accuracy                           0.78     22544
   macro avg       0.67      0.53      0.52     22544
weighted avg       0.79      0.78      0.74     22544

2020-01-14 12:22:21,100 [INFO] Overall accuracy (micro avg): 0.7775017743080199
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:22:21,696 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7775         0.7775                       0.7775                0.0556                   0.2225  0.7775
1     Macro avg        0.9110         0.6654                       0.5271                0.0740                   0.4729  0.5217
2  Weighted avg        0.8734         0.7942                       0.7775                0.1477                   0.2225  0.7385
2020-01-14 12:22:22,364 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:22:22,364 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.98      0.98      2331
         r2l       0.90      0.73      0.81       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.99     25195
   macro avg       0.77      0.74      0.76     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-14 12:22:22,364 [INFO] Overall accuracy (micro avg): 0.9917443937289144
2020-01-14 12:22:23,033 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9917         0.9917                       0.9917                0.0021                   0.0083  0.9917
1     Macro avg        0.9967         0.7736                       0.7404                0.0028                   0.2596  0.7552
2  Weighted avg        0.9948         0.9912                       0.9917                0.0058                   0.0083  0.9914
2020-01-14 12:22:25,875 [INFO] Dataset: Training. Classification report below
2020-01-14 12:22:25,875 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      0.99      0.99     53874
       probe       0.99      0.98      0.98      9325
         r2l       0.89      0.74      0.81       796
         u2r       0.00      0.00      0.00        42

    accuracy                           0.99    100778
   macro avg       0.77      0.74      0.76    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-14 12:22:25,875 [INFO] Overall accuracy (micro avg): 0.9916747702871659
2020-01-14 12:22:28,919 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9917         0.9917                       0.9917                0.0021                   0.0083  0.9917
1     Macro avg        0.9967         0.7724                       0.7411                0.0030                   0.2589  0.7553
2  Weighted avg        0.9947         0.9911                       0.9917                0.0066                   0.0083  0.9913
2020-01-14 12:22:28,967 [INFO] Results saved to: results_additional_exps/train_time_nsl_dbn_deep_rep1/train_time_nsl_dbn_deep_rep1_results.xlsx
2020-01-14 12:22:28,967 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 12:22:28,968 [INFO] Created directory: results_additional_exps/train_time_nsl_dbn_deep_rep2
2020-01-14 12:22:28,968 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_dbn_deep_rep2/run_log.log
2020-01-14 12:22:28,968 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 12:22:28,968 [INFO] Experiment parameters given below
2020-01-14 12:22:28,969 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_nsl_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.740772514, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_dbn_deep_rep2'}
2020-01-14 12:22:28,969 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_dbn_deep_rep2/tf_logs_run_2020_01_14-12_22_28
2020-01-14 12:22:28,969 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:22:28,969 [INFO] Reading X, y files
2020-01-14 12:22:28,969 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:22:29,196 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 12:22:29,196 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:22:29,258 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:22:29,258 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:22:29,314 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:22:29,314 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:22:29,322 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:22:29,322 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:22:29,327 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:22:29,327 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:22:29,331 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:22:29,441 [INFO] Initializing model
2020-01-14 12:22:29,442 [INFO] Training model
2020-01-14 12:22:29,442 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:22:30,445 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 4711e012fd9ba1949ba3317ff4095cc6219bff41
2020-01-14 12:22:30,445 [INFO] Pretraining Deep Belief Network
2020-01-14 12:22:44,943 [INFO] Pretraining Complete
2020-01-14 12:22:44,943 [INFO] Getting pretrained weights
2020-01-14 12:22:44,943 [INFO] Creating and initializing feed forward neural network
2020-01-14 12:22:45,232 [INFO] _________________________________________________________________
2020-01-14 12:22:45,232 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:22:45,233 [INFO] =================================================================
2020-01-14 12:22:45,233 [INFO] dense_5 (Dense)              (None, 128)               15744     
2020-01-14 12:22:45,233 [INFO] _________________________________________________________________
2020-01-14 12:22:45,233 [INFO] batch_normalization_4 (Batch (None, 128)               512       
2020-01-14 12:22:45,233 [INFO] _________________________________________________________________
2020-01-14 12:22:45,233 [INFO] dropout_4 (Dropout)          (None, 128)               0         
2020-01-14 12:22:45,233 [INFO] _________________________________________________________________
2020-01-14 12:22:45,233 [INFO] dense_6 (Dense)              (None, 64)                8256      
2020-01-14 12:22:45,233 [INFO] _________________________________________________________________
2020-01-14 12:22:45,233 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-14 12:22:45,233 [INFO] _________________________________________________________________
2020-01-14 12:22:45,234 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-14 12:22:45,234 [INFO] _________________________________________________________________
2020-01-14 12:22:45,234 [INFO] dense_7 (Dense)              (None, 32)                2080      
2020-01-14 12:22:45,234 [INFO] _________________________________________________________________
2020-01-14 12:22:45,234 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2020-01-14 12:22:45,234 [INFO] _________________________________________________________________
2020-01-14 12:22:45,234 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2020-01-14 12:22:45,234 [INFO] _________________________________________________________________
2020-01-14 12:22:45,234 [INFO] dense_8 (Dense)              (None, 5)                 165       
2020-01-14 12:22:45,234 [INFO] =================================================================
2020-01-14 12:22:45,235 [INFO] Total params: 27,141
2020-01-14 12:22:45,235 [INFO] Trainable params: 26,693
2020-01-14 12:22:45,235 [INFO] Non-trainable params: 448
2020-01-14 12:22:45,235 [INFO] _________________________________________________________________
2020-01-14 12:22:45,647 [INFO] Fine-tuning final neural network
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.7594
[BernoulliRBM] Iteration 1, pseudo-likelihood = -54.41, time = 0.44s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -55.47, time = 0.77s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -61.15, time = 0.77s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -67.40, time = 0.76s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -72.91, time = 0.77s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -77.40, time = 0.77s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -81.09, time = 0.77s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -84.13, time = 0.77s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -86.65, time = 0.77s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -88.76, time = 0.77s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -88.58, time = 0.28s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -88.44, time = 0.46s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -88.34, time = 0.45s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -88.27, time = 0.45s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -88.22, time = 0.45s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -88.18, time = 0.45s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -88.16, time = 0.46s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -88.14, time = 0.45s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -88.11, time = 0.45s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -88.10, time = 0.46s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -44.12, time = 0.13s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -43.91, time = 0.21s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -43.74, time = 0.21s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -43.61, time = 0.21s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -43.51, time = 0.21s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -43.44, time = 0.21s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -43.38, time = 0.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.34, time = 0.21s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -43.32, time = 0.21s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -43.30, time = 0.21s
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 3s - loss: 0.1063 - val_loss: 0.0211
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.7219
Epoch 2/100
 - 1s - loss: 0.0240 - val_loss: 0.0132
 - val_f1: 0.9890
 - out_of_sample_accuracy: 0.7394
Epoch 3/100
 - 1s - loss: 0.0175 - val_loss: 0.0120
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:22:56,406 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7408, current_metric = 0.7529, num_epochs = 3
2020-01-14 12:22:56,407 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:22:59,016 [INFO] Last epoch loss evaluation: train_loss = 0.011471, val_loss = 0.011984
2020-01-14 12:22:59,017 [INFO] Training complete. time_to_train = 29.57 sec, 0.49 min
2020-01-14 12:22:59,333 [INFO] Model saved to results_additional_exps/train_time_nsl_dbn_deep_rep2/best_model.pickle
2020-01-14 12:22:59,334 [INFO] Training history saved to: results_additional_exps/train_time_nsl_dbn_deep_rep2/training_error_history.csv
2020-01-14 12:22:59,517 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep2/training_error_history.png
2020-01-14 12:22:59,703 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep2/training_f1_history.png
2020-01-14 12:22:59,703 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:23:02,911 [INFO] Making predictions complete. time_to_predict = 3.21 sec, 0.05 min
2020-01-14 12:23:02,914 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:23:03,465 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:23:03,465 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.80      0.88      7458
      normal       0.68      0.93      0.78      9711
       probe       0.63      0.70      0.66      2421
         r2l       0.97      0.12      0.22      2421
         u2r       0.00      0.00      0.00       533

    accuracy                           0.76     22544
   macro avg       0.65      0.51      0.51     22544
weighted avg       0.78      0.76      0.72     22544

2020-01-14 12:23:03,466 [INFO] Overall accuracy (micro avg): 0.7550124201561391
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:23:04,064 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7550         0.7550                       0.7550                0.0612                   0.2450  0.7550
1     Macro avg        0.9020         0.6486                       0.5119                0.0799                   0.4881  0.5086
2  Weighted avg        0.8612         0.7830                       0.7550                0.1544                   0.2450  0.7225
2020-01-14 12:23:04,734 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:23:04,734 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.98      0.98      2331
         r2l       0.68      0.62      0.65       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.99     25195
   macro avg       0.73      0.72      0.72     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-14 12:23:04,734 [INFO] Overall accuracy (micro avg): 0.9900773963087914
2020-01-14 12:23:05,405 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9901         0.9901                       0.9901                0.0025                   0.0099  0.9901
1     Macro avg        0.9960         0.7301                       0.7181                0.0033                   0.2819  0.7238
2  Weighted avg        0.9941         0.9895                       0.9901                0.0064                   0.0099  0.9898
2020-01-14 12:23:08,239 [INFO] Dataset: Training. Classification report below
2020-01-14 12:23:08,240 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      0.99      0.99     53874
       probe       0.99      0.98      0.98      9325
         r2l       0.67      0.61      0.64       796
         u2r       0.00      0.00      0.00        42

    accuracy                           0.99    100778
   macro avg       0.73      0.72      0.72    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-14 12:23:08,240 [INFO] Overall accuracy (micro avg): 0.990017662585088
2020-01-14 12:23:11,274 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9900         0.9900                       0.9900                0.0025                   0.0100  0.9900
1     Macro avg        0.9960         0.7292                       0.7168                0.0034                   0.2832  0.7227
2  Weighted avg        0.9940         0.9894                       0.9900                0.0068                   0.0100  0.9897
2020-01-14 12:23:11,321 [INFO] Results saved to: results_additional_exps/train_time_nsl_dbn_deep_rep2/train_time_nsl_dbn_deep_rep2_results.xlsx
2020-01-14 12:23:11,322 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 12:23:11,323 [INFO] Created directory: results_additional_exps/train_time_nsl_dbn_deep_rep3
2020-01-14 12:23:11,323 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_dbn_deep_rep3/run_log.log
2020-01-14 12:23:11,323 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 12:23:11,323 [INFO] Experiment parameters given below
2020-01-14 12:23:11,323 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_nsl_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.740772514, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_dbn_deep_rep3'}
2020-01-14 12:23:11,323 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_dbn_deep_rep3/tf_logs_run_2020_01_14-12_23_11
2020-01-14 12:23:11,323 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:23:11,323 [INFO] Reading X, y files
2020-01-14 12:23:11,324 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:23:11,555 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 12:23:11,555 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:23:11,618 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:23:11,618 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:23:11,675 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:23:11,675 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:23:11,684 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:23:11,684 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:23:11,688 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:23:11,688 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:23:11,692 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:23:11,806 [INFO] Initializing model
2020-01-14 12:23:11,807 [INFO] Training model
2020-01-14 12:23:11,807 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:23:12,805 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 7b49407657d803eb13c3ae37639221c1efd9e5bf
2020-01-14 12:23:12,805 [INFO] Pretraining Deep Belief Network
2020-01-14 12:23:27,319 [INFO] Pretraining Complete
2020-01-14 12:23:27,319 [INFO] Getting pretrained weights
2020-01-14 12:23:27,319 [INFO] Creating and initializing feed forward neural network
2020-01-14 12:23:27,612 [INFO] _________________________________________________________________
2020-01-14 12:23:27,612 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:23:27,612 [INFO] =================================================================
2020-01-14 12:23:27,612 [INFO] dense_9 (Dense)              (None, 128)               15744     
2020-01-14 12:23:27,612 [INFO] _________________________________________________________________
2020-01-14 12:23:27,612 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2020-01-14 12:23:27,612 [INFO] _________________________________________________________________
2020-01-14 12:23:27,612 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2020-01-14 12:23:27,612 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] dense_10 (Dense)             (None, 64)                8256      
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] dense_11 (Dense)             (None, 32)                2080      
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2020-01-14 12:23:27,613 [INFO] _________________________________________________________________
2020-01-14 12:23:27,613 [INFO] dense_12 (Dense)             (None, 5)                 165       
2020-01-14 12:23:27,614 [INFO] =================================================================
2020-01-14 12:23:27,614 [INFO] Total params: 27,141
2020-01-14 12:23:27,614 [INFO] Trainable params: 26,693
2020-01-14 12:23:27,614 [INFO] Non-trainable params: 448
2020-01-14 12:23:27,614 [INFO] _________________________________________________________________
2020-01-14 12:23:28,287 [INFO] Fine-tuning final neural network
 - val_f1: 0.9902
 - out_of_sample_accuracy: 0.7529
[BernoulliRBM] Iteration 1, pseudo-likelihood = -54.52, time = 0.44s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -55.84, time = 0.77s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -61.77, time = 0.77s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -68.22, time = 0.76s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -73.84, time = 0.77s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.42, time = 0.77s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -82.15, time = 0.77s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -85.17, time = 0.77s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -87.64, time = 0.77s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -89.68, time = 0.77s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -88.59, time = 0.28s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -88.46, time = 0.46s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -88.36, time = 0.45s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -88.30, time = 0.46s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -88.25, time = 0.45s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -88.22, time = 0.45s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -88.19, time = 0.46s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -88.17, time = 0.46s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -88.15, time = 0.46s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -88.13, time = 0.46s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -44.12, time = 0.13s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -43.92, time = 0.21s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -43.76, time = 0.21s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -43.63, time = 0.21s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -43.53, time = 0.21s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -43.47, time = 0.21s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -43.42, time = 0.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.38, time = 0.21s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -43.35, time = 0.21s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -43.33, time = 0.21s
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 3s - loss: 0.1021 - val_loss: 0.0195
 - val_f1: 0.9822
 - out_of_sample_accuracy: 0.7376
Epoch 2/100
 - 2s - loss: 0.0228 - val_loss: 0.0134
 - val_f1: 0.9889
 - out_of_sample_accuracy: 0.7403
Epoch 3/100
 - 2s - loss: 0.0171 - val_loss: 0.0108
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:23:39,774 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7408, current_metric = 0.7664, num_epochs = 3
2020-01-14 12:23:39,775 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:23:42,692 [INFO] Last epoch loss evaluation: train_loss = 0.010286, val_loss = 0.010783
2020-01-14 12:23:42,692 [INFO] Training complete. time_to_train = 30.89 sec, 0.51 min
2020-01-14 12:23:43,171 [INFO] Model saved to results_additional_exps/train_time_nsl_dbn_deep_rep3/best_model.pickle
2020-01-14 12:23:43,172 [INFO] Training history saved to: results_additional_exps/train_time_nsl_dbn_deep_rep3/training_error_history.csv
2020-01-14 12:23:43,355 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep3/training_error_history.png
2020-01-14 12:23:43,529 [INFO] Plot saved to: results_additional_exps/train_time_nsl_dbn_deep_rep3/training_f1_history.png
2020-01-14 12:23:43,529 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:23:47,100 [INFO] Making predictions complete. time_to_predict = 3.57 sec, 0.06 min
2020-01-14 12:23:47,104 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:23:47,655 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:23:47,655 [INFO] 
              precision    recall  f1-score   support

         dos       0.92      0.85      0.88      7458
      normal       0.68      0.93      0.78      9711
       probe       0.81      0.77      0.79      2421
         r2l       0.93      0.05      0.10      2421
         u2r       0.00      0.00      0.00       533

    accuracy                           0.77     22544
   macro avg       0.67      0.52      0.51     22544
weighted avg       0.78      0.77      0.72     22544

2020-01-14 12:23:47,655 [INFO] Overall accuracy (micro avg): 0.767388218594748
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:23:48,252 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7674         0.7674                       0.7674                0.0582                   0.2326  0.7674
1     Macro avg        0.9070         0.6675                       0.5195                0.0778                   0.4805  0.5105
2  Weighted avg        0.8642         0.7834                       0.7674                0.1564                   0.2326  0.7245
2020-01-14 12:23:48,929 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:23:48,929 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      0.99      0.99     13469
       probe       0.97      0.99      0.98      2331
         r2l       0.95      0.53      0.68       199
         u2r       0.00      0.00      0.00        10

    accuracy                           0.99     25195
   macro avg       0.78      0.70      0.73     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-14 12:23:48,929 [INFO] Overall accuracy (micro avg): 0.9910696566779122
2020-01-14 12:23:49,622 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9911         0.9911                       0.9911                0.0022                   0.0089  0.9911
1     Macro avg        0.9964         0.7830                       0.7015                0.0031                   0.2985  0.7300
2  Weighted avg        0.9946         0.9906                       0.9911                0.0066                   0.0089  0.9903
2020-01-14 12:23:52,457 [INFO] Dataset: Training. Classification report below
2020-01-14 12:23:52,457 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      0.99      0.99     53874
       probe       0.98      0.98      0.98      9325
         r2l       0.96      0.53      0.68       796
         u2r       0.00      0.00      0.00        42

    accuracy                           0.99    100778
   macro avg       0.78      0.70      0.73    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-14 12:23:52,460 [INFO] Overall accuracy (micro avg): 0.9911984758578262
2020-01-14 12:23:55,500 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9912         0.9912                       0.9912                0.0022                   0.0088  0.9912
1     Macro avg        0.9965         0.7848                       0.7022                0.0032                   0.2978  0.7313
2  Weighted avg        0.9946         0.9907                       0.9912                0.0070                   0.0088  0.9905
2020-01-14 12:23:55,547 [INFO] Results saved to: results_additional_exps/train_time_nsl_dbn_deep_rep3/train_time_nsl_dbn_deep_rep3_results.xlsx
2020-01-14 12:23:55,547 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 12:23:55,548 [INFO] Created directory: results_additional_exps/train_time_ids17_dbn_deep_rep1
2020-01-14 12:23:55,548 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_dbn_deep_rep1/run_log.log
2020-01-14 12:23:55,548 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:23:55,548 [INFO] Experiment parameters given below
2020-01-14 12:23:55,548 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids17_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.995285982, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_dbn_deep_rep1'}
2020-01-14 12:23:55,548 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_dbn_deep_rep1/tf_logs_run_2020_01_14-12_23_55
2020-01-14 12:23:55,548 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 12:23:55,549 [INFO] Reading X, y files
2020-01-14 12:23:55,549 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 12:23:59,359 [INFO] Reading complete. time_to_read=3.81 seconds
2020-01-14 12:23:59,360 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 12:24:00,646 [INFO] Reading complete. time_to_read=1.29 seconds
2020-01-14 12:24:00,646 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 12:24:01,931 [INFO] Reading complete. time_to_read=1.29 seconds
2020-01-14 12:24:01,931 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 12:24:02,193 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-14 12:24:02,193 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 12:24:02,276 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 12:24:02,276 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 12:24:02,362 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 12:24:05,315 [INFO] Initializing model
2020-01-14 12:24:05,315 [INFO] Training model
2020-01-14 12:24:05,315 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:24:30,533 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 6ab0ecc8b5adde0179b1bfc837cbef40a00719e7
2020-01-14 12:24:30,533 [INFO] Pretraining Deep Belief Network
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16772 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16773 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 16375 tid 16774 thread 19 bound to OS proc set 3
2020-01-14 12:31:48,555 [INFO] Pretraining Complete
2020-01-14 12:31:48,555 [INFO] Getting pretrained weights
2020-01-14 12:31:48,555 [INFO] Creating and initializing feed forward neural network
2020-01-14 12:31:48,850 [INFO] _________________________________________________________________
2020-01-14 12:31:48,850 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:31:48,850 [INFO] =================================================================
2020-01-14 12:31:48,850 [INFO] dense_13 (Dense)             (None, 128)               10112     
2020-01-14 12:31:48,850 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] batch_normalization_10 (Batc (None, 128)               512       
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] dropout_10 (Dropout)         (None, 128)               0         
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] dense_14 (Dense)             (None, 64)                8256      
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,851 [INFO] dense_15 (Dense)             (None, 32)                2080      
2020-01-14 12:31:48,851 [INFO] _________________________________________________________________
2020-01-14 12:31:48,852 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2020-01-14 12:31:48,852 [INFO] _________________________________________________________________
2020-01-14 12:31:48,852 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2020-01-14 12:31:48,852 [INFO] _________________________________________________________________
2020-01-14 12:31:48,852 [INFO] dense_16 (Dense)             (None, 12)                396       
2020-01-14 12:31:48,852 [INFO] =================================================================
2020-01-14 12:31:48,852 [INFO] Total params: 21,740
2020-01-14 12:31:48,852 [INFO] Trainable params: 21,292
2020-01-14 12:31:48,852 [INFO] Non-trainable params: 448
2020-01-14 12:31:48,852 [INFO] _________________________________________________________________
2020-01-14 12:31:49,822 [INFO] Fine-tuning final neural network
 - val_f1: 0.9904
 - out_of_sample_accuracy: 0.7664
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.56, time = 12.01s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.17, time = 22.32s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.30, time = 21.86s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.51, time = 21.73s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.20, time = 21.70s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.94, time = 21.65s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.89, time = 21.59s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -64.01, time = 21.57s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -68.23, time = 21.55s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -72.51, time = 21.51s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.24, time = 9.29s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -56.86, time = 14.77s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -56.59, time = 14.76s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.32, time = 14.75s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.04, time = 14.75s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.76, time = 14.74s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.48, time = 14.74s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.19, time = 14.74s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.89, time = 14.74s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.59, time = 14.74s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -23.72, time = 4.38s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -22.04, time = 6.88s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -21.85, time = 6.87s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.82, time = 6.87s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.81, time = 6.87s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.81, time = 6.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -21.81, time = 6.87s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -21.80, time = 6.87s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -21.81, time = 6.88s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -21.80, time = 6.87s
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 20s - loss: 0.0637 - val_loss: 0.0278
 - val_f1: 0.9194
 - out_of_sample_accuracy: 0.9301
Epoch 2/100
 - 18s - loss: 0.0250 - val_loss: 0.0150
 - val_f1: 0.9598
 - out_of_sample_accuracy: 0.9619
Epoch 3/100
 - 18s - loss: 0.0163 - val_loss: 0.0119
 - val_f1: 0.9688
 - out_of_sample_accuracy: 0.9685
Epoch 4/100
 - 18s - loss: 0.0133 - val_loss: 0.0089
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9782
Epoch 5/100
 - 18s - loss: 0.0110 - val_loss: 0.0060
 - val_f1: 0.9867
 - out_of_sample_accuracy: 0.9874
Epoch 6/100
 - 18s - loss: 0.0088 - val_loss: 0.0054
 - val_f1: 0.9871
 - out_of_sample_accuracy: 0.9877
Epoch 7/100
 - 18s - loss: 0.0076 - val_loss: 0.0053
 - val_f1: 0.9855
 - out_of_sample_accuracy: 0.9860
Epoch 8/100
 - 18s - loss: 0.0068 - val_loss: 0.0056
 - val_f1: 0.9871
 - out_of_sample_accuracy: 0.9874
Epoch 9/100
 - 18s - loss: 0.0063 - val_loss: 0.0037
 - val_f1: 0.9898
 - out_of_sample_accuracy: 0.9902
Epoch 10/100
 - 18s - loss: 0.0055 - val_loss: 0.0034
 - val_f1: 0.9923
 - out_of_sample_accuracy: 0.9928
Epoch 11/100
 - 18s - loss: 0.0051 - val_loss: 0.0037
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:40:26,622 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9901
 - out_of_sample_accuracy: 0.9904
Epoch 12/100
 - 18s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9890
 - out_of_sample_accuracy: 0.9893
Epoch 13/100
 - 18s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9927
 - out_of_sample_accuracy: 0.9931
Epoch 14/100
 - 18s - loss: 0.0046 - val_loss: 0.0031
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9931
Epoch 15/100
 - 18s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9917
 - out_of_sample_accuracy: 0.9920
Epoch 16/100
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9929
 - out_of_sample_accuracy: 0.9933
Epoch 17/100
 - 18s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9940
 - out_of_sample_accuracy: 0.9942
Epoch 18/100
 - 18s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9921
 - out_of_sample_accuracy: 0.9923
Epoch 19/100
 - 18s - loss: 0.0042 - val_loss: 0.0042
 - val_f1: 0.9902
 - out_of_sample_accuracy: 0.9904
Epoch 20/100
 - 18s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9931
 - out_of_sample_accuracy: 0.9936
Epoch 21/100
 - 18s - loss: 0.0040 - val_loss: 0.0062
2020-01-14 12:48:40,509 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9876
 - out_of_sample_accuracy: 0.9877
Epoch 22/100
 - 18s - loss: 0.0041 - val_loss: 0.0071
 - val_f1: 0.9879
 - out_of_sample_accuracy: 0.9883
Epoch 23/100
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9938
 - out_of_sample_accuracy: 0.9941
Epoch 24/100
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9932
 - out_of_sample_accuracy: 0.9935
Epoch 25/100
 - 18s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9927
Epoch 26/100
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9939
 - out_of_sample_accuracy: 0.9943
Epoch 27/100
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9921
 - out_of_sample_accuracy: 0.9923
Epoch 28/100
 - 18s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9907
 - out_of_sample_accuracy: 0.9909
Epoch 29/100
 - 18s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9910
 - out_of_sample_accuracy: 0.9913
Epoch 30/100
 - 18s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9897
 - out_of_sample_accuracy: 0.9900
Epoch 31/100
 - 18s - loss: 0.0037 - val_loss: 0.0029
2020-01-14 12:56:54,461 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9930
 - out_of_sample_accuracy: 0.9931
Epoch 32/100
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9940
 - out_of_sample_accuracy: 0.9945
Epoch 33/100
 - 18s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9915
 - out_of_sample_accuracy: 0.9917
Epoch 34/100
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9937
 - out_of_sample_accuracy: 0.9939
Epoch 35/100
 - 18s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9921
 - out_of_sample_accuracy: 0.9924
Epoch 36/100
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9936
 - out_of_sample_accuracy: 0.9939
Epoch 37/100
 - 18s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9904
 - out_of_sample_accuracy: 0.9906
Epoch 38/100
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9922
 - out_of_sample_accuracy: 0.9925
Epoch 39/100
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9946
Epoch 40/100
 - 18s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9920
 - out_of_sample_accuracy: 0.9922
Epoch 41/100
 - 19s - loss: 0.0035 - val_loss: 0.0062
2020-01-14 13:05:09,471 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9851
 - out_of_sample_accuracy: 0.9852
Epoch 42/100
 - 18s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9915
 - out_of_sample_accuracy: 0.9919
Epoch 43/100
 - 18s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9918
 - out_of_sample_accuracy: 0.9919
Epoch 44/100
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9938
 - out_of_sample_accuracy: 0.9941
Epoch 45/100
 - 18s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9901
 - out_of_sample_accuracy: 0.9904
Epoch 46/100
 - 18s - loss: 0.0036 - val_loss: 0.0074
 - val_f1: 0.9864
 - out_of_sample_accuracy: 0.9869
Epoch 47/100
 - 18s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9935
 - out_of_sample_accuracy: 0.9936
Epoch 48/100
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9947
Epoch 49/100
 - 18s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9926
Epoch 50/100
 - 18s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9902
 - out_of_sample_accuracy: 0.9905
Epoch 51/100
 - 18s - loss: 0.0034 - val_loss: 0.0025
2020-01-14 13:13:23,970 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_50.pickle
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9945
Epoch 52/100
 - 18s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.9908
Epoch 53/100
 - 18s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9927
 - out_of_sample_accuracy: 0.9930
Epoch 54/100
 - 18s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9916
 - out_of_sample_accuracy: 0.9920
Epoch 55/100
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9946
Epoch 56/100
 - 18s - loss: 0.0034 - val_loss: 0.0081
 - val_f1: 0.9866
 - out_of_sample_accuracy: 0.9871
Epoch 57/100
 - 18s - loss: 0.0033 - val_loss: 0.0538
 - val_f1: 0.9535
 - out_of_sample_accuracy: 0.9581
Epoch 58/100
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9949
 - out_of_sample_accuracy: 0.9952
Epoch 59/100
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9944
Epoch 60/100
 - 18s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.9911
Epoch 61/100
 - 18s - loss: 0.0033 - val_loss: 0.0039
2020-01-14 13:21:37,982 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9905
 - out_of_sample_accuracy: 0.9907
Epoch 62/100
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9946
Epoch 63/100
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9925
 - out_of_sample_accuracy: 0.9928
Epoch 64/100
 - 18s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9928
 - out_of_sample_accuracy: 0.9931
Epoch 65/100
 - 18s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9909
 - out_of_sample_accuracy: 0.9912
Epoch 66/100
 - 18s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9922
 - out_of_sample_accuracy: 0.9924
Epoch 67/100
 - 18s - loss: 0.0035 - val_loss: 0.0094
 - val_f1: 0.9858
 - out_of_sample_accuracy: 0.9863
Epoch 68/100
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9945
Epoch 69/100
 - 18s - loss: 0.0033 - val_loss: 0.0056
 - val_f1: 0.9911
 - out_of_sample_accuracy: 0.9913
Epoch 70/100
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9940
 - out_of_sample_accuracy: 0.9944
Epoch 71/100
 - 18s - loss: 0.0033 - val_loss: 0.0033
2020-01-14 13:29:51,601 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_70.pickle
 - val_f1: 0.9932
 - out_of_sample_accuracy: 0.9935
Epoch 72/100
 - 18s - loss: 0.0033 - val_loss: 0.0062
 - val_f1: 0.9863
 - out_of_sample_accuracy: 0.9865
Epoch 73/100
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
 - out_of_sample_accuracy: 0.9948
Epoch 74/100
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9946
Epoch 75/100
 - 18s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9927
Epoch 76/100
 - 18s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9922
 - out_of_sample_accuracy: 0.9924
Epoch 77/100
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
 - out_of_sample_accuracy: 0.9947
Epoch 78/100
 - 18s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9916
 - out_of_sample_accuracy: 0.9917
Epoch 79/100
 - 18s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9918
 - out_of_sample_accuracy: 0.9920
Epoch 80/100
 - 18s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9926
 - out_of_sample_accuracy: 0.9928
Epoch 81/100
 - 18s - loss: 0.0034 - val_loss: 0.0026
2020-01-14 13:38:05,457 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9939
 - out_of_sample_accuracy: 0.9943
Epoch 82/100
 - 18s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9933
 - out_of_sample_accuracy: 0.9936
Epoch 83/100
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9946
Epoch 84/100
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9925
 - out_of_sample_accuracy: 0.9927
Epoch 85/100
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
 - out_of_sample_accuracy: 0.9950
Epoch 86/100
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9947
Epoch 87/100
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
 - out_of_sample_accuracy: 0.9952
Epoch 88/100
 - 18s - loss: 0.0033 - val_loss: 0.0024
2020-01-14 13:44:22,357 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9953, current_metric = 0.9954, num_epochs = 88
2020-01-14 13:44:22,358 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 13:45:04,567 [INFO] Last epoch loss evaluation: train_loss = 0.002289, val_loss = 0.002338
2020-01-14 13:45:04,571 [INFO] Training complete. time_to_train = 4859.26 sec, 80.99 min
2020-01-14 13:45:04,581 [INFO] Model saved to results_additional_exps/train_time_ids17_dbn_deep_rep1/best_model.pickle
2020-01-14 13:45:04,583 [INFO] Training history saved to: results_additional_exps/train_time_ids17_dbn_deep_rep1/training_error_history.csv
2020-01-14 13:45:04,758 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep1/training_error_history.png
2020-01-14 13:45:04,926 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep1/training_f1_history.png
2020-01-14 13:45:04,926 [INFO] Making predictions on training, validation, testing data
2020-01-14 13:46:19,449 [INFO] Making predictions complete. time_to_predict = 74.52 sec, 1.24 min
2020-01-14 13:46:19,514 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 13:46:39,356 [INFO] Dataset: Testing. Classification report below
2020-01-14 13:46:39,356 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2058
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.97      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.92      0.08      0.15       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-14 13:46:39,356 [INFO] Overall accuracy (micro avg): 0.9951959290051312
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 13:47:00,700 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.8876                       0.7788                0.0011                   0.2212  0.7920
2  Weighted avg        0.9960         0.9950                       0.9952                0.0083                   0.0048  0.9948
2020-01-14 13:47:20,688 [INFO] Dataset: Validation. Classification report below
2020-01-14 13:47:20,688 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.33      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.98      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1180
Web Attack Brute Force       0.68      0.04      0.08       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           1.00    565562
             macro avg       0.87      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-14 13:47:20,688 [INFO] Overall accuracy (micro avg): 0.995326772307899
2020-01-14 13:47:42,216 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0004                   0.0047  0.9953
1     Macro avg        0.9992         0.8688                       0.7712                0.0011                   0.2288  0.7825
2  Weighted avg        0.9961         0.9950                       0.9953                0.0081                   0.0047  0.9949
2020-01-14 13:48:49,117 [INFO] Dataset: Training. Classification report below
2020-01-14 13:48:49,117 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.99      0.94      3300
         DoS slowloris       0.98      0.98      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.82      0.07      0.12       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           1.00   1696684
             macro avg       0.88      0.78      0.79   1696684
          weighted avg       1.00      1.00      0.99   1696684

2020-01-14 13:48:49,117 [INFO] Overall accuracy (micro avg): 0.9953898309879742
2020-01-14 13:50:01,265 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8821                       0.7774                0.0011                   0.2226  0.7908
2  Weighted avg        0.9962         0.9951                       0.9954                0.0081                   0.0046  0.9950
2020-01-14 13:50:01,330 [INFO] Results saved to: results_additional_exps/train_time_ids17_dbn_deep_rep1/train_time_ids17_dbn_deep_rep1_results.xlsx
2020-01-14 13:50:01,334 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 13:50:01,380 [INFO] Created directory: results_additional_exps/train_time_ids17_dbn_deep_rep2
2020-01-14 13:50:01,380 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_dbn_deep_rep2/run_log.log
2020-01-14 13:50:01,380 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 13:50:01,380 [INFO] Experiment parameters given below
2020-01-14 13:50:01,380 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids17_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.995285982, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_dbn_deep_rep2'}
2020-01-14 13:50:01,381 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_dbn_deep_rep2/tf_logs_run_2020_01_14-13_50_01
2020-01-14 13:50:01,381 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 13:50:01,381 [INFO] Reading X, y files
2020-01-14 13:50:01,381 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 13:50:05,154 [INFO] Reading complete. time_to_read=3.77 seconds
2020-01-14 13:50:05,155 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 13:50:06,438 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-14 13:50:06,438 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 13:50:07,725 [INFO] Reading complete. time_to_read=1.29 seconds
2020-01-14 13:50:07,726 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 13:50:07,979 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-14 13:50:07,979 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 13:50:08,062 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 13:50:08,062 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 13:50:08,146 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 13:50:11,100 [INFO] Initializing model
2020-01-14 13:50:11,100 [INFO] Training model
2020-01-14 13:50:11,100 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 13:50:35,506 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 11474d9890a80878732f229ec97edb5b649f6798
2020-01-14 13:50:35,506 [INFO] Pretraining Deep Belief Network
2020-01-14 13:57:55,594 [INFO] Pretraining Complete
2020-01-14 13:57:55,594 [INFO] Getting pretrained weights
2020-01-14 13:57:55,595 [INFO] Creating and initializing feed forward neural network
2020-01-14 13:57:55,894 [INFO] _________________________________________________________________
2020-01-14 13:57:55,894 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 13:57:55,894 [INFO] =================================================================
2020-01-14 13:57:55,894 [INFO] dense_17 (Dense)             (None, 128)               10112     
2020-01-14 13:57:55,894 [INFO] _________________________________________________________________
2020-01-14 13:57:55,894 [INFO] batch_normalization_13 (Batc (None, 128)               512       
2020-01-14 13:57:55,894 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] dropout_13 (Dropout)         (None, 128)               0         
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] dense_18 (Dense)             (None, 64)                8256      
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] dense_19 (Dense)             (None, 33)                2145      
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,895 [INFO] batch_normalization_15 (Batc (None, 33)                132       
2020-01-14 13:57:55,895 [INFO] _________________________________________________________________
2020-01-14 13:57:55,896 [INFO] dropout_15 (Dropout)         (None, 33)                0         
2020-01-14 13:57:55,896 [INFO] _________________________________________________________________
2020-01-14 13:57:55,896 [INFO] dense_20 (Dense)             (None, 12)                408       
2020-01-14 13:57:55,896 [INFO] =================================================================
2020-01-14 13:57:55,896 [INFO] Total params: 21,821
2020-01-14 13:57:55,896 [INFO] Trainable params: 21,371
2020-01-14 13:57:55,896 [INFO] Non-trainable params: 450
2020-01-14 13:57:55,896 [INFO] _________________________________________________________________
2020-01-14 13:57:57,169 [INFO] Fine-tuning final neural network
 - val_f1: 0.9951
 - out_of_sample_accuracy: 0.9954
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.41, time = 12.04s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -38.98, time = 22.37s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.14, time = 21.90s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.40, time = 21.77s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.09, time = 21.73s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.76, time = 21.68s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.60, time = 21.63s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -63.58, time = 21.60s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -67.65, time = 21.59s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -71.76, time = 21.56s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.32, time = 9.28s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -56.94, time = 14.76s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -56.67, time = 14.74s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.40, time = 14.73s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.12, time = 14.74s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.84, time = 14.74s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.56, time = 14.72s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.26, time = 14.73s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.96, time = 14.73s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.66, time = 14.75s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -23.64, time = 4.45s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -22.02, time = 7.06s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -21.86, time = 7.05s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.83, time = 7.05s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.83, time = 7.06s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.83, time = 7.05s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -21.83, time = 7.06s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -21.82, time = 7.05s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -21.82, time = 7.05s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -21.82, time = 7.05s
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 20s - loss: 0.0610 - val_loss: 0.0270
 - val_f1: 0.9026
 - out_of_sample_accuracy: 0.9158
Epoch 2/100
 - 19s - loss: 0.0275 - val_loss: 0.0307
 - val_f1: 0.8904
 - out_of_sample_accuracy: 0.8901
Epoch 3/100
 - 19s - loss: 0.0172 - val_loss: 0.0113
 - val_f1: 0.9702
 - out_of_sample_accuracy: 0.9705
Epoch 4/100
 - 19s - loss: 0.0130 - val_loss: 0.0075
 - val_f1: 0.9857
 - out_of_sample_accuracy: 0.9859
Epoch 5/100
 - 19s - loss: 0.0097 - val_loss: 0.0491
 - val_f1: 0.8492
 - out_of_sample_accuracy: 0.8828
Epoch 6/100
 - 19s - loss: 0.0083 - val_loss: 0.0054
 - val_f1: 0.9874
 - out_of_sample_accuracy: 0.9877
Epoch 7/100
 - 19s - loss: 0.0074 - val_loss: 0.0054
 - val_f1: 0.9888
 - out_of_sample_accuracy: 0.9895
Epoch 8/100
 - 19s - loss: 0.0068 - val_loss: 0.0046
 - val_f1: 0.9898
 - out_of_sample_accuracy: 0.9906
Epoch 9/100
 - 19s - loss: 0.0063 - val_loss: 0.0040
 - val_f1: 0.9897
 - out_of_sample_accuracy: 0.9903
Epoch 10/100
 - 19s - loss: 0.0060 - val_loss: 0.0039
 - val_f1: 0.9917
 - out_of_sample_accuracy: 0.9924
Epoch 11/100
 - 19s - loss: 0.0055 - val_loss: 0.0034
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 14:07:10,679 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/ann_model_epoch_10.pickle
 - val_f1: 0.9912
 - out_of_sample_accuracy: 0.9917
Epoch 12/100
 - 19s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9930
Epoch 13/100
 - 19s - loss: 0.0051 - val_loss: 0.0032
 - val_f1: 0.9912
 - out_of_sample_accuracy: 0.9915
Epoch 14/100
 - 19s - loss: 0.0051 - val_loss: 0.0035
 - val_f1: 0.9921
 - out_of_sample_accuracy: 0.9928
Epoch 15/100
 - 19s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9936
 - out_of_sample_accuracy: 0.9939
Epoch 16/100
 - 19s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9911
 - out_of_sample_accuracy: 0.9915
Epoch 17/100
 - 19s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9928
 - out_of_sample_accuracy: 0.9929
Epoch 18/100
 - 19s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9927
 - out_of_sample_accuracy: 0.9932
Epoch 19/100
 - 19s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9940
 - out_of_sample_accuracy: 0.9941
Epoch 20/100
 - 19s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9928
 - out_of_sample_accuracy: 0.9934
Epoch 21/100
 - 19s - loss: 0.0045 - val_loss: 0.0032
2020-01-14 14:15:59,008 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9931
 - out_of_sample_accuracy: 0.9934
Epoch 22/100
 - 19s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9935
 - out_of_sample_accuracy: 0.9938
Epoch 23/100
 - 19s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9936
 - out_of_sample_accuracy: 0.9939
Epoch 24/100
 - 19s - loss: 0.0044 - val_loss: 0.0051
 - val_f1: 0.9884
 - out_of_sample_accuracy: 0.9886
Epoch 25/100
 - 19s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9926
 - out_of_sample_accuracy: 0.9930
Epoch 26/100
 - 19s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9901
 - out_of_sample_accuracy: 0.9903
Epoch 27/100
 - 19s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9857
 - out_of_sample_accuracy: 0.9859
Epoch 28/100
 - 19s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9944
Epoch 29/100
 - 19s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9920
 - out_of_sample_accuracy: 0.9922
Epoch 30/100
 - 19s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9917
 - out_of_sample_accuracy: 0.9919
Epoch 31/100
 - 19s - loss: 0.0039 - val_loss: 0.0098
2020-01-14 14:24:48,110 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9811
 - out_of_sample_accuracy: 0.9815
Epoch 32/100
 - 19s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9943
Epoch 33/100
 - 19s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9947
 - out_of_sample_accuracy: 0.9951
Epoch 34/100
 - 19s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9948
 - out_of_sample_accuracy: 0.9951
Epoch 35/100
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9947
Epoch 36/100
 - 19s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9945
Epoch 37/100
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9938
 - out_of_sample_accuracy: 0.9941
Epoch 38/100
 - 19s - loss: 0.0039 - val_loss: 0.0089
 - val_f1: 0.9851
 - out_of_sample_accuracy: 0.9857
Epoch 39/100
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9944
Epoch 40/100
 - 19s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.9911
Epoch 41/100
 - 19s - loss: 0.0038 - val_loss: 0.0042
2020-01-14 14:33:37,067 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9884
 - out_of_sample_accuracy: 0.9887
Epoch 42/100
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9947
 - out_of_sample_accuracy: 0.9949
Epoch 43/100
 - 19s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9945
 - out_of_sample_accuracy: 0.9948
Epoch 44/100
 - 19s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9923
 - out_of_sample_accuracy: 0.9925
Epoch 45/100
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
 - out_of_sample_accuracy: 0.9949
Epoch 46/100
 - 19s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9924
 - out_of_sample_accuracy: 0.9927
Epoch 47/100
 - 19s - loss: 0.0038 - val_loss: 0.0068
 - val_f1: 0.9876
 - out_of_sample_accuracy: 0.9883
Epoch 48/100
 - 19s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9946
Epoch 49/100
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
 - out_of_sample_accuracy: 0.9949
Epoch 50/100
 - 19s - loss: 0.0036 - val_loss: 0.0061
 - val_f1: 0.9896
 - out_of_sample_accuracy: 0.9898
Epoch 51/100
 - 19s - loss: 0.0036 - val_loss: 0.0063
2020-01-14 14:42:25,075 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/ann_model_epoch_50.pickle
 - val_f1: 0.9851
 - out_of_sample_accuracy: 0.9853
Epoch 52/100
 - 19s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9949
 - out_of_sample_accuracy: 0.9951
Epoch 53/100
 - 19s - loss: 0.0036 - val_loss: 0.0077
 - val_f1: 0.9881
 - out_of_sample_accuracy: 0.9885
Epoch 54/100
 - 19s - loss: 0.0035 - val_loss: 0.0025
2020-01-14 14:45:37,525 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9953, current_metric = 0.9954, num_epochs = 54
2020-01-14 14:45:37,527 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 14:46:23,119 [INFO] Last epoch loss evaluation: train_loss = 0.002389, val_loss = 0.002459
2020-01-14 14:46:23,123 [INFO] Training complete. time_to_train = 3372.02 sec, 56.20 min
2020-01-14 14:46:23,131 [INFO] Model saved to results_additional_exps/train_time_ids17_dbn_deep_rep2/best_model.pickle
2020-01-14 14:46:23,133 [INFO] Training history saved to: results_additional_exps/train_time_ids17_dbn_deep_rep2/training_error_history.csv
2020-01-14 14:46:23,312 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep2/training_error_history.png
2020-01-14 14:46:23,623 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep2/training_f1_history.png
2020-01-14 14:46:23,623 [INFO] Making predictions on training, validation, testing data
2020-01-14 14:47:46,191 [INFO] Making predictions complete. time_to_predict = 82.57 sec, 1.38 min
2020-01-14 14:47:46,256 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 14:48:06,098 [INFO] Dataset: Testing. Classification report below
2020-01-14 14:48:06,098 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.97      0.98      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-14 14:48:06,098 [INFO] Overall accuracy (micro avg): 0.9954558474579268
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 14:48:27,424 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9992         0.8110                       0.7702                0.0011                   0.2298  0.7785
2  Weighted avg        0.9963         0.9947                       0.9955                0.0091                   0.0045  0.9950
2020-01-14 14:48:47,445 [INFO] Dataset: Validation. Classification report below
2020-01-14 14:48:47,445 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.31      0.47       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.97      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.97      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           1.00    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      1.00      1.00    565562

2020-01-14 14:48:47,445 [INFO] Overall accuracy (micro avg): 0.9956185175100166
2020-01-14 14:49:08,992 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8105                       0.7647                0.0011                   0.2353  0.7731
2  Weighted avg        0.9965         0.9949                       0.9956                0.0087                   0.0044  0.9951
2020-01-14 14:50:15,926 [INFO] Dataset: Training. Classification report below
2020-01-14 14:50:15,926 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.35      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.96      0.98      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.97      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           1.00   1696684
             macro avg       0.81      0.77      0.78   1696684
          weighted avg       0.99      1.00      1.00   1696684

2020-01-14 14:50:15,926 [INFO] Overall accuracy (micro avg): 0.9956874703834067
2020-01-14 14:51:28,031 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8133                       0.7699                0.0011                   0.2301  0.7792
2  Weighted avg        0.9965         0.9949                       0.9957                0.0088                   0.0043  0.9952
2020-01-14 14:51:28,096 [INFO] Results saved to: results_additional_exps/train_time_ids17_dbn_deep_rep2/train_time_ids17_dbn_deep_rep2_results.xlsx
2020-01-14 14:51:28,100 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 14:51:28,144 [INFO] Created directory: results_additional_exps/train_time_ids17_dbn_deep_rep3
2020-01-14 14:51:28,145 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_dbn_deep_rep3/run_log.log
2020-01-14 14:51:28,145 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 14:51:28,145 [INFO] Experiment parameters given below
2020-01-14 14:51:28,145 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids17_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.995285982, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_dbn_deep_rep3'}
2020-01-14 14:51:28,145 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_dbn_deep_rep3/tf_logs_run_2020_01_14-14_51_28
2020-01-14 14:51:28,145 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 14:51:28,146 [INFO] Reading X, y files
2020-01-14 14:51:28,146 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 14:51:31,966 [INFO] Reading complete. time_to_read=3.82 seconds
2020-01-14 14:51:31,966 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 14:51:33,252 [INFO] Reading complete. time_to_read=1.29 seconds
2020-01-14 14:51:33,255 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 14:51:34,541 [INFO] Reading complete. time_to_read=1.29 seconds
2020-01-14 14:51:34,541 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 14:51:34,813 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-14 14:51:34,813 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 14:51:34,897 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 14:51:34,897 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 14:51:34,982 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 14:51:37,930 [INFO] Initializing model
2020-01-14 14:51:37,930 [INFO] Training model
2020-01-14 14:51:37,930 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 14:52:03,050 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 78227e978bd0c1a37aad8069b2f7e8db1cd3271e
2020-01-14 14:52:03,050 [INFO] Pretraining Deep Belief Network
2020-01-14 14:59:24,203 [INFO] Pretraining Complete
2020-01-14 14:59:24,203 [INFO] Getting pretrained weights
2020-01-14 14:59:24,203 [INFO] Creating and initializing feed forward neural network
2020-01-14 14:59:24,507 [INFO] _________________________________________________________________
2020-01-14 14:59:24,507 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 14:59:24,507 [INFO] =================================================================
2020-01-14 14:59:24,507 [INFO] dense_21 (Dense)             (None, 128)               10112     
2020-01-14 14:59:24,507 [INFO] _________________________________________________________________
2020-01-14 14:59:24,507 [INFO] batch_normalization_16 (Batc (None, 128)               512       
2020-01-14 14:59:24,507 [INFO] _________________________________________________________________
2020-01-14 14:59:24,507 [INFO] dropout_16 (Dropout)         (None, 128)               0         
2020-01-14 14:59:24,507 [INFO] _________________________________________________________________
2020-01-14 14:59:24,507 [INFO] dense_22 (Dense)             (None, 64)                8256      
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] batch_normalization_17 (Batc (None, 64)                256       
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] dropout_17 (Dropout)         (None, 64)                0         
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] dense_23 (Dense)             (None, 34)                2210      
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] batch_normalization_18 (Batc (None, 34)                136       
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] dropout_18 (Dropout)         (None, 34)                0         
2020-01-14 14:59:24,508 [INFO] _________________________________________________________________
2020-01-14 14:59:24,508 [INFO] dense_24 (Dense)             (None, 12)                420       
2020-01-14 14:59:24,509 [INFO] =================================================================
2020-01-14 14:59:24,509 [INFO] Total params: 21,902
2020-01-14 14:59:24,509 [INFO] Trainable params: 21,450
2020-01-14 14:59:24,509 [INFO] Non-trainable params: 452
2020-01-14 14:59:24,509 [INFO] _________________________________________________________________
2020-01-14 14:59:26,134 [INFO] Fine-tuning final neural network
 - val_f1: 0.9952
 - out_of_sample_accuracy: 0.9954
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.67, time = 12.04s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.22, time = 22.34s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.32, time = 21.89s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.50, time = 21.76s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.13, time = 21.73s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.78, time = 21.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.62, time = 21.62s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -63.63, time = 21.58s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -67.73, time = 21.58s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -71.89, time = 21.54s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.33, time = 9.30s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -56.95, time = 14.76s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -56.68, time = 14.77s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.41, time = 14.76s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.13, time = 14.75s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.85, time = 14.75s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.57, time = 14.76s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.27, time = 14.75s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.97, time = 14.76s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.67, time = 14.76s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -23.53, time = 4.51s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -21.98, time = 7.15s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -21.83, time = 7.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.80, time = 7.15s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.80, time = 7.15s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.80, time = 7.15s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -21.79, time = 7.15s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -21.79, time = 7.14s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -21.79, time = 7.16s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -21.79, time = 7.17s
Train on 848342 samples, validate on 565562 samples
Epoch 1/100
 - 21s - loss: 0.0705 - val_loss: 0.0259
 - val_f1: 0.9397
 - out_of_sample_accuracy: 0.9441
Epoch 2/100
 - 19s - loss: 0.0250 - val_loss: 0.0282
 - val_f1: 0.9188
 - out_of_sample_accuracy: 0.9277
Epoch 3/100
 - 19s - loss: 0.0178 - val_loss: 0.0125
 - val_f1: 0.9698
 - out_of_sample_accuracy: 0.9694
Epoch 4/100
 - 19s - loss: 0.0134 - val_loss: 0.0070
 - val_f1: 0.9830
 - out_of_sample_accuracy: 0.9839
Epoch 5/100
 - 19s - loss: 0.0107 - val_loss: 0.0080
 - val_f1: 0.9804
 - out_of_sample_accuracy: 0.9812
Epoch 6/100
 - 19s - loss: 0.0095 - val_loss: 0.0061
 - val_f1: 0.9864
 - out_of_sample_accuracy: 0.9866
Epoch 7/100
 - 19s - loss: 0.0082 - val_loss: 0.0049
 - val_f1: 0.9883
 - out_of_sample_accuracy: 0.9887
Epoch 8/100
 - 19s - loss: 0.0074 - val_loss: 0.0048
 - val_f1: 0.9918
 - out_of_sample_accuracy: 0.9921
Epoch 9/100
 - 19s - loss: 0.0067 - val_loss: 0.0039
 - val_f1: 0.9928
 - out_of_sample_accuracy: 0.9933
Epoch 10/100
 - 19s - loss: 0.0062 - val_loss: 0.0082
 - val_f1: 0.9851
 - out_of_sample_accuracy: 0.9858
Epoch 11/100
 - 19s - loss: 0.0059 - val_loss: 0.0035
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 15:09:14,685 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9929
 - out_of_sample_accuracy: 0.9934
Epoch 12/100
 - 19s - loss: 0.0058 - val_loss: 0.0098
 - val_f1: 0.9810
 - out_of_sample_accuracy: 0.9812
Epoch 13/100
 - 19s - loss: 0.0055 - val_loss: 0.0093
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9743
Epoch 14/100
 - 19s - loss: 0.0055 - val_loss: 0.0035
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.9909
Epoch 15/100
 - 19s - loss: 0.0052 - val_loss: 0.0034
 - val_f1: 0.9927
 - out_of_sample_accuracy: 0.9930
Epoch 16/100
 - 19s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9895
 - out_of_sample_accuracy: 0.9898
Epoch 17/100
 - 19s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9945
Epoch 18/100
 - 19s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9895
 - out_of_sample_accuracy: 0.9900
Epoch 19/100
 - 19s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9937
 - out_of_sample_accuracy: 0.9937
Epoch 20/100
 - 19s - loss: 0.0048 - val_loss: 0.0038
 - val_f1: 0.9899
 - out_of_sample_accuracy: 0.9901
Epoch 21/100
 - 19s - loss: 0.0046 - val_loss: 0.0032
2020-01-14 15:18:38,753 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9914
 - out_of_sample_accuracy: 0.9917
Epoch 22/100
 - 19s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9939
 - out_of_sample_accuracy: 0.9941
Epoch 23/100
 - 19s - loss: 0.0045 - val_loss: 0.0297
 - val_f1: 0.9574
 - out_of_sample_accuracy: 0.9618
Epoch 24/100
 - 19s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9938
 - out_of_sample_accuracy: 0.9941
Epoch 25/100
 - 19s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9922
 - out_of_sample_accuracy: 0.9927
Epoch 26/100
 - 19s - loss: 0.0044 - val_loss: 0.0103
 - val_f1: 0.9864
 - out_of_sample_accuracy: 0.9869
Epoch 27/100
 - 19s - loss: 0.0043 - val_loss: 0.0043
 - val_f1: 0.9897
 - out_of_sample_accuracy: 0.9901
Epoch 28/100
 - 19s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9946
 - out_of_sample_accuracy: 0.9950
Epoch 29/100
 - 19s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9939
 - out_of_sample_accuracy: 0.9942
Epoch 30/100
 - 19s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9921
 - out_of_sample_accuracy: 0.9924
Epoch 31/100
 - 19s - loss: 0.0042 - val_loss: 0.0027
2020-01-14 15:28:02,498 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9943
Epoch 32/100
 - 19s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9947
Epoch 33/100
 - 19s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9894
 - out_of_sample_accuracy: 0.9896
Epoch 34/100
 - 19s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9944
Epoch 35/100
 - 19s - loss: 0.0041 - val_loss: 0.0118
 - val_f1: 0.9658
 - out_of_sample_accuracy: 0.9696
Epoch 36/100
 - 19s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9946
Epoch 37/100
 - 19s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9922
 - out_of_sample_accuracy: 0.9925
Epoch 38/100
 - 19s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9944
 - out_of_sample_accuracy: 0.9947
Epoch 39/100
 - 19s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9945
 - out_of_sample_accuracy: 0.9947
Epoch 40/100
 - 19s - loss: 0.0040 - val_loss: 0.0068
 - val_f1: 0.9873
 - out_of_sample_accuracy: 0.9877
Epoch 41/100
 - 19s - loss: 0.0040 - val_loss: 0.0027
2020-01-14 15:37:26,192 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9934
 - out_of_sample_accuracy: 0.9939
Epoch 42/100
 - 19s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9912
 - out_of_sample_accuracy: 0.9914
Epoch 43/100
 - 19s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9897
 - out_of_sample_accuracy: 0.9900
Epoch 44/100
 - 19s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9946
 - out_of_sample_accuracy: 0.9948
Epoch 45/100
 - 19s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9946
 - out_of_sample_accuracy: 0.9949
Epoch 46/100
 - 19s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9918
 - out_of_sample_accuracy: 0.9919
Epoch 47/100
 - 19s - loss: 0.0040 - val_loss: 0.0045
 - val_f1: 0.9890
 - out_of_sample_accuracy: 0.9892
Epoch 48/100
 - 19s - loss: 0.0039 - val_loss: 0.0160
 - val_f1: 0.9640
 - out_of_sample_accuracy: 0.9682
Epoch 49/100
 - 19s - loss: 0.0041 - val_loss: 0.0081
 - val_f1: 0.9849
 - out_of_sample_accuracy: 0.9851
Epoch 50/100
 - 19s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9923
 - out_of_sample_accuracy: 0.9926
Epoch 51/100
 - 19s - loss: 0.0039 - val_loss: 0.0048
2020-01-14 15:46:44,648 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_50.pickle
 - val_f1: 0.9891
 - out_of_sample_accuracy: 0.9893
Epoch 52/100
 - 19s - loss: 0.0038 - val_loss: 0.0042
 - val_f1: 0.9916
 - out_of_sample_accuracy: 0.9918
Epoch 53/100
 - 19s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9906
 - out_of_sample_accuracy: 0.9910
Epoch 54/100
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9925
 - out_of_sample_accuracy: 0.9928
Epoch 55/100
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9940
 - out_of_sample_accuracy: 0.9945
Epoch 56/100
 - 19s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9946
Epoch 57/100
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
 - out_of_sample_accuracy: 0.9945
Epoch 58/100
 - 19s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9932
 - out_of_sample_accuracy: 0.9936
Epoch 59/100
 - 19s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9945
 - out_of_sample_accuracy: 0.9948
Epoch 60/100
 - 19s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9913
 - out_of_sample_accuracy: 0.9916
Epoch 61/100
 - 19s - loss: 0.0037 - val_loss: 0.0025
2020-01-14 15:56:03,762 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9948
 - out_of_sample_accuracy: 0.9952
Epoch 62/100
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9943
 - out_of_sample_accuracy: 0.9947
Epoch 63/100
 - 19s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9919
 - out_of_sample_accuracy: 0.9922
Epoch 64/100
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9941
 - out_of_sample_accuracy: 0.9946
Epoch 65/100
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9939
 - out_of_sample_accuracy: 0.9942
Epoch 66/100
 - 19s - loss: 0.0036 - val_loss: 0.0025
2020-01-14 16:01:19,776 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9953, current_metric = 0.9954, num_epochs = 66
2020-01-14 16:01:19,777 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:02:08,432 [INFO] Last epoch loss evaluation: train_loss = 0.002453, val_loss = 0.002468
2020-01-14 16:02:08,436 [INFO] Training complete. time_to_train = 4230.51 sec, 70.51 min
2020-01-14 16:02:08,445 [INFO] Model saved to results_additional_exps/train_time_ids17_dbn_deep_rep3/best_model.pickle
2020-01-14 16:02:08,447 [INFO] Training history saved to: results_additional_exps/train_time_ids17_dbn_deep_rep3/training_error_history.csv
2020-01-14 16:02:08,636 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep3/training_error_history.png
2020-01-14 16:02:08,813 [INFO] Plot saved to: results_additional_exps/train_time_ids17_dbn_deep_rep3/training_f1_history.png
2020-01-14 16:02:08,813 [INFO] Making predictions on training, validation, testing data
2020-01-14 16:03:37,803 [INFO] Making predictions complete. time_to_predict = 88.99 sec, 1.48 min
2020-01-14 16:03:37,866 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 16:03:57,695 [INFO] Dataset: Testing. Classification report below
2020-01-14 16:03:57,695 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.93      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-14 16:03:57,695 [INFO] Overall accuracy (micro avg): 0.9954116436394241
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 16:04:19,016 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8106                       0.7727                0.0011                   0.2273  0.7799
2  Weighted avg        0.9962         0.9947                       0.9954                0.0091                   0.0046  0.9949
2020-01-14 16:04:39,025 [INFO] Dataset: Validation. Classification report below
2020-01-14 16:04:39,025 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.97      0.97      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           1.00    565562
             macro avg       0.81      0.77      0.77    565562
          weighted avg       0.99      1.00      1.00    565562

2020-01-14 16:04:39,025 [INFO] Overall accuracy (micro avg): 0.9955849226079546
2020-01-14 16:05:00,576 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8102                       0.7675                0.0011                   0.2325  0.7750
2  Weighted avg        0.9964         0.9949                       0.9956                0.0088                   0.0044  0.9951
2020-01-14 16:06:07,295 [INFO] Dataset: Training. Classification report below
2020-01-14 16:06:07,295 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.98      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.98      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.95      0.98      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           1.00   1696684
             macro avg       0.81      0.77      0.78   1696684
          weighted avg       0.99      1.00      1.00   1696684

2020-01-14 16:06:07,295 [INFO] Overall accuracy (micro avg): 0.9956385514332663
2020-01-14 16:07:19,251 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8134                       0.7718                0.0011                   0.2282  0.7803
2  Weighted avg        0.9964         0.9949                       0.9956                0.0090                   0.0044  0.9952
2020-01-14 16:07:19,317 [INFO] Results saved to: results_additional_exps/train_time_ids17_dbn_deep_rep3/train_time_ids17_dbn_deep_rep3_results.xlsx
2020-01-14 16:07:19,322 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 16:07:19,366 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1
2020-01-14 16:07:19,366 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/run_log.log
2020-01-14 16:07:19,367 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 16:07:19,367 [INFO] Experiment parameters given below
2020-01-14 16:07:19,367 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids18_subset_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982550715, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_dbn_deep_rep1'}
2020-01-14 16:07:19,367 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/tf_logs_run_2020_01_14-16_07_19
2020-01-14 16:07:19,367 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 16:07:19,367 [INFO] Reading X, y files
2020-01-14 16:07:19,367 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 16:07:23,429 [INFO] Reading complete. time_to_read=4.06 seconds
2020-01-14 16:07:23,429 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 16:07:24,819 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 16:07:24,819 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 16:07:26,211 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 16:07:26,212 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 16:07:26,521 [INFO] Reading complete. time_to_read=0.31 seconds
2020-01-14 16:07:26,521 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 16:07:26,618 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 16:07:26,618 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 16:07:26,714 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 16:07:30,087 [INFO] Initializing model
2020-01-14 16:07:30,088 [INFO] Training model
2020-01-14 16:07:30,089 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 16:08:00,128 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 4560b0ebc840dd5e57d664d416205a1922818a22
2020-01-14 16:08:00,128 [INFO] Pretraining Deep Belief Network
2020-01-14 16:16:20,688 [INFO] Pretraining Complete
2020-01-14 16:16:20,689 [INFO] Getting pretrained weights
2020-01-14 16:16:20,689 [INFO] Creating and initializing feed forward neural network
2020-01-14 16:16:20,994 [INFO] _________________________________________________________________
2020-01-14 16:16:20,994 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:16:20,994 [INFO] =================================================================
2020-01-14 16:16:20,995 [INFO] dense_25 (Dense)             (None, 128)               9984      
2020-01-14 16:16:20,995 [INFO] _________________________________________________________________
2020-01-14 16:16:20,995 [INFO] batch_normalization_19 (Batc (None, 128)               512       
2020-01-14 16:16:20,995 [INFO] _________________________________________________________________
2020-01-14 16:16:20,995 [INFO] dropout_19 (Dropout)         (None, 128)               0         
2020-01-14 16:16:20,995 [INFO] _________________________________________________________________
2020-01-14 16:16:20,995 [INFO] dense_26 (Dense)             (None, 64)                8256      
2020-01-14 16:16:20,995 [INFO] _________________________________________________________________
2020-01-14 16:16:20,995 [INFO] batch_normalization_20 (Batc (None, 64)                256       
2020-01-14 16:16:20,995 [INFO] _________________________________________________________________
2020-01-14 16:16:20,995 [INFO] dropout_20 (Dropout)         (None, 64)                0         
2020-01-14 16:16:20,996 [INFO] _________________________________________________________________
2020-01-14 16:16:20,996 [INFO] dense_27 (Dense)             (None, 32)                2080      
2020-01-14 16:16:20,996 [INFO] _________________________________________________________________
2020-01-14 16:16:20,996 [INFO] batch_normalization_21 (Batc (None, 32)                128       
2020-01-14 16:16:20,996 [INFO] _________________________________________________________________
2020-01-14 16:16:20,996 [INFO] dropout_21 (Dropout)         (None, 32)                0         
2020-01-14 16:16:20,996 [INFO] _________________________________________________________________
2020-01-14 16:16:20,996 [INFO] dense_28 (Dense)             (None, 15)                495       
2020-01-14 16:16:20,996 [INFO] =================================================================
2020-01-14 16:16:20,996 [INFO] Total params: 21,711
2020-01-14 16:16:20,997 [INFO] Trainable params: 21,263
2020-01-14 16:16:20,997 [INFO] Non-trainable params: 448
2020-01-14 16:16:20,997 [INFO] _________________________________________________________________
2020-01-14 16:16:22,982 [INFO] Fine-tuning final neural network
 - val_f1: 0.9951
 - out_of_sample_accuracy: 0.9954
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.18, time = 13.71s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.37, time = 25.45s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.24, time = 24.94s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -63.50, time = 24.75s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -70.26, time = 24.72s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -77.54, time = 24.73s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.19, time = 24.70s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -92.93, time = 24.64s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -100.67, time = 24.63s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -108.37, time = 24.51s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.64, time = 10.61s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.09, time = 16.94s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.59, time = 16.90s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.07, time = 16.90s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.55, time = 16.89s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.01, time = 16.89s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.45, time = 16.88s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.87, time = 16.88s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.29, time = 16.87s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.69, time = 16.88s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.77, time = 5.00s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.84, time = 7.89s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.79, time = 7.88s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.79, time = 7.86s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.78, time = 7.86s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.78, time = 7.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.78, time = 7.87s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.77, time = 7.87s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.77, time = 7.86s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -29.76, time = 7.87s
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 24s - loss: 0.0527 - val_loss: 0.0303
 - val_f1: 0.9180
 - out_of_sample_accuracy: 0.9308
Epoch 2/100
 - 22s - loss: 0.0276 - val_loss: 0.0222
 - val_f1: 0.9237
 - out_of_sample_accuracy: 0.9347
Epoch 3/100
 - 22s - loss: 0.0236 - val_loss: 0.0206
 - val_f1: 0.9328
 - out_of_sample_accuracy: 0.9117
Epoch 4/100
 - 22s - loss: 0.0185 - val_loss: 0.0118
 - val_f1: 0.9651
 - out_of_sample_accuracy: 0.9639
Epoch 5/100
 - 22s - loss: 0.0141 - val_loss: 0.0100
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9786
Epoch 6/100
 - 22s - loss: 0.0118 - val_loss: 0.0094
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9787
Epoch 7/100
 - 22s - loss: 0.0108 - val_loss: 0.0089
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9796
Epoch 8/100
 - 22s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9803
Epoch 9/100
 - 22s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9813
Epoch 10/100
 - 22s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9772
 - out_of_sample_accuracy: 0.9824
Epoch 11/100
 - 22s - loss: 0.0092 - val_loss: 0.0083
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 16:28:03,529 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9825
Epoch 12/100
 - 22s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9809
Epoch 13/100
 - 22s - loss: 0.0089 - val_loss: 0.0082
2020-01-14 16:31:02,120 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9826, current_metric = 0.9828, num_epochs = 13
2020-01-14 16:31:02,122 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:32:00,889 [INFO] Last epoch loss evaluation: train_loss = 0.008177, val_loss = 0.008190
2020-01-14 16:32:00,894 [INFO] Training complete. time_to_train = 1470.80 sec, 24.51 min
2020-01-14 16:32:00,903 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/best_model.pickle
2020-01-14 16:32:00,905 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/training_error_history.csv
2020-01-14 16:32:01,078 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/training_error_history.png
2020-01-14 16:32:01,250 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/training_f1_history.png
2020-01-14 16:32:01,250 [INFO] Making predictions on training, validation, testing data
2020-01-14 16:33:48,674 [INFO] Making predictions complete. time_to_predict = 107.42 sec, 1.79 min
2020-01-14 16:33:48,747 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 16:34:11,960 [INFO] Dataset: Testing. Classification report below
2020-01-14 16:34:11,960 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.96      0.99      0.98      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.71      0.83       440
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.42      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.70      0.67      0.66    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-14 16:34:11,960 [INFO] Overall accuracy (micro avg): 0.9828284956498029
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 16:34:36,935 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9828         0.9828                       0.9828                0.0012                   0.0172  0.9828
1     Macro avg        0.9977         0.6982                       0.6689                0.0045                   0.3311  0.6630
2  Weighted avg        0.9907         0.9775                       0.9828                0.0502                   0.0172  0.9776
2020-01-14 16:35:00,007 [INFO] Dataset: Validation. Classification report below
2020-01-14 16:35:00,007 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.85        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.97      0.99      0.98      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.76      0.86       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.40      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.70      0.67      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-14 16:35:00,008 [INFO] Overall accuracy (micro avg): 0.982992686142401
2020-01-14 16:35:24,860 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.7015                       0.6717                0.0045                   0.3283  0.6676
2  Weighted avg        0.9907         0.9775                       0.9830                0.0500                   0.0170  0.9777
2020-01-14 16:36:40,518 [INFO] Dataset: Training. Classification report below
2020-01-14 16:36:40,519 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.96      0.99      0.98      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.99      0.74      0.85      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.46      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.70      0.67      0.66   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-14 16:36:40,519 [INFO] Overall accuracy (micro avg): 0.9829038731459745
2020-01-14 16:38:02,047 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.7024                       0.6699                0.0045                   0.3301  0.6650
2  Weighted avg        0.9907         0.9780                       0.9829                0.0500                   0.0171  0.9777
2020-01-14 16:38:02,121 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep1/train_time_ids18_subset_dbn_deep_rep1_results.xlsx
2020-01-14 16:38:02,125 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 16:38:02,179 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2
2020-01-14 16:38:02,179 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/run_log.log
2020-01-14 16:38:02,179 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 16:38:02,179 [INFO] Experiment parameters given below
2020-01-14 16:38:02,179 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids18_subset_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982550715, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_dbn_deep_rep2'}
2020-01-14 16:38:02,180 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/tf_logs_run_2020_01_14-16_38_02
2020-01-14 16:38:02,180 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 16:38:02,180 [INFO] Reading X, y files
2020-01-14 16:38:02,180 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 16:38:06,215 [INFO] Reading complete. time_to_read=4.04 seconds
2020-01-14 16:38:06,215 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 16:38:07,602 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 16:38:07,602 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 16:38:08,989 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 16:38:08,989 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 16:38:09,282 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-14 16:38:09,282 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 16:38:09,378 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 16:38:09,378 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 16:38:09,474 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 16:38:12,842 [INFO] Initializing model
2020-01-14 16:38:12,842 [INFO] Training model
2020-01-14 16:38:12,844 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 16:38:43,365 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 4c1a91f2655f519851bfff3122484ff3ddc209a1
2020-01-14 16:38:43,365 [INFO] Pretraining Deep Belief Network
2020-01-14 16:47:05,549 [INFO] Pretraining Complete
2020-01-14 16:47:05,549 [INFO] Getting pretrained weights
2020-01-14 16:47:05,549 [INFO] Creating and initializing feed forward neural network
2020-01-14 16:47:05,859 [INFO] _________________________________________________________________
2020-01-14 16:47:05,859 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 16:47:05,859 [INFO] =================================================================
2020-01-14 16:47:05,859 [INFO] dense_29 (Dense)             (None, 128)               9984      
2020-01-14 16:47:05,859 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] batch_normalization_22 (Batc (None, 128)               512       
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] dropout_22 (Dropout)         (None, 128)               0         
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] dense_30 (Dense)             (None, 64)                8256      
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] batch_normalization_23 (Batc (None, 64)                256       
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] dropout_23 (Dropout)         (None, 64)                0         
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,860 [INFO] dense_31 (Dense)             (None, 33)                2145      
2020-01-14 16:47:05,860 [INFO] _________________________________________________________________
2020-01-14 16:47:05,861 [INFO] batch_normalization_24 (Batc (None, 33)                132       
2020-01-14 16:47:05,861 [INFO] _________________________________________________________________
2020-01-14 16:47:05,861 [INFO] dropout_24 (Dropout)         (None, 33)                0         
2020-01-14 16:47:05,861 [INFO] _________________________________________________________________
2020-01-14 16:47:05,861 [INFO] dense_32 (Dense)             (None, 15)                510       
2020-01-14 16:47:05,861 [INFO] =================================================================
2020-01-14 16:47:05,861 [INFO] Total params: 21,795
2020-01-14 16:47:05,861 [INFO] Trainable params: 21,345
2020-01-14 16:47:05,861 [INFO] Non-trainable params: 450
2020-01-14 16:47:05,861 [INFO] _________________________________________________________________
2020-01-14 16:47:08,214 [INFO] Fine-tuning final neural network
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.29, time = 13.69s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.68, time = 25.41s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.73, time = 24.89s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.06, time = 24.69s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -70.88, time = 24.68s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.21, time = 24.68s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.86, time = 24.65s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -93.60, time = 24.61s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.36, time = 24.59s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -109.09, time = 24.46s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.63, time = 10.64s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.08, time = 16.95s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.58, time = 16.92s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.06, time = 16.92s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.55, time = 16.92s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.00, time = 16.90s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.44, time = 16.90s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.86, time = 16.89s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.28, time = 16.91s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.68, time = 16.90s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.70, time = 5.09s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.82, time = 8.07s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.78, time = 8.06s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.77, time = 8.05s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.77, time = 8.06s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.77, time = 8.06s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.76, time = 8.05s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.75, time = 8.05s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.76, time = 8.05s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -29.75, time = 8.07s
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 25s - loss: 0.0521 - val_loss: 0.0280
 - val_f1: 0.9193
 - out_of_sample_accuracy: 0.9314
Epoch 2/100
 - 23s - loss: 0.0244 - val_loss: 0.0164
 - val_f1: 0.9399
 - out_of_sample_accuracy: 0.9279
Epoch 3/100
 - 23s - loss: 0.0180 - val_loss: 0.0141
 - val_f1: 0.9623
 - out_of_sample_accuracy: 0.9604
Epoch 4/100
 - 23s - loss: 0.0155 - val_loss: 0.0114
 - val_f1: 0.9642
 - out_of_sample_accuracy: 0.9652
Epoch 5/100
 - 23s - loss: 0.0136 - val_loss: 0.0111
 - val_f1: 0.9644
 - out_of_sample_accuracy: 0.9706
Epoch 6/100
 - 23s - loss: 0.0125 - val_loss: 0.0098
 - val_f1: 0.9715
 - out_of_sample_accuracy: 0.9770
Epoch 7/100
 - 23s - loss: 0.0113 - val_loss: 0.0093
 - val_f1: 0.9747
 - out_of_sample_accuracy: 0.9787
Epoch 8/100
 - 23s - loss: 0.0106 - val_loss: 0.0090
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9787
Epoch 9/100
 - 23s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9817
Epoch 10/100
 - 23s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9814
Epoch 11/100
 - 23s - loss: 0.0096 - val_loss: 0.0085
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 16:59:25,897 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/ann_model_epoch_10.pickle
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9815
Epoch 12/100
 - 23s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9818
Epoch 13/100
 - 23s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9815
Epoch 14/100
 - 23s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9817
Epoch 15/100
 - 23s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9817
Epoch 16/100
 - 23s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9814
Epoch 17/100
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9809
Epoch 18/100
 - 23s - loss: 0.0089 - val_loss: 0.0082
2020-01-14 17:08:30,464 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9826, current_metric = 0.9827, num_epochs = 18
2020-01-14 17:08:30,465 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:09:34,011 [INFO] Last epoch loss evaluation: train_loss = 0.008154, val_loss = 0.008166
2020-01-14 17:09:34,015 [INFO] Training complete. time_to_train = 1881.17 sec, 31.35 min
2020-01-14 17:09:34,025 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/best_model.pickle
2020-01-14 17:09:34,026 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/training_error_history.csv
2020-01-14 17:09:34,205 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/training_error_history.png
2020-01-14 17:09:34,382 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/training_f1_history.png
2020-01-14 17:09:34,382 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:11:30,161 [INFO] Making predictions complete. time_to_predict = 115.78 sec, 1.93 min
2020-01-14 17:11:30,235 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:11:53,385 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:11:53,385 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.93      1.00      0.96      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.89      0.73      0.80       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.66      0.67      0.66    645488
            weighted avg       0.97      0.98      0.98    645488

2020-01-14 17:11:53,385 [INFO] Overall accuracy (micro avg): 0.9827742731080981
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 17:12:18,270 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9828         0.9828                       0.9828                0.0012                   0.0172  0.9828
1     Macro avg        0.9977         0.6618                       0.6699                0.0045                   0.3301  0.6595
2  Weighted avg        0.9906         0.9732                       0.9828                0.0510                   0.0172  0.9774
2020-01-14 17:12:41,357 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:12:41,357 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.94      1.00      0.97      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.92      0.77      0.84       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.67      0.67      0.66    645487
            weighted avg       0.97      0.98      0.98    645487

2020-01-14 17:12:41,357 [INFO] Overall accuracy (micro avg): 0.9829632510027313
2020-01-14 17:13:06,223 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.6691                       0.6719                0.0045                   0.3281  0.6645
2  Weighted avg        0.9907         0.9735                       0.9830                0.0508                   0.0170  0.9776
2020-01-14 17:14:21,900 [INFO] Dataset: Training. Classification report below
2020-01-14 17:14:21,900 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.94      1.00      0.97      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.92      0.75      0.83      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.67      0.67      0.66   1936462
            weighted avg       0.97      0.98      0.98   1936462

2020-01-14 17:14:21,900 [INFO] Overall accuracy (micro avg): 0.9828692739645808
2020-01-14 17:15:43,452 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.6662                       0.6701                0.0045                   0.3299  0.6619
2  Weighted avg        0.9907         0.9733                       0.9829                0.0509                   0.0171  0.9775
2020-01-14 17:15:43,526 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep2/train_time_ids18_subset_dbn_deep_rep2_results.xlsx
2020-01-14 17:15:43,532 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 17:15:43,584 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3
2020-01-14 17:15:43,585 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/run_log.log
2020-01-14 17:15:43,585 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 17:15:43,585 [INFO] Experiment parameters given below
2020-01-14 17:15:43,585 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids18_subset_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982550715, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_dbn_deep_rep3'}
2020-01-14 17:15:43,585 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/tf_logs_run_2020_01_14-17_15_43
2020-01-14 17:15:43,585 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 17:15:43,585 [INFO] Reading X, y files
2020-01-14 17:15:43,585 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 17:15:47,634 [INFO] Reading complete. time_to_read=4.05 seconds
2020-01-14 17:15:47,634 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 17:15:49,021 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 17:15:49,021 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 17:15:50,415 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-14 17:15:50,415 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 17:15:50,718 [INFO] Reading complete. time_to_read=0.30 seconds
2020-01-14 17:15:50,718 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 17:15:50,814 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 17:15:50,815 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 17:15:50,911 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-14 17:15:54,272 [INFO] Initializing model
2020-01-14 17:15:54,273 [INFO] Training model
2020-01-14 17:15:54,274 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:16:25,049 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 63d13576323aeca5bb252a360ebafc68df725e90
2020-01-14 17:16:25,050 [INFO] Pretraining Deep Belief Network
2020-01-14 17:24:48,309 [INFO] Pretraining Complete
2020-01-14 17:24:48,309 [INFO] Getting pretrained weights
2020-01-14 17:24:48,309 [INFO] Creating and initializing feed forward neural network
2020-01-14 17:24:48,624 [INFO] _________________________________________________________________
2020-01-14 17:24:48,624 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:24:48,624 [INFO] =================================================================
2020-01-14 17:24:48,624 [INFO] dense_33 (Dense)             (None, 128)               9984      
2020-01-14 17:24:48,624 [INFO] _________________________________________________________________
2020-01-14 17:24:48,624 [INFO] batch_normalization_25 (Batc (None, 128)               512       
2020-01-14 17:24:48,624 [INFO] _________________________________________________________________
2020-01-14 17:24:48,624 [INFO] dropout_25 (Dropout)         (None, 128)               0         
2020-01-14 17:24:48,624 [INFO] _________________________________________________________________
2020-01-14 17:24:48,624 [INFO] dense_34 (Dense)             (None, 64)                8256      
2020-01-14 17:24:48,624 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2020-01-14 17:24:48,625 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2020-01-14 17:24:48,625 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] dense_35 (Dense)             (None, 34)                2210      
2020-01-14 17:24:48,625 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] batch_normalization_27 (Batc (None, 34)                136       
2020-01-14 17:24:48,625 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] dropout_27 (Dropout)         (None, 34)                0         
2020-01-14 17:24:48,625 [INFO] _________________________________________________________________
2020-01-14 17:24:48,625 [INFO] dense_36 (Dense)             (None, 15)                525       
2020-01-14 17:24:48,625 [INFO] =================================================================
2020-01-14 17:24:48,626 [INFO] Total params: 21,879
2020-01-14 17:24:48,626 [INFO] Trainable params: 21,427
2020-01-14 17:24:48,626 [INFO] Non-trainable params: 452
2020-01-14 17:24:48,626 [INFO] _________________________________________________________________
2020-01-14 17:24:51,306 [INFO] Fine-tuning final neural network
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9827
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.26, time = 13.69s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.59, time = 25.44s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.68, time = 24.89s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.18, time = 24.72s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -71.13, time = 24.68s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.55, time = 24.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.28, time = 24.64s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -94.09, time = 24.62s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.90, time = 24.59s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -109.68, time = 24.46s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.69, time = 10.63s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.14, time = 16.95s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.65, time = 16.93s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.13, time = 16.90s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.61, time = 16.91s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.06, time = 16.90s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.51, time = 16.91s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.93, time = 16.91s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.34, time = 16.91s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.74, time = 16.90s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.68, time = 5.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.84, time = 8.18s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.80, time = 8.16s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.79, time = 8.16s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.78, time = 8.16s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.79, time = 8.16s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.77, time = 8.15s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.77, time = 8.16s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.77, time = 8.16s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -29.77, time = 8.16s
Train on 968231 samples, validate on 645487 samples
Epoch 1/100
 - 25s - loss: 0.0567 - val_loss: 0.0299
 - val_f1: 0.9164
 - out_of_sample_accuracy: 0.9301
Epoch 2/100
 - 23s - loss: 0.0293 - val_loss: 0.0185
 - val_f1: 0.9431
 - out_of_sample_accuracy: 0.9298
Epoch 3/100
 - 23s - loss: 0.0195 - val_loss: 0.0123
 - val_f1: 0.9624
 - out_of_sample_accuracy: 0.9605
Epoch 4/100
 - 23s - loss: 0.0147 - val_loss: 0.0120
 - val_f1: 0.9678
 - out_of_sample_accuracy: 0.9725
Epoch 5/100
 - 23s - loss: 0.0127 - val_loss: 0.0099
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9785
Epoch 6/100
 - 23s - loss: 0.0115 - val_loss: 0.0149
 - val_f1: 0.9663
 - out_of_sample_accuracy: 0.9725
Epoch 7/100
 - 23s - loss: 0.0107 - val_loss: 0.0091
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9789
Epoch 8/100
 - 23s - loss: 0.0103 - val_loss: 0.0089
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9807
Epoch 9/100
 - 23s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9811
Epoch 10/100
 - 23s - loss: 0.0097 - val_loss: 0.0193
 - val_f1: 0.9521
 - out_of_sample_accuracy: 0.9588
Epoch 11/100
 - 23s - loss: 0.0095 - val_loss: 0.0103
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:37:55,861 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9798
Epoch 12/100
 - 23s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9817
Epoch 13/100
 - 23s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9820
Epoch 14/100
 - 23s - loss: 0.0091 - val_loss: 0.0082
2020-01-14 17:42:34,524 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9826, current_metric = 0.9828, num_epochs = 14
2020-01-14 17:42:34,526 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:43:42,266 [INFO] Last epoch loss evaluation: train_loss = 0.008192, val_loss = 0.008207
2020-01-14 17:43:42,271 [INFO] Training complete. time_to_train = 1668.00 sec, 27.80 min
2020-01-14 17:43:42,281 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/best_model.pickle
2020-01-14 17:43:42,283 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/training_error_history.csv
2020-01-14 17:43:42,457 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/training_error_history.png
2020-01-14 17:43:42,629 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/training_f1_history.png
2020-01-14 17:43:42,629 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:45:47,184 [INFO] Making predictions complete. time_to_predict = 124.55 sec, 2.08 min
2020-01-14 17:45:47,256 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:46:10,337 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:46:10,337 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.44      0.55      5596
   DoS attacks-Slowloris       0.99      0.73      0.84       440
          FTP-BruteForce       0.68      0.89      0.77      7718
           Infilteration       0.39      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.70      0.67      0.66    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-14 17:46:10,337 [INFO] Overall accuracy (micro avg): 0.9827897652628709
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 17:46:35,156 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9828         0.9828                       0.9828                0.0012                   0.0172  0.9828
1     Macro avg        0.9977         0.6972                       0.6695                0.0046                   0.3305  0.6644
2  Weighted avg        0.9907         0.9771                       0.9828                0.0511                   0.0172  0.9776
2020-01-14 17:46:58,311 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:46:58,311 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.85        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.78      0.87       439
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.35      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.70      0.67      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-14 17:46:58,311 [INFO] Overall accuracy (micro avg): 0.9828904377624956
2020-01-14 17:47:23,231 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.6986                       0.6721                0.0045                   0.3279  0.6685
2  Weighted avg        0.9907         0.9769                       0.9829                0.0509                   0.0171  0.9776
2020-01-14 17:48:38,984 [INFO] Dataset: Training. Classification report below
2020-01-14 17:48:38,985 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.43      0.55     16787
   DoS attacks-Slowloris       0.99      0.76      0.86      1318
          FTP-BruteForce       0.68      0.89      0.77     23153
           Infilteration       0.43      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.70      0.67      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-14 17:48:38,985 [INFO] Overall accuracy (micro avg): 0.9828620442848865
2020-01-14 17:50:00,580 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.7017                       0.6699                0.0045                   0.3301  0.6662
2  Weighted avg        0.9908         0.9776                       0.9829                0.0508                   0.0171  0.9776
2020-01-14 17:50:00,654 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_dbn_deep_rep3/train_time_ids18_subset_dbn_deep_rep3_results.xlsx
2020-01-14 17:50:00,659 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 17:50:00,712 [INFO] Created directory: results_additional_exps/train_time_kdd99_dbn_deep_rep1
2020-01-14 17:50:00,713 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_deep_rep1/run_log.log
2020-01-14 17:50:00,713 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 17:50:00,713 [INFO] Experiment parameters given below
2020-01-14 17:50:00,713 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920635575, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_deep_rep1'}
2020-01-14 17:50:00,713 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_deep_rep1/tf_logs_run_2020_01_14-17_50_00
2020-01-14 17:50:00,713 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 17:50:00,713 [INFO] Reading X, y files
2020-01-14 17:50:00,713 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 17:50:07,418 [INFO] Reading complete. time_to_read=6.70 seconds
2020-01-14 17:50:07,418 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 17:50:09,114 [INFO] Reading complete. time_to_read=1.70 seconds
2020-01-14 17:50:09,114 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 17:50:09,590 [INFO] Reading complete. time_to_read=0.48 seconds
2020-01-14 17:50:09,591 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 17:50:09,817 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 17:50:09,817 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 17:50:09,872 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-14 17:50:09,872 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 17:50:09,891 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 17:50:17,086 [INFO] Initializing model
2020-01-14 17:50:17,086 [INFO] Training model
2020-01-14 17:50:17,086 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:50:56,436 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 6f8609e5223fa8ee2ed743e8a3277ab59426da41
2020-01-14 17:50:56,436 [INFO] Pretraining Deep Belief Network
2020-01-14 18:00:02,993 [INFO] Pretraining Complete
2020-01-14 18:00:02,993 [INFO] Getting pretrained weights
2020-01-14 18:00:02,993 [INFO] Creating and initializing feed forward neural network
2020-01-14 18:00:03,308 [INFO] _________________________________________________________________
2020-01-14 18:00:03,308 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:00:03,308 [INFO] =================================================================
2020-01-14 18:00:03,308 [INFO] dense_37 (Dense)             (None, 128)               15872     
2020-01-14 18:00:03,308 [INFO] _________________________________________________________________
2020-01-14 18:00:03,308 [INFO] batch_normalization_28 (Batc (None, 128)               512       
2020-01-14 18:00:03,308 [INFO] _________________________________________________________________
2020-01-14 18:00:03,308 [INFO] dropout_28 (Dropout)         (None, 128)               0         
2020-01-14 18:00:03,308 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] dense_38 (Dense)             (None, 64)                8256      
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] batch_normalization_29 (Batc (None, 64)                256       
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] dropout_29 (Dropout)         (None, 64)                0         
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] dense_39 (Dense)             (None, 32)                2080      
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] batch_normalization_30 (Batc (None, 32)                128       
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,309 [INFO] dropout_30 (Dropout)         (None, 32)                0         
2020-01-14 18:00:03,309 [INFO] _________________________________________________________________
2020-01-14 18:00:03,310 [INFO] dense_40 (Dense)             (None, 5)                 165       
2020-01-14 18:00:03,310 [INFO] =================================================================
2020-01-14 18:00:03,310 [INFO] Total params: 27,269
2020-01-14 18:00:03,310 [INFO] Trainable params: 26,821
2020-01-14 18:00:03,310 [INFO] Non-trainable params: 448
2020-01-14 18:00:03,310 [INFO] _________________________________________________________________
2020-01-14 18:00:06,381 [INFO] Fine-tuning final neural network
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9828
[BernoulliRBM] Iteration 1, pseudo-likelihood = -64.06, time = 17.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -96.51, time = 30.40s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -124.78, time = 29.71s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -155.49, time = 29.39s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -187.80, time = 28.99s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -219.34, time = 28.80s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -250.91, time = 28.74s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -282.60, time = 28.94s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -314.42, time = 28.92s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -346.37, time = 28.91s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.87, time = 10.76s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.97, time = 17.11s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.53, time = 16.98s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.23, time = 16.91s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.52, time = 16.86s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.18, time = 16.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.48, time = 16.88s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.07, time = 16.87s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.86, time = 16.86s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.72, time = 16.86s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -13.05, time = 5.08s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -11.11, time = 8.01s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -10.46, time = 8.01s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -9.73, time = 8.02s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -9.07, time = 7.99s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -8.55, time = 7.94s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -8.29, time = 7.92s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -8.12, time = 7.91s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -7.89, time = 7.91s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -7.78, time = 7.92s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 71s - loss: 0.0131 - val_loss: 0.0028
 - val_f1: 0.9981
 - out_of_sample_accuracy: 0.9195
Epoch 2/100
 - 69s - loss: 0.0034 - val_loss: 0.0020
 - val_f1: 0.9987
 - out_of_sample_accuracy: 0.9203
Epoch 3/100
 - 69s - loss: 0.0021 - val_loss: 0.0014
 - val_f1: 0.9992
 - out_of_sample_accuracy: 0.9189
Epoch 4/100
 - 69s - loss: 0.0016 - val_loss: 0.0010
 - val_f1: 0.9994
 - out_of_sample_accuracy: 0.9201
Epoch 5/100
 - 69s - loss: 0.0014 - val_loss: 9.0367e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9198
Epoch 6/100
 - 69s - loss: 0.0012 - val_loss: 8.6339e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9194
Epoch 7/100
 - 69s - loss: 0.0011 - val_loss: 7.4987e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9195
Epoch 8/100
 - 69s - loss: 0.0010 - val_loss: 7.8413e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9199
Epoch 9/100
 - 69s - loss: 9.3018e-04 - val_loss: 6.6967e-04
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9206
Epoch 10/100
 - 69s - loss: 8.8336e-04 - val_loss: 6.1590e-04
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9205
Epoch 11/100
 - 69s - loss: 8.2310e-04 - val_loss: 6.3393e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 18:21:55,773 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_kdd99_dbn_deep_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9201
Epoch 12/100
 - 70s - loss: 7.8779e-04 - val_loss: 6.2261e-04
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9204
Epoch 13/100
 - 69s - loss: 7.7587e-04 - val_loss: 6.0303e-04
2020-01-14 18:26:56,481 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9206, current_metric = 0.9210, num_epochs = 13
2020-01-14 18:26:56,483 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 18:29:53,101 [INFO] Last epoch loss evaluation: train_loss = 0.000570, val_loss = 0.000603
2020-01-14 18:29:53,115 [INFO] Training complete. time_to_train = 2376.03 sec, 39.60 min
2020-01-14 18:29:53,125 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_deep_rep1/best_model.pickle
2020-01-14 18:29:53,126 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep1/training_error_history.csv
2020-01-14 18:29:53,308 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep1/training_error_history.png
2020-01-14 18:29:53,485 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep1/training_f1_history.png
2020-01-14 18:29:53,485 [INFO] Making predictions on training, validation, testing data
2020-01-14 18:33:28,854 [INFO] Making predictions complete. time_to_predict = 215.37 sec, 3.59 min
2020-01-14 18:33:28,971 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 18:33:37,655 [INFO] Dataset: Testing. Classification report below
2020-01-14 18:33:37,655 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.91      0.78      0.84      4166
         r2l       0.96      0.03      0.06     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.72      0.55      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 18:33:37,655 [INFO] Overall accuracy (micro avg): 0.9210395172154365
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 18:33:46,956 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9210         0.9210                       0.9210                0.0197                   0.0790  0.9210
1     Macro avg        0.9684         0.7180                       0.5529                0.0212                   0.4471  0.5423
2  Weighted avg        0.9647         0.9309                       0.9210                0.0269                   0.0790  0.9023
2020-01-14 18:34:17,150 [INFO] Dataset: Validation. Classification report below
2020-01-14 18:34:17,150 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.99      0.99      8221
         r2l       0.76      0.64      0.69       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.75      0.72      0.74    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 18:34:17,150 [INFO] Overall accuracy (micro avg): 0.9996539711152643
2020-01-14 18:34:49,738 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.7499                       0.7248                0.0001                   0.2752  0.7363
2  Weighted avg        0.9999         0.9996                       0.9997                0.0003                   0.0003  0.9996
2020-01-14 18:37:02,875 [INFO] Dataset: Training. Classification report below
2020-01-14 18:37:02,875 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.73      0.61      0.66       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.74      0.72      0.73   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 18:37:02,875 [INFO] Overall accuracy (micro avg): 0.9996468256155544
2020-01-14 18:39:26,580 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9999         0.7442                       0.7201                0.0001                   0.2799  0.7311
2  Weighted avg        0.9999         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-14 18:39:26,627 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep1/train_time_kdd99_dbn_deep_rep1_results.xlsx
2020-01-14 18:39:26,634 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 18:39:26,660 [INFO] Created directory: results_additional_exps/train_time_kdd99_dbn_deep_rep2
2020-01-14 18:39:26,660 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_deep_rep2/run_log.log
2020-01-14 18:39:26,660 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 18:39:26,660 [INFO] Experiment parameters given below
2020-01-14 18:39:26,660 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920635575, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_deep_rep2'}
2020-01-14 18:39:26,660 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_deep_rep2/tf_logs_run_2020_01_14-18_39_26
2020-01-14 18:39:26,661 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 18:39:26,661 [INFO] Reading X, y files
2020-01-14 18:39:26,661 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 18:39:33,341 [INFO] Reading complete. time_to_read=6.68 seconds
2020-01-14 18:39:33,341 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 18:39:35,025 [INFO] Reading complete. time_to_read=1.68 seconds
2020-01-14 18:39:35,025 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 18:39:35,501 [INFO] Reading complete. time_to_read=0.48 seconds
2020-01-14 18:39:35,501 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 18:39:35,721 [INFO] Reading complete. time_to_read=0.22 seconds
2020-01-14 18:39:35,721 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 18:39:35,775 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-14 18:39:35,776 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 18:39:35,795 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 18:39:42,972 [INFO] Initializing model
2020-01-14 18:39:42,972 [INFO] Training model
2020-01-14 18:39:42,972 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 18:40:23,934 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 45f7d8ee9b2101cbefe9d62efec04b10a9b8a948
2020-01-14 18:40:23,935 [INFO] Pretraining Deep Belief Network
2020-01-14 18:49:33,021 [INFO] Pretraining Complete
2020-01-14 18:49:33,021 [INFO] Getting pretrained weights
2020-01-14 18:49:33,021 [INFO] Creating and initializing feed forward neural network
2020-01-14 18:49:33,338 [INFO] _________________________________________________________________
2020-01-14 18:49:33,339 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:49:33,339 [INFO] =================================================================
2020-01-14 18:49:33,339 [INFO] dense_41 (Dense)             (None, 128)               15872     
2020-01-14 18:49:33,339 [INFO] _________________________________________________________________
2020-01-14 18:49:33,339 [INFO] batch_normalization_31 (Batc (None, 128)               512       
2020-01-14 18:49:33,339 [INFO] _________________________________________________________________
2020-01-14 18:49:33,339 [INFO] dropout_31 (Dropout)         (None, 128)               0         
2020-01-14 18:49:33,339 [INFO] _________________________________________________________________
2020-01-14 18:49:33,339 [INFO] dense_42 (Dense)             (None, 64)                8256      
2020-01-14 18:49:33,339 [INFO] _________________________________________________________________
2020-01-14 18:49:33,339 [INFO] batch_normalization_32 (Batc (None, 64)                256       
2020-01-14 18:49:33,340 [INFO] _________________________________________________________________
2020-01-14 18:49:33,340 [INFO] dropout_32 (Dropout)         (None, 64)                0         
2020-01-14 18:49:33,340 [INFO] _________________________________________________________________
2020-01-14 18:49:33,340 [INFO] dense_43 (Dense)             (None, 33)                2145      
2020-01-14 18:49:33,340 [INFO] _________________________________________________________________
2020-01-14 18:49:33,340 [INFO] batch_normalization_33 (Batc (None, 33)                132       
2020-01-14 18:49:33,340 [INFO] _________________________________________________________________
2020-01-14 18:49:33,340 [INFO] dropout_33 (Dropout)         (None, 33)                0         
2020-01-14 18:49:33,340 [INFO] _________________________________________________________________
2020-01-14 18:49:33,340 [INFO] dense_44 (Dense)             (None, 5)                 170       
2020-01-14 18:49:33,340 [INFO] =================================================================
2020-01-14 18:49:33,341 [INFO] Total params: 27,343
2020-01-14 18:49:33,341 [INFO] Trainable params: 26,893
2020-01-14 18:49:33,341 [INFO] Non-trainable params: 450
2020-01-14 18:49:33,341 [INFO] _________________________________________________________________
2020-01-14 18:49:36,767 [INFO] Fine-tuning final neural network
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9210
[BernoulliRBM] Iteration 1, pseudo-likelihood = -66.62, time = 17.67s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -96.37, time = 30.43s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -124.11, time = 29.75s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -151.29, time = 29.32s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -180.27, time = 28.94s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -208.92, time = 28.77s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -238.01, time = 28.71s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -268.46, time = 28.93s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -299.70, time = 28.94s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -330.46, time = 28.90s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -14.98, time = 10.76s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -8.84, time = 17.09s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -6.78, time = 16.98s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.90, time = 16.96s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.39, time = 16.97s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.97, time = 16.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.53, time = 16.86s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.22, time = 16.84s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.05, time = 16.83s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.94, time = 16.83s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.21, time = 5.18s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -12.79, time = 8.23s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -11.27, time = 8.23s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -10.53, time = 8.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -10.24, time = 8.23s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -10.01, time = 8.23s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -9.81, time = 8.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -9.74, time = 8.21s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -9.53, time = 8.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -9.47, time = 8.18s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 73s - loss: 0.0163 - val_loss: 0.0029
 - val_f1: 0.9980
 - out_of_sample_accuracy: 0.9165
Epoch 2/100
 - 71s - loss: 0.0041 - val_loss: 0.0022
 - val_f1: 0.9985
 - out_of_sample_accuracy: 0.9199
Epoch 3/100
 - 71s - loss: 0.0031 - val_loss: 0.0019
 - val_f1: 0.9987
 - out_of_sample_accuracy: 0.9203
Epoch 4/100
 - 71s - loss: 0.0023 - val_loss: 0.0014
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 18:58:09,945 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9206, current_metric = 0.9208, num_epochs = 4
2020-01-14 18:58:09,947 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:01:15,195 [INFO] Last epoch loss evaluation: train_loss = 0.001425, val_loss = 0.001424
2020-01-14 19:01:15,210 [INFO] Training complete. time_to_train = 1292.24 sec, 21.54 min
2020-01-14 19:01:17,059 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_deep_rep2/best_model.pickle
2020-01-14 19:01:17,061 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep2/training_error_history.csv
/home/sunanda/research/ids_experiments/utility.py:289: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 19:01:17,245 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep2/training_error_history.png
/home/sunanda/research/ids_experiments/utility.py:306: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 19:01:17,409 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep2/training_f1_history.png
2020-01-14 19:01:17,409 [INFO] Making predictions on training, validation, testing data
2020-01-14 19:04:58,908 [INFO] Making predictions complete. time_to_predict = 221.50 sec, 3.69 min
2020-01-14 19:04:59,027 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 19:05:07,723 [INFO] Dataset: Testing. Classification report below
2020-01-14 19:05:07,723 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.99      0.83     60593
       probe       0.90      0.80      0.85      4166
         r2l       0.00      0.00      0.00     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.52      0.55      0.53    311029
weighted avg       0.89      0.92      0.90    311029

2020-01-14 19:05:07,723 [INFO] Overall accuracy (micro avg): 0.9209623539927145
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 19:05:17,037 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9210         0.9210                       0.9210                0.0198                   0.0790  0.9210
1     Macro avg        0.9684         0.5234                       0.5526                0.0206                   0.4474  0.5330
2  Weighted avg        0.9652         0.8889                       0.9210                0.0241                   0.0790  0.9005
2020-01-14 19:05:47,198 [INFO] Dataset: Validation. Classification report below
2020-01-14 19:05:47,198 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.96      0.97      8221
         r2l       0.00      0.00      0.00       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.60      0.59      0.59    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 19:05:47,198 [INFO] Overall accuracy (micro avg): 0.9992324079017074
2020-01-14 19:06:19,731 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.5966                       0.5922                0.0003                   0.4078  0.5944
2  Weighted avg        0.9997         0.9990                       0.9992                0.0007                   0.0008  0.9991
2020-01-14 19:08:32,789 [INFO] Dataset: Training. Classification report below
2020-01-14 19:08:32,789 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.96      0.97     32881
         r2l       0.00      0.00      0.00       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.60      0.59      0.59   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 19:08:32,789 [INFO] Overall accuracy (micro avg): 0.9992244964202815
2020-01-14 19:10:56,342 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.5969                       0.5919                0.0003                   0.4081  0.5944
2  Weighted avg        0.9997         0.9990                       0.9992                0.0007                   0.0008  0.9991
2020-01-14 19:10:56,390 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep2/train_time_kdd99_dbn_deep_rep2_results.xlsx
2020-01-14 19:10:56,398 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 19:10:56,422 [INFO] Created directory: results_additional_exps/train_time_kdd99_dbn_deep_rep3
2020-01-14 19:10:56,422 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_deep_rep3/run_log.log
2020-01-14 19:10:56,422 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 19:10:56,422 [INFO] Experiment parameters given below
2020-01-14 19:10:56,422 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.920635575, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_deep_rep3'}
2020-01-14 19:10:56,422 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_deep_rep3/tf_logs_run_2020_01_14-19_10_56
2020-01-14 19:10:56,423 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 19:10:56,423 [INFO] Reading X, y files
2020-01-14 19:10:56,423 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 19:11:03,025 [INFO] Reading complete. time_to_read=6.60 seconds
2020-01-14 19:11:03,025 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 19:11:04,706 [INFO] Reading complete. time_to_read=1.68 seconds
2020-01-14 19:11:04,707 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 19:11:05,182 [INFO] Reading complete. time_to_read=0.47 seconds
2020-01-14 19:11:05,182 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 19:11:05,381 [INFO] Reading complete. time_to_read=0.20 seconds
2020-01-14 19:11:05,381 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 19:11:05,435 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-14 19:11:05,435 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 19:11:05,455 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 19:11:12,620 [INFO] Initializing model
2020-01-14 19:11:12,620 [INFO] Training model
2020-01-14 19:11:12,620 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 19:11:53,325 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = b064712f34e8186ba50c8c88b0864cefc8bd21d1
2020-01-14 19:11:53,325 [INFO] Pretraining Deep Belief Network
2020-01-14 19:21:03,143 [INFO] Pretraining Complete
2020-01-14 19:21:03,143 [INFO] Getting pretrained weights
2020-01-14 19:21:03,143 [INFO] Creating and initializing feed forward neural network
2020-01-14 19:21:03,466 [INFO] _________________________________________________________________
2020-01-14 19:21:03,466 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 19:21:03,466 [INFO] =================================================================
2020-01-14 19:21:03,466 [INFO] dense_45 (Dense)             (None, 128)               15872     
2020-01-14 19:21:03,466 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] batch_normalization_34 (Batc (None, 128)               512       
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] dropout_34 (Dropout)         (None, 128)               0         
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] dense_46 (Dense)             (None, 64)                8256      
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] batch_normalization_35 (Batc (None, 64)                256       
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] dropout_35 (Dropout)         (None, 64)                0         
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,467 [INFO] dense_47 (Dense)             (None, 34)                2210      
2020-01-14 19:21:03,467 [INFO] _________________________________________________________________
2020-01-14 19:21:03,468 [INFO] batch_normalization_36 (Batc (None, 34)                136       
2020-01-14 19:21:03,468 [INFO] _________________________________________________________________
2020-01-14 19:21:03,468 [INFO] dropout_36 (Dropout)         (None, 34)                0         
2020-01-14 19:21:03,468 [INFO] _________________________________________________________________
2020-01-14 19:21:03,468 [INFO] dense_48 (Dense)             (None, 5)                 175       
2020-01-14 19:21:03,468 [INFO] =================================================================
2020-01-14 19:21:03,468 [INFO] Total params: 27,417
2020-01-14 19:21:03,468 [INFO] Trainable params: 26,965
2020-01-14 19:21:03,468 [INFO] Non-trainable params: 452
2020-01-14 19:21:03,468 [INFO] _________________________________________________________________
2020-01-14 19:21:07,248 [INFO] Fine-tuning final neural network
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9208
[BernoulliRBM] Iteration 1, pseudo-likelihood = -66.70, time = 17.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -98.26, time = 30.40s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -126.42, time = 29.72s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -156.37, time = 29.35s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -187.97, time = 28.97s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -218.93, time = 28.78s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -249.93, time = 28.71s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -281.14, time = 28.91s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -312.11, time = 28.92s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -343.38, time = 28.90s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.63, time = 10.79s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.78, time = 17.13s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.40, time = 16.99s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.27, time = 16.92s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.34, time = 16.90s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.80, time = 16.90s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.42, time = 16.89s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.05, time = 16.88s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.84, time = 16.89s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.56, time = 16.88s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -12.33, time = 5.22s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -10.91, time = 8.33s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -10.04, time = 8.34s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -9.26, time = 8.32s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -8.63, time = 8.30s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -8.19, time = 8.29s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -7.96, time = 8.25s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -7.72, time = 8.23s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -7.56, time = 8.23s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -7.45, time = 8.23s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 74s - loss: 0.0154 - val_loss: 0.0032
 - val_f1: 0.9979
 - out_of_sample_accuracy: 0.9163
Epoch 2/100
 - 72s - loss: 0.0042 - val_loss: 0.0021
 - val_f1: 0.9986
 - out_of_sample_accuracy: 0.9202
Epoch 3/100
 - 72s - loss: 0.0028 - val_loss: 0.0015
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9192
Epoch 4/100
 - 72s - loss: 0.0021 - val_loss: 0.0012
 - val_f1: 0.9992
 - out_of_sample_accuracy: 0.9194
Epoch 5/100
 - 72s - loss: 0.0018 - val_loss: 0.0011
 - val_f1: 0.9993
 - out_of_sample_accuracy: 0.9195
Epoch 6/100
 - 72s - loss: 0.0016 - val_loss: 0.0010
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9197
Epoch 7/100
 - 72s - loss: 0.0014 - val_loss: 8.7457e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9197
Epoch 8/100
 - 72s - loss: 0.0013 - val_loss: 7.9188e-04
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9205
Epoch 9/100
 - 72s - loss: 0.0012 - val_loss: 8.4257e-04
 - val_f1: 0.9994
 - out_of_sample_accuracy: 0.9188
Epoch 10/100
 - 72s - loss: 0.0012 - val_loss: 7.9731e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 19:42:47,419 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9206, current_metric = 0.9211, num_epochs = 10
2020-01-14 19:42:47,419 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:45:54,344 [INFO] Last epoch loss evaluation: train_loss = 0.000750, val_loss = 0.000792
2020-01-14 19:45:54,358 [INFO] Training complete. time_to_train = 2081.74 sec, 34.70 min
2020-01-14 19:45:56,424 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_deep_rep3/best_model.pickle
2020-01-14 19:45:56,426 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep3/training_error_history.csv
/home/sunanda/research/ids_experiments/utility.py:289: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 19:45:56,595 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep3/training_error_history.png
/home/sunanda/research/ids_experiments/utility.py:306: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
2020-01-14 19:45:56,753 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep3/training_f1_history.png
2020-01-14 19:45:56,753 [INFO] Making predictions on training, validation, testing data
2020-01-14 19:49:43,499 [INFO] Making predictions complete. time_to_predict = 226.75 sec, 3.78 min
2020-01-14 19:49:43,615 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 19:49:52,300 [INFO] Dataset: Testing. Classification report below
2020-01-14 19:49:52,300 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.91      0.79      0.84      4166
         r2l       0.98      0.02      0.05     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.72      0.55      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 19:49:52,300 [INFO] Overall accuracy (micro avg): 0.9207501551302291
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 19:50:01,591 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9208         0.9208                       0.9208                0.0198                   0.0792  0.9208
1     Macro avg        0.9683         0.7215                       0.5532                0.0213                   0.4468  0.5410
2  Weighted avg        0.9644         0.9314                       0.9208                0.0274                   0.0792  0.9017
2020-01-14 19:50:31,826 [INFO] Dataset: Validation. Classification report below
2020-01-14 19:50:31,826 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.98      0.99      8221
         r2l       0.88      0.44      0.59       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.78      0.68      0.72    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 19:50:31,826 [INFO] Overall accuracy (micro avg): 0.9995947685332152
2020-01-14 19:51:04,461 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9998         0.7755                       0.6847                0.0002                   0.3153  0.7152
2  Weighted avg        0.9998         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-14 19:53:17,493 [INFO] Dataset: Training. Classification report below
2020-01-14 19:53:17,493 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.98      0.99     32881
         r2l       0.90      0.46      0.61       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.78      0.69      0.72   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 19:53:17,493 [INFO] Overall accuracy (micro avg): 0.9995988510604418
2020-01-14 19:55:41,078 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9998         0.7780                       0.6881                0.0002                   0.3119  0.7189
2  Weighted avg        0.9998         0.9996                       0.9996                0.0005                   0.0004  0.9996
2020-01-14 19:55:41,124 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_deep_rep3/train_time_kdd99_dbn_deep_rep3_results.xlsx
2020-01-14 19:55:41,131 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 19:55:41,157 [INFO] ================= Finished running 12 experiments ================= 

 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9211
