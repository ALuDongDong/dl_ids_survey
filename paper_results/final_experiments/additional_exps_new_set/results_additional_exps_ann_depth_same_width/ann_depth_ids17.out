Using TensorFlow backend.
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-08 14:31:34,808 [INFO] Read 5 experiments from file: experiment_specs/additional_exps/ann_depth.csv
2020-01-08 14:31:34,808 [INFO] ================= Started running experiments ================= 

2020-01-08 14:31:34,808 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_1
2020-01-08 14:31:34,808 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_1/run_log.log
2020-01-08 14:31:34,808 [INFO] ================= Running experiment no. 1  ================= 

2020-01-08 14:31:34,808 [INFO] Experiment parameters given below
2020-01-08 14:31:34,808 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_1'}
2020-01-08 14:31:34,808 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_1/tf_logs_run_2020_01_08-14_31_34
2020-01-08 14:31:34,809 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 14:31:34,831 [INFO] Reading X, y files
2020-01-08 14:31:34,831 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 14:31:35,256 [INFO] NumExpr defaulting to 4 threads.
2020-01-08 14:31:46,924 [INFO] Reading complete. time_to_read=12.09 seconds
2020-01-08 14:31:46,924 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 14:31:51,680 [INFO] Reading complete. time_to_read=4.76 seconds
2020-01-08 14:31:51,680 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 14:31:55,771 [INFO] Reading complete. time_to_read=4.09 seconds
2020-01-08 14:31:55,772 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 14:31:56,622 [INFO] Reading complete. time_to_read=0.85 seconds
2020-01-08 14:31:56,622 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 14:31:57,015 [INFO] Reading complete. time_to_read=0.39 seconds
2020-01-08 14:31:57,016 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 14:31:57,380 [INFO] Reading complete. time_to_read=0.36 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-3
OMP: Info #156: KMP_AFFINITY: 4 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 1 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7927 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7936 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7938 thread 3 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7937 thread 2 bound to OS proc set 2
2020-01-08 14:32:00,194 [INFO] Initializing model
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-08 14:32:00,308 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 14:32:00,472 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 14:32:00,512 [INFO] _________________________________________________________________
2020-01-08 14:32:00,512 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 14:32:00,512 [INFO] =================================================================
2020-01-08 14:32:00,512 [INFO] dense_1 (Dense)              (None, 64)                5056      
2020-01-08 14:32:00,512 [INFO] _________________________________________________________________
2020-01-08 14:32:00,512 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 14:32:00,512 [INFO] _________________________________________________________________
2020-01-08 14:32:00,512 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 14:32:00,512 [INFO] _________________________________________________________________
2020-01-08 14:32:00,512 [INFO] dense_2 (Dense)              (None, 12)                780       
2020-01-08 14:32:00,512 [INFO] =================================================================
2020-01-08 14:32:00,512 [INFO] Total params: 6,092
2020-01-08 14:32:00,512 [INFO] Trainable params: 5,964
2020-01-08 14:32:00,512 [INFO] Non-trainable params: 128
2020-01-08 14:32:00,513 [INFO] _________________________________________________________________
2020-01-08 14:32:00,513 [INFO] Training model
WARNING:tensorflow:From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 14:32:07,531 [WARNING] From /home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 14:32:07.882074: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-08 14:32:08.103501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893580000 Hz
2020-01-08 14:32:08.149635: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559c7bd605c0 executing computations on platform Host. Devices:
2020-01-08 14:32:08.149668: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-08 14:32:08.160367: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7950 thread 4 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7951 thread 5 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7969 thread 6 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7971 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7970 thread 7 bound to OS proc set 3
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 16s - loss: 0.0194 - val_loss: 0.0111
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7986 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7987 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 7927 tid 7988 thread 11 bound to OS proc set 3
 - val_f1: 0.9646
Epoch 2/200
 - 14s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9841
Epoch 3/200
 - 14s - loss: 0.0068 - val_loss: 0.0056
 - val_f1: 0.9873
Epoch 4/200
 - 14s - loss: 0.0062 - val_loss: 0.0066
 - val_f1: 0.9828
Epoch 5/200
 - 14s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9923
Epoch 6/200
 - 14s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 7/200
 - 14s - loss: 0.0049 - val_loss: 0.0052
 - val_f1: 0.9900
Epoch 8/200
 - 14s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9925
Epoch 9/200
 - 14s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 10/200
 - 14s - loss: 0.0045 - val_loss: 0.0047
 - val_f1: 0.9920
Epoch 11/200
 - 14s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9935
Epoch 12/200
 - 14s - loss: 0.0046 - val_loss: 0.0062
 - val_f1: 0.9870
Epoch 13/200
 - 14s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9916
Epoch 14/200
 - 14s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 15/200
 - 14s - loss: 0.0044 - val_loss: 0.0120
 - val_f1: 0.9599
Epoch 16/200
 - 14s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 17/200
 - 14s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9937
Epoch 18/200
 - 14s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 19/200
 - 15s - loss: 0.0046 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 20/200
 - 17s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9921
Epoch 21/200
 - 14s - loss: 0.0043 - val_loss: 0.0045
2020-01-08 14:39:13,658 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_20.pickle
 - val_f1: 0.9906
Epoch 22/200
 - 14s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9911
Epoch 23/200
 - 14s - loss: 0.0042 - val_loss: 0.0042
 - val_f1: 0.9899
Epoch 24/200
 - 14s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9925
Epoch 25/200
 - 14s - loss: 0.0041 - val_loss: 0.0059
 - val_f1: 0.9885
Epoch 26/200
 - 14s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9921
Epoch 27/200
 - 14s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 28/200
 - 14s - loss: 0.0039 - val_loss: 0.0071
 - val_f1: 0.9722
Epoch 29/200
 - 14s - loss: 0.0040 - val_loss: 0.0070
 - val_f1: 0.9862
Epoch 30/200
 - 14s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 31/200
 - 14s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 32/200
 - 14s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 33/200
 - 14s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 34/200
 - 14s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9889
Epoch 35/200
 - 14s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9912
Epoch 36/200
 - 14s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 37/200
 - 14s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 38/200
 - 14s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 39/200
 - 14s - loss: 0.0038 - val_loss: 0.0053
 - val_f1: 0.9897
Epoch 40/200
 - 14s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 41/200
 - 14s - loss: 0.0038 - val_loss: 0.0036
2020-01-08 14:46:00,030 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_40.pickle
 - val_f1: 0.9914
Epoch 42/200
 - 14s - loss: 0.0042 - val_loss: 0.0070
 - val_f1: 0.9882
Epoch 43/200
 - 14s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 44/200
 - 14s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 45/200
 - 14s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 46/200
 - 14s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 47/200
 - 14s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9917
Epoch 48/200
 - 14s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9912
Epoch 49/200
 - 14s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 50/200
 - 14s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 51/200
 - 14s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 52/200
 - 14s - loss: 0.0035 - val_loss: 0.0071
 - val_f1: 0.9824
Epoch 53/200
 - 14s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 54/200
 - 14s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 55/200
 - 14s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 56/200
 - 14s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 57/200
 - 14s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9939
Epoch 58/200
 - 14s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 59/200
 - 14s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9912
Epoch 60/200
 - 14s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 61/200
 - 14s - loss: 0.0034 - val_loss: 0.0029
2020-01-08 14:52:46,709 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_60.pickle
 - val_f1: 0.9925
Epoch 62/200
 - 14s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 63/200
 - 14s - loss: 0.0034 - val_loss: 0.0078
 - val_f1: 0.9856
Epoch 64/200
 - 14s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 65/200
 - 14s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 66/200
 - 14s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 67/200
 - 14s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 68/200
 - 14s - loss: 0.0033 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 69/200
 - 14s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 70/200
 - 14s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 71/200
 - 14s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 72/200
 - 14s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 73/200
 - 14s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 74/200
 - 14s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 75/200
 - 14s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 76/200
 - 14s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 77/200
 - 14s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 78/200
 - 14s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 79/200
 - 14s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 80/200
 - 14s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 81/200
 - 14s - loss: 0.0032 - val_loss: 0.0038
2020-01-08 14:59:33,974 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_80.pickle
 - val_f1: 0.9920
Epoch 82/200
 - 14s - loss: 0.0032 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 83/200
 - 14s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 84/200
 - 14s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 85/200
 - 14s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 86/200
 - 14s - loss: 0.0032 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 87/200
 - 14s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 88/200
 - 14s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 89/200
 - 14s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 90/200
 - 14s - loss: 0.0032 - val_loss: 0.0061
 - val_f1: 0.9879
Epoch 91/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 92/200
 - 14s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 93/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 94/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 95/200
 - 14s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 96/200
 - 14s - loss: 0.0031 - val_loss: 0.0048
 - val_f1: 0.9891
Epoch 97/200
 - 14s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 98/200
 - 14s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 99/200
 - 14s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 100/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 101/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
2020-01-08 15:06:21,780 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_100.pickle
 - val_f1: 0.9951
Epoch 102/200
 - 14s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 103/200
 - 14s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 104/200
 - 14s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 105/200
 - 14s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 106/200
 - 14s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 107/200
 - 14s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 108/200
 - 14s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 109/200
 - 14s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 110/200
 - 14s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 111/200
 - 14s - loss: 0.0030 - val_loss: 0.0044
 - val_f1: 0.9933
Epoch 112/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 113/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 114/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 115/200
 - 14s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 116/200
 - 14s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 117/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 118/200
 - 14s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 119/200
 - 14s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 120/200
 - 14s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 121/200
 - 14s - loss: 0.0030 - val_loss: 0.0029
2020-01-08 15:13:09,678 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_120.pickle
 - val_f1: 0.9928
Epoch 122/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 123/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9957
Epoch 124/200
 - 14s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 125/200
 - 14s - loss: 0.0030 - val_loss: 0.0043
 - val_f1: 0.9924
Epoch 126/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 127/200
 - 14s - loss: 0.0030 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 128/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9926
Epoch 129/200
 - 14s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 130/200
 - 14s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 131/200
 - 14s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 132/200
 - 14s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 133/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9952
Epoch 134/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 135/200
 - 14s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 136/200
 - 14s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 137/200
 - 14s - loss: 0.0029 - val_loss: 0.0036
 - val_f1: 0.9940
Epoch 138/200
 - 14s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 139/200
 - 14s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 140/200
 - 14s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 141/200
 - 14s - loss: 0.0030 - val_loss: 0.0023
2020-01-08 15:19:58,327 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_140.pickle
 - val_f1: 0.9950
Epoch 142/200
 - 14s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 143/200
 - 14s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 144/200
 - 14s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 145/200
 - 14s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 146/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 147/200
 - 14s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 148/200
 - 14s - loss: 0.0030 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 149/200
 - 14s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 150/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 151/200
 - 14s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 152/200
 - 14s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 153/200
 - 14s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 154/200
 - 14s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 155/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 156/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 157/200
 - 14s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 158/200
 - 14s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 159/200
 - 14s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 160/200
 - 14s - loss: 0.0030 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 161/200
 - 14s - loss: 0.0031 - val_loss: 0.0027
2020-01-08 15:26:45,914 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_160.pickle
 - val_f1: 0.9948
Epoch 162/200
 - 14s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 163/200
 - 14s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 164/200
 - 14s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9898
Epoch 165/200
 - 14s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 166/200
 - 14s - loss: 0.0030 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 167/200
 - 14s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 168/200
 - 14s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 169/200
 - 14s - loss: 0.0031 - val_loss: 0.0053
 - val_f1: 0.9890
Epoch 170/200
 - 14s - loss: 0.0031 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 171/200
 - 14s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 172/200
 - 14s - loss: 0.0030 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 173/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 174/200
 - 14s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 175/200
 - 14s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 176/200
 - 14s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 177/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 178/200
 - 14s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 179/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9926
Epoch 180/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 181/200
 - 14s - loss: 0.0030 - val_loss: 0.0057
2020-01-08 15:33:34,785 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_1/ann_model_epoch_180.pickle
 - val_f1: 0.9872
Epoch 182/200
 - 14s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 183/200
 - 14s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 184/200
 - 14s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 185/200
 - 14s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9920
Epoch 186/200
 - 14s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 187/200
 - 14s - loss: 0.0030 - val_loss: 0.0048
 - val_f1: 0.9933
Epoch 188/200
 - 14s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 189/200
 - 14s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 190/200
 - 14s - loss: 0.0030 - val_loss: 0.0037
 - val_f1: 0.9948
Epoch 191/200
 - 14s - loss: 0.0030 - val_loss: 0.0059
2020-01-08 15:37:05,161 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 15:37:31,577 [INFO] Last epoch loss evaluation: train_loss = 0.002277, val_loss = 0.002334
2020-01-08 15:37:31,577 [INFO] Training complete. time_to_train = 3931.06 sec, 65.52 min
2020-01-08 15:37:31,581 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_1/best_model.pickle
2020-01-08 15:37:31,598 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_1/training_error_history.csv
2020-01-08 15:37:31,880 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_1/training_error_history.png
2020-01-08 15:37:32,090 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_1/training_f1_history.png
2020-01-08 15:37:32,090 [INFO] Making predictions on training, validation, testing data
2020-01-08 15:37:59,398 [INFO] Evaluating predictions (results)
/home/nilwala/anaconda3/envs/ml_env/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
2020-01-08 15:38:18,075 [INFO] Dataset: Testing. Classification report below
2020-01-08 15:38:18,075 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.97      0.98      2058
              DoS Hulk       0.98      0.98      0.98     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.96      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.74      0.10      0.18       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.87      0.78      0.80    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 15:38:18,075 [INFO] Overall accuracy (micro avg): 0.9949978958982393
/home/nilwala/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/nilwala/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 15:38:37,852 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.8749                       0.7801                0.0013                   0.2199  0.7965
2  Weighted avg        0.9958         0.9947                       0.9950                0.0112                   0.0050  0.9946
2020-01-08 15:38:56,446 [INFO] Dataset: Validation. Classification report below
2020-01-08 15:38:56,446 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.96      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1180
Web Attack Brute Force       0.65      0.07      0.12       301
        Web Attack XSS       0.57      0.03      0.06       131

              accuracy                           1.00    565562
             macro avg       0.92      0.78      0.79    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-08 15:38:56,446 [INFO] Overall accuracy (micro avg): 0.9951517251866285
2020-01-08 15:39:16,430 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.9150                       0.7763                0.0013                   0.2237  0.7937
2  Weighted avg        0.9960         0.9949                       0.9952                0.0107                   0.0048  0.9947
2020-01-08 15:40:18,132 [INFO] Dataset: Training. Classification report below
2020-01-08 15:40:18,132 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      0.98      0.98    138074
      DoS Slowhttptest       0.91      0.98      0.94      3300
         DoS slowloris       0.99      0.97      0.98      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.72      0.09      0.16       904
        Web Attack XSS       0.86      0.03      0.06       391

              accuracy                           1.00   1696684
             macro avg       0.95      0.78      0.80   1696684
          weighted avg       1.00      1.00      0.99   1696684

2020-01-08 15:40:18,132 [INFO] Overall accuracy (micro avg): 0.9952018171916515
2020-01-08 15:41:24,687 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.9487                       0.7808                0.0013                   0.2192  0.8001
2  Weighted avg        0.9960         0.9951                       0.9952                0.0110                   0.0048  0.9948
2020-01-08 15:41:24,751 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_1/ann_depth_ids17_layers_1_results.xlsx
2020-01-08 15:41:24,756 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-08 15:41:24,793 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_2
2020-01-08 15:41:24,794 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_2/run_log.log
2020-01-08 15:41:24,794 [INFO] ================= Running experiment no. 2  ================= 

2020-01-08 15:41:24,794 [INFO] Experiment parameters given below
2020-01-08 15:41:24,794 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_2'}
2020-01-08 15:41:24,794 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_2/tf_logs_run_2020_01_08-15_41_24
2020-01-08 15:41:24,794 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 15:41:24,794 [INFO] Reading X, y files
2020-01-08 15:41:24,794 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 15:41:28,816 [INFO] Reading complete. time_to_read=4.02 seconds
2020-01-08 15:41:28,816 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 15:41:30,185 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 15:41:30,185 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 15:41:31,550 [INFO] Reading complete. time_to_read=1.36 seconds
2020-01-08 15:41:31,550 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 15:41:31,785 [INFO] Reading complete. time_to_read=0.24 seconds
2020-01-08 15:41:31,785 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 15:41:31,862 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 15:41:31,863 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 15:41:31,940 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 15:41:34,752 [INFO] Initializing model
2020-01-08 15:41:34,936 [INFO] _________________________________________________________________
2020-01-08 15:41:34,936 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 15:41:34,936 [INFO] =================================================================
2020-01-08 15:41:34,937 [INFO] dense_3 (Dense)              (None, 64)                5056      
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] dense_4 (Dense)              (None, 64)                4160      
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 15:41:34,937 [INFO] _________________________________________________________________
2020-01-08 15:41:34,937 [INFO] dense_5 (Dense)              (None, 12)                780       
2020-01-08 15:41:34,937 [INFO] =================================================================
2020-01-08 15:41:34,938 [INFO] Total params: 10,508
2020-01-08 15:41:34,938 [INFO] Trainable params: 10,252
2020-01-08 15:41:34,938 [INFO] Non-trainable params: 256
2020-01-08 15:41:34,938 [INFO] _________________________________________________________________
2020-01-08 15:41:34,938 [INFO] Training model
 - val_f1: 0.9862
Epoch 00191: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 20s - loss: 0.0188 - val_loss: 0.0095
 - val_f1: 0.9747
Epoch 2/200
 - 19s - loss: 0.0098 - val_loss: 0.0069
 - val_f1: 0.9822
Epoch 3/200
 - 19s - loss: 0.0068 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 4/200
 - 19s - loss: 0.0060 - val_loss: 0.0067
 - val_f1: 0.9818
Epoch 5/200
 - 19s - loss: 0.0057 - val_loss: 0.0052
 - val_f1: 0.9863
Epoch 6/200
 - 20s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9886
Epoch 7/200
 - 19s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9870
Epoch 8/200
 - 20s - loss: 0.0059 - val_loss: 0.0071
 - val_f1: 0.9800
Epoch 9/200
 - 19s - loss: 0.0053 - val_loss: 0.0044
 - val_f1: 0.9897
Epoch 10/200
 - 19s - loss: 0.0052 - val_loss: 0.0058
 - val_f1: 0.9821
Epoch 11/200
 - 19s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 12/200
 - 19s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 13/200
 - 19s - loss: 0.0046 - val_loss: 0.0046
 - val_f1: 0.9865
Epoch 14/200
 - 19s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9906
Epoch 15/200
 - 19s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9915
Epoch 16/200
 - 20s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 17/200
 - 19s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9899
Epoch 18/200
 - 20s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 19/200
 - 20s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 20/200
 - 19s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 21/200
 - 19s - loss: 0.0041 - val_loss: 0.0028
2020-01-08 15:51:01,705 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_20.pickle
 - val_f1: 0.9939
Epoch 22/200
 - 19s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 23/200
 - 19s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 24/200
 - 19s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 25/200
 - 19s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 26/200
 - 19s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 27/200
 - 19s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 28/200
 - 19s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 29/200
 - 19s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 30/200
 - 19s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 31/200
 - 19s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 32/200
 - 19s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 33/200
 - 19s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 34/200
 - 19s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 35/200
 - 19s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 36/200
 - 19s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9926
Epoch 37/200
 - 19s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 38/200
 - 20s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 39/200
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 40/200
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 41/200
 - 19s - loss: 0.0038 - val_loss: 0.0028
2020-01-08 16:00:04,258 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_40.pickle
 - val_f1: 0.9931
Epoch 42/200
 - 19s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 43/200
 - 19s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9928
Epoch 44/200
 - 19s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 45/200
 - 19s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 46/200
 - 19s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 47/200
 - 19s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 48/200
 - 19s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 49/200
 - 19s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 50/200
 - 19s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 51/200
 - 19s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 52/200
 - 19s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 53/200
 - 19s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 54/200
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 55/200
 - 19s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9911
Epoch 56/200
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 57/200
 - 19s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 58/200
 - 19s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 59/200
 - 19s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 60/200
 - 20s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 61/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
2020-01-08 16:09:06,502 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_60.pickle
 - val_f1: 0.9944
Epoch 62/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 63/200
 - 19s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 64/200
 - 19s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 65/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 66/200
 - 19s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 67/200
 - 19s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 68/200
 - 19s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 69/200
 - 19s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 70/200
 - 19s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 71/200
 - 19s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 72/200
 - 19s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 73/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 74/200
 - 19s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 75/200
 - 19s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 76/200
 - 19s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 77/200
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 78/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 79/200
 - 19s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 80/200
 - 19s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 81/200
 - 20s - loss: 0.0034 - val_loss: 0.0026
2020-01-08 16:18:09,169 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_80.pickle
 - val_f1: 0.9940
Epoch 82/200
 - 19s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 83/200
 - 19s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 84/200
 - 19s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 85/200
 - 19s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 86/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 87/200
 - 19s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 88/200
 - 19s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 89/200
 - 19s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 90/200
 - 20s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 91/200
 - 19s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 92/200
 - 20s - loss: 0.0037 - val_loss: 0.0058
 - val_f1: 0.9831
Epoch 93/200
 - 19s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 94/200
 - 19s - loss: 0.0033 - val_loss: 0.0049
 - val_f1: 0.9884
Epoch 95/200
 - 19s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 96/200
 - 19s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9930
Epoch 97/200
 - 19s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 98/200
 - 19s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 99/200
 - 19s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 100/200
 - 19s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 101/200
 - 19s - loss: 0.0034 - val_loss: 0.0026
2020-01-08 16:27:11,595 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_100.pickle
 - val_f1: 0.9933
Epoch 102/200
 - 19s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 103/200
 - 19s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 104/200
 - 19s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 105/200
 - 19s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 106/200
 - 19s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 107/200
 - 19s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 108/200
 - 19s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 109/200
 - 19s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 110/200
 - 19s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 111/200
 - 19s - loss: 0.0033 - val_loss: 0.0038
 - val_f1: 0.9904
Epoch 112/200
 - 19s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 113/200
 - 19s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 114/200
 - 19s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 115/200
 - 19s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 116/200
 - 19s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 117/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 118/200
 - 19s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 119/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 120/200
 - 19s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 121/200
 - 19s - loss: 0.0033 - val_loss: 0.0034
2020-01-08 16:36:14,427 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_120.pickle
 - val_f1: 0.9904
Epoch 122/200
 - 19s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 123/200
 - 19s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 124/200
 - 19s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 125/200
 - 19s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 126/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 127/200
 - 19s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 128/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 129/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 130/200
 - 19s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 131/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 132/200
 - 19s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 133/200
 - 19s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 134/200
 - 19s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 135/200
 - 19s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 136/200
 - 19s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 137/200
 - 19s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 138/200
 - 19s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 139/200
 - 19s - loss: 0.0031 - val_loss: 0.0042
 - val_f1: 0.9938
Epoch 140/200
 - 19s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 141/200
 - 20s - loss: 0.0032 - val_loss: 0.0023
2020-01-08 16:45:17,279 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_140.pickle
 - val_f1: 0.9947
Epoch 142/200
 - 19s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 143/200
 - 19s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 144/200
 - 19s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 145/200
 - 19s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 146/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 147/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 148/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 149/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 150/200
 - 20s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 151/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 152/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9930
Epoch 153/200
 - 20s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 154/200
 - 19s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 155/200
 - 19s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 156/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 157/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 158/200
 - 19s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 159/200
 - 19s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 160/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 161/200
 - 20s - loss: 0.0031 - val_loss: 0.0024
2020-01-08 16:54:19,880 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_160.pickle
 - val_f1: 0.9947
Epoch 162/200
 - 19s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 163/200
 - 20s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 164/200
 - 19s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 165/200
 - 19s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 166/200
 - 19s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 167/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 168/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 169/200
 - 19s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9935
Epoch 170/200
 - 19s - loss: 0.0030 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 171/200
 - 20s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 172/200
 - 19s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 173/200
 - 19s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 174/200
 - 20s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 175/200
 - 20s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 176/200
 - 20s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 177/200
 - 19s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 178/200
 - 19s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 179/200
 - 19s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 180/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 181/200
 - 19s - loss: 0.0030 - val_loss: 0.0031
2020-01-08 17:03:23,602 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_2/ann_model_epoch_180.pickle
 - val_f1: 0.9940
Epoch 182/200
 - 19s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 183/200
 - 19s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 184/200
 - 20s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 185/200
 - 19s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 186/200
 - 19s - loss: 0.0031 - val_loss: 0.0026
2020-01-08 17:05:47,265 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 17:06:20,090 [INFO] Last epoch loss evaluation: train_loss = 0.002223, val_loss = 0.002242
2020-01-08 17:06:20,091 [INFO] Training complete. time_to_train = 5085.15 sec, 84.75 min
2020-01-08 17:06:20,094 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_2/best_model.pickle
2020-01-08 17:06:20,097 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_2/training_error_history.csv
2020-01-08 17:06:20,253 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_2/training_error_history.png
2020-01-08 17:06:20,391 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_2/training_f1_history.png
2020-01-08 17:06:20,391 [INFO] Making predictions on training, validation, testing data
2020-01-08 17:06:55,050 [INFO] Evaluating predictions (results)
2020-01-08 17:07:13,363 [INFO] Dataset: Testing. Classification report below
2020-01-08 17:07:13,363 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.96      0.39      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       1.00      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           1.00    565562
             macro avg       0.90      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 17:07:13,363 [INFO] Overall accuracy (micro avg): 0.9954293251668253
/home/nilwala/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-08 17:07:33,116 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8956                       0.7836                0.0010                   0.2164  0.7996
2  Weighted avg        0.9962         0.9952                       0.9954                0.0080                   0.0046  0.9951
2020-01-08 17:07:51,737 [INFO] Dataset: Validation. Classification report below
2020-01-08 17:07:51,737 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.96      0.08      0.14       301
        Web Attack XSS       0.75      0.02      0.04       131

              accuracy                           1.00    565562
             macro avg       0.96      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 17:07:51,737 [INFO] Overall accuracy (micro avg): 0.99550889204013
2020-01-08 17:08:11,759 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.9556                       0.7800                0.0010                   0.2200  0.7961
2  Weighted avg        0.9963         0.9955                       0.9955                0.0077                   0.0045  0.9951
2020-01-08 17:09:13,690 [INFO] Dataset: Training. Classification report below
2020-01-08 17:09:13,690 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.98      0.98      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.99      0.09      0.17       904
        Web Attack XSS       1.00      0.03      0.06       391

              accuracy                           1.00   1696684
             macro avg       0.98      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2020-01-08 17:09:13,690 [INFO] Overall accuracy (micro avg): 0.9955914006379503
2020-01-08 17:10:20,435 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.9804                       0.7836                0.0010                   0.2164  0.8019
2  Weighted avg        0.9963         0.9956                       0.9956                0.0078                   0.0044  0.9952
2020-01-08 17:10:20,487 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_2/ann_depth_ids17_layers_2_results.xlsx
2020-01-08 17:10:20,491 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-08 17:10:20,547 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_3
2020-01-08 17:10:20,547 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_3/run_log.log
2020-01-08 17:10:20,547 [INFO] ================= Running experiment no. 3  ================= 

2020-01-08 17:10:20,547 [INFO] Experiment parameters given below
2020-01-08 17:10:20,547 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_3'}
2020-01-08 17:10:20,547 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_3/tf_logs_run_2020_01_08-17_10_20
2020-01-08 17:10:20,547 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 17:10:20,548 [INFO] Reading X, y files
2020-01-08 17:10:20,548 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 17:10:24,559 [INFO] Reading complete. time_to_read=4.01 seconds
2020-01-08 17:10:24,559 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 17:10:25,923 [INFO] Reading complete. time_to_read=1.36 seconds
2020-01-08 17:10:25,923 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 17:10:27,295 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 17:10:27,295 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 17:10:27,529 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-08 17:10:27,529 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 17:10:27,606 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 17:10:27,606 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 17:10:27,683 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 17:10:30,463 [INFO] Initializing model
2020-01-08 17:10:30,724 [INFO] _________________________________________________________________
2020-01-08 17:10:30,724 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 17:10:30,724 [INFO] =================================================================
2020-01-08 17:10:30,724 [INFO] dense_6 (Dense)              (None, 64)                5056      
2020-01-08 17:10:30,724 [INFO] _________________________________________________________________
2020-01-08 17:10:30,724 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-08 17:10:30,724 [INFO] _________________________________________________________________
2020-01-08 17:10:30,724 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-08 17:10:30,724 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] dense_7 (Dense)              (None, 64)                4160      
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] dense_8 (Dense)              (None, 64)                4160      
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-08 17:10:30,725 [INFO] _________________________________________________________________
2020-01-08 17:10:30,725 [INFO] dense_9 (Dense)              (None, 12)                780       
2020-01-08 17:10:30,725 [INFO] =================================================================
2020-01-08 17:10:30,725 [INFO] Total params: 14,924
2020-01-08 17:10:30,726 [INFO] Trainable params: 14,540
2020-01-08 17:10:30,726 [INFO] Non-trainable params: 384
2020-01-08 17:10:30,726 [INFO] _________________________________________________________________
2020-01-08 17:10:30,726 [INFO] Training model
 - val_f1: 0.9947
Epoch 00186: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 26s - loss: 0.0198 - val_loss: 0.0109
 - val_f1: 0.9702
Epoch 2/200
 - 25s - loss: 0.0103 - val_loss: 0.0079
 - val_f1: 0.9810
Epoch 3/200
 - 25s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9771
Epoch 4/200
 - 25s - loss: 0.0082 - val_loss: 0.0068
 - val_f1: 0.9831
Epoch 5/200
 - 25s - loss: 0.0072 - val_loss: 0.0066
 - val_f1: 0.9827
Epoch 6/200
 - 25s - loss: 0.0062 - val_loss: 0.0053
 - val_f1: 0.9883
Epoch 7/200
 - 25s - loss: 0.0057 - val_loss: 0.0065
 - val_f1: 0.9817
Epoch 8/200
 - 25s - loss: 0.0054 - val_loss: 0.0044
 - val_f1: 0.9891
Epoch 9/200
 - 25s - loss: 0.0054 - val_loss: 0.0037
 - val_f1: 0.9908
Epoch 10/200
 - 25s - loss: 0.0053 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 11/200
 - 25s - loss: 0.0057 - val_loss: 0.0041
 - val_f1: 0.9896
Epoch 12/200
 - 25s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 13/200
 - 25s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9907
Epoch 14/200
 - 25s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 15/200
 - 25s - loss: 0.0055 - val_loss: 0.0037
 - val_f1: 0.9935
Epoch 16/200
 - 25s - loss: 0.0054 - val_loss: 0.0046
 - val_f1: 0.9891
Epoch 17/200
 - 25s - loss: 0.0046 - val_loss: 0.0058
 - val_f1: 0.9838
Epoch 18/200
 - 24s - loss: 0.0051 - val_loss: 0.0066
 - val_f1: 0.9845
Epoch 19/200
 - 25s - loss: 0.0048 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 20/200
 - 25s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9918
Epoch 21/200
 - 25s - loss: 0.0043 - val_loss: 0.0035
2020-01-08 17:22:18,684 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_20.pickle
 - val_f1: 0.9919
Epoch 22/200
 - 25s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 23/200
 - 25s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9921
Epoch 24/200
 - 24s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9894
Epoch 25/200
 - 25s - loss: 0.0045 - val_loss: 0.0064
 - val_f1: 0.9847
Epoch 26/200
 - 24s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 27/200
 - 25s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 28/200
 - 25s - loss: 0.0044 - val_loss: 0.0045
 - val_f1: 0.9900
Epoch 29/200
 - 25s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 30/200
 - 25s - loss: 0.0039 - val_loss: 0.0068
 - val_f1: 0.9769
Epoch 31/200
 - 25s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 32/200
 - 25s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 33/200
 - 25s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 34/200
 - 25s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9921
Epoch 35/200
 - 25s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 36/200
 - 25s - loss: 0.0037 - val_loss: 0.0094
 - val_f1: 0.9656
Epoch 37/200
 - 25s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 38/200
 - 25s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9924
Epoch 39/200
 - 24s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 40/200
 - 25s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9883
Epoch 41/200
 - 25s - loss: 0.0037 - val_loss: 0.0028
2020-01-08 17:33:37,478 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_40.pickle
 - val_f1: 0.9920
Epoch 42/200
 - 25s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9880
Epoch 43/200
 - 25s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 44/200
 - 25s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 45/200
 - 25s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9908
Epoch 46/200
 - 25s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9923
Epoch 47/200
 - 25s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 48/200
 - 25s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 49/200
 - 25s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 50/200
 - 25s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 51/200
 - 25s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 52/200
 - 25s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 53/200
 - 25s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 54/200
 - 24s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 55/200
 - 24s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 56/200
 - 25s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 57/200
 - 24s - loss: 0.0034 - val_loss: 0.0040
 - val_f1: 0.9902
Epoch 58/200
 - 25s - loss: 0.0034 - val_loss: 0.0054
 - val_f1: 0.9913
Epoch 59/200
 - 25s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 60/200
 - 25s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 61/200
 - 25s - loss: 0.0036 - val_loss: 0.0088
2020-01-08 17:44:55,680 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_60.pickle
 - val_f1: 0.9851
Epoch 62/200
 - 25s - loss: 0.0038 - val_loss: 0.0060
 - val_f1: 0.9854
Epoch 63/200
 - 24s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 64/200
 - 25s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 65/200
 - 25s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 66/200
 - 25s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 67/200
 - 25s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 68/200
 - 25s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 69/200
 - 25s - loss: 0.0034 - val_loss: 0.0078
 - val_f1: 0.9830
Epoch 70/200
 - 24s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 71/200
 - 25s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 72/200
 - 25s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 73/200
 - 25s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 74/200
 - 25s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9925
Epoch 75/200
 - 25s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 76/200
 - 25s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 77/200
 - 25s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 78/200
 - 25s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 79/200
 - 25s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 80/200
 - 24s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 81/200
 - 24s - loss: 0.0035 - val_loss: 0.0025
2020-01-08 17:56:13,294 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_80.pickle
 - val_f1: 0.9926
Epoch 82/200
 - 24s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 83/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 84/200
 - 24s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 85/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 86/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 87/200
 - 24s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9927
Epoch 88/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 89/200
 - 24s - loss: 0.0031 - val_loss: 0.0087
 - val_f1: 0.9850
Epoch 90/200
 - 24s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 91/200
 - 24s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 92/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 93/200
 - 24s - loss: 0.0031 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 94/200
 - 24s - loss: 0.0033 - val_loss: 0.0043
 - val_f1: 0.9905
Epoch 95/200
 - 24s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9926
Epoch 96/200
 - 24s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 97/200
 - 24s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 98/200
 - 24s - loss: 0.0031 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 99/200
 - 24s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 100/200
 - 24s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 101/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
2020-01-08 18:07:19,383 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_100.pickle
 - val_f1: 0.9948
Epoch 102/200
 - 24s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 103/200
 - 24s - loss: 0.0030 - val_loss: 0.0075
 - val_f1: 0.9851
Epoch 104/200
 - 24s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 105/200
 - 24s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 106/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9928
Epoch 107/200
 - 24s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 108/200
 - 24s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 109/200
 - 24s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 110/200
 - 24s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 111/200
 - 24s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 112/200
 - 24s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 113/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9926
Epoch 114/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 115/200
 - 24s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 116/200
 - 24s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 117/200
 - 24s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 118/200
 - 24s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 119/200
 - 24s - loss: 0.0031 - val_loss: 0.0052
 - val_f1: 0.9900
Epoch 120/200
 - 24s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 121/200
 - 24s - loss: 0.0029 - val_loss: 0.0022
2020-01-08 18:18:25,241 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_120.pickle
 - val_f1: 0.9949
Epoch 122/200
 - 24s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 123/200
 - 24s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 124/200
 - 24s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 125/200
 - 24s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 126/200
 - 24s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 127/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 128/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 129/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 130/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 131/200
 - 25s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 132/200
 - 25s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 133/200
 - 25s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9922
Epoch 134/200
 - 24s - loss: 0.0029 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 135/200
 - 25s - loss: 0.0030 - val_loss: 0.0104
 - val_f1: 0.9854
Epoch 136/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 137/200
 - 25s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 138/200
 - 25s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 139/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 140/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 141/200
 - 25s - loss: 0.0029 - val_loss: 0.0034
2020-01-08 18:29:40,446 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_140.pickle
 - val_f1: 0.9924
Epoch 142/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 143/200
 - 24s - loss: 0.0029 - val_loss: 0.0046
 - val_f1: 0.9898
Epoch 144/200
 - 25s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 145/200
 - 25s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 146/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 147/200
 - 24s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 148/200
 - 25s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 149/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 150/200
 - 25s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 151/200
 - 25s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 152/200
 - 25s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 153/200
 - 25s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 154/200
 - 25s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 155/200
 - 25s - loss: 0.0030 - val_loss: 0.0038
 - val_f1: 0.9925
Epoch 156/200
 - 25s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 157/200
 - 24s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 158/200
 - 25s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 159/200
 - 25s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 160/200
 - 25s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 161/200
 - 25s - loss: 0.0029 - val_loss: 0.0022
2020-01-08 18:40:57,947 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_160.pickle
 - val_f1: 0.9951
Epoch 162/200
 - 24s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9926
Epoch 163/200
 - 25s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 164/200
 - 24s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 165/200
 - 25s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 166/200
 - 24s - loss: 0.0029 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 167/200
 - 25s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 168/200
 - 24s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 169/200
 - 25s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 170/200
 - 25s - loss: 0.0030 - val_loss: 0.0050
 - val_f1: 0.9884
Epoch 171/200
 - 25s - loss: 0.0032 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 172/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9931
Epoch 173/200
 - 25s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 174/200
 - 24s - loss: 0.0030 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 175/200
 - 25s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 176/200
 - 24s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 177/200
 - 24s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 178/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 179/200
 - 24s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 180/200
 - 25s - loss: 0.0029 - val_loss: 0.0021
 - val_f1: 0.9953
Epoch 181/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
2020-01-08 18:52:15,418 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_3/ann_model_epoch_180.pickle
 - val_f1: 0.9950
Epoch 182/200
 - 25s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9927
Epoch 183/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 184/200
 - 25s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 185/200
 - 25s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 186/200
 - 25s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 187/200
 - 24s - loss: 0.0029 - val_loss: 0.0021
 - val_f1: 0.9950
Epoch 188/200
 - 25s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 189/200
 - 25s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9950
Epoch 190/200
 - 25s - loss: 0.0029 - val_loss: 0.0053
 - val_f1: 0.9882
Epoch 191/200
 - 25s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 192/200
 - 24s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 193/200
 - 24s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 194/200
 - 24s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 195/200
 - 25s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 196/200
 - 25s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 197/200
 - 25s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9951
Epoch 198/200
 - 25s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 199/200
 - 25s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 200/200
 - 25s - loss: 0.0027 - val_loss: 0.0021
2020-01-08 19:03:08,207 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 19:03:46,471 [INFO] Last epoch loss evaluation: train_loss = 0.002042, val_loss = 0.002069
2020-01-08 19:03:46,471 [INFO] Training complete. time_to_train = 6795.75 sec, 113.26 min
2020-01-08 19:03:46,476 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_3/best_model.pickle
2020-01-08 19:03:46,478 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_3/training_error_history.csv
2020-01-08 19:03:46,645 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_3/training_error_history.png
2020-01-08 19:03:46,795 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_3/training_f1_history.png
2020-01-08 19:03:46,795 [INFO] Making predictions on training, validation, testing data
2020-01-08 19:04:29,239 [INFO] Evaluating predictions (results)
2020-01-08 19:04:47,574 [INFO] Dataset: Testing. Classification report below
2020-01-08 19:04:47,574 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       1.00      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           1.00    565562
             macro avg       0.90      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 19:04:47,574 [INFO] Overall accuracy (micro avg): 0.9961189047354667
2020-01-08 19:05:07,353 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9994         0.8995                       0.7838                0.0008                   0.2162  0.7992
2  Weighted avg        0.9968         0.9959                       0.9961                0.0063                   0.0039  0.9957
2020-01-08 19:05:25,914 [INFO] Dataset: Validation. Classification report below
2020-01-08 19:05:25,914 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.34      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.95      0.07      0.13       301
        Web Attack XSS       1.00      0.02      0.04       131

              accuracy                           1.00    565562
             macro avg       0.98      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 19:05:25,914 [INFO] Overall accuracy (micro avg): 0.9961171365827266
2020-01-08 19:05:45,907 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9994         0.9781                       0.7794                0.0008                   0.2206  0.7948
2  Weighted avg        0.9968         0.9961                       0.9961                0.0062                   0.0039  0.9957
2020-01-08 19:06:47,806 [INFO] Dataset: Training. Classification report below
2020-01-08 19:06:47,806 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.99      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.98      0.99      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.99      0.09      0.16       904
        Web Attack XSS       0.92      0.03      0.06       391

              accuracy                           1.00   1696684
             macro avg       0.98      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2020-01-08 19:06:47,806 [INFO] Overall accuracy (micro avg): 0.9962403134584873
2020-01-08 19:07:54,495 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0003                   0.0038  0.9962
1     Macro avg        0.9994         0.9767                       0.7844                0.0008                   0.2156  0.8021
2  Weighted avg        0.9969         0.9963                       0.9962                0.0061                   0.0038  0.9958
2020-01-08 19:07:54,546 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_3/ann_depth_ids17_layers_3_results.xlsx
2020-01-08 19:07:54,550 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-08 19:07:54,588 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_4
2020-01-08 19:07:54,588 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_4/run_log.log
2020-01-08 19:07:54,589 [INFO] ================= Running experiment no. 4  ================= 

2020-01-08 19:07:54,589 [INFO] Experiment parameters given below
2020-01-08 19:07:54,589 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_4'}
2020-01-08 19:07:54,589 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_4/tf_logs_run_2020_01_08-19_07_54
2020-01-08 19:07:54,589 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 19:07:54,589 [INFO] Reading X, y files
2020-01-08 19:07:54,589 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 19:07:58,653 [INFO] Reading complete. time_to_read=4.06 seconds
2020-01-08 19:07:58,654 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 19:08:00,027 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 19:08:00,027 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 19:08:01,403 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 19:08:01,403 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 19:08:01,630 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-08 19:08:01,631 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 19:08:01,709 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 19:08:01,709 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 19:08:01,786 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 19:08:04,600 [INFO] Initializing model
2020-01-08 19:08:04,942 [INFO] _________________________________________________________________
2020-01-08 19:08:04,942 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 19:08:04,943 [INFO] =================================================================
2020-01-08 19:08:04,943 [INFO] dense_10 (Dense)             (None, 64)                5056      
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] dense_11 (Dense)             (None, 64)                4160      
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,943 [INFO] dense_12 (Dense)             (None, 64)                4160      
2020-01-08 19:08:04,943 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] batch_normalization_9 (Batch (None, 64)                256       
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] dropout_9 (Dropout)          (None, 64)                0         
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] dense_13 (Dense)             (None, 64)                4160      
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,944 [INFO] dense_14 (Dense)             (None, 12)                780       
2020-01-08 19:08:04,944 [INFO] =================================================================
2020-01-08 19:08:04,944 [INFO] Total params: 19,340
2020-01-08 19:08:04,944 [INFO] Trainable params: 18,828
2020-01-08 19:08:04,944 [INFO] Non-trainable params: 512
2020-01-08 19:08:04,944 [INFO] _________________________________________________________________
2020-01-08 19:08:04,945 [INFO] Training model
 - val_f1: 0.9957
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 33s - loss: 0.0207 - val_loss: 0.0092
 - val_f1: 0.9748
Epoch 2/200
 - 31s - loss: 0.0104 - val_loss: 0.0080
 - val_f1: 0.9828
Epoch 3/200
 - 31s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 4/200
 - 31s - loss: 0.0075 - val_loss: 0.0066
 - val_f1: 0.9858
Epoch 5/200
 - 31s - loss: 0.0066 - val_loss: 0.0074
 - val_f1: 0.9820
Epoch 6/200
 - 31s - loss: 0.0071 - val_loss: 0.0057
 - val_f1: 0.9845
Epoch 7/200
 - 31s - loss: 0.0064 - val_loss: 0.0069
 - val_f1: 0.9820
Epoch 8/200
 - 31s - loss: 0.0067 - val_loss: 0.0075
 - val_f1: 0.9819
Epoch 9/200
 - 31s - loss: 0.0056 - val_loss: 0.0078
 - val_f1: 0.9789
Epoch 10/200
 - 31s - loss: 0.0067 - val_loss: 0.0065
 - val_f1: 0.9818
Epoch 11/200
 - 31s - loss: 0.0064 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 12/200
 - 31s - loss: 0.0058 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 13/200
 - 31s - loss: 0.0057 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 14/200
 - 31s - loss: 0.0059 - val_loss: 0.0071
 - val_f1: 0.9798
Epoch 15/200
 - 31s - loss: 0.0066 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 16/200
 - 31s - loss: 0.0060 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 17/200
 - 31s - loss: 0.0051 - val_loss: 0.0048
 - val_f1: 0.9888
Epoch 18/200
 - 31s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 19/200
 - 31s - loss: 0.0047 - val_loss: 0.0083
 - val_f1: 0.9682
Epoch 20/200
 - 31s - loss: 0.0048 - val_loss: 0.0054
 - val_f1: 0.9840
Epoch 21/200
 - 31s - loss: 0.0046 - val_loss: 0.0062
2020-01-08 19:22:41,099 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_20.pickle
 - val_f1: 0.9883
Epoch 22/200
 - 31s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9890
Epoch 23/200
 - 31s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 24/200
 - 31s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 25/200
 - 31s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 26/200
 - 31s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 27/200
 - 31s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9920
Epoch 28/200
 - 31s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9900
Epoch 29/200
 - 31s - loss: 0.0047 - val_loss: 0.0045
 - val_f1: 0.9893
Epoch 30/200
 - 31s - loss: 0.0046 - val_loss: 0.0050
 - val_f1: 0.9883
Epoch 31/200
 - 31s - loss: 0.0044 - val_loss: 0.0044
 - val_f1: 0.9882
Epoch 32/200
 - 31s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 33/200
 - 31s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 34/200
 - 31s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 35/200
 - 31s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9881
Epoch 36/200
 - 31s - loss: 0.0043 - val_loss: 0.0082
 - val_f1: 0.9807
Epoch 37/200
 - 31s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 38/200
 - 31s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 39/200
 - 31s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9897
Epoch 40/200
 - 31s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9924
Epoch 41/200
 - 31s - loss: 0.0040 - val_loss: 0.0029
2020-01-08 19:36:42,062 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_40.pickle
 - val_f1: 0.9926
Epoch 42/200
 - 31s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 43/200
 - 31s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 44/200
 - 31s - loss: 0.0038 - val_loss: 0.0202
 - val_f1: 0.9635
Epoch 45/200
 - 31s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 46/200
 - 31s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 47/200
 - 31s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 48/200
 - 31s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 49/200
 - 31s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 50/200
 - 31s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 51/200
 - 31s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 52/200
 - 31s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 53/200
 - 31s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 54/200
 - 31s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 55/200
 - 31s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9922
Epoch 56/200
 - 31s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 57/200
 - 31s - loss: 0.0038 - val_loss: 0.0113
 - val_f1: 0.9778
Epoch 58/200
 - 31s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 59/200
 - 31s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 60/200
 - 31s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 61/200
 - 31s - loss: 0.0035 - val_loss: 0.0027
2020-01-08 19:50:42,722 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_60.pickle
 - val_f1: 0.9926
Epoch 62/200
 - 31s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 63/200
 - 31s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 64/200
 - 31s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 65/200
 - 31s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 66/200
 - 31s - loss: 0.0039 - val_loss: 0.0094
 - val_f1: 0.9722
Epoch 67/200
 - 31s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 68/200
 - 31s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 69/200
 - 31s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 70/200
 - 31s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 71/200
 - 31s - loss: 0.0034 - val_loss: 0.0040
 - val_f1: 0.9903
Epoch 72/200
 - 31s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 73/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 74/200
 - 31s - loss: 0.0034 - val_loss: 0.0091
 - val_f1: 0.9816
Epoch 75/200
 - 31s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 76/200
 - 31s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 77/200
 - 31s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9925
Epoch 78/200
 - 31s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 79/200
 - 31s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 80/200
 - 31s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 81/200
 - 31s - loss: 0.0039 - val_loss: 0.0029
2020-01-08 20:04:45,993 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_80.pickle
 - val_f1: 0.9925
Epoch 82/200
 - 31s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 83/200
 - 31s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 84/200
 - 31s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 85/200
 - 31s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 86/200
 - 31s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 87/200
 - 31s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 88/200
 - 31s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 89/200
 - 31s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 90/200
 - 31s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 91/200
 - 31s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 92/200
 - 31s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 93/200
 - 31s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 94/200
 - 31s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 95/200
 - 31s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 96/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 97/200
 - 31s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 98/200
 - 31s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 99/200
 - 31s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 100/200
 - 31s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 101/200
 - 31s - loss: 0.0036 - val_loss: 0.0027
2020-01-08 20:18:48,724 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_100.pickle
 - val_f1: 0.9928
Epoch 102/200
 - 31s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 103/200
 - 31s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 104/200
 - 31s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 105/200
 - 31s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 106/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 107/200
 - 31s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 108/200
 - 31s - loss: 0.0034 - val_loss: 0.0103
 - val_f1: 0.9829
Epoch 109/200
 - 31s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 110/200
 - 31s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 111/200
 - 31s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 112/200
 - 31s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9918
Epoch 113/200
 - 31s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9929
Epoch 114/200
 - 31s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 115/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 116/200
 - 31s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 117/200
 - 31s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 118/200
 - 31s - loss: 0.0034 - val_loss: 0.0041
 - val_f1: 0.9888
Epoch 119/200
 - 31s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9918
Epoch 120/200
 - 31s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9924
Epoch 121/200
 - 31s - loss: 0.0035 - val_loss: 0.0027
2020-01-08 20:32:49,829 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_4/ann_model_epoch_120.pickle
 - val_f1: 0.9941
Epoch 122/200
 - 31s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 123/200
 - 31s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 124/200
 - 31s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 125/200
 - 31s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 126/200
 - 31s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 127/200
 - 31s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 128/200
 - 31s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 129/200
 - 31s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 130/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 131/200
 - 31s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 132/200
 - 31s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 133/200
 - 31s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 134/200
 - 31s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 135/200
 - 31s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9923
Epoch 136/200
 - 31s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 137/200
 - 31s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 138/200
 - 31s - loss: 0.0032 - val_loss: 0.0026
2020-01-08 20:44:55,329 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 20:45:40,841 [INFO] Last epoch loss evaluation: train_loss = 0.002395, val_loss = 0.002421
2020-01-08 20:45:40,841 [INFO] Training complete. time_to_train = 5855.90 sec, 97.60 min
2020-01-08 20:45:40,848 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_4/best_model.pickle
2020-01-08 20:45:40,850 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_4/training_error_history.csv
2020-01-08 20:45:41,012 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_4/training_error_history.png
2020-01-08 20:45:41,158 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_4/training_f1_history.png
2020-01-08 20:45:41,158 [INFO] Making predictions on training, validation, testing data
2020-01-08 20:46:32,515 [INFO] Evaluating predictions (results)
2020-01-08 20:46:50,850 [INFO] Dataset: Testing. Classification report below
2020-01-08 20:46:50,850 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.96      0.97      0.96      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 20:46:50,850 [INFO] Overall accuracy (micro avg): 0.9945912207680149
2020-01-08 20:47:10,629 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0005                   0.0054  0.9946
1     Macro avg        0.9991         0.8910                       0.7822                0.0011                   0.2178  0.7954
2  Weighted avg        0.9955         0.9944                       0.9946                0.0078                   0.0054  0.9942
2020-01-08 20:47:29,200 [INFO] Dataset: Validation. Classification report below
2020-01-08 20:47:29,200 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.96      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.95      1180
Web Attack Brute Force       0.91      0.07      0.13       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.99    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 20:47:29,200 [INFO] Overall accuracy (micro avg): 0.9946884691687207
2020-01-08 20:47:49,221 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8833                       0.7764                0.0011                   0.2236  0.7878
2  Weighted avg        0.9956         0.9945                       0.9947                0.0076                   0.0053  0.9943
2020-01-08 20:48:51,148 [INFO] Dataset: Training. Classification report below
2020-01-08 20:48:51,148 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.97      0.98      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.95      0.98      0.96      3538
Web Attack Brute Force       0.99      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.99   1696684
             macro avg       0.89      0.78      0.79   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-08 20:48:51,148 [INFO] Overall accuracy (micro avg): 0.9947385606276714
2020-01-08 20:49:57,909 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8931                       0.7801                0.0011                   0.2199  0.7937
2  Weighted avg        0.9956         0.9946                       0.9947                0.0077                   0.0053  0.9943
2020-01-08 20:49:57,961 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_4/ann_depth_ids17_layers_4_results.xlsx
2020-01-08 20:49:57,965 [INFO] ================= Finished running experiment no. 4 ================= 

2020-01-08 20:49:58,004 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_5
2020-01-08 20:49:58,005 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_5/run_log.log
2020-01-08 20:49:58,005 [INFO] ================= Running experiment no. 5  ================= 

2020-01-08 20:49:58,005 [INFO] Experiment parameters given below
2020-01-08 20:49:58,005 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_5'}
2020-01-08 20:49:58,005 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_5/tf_logs_run_2020_01_08-20_49_58
2020-01-08 20:49:58,005 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 20:49:58,005 [INFO] Reading X, y files
2020-01-08 20:49:58,005 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 20:50:02,092 [INFO] Reading complete. time_to_read=4.09 seconds
2020-01-08 20:50:02,092 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 20:50:03,478 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-08 20:50:03,478 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 20:50:04,857 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 20:50:04,858 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 20:50:05,089 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-08 20:50:05,089 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 20:50:05,166 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 20:50:05,166 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 20:50:05,243 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 20:50:08,099 [INFO] Initializing model
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,529 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 20:50:08,529 [INFO] =================================================================
2020-01-08 20:50:08,529 [INFO] dense_15 (Dense)             (None, 64)                5056      
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,529 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,529 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,529 [INFO] dense_16 (Dense)             (None, 64)                4160      
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,529 [INFO] batch_normalization_12 (Batc (None, 64)                256       
2020-01-08 20:50:08,529 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dropout_12 (Dropout)         (None, 64)                0         
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dense_17 (Dense)             (None, 64)                4160      
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dense_18 (Dense)             (None, 64)                4160      
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,530 [INFO] dense_19 (Dense)             (None, 64)                4160      
2020-01-08 20:50:08,530 [INFO] _________________________________________________________________
2020-01-08 20:50:08,531 [INFO] batch_normalization_15 (Batc (None, 64)                256       
2020-01-08 20:50:08,531 [INFO] _________________________________________________________________
2020-01-08 20:50:08,531 [INFO] dropout_15 (Dropout)         (None, 64)                0         
2020-01-08 20:50:08,531 [INFO] _________________________________________________________________
2020-01-08 20:50:08,531 [INFO] dense_20 (Dense)             (None, 12)                780       
2020-01-08 20:50:08,531 [INFO] =================================================================
2020-01-08 20:50:08,531 [INFO] Total params: 23,756
2020-01-08 20:50:08,531 [INFO] Trainable params: 23,116
2020-01-08 20:50:08,531 [INFO] Non-trainable params: 640
2020-01-08 20:50:08,531 [INFO] _________________________________________________________________
2020-01-08 20:50:08,531 [INFO] Training model
 - val_f1: 0.9928
Epoch 00138: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 39s - loss: 0.0216 - val_loss: 0.0096
 - val_f1: 0.9733
Epoch 2/200
 - 37s - loss: 0.0110 - val_loss: 0.0088
 - val_f1: 0.9750
Epoch 3/200
 - 37s - loss: 0.0095 - val_loss: 0.0078
 - val_f1: 0.9797
Epoch 4/200
 - 37s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9822
Epoch 5/200
 - 37s - loss: 0.0070 - val_loss: 0.0045
 - val_f1: 0.9900
Epoch 6/200
 - 37s - loss: 0.0064 - val_loss: 0.0044
 - val_f1: 0.9894
Epoch 7/200
 - 37s - loss: 0.0069 - val_loss: 0.0044
 - val_f1: 0.9898
Epoch 8/200
 - 37s - loss: 0.0061 - val_loss: 0.0044
 - val_f1: 0.9900
Epoch 9/200
 - 37s - loss: 0.0062 - val_loss: 0.0044
 - val_f1: 0.9904
Epoch 10/200
 - 37s - loss: 0.0054 - val_loss: 0.0042
 - val_f1: 0.9893
Epoch 11/200
 - 37s - loss: 0.0054 - val_loss: 0.0044
 - val_f1: 0.9889
Epoch 12/200
 - 37s - loss: 0.0052 - val_loss: 0.0059
 - val_f1: 0.9838
Epoch 13/200
 - 37s - loss: 0.0053 - val_loss: 0.0053
 - val_f1: 0.9861
Epoch 14/200
 - 37s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 15/200
 - 37s - loss: 0.0050 - val_loss: 0.0061
 - val_f1: 0.9835
Epoch 16/200
 - 37s - loss: 0.0048 - val_loss: 0.0043
 - val_f1: 0.9895
Epoch 17/200
 - 37s - loss: 0.0052 - val_loss: 0.0045
 - val_f1: 0.9879
Epoch 18/200
 - 37s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 19/200
 - 37s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9918
Epoch 20/200
 - 37s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 21/200
 - 37s - loss: 0.0044 - val_loss: 0.0036
2020-01-08 21:07:34,250 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_20.pickle
 - val_f1: 0.9908
Epoch 22/200
 - 37s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 23/200
 - 37s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9879
Epoch 24/200
 - 37s - loss: 0.0048 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 25/200
 - 36s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 26/200
 - 36s - loss: 0.0045 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 27/200
 - 36s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 28/200
 - 37s - loss: 0.0047 - val_loss: 0.0067
 - val_f1: 0.9817
Epoch 29/200
 - 36s - loss: 0.0048 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 30/200
 - 36s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9896
Epoch 31/200
 - 36s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 32/200
 - 36s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 33/200
 - 36s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 34/200
 - 36s - loss: 0.0040 - val_loss: 0.0061
 - val_f1: 0.9825
Epoch 35/200
 - 36s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 36/200
 - 36s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 37/200
 - 36s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 38/200
 - 36s - loss: 0.0042 - val_loss: 0.0066
 - val_f1: 0.9813
Epoch 39/200
 - 36s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9922
Epoch 40/200
 - 36s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 41/200
 - 36s - loss: 0.0042 - val_loss: 0.0032
2020-01-08 21:24:03,448 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_40.pickle
 - val_f1: 0.9931
Epoch 42/200
 - 36s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 43/200
 - 36s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 44/200
 - 36s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 45/200
 - 36s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9920
Epoch 46/200
 - 36s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 47/200
 - 36s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 48/200
 - 36s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9906
Epoch 49/200
 - 36s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 50/200
 - 36s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 51/200
 - 36s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 52/200
 - 36s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 53/200
 - 36s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 54/200
 - 36s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 55/200
 - 36s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 56/200
 - 36s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 57/200
 - 36s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 58/200
 - 36s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 59/200
 - 36s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 60/200
 - 36s - loss: 0.0039 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 61/200
 - 36s - loss: 0.0039 - val_loss: 0.0029
2020-01-08 21:40:30,237 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_60.pickle
 - val_f1: 0.9930
Epoch 62/200
 - 36s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 63/200
 - 36s - loss: 0.0037 - val_loss: 0.0158
 - val_f1: 0.9646
Epoch 64/200
 - 36s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 65/200
 - 36s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 66/200
 - 36s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9912
Epoch 67/200
 - 36s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9911
Epoch 68/200
 - 36s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 69/200
 - 36s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 70/200
 - 36s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 71/200
 - 36s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 72/200
 - 36s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 73/200
 - 36s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9904
Epoch 74/200
 - 36s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 75/200
 - 36s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 76/200
 - 36s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 77/200
 - 36s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 78/200
 - 36s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 79/200
 - 36s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 80/200
 - 36s - loss: 0.0035 - val_loss: 0.0042
 - val_f1: 0.9894
Epoch 81/200
 - 36s - loss: 0.0035 - val_loss: 0.0028
2020-01-08 21:56:55,887 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_80.pickle
 - val_f1: 0.9936
Epoch 82/200
 - 37s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 83/200
 - 36s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 84/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 85/200
 - 36s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 86/200
 - 36s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 87/200
 - 36s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 88/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 89/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 90/200
 - 36s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 91/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 92/200
 - 36s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 93/200
 - 36s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 94/200
 - 36s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 95/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 96/200
 - 36s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 97/200
 - 36s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 98/200
 - 36s - loss: 0.0033 - val_loss: 0.0040
 - val_f1: 0.9907
Epoch 99/200
 - 36s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 100/200
 - 36s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 101/200
 - 36s - loss: 0.0033 - val_loss: 0.0043
2020-01-08 22:13:23,556 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_100.pickle
 - val_f1: 0.9884
Epoch 102/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 103/200
 - 36s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 104/200
 - 36s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9909
Epoch 105/200
 - 36s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 106/200
 - 36s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 107/200
 - 36s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 108/200
 - 36s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 109/200
 - 36s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 110/200
 - 36s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 111/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 112/200
 - 36s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 113/200
 - 36s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 114/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 115/200
 - 36s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 116/200
 - 36s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 117/200
 - 36s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 118/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 119/200
 - 36s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 120/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 121/200
 - 36s - loss: 0.0031 - val_loss: 0.0027
2020-01-08 22:29:49,993 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_120.pickle
 - val_f1: 0.9933
Epoch 122/200
 - 36s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 123/200
 - 36s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 124/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 125/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 126/200
 - 36s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 127/200
 - 36s - loss: 0.0031 - val_loss: 0.0040
 - val_f1: 0.9897
Epoch 128/200
 - 36s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 129/200
 - 36s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 130/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 131/200
 - 36s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 132/200
 - 36s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 133/200
 - 36s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 134/200
 - 36s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 135/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 136/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 137/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 138/200
 - 37s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 139/200
 - 36s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 140/200
 - 36s - loss: 0.0031 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 141/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
2020-01-08 22:46:17,097 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_5/ann_model_epoch_140.pickle
 - val_f1: 0.9943
Epoch 142/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 143/200
 - 37s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 144/200
 - 36s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 145/200
 - 36s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 146/200
 - 36s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 147/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 148/200
 - 36s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 149/200
 - 37s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9926
Epoch 150/200
 - 36s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 151/200
 - 36s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 152/200
 - 36s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 153/200
 - 36s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 154/200
 - 36s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 155/200
 - 36s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 156/200
 - 36s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 157/200
 - 36s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 158/200
 - 36s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 159/200
 - 36s - loss: 0.0030 - val_loss: 0.0031
2020-01-08 23:01:20,190 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 23:02:14,817 [INFO] Last epoch loss evaluation: train_loss = 0.002376, val_loss = 0.002401
2020-01-08 23:02:14,818 [INFO] Training complete. time_to_train = 7926.29 sec, 132.10 min
2020-01-08 23:02:14,826 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_5/best_model.pickle
2020-01-08 23:02:14,828 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_5/training_error_history.csv
2020-01-08 23:02:14,993 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_5/training_error_history.png
2020-01-08 23:02:15,141 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_5/training_f1_history.png
2020-01-08 23:02:15,141 [INFO] Making predictions on training, validation, testing data
2020-01-08 23:03:16,268 [INFO] Evaluating predictions (results)
2020-01-08 23:03:34,592 [INFO] Dataset: Testing. Classification report below
2020-01-08 23:03:34,592 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.95      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 23:03:34,592 [INFO] Overall accuracy (micro avg): 0.9947291366817431
2020-01-08 23:03:54,362 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8939                       0.7801                0.0012                   0.2199  0.7956
2  Weighted avg        0.9956         0.9945                       0.9947                0.0096                   0.0053  0.9943
2020-01-08 23:04:12,913 [INFO] Dataset: Validation. Classification report below
2020-01-08 23:04:12,913 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.35      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.98      0.95      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1180
Web Attack Brute Force       0.87      0.07      0.12       301
        Web Attack XSS       0.00      0.00      0.00       131

              accuracy                           0.99    565562
             macro avg       0.88      0.77      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 23:04:12,913 [INFO] Overall accuracy (micro avg): 0.9948511392208105
2020-01-08 23:04:32,883 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8836                       0.7724                0.0012                   0.2276  0.7867
2  Weighted avg        0.9957         0.9946                       0.9949                0.0094                   0.0051  0.9944
2020-01-08 23:05:34,783 [INFO] Dataset: Training. Classification report below
2020-01-08 23:05:34,783 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.98    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.96      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.99      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

              accuracy                           0.99   1696684
             macro avg       0.90      0.78      0.79   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-08 23:05:34,783 [INFO] Overall accuracy (micro avg): 0.9949548649011837
2020-01-08 23:06:41,500 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.8955                       0.7781                0.0012                   0.2219  0.7938
2  Weighted avg        0.9958         0.9948                       0.9950                0.0093                   0.0050  0.9946
2020-01-08 23:06:41,552 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_5/ann_depth_ids17_layers_5_results.xlsx
2020-01-08 23:06:41,556 [INFO] ================= Finished running experiment no. 5 ================= 

2020-01-08 23:06:41,594 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9925
Epoch 00159: early stopping
Using TensorFlow backend.
2020-01-08 16:16:43,858 [INFO] Read 5 experiments from file: experiment_specs/additional_exps/ann_depth.csv
2020-01-08 16:16:43,859 [INFO] ================= Started running experiments ================= 

2020-01-08 16:16:43,859 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_6
2020-01-08 16:16:43,859 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_6/run_log.log
2020-01-08 16:16:43,859 [INFO] ================= Running experiment no. 6  ================= 

2020-01-08 16:16:43,859 [INFO] Experiment parameters given below
2020-01-08 16:16:43,859 [INFO] 
{'experiment_num': 6, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_6', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_6'}
2020-01-08 16:16:43,859 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_6/tf_logs_run_2020_01_08-16_16_43
2020-01-08 16:16:43,859 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 16:16:43,860 [INFO] Reading X, y files
2020-01-08 16:16:43,860 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 16:16:47,921 [INFO] Reading complete. time_to_read=4.06 seconds
2020-01-08 16:16:47,921 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 16:16:49,303 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 16:16:49,303 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 16:16:50,686 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 16:16:50,686 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 16:16:50,914 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-08 16:16:50,914 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 16:16:50,982 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 16:16:50,982 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 16:16:51,049 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 16:16:54,252 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-08 16:16:54,265 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 16:16:54,328 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 16:16:54,726 [INFO] _________________________________________________________________
2020-01-08 16:16:54,726 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 16:16:54,726 [INFO] =================================================================
2020-01-08 16:16:54,726 [INFO] dense_1 (Dense)              (None, 64)                5056      
2020-01-08 16:16:54,726 [INFO] _________________________________________________________________
2020-01-08 16:16:54,726 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 16:16:54,726 [INFO] _________________________________________________________________
2020-01-08 16:16:54,726 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,726 [INFO] _________________________________________________________________
2020-01-08 16:16:54,726 [INFO] dense_2 (Dense)              (None, 64)                4160      
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] dense_3 (Dense)              (None, 64)                4160      
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] dense_4 (Dense)              (None, 64)                4160      
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,727 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,727 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] dense_5 (Dense)              (None, 64)                4160      
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] dense_6 (Dense)              (None, 64)                4160      
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-08 16:16:54,728 [INFO] _________________________________________________________________
2020-01-08 16:16:54,728 [INFO] dense_7 (Dense)              (None, 12)                780       
2020-01-08 16:16:54,728 [INFO] =================================================================
2020-01-08 16:16:54,729 [INFO] Total params: 28,172
2020-01-08 16:16:54,729 [INFO] Trainable params: 27,404
2020-01-08 16:16:54,729 [INFO] Non-trainable params: 768
2020-01-08 16:16:54,729 [INFO] _________________________________________________________________
2020-01-08 16:16:54,729 [INFO] Training model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 16:16:55,103 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 16:16:56.245699: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-08 16:16:56.264722: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2020-01-08 16:16:56.264907: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x270c9b0 executing computations on platform Host. Devices:
2020-01-08 16:16:56.264942: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 40s - loss: 0.0230 - val_loss: 0.0111
 - val_f1: 0.9702
Epoch 2/200
 - 39s - loss: 0.0111 - val_loss: 0.0087
 - val_f1: 0.9746
Epoch 3/200
 - 39s - loss: 0.0089 - val_loss: 0.0096
 - val_f1: 0.9746
Epoch 4/200
 - 39s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9833
Epoch 5/200
 - 39s - loss: 0.0070 - val_loss: 0.0074
 - val_f1: 0.9781
Epoch 6/200
 - 39s - loss: 0.0059 - val_loss: 0.0039
 - val_f1: 0.9894
Epoch 7/200
 - 39s - loss: 0.0069 - val_loss: 0.0052
 - val_f1: 0.9873
Epoch 8/200
 - 39s - loss: 0.0056 - val_loss: 0.0051
 - val_f1: 0.9882
Epoch 9/200
 - 39s - loss: 0.0056 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 10/200
 - 39s - loss: 0.0052 - val_loss: 0.0035
 - val_f1: 0.9911
Epoch 11/200
 - 39s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 12/200
 - 39s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9877
Epoch 13/200
 - 39s - loss: 0.0053 - val_loss: 0.0086
 - val_f1: 0.9778
Epoch 14/200
 - 39s - loss: 0.0048 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 15/200
 - 39s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 16/200
 - 39s - loss: 0.0044 - val_loss: 0.0077
 - val_f1: 0.9809
Epoch 17/200
 - 39s - loss: 0.0044 - val_loss: 0.0151
 - val_f1: 0.9576
Epoch 18/200
 - 39s - loss: 0.0045 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 19/200
 - 39s - loss: 0.0044 - val_loss: 0.0047
 - val_f1: 0.9906
Epoch 20/200
 - 39s - loss: 0.0042 - val_loss: 0.0091
 - val_f1: 0.9820
Epoch 21/200
 - 39s - loss: 0.0043 - val_loss: 0.0028
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 16:33:23,996 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_20.pickle
 - val_f1: 0.9937
Epoch 22/200
 - 39s - loss: 0.0042 - val_loss: 0.0180
 - val_f1: 0.9638
Epoch 23/200
 - 39s - loss: 0.0042 - val_loss: 0.0043
 - val_f1: 0.9892
Epoch 24/200
 - 39s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9913
Epoch 25/200
 - 39s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 26/200
 - 39s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 27/200
 - 39s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 28/200
 - 39s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 29/200
 - 39s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 30/200
 - 39s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 31/200
 - 39s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9875
Epoch 32/200
 - 39s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 33/200
 - 39s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 34/200
 - 39s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 35/200
 - 39s - loss: 0.0041 - val_loss: 0.0026
 - val_f1: 0.9923
Epoch 36/200
 - 39s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 37/200
 - 39s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 38/200
 - 39s - loss: 0.0040 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 39/200
 - 39s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 40/200
 - 39s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 41/200
 - 39s - loss: 0.0036 - val_loss: 0.0027
2020-01-08 16:49:13,325 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_40.pickle
 - val_f1: 0.9939
Epoch 42/200
 - 39s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 43/200
 - 39s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 44/200
 - 39s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9874
Epoch 45/200
 - 39s - loss: 0.0039 - val_loss: 0.0075
 - val_f1: 0.9836
Epoch 46/200
 - 39s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 47/200
 - 39s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 48/200
 - 39s - loss: 0.0038 - val_loss: 0.0064
 - val_f1: 0.9745
Epoch 49/200
 - 39s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9915
Epoch 50/200
 - 39s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 51/200
 - 39s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 52/200
 - 39s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9889
Epoch 53/200
 - 39s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 54/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 55/200
 - 39s - loss: 0.0035 - val_loss: 0.0062
 - val_f1: 0.9862
Epoch 56/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 57/200
 - 39s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 58/200
 - 39s - loss: 0.0034 - val_loss: 0.0060
 - val_f1: 0.9873
Epoch 59/200
 - 39s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 60/200
 - 39s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 61/200
 - 39s - loss: 0.0035 - val_loss: 0.0030
2020-01-08 17:05:03,233 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_60.pickle
 - val_f1: 0.9916
Epoch 62/200
 - 39s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 63/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 64/200
 - 39s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9930
Epoch 65/200
 - 39s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 66/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9927
Epoch 67/200
 - 39s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 68/200
 - 39s - loss: 0.0034 - val_loss: 0.0041
 - val_f1: 0.9893
Epoch 69/200
 - 39s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 70/200
 - 39s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 71/200
 - 39s - loss: 0.0035 - val_loss: 0.0056
 - val_f1: 0.9908
Epoch 72/200
 - 39s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 73/200
 - 39s - loss: 0.0033 - val_loss: 0.0053
 - val_f1: 0.9896
Epoch 74/200
 - 39s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 75/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 76/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 77/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 78/200
 - 39s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 79/200
 - 39s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 80/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 81/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
2020-01-08 17:20:51,895 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_80.pickle
 - val_f1: 0.9942
Epoch 82/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 83/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 84/200
 - 39s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 85/200
 - 39s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 86/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 87/200
 - 39s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 88/200
 - 39s - loss: 0.0033 - val_loss: 0.0039
 - val_f1: 0.9896
Epoch 89/200
 - 39s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 90/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 91/200
 - 39s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 92/200
 - 39s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 93/200
 - 39s - loss: 0.0031 - val_loss: 0.0095
 - val_f1: 0.9842
Epoch 94/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 95/200
 - 39s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9930
Epoch 96/200
 - 39s - loss: 0.0032 - val_loss: 0.0062
 - val_f1: 0.9875
Epoch 97/200
 - 39s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 98/200
 - 39s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 99/200
 - 39s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9928
Epoch 100/200
 - 39s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 101/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
2020-01-08 17:36:40,403 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_100.pickle
 - val_f1: 0.9952
Epoch 102/200
 - 39s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 103/200
 - 39s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 104/200
 - 39s - loss: 0.0030 - val_loss: 0.0047
 - val_f1: 0.9905
Epoch 105/200
 - 39s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 106/200
 - 39s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9929
Epoch 107/200
 - 39s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 108/200
 - 39s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9921
Epoch 109/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 110/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 111/200
 - 39s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9928
Epoch 112/200
 - 39s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 113/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 114/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 115/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 116/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 117/200
 - 39s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 118/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 119/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 120/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 121/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
2020-01-08 17:52:29,289 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_120.pickle
 - val_f1: 0.9952
Epoch 122/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 123/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 124/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 125/200
 - 39s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 126/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 127/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 128/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 129/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 130/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 131/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 132/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 133/200
 - 39s - loss: 0.0030 - val_loss: 0.0101
 - val_f1: 0.9838
Epoch 134/200
 - 39s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9926
Epoch 135/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 136/200
 - 39s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 137/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 138/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 139/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 140/200
 - 39s - loss: 0.0030 - val_loss: 0.0049
 - val_f1: 0.9905
Epoch 141/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
2020-01-08 18:08:15,696 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_140.pickle
 - val_f1: 0.9954
Epoch 142/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 143/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 144/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 145/200
 - 39s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 146/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 147/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 148/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 149/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 150/200
 - 39s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 151/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 152/200
 - 39s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 153/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 154/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 155/200
 - 39s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 156/200
 - 39s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 157/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 158/200
 - 39s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 159/200
 - 39s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 160/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 161/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
2020-01-08 18:24:01,656 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_160.pickle
 - val_f1: 0.9949
Epoch 162/200
 - 39s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 163/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 164/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 165/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 166/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 167/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 168/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 169/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 170/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9957
Epoch 171/200
 - 39s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 172/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 173/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 174/200
 - 39s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 175/200
 - 39s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 176/200
 - 39s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 177/200
 - 39s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 178/200
 - 39s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 179/200
 - 39s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9924
Epoch 180/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 181/200
 - 39s - loss: 0.0029 - val_loss: 0.0030
2020-01-08 18:39:50,366 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_6/ann_model_epoch_180.pickle
 - val_f1: 0.9926
Epoch 182/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 183/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 184/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 185/200
 - 39s - loss: 0.0030 - val_loss: 0.0105
 - val_f1: 0.9819
Epoch 186/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 187/200
 - 39s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 188/200
 - 39s - loss: 0.0029 - val_loss: 0.0032
 - val_f1: 0.9929
Epoch 189/200
 - 39s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 190/200
 - 39s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 191/200
 - 39s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 192/200
 - 39s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 193/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 194/200
 - 39s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 195/200
 - 39s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9930
Epoch 196/200
 - 39s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 197/200
 - 39s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 198/200
 - 39s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 199/200
 - 39s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 200/200
 - 39s - loss: 0.0028 - val_loss: 0.0022
2020-01-08 18:54:59,461 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 18:55:36,756 [INFO] Last epoch loss evaluation: train_loss = 0.002132, val_loss = 0.002160
2020-01-08 18:55:36,756 [INFO] Training complete. time_to_train = 9522.03 sec, 158.70 min
2020-01-08 18:55:36,766 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_6/best_model.pickle
2020-01-08 18:55:36,769 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_6/training_error_history.csv
2020-01-08 18:55:36,962 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_6/training_error_history.png
2020-01-08 18:55:37,147 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_6/training_f1_history.png
2020-01-08 18:55:37,147 [INFO] Making predictions on training, validation, testing data
2020-01-08 18:56:16,627 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 18:56:26,863 [INFO] Dataset: Testing. Classification report below
2020-01-08 18:56:26,863 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.96      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 18:56:26,863 [INFO] Overall accuracy (micro avg): 0.9957953327840272
/home/sunanda/test/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 18:56:38,397 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8939                       0.7830                0.0010                   0.2170  0.7973
2  Weighted avg        0.9966         0.9956                       0.9958                0.0082                   0.0042  0.9954
2020-01-08 18:56:48,703 [INFO] Dataset: Validation. Classification report below
2020-01-08 18:56:48,704 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.96      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.81      0.07      0.13       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 18:56:48,704 [INFO] Overall accuracy (micro avg): 0.9959792206689982
2020-01-08 18:57:00,404 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8793                       0.7765                0.0010                   0.2235  0.7898
2  Weighted avg        0.9967         0.9957                       0.9960                0.0079                   0.0040  0.9956
2020-01-08 18:57:34,451 [INFO] Dataset: Training. Classification report below
2020-01-08 18:57:34,451 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.99      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.86      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2020-01-08 18:57:34,451 [INFO] Overall accuracy (micro avg): 0.9960010231722584
2020-01-08 18:58:13,116 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8856                       0.7807                0.0010                   0.2193  0.7956
2  Weighted avg        0.9967         0.9957                       0.9960                0.0079                   0.0040  0.9956
2020-01-08 18:58:13,167 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_6/ann_depth_ids17_layers_6_results.xlsx
2020-01-08 18:58:13,174 [INFO] ================= Finished running experiment no. 6 ================= 

2020-01-08 18:58:13,240 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_7
2020-01-08 18:58:13,240 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_7/run_log.log
2020-01-08 18:58:13,240 [INFO] ================= Running experiment no. 7  ================= 

2020-01-08 18:58:13,240 [INFO] Experiment parameters given below
2020-01-08 18:58:13,240 [INFO] 
{'experiment_num': 7, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_7', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_7'}
2020-01-08 18:58:13,241 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_7/tf_logs_run_2020_01_08-18_58_13
2020-01-08 18:58:13,241 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 18:58:13,241 [INFO] Reading X, y files
2020-01-08 18:58:13,241 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 18:58:17,298 [INFO] Reading complete. time_to_read=4.06 seconds
2020-01-08 18:58:17,299 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 18:58:18,684 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-08 18:58:18,684 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 18:58:20,064 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 18:58:20,065 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 18:58:20,276 [INFO] Reading complete. time_to_read=0.21 seconds
2020-01-08 18:58:20,276 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 18:58:20,343 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 18:58:20,343 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 18:58:20,409 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 18:58:23,594 [INFO] Initializing model
2020-01-08 18:58:24,141 [INFO] _________________________________________________________________
2020-01-08 18:58:24,141 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 18:58:24,141 [INFO] =================================================================
2020-01-08 18:58:24,142 [INFO] dense_8 (Dense)              (None, 64)                5056      
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] dense_9 (Dense)              (None, 64)                4160      
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] dense_10 (Dense)             (None, 64)                4160      
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] batch_normalization_9 (Batch (None, 64)                256       
2020-01-08 18:58:24,142 [INFO] _________________________________________________________________
2020-01-08 18:58:24,142 [INFO] dropout_9 (Dropout)          (None, 64)                0         
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] dense_11 (Dense)             (None, 64)                4160      
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] dense_12 (Dense)             (None, 64)                4160      
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] dense_13 (Dense)             (None, 64)                4160      
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,143 [INFO] batch_normalization_12 (Batc (None, 64)                256       
2020-01-08 18:58:24,143 [INFO] _________________________________________________________________
2020-01-08 18:58:24,144 [INFO] dropout_12 (Dropout)         (None, 64)                0         
2020-01-08 18:58:24,144 [INFO] _________________________________________________________________
2020-01-08 18:58:24,144 [INFO] dense_14 (Dense)             (None, 64)                4160      
2020-01-08 18:58:24,144 [INFO] _________________________________________________________________
2020-01-08 18:58:24,144 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2020-01-08 18:58:24,144 [INFO] _________________________________________________________________
2020-01-08 18:58:24,144 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2020-01-08 18:58:24,144 [INFO] _________________________________________________________________
2020-01-08 18:58:24,144 [INFO] dense_15 (Dense)             (None, 12)                780       
2020-01-08 18:58:24,144 [INFO] =================================================================
2020-01-08 18:58:24,144 [INFO] Total params: 32,588
2020-01-08 18:58:24,144 [INFO] Trainable params: 31,692
2020-01-08 18:58:24,144 [INFO] Non-trainable params: 896
2020-01-08 18:58:24,144 [INFO] _________________________________________________________________
2020-01-08 18:58:24,145 [INFO] Training model
 - val_f1: 0.9949
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 45s - loss: 0.0247 - val_loss: 0.0122
 - val_f1: 0.9682
Epoch 2/200
 - 45s - loss: 0.0117 - val_loss: 0.0090
 - val_f1: 0.9719
Epoch 3/200
 - 45s - loss: 0.0087 - val_loss: 0.0046
 - val_f1: 0.9880
Epoch 4/200
 - 45s - loss: 0.0081 - val_loss: 0.0121
 - val_f1: 0.9775
Epoch 5/200
 - 45s - loss: 0.0071 - val_loss: 0.0075
 - val_f1: 0.9760
Epoch 6/200
 - 45s - loss: 0.0065 - val_loss: 0.0070
 - val_f1: 0.9806
Epoch 7/200
 - 45s - loss: 0.0064 - val_loss: 0.0087
 - val_f1: 0.9789
Epoch 8/200
 - 44s - loss: 0.0067 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 9/200
 - 45s - loss: 0.0065 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 10/200
 - 45s - loss: 0.0058 - val_loss: 0.0044
 - val_f1: 0.9898
Epoch 11/200
 - 45s - loss: 0.0056 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 12/200
 - 45s - loss: 0.0052 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 13/200
 - 44s - loss: 0.0056 - val_loss: 0.0043
 - val_f1: 0.9910
Epoch 14/200
 - 45s - loss: 0.0055 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 15/200
 - 45s - loss: 0.0054 - val_loss: 0.0060
 - val_f1: 0.9825
Epoch 16/200
 - 44s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 17/200
 - 45s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 18/200
 - 45s - loss: 0.0049 - val_loss: 0.0048
 - val_f1: 0.9888
Epoch 19/200
 - 45s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9893
Epoch 20/200
 - 45s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 21/200
 - 45s - loss: 0.0048 - val_loss: 0.0045
2020-01-08 19:17:25,987 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_20.pickle
 - val_f1: 0.9878
Epoch 22/200
 - 45s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 23/200
 - 45s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 24/200
 - 45s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 25/200
 - 45s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 26/200
 - 45s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 27/200
 - 45s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 28/200
 - 45s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 29/200
 - 45s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 30/200
 - 45s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 31/200
 - 45s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 32/200
 - 45s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 33/200
 - 45s - loss: 0.0041 - val_loss: 0.0103
 - val_f1: 0.9813
Epoch 34/200
 - 45s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 35/200
 - 45s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9921
Epoch 36/200
 - 45s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 37/200
 - 45s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9915
Epoch 38/200
 - 45s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9883
Epoch 39/200
 - 45s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 40/200
 - 45s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 41/200
 - 45s - loss: 0.0038 - val_loss: 0.0028
2020-01-08 19:35:42,250 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_40.pickle
 - val_f1: 0.9938
Epoch 42/200
 - 45s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 43/200
 - 45s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 44/200
 - 45s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 45/200
 - 45s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 46/200
 - 45s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 47/200
 - 45s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9919
Epoch 48/200
 - 45s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 49/200
 - 45s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 50/200
 - 45s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 51/200
 - 45s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9903
Epoch 52/200
 - 45s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 53/200
 - 45s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 54/200
 - 45s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 55/200
 - 45s - loss: 0.0041 - val_loss: 0.0063
 - val_f1: 0.9785
Epoch 56/200
 - 45s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 57/200
 - 45s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 58/200
 - 45s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 59/200
 - 45s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 60/200
 - 45s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9893
Epoch 61/200
 - 45s - loss: 0.0039 - val_loss: 0.0036
2020-01-08 19:53:59,434 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_60.pickle
 - val_f1: 0.9896
Epoch 62/200
 - 45s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 63/200
 - 45s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 64/200
 - 45s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 65/200
 - 45s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 66/200
 - 45s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 67/200
 - 45s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 68/200
 - 45s - loss: 0.0040 - val_loss: 0.0061
 - val_f1: 0.9741
Epoch 69/200
 - 45s - loss: 0.0038 - val_loss: 0.0042
 - val_f1: 0.9865
Epoch 70/200
 - 45s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 71/200
 - 45s - loss: 0.0037 - val_loss: 0.0062
 - val_f1: 0.9767
Epoch 72/200
 - 45s - loss: 0.0038 - val_loss: 0.0058
 - val_f1: 0.9817
Epoch 73/200
 - 45s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9910
Epoch 74/200
 - 45s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 75/200
 - 45s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 76/200
 - 45s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 77/200
 - 45s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 78/200
 - 45s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9905
Epoch 79/200
 - 45s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 80/200
 - 45s - loss: 0.0038 - val_loss: 0.0058
 - val_f1: 0.9781
Epoch 81/200
 - 45s - loss: 0.0037 - val_loss: 0.0029
2020-01-08 20:12:16,104 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_80.pickle
 - val_f1: 0.9930
Epoch 82/200
 - 45s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 83/200
 - 45s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 84/200
 - 45s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 85/200
 - 45s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 86/200
 - 45s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 87/200
 - 45s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 88/200
 - 45s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9917
Epoch 89/200
 - 45s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 90/200
 - 45s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 91/200
 - 45s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9852
Epoch 92/200
 - 45s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 93/200
 - 45s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 94/200
 - 45s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 95/200
 - 45s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 96/200
 - 45s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 97/200
 - 45s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 98/200
 - 45s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 99/200
 - 45s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 100/200
 - 45s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9908
Epoch 101/200
 - 45s - loss: 0.0037 - val_loss: 0.0032
2020-01-08 20:30:33,145 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_100.pickle
 - val_f1: 0.9925
Epoch 102/200
 - 45s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 103/200
 - 45s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 104/200
 - 45s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 105/200
 - 45s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 106/200
 - 45s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 107/200
 - 45s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 108/200
 - 45s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 109/200
 - 45s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 110/200
 - 45s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 111/200
 - 45s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 112/200
 - 45s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 113/200
 - 45s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 114/200
 - 45s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9904
Epoch 115/200
 - 45s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 116/200
 - 45s - loss: 0.0036 - val_loss: 0.0038
 - val_f1: 0.9893
Epoch 117/200
 - 45s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 118/200
 - 45s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 119/200
 - 45s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 120/200
 - 45s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9909
Epoch 121/200
 - 45s - loss: 0.0035 - val_loss: 0.0029
2020-01-08 20:48:49,756 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_120.pickle
 - val_f1: 0.9929
Epoch 122/200
 - 45s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 123/200
 - 45s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 124/200
 - 45s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 125/200
 - 45s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 126/200
 - 45s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 127/200
 - 45s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 128/200
 - 45s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 129/200
 - 45s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 130/200
 - 45s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 131/200
 - 45s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 132/200
 - 45s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9877
Epoch 133/200
 - 45s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 134/200
 - 45s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 135/200
 - 45s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 136/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 137/200
 - 45s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 138/200
 - 45s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 139/200
 - 45s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 140/200
 - 45s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 141/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
2020-01-08 21:07:06,209 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_140.pickle
 - val_f1: 0.9944
Epoch 142/200
 - 45s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 143/200
 - 45s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9915
Epoch 144/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 145/200
 - 45s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 146/200
 - 45s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 147/200
 - 45s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 148/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 149/200
 - 45s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 150/200
 - 45s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 151/200
 - 45s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 152/200
 - 45s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 153/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 154/200
 - 45s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 155/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 156/200
 - 45s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 157/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 158/200
 - 45s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 159/200
 - 45s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 160/200
 - 45s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 161/200
 - 45s - loss: 0.0033 - val_loss: 0.0026
2020-01-08 21:25:20,446 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_160.pickle
 - val_f1: 0.9944
Epoch 162/200
 - 45s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 163/200
 - 45s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 164/200
 - 45s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9912
Epoch 165/200
 - 45s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 166/200
 - 45s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 167/200
 - 45s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 168/200
 - 45s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 169/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 170/200
 - 45s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 171/200
 - 45s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 172/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 173/200
 - 45s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 174/200
 - 45s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 175/200
 - 45s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 176/200
 - 45s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 177/200
 - 45s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 178/200
 - 45s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 179/200
 - 45s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 180/200
 - 45s - loss: 0.0032 - val_loss: 0.0037
 - val_f1: 0.9917
Epoch 181/200
 - 45s - loss: 0.0033 - val_loss: 0.0029
2020-01-08 21:43:34,518 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_7/ann_model_epoch_180.pickle
 - val_f1: 0.9932
Epoch 182/200
 - 45s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 183/200
 - 45s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 184/200
 - 45s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 185/200
 - 45s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 186/200
 - 45s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 187/200
 - 45s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 188/200
 - 45s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 189/200
 - 45s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 190/200
 - 45s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 191/200
 - 45s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 192/200
 - 45s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9913
Epoch 193/200
 - 45s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 194/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 195/200
 - 45s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 196/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 197/200
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 198/200
 - 45s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 199/200
 - 45s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 200/200
 - 45s - loss: 0.0034 - val_loss: 0.0025
2020-01-08 22:01:04,048 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 22:01:48,380 [INFO] Last epoch loss evaluation: train_loss = 0.002307, val_loss = 0.002353
2020-01-08 22:01:48,380 [INFO] Training complete. time_to_train = 11004.24 sec, 183.40 min
2020-01-08 22:01:48,392 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_7/best_model.pickle
2020-01-08 22:01:48,396 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_7/training_error_history.csv
2020-01-08 22:01:48,579 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_7/training_error_history.png
2020-01-08 22:01:48,756 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_7/training_f1_history.png
2020-01-08 22:01:48,756 [INFO] Making predictions on training, validation, testing data
2020-01-08 22:02:36,955 [INFO] Evaluating predictions (results)
2020-01-08 22:02:47,085 [INFO] Dataset: Testing. Classification report below
2020-01-08 22:02:47,085 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.96      0.98      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.95      1179
Web Attack Brute Force       1.00      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 22:02:47,085 [INFO] Overall accuracy (micro avg): 0.9954735289853278
2020-01-08 22:02:58,608 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9992         0.8914                       0.7843                0.0011                   0.2157  0.7974
2  Weighted avg        0.9963         0.9953                       0.9955                0.0083                   0.0045  0.9951
2020-01-08 22:03:08,886 [INFO] Dataset: Validation. Classification report below
2020-01-08 22:03:08,886 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.96      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.96      0.98      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.95      1180
Web Attack Brute Force       0.96      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2020-01-08 22:03:08,886 [INFO] Overall accuracy (micro avg): 0.9955336461784915
2020-01-08 22:03:20,552 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8871                       0.7768                0.0011                   0.2232  0.7881
2  Weighted avg        0.9963         0.9953                       0.9955                0.0082                   0.0045  0.9951
2020-01-08 22:03:54,614 [INFO] Dataset: Training. Classification report below
2020-01-08 22:03:54,614 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.96      0.98      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.94      0.98      0.96      3538
Web Attack Brute Force       0.98      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2020-01-08 22:03:54,614 [INFO] Overall accuracy (micro avg): 0.9956297106591445
2020-01-08 22:04:33,299 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8925                       0.7818                0.0010                   0.2182  0.7951
2  Weighted avg        0.9964         0.9954                       0.9956                0.0082                   0.0044  0.9952
2020-01-08 22:04:33,350 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_7/ann_depth_ids17_layers_7_results.xlsx
2020-01-08 22:04:33,356 [INFO] ================= Finished running experiment no. 7 ================= 

2020-01-08 22:04:33,423 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_8
2020-01-08 22:04:33,423 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_8/run_log.log
2020-01-08 22:04:33,423 [INFO] ================= Running experiment no. 8  ================= 

2020-01-08 22:04:33,424 [INFO] Experiment parameters given below
2020-01-08 22:04:33,424 [INFO] 
{'experiment_num': 8, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_8', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_8'}
2020-01-08 22:04:33,424 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_8/tf_logs_run_2020_01_08-22_04_33
2020-01-08 22:04:33,424 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-08 22:04:33,424 [INFO] Reading X, y files
2020-01-08 22:04:33,424 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-08 22:04:37,459 [INFO] Reading complete. time_to_read=4.03 seconds
2020-01-08 22:04:37,459 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-08 22:04:38,847 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-08 22:04:38,847 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-08 22:04:40,239 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-08 22:04:40,239 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-08 22:04:40,442 [INFO] Reading complete. time_to_read=0.20 seconds
2020-01-08 22:04:40,442 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-08 22:04:40,509 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 22:04:40,509 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-08 22:04:40,575 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-08 22:04:43,779 [INFO] Initializing model
2020-01-08 22:04:44,417 [INFO] _________________________________________________________________
2020-01-08 22:04:44,417 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 22:04:44,417 [INFO] =================================================================
2020-01-08 22:04:44,417 [INFO] dense_16 (Dense)             (None, 64)                5056      
2020-01-08 22:04:44,417 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] dense_17 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] batch_normalization_15 (Batc (None, 64)                256       
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] dropout_15 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] dense_18 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] batch_normalization_16 (Batc (None, 64)                256       
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,418 [INFO] dropout_16 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,418 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dense_19 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] batch_normalization_17 (Batc (None, 64)                256       
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dropout_17 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dense_20 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] batch_normalization_18 (Batc (None, 64)                256       
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dropout_18 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dense_21 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] batch_normalization_19 (Batc (None, 64)                256       
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,419 [INFO] dropout_19 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,419 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] dense_22 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] batch_normalization_20 (Batc (None, 64)                256       
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] dropout_20 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] dense_23 (Dense)             (None, 64)                4160      
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] batch_normalization_21 (Batc (None, 64)                256       
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] dropout_21 (Dropout)         (None, 64)                0         
2020-01-08 22:04:44,420 [INFO] _________________________________________________________________
2020-01-08 22:04:44,420 [INFO] dense_24 (Dense)             (None, 12)                780       
2020-01-08 22:04:44,420 [INFO] =================================================================
2020-01-08 22:04:44,421 [INFO] Total params: 37,004
2020-01-08 22:04:44,421 [INFO] Trainable params: 35,980
2020-01-08 22:04:44,421 [INFO] Non-trainable params: 1,024
2020-01-08 22:04:44,421 [INFO] _________________________________________________________________
2020-01-08 22:04:44,421 [INFO] Training model
 - val_f1: 0.9942
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 52s - loss: 0.0258 - val_loss: 0.0271
 - val_f1: 0.9457
Epoch 2/200
 - 51s - loss: 0.0125 - val_loss: 0.0102
 - val_f1: 0.9714
Epoch 3/200
 - 51s - loss: 0.0107 - val_loss: 0.0083
 - val_f1: 0.9770
Epoch 4/200
 - 51s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9783
Epoch 5/200
 - 51s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 6/200
 - 51s - loss: 0.0078 - val_loss: 0.0090
 - val_f1: 0.9747
Epoch 7/200
 - 51s - loss: 0.0081 - val_loss: 0.0112
 - val_f1: 0.9743
Epoch 8/200
 - 51s - loss: 0.0071 - val_loss: 0.0045
 - val_f1: 0.9890
Epoch 9/200
 - 51s - loss: 0.0064 - val_loss: 0.0046
 - val_f1: 0.9870
Epoch 10/200
 - 51s - loss: 0.0067 - val_loss: 0.0049
 - val_f1: 0.9868
Epoch 11/200
 - 51s - loss: 0.0065 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 12/200
 - 51s - loss: 0.0060 - val_loss: 0.0046
 - val_f1: 0.9899
Epoch 13/200
 - 51s - loss: 0.0057 - val_loss: 0.0041
 - val_f1: 0.9924
Epoch 14/200
 - 51s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 15/200
 - 51s - loss: 0.0053 - val_loss: 0.0045
 - val_f1: 0.9889
Epoch 16/200
 - 51s - loss: 0.0056 - val_loss: 0.0036
 - val_f1: 0.9905
Epoch 17/200
 - 51s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9875
Epoch 18/200
 - 51s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9910
Epoch 19/200
 - 51s - loss: 0.0055 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 20/200
 - 51s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 21/200
 - 51s - loss: 0.0053 - val_loss: 0.0065
2020-01-08 22:26:38,773 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_20.pickle
 - val_f1: 0.9840
Epoch 22/200
 - 51s - loss: 0.0056 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 23/200
 - 51s - loss: 0.0051 - val_loss: 0.0035
 - val_f1: 0.9910
Epoch 24/200
 - 51s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 25/200
 - 51s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 26/200
 - 51s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 27/200
 - 51s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9911
Epoch 28/200
 - 51s - loss: 0.0050 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 29/200
 - 51s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 30/200
 - 51s - loss: 0.0050 - val_loss: 0.0034
 - val_f1: 0.9905
Epoch 31/200
 - 51s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 32/200
 - 51s - loss: 0.0049 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 33/200
 - 51s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9914
Epoch 34/200
 - 51s - loss: 0.0054 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 35/200
 - 51s - loss: 0.0051 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 36/200
 - 51s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 37/200
 - 51s - loss: 0.0047 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 38/200
 - 51s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 39/200
 - 51s - loss: 0.0048 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 40/200
 - 51s - loss: 0.0047 - val_loss: 0.0070
 - val_f1: 0.9809
Epoch 41/200
 - 51s - loss: 0.0048 - val_loss: 0.0036
2020-01-08 22:47:38,890 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_40.pickle
 - val_f1: 0.9915
Epoch 42/200
 - 51s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 43/200
 - 51s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 44/200
 - 51s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 45/200
 - 51s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 46/200
 - 51s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 47/200
 - 51s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 48/200
 - 51s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 49/200
 - 51s - loss: 0.0041 - val_loss: 0.0077
 - val_f1: 0.9629
Epoch 50/200
 - 51s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 51/200
 - 51s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 52/200
 - 51s - loss: 0.0041 - val_loss: 0.0061
 - val_f1: 0.9830
Epoch 53/200
 - 51s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 54/200
 - 51s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 55/200
 - 51s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 56/200
 - 51s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 57/200
 - 51s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 58/200
 - 51s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 59/200
 - 51s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 60/200
 - 51s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 61/200
 - 51s - loss: 0.0040 - val_loss: 0.0032
2020-01-08 23:08:38,338 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_60.pickle
 - val_f1: 0.9930
Epoch 62/200
 - 51s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9836
Epoch 63/200
 - 51s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9929
Epoch 64/200
 - 51s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9917
Epoch 65/200
 - 51s - loss: 0.0042 - val_loss: 0.0100
 - val_f1: 0.9640
Epoch 66/200
 - 51s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9863
Epoch 67/200
 - 51s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 68/200
 - 51s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9881
Epoch 69/200
 - 51s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 70/200
 - 51s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9897
Epoch 71/200
 - 51s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9925
Epoch 72/200
 - 51s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9919
Epoch 73/200
 - 51s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 74/200
 - 51s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 75/200
 - 51s - loss: 0.0042 - val_loss: 0.0066
 - val_f1: 0.9734
Epoch 76/200
 - 51s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 77/200
 - 51s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 78/200
 - 51s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 79/200
 - 51s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 80/200
 - 51s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 81/200
 - 51s - loss: 0.0041 - val_loss: 0.0029
2020-01-08 23:29:37,984 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_80.pickle
 - val_f1: 0.9933
Epoch 82/200
 - 51s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 83/200
 - 51s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 84/200
 - 51s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 85/200
 - 51s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 86/200
 - 51s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 87/200
 - 51s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 88/200
 - 51s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 89/200
 - 51s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 90/200
 - 51s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 91/200
 - 51s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 92/200
 - 51s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 93/200
 - 51s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 94/200
 - 51s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9915
Epoch 95/200
 - 51s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 96/200
 - 51s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 97/200
 - 51s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 98/200
 - 51s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 99/200
 - 51s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 100/200
 - 51s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 101/200
 - 51s - loss: 0.0040 - val_loss: 0.0029
2020-01-08 23:50:37,465 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_100.pickle
 - val_f1: 0.9932
Epoch 102/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 103/200
 - 51s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 104/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 105/200
 - 51s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 106/200
 - 51s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 107/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 108/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 109/200
 - 51s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 110/200
 - 51s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9913
Epoch 111/200
 - 51s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 112/200
 - 51s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 113/200
 - 51s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 114/200
 - 51s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 115/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 116/200
 - 51s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 117/200
 - 51s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 118/200
 - 51s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9877
Epoch 119/200
 - 51s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 120/200
 - 51s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 121/200
 - 51s - loss: 0.0037 - val_loss: 0.0028
2020-01-09 00:11:37,491 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_120.pickle
 - val_f1: 0.9936
Epoch 122/200
 - 51s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 123/200
 - 51s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 124/200
 - 51s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 125/200
 - 51s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 126/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 127/200
 - 51s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 128/200
 - 51s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 129/200
 - 51s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 130/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 131/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 132/200
 - 51s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 133/200
 - 51s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 134/200
 - 51s - loss: 0.0036 - val_loss: 0.0107
 - val_f1: 0.9809
Epoch 135/200
 - 51s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 136/200
 - 51s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 137/200
 - 51s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 138/200
 - 51s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 139/200
 - 51s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 140/200
 - 51s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 141/200
 - 51s - loss: 0.0038 - val_loss: 0.0032
2020-01-09 00:32:37,836 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_140.pickle
 - val_f1: 0.9935
Epoch 142/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 143/200
 - 51s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 144/200
 - 51s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 145/200
 - 51s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 146/200
 - 51s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 147/200
 - 51s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 148/200
 - 51s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 149/200
 - 51s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 150/200
 - 51s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 151/200
 - 51s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 152/200
 - 51s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 153/200
 - 51s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 154/200
 - 51s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9918
Epoch 155/200
 - 51s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 156/200
 - 51s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 157/200
 - 51s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 158/200
 - 51s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9907
Epoch 159/200
 - 51s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 160/200
 - 51s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 161/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
2020-01-09 00:53:37,606 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_160.pickle
 - val_f1: 0.9934
Epoch 162/200
 - 51s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 163/200
 - 51s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 164/200
 - 51s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 165/200
 - 51s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 166/200
 - 51s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 167/200
 - 51s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 168/200
 - 51s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 169/200
 - 51s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9888
Epoch 170/200
 - 51s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 171/200
 - 51s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 172/200
 - 51s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 173/200
 - 51s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 174/200
 - 51s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 175/200
 - 51s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 176/200
 - 51s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 177/200
 - 51s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 178/200
 - 51s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 179/200
 - 51s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 180/200
 - 51s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 181/200
 - 51s - loss: 0.0033 - val_loss: 0.0030
2020-01-09 01:14:37,933 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_8/ann_model_epoch_180.pickle
 - val_f1: 0.9942
Epoch 182/200
 - 51s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 183/200
 - 51s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 184/200
 - 51s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 185/200
 - 51s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 186/200
 - 51s - loss: 0.0034 - val_loss: 0.0069
 - val_f1: 0.9744
Epoch 187/200
 - 51s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 188/200
 - 51s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 189/200
 - 51s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 190/200
 - 51s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 191/200
 - 51s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 192/200
 - 51s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 193/200
 - 51s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 194/200
 - 51s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 195/200
 - 51s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 196/200
 - 51s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 197/200
 - 51s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 198/200
 - 51s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 199/200
 - 51s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 200/200
 - 51s - loss: 0.0035 - val_loss: 0.0027
2020-01-09 01:34:47,138 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 01:35:40,057 [INFO] Last epoch loss evaluation: train_loss = 0.002360, val_loss = 0.002410
2020-01-09 01:35:40,058 [INFO] Training complete. time_to_train = 12655.64 sec, 210.93 min
2020-01-09 01:35:40,070 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_8/best_model.pickle
2020-01-09 01:35:40,073 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_8/training_error_history.csv
2020-01-09 01:35:40,256 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_8/training_error_history.png
2020-01-09 01:35:40,427 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_8/training_f1_history.png
2020-01-09 01:35:40,427 [INFO] Making predictions on training, validation, testing data
2020-01-09 01:36:38,700 [INFO] Evaluating predictions (results)
2020-01-09 01:36:48,834 [INFO] Dataset: Testing. Classification report below
2020-01-09 01:36:48,834 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.96      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.96      0.97      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.95      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-09 01:36:48,834 [INFO] Overall accuracy (micro avg): 0.9952136105325322
2020-01-09 01:37:00,356 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.8065                       0.7742                0.0011                   0.2258  0.7801
2  Weighted avg        0.9961         0.9945                       0.9952                0.0087                   0.0048  0.9948
2020-01-09 01:37:10,688 [INFO] Dataset: Validation. Classification report below
2020-01-09 01:37:10,688 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.95      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.96      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.92      0.98      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-09 01:37:10,688 [INFO] Overall accuracy (micro avg): 0.9953126270859782
2020-01-09 01:37:22,403 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0004                   0.0047  0.9953
1     Macro avg        0.9992         0.8056                       0.7702                0.0011                   0.2298  0.7767
2  Weighted avg        0.9962         0.9946                       0.9953                0.0084                   0.0047  0.9948
2020-01-09 01:37:56,413 [INFO] Dataset: Training. Classification report below
2020-01-09 01:37:56,413 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.98      0.94      3300
         DoS slowloris       0.96      0.98      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.94      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.81      0.77      0.78   1696684
          weighted avg       0.99      1.00      0.99   1696684

2020-01-09 01:37:56,415 [INFO] Overall accuracy (micro avg): 0.9954210683898711
2020-01-09 01:38:35,067 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8099                       0.7731                0.0011                   0.2269  0.7802
2  Weighted avg        0.9962         0.9947                       0.9954                0.0084                   0.0046  0.9950
2020-01-09 01:38:35,120 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_8/ann_depth_ids17_layers_8_results.xlsx
2020-01-09 01:38:35,126 [INFO] ================= Finished running experiment no. 8 ================= 

2020-01-09 01:38:35,194 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_9
2020-01-09 01:38:35,194 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_9/run_log.log
2020-01-09 01:38:35,194 [INFO] ================= Running experiment no. 9  ================= 

2020-01-09 01:38:35,194 [INFO] Experiment parameters given below
2020-01-09 01:38:35,195 [INFO] 
{'experiment_num': 9, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_9', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_9'}
2020-01-09 01:38:35,195 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_9/tf_logs_run_2020_01_09-01_38_35
2020-01-09 01:38:35,195 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-09 01:38:35,195 [INFO] Reading X, y files
2020-01-09 01:38:35,195 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-09 01:38:39,281 [INFO] Reading complete. time_to_read=4.09 seconds
2020-01-09 01:38:39,283 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-09 01:38:40,675 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-09 01:38:40,675 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-09 01:38:42,069 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-09 01:38:42,070 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-09 01:38:42,272 [INFO] Reading complete. time_to_read=0.20 seconds
2020-01-09 01:38:42,273 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-09 01:38:42,340 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-09 01:38:42,340 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-09 01:38:42,406 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-09 01:38:45,616 [INFO] Initializing model
2020-01-09 01:38:46,494 [INFO] _________________________________________________________________
2020-01-09 01:38:46,494 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-09 01:38:46,494 [INFO] =================================================================
2020-01-09 01:38:46,494 [INFO] dense_25 (Dense)             (None, 64)                5056      
2020-01-09 01:38:46,494 [INFO] _________________________________________________________________
2020-01-09 01:38:46,494 [INFO] batch_normalization_22 (Batc (None, 64)                256       
2020-01-09 01:38:46,494 [INFO] _________________________________________________________________
2020-01-09 01:38:46,494 [INFO] dropout_22 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,494 [INFO] _________________________________________________________________
2020-01-09 01:38:46,494 [INFO] dense_26 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] batch_normalization_23 (Batc (None, 64)                256       
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] dropout_23 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] dense_27 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] batch_normalization_24 (Batc (None, 64)                256       
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] dropout_24 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] dense_28 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] batch_normalization_25 (Batc (None, 64)                256       
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,495 [INFO] dropout_25 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,495 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dense_29 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dense_30 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] batch_normalization_27 (Batc (None, 64)                256       
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dropout_27 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dense_31 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] batch_normalization_28 (Batc (None, 64)                256       
2020-01-09 01:38:46,496 [INFO] _________________________________________________________________
2020-01-09 01:38:46,496 [INFO] dropout_28 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] dense_32 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] batch_normalization_29 (Batc (None, 64)                256       
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] dropout_29 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] dense_33 (Dense)             (None, 64)                4160      
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] batch_normalization_30 (Batc (None, 64)                256       
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] dropout_30 (Dropout)         (None, 64)                0         
2020-01-09 01:38:46,497 [INFO] _________________________________________________________________
2020-01-09 01:38:46,497 [INFO] dense_34 (Dense)             (None, 12)                780       
2020-01-09 01:38:46,497 [INFO] =================================================================
2020-01-09 01:38:46,498 [INFO] Total params: 41,420
2020-01-09 01:38:46,498 [INFO] Trainable params: 40,268
2020-01-09 01:38:46,498 [INFO] Non-trainable params: 1,152
2020-01-09 01:38:46,498 [INFO] _________________________________________________________________
2020-01-09 01:38:46,498 [INFO] Training model
 - val_f1: 0.9941
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 58s - loss: 0.0281 - val_loss: 0.0118
 - val_f1: 0.9682
Epoch 2/200
 - 57s - loss: 0.0130 - val_loss: 0.0093
 - val_f1: 0.9727
Epoch 3/200
 - 55s - loss: 0.0111 - val_loss: 0.0089
 - val_f1: 0.9728
Epoch 4/200
 - 56s - loss: 0.0100 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 5/200
 - 56s - loss: 0.0087 - val_loss: 0.0063
 - val_f1: 0.9839
Epoch 6/200
 - 56s - loss: 0.0073 - val_loss: 0.0085
 - val_f1: 0.9790
Epoch 7/200
 - 56s - loss: 0.0078 - val_loss: 0.0063
 - val_f1: 0.9857
Epoch 8/200
 - 56s - loss: 0.0069 - val_loss: 0.0048
 - val_f1: 0.9876
Epoch 9/200
 - 56s - loss: 0.0067 - val_loss: 0.0042
 - val_f1: 0.9897
Epoch 10/200
 - 56s - loss: 0.0068 - val_loss: 0.0047
 - val_f1: 0.9887
Epoch 11/200
 - 56s - loss: 0.0068 - val_loss: 0.0064
 - val_f1: 0.9840
Epoch 12/200
 - 56s - loss: 0.0064 - val_loss: 0.0119
 - val_f1: 0.9814
Epoch 13/200
 - 56s - loss: 0.0064 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 14/200
 - 56s - loss: 0.0052 - val_loss: 0.0058
 - val_f1: 0.9838
Epoch 15/200
 - 56s - loss: 0.0052 - val_loss: 0.0035
 - val_f1: 0.9909
Epoch 16/200
 - 56s - loss: 0.0056 - val_loss: 0.0055
 - val_f1: 0.9876
Epoch 17/200
 - 56s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9869
Epoch 18/200
 - 56s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 19/200
 - 55s - loss: 0.0055 - val_loss: 0.0079
 - val_f1: 0.9805
Epoch 20/200
 - 56s - loss: 0.0060 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 21/200
 - 56s - loss: 0.0051 - val_loss: 0.0039
2020-01-09 02:03:12,615 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_20.pickle
 - val_f1: 0.9900
Epoch 22/200
 - 57s - loss: 0.0046 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 23/200
 - 57s - loss: 0.0048 - val_loss: 0.0054
 - val_f1: 0.9879
Epoch 24/200
 - 57s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 25/200
 - 57s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9921
Epoch 26/200
 - 57s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9903
Epoch 27/200
 - 57s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 28/200
 - 57s - loss: 0.0044 - val_loss: 0.0086
 - val_f1: 0.9883
Epoch 29/200
 - 57s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 30/200
 - 57s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9929
Epoch 31/200
 - 57s - loss: 0.0059 - val_loss: 0.0101
 - val_f1: 0.9670
Epoch 32/200
 - 57s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 33/200
 - 57s - loss: 0.0046 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 34/200
 - 57s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 35/200
 - 57s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 36/200
 - 57s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 37/200
 - 57s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 38/200
 - 57s - loss: 0.0046 - val_loss: 0.0057
 - val_f1: 0.9838
Epoch 39/200
 - 57s - loss: 0.0042 - val_loss: 0.0133
 - val_f1: 0.9855
Epoch 40/200
 - 57s - loss: 0.0043 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 41/200
 - 57s - loss: 0.0043 - val_loss: 0.0028
2020-01-09 02:26:48,572 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_40.pickle
 - val_f1: 0.9944
Epoch 42/200
 - 57s - loss: 0.0043 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 43/200
 - 57s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 44/200
 - 57s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9910
Epoch 45/200
 - 57s - loss: 0.0041 - val_loss: 0.0113
 - val_f1: 0.9889
Epoch 46/200
 - 57s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 47/200
 - 57s - loss: 0.0037 - val_loss: 0.0056
 - val_f1: 0.9885
Epoch 48/200
 - 57s - loss: 0.0038 - val_loss: 0.0112
 - val_f1: 0.9828
Epoch 49/200
 - 57s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 50/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 51/200
 - 57s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 52/200
 - 57s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 53/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 54/200
 - 57s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 55/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 56/200
 - 57s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 57/200
 - 57s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 58/200
 - 57s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 59/200
 - 57s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 60/200
 - 57s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9921
Epoch 61/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
2020-01-09 02:50:24,804 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_60.pickle
 - val_f1: 0.9943
Epoch 62/200
 - 57s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 63/200
 - 57s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 64/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 65/200
 - 57s - loss: 0.0040 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 66/200
 - 57s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 67/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 68/200
 - 57s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 69/200
 - 57s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 70/200
 - 57s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 71/200
 - 57s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 72/200
 - 57s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 73/200
 - 57s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 74/200
 - 57s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9891
Epoch 75/200
 - 57s - loss: 0.0040 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 76/200
 - 57s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9923
Epoch 77/200
 - 57s - loss: 0.0040 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 78/200
 - 57s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 79/200
 - 57s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 80/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 81/200
 - 57s - loss: 0.0042 - val_loss: 0.0047
2020-01-09 03:14:01,426 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_80.pickle
 - val_f1: 0.9881
Epoch 82/200
 - 57s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 83/200
 - 57s - loss: 0.0037 - val_loss: 0.0041
 - val_f1: 0.9897
Epoch 84/200
 - 57s - loss: 0.0041 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 85/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 86/200
 - 57s - loss: 0.0041 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 87/200
 - 57s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 88/200
 - 57s - loss: 0.0042 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 89/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 90/200
 - 57s - loss: 0.0043 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 91/200
 - 57s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 92/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 93/200
 - 57s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 94/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 95/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 96/200
 - 57s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 97/200
 - 57s - loss: 0.0040 - val_loss: 0.0093
 - val_f1: 0.9864
Epoch 98/200
 - 57s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 99/200
 - 57s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 100/200
 - 57s - loss: 0.0039 - val_loss: 0.0069
 - val_f1: 0.9865
Epoch 101/200
 - 57s - loss: 0.0038 - val_loss: 0.0025
2020-01-09 03:37:38,204 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_100.pickle
 - val_f1: 0.9942
Epoch 102/200
 - 57s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 103/200
 - 57s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 104/200
 - 57s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 105/200
 - 57s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 106/200
 - 57s - loss: 0.0048 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 107/200
 - 57s - loss: 0.0038 - val_loss: 0.0058
 - val_f1: 0.9875
Epoch 108/200
 - 57s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 109/200
 - 57s - loss: 0.0044 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 110/200
 - 57s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 111/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 112/200
 - 57s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 113/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 114/200
 - 57s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 115/200
 - 57s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 116/200
 - 57s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 117/200
 - 57s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 118/200
 - 57s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 119/200
 - 57s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 120/200
 - 57s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 121/200
 - 57s - loss: 0.0039 - val_loss: 0.0041
2020-01-09 04:01:14,845 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_120.pickle
 - val_f1: 0.9907
Epoch 122/200
 - 57s - loss: 0.0039 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 123/200
 - 57s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 124/200
 - 57s - loss: 0.0050 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 125/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 126/200
 - 57s - loss: 0.0038 - val_loss: 0.0067
 - val_f1: 0.9841
Epoch 127/200
 - 57s - loss: 0.0038 - val_loss: 0.0052
 - val_f1: 0.9918
Epoch 128/200
 - 57s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 129/200
 - 57s - loss: 0.0039 - val_loss: 0.0060
 - val_f1: 0.9898
Epoch 130/200
 - 57s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 131/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 132/200
 - 57s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 133/200
 - 57s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 134/200
 - 57s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 135/200
 - 57s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9886
Epoch 136/200
 - 57s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9891
Epoch 137/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 138/200
 - 57s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 139/200
 - 57s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 140/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 141/200
 - 57s - loss: 0.0040 - val_loss: 0.0028
2020-01-09 04:24:50,309 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_140.pickle
 - val_f1: 0.9937
Epoch 142/200
 - 57s - loss: 0.0040 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 143/200
 - 57s - loss: 0.0041 - val_loss: 0.0049
 - val_f1: 0.9911
Epoch 144/200
 - 57s - loss: 0.0039 - val_loss: 0.0055
 - val_f1: 0.9848
Epoch 145/200
 - 57s - loss: 0.0046 - val_loss: 0.0047
 - val_f1: 0.9896
Epoch 146/200
 - 57s - loss: 0.0044 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 147/200
 - 57s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9933
Epoch 148/200
 - 57s - loss: 0.0047 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 149/200
 - 57s - loss: 0.0053 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 150/200
 - 57s - loss: 0.0052 - val_loss: 0.0053
 - val_f1: 0.9888
Epoch 151/200
 - 57s - loss: 0.0046 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 152/200
 - 57s - loss: 0.0042 - val_loss: 0.0057
 - val_f1: 0.9841
Epoch 153/200
 - 57s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9942
Epoch 154/200
 - 57s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 155/200
 - 57s - loss: 0.0041 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 156/200
 - 57s - loss: 0.0049 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 157/200
 - 57s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 158/200
 - 57s - loss: 0.0041 - val_loss: 0.0101
 - val_f1: 0.9583
Epoch 159/200
 - 57s - loss: 0.0043 - val_loss: 0.0101
 - val_f1: 0.9652
Epoch 160/200
 - 57s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 161/200
 - 57s - loss: 0.0036 - val_loss: 0.0024
2020-01-09 04:48:26,832 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_160.pickle
 - val_f1: 0.9953
Epoch 162/200
 - 57s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 163/200
 - 57s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 164/200
 - 57s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 165/200
 - 57s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 166/200
 - 57s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9922
Epoch 167/200
 - 57s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 168/200
 - 57s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 169/200
 - 57s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 170/200
 - 57s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 171/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 172/200
 - 57s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 173/200
 - 57s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 174/200
 - 57s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9953
Epoch 175/200
 - 57s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 176/200
 - 57s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 177/200
 - 57s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 178/200
 - 57s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 179/200
 - 57s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 180/200
 - 57s - loss: 0.0040 - val_loss: 0.0055
 - val_f1: 0.9856
Epoch 181/200
 - 57s - loss: 0.0041 - val_loss: 0.0032
2020-01-09 05:12:02,681 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_9/ann_model_epoch_180.pickle
 - val_f1: 0.9922
Epoch 182/200
 - 57s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 183/200
 - 57s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 184/200
 - 57s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 185/200
 - 57s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 186/200
 - 57s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 187/200
 - 57s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 188/200
 - 57s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 189/200
 - 57s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 190/200
 - 57s - loss: 0.0031 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 191/200
 - 57s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 192/200
 - 57s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 193/200
 - 57s - loss: 0.0031 - val_loss: 0.0057
 - val_f1: 0.9872
Epoch 194/200
 - 57s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 195/200
 - 57s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 196/200
 - 57s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 197/200
 - 57s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 198/200
 - 57s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 199/200
 - 57s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9911
Epoch 200/200
 - 57s - loss: 0.0032 - val_loss: 0.0025
2020-01-09 05:34:42,250 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 05:35:42,949 [INFO] Last epoch loss evaluation: train_loss = 0.002261, val_loss = 0.002281
2020-01-09 05:35:42,949 [INFO] Training complete. time_to_train = 14216.45 sec, 236.94 min
2020-01-09 05:35:42,967 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_9/best_model.pickle
2020-01-09 05:35:42,971 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_9/training_error_history.csv
2020-01-09 05:35:43,159 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_9/training_error_history.png
2020-01-09 05:35:43,345 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_9/training_f1_history.png
2020-01-09 05:35:43,345 [INFO] Making predictions on training, validation, testing data
2020-01-09 05:36:52,375 [INFO] Evaluating predictions (results)
2020-01-09 05:37:02,530 [INFO] Dataset: Testing. Classification report below
2020-01-09 05:37:02,530 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.97      0.98      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.95      0.97      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      1.00    565562

2020-01-09 05:37:02,530 [INFO] Overall accuracy (micro avg): 0.9955371824839717
2020-01-09 05:37:14,078 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8082                       0.7714                0.0011                   0.2286  0.7780
2  Weighted avg        0.9964         0.9948                       0.9955                0.0090                   0.0045  0.9951
2020-01-09 05:37:24,400 [INFO] Dataset: Validation. Classification report below
2020-01-09 05:37:24,400 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.33      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.95      0.97      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.92      0.98      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.77    565562
          weighted avg       0.99      1.00      1.00    565562

2020-01-09 05:37:24,400 [INFO] Overall accuracy (micro avg): 0.9956697939394796
2020-01-09 05:37:36,098 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8081                       0.7667                0.0011                   0.2333  0.7736
2  Weighted avg        0.9965         0.9949                       0.9957                0.0086                   0.0043  0.9952
2020-01-09 05:38:10,195 [INFO] Dataset: Training. Classification report below
2020-01-09 05:38:10,195 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.98      0.94      3300
         DoS slowloris       0.96      0.98      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.94      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.81      0.77      0.78   1696684
          weighted avg       1.00      1.00      1.00   1696684

2020-01-09 05:38:10,197 [INFO] Overall accuracy (micro avg): 0.9957970959825165
/home/sunanda/test/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-09 05:38:48,925 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8118                       0.7711                0.0011                   0.2289  0.7791
2  Weighted avg        0.9966         0.9951                       0.9958                0.0086                   0.0042  0.9953
2020-01-09 05:38:48,978 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_9/ann_depth_ids17_layers_9_results.xlsx
2020-01-09 05:38:48,981 [INFO] ================= Finished running experiment no. 9 ================= 

2020-01-09 05:38:49,049 [INFO] Created directory: results_additional_exps/ann_depth_ids17_layers_10
2020-01-09 05:38:49,049 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids17_layers_10/run_log.log
2020-01-09 05:38:49,050 [INFO] ================= Running experiment no. 10  ================= 

2020-01-09 05:38:49,050 [INFO] Experiment parameters given below
2020-01-09 05:38:49,050 [INFO] 
{'experiment_num': 10, 'results_dir': 'results_additional_exps/ann_depth_ids17_layers_10', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'ann_depth_ids17_layers_10'}
2020-01-09 05:38:49,050 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids17_layers_10/tf_logs_run_2020_01_09-05_38_49
2020-01-09 05:38:49,050 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-09 05:38:49,050 [INFO] Reading X, y files
2020-01-09 05:38:49,050 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-09 05:38:53,146 [INFO] Reading complete. time_to_read=4.10 seconds
2020-01-09 05:38:53,146 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-09 05:38:54,540 [INFO] Reading complete. time_to_read=1.39 seconds
2020-01-09 05:38:54,541 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-09 05:38:55,937 [INFO] Reading complete. time_to_read=1.40 seconds
2020-01-09 05:38:55,937 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-09 05:38:56,125 [INFO] Reading complete. time_to_read=0.19 seconds
2020-01-09 05:38:56,125 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-09 05:38:56,191 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-09 05:38:56,191 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-09 05:38:56,258 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-09 05:38:59,455 [INFO] Initializing model
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-09 05:39:00,292 [INFO] =================================================================
2020-01-09 05:39:00,292 [INFO] dense_35 (Dense)             (None, 64)                5056      
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] batch_normalization_31 (Batc (None, 64)                256       
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] dropout_31 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] dense_36 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] batch_normalization_32 (Batc (None, 64)                256       
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,292 [INFO] dropout_32 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,292 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] dense_37 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] batch_normalization_33 (Batc (None, 64)                256       
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] dropout_33 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] dense_38 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] batch_normalization_34 (Batc (None, 64)                256       
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] dropout_34 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] dense_39 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,293 [INFO] batch_normalization_35 (Batc (None, 64)                256       
2020-01-09 05:39:00,293 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dropout_35 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dense_40 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] batch_normalization_36 (Batc (None, 64)                256       
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dropout_36 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dense_41 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] batch_normalization_37 (Batc (None, 64)                256       
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dropout_37 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] dense_42 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,294 [INFO] _________________________________________________________________
2020-01-09 05:39:00,294 [INFO] batch_normalization_38 (Batc (None, 64)                256       
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dropout_38 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dense_43 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] batch_normalization_39 (Batc (None, 64)                256       
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dropout_39 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dense_44 (Dense)             (None, 64)                4160      
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] batch_normalization_40 (Batc (None, 64)                256       
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dropout_40 (Dropout)         (None, 64)                0         
2020-01-09 05:39:00,295 [INFO] _________________________________________________________________
2020-01-09 05:39:00,295 [INFO] dense_45 (Dense)             (None, 12)                780       
2020-01-09 05:39:00,295 [INFO] =================================================================
2020-01-09 05:39:00,296 [INFO] Total params: 45,836
2020-01-09 05:39:00,296 [INFO] Trainable params: 44,556
2020-01-09 05:39:00,296 [INFO] Non-trainable params: 1,280
2020-01-09 05:39:00,296 [INFO] _________________________________________________________________
2020-01-09 05:39:00,296 [INFO] Training model
 - val_f1: 0.9948
Train on 1696684 samples, validate on 565562 samples
Epoch 1/200
 - 64s - loss: 0.0291 - val_loss: 0.0134
 - val_f1: 0.9616
Epoch 2/200
 - 63s - loss: 0.0137 - val_loss: 0.0109
 - val_f1: 0.9698
Epoch 3/200
 - 62s - loss: 0.0115 - val_loss: 0.0100
 - val_f1: 0.9739
Epoch 4/200
 - 62s - loss: 0.0103 - val_loss: 0.0089
 - val_f1: 0.9773
Epoch 5/200
 - 63s - loss: 0.0092 - val_loss: 0.0094
 - val_f1: 0.9742
Epoch 6/200
 - 63s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 7/200
 - 63s - loss: 0.0085 - val_loss: 0.0105
 - val_f1: 0.9733
Epoch 8/200
 - 62s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9741
Epoch 9/200
 - 63s - loss: 0.0072 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 10/200
 - 62s - loss: 0.0067 - val_loss: 0.0045
 - val_f1: 0.9893
Epoch 11/200
 - 62s - loss: 0.0066 - val_loss: 0.0073
 - val_f1: 0.9789
Epoch 12/200
 - 63s - loss: 0.0063 - val_loss: 0.0103
 - val_f1: 0.9786
Epoch 13/200
 - 62s - loss: 0.0064 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 14/200
 - 62s - loss: 0.0059 - val_loss: 0.0039
 - val_f1: 0.9911
Epoch 15/200
 - 63s - loss: 0.0066 - val_loss: 0.0051
 - val_f1: 0.9890
Epoch 16/200
 - 63s - loss: 0.0062 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 17/200
 - 63s - loss: 0.0058 - val_loss: 0.0081
 - val_f1: 0.9787
Epoch 18/200
 - 62s - loss: 0.0061 - val_loss: 0.0078
 - val_f1: 0.9771
Epoch 19/200
 - 62s - loss: 0.0056 - val_loss: 0.0039
 - val_f1: 0.9897
Epoch 20/200
 - 62s - loss: 0.0058 - val_loss: 0.0038
 - val_f1: 0.9913
Epoch 21/200
 - 62s - loss: 0.0052 - val_loss: 0.0036
2020-01-09 06:06:30,827 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_20.pickle
 - val_f1: 0.9912
Epoch 22/200
 - 62s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 23/200
 - 62s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9903
Epoch 24/200
 - 62s - loss: 0.0052 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 25/200
 - 62s - loss: 0.0051 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 26/200
 - 62s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 27/200
 - 62s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9920
Epoch 28/200
 - 62s - loss: 0.0047 - val_loss: 0.0068
 - val_f1: 0.9835
Epoch 29/200
 - 62s - loss: 0.0049 - val_loss: 0.0042
 - val_f1: 0.9904
Epoch 30/200
 - 62s - loss: 0.0052 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 31/200
 - 62s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9914
Epoch 32/200
 - 62s - loss: 0.0053 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 33/200
 - 62s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9898
Epoch 34/200
 - 62s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 35/200
 - 62s - loss: 0.0049 - val_loss: 0.0052
 - val_f1: 0.9914
Epoch 36/200
 - 62s - loss: 0.0051 - val_loss: 0.0062
 - val_f1: 0.9835
Epoch 37/200
 - 62s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9910
Epoch 38/200
 - 63s - loss: 0.0051 - val_loss: 0.0049
 - val_f1: 0.9895
Epoch 39/200
 - 62s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9886
Epoch 40/200
 - 62s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 41/200
 - 62s - loss: 0.0046 - val_loss: 0.0030
2020-01-09 06:32:44,544 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_40.pickle
 - val_f1: 0.9927
Epoch 42/200
 - 63s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 43/200
 - 62s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9884
Epoch 44/200
 - 62s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 45/200
 - 62s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 46/200
 - 62s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 47/200
 - 62s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 48/200
 - 62s - loss: 0.0042 - val_loss: 0.0044
 - val_f1: 0.9883
Epoch 49/200
 - 62s - loss: 0.0044 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 50/200
 - 62s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 51/200
 - 62s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 52/200
 - 62s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 53/200
 - 62s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9913
Epoch 54/200
 - 62s - loss: 0.0049 - val_loss: 0.0091
 - val_f1: 0.9821
Epoch 55/200
 - 62s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 56/200
 - 62s - loss: 0.0041 - val_loss: 0.0075
 - val_f1: 0.9827
Epoch 57/200
 - 62s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9926
Epoch 58/200
 - 62s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 59/200
 - 62s - loss: 0.0045 - val_loss: 0.0051
 - val_f1: 0.9900
Epoch 60/200
 - 62s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 61/200
 - 62s - loss: 0.0041 - val_loss: 0.0054
2020-01-09 06:58:57,961 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_60.pickle
 - val_f1: 0.9932
Epoch 62/200
 - 62s - loss: 0.0040 - val_loss: 0.0095
 - val_f1: 0.9843
Epoch 63/200
 - 62s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 64/200
 - 62s - loss: 0.0046 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 65/200
 - 62s - loss: 0.0040 - val_loss: 0.0057
 - val_f1: 0.9883
Epoch 66/200
 - 62s - loss: 0.0041 - val_loss: 0.0045
 - val_f1: 0.9877
Epoch 67/200
 - 62s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 68/200
 - 62s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 69/200
 - 62s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 70/200
 - 62s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 71/200
 - 62s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9876
Epoch 72/200
 - 62s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9910
Epoch 73/200
 - 62s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 74/200
 - 62s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 75/200
 - 62s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9910
Epoch 76/200
 - 62s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 77/200
 - 62s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 78/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 79/200
 - 62s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 80/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 81/200
 - 62s - loss: 0.0039 - val_loss: 0.0046
2020-01-09 07:25:11,329 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_80.pickle
 - val_f1: 0.9890
Epoch 82/200
 - 62s - loss: 0.0037 - val_loss: 0.0071
 - val_f1: 0.9858
Epoch 83/200
 - 62s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 84/200
 - 62s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 85/200
 - 62s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 86/200
 - 62s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 87/200
 - 62s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 88/200
 - 62s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9884
Epoch 89/200
 - 62s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9904
Epoch 90/200
 - 62s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 91/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 92/200
 - 62s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 93/200
 - 62s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 94/200
 - 62s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 95/200
 - 62s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 96/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 97/200
 - 62s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 98/200
 - 62s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 99/200
 - 62s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 100/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 101/200
 - 62s - loss: 0.0036 - val_loss: 0.0026
2020-01-09 07:51:25,314 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_100.pickle
 - val_f1: 0.9944
Epoch 102/200
 - 62s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9939
Epoch 103/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 104/200
 - 62s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 105/200
 - 62s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 106/200
 - 62s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 107/200
 - 62s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 108/200
 - 62s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 109/200
 - 62s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 110/200
 - 62s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 111/200
 - 62s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9921
Epoch 112/200
 - 62s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 113/200
 - 62s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 114/200
 - 62s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9930
Epoch 115/200
 - 62s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 116/200
 - 62s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 117/200
 - 62s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 118/200
 - 62s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 119/200
 - 62s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 120/200
 - 62s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 121/200
 - 62s - loss: 0.0036 - val_loss: 0.0025
2020-01-09 08:17:39,259 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_120.pickle
 - val_f1: 0.9947
Epoch 122/200
 - 62s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 123/200
 - 62s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 124/200
 - 62s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 125/200
 - 62s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 126/200
 - 62s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 127/200
 - 62s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 128/200
 - 62s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 129/200
 - 62s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9921
Epoch 130/200
 - 62s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 131/200
 - 62s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 132/200
 - 62s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 133/200
 - 62s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 134/200
 - 62s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 135/200
 - 62s - loss: 0.0035 - val_loss: 0.0064
 - val_f1: 0.9839
Epoch 136/200
 - 62s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 137/200
 - 63s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 138/200
 - 62s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 139/200
 - 62s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 140/200
 - 62s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 141/200
 - 62s - loss: 0.0037 - val_loss: 0.0026
2020-01-09 08:43:53,385 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids17_layers_10/ann_model_epoch_140.pickle
 - val_f1: 0.9939
Epoch 142/200
 - 62s - loss: 0.0035 - val_loss: 0.0062
 - val_f1: 0.9842
Epoch 143/200
 - 62s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 144/200
 - 62s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 145/200
 - 62s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 146/200
 - 62s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 147/200
 - 62s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9925
Epoch 148/200
 - 62s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 149/200
 - 62s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 150/200
 - 62s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 151/200
 - 62s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 152/200
 - 62s - loss: 0.0035 - val_loss: 0.0060
 - val_f1: 0.9865
Epoch 153/200
 - 62s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 154/200
 - 62s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 155/200
 - 62s - loss: 0.0035 - val_loss: 0.0024
2020-01-09 09:02:31,709 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 09:03:41,439 [INFO] Last epoch loss evaluation: train_loss = 0.002377, val_loss = 0.002403
2020-01-09 09:03:41,439 [INFO] Training complete. time_to_train = 12281.14 sec, 204.69 min
2020-01-09 09:03:41,458 [INFO] Model saved to results_additional_exps/ann_depth_ids17_layers_10/best_model.pickle
2020-01-09 09:03:41,461 [INFO] Training history saved to: results_additional_exps/ann_depth_ids17_layers_10/training_error_history.csv
2020-01-09 09:03:41,647 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_10/training_error_history.png
2020-01-09 09:03:41,832 [INFO] Plot saved to: results_additional_exps/ann_depth_ids17_layers_10/training_f1_history.png
2020-01-09 09:03:41,832 [INFO] Making predictions on training, validation, testing data
2020-01-09 09:05:02,243 [INFO] Evaluating predictions (results)
2020-01-09 09:05:12,451 [INFO] Dataset: Testing. Classification report below
2020-01-09 09:05:12,451 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.95      0.97      0.96      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.98      0.95      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-09 09:05:12,451 [INFO] Overall accuracy (micro avg): 0.9952277557544531
2020-01-09 09:05:24,072 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.8065                       0.7722                0.0012                   0.2278  0.7773
2  Weighted avg        0.9961         0.9945                       0.9952                0.0093                   0.0048  0.9948
2020-01-09 09:05:34,421 [INFO] Dataset: Validation. Classification report below
2020-01-09 09:05:34,422 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.99      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.95      0.98      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.93      0.97      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.81      0.77      0.77    565562
          weighted avg       0.99      1.00      0.99    565562

2020-01-09 09:05:34,422 [INFO] Overall accuracy (micro avg): 0.9954381659305257
2020-01-09 09:05:46,185 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8076                       0.7683                0.0011                   0.2317  0.7741
2  Weighted avg        0.9963         0.9947                       0.9954                0.0087                   0.0046  0.9950
2020-01-09 09:06:20,285 [INFO] Dataset: Training. Classification report below
2020-01-09 09:06:20,285 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.35      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.99      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.95      0.98      0.97      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.94      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.81      0.77      0.78   1696684
          weighted avg       0.99      1.00      1.00   1696684

2020-01-09 09:06:20,285 [INFO] Overall accuracy (micro avg): 0.9955165487503861
2020-01-09 09:06:59,015 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8104                       0.7719                0.0011                   0.2281  0.7787
2  Weighted avg        0.9963         0.9948                       0.9955                0.0089                   0.0045  0.9950
2020-01-09 09:06:59,066 [INFO] Results saved to: results_additional_exps/ann_depth_ids17_layers_10/ann_depth_ids17_layers_10_results.xlsx
2020-01-09 09:06:59,071 [INFO] ================= Finished running experiment no. 10 ================= 

2020-01-09 09:06:59,137 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9948
Epoch 00155: early stopping
