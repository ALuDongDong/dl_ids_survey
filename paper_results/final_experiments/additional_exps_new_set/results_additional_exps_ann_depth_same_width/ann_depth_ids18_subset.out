Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-08 16:15:32,335 [INFO] Read 5 experiments from file: experiment_specs/additional_exps/ann_depth.csv
2020-01-08 16:15:32,335 [INFO] ================= Started running experiments ================= 

2020-01-08 16:15:32,336 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_1
2020-01-08 16:15:32,336 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_1/run_log.log
2020-01-08 16:15:32,336 [INFO] ================= Running experiment no. 1  ================= 

2020-01-08 16:15:32,336 [INFO] Experiment parameters given below
2020-01-08 16:15:32,336 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_1'}
2020-01-08 16:15:32,336 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_1/tf_logs_run_2020_01_08-16_15_32
2020-01-08 16:15:32,336 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 16:15:32,337 [INFO] Reading X, y files
2020-01-08 16:15:32,337 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 16:15:32,346 [INFO] NumExpr defaulting to 8 threads.
2020-01-08 16:15:36,368 [INFO] Reading complete. time_to_read=4.03 seconds
2020-01-08 16:15:36,368 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 16:15:37,742 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 16:15:37,742 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 16:15:39,119 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 16:15:39,119 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 16:15:39,479 [INFO] Reading complete. time_to_read=0.36 seconds
2020-01-08 16:15:39,479 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 16:15:39,586 [INFO] Reading complete. time_to_read=0.11 seconds
2020-01-08 16:15:39,586 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 16:15:39,694 [INFO] Reading complete. time_to_read=0.11 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2167 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2178 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2179 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2180 thread 3 bound to OS proc set 3
2020-01-08 16:15:43,121 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-08 16:15:43,136 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 16:15:43,209 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 16:15:43,252 [INFO] _________________________________________________________________
2020-01-08 16:15:43,252 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 16:15:43,252 [INFO] =================================================================
2020-01-08 16:15:43,252 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-08 16:15:43,253 [INFO] _________________________________________________________________
2020-01-08 16:15:43,253 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 16:15:43,253 [INFO] _________________________________________________________________
2020-01-08 16:15:43,253 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 16:15:43,253 [INFO] _________________________________________________________________
2020-01-08 16:15:43,253 [INFO] dense_2 (Dense)              (None, 15)                975       
2020-01-08 16:15:43,253 [INFO] =================================================================
2020-01-08 16:15:43,253 [INFO] Total params: 6,223
2020-01-08 16:15:43,253 [INFO] Trainable params: 6,095
2020-01-08 16:15:43,253 [INFO] Non-trainable params: 128
2020-01-08 16:15:43,253 [INFO] _________________________________________________________________
2020-01-08 16:15:43,254 [INFO] Training model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 16:15:43,659 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 16:15:43.978635: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-08 16:15:43.999566: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-08 16:15:43.999712: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5585fae79560 executing computations on platform Host. Devices:
2020-01-08 16:15:43.999733: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-08 16:15:43.999825: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2188 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2207 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2208 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2209 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2210 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2189 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2211 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2213 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2212 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2215 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2216 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2214 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2217 thread 16 bound to OS proc set 0
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 23s - loss: 0.0148 - val_loss: 0.0086
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2230 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2231 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 2167 tid 2232 thread 19 bound to OS proc set 3
 - val_f1: 0.9774
Epoch 2/200
 - 23s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9764
Epoch 3/200
 - 23s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 4/200
 - 23s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 5/200
 - 23s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 6/200
 - 23s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 7/200
 - 23s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9765
Epoch 8/200
 - 23s - loss: 0.0082 - val_loss: 0.0633
 - val_f1: 0.7939
Epoch 9/200
 - 23s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 10/200
 - 23s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 11/200
 - 23s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 12/200
 - 23s - loss: 0.0081 - val_loss: 0.0606
 - val_f1: 0.8355
Epoch 13/200
 - 23s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9784
Epoch 14/200
 - 23s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 15/200
 - 23s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 16/200
 - 23s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 17/200
 - 23s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9762
Epoch 18/200
 - 23s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 19/200
 - 23s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 20/200
 - 23s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 21/200
 - 23s - loss: 0.0081 - val_loss: 0.0081
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 16:27:16,392 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_20.pickle
 - val_f1: 0.9763
Epoch 22/200
 - 23s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 23/200
 - 23s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 24/200
 - 23s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 25/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 26/200
 - 23s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 27/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 28/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 29/200
 - 23s - loss: 0.0080 - val_loss: 0.0140
 - val_f1: 0.9535
Epoch 30/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 31/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 32/200
 - 23s - loss: 0.0080 - val_loss: 0.0127
 - val_f1: 0.9658
Epoch 33/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 34/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9762
Epoch 35/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 36/200
 - 23s - loss: 0.0080 - val_loss: 0.0109
 - val_f1: 0.9711
Epoch 37/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 38/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 39/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 40/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 41/200
 - 23s - loss: 0.0080 - val_loss: 0.0206
2020-01-08 16:38:24,430 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_40.pickle
 - val_f1: 0.9513
Epoch 42/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 43/200
 - 23s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 44/200
 - 23s - loss: 0.0080 - val_loss: 0.0130
 - val_f1: 0.9587
Epoch 45/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 46/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 47/200
 - 23s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9763
Epoch 48/200
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 49/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 50/200
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 51/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 52/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 53/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 54/200
 - 23s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 55/200
 - 23s - loss: 0.0080 - val_loss: 0.0090
 - val_f1: 0.9763
Epoch 56/200
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 57/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 58/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 59/200
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 60/200
 - 23s - loss: 0.0080 - val_loss: 0.0149
 - val_f1: 0.9588
Epoch 61/200
 - 23s - loss: 0.0079 - val_loss: 0.0081
2020-01-08 16:49:32,553 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 23s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 63/200
 - 23s - loss: 0.0079 - val_loss: 0.0133
 - val_f1: 0.9638
Epoch 64/200
 - 23s - loss: 0.0080 - val_loss: 0.0143
 - val_f1: 0.9545
Epoch 65/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 66/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 67/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 68/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 69/200
 - 23s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9758
Epoch 70/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 71/200
 - 23s - loss: 0.0079 - val_loss: 0.0141
 - val_f1: 0.9563
Epoch 72/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 73/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 74/200
 - 23s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9763
Epoch 75/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 76/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 77/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9764
Epoch 78/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 79/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 80/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 81/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
2020-01-08 17:00:40,612 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_80.pickle
 - val_f1: 0.9780
Epoch 82/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 83/200
 - 23s - loss: 0.0079 - val_loss: 0.0160
 - val_f1: 0.9550
Epoch 84/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9769
Epoch 85/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 86/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 87/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 88/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9765
Epoch 89/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 90/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 91/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 92/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 93/200
 - 23s - loss: 0.0079 - val_loss: 0.0147
 - val_f1: 0.9571
Epoch 94/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 95/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 96/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 97/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 98/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 99/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 100/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 101/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
2020-01-08 17:11:48,821 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9765
Epoch 103/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 104/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 105/200
 - 23s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 106/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 107/200
 - 23s - loss: 0.0079 - val_loss: 0.0112
 - val_f1: 0.9694
Epoch 108/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 109/200
 - 23s - loss: 0.0079 - val_loss: 0.0148
 - val_f1: 0.9480
Epoch 110/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 111/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 112/200
 - 23s - loss: 0.0079 - val_loss: 0.0106
 - val_f1: 0.9734
Epoch 113/200
 - 23s - loss: 0.0079 - val_loss: 0.0139
 - val_f1: 0.9561
Epoch 114/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 115/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 116/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9764
Epoch 117/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 118/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 119/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 120/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9766
Epoch 121/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
2020-01-08 17:22:57,069 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_120.pickle
 - val_f1: 0.9783
Epoch 122/200
 - 23s - loss: 0.0079 - val_loss: 0.0112
 - val_f1: 0.9692
Epoch 123/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 124/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 125/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 126/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 127/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 128/200
 - 23s - loss: 0.0079 - val_loss: 0.0119
 - val_f1: 0.9689
Epoch 129/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 130/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 131/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 132/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 133/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 134/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 135/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 136/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 137/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 138/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 139/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 140/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 141/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
2020-01-08 17:34:05,758 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_140.pickle
 - val_f1: 0.9781
Epoch 142/200
 - 23s - loss: 0.0079 - val_loss: 0.0088
 - val_f1: 0.9761
Epoch 143/200
 - 23s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 144/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 145/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 146/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 147/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 148/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 149/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 150/200
 - 23s - loss: 0.0079 - val_loss: 0.0099
 - val_f1: 0.9737
Epoch 151/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 152/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 153/200
 - 23s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 154/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 155/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 156/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 157/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 158/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 159/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 160/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 161/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
2020-01-08 17:45:14,815 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/ann_model_epoch_160.pickle
 - val_f1: 0.9779
Epoch 162/200
 - 23s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 163/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 164/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 165/200
 - 23s - loss: 0.0079 - val_loss: 0.0079
2020-01-08 17:47:39,333 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 17:48:23,788 [INFO] Last epoch loss evaluation: train_loss = 0.007763, val_loss = 0.007781
2020-01-08 17:48:23,788 [INFO] Training complete. time_to_train = 5560.53 sec, 92.68 min
2020-01-08 17:48:23,792 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_1/best_model.pickle
2020-01-08 17:48:23,795 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_error_history.csv
2020-01-08 17:48:23,984 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_error_history.png
2020-01-08 17:48:24,229 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/training_f1_history.png
2020-01-08 17:48:24,229 [INFO] Making predictions on training, validation, testing data
2020-01-08 17:49:11,631 [INFO] Evaluating predictions (results)
2020-01-08 17:49:34,884 [INFO] Dataset: Testing. Classification report below
2020-01-08 17:49:34,884 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.25      0.40        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.18      0.29        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.47      0.57      5596
   DoS attacks-Slowloris       0.93      0.98      0.96       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.38      0.00      0.00      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.89      0.70      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 17:49:34,884 [INFO] Overall accuracy (micro avg): 0.9832436853977146
2020-01-08 17:49:59,766 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8943                       0.7050                0.0044                   0.2950  0.7424
2  Weighted avg        0.9910         0.9774                       0.9832                0.0498                   0.0168  0.9780
2020-01-08 17:50:22,893 [INFO] Dataset: Validation. Classification report below
2020-01-08 17:50:22,894 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.40      0.57        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.22      0.34        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.47      0.57      5596
   DoS attacks-Slowloris       0.92      0.98      0.95       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.35      0.00      0.00      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.89      0.72      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 17:50:22,894 [INFO] Overall accuracy (micro avg): 0.9832870375390984
2020-01-08 17:50:47,790 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.8920                       0.7237                0.0044                   0.2763  0.7592
2  Weighted avg        0.9910         0.9771                       0.9833                0.0497                   0.0167  0.9780
2020-01-08 17:52:03,562 [INFO] Dataset: Training. Classification report below
2020-01-08 17:52:03,562 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.22      0.36        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.66      0.17      0.27       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.47      0.57     16787
   DoS attacks-Slowloris       0.94      0.99      0.97      1318
          FTP-BruteForce       0.69      0.87      0.77     23153
           Infilteration       0.43      0.00      0.00     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.90      0.70      0.74   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 17:52:03,562 [INFO] Overall accuracy (micro avg): 0.9832596766680678
2020-01-08 17:53:25,183 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.8953                       0.7034                0.0044                   0.2966  0.7396
2  Weighted avg        0.9910         0.9779                       0.9833                0.0498                   0.0167  0.9780
2020-01-08 17:53:25,259 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_1/ann_depth_ids18_subset_layers_1_results.xlsx
2020-01-08 17:53:25,264 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-08 17:53:25,328 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_2
2020-01-08 17:53:25,328 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_2/run_log.log
2020-01-08 17:53:25,328 [INFO] ================= Running experiment no. 2  ================= 

2020-01-08 17:53:25,328 [INFO] Experiment parameters given below
2020-01-08 17:53:25,328 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_2'}
2020-01-08 17:53:25,328 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_2/tf_logs_run_2020_01_08-17_53_25
2020-01-08 17:53:25,328 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 17:53:25,329 [INFO] Reading X, y files
2020-01-08 17:53:25,329 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 17:53:29,326 [INFO] Reading complete. time_to_read=4.00 seconds
2020-01-08 17:53:29,326 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 17:53:30,695 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 17:53:30,695 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 17:53:32,071 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 17:53:32,072 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 17:53:32,406 [INFO] Reading complete. time_to_read=0.33 seconds
2020-01-08 17:53:32,406 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 17:53:32,505 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 17:53:32,505 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 17:53:32,604 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 17:53:36,005 [INFO] Initializing model
2020-01-08 17:53:36,212 [INFO] _________________________________________________________________
2020-01-08 17:53:36,212 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 17:53:36,212 [INFO] =================================================================
2020-01-08 17:53:36,212 [INFO] dense_3 (Dense)              (None, 64)                4992      
2020-01-08 17:53:36,212 [INFO] _________________________________________________________________
2020-01-08 17:53:36,212 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 17:53:36,212 [INFO] _________________________________________________________________
2020-01-08 17:53:36,212 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 17:53:36,212 [INFO] _________________________________________________________________
2020-01-08 17:53:36,212 [INFO] dense_4 (Dense)              (None, 64)                4160      
2020-01-08 17:53:36,212 [INFO] _________________________________________________________________
2020-01-08 17:53:36,213 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 17:53:36,213 [INFO] _________________________________________________________________
2020-01-08 17:53:36,213 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 17:53:36,213 [INFO] _________________________________________________________________
2020-01-08 17:53:36,213 [INFO] dense_5 (Dense)              (None, 15)                975       
2020-01-08 17:53:36,213 [INFO] =================================================================
2020-01-08 17:53:36,213 [INFO] Total params: 10,639
2020-01-08 17:53:36,213 [INFO] Trainable params: 10,383
2020-01-08 17:53:36,213 [INFO] Non-trainable params: 256
2020-01-08 17:53:36,213 [INFO] _________________________________________________________________
2020-01-08 17:53:36,213 [INFO] Training model
 - val_f1: 0.9782
Epoch 00165: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 30s - loss: 0.0141 - val_loss: 0.0087
 - val_f1: 0.9772
Epoch 2/200
 - 29s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9765
Epoch 3/200
 - 29s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 4/200
 - 29s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 5/200
 - 29s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 6/200
 - 29s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 7/200
 - 29s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 8/200
 - 29s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 9/200
 - 29s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 10/200
 - 29s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 11/200
 - 28s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 12/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 13/200
 - 28s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9766
Epoch 14/200
 - 28s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 15/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 16/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 17/200
 - 28s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 18/200
 - 28s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 19/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 20/200
 - 29s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 21/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
2020-01-08 18:08:00,376 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_20.pickle
 - val_f1: 0.9784
Epoch 22/200
 - 29s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 23/200
 - 29s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 24/200
 - 28s - loss: 0.0080 - val_loss: 0.0224
 - val_f1: 0.9117
Epoch 25/200
 - 28s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 26/200
 - 29s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 27/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 28/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 29/200
 - 28s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9756
Epoch 30/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 31/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9768
Epoch 32/200
 - 28s - loss: 0.0080 - val_loss: 0.0101
 - val_f1: 0.9720
Epoch 33/200
 - 29s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 34/200
 - 29s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 35/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 36/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 37/200
 - 28s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 38/200
 - 28s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 39/200
 - 28s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 40/200
 - 28s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 41/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 18:21:52,031 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_40.pickle
 - val_f1: 0.9787
Epoch 42/200
 - 29s - loss: 0.0079 - val_loss: 0.0202
 - val_f1: 0.9292
Epoch 43/200
 - 29s - loss: 0.0079 - val_loss: 0.0328
 - val_f1: 0.8636
Epoch 44/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 45/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 46/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 47/200
 - 29s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 48/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 49/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 50/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 51/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 52/200
 - 29s - loss: 0.0079 - val_loss: 0.0173
 - val_f1: 0.9463
Epoch 53/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 54/200
 - 29s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 55/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 56/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 57/200
 - 29s - loss: 0.0079 - val_loss: 0.0091
 - val_f1: 0.9760
Epoch 58/200
 - 29s - loss: 0.0078 - val_loss: 0.0240
 - val_f1: 0.8767
Epoch 59/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 60/200
 - 29s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 61/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 18:35:49,704 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_60.pickle
 - val_f1: 0.9785
Epoch 62/200
 - 29s - loss: 0.0079 - val_loss: 0.0115
 - val_f1: 0.9571
Epoch 63/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 64/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 65/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 66/200
 - 29s - loss: 0.0078 - val_loss: 0.0302
 - val_f1: 0.8327
Epoch 67/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 68/200
 - 29s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 69/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 70/200
 - 29s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 71/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 72/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 73/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 74/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 75/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 76/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 77/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 78/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 79/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 80/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 81/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 18:49:47,429 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_80.pickle
 - val_f1: 0.9786
Epoch 82/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 83/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 84/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 85/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 86/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 87/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 88/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 89/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 90/200
 - 29s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 91/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 92/200
 - 29s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9763
Epoch 93/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 94/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 95/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 96/200
 - 29s - loss: 0.0078 - val_loss: 0.0122
 - val_f1: 0.9582
Epoch 97/200
 - 29s - loss: 0.0078 - val_loss: 0.0162
 - val_f1: 0.9498
Epoch 98/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 99/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 100/200
 - 29s - loss: 0.0078 - val_loss: 0.0152
 - val_f1: 0.9492
Epoch 101/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 19:03:45,068 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_100.pickle
 - val_f1: 0.9790
Epoch 102/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 103/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 104/200
 - 29s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 105/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 106/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 107/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 108/200
 - 29s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 109/200
 - 29s - loss: 0.0078 - val_loss: 0.0100
 - val_f1: 0.9754
Epoch 110/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 111/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 112/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 113/200
 - 29s - loss: 0.0078 - val_loss: 0.0126
 - val_f1: 0.9510
Epoch 114/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 115/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 116/200
 - 29s - loss: 0.0078 - val_loss: 0.0157
 - val_f1: 0.9520
Epoch 117/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 118/200
 - 29s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 119/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 120/200
 - 29s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 121/200
 - 29s - loss: 0.0078 - val_loss: 0.0078
2020-01-08 19:17:43,384 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_120.pickle
 - val_f1: 0.9785
Epoch 122/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 123/200
 - 29s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 124/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9792
Epoch 125/200
 - 29s - loss: 0.0078 - val_loss: 0.0158
 - val_f1: 0.9181
Epoch 126/200
 - 29s - loss: 0.0078 - val_loss: 0.0158
 - val_f1: 0.9389
Epoch 127/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 128/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 129/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 130/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 131/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 132/200
 - 29s - loss: 0.0078 - val_loss: 0.0226
 - val_f1: 0.9153
Epoch 133/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 134/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 135/200
 - 29s - loss: 0.0078 - val_loss: 0.0104
 - val_f1: 0.9747
Epoch 136/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 137/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9795
Epoch 138/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 139/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 140/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 141/200
 - 29s - loss: 0.0078 - val_loss: 0.0142
2020-01-08 19:31:41,033 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_140.pickle
 - val_f1: 0.9455
Epoch 142/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 143/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 144/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 145/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 146/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 147/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 148/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 149/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 150/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 151/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 152/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 153/200
 - 29s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 154/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 155/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 156/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 157/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 158/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 159/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 160/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 161/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 19:45:38,229 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_160.pickle
 - val_f1: 0.9791
Epoch 162/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 163/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 164/200
 - 29s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 165/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 166/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 167/200
 - 29s - loss: 0.0078 - val_loss: 0.0117
 - val_f1: 0.9623
Epoch 168/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 169/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 170/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 171/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 172/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 173/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 174/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 175/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 176/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 177/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 178/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 179/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 180/200
 - 29s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 181/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
2020-01-08 19:59:35,938 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/ann_model_epoch_180.pickle
 - val_f1: 0.9788
Epoch 182/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 183/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 184/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 185/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 186/200
 - 29s - loss: 0.0077 - val_loss: 0.0184
 - val_f1: 0.9205
Epoch 187/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 188/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 189/200
 - 29s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 190/200
 - 29s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 191/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 192/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 193/200
 - 29s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 194/200
 - 29s - loss: 0.0078 - val_loss: 0.0143
 - val_f1: 0.9730
Epoch 195/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 196/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 197/200
 - 29s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 198/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 199/200
 - 29s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 200/200
 - 29s - loss: 0.0077 - val_loss: 0.0076
2020-01-08 20:13:04,754 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 20:13:56,879 [INFO] Last epoch loss evaluation: train_loss = 0.007581, val_loss = 0.007604
2020-01-08 20:13:56,879 [INFO] Training complete. time_to_train = 8420.67 sec, 140.34 min
2020-01-08 20:13:56,884 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_2/best_model.pickle
2020-01-08 20:13:56,887 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_error_history.csv
2020-01-08 20:13:57,076 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_error_history.png
2020-01-08 20:13:57,264 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/training_f1_history.png
2020-01-08 20:13:57,264 [INFO] Making predictions on training, validation, testing data
2020-01-08 20:14:56,205 [INFO] Evaluating predictions (results)
2020-01-08 20:15:19,291 [INFO] Dataset: Testing. Classification report below
2020-01-08 20:15:19,291 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.21      0.34        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.53      0.61      5596
   DoS attacks-Slowloris       0.97      0.97      0.97       440
          FTP-BruteForce       0.71      0.85      0.78      7718
           Infilteration       0.48      0.02      0.04      6404
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.90      0.74      0.76    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 20:15:19,291 [INFO] Overall accuracy (micro avg): 0.983493109089557
2020-01-08 20:15:44,127 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.9021                       0.7435                0.0044                   0.2565  0.7619
2  Weighted avg        0.9910         0.9787                       0.9835                0.0497                   0.0165  0.9787
2020-01-08 20:16:07,181 [INFO] Dataset: Validation. Classification report below
2020-01-08 20:16:07,181 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.24      0.39        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       439
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.43      0.02      0.03      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.90      0.77      0.79    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 20:16:07,181 [INFO] Overall accuracy (micro avg): 0.9835720936285316
2020-01-08 20:16:32,012 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.9018                       0.7684                0.0044                   0.2316  0.7866
2  Weighted avg        0.9910         0.9783                       0.9836                0.0496                   0.0164  0.9788
2020-01-08 20:17:47,678 [INFO] Dataset: Training. Classification report below
2020-01-08 20:17:47,678 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.26      0.41        73
        Brute Force -XSS       1.00      0.46      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.72      0.53      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.85      0.78     23153
           Infilteration       0.51      0.02      0.04     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.91      0.76      0.78   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 20:17:47,678 [INFO] Overall accuracy (micro avg): 0.9836154801901612
2020-01-08 20:19:09,221 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.9066                       0.7624                0.0044                   0.2376  0.7841
2  Weighted avg        0.9911         0.9791                       0.9836                0.0494                   0.0164  0.9789
2020-01-08 20:19:09,295 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_2/ann_depth_ids18_subset_layers_2_results.xlsx
2020-01-08 20:19:09,299 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-08 20:19:09,359 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_3
2020-01-08 20:19:09,359 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_3/run_log.log
2020-01-08 20:19:09,359 [INFO] ================= Running experiment no. 3  ================= 

2020-01-08 20:19:09,360 [INFO] Experiment parameters given below
2020-01-08 20:19:09,360 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_3'}
2020-01-08 20:19:09,360 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_3/tf_logs_run_2020_01_08-20_19_09
2020-01-08 20:19:09,360 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 20:19:09,360 [INFO] Reading X, y files
2020-01-08 20:19:09,360 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 20:19:13,380 [INFO] Reading complete. time_to_read=4.02 seconds
2020-01-08 20:19:13,380 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 20:19:14,745 [INFO] Reading complete. time_to_read=1.36 seconds
2020-01-08 20:19:14,746 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 20:19:16,113 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-08 20:19:16,113 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 20:19:16,434 [INFO] Reading complete. time_to_read=0.32 seconds
2020-01-08 20:19:16,434 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 20:19:16,534 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 20:19:16,535 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 20:19:16,633 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 20:19:20,028 [INFO] Initializing model
2020-01-08 20:19:20,319 [INFO] _________________________________________________________________
2020-01-08 20:19:20,319 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 20:19:20,319 [INFO] =================================================================
2020-01-08 20:19:20,319 [INFO] dense_6 (Dense)              (None, 64)                4992      
2020-01-08 20:19:20,319 [INFO] _________________________________________________________________
2020-01-08 20:19:20,319 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-08 20:19:20,319 [INFO] _________________________________________________________________
2020-01-08 20:19:20,319 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-08 20:19:20,319 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] dense_7 (Dense)              (None, 64)                4160      
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] dense_8 (Dense)              (None, 64)                4160      
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,320 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-08 20:19:20,320 [INFO] _________________________________________________________________
2020-01-08 20:19:20,321 [INFO] dense_9 (Dense)              (None, 15)                975       
2020-01-08 20:19:20,321 [INFO] =================================================================
2020-01-08 20:19:20,321 [INFO] Total params: 15,055
2020-01-08 20:19:20,321 [INFO] Trainable params: 14,671
2020-01-08 20:19:20,321 [INFO] Non-trainable params: 384
2020-01-08 20:19:20,321 [INFO] _________________________________________________________________
2020-01-08 20:19:20,321 [INFO] Training model
 - val_f1: 0.9789
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 37s - loss: 0.0140 - val_loss: 0.0084
 - val_f1: 0.9772
Epoch 2/200
 - 36s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 3/200
 - 36s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 4/200
 - 36s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 5/200
 - 36s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 6/200
 - 36s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 7/200
 - 36s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 8/200
 - 36s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 9/200
 - 36s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 10/200
 - 36s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9764
Epoch 11/200
 - 36s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 12/200
 - 36s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 13/200
 - 36s - loss: 0.0081 - val_loss: 0.0128
 - val_f1: 0.9502
Epoch 14/200
 - 36s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 15/200
 - 36s - loss: 0.0081 - val_loss: 0.0829
 - val_f1: 0.7629
Epoch 16/200
 - 36s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 17/200
 - 36s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 18/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 19/200
 - 36s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 20/200
 - 36s - loss: 0.0080 - val_loss: 0.0272
 - val_f1: 0.8831
Epoch 21/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
2020-01-08 20:37:14,134 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_20.pickle
 - val_f1: 0.9780
Epoch 22/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 23/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 24/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 25/200
 - 36s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 26/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 27/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 28/200
 - 36s - loss: 0.0080 - val_loss: 0.0241
 - val_f1: 0.9185
Epoch 29/200
 - 36s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 30/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 31/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 32/200
 - 36s - loss: 0.0079 - val_loss: 0.0189
 - val_f1: 0.9450
Epoch 33/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 34/200
 - 36s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 35/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 36/200
 - 36s - loss: 0.0079 - val_loss: 0.0419
 - val_f1: 0.8772
Epoch 37/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 38/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 39/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 40/200
 - 36s - loss: 0.0079 - val_loss: 0.0436
 - val_f1: 0.8248
Epoch 41/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 20:54:27,230 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_40.pickle
 - val_f1: 0.9786
Epoch 42/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 43/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 44/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 45/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 46/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 47/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 48/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 49/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 50/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 51/200
 - 36s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 52/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 53/200
 - 36s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 54/200
 - 35s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 55/200
 - 35s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 56/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 57/200
 - 35s - loss: 0.0079 - val_loss: 0.0170
 - val_f1: 0.9454
Epoch 58/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 59/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 60/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 61/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 21:11:37,636 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_60.pickle
 - val_f1: 0.9789
Epoch 62/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 63/200
 - 35s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 64/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9797
Epoch 65/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 66/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 67/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 68/200
 - 35s - loss: 0.0079 - val_loss: 0.0316
 - val_f1: 0.8756
Epoch 69/200
 - 35s - loss: 0.0079 - val_loss: 0.0170
 - val_f1: 0.9516
Epoch 70/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 71/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 72/200
 - 35s - loss: 0.0078 - val_loss: 0.0642
 - val_f1: 0.8151
Epoch 73/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 74/200
 - 35s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 75/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 76/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 77/200
 - 35s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 78/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 79/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 80/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 81/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 21:28:43,371 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_80.pickle
 - val_f1: 0.9787
Epoch 82/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 83/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 84/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 85/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 86/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 87/200
 - 35s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 88/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 89/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 90/200
 - 35s - loss: 0.0078 - val_loss: 0.0502
 - val_f1: 0.8287
Epoch 91/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 92/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 93/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 94/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 95/200
 - 35s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 96/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 97/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 98/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 99/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 100/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 101/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 21:45:48,495 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_100.pickle
 - val_f1: 0.9788
Epoch 102/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 103/200
 - 35s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 104/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 105/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 106/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 107/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 108/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 109/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 110/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 111/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 112/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 113/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 114/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 115/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 116/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 117/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 118/200
 - 35s - loss: 0.0078 - val_loss: 0.0612
 - val_f1: 0.7927
Epoch 119/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 120/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 121/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 22:02:53,232 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_120.pickle
 - val_f1: 0.9788
Epoch 122/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 123/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 124/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 125/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 126/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 127/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 128/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 129/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 130/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 131/200
 - 35s - loss: 0.0078 - val_loss: 0.0100
 - val_f1: 0.9731
Epoch 132/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 133/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 134/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 135/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 136/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 137/200
 - 35s - loss: 0.0078 - val_loss: 0.0205
 - val_f1: 0.9038
Epoch 138/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 139/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 140/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 141/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 22:19:58,070 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_140.pickle
 - val_f1: 0.9789
Epoch 142/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 143/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 144/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 145/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 146/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 147/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 148/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 149/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 150/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 151/200
 - 35s - loss: 0.0078 - val_loss: 0.0104
 - val_f1: 0.9699
Epoch 152/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 153/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 154/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 155/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 156/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 157/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 158/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 159/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 160/200
 - 35s - loss: 0.0078 - val_loss: 0.0458
 - val_f1: 0.8562
Epoch 161/200
 - 35s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 22:37:01,187 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_160.pickle
 - val_f1: 0.9787
Epoch 162/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 163/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 164/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 165/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 166/200
 - 35s - loss: 0.0078 - val_loss: 0.0634
 - val_f1: 0.8473
Epoch 167/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 168/200
 - 35s - loss: 0.0078 - val_loss: 0.0672
 - val_f1: 0.8233
Epoch 169/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 170/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 171/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 172/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 173/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 174/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 175/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 176/200
 - 35s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9762
Epoch 177/200
 - 35s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 178/200
 - 35s - loss: 0.0078 - val_loss: 0.0493
 - val_f1: 0.8207
Epoch 179/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 180/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 181/200
 - 35s - loss: 0.0078 - val_loss: 0.0715
2020-01-08 22:54:04,809 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/ann_model_epoch_180.pickle
 - val_f1: 0.8025
Epoch 182/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 183/200
 - 35s - loss: 0.0078 - val_loss: 0.0222
 - val_f1: 0.9033
Epoch 184/200
 - 35s - loss: 0.0078 - val_loss: 0.0426
 - val_f1: 0.8630
Epoch 185/200
 - 35s - loss: 0.0078 - val_loss: 0.0623
 - val_f1: 0.8211
Epoch 186/200
 - 35s - loss: 0.0078 - val_loss: 0.0435
 - val_f1: 0.8266
Epoch 187/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 188/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 189/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 190/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 191/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 192/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 193/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 194/200
 - 35s - loss: 0.0078 - val_loss: 0.0229
 - val_f1: 0.9326
Epoch 195/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 196/200
 - 35s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 23:07:09,723 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 23:08:16,663 [INFO] Last epoch loss evaluation: train_loss = 0.007576, val_loss = 0.007601
2020-01-08 23:08:16,663 [INFO] Training complete. time_to_train = 10136.34 sec, 168.94 min
2020-01-08 23:08:16,670 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_3/best_model.pickle
2020-01-08 23:08:16,673 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_error_history.csv
2020-01-08 23:08:16,873 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_error_history.png
2020-01-08 23:08:17,048 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/training_f1_history.png
2020-01-08 23:08:17,048 [INFO] Making predictions on training, validation, testing data
2020-01-08 23:09:29,857 [INFO] Evaluating predictions (results)
2020-01-08 23:09:52,934 [INFO] Dataset: Testing. Classification report below
2020-01-08 23:09:52,934 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.80      0.33      0.47        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      0.99      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.97      0.99      0.98       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.45      0.01      0.02      6404
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.89      0.75      0.77    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 23:09:52,934 [INFO] Overall accuracy (micro avg): 0.9836712688694446
2020-01-08 23:10:17,771 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.8884                       0.7520                0.0044                   0.2480  0.7706
2  Weighted avg        0.9911         0.9785                       0.9837                0.0492                   0.0163  0.9787
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 23:10:40,798 [INFO] Dataset: Validation. Classification report below
2020-01-08 23:10:40,798 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.86      0.48      0.62        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.97      0.85        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.72      0.87      0.78      7718
           Infilteration       0.43      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.83      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 23:10:40,798 [INFO] Overall accuracy (micro avg): 0.9837765903883424
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 23:11:05,615 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.8288                       0.7666                0.0044                   0.2334  0.7759
2  Weighted avg        0.9911         0.9784                       0.9838                0.0492                   0.0162  0.9788
2020-01-08 23:12:21,345 [INFO] Dataset: Training. Classification report below
2020-01-08 23:12:21,345 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.97      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.96      1.00      0.98      1318
          FTP-BruteForce       0.71      0.86      0.78     23153
           Infilteration       0.51      0.01      0.02     19210
           SQL Injection       1.00      0.25      0.40        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.90      0.77      0.79   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 23:12:21,345 [INFO] Overall accuracy (micro avg): 0.9837631722182
2020-01-08 23:13:42,946 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.9041                       0.7652                0.0044                   0.2348  0.7873
2  Weighted avg        0.9911         0.9792                       0.9838                0.0490                   0.0162  0.9789
2020-01-08 23:13:43,019 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_3/ann_depth_ids18_subset_layers_3_results.xlsx
2020-01-08 23:13:43,024 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-08 23:13:43,084 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_4
2020-01-08 23:13:43,085 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_4/run_log.log
2020-01-08 23:13:43,085 [INFO] ================= Running experiment no. 4  ================= 

2020-01-08 23:13:43,085 [INFO] Experiment parameters given below
2020-01-08 23:13:43,085 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_4'}
2020-01-08 23:13:43,085 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_4/tf_logs_run_2020_01_08-23_13_43
2020-01-08 23:13:43,085 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 23:13:43,085 [INFO] Reading X, y files
2020-01-08 23:13:43,085 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 23:13:47,089 [INFO] Reading complete. time_to_read=4.00 seconds
2020-01-08 23:13:47,089 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 23:13:48,467 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 23:13:48,467 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 23:13:49,845 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-08 23:13:49,845 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 23:13:50,174 [INFO] Reading complete. time_to_read=0.33 seconds
2020-01-08 23:13:50,174 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 23:13:50,272 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 23:13:50,272 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 23:13:50,368 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-08 23:13:53,760 [INFO] Initializing model
2020-01-08 23:13:54,141 [INFO] _________________________________________________________________
2020-01-08 23:13:54,141 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 23:13:54,141 [INFO] =================================================================
2020-01-08 23:13:54,141 [INFO] dense_10 (Dense)             (None, 64)                4992      
2020-01-08 23:13:54,141 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] dense_11 (Dense)             (None, 64)                4160      
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,142 [INFO] dense_12 (Dense)             (None, 64)                4160      
2020-01-08 23:13:54,142 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] batch_normalization_9 (Batch (None, 64)                256       
2020-01-08 23:13:54,143 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] dropout_9 (Dropout)          (None, 64)                0         
2020-01-08 23:13:54,143 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] dense_13 (Dense)             (None, 64)                4160      
2020-01-08 23:13:54,143 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2020-01-08 23:13:54,143 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2020-01-08 23:13:54,143 [INFO] _________________________________________________________________
2020-01-08 23:13:54,143 [INFO] dense_14 (Dense)             (None, 15)                975       
2020-01-08 23:13:54,143 [INFO] =================================================================
2020-01-08 23:13:54,144 [INFO] Total params: 19,471
2020-01-08 23:13:54,144 [INFO] Trainable params: 18,959
2020-01-08 23:13:54,144 [INFO] Non-trainable params: 512
2020-01-08 23:13:54,144 [INFO] _________________________________________________________________
2020-01-08 23:13:54,144 [INFO] Training model
 - val_f1: 0.9786
Epoch 00196: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 45s - loss: 0.0142 - val_loss: 0.0356
 - val_f1: 0.8427
Epoch 2/200
 - 43s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 3/200
 - 43s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 4/200
 - 43s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 5/200
 - 43s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 6/200
 - 43s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 7/200
 - 43s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 8/200
 - 43s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 9/200
 - 43s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 10/200
 - 43s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 11/200
 - 43s - loss: 0.0081 - val_loss: 0.0165
 - val_f1: 0.9473
Epoch 12/200
 - 43s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 13/200
 - 43s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 14/200
 - 43s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 15/200
 - 43s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 16/200
 - 43s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 17/200
 - 43s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 18/200
 - 43s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 19/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 20/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 21/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
2020-01-08 23:35:15,851 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_20.pickle
 - val_f1: 0.9791
Epoch 22/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 23/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 24/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 25/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 26/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 27/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 28/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 29/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 30/200
 - 43s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9743
Epoch 31/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 32/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 33/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 34/200
 - 43s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 35/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 36/200
 - 43s - loss: 0.0079 - val_loss: 0.0763
 - val_f1: 0.7995
Epoch 37/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 38/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 39/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9792
Epoch 40/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 41/200
 - 43s - loss: 0.0079 - val_loss: 0.0089
2020-01-08 23:55:44,709 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_40.pickle
 - val_f1: 0.9756
Epoch 42/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 43/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 44/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 45/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 46/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 47/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 48/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 49/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 50/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 51/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 52/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 53/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 54/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 55/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 56/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 57/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 58/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 59/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 60/200
 - 43s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 61/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 00:16:15,867 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_60.pickle
 - val_f1: 0.9781
Epoch 62/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 63/200
 - 43s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9773
Epoch 64/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 65/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 66/200
 - 43s - loss: 0.0079 - val_loss: 0.0153
 - val_f1: 0.9430
Epoch 67/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 68/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 69/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 70/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 71/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 72/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 73/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 74/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 75/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 76/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 77/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 78/200
 - 43s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 79/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 80/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 81/200
 - 43s - loss: 0.0079 - val_loss: 0.0080
2020-01-09 00:36:45,990 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_80.pickle
 - val_f1: 0.9775
Epoch 82/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 83/200
 - 43s - loss: 0.0079 - val_loss: 0.0130
 - val_f1: 0.9666
Epoch 84/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 85/200
 - 43s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 86/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 87/200
 - 43s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9759
Epoch 88/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 89/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 90/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 91/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 92/200
 - 43s - loss: 0.0079 - val_loss: 0.0086
 - val_f1: 0.9752
Epoch 93/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 94/200
 - 43s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 95/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 96/200
 - 43s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 97/200
 - 43s - loss: 0.0078 - val_loss: 0.0109
 - val_f1: 0.9762
Epoch 98/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 99/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 100/200
 - 43s - loss: 0.0079 - val_loss: 0.0093
 - val_f1: 0.9748
Epoch 101/200
 - 43s - loss: 0.0078 - val_loss: 0.0171
2020-01-09 00:57:15,842 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_100.pickle
 - val_f1: 0.9429
Epoch 102/200
 - 43s - loss: 0.0078 - val_loss: 0.0283
 - val_f1: 0.8869
Epoch 103/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 104/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 105/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 106/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 107/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 108/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 109/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 110/200
 - 43s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 111/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 112/200
 - 43s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 113/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 114/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 115/200
 - 43s - loss: 0.0078 - val_loss: 0.0129
 - val_f1: 0.9731
Epoch 116/200
 - 43s - loss: 0.0078 - val_loss: 0.0240
 - val_f1: 0.8860
Epoch 117/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 118/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 119/200
 - 43s - loss: 0.0078 - val_loss: 0.0637
 - val_f1: 0.7955
Epoch 120/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 121/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
2020-01-09 01:17:46,261 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_120.pickle
 - val_f1: 0.9781
Epoch 122/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9798
Epoch 123/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 124/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 125/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 126/200
 - 43s - loss: 0.0078 - val_loss: 0.0116
 - val_f1: 0.9730
Epoch 127/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 128/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 129/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 130/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 131/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 132/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 133/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 134/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 135/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 136/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 137/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 138/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 139/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 140/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 141/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 01:38:18,000 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_140.pickle
 - val_f1: 0.9781
Epoch 142/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 143/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 144/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 145/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 146/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 147/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 148/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 149/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 150/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 151/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9799
Epoch 152/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 153/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9780
Epoch 154/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 155/200
 - 43s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 156/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 157/200
 - 43s - loss: 0.0078 - val_loss: 0.0124
 - val_f1: 0.9642
Epoch 158/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 159/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 160/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 161/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 01:58:49,481 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_160.pickle
 - val_f1: 0.9785
Epoch 162/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 163/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 164/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 165/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 166/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 167/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 168/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 169/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9780
Epoch 170/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 171/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 172/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 173/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 174/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 175/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 176/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 177/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 178/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 179/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 180/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 181/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
2020-01-09 02:19:20,430 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/ann_model_epoch_180.pickle
 - val_f1: 0.9781
Epoch 182/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9800
Epoch 183/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 184/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 185/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 186/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 187/200
 - 43s - loss: 0.0078 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 188/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 189/200
 - 43s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9764
Epoch 190/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 191/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 192/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 193/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 194/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 195/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 196/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 197/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 198/200
 - 43s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9782
Epoch 199/200
 - 43s - loss: 0.0078 - val_loss: 0.0103
 - val_f1: 0.9739
Epoch 200/200
 - 43s - loss: 0.0078 - val_loss: 0.0077
2020-01-09 02:39:06,953 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 02:40:24,098 [INFO] Last epoch loss evaluation: train_loss = 0.007554, val_loss = 0.007579
2020-01-09 02:40:24,099 [INFO] Training complete. time_to_train = 12389.95 sec, 206.50 min
2020-01-09 02:40:24,108 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_4/best_model.pickle
2020-01-09 02:40:24,111 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_error_history.csv
2020-01-09 02:40:24,303 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_error_history.png
2020-01-09 02:40:24,490 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/training_f1_history.png
2020-01-09 02:40:24,490 [INFO] Making predictions on training, validation, testing data
2020-01-09 02:41:50,737 [INFO] Evaluating predictions (results)
2020-01-09 02:42:13,884 [INFO] Dataset: Testing. Classification report below
2020-01-09 02:42:13,885 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.89      0.33      0.48        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.66      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.43      0.55      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       440
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.49      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.83      0.73      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-09 02:42:13,885 [INFO] Overall accuracy (micro avg): 0.9834466326252386
2020-01-09 02:42:38,772 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8274                       0.7323                0.0044                   0.2677  0.7384
2  Weighted avg        0.9912         0.9789                       0.9834                0.0492                   0.0166  0.9782
2020-01-09 02:43:01,850 [INFO] Dataset: Validation. Classification report below
2020-01-09 02:43:01,850 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.48      0.65        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.94      0.99      0.97       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.40      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.83      0.77      0.77    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-09 02:43:01,850 [INFO] Overall accuracy (micro avg): 0.9835674459748995
2020-01-09 02:43:26,701 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.8317                       0.7651                0.0044                   0.2349  0.7713
2  Weighted avg        0.9912         0.9781                       0.9836                0.0491                   0.0164  0.9783
2020-01-09 02:44:42,389 [INFO] Dataset: Training. Classification report below
2020-01-09 02:44:42,389 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.36      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      1.00      0.82       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.96      0.99      0.98      1318
          FTP-BruteForce       0.69      0.90      0.78     23153
           Infilteration       0.50      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.84      0.75      0.75   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-09 02:44:42,389 [INFO] Overall accuracy (micro avg): 0.9835333716850627
2020-01-09 02:46:03,975 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.8390                       0.7455                0.0044                   0.2545  0.7547
2  Weighted avg        0.9912         0.9791                       0.9835                0.0491                   0.0165  0.9783
2020-01-09 02:46:04,049 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_4/ann_depth_ids18_subset_layers_4_results.xlsx
2020-01-09 02:46:04,053 [INFO] ================= Finished running experiment no. 4 ================= 

2020-01-09 02:46:04,112 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_5
2020-01-09 02:46:04,113 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_5/run_log.log
2020-01-09 02:46:04,113 [INFO] ================= Running experiment no. 5  ================= 

2020-01-09 02:46:04,113 [INFO] Experiment parameters given below
2020-01-09 02:46:04,113 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_5'}
2020-01-09 02:46:04,113 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_5/tf_logs_run_2020_01_09-02_46_04
2020-01-09 02:46:04,113 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-09 02:46:04,113 [INFO] Reading X, y files
2020-01-09 02:46:04,114 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-09 02:46:08,126 [INFO] Reading complete. time_to_read=4.01 seconds
2020-01-09 02:46:08,126 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-09 02:46:09,509 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-09 02:46:09,512 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-09 02:46:10,896 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-09 02:46:10,896 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-09 02:46:11,216 [INFO] Reading complete. time_to_read=0.32 seconds
2020-01-09 02:46:11,216 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-09 02:46:11,315 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-09 02:46:11,316 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-09 02:46:11,419 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-09 02:46:14,794 [INFO] Initializing model
2020-01-09 02:46:15,269 [INFO] _________________________________________________________________
2020-01-09 02:46:15,270 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-09 02:46:15,270 [INFO] =================================================================
2020-01-09 02:46:15,270 [INFO] dense_15 (Dense)             (None, 64)                4992      
2020-01-09 02:46:15,270 [INFO] _________________________________________________________________
2020-01-09 02:46:15,270 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2020-01-09 02:46:15,270 [INFO] _________________________________________________________________
2020-01-09 02:46:15,270 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2020-01-09 02:46:15,270 [INFO] _________________________________________________________________
2020-01-09 02:46:15,270 [INFO] dense_16 (Dense)             (None, 64)                4160      
2020-01-09 02:46:15,270 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] batch_normalization_12 (Batc (None, 64)                256       
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] dropout_12 (Dropout)         (None, 64)                0         
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] dense_17 (Dense)             (None, 64)                4160      
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,271 [INFO] dense_18 (Dense)             (None, 64)                4160      
2020-01-09 02:46:15,271 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-09 02:46:15,272 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-09 02:46:15,272 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] dense_19 (Dense)             (None, 64)                4160      
2020-01-09 02:46:15,272 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] batch_normalization_15 (Batc (None, 64)                256       
2020-01-09 02:46:15,272 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] dropout_15 (Dropout)         (None, 64)                0         
2020-01-09 02:46:15,272 [INFO] _________________________________________________________________
2020-01-09 02:46:15,272 [INFO] dense_20 (Dense)             (None, 15)                975       
2020-01-09 02:46:15,272 [INFO] =================================================================
2020-01-09 02:46:15,273 [INFO] Total params: 23,887
2020-01-09 02:46:15,273 [INFO] Trainable params: 23,247
2020-01-09 02:46:15,273 [INFO] Non-trainable params: 640
2020-01-09 02:46:15,273 [INFO] _________________________________________________________________
2020-01-09 02:46:15,273 [INFO] Training model
 - val_f1: 0.9778
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 54s - loss: 0.0148 - val_loss: 0.0088
 - val_f1: 0.9769
Epoch 2/200
 - 51s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 3/200
 - 51s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 4/200
 - 51s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 5/200
 - 51s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9753
Epoch 6/200
 - 51s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 7/200
 - 51s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9789
Epoch 8/200
 - 51s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 9/200
 - 52s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 10/200
 - 51s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 11/200
 - 51s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 12/200
 - 51s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 13/200
 - 51s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 14/200
 - 51s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 15/200
 - 51s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 16/200
 - 51s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 17/200
 - 51s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 18/200
 - 51s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9771
Epoch 19/200
 - 51s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 20/200
 - 51s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 21/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
2020-01-09 03:11:55,928 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_20.pickle
 - val_f1: 0.9776
Epoch 22/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 23/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 24/200
 - 51s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 25/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 26/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 27/200
 - 51s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9767
Epoch 28/200
 - 51s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 29/200
 - 51s - loss: 0.0080 - val_loss: 0.0115
 - val_f1: 0.9716
Epoch 30/200
 - 51s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 31/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 32/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 33/200
 - 51s - loss: 0.0080 - val_loss: 0.0093
 - val_f1: 0.9757
Epoch 34/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 35/200
 - 51s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 36/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9798
Epoch 37/200
 - 51s - loss: 0.0080 - val_loss: 0.0086
 - val_f1: 0.9769
Epoch 38/200
 - 51s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 39/200
 - 51s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 40/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 41/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 03:36:37,684 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_40.pickle
 - val_f1: 0.9783
Epoch 42/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 43/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 44/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 45/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 46/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 47/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 48/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 49/200
 - 51s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 50/200
 - 52s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 51/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 52/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 53/200
 - 51s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9752
Epoch 54/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 55/200
 - 51s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 56/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 57/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 58/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 59/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 60/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 61/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 04:01:20,193 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_60.pickle
 - val_f1: 0.9782
Epoch 62/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 63/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 64/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 65/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9801
Epoch 66/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 67/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 68/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 69/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 70/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 71/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 72/200
 - 51s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 73/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 74/200
 - 52s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9745
Epoch 75/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 76/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 77/200
 - 51s - loss: 0.0079 - val_loss: 0.0101
 - val_f1: 0.9752
Epoch 78/200
 - 51s - loss: 0.0079 - val_loss: 0.0099
 - val_f1: 0.9742
Epoch 79/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 80/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 81/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
2020-01-09 04:26:08,259 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_80.pickle
 - val_f1: 0.9786
Epoch 82/200
 - 52s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 83/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 84/200
 - 52s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 85/200
 - 51s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 86/200
 - 52s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 87/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 88/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 89/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9801
Epoch 90/200
 - 51s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 91/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 92/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 93/200
 - 51s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 94/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 95/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 96/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 97/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 98/200
 - 52s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 99/200
 - 51s - loss: 0.0078 - val_loss: 0.0099
 - val_f1: 0.9749
Epoch 100/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 101/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
2020-01-09 04:50:51,896 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_100.pickle
 - val_f1: 0.9786
Epoch 102/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 103/200
 - 51s - loss: 0.0078 - val_loss: 0.0116
 - val_f1: 0.9710
Epoch 104/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 105/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 106/200
 - 52s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 107/200
 - 51s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 108/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 109/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 110/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 111/200
 - 51s - loss: 0.0078 - val_loss: 0.0099
 - val_f1: 0.9747
Epoch 112/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 113/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 114/200
 - 52s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 115/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 116/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 117/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 118/200
 - 51s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 119/200
 - 51s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 120/200
 - 52s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 121/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 05:15:36,075 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_120.pickle
 - val_f1: 0.9787
Epoch 122/200
 - 52s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 123/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 124/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 125/200
 - 51s - loss: 0.0078 - val_loss: 0.0109
 - val_f1: 0.9736
Epoch 126/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 127/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 128/200
 - 51s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 129/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 130/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 131/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 132/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 133/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 134/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 135/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9804
Epoch 136/200
 - 51s - loss: 0.0078 - val_loss: 0.0123
 - val_f1: 0.9692
Epoch 137/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 138/200
 - 51s - loss: 0.0078 - val_loss: 0.0118
 - val_f1: 0.9730
Epoch 139/200
 - 51s - loss: 0.0078 - val_loss: 0.0162
 - val_f1: 0.9572
Epoch 140/200
 - 51s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9791
Epoch 141/200
 - 51s - loss: 0.0078 - val_loss: 0.0079
2020-01-09 05:40:19,743 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_140.pickle
 - val_f1: 0.9777
Epoch 142/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 143/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 144/200
 - 51s - loss: 0.0078 - val_loss: 0.0133
 - val_f1: 0.9633
Epoch 145/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 146/200
 - 51s - loss: 0.0078 - val_loss: 0.0100
 - val_f1: 0.9742
Epoch 147/200
 - 52s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 148/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 149/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 150/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 151/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 152/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 153/200
 - 51s - loss: 0.0078 - val_loss: 0.0168
 - val_f1: 0.9583
Epoch 154/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 155/200
 - 51s - loss: 0.0078 - val_loss: 0.0164
 - val_f1: 0.9560
Epoch 156/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 157/200
 - 51s - loss: 0.0078 - val_loss: 0.0120
 - val_f1: 0.9698
Epoch 158/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 159/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 160/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 161/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 06:05:02,887 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_160.pickle
 - val_f1: 0.9789
Epoch 162/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 163/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 164/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 165/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 166/200
 - 51s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9773
Epoch 167/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 168/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 169/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 170/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 171/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 172/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 173/200
 - 51s - loss: 0.0078 - val_loss: 0.0120
 - val_f1: 0.9697
Epoch 174/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 175/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 176/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 177/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 178/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 179/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 180/200
 - 57s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 181/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 06:29:53,357 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/ann_model_epoch_180.pickle
 - val_f1: 0.9788
Epoch 182/200
 - 51s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9764
Epoch 183/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 184/200
 - 52s - loss: 0.0078 - val_loss: 0.0123
 - val_f1: 0.9680
Epoch 185/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 186/200
 - 51s - loss: 0.0078 - val_loss: 0.0124
 - val_f1: 0.9651
Epoch 187/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 188/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 189/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 190/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 191/200
 - 51s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 192/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 193/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9789
Epoch 194/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 195/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 196/200
 - 52s - loss: 0.0078 - val_loss: 0.0098
 - val_f1: 0.9744
Epoch 197/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 198/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9797
Epoch 199/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 200/200
 - 52s - loss: 0.0078 - val_loss: 0.0076
2020-01-09 06:53:47,572 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 06:55:21,618 [INFO] Last epoch loss evaluation: train_loss = 0.007564, val_loss = 0.007583
2020-01-09 06:55:21,618 [INFO] Training complete. time_to_train = 14946.34 sec, 249.11 min
2020-01-09 06:55:21,629 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_5/best_model.pickle
2020-01-09 06:55:21,632 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_error_history.csv
2020-01-09 06:55:21,822 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_error_history.png
2020-01-09 06:55:22,004 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/training_f1_history.png
2020-01-09 06:55:22,004 [INFO] Making predictions on training, validation, testing data
2020-01-09 06:57:09,265 [INFO] Evaluating predictions (results)
2020-01-09 06:57:32,451 [INFO] Dataset: Testing. Classification report below
2020-01-09 06:57:32,451 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.83      0.21      0.33        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.94      0.97      0.96       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.43      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.82      0.73      0.73    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-09 06:57:32,451 [INFO] Overall accuracy (micro avg): 0.9837208437647176
2020-01-09 06:57:57,388 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.8215                       0.7273                0.0044                   0.2727  0.7333
2  Weighted avg        0.9910         0.9784                       0.9837                0.0492                   0.0163  0.9788
2020-01-09 06:58:20,381 [INFO] Dataset: Validation. Classification report below
2020-01-09 06:58:20,381 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.28      0.44        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.94      0.98      0.96       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.54      0.01      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.84      0.76      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-09 06:58:20,381 [INFO] Overall accuracy (micro avg): 0.9838525020643328
2020-01-09 06:58:45,155 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0012                   0.0161  0.9839
1     Macro avg        0.9978         0.8435                       0.7552                0.0043                   0.2448  0.7632
2  Weighted avg        0.9911         0.9797                       0.9839                0.0489                   0.0161  0.9789
2020-01-09 07:00:00,907 [INFO] Dataset: Training. Classification report below
2020-01-09 07:00:00,907 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.26      0.41        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.95      0.99      0.97      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.54      0.01      0.03     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.84      0.74      0.75   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-09 07:00:00,907 [INFO] Overall accuracy (micro avg): 0.9838199768443687
2020-01-09 07:01:22,547 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.8427                       0.7421                0.0043                   0.2579  0.7520
2  Weighted avg        0.9911         0.9796                       0.9838                0.0489                   0.0162  0.9789
2020-01-09 07:01:22,621 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_5/ann_depth_ids18_subset_layers_5_results.xlsx
2020-01-09 07:01:22,625 [INFO] ================= Finished running experiment no. 5 ================= 

2020-01-09 07:01:22,682 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9786
Using TensorFlow backend.
2020-01-08 16:18:52,580 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_6/run_log.log
2020-01-08 16:18:52,580 [INFO] ================= Running experiment no. 6  ================= 

2020-01-08 16:18:52,580 [INFO] Experiment parameters given below
2020-01-08 16:18:52,580 [INFO] 
{'experiment_num': 6, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_6', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_6'}
2020-01-08 16:18:52,580 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_6/tf_logs_run_2020_01_08-16_18_52
2020-01-08 16:18:52,580 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 16:18:52,581 [INFO] Reading X, y files
2020-01-08 16:18:52,581 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 16:18:57,113 [INFO] Reading complete. time_to_read=4.53 seconds
2020-01-08 16:18:57,113 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 16:18:58,644 [INFO] Reading complete. time_to_read=1.53 seconds
2020-01-08 16:18:58,644 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 16:19:00,171 [INFO] Reading complete. time_to_read=1.53 seconds
2020-01-08 16:19:00,171 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 16:19:00,458 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-08 16:19:00,458 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 16:19:00,543 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 16:19:00,543 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 16:19:00,627 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 16:19:04,534 [INFO] Initializing model
2020-01-08 16:19:04,535 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2020-01-08 16:19:04,544 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2020-01-08 16:19:04,545 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2020-01-08 16:19:04,603 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2020-01-08 16:19:04,618 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 16:19:05,056 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-01-08 16:19:05,068 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2020-01-08 16:19:05,071 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-01-08 16:19:05,080 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 16:19:05,081 [INFO] =================================================================
2020-01-08 16:19:05,081 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] dense_2 (Dense)              (None, 64)                4160      
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,081 [INFO] dense_3 (Dense)              (None, 64)                4160      
2020-01-08 16:19:05,081 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dense_4 (Dense)              (None, 64)                4160      
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dense_5 (Dense)              (None, 64)                4160      
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,082 [INFO] dense_6 (Dense)              (None, 64)                4160      
2020-01-08 16:19:05,082 [INFO] _________________________________________________________________
2020-01-08 16:19:05,083 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-08 16:19:05,083 [INFO] _________________________________________________________________
2020-01-08 16:19:05,083 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-08 16:19:05,083 [INFO] _________________________________________________________________
2020-01-08 16:19:05,083 [INFO] dense_7 (Dense)              (None, 15)                975       
2020-01-08 16:19:05,083 [INFO] =================================================================
2020-01-08 16:19:05,083 [INFO] Total params: 28,303
2020-01-08 16:19:05,083 [INFO] Trainable params: 27,535
2020-01-08 16:19:05,083 [INFO] Non-trainable params: 768
2020-01-08 16:19:05,083 [INFO] _________________________________________________________________
2020-01-08 16:19:05,083 [INFO] Training model
2020-01-08 16:19:06.692891: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-08 16:19:06.712865: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2020-01-08 16:19:06.713042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56516d94aa20 executing computations on platform Host. Devices:
2020-01-08 16:19:06.713063: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-08 16:19:07.124840: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-01-08 16:19:07,136 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2020-01-08 16:19:07,136 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 47s - loss: 0.0157 - val_loss: 0.0090
 - val_f1: 0.9743
Epoch 2/200
 - 47s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 3/200
 - 47s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 4/200
 - 47s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 5/200
 - 47s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 6/200
 - 47s - loss: 0.0084 - val_loss: 0.0169
 - val_f1: 0.9476
Epoch 7/200
 - 47s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 8/200
 - 47s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 9/200
 - 47s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 10/200
 - 47s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 11/200
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 12/200
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9774
Epoch 13/200
 - 47s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 14/200
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 15/200
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 16/200
 - 47s - loss: 0.0081 - val_loss: 0.0182
 - val_f1: 0.9552
Epoch 17/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 18/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 19/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 20/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 21/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 16:39:16,283 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_20.pickle
 - val_f1: 0.9779
Epoch 22/200
 - 48s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 23/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 24/200
 - 48s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 25/200
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 26/200
 - 48s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 27/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 28/200
 - 47s - loss: 0.0080 - val_loss: 0.0098
 - val_f1: 0.9751
Epoch 29/200
 - 48s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 30/200
 - 48s - loss: 0.0080 - val_loss: 0.0132
 - val_f1: 0.9640
Epoch 31/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 32/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 33/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 34/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 35/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 36/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 37/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 38/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 39/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 40/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 41/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
2020-01-08 16:58:54,026 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_40.pickle
 - val_f1: 0.9778
Epoch 42/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 43/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 44/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 45/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 46/200
 - 48s - loss: 0.0080 - val_loss: 0.0160
 - val_f1: 0.9517
Epoch 47/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 48/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 49/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 50/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 51/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9754
Epoch 52/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 53/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 54/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 55/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 56/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 57/200
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 58/200
 - 48s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9796
Epoch 59/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 60/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9796
Epoch 61/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
2020-01-08 17:18:37,415 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 48s - loss: 0.0079 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 63/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 64/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 65/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 66/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 67/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 68/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 69/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 70/200
 - 48s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9747
Epoch 71/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 72/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 73/200
 - 48s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9773
Epoch 74/200
 - 48s - loss: 0.0079 - val_loss: 0.0181
 - val_f1: 0.9554
Epoch 75/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 76/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 77/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 78/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 79/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 80/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 81/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
2020-01-08 17:38:21,254 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_80.pickle
 - val_f1: 0.9776
Epoch 82/200
 - 48s - loss: 0.0079 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 83/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 84/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 85/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 86/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 87/200
 - 48s - loss: 0.0079 - val_loss: 0.0162
 - val_f1: 0.9550
Epoch 88/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 89/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 90/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 91/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 92/200
 - 48s - loss: 0.0079 - val_loss: 0.0154
 - val_f1: 0.9558
Epoch 93/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 94/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 95/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 96/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 97/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 98/200
 - 48s - loss: 0.0079 - val_loss: 0.0578
 - val_f1: 0.8567
Epoch 99/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 100/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 101/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 17:58:04,782 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 103/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 104/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 105/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 106/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 107/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 108/200
 - 48s - loss: 0.0079 - val_loss: 0.0127
 - val_f1: 0.9665
Epoch 109/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 110/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 111/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 112/200
 - 48s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 113/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 114/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 115/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 116/200
 - 48s - loss: 0.0079 - val_loss: 0.0084
 - val_f1: 0.9764
Epoch 117/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 118/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 119/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 120/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 121/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 18:17:49,046 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_120.pickle
 - val_f1: 0.9781
Epoch 122/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 123/200
 - 48s - loss: 0.0079 - val_loss: 0.0108
 - val_f1: 0.9728
Epoch 124/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 125/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 126/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 127/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 128/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 129/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 130/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 131/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 132/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 133/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 134/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 135/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 136/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 137/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 138/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 139/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 140/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 141/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 18:37:32,047 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_140.pickle
 - val_f1: 0.9779
Epoch 142/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 143/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 144/200
 - 48s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 145/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 146/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 147/200
 - 48s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 148/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 149/200
 - 48s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 150/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 151/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 152/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 153/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 154/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 155/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 156/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 157/200
 - 48s - loss: 0.0078 - val_loss: 0.0199
 - val_f1: 0.9241
Epoch 158/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 159/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 160/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 161/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 18:57:14,306 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_160.pickle
 - val_f1: 0.9780
Epoch 162/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 163/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 164/200
 - 48s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9725
Epoch 165/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 166/200
 - 48s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9737
Epoch 167/200
 - 48s - loss: 0.0078 - val_loss: 0.0165
 - val_f1: 0.9576
Epoch 168/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 169/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 170/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 171/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 172/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 173/200
 - 48s - loss: 0.0078 - val_loss: 0.0114
 - val_f1: 0.9683
Epoch 174/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 175/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 176/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 177/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 178/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 179/200
 - 48s - loss: 0.0078 - val_loss: 0.0106
 - val_f1: 0.9727
Epoch 180/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 181/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 19:16:56,559 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/ann_model_epoch_180.pickle
 - val_f1: 0.9780
Epoch 182/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 183/200
 - 48s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9768
Epoch 184/200
 - 48s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9758
Epoch 185/200
 - 48s - loss: 0.0078 - val_loss: 0.0122
 - val_f1: 0.9667
Epoch 186/200
 - 48s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 187/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 188/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 189/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 190/200
 - 48s - loss: 0.0078 - val_loss: 0.0098
 - val_f1: 0.9729
Epoch 191/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 192/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 193/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 194/200
 - 48s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 195/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 196/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9800
Epoch 197/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 198/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 199/200
 - 48s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 200/200
 - 48s - loss: 0.0078 - val_loss: 0.0076
2020-01-08 19:35:50,472 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 19:36:38,206 [INFO] Last epoch loss evaluation: train_loss = 0.007632, val_loss = 0.007647
2020-01-08 19:36:38,206 [INFO] Training complete. time_to_train = 11853.12 sec, 197.55 min
2020-01-08 19:36:38,214 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_6/best_model.pickle
2020-01-08 19:36:38,217 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_error_history.csv
2020-01-08 19:36:38,365 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_error_history.png
2020-01-08 19:36:38,496 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/training_f1_history.png
2020-01-08 19:36:38,496 [INFO] Making predictions on training, validation, testing data
2020-01-08 19:37:30,939 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 19:37:43,142 [INFO] Dataset: Testing. Classification report below
2020-01-08 19:37:43,142 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.50      0.33      0.40         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.64      1.00      0.78        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.55      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.74      0.71      0.70    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 19:37:43,142 [INFO] Overall accuracy (micro avg): 0.9833134000941923
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 19:37:56,986 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7369                       0.7100                0.0044                   0.2900  0.6979
2  Weighted avg        0.9911         0.9793                       0.9833                0.0494                   0.0167  0.9780
2020-01-08 19:38:09,185 [INFO] Dataset: Validation. Classification report below
2020-01-08 19:38:09,185 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.55      0.67      0.60         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.93      1.00      0.96       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.41      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.73      0.73      0.71    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 19:38:09,185 [INFO] Overall accuracy (micro avg): 0.9834063273156547
2020-01-08 19:38:23,052 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7344                       0.7329                0.0044                   0.2671  0.7136
2  Weighted avg        0.9911         0.9781                       0.9834                0.0492                   0.0166  0.9781
2020-01-08 19:39:02,639 [INFO] Dataset: Training. Classification report below
2020-01-08 19:39:02,640 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.59      0.50      0.54        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.69      1.00      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.95      1.00      0.97      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.61      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.75      0.72      0.71   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 19:39:02,640 [INFO] Overall accuracy (micro avg): 0.9833784499773298
2020-01-08 19:39:47,621 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7511                       0.7216                0.0044                   0.2784  0.7101
2  Weighted avg        0.9911         0.9800                       0.9834                0.0492                   0.0166  0.9781
2020-01-08 19:39:47,648 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_6/ann_depth_ids18_subset_layers_6_results.xlsx
2020-01-08 19:39:47,655 [INFO] ================= Finished running experiment no. 6 ================= 

2020-01-08 19:39:47,734 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_7
2020-01-08 19:39:47,735 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_7/run_log.log
2020-01-08 19:39:47,735 [INFO] ================= Running experiment no. 7  ================= 

2020-01-08 19:39:47,735 [INFO] Experiment parameters given below
2020-01-08 19:39:47,735 [INFO] 
{'experiment_num': 7, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_7', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_7'}
2020-01-08 19:39:47,735 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_7/tf_logs_run_2020_01_08-19_39_47
2020-01-08 19:39:47,735 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 19:39:47,735 [INFO] Reading X, y files
2020-01-08 19:39:47,735 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 19:39:52,178 [INFO] Reading complete. time_to_read=4.44 seconds
2020-01-08 19:39:52,178 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 19:39:53,714 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-08 19:39:53,714 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 19:39:55,253 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-08 19:39:55,253 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 19:39:55,511 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-08 19:39:55,511 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 19:39:55,596 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 19:39:55,596 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 19:39:55,680 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 19:39:59,577 [INFO] Initializing model
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 19:40:00,134 [INFO] =================================================================
2020-01-08 19:40:00,134 [INFO] dense_8 (Dense)              (None, 64)                4992      
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] dense_9 (Dense)              (None, 64)                4160      
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,134 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-08 19:40:00,134 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dense_10 (Dense)             (None, 64)                4160      
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] batch_normalization_9 (Batch (None, 64)                256       
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dropout_9 (Dropout)          (None, 64)                0         
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dense_11 (Dense)             (None, 64)                4160      
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dense_12 (Dense)             (None, 64)                4160      
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,135 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2020-01-08 19:40:00,135 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] dense_13 (Dense)             (None, 64)                4160      
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] batch_normalization_12 (Batc (None, 64)                256       
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] dropout_12 (Dropout)         (None, 64)                0         
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] dense_14 (Dense)             (None, 64)                4160      
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2020-01-08 19:40:00,136 [INFO] _________________________________________________________________
2020-01-08 19:40:00,136 [INFO] dense_15 (Dense)             (None, 15)                975       
2020-01-08 19:40:00,136 [INFO] =================================================================
2020-01-08 19:40:00,137 [INFO] Total params: 32,719
2020-01-08 19:40:00,137 [INFO] Trainable params: 31,823
2020-01-08 19:40:00,137 [INFO] Non-trainable params: 896
2020-01-08 19:40:00,137 [INFO] _________________________________________________________________
2020-01-08 19:40:00,137 [INFO] Training model
 - val_f1: 0.9780
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 54s - loss: 0.0166 - val_loss: 0.0092
 - val_f1: 0.9755
Epoch 2/200
 - 53s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9746
Epoch 3/200
 - 53s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9751
Epoch 4/200
 - 53s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 5/200
 - 53s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 6/200
 - 55s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 7/200
 - 55s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 8/200
 - 55s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 9/200
 - 55s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 10/200
 - 55s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 11/200
 - 55s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 12/200
 - 55s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 13/200
 - 55s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 14/200
 - 55s - loss: 0.0082 - val_loss: 0.0296
 - val_f1: 0.9091
Epoch 15/200
 - 55s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9793
Epoch 16/200
 - 55s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 17/200
 - 55s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 18/200
 - 55s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 19/200
 - 55s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 20/200
 - 55s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 21/200
 - 55s - loss: 0.0081 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 20:03:30,333 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_20.pickle
 - val_f1: 0.9776
Epoch 22/200
 - 55s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 23/200
 - 55s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 24/200
 - 55s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 25/200
 - 55s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 26/200
 - 55s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 27/200
 - 55s - loss: 0.0081 - val_loss: 0.0175
 - val_f1: 0.9560
Epoch 28/200
 - 55s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 29/200
 - 55s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 30/200
 - 55s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 31/200
 - 55s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9760
Epoch 32/200
 - 55s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 33/200
 - 55s - loss: 0.0080 - val_loss: 0.0166
 - val_f1: 0.9557
Epoch 34/200
 - 55s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 35/200
 - 55s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 36/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 37/200
 - 55s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 38/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 39/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 40/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 41/200
 - 55s - loss: 0.0080 - val_loss: 0.0081
2020-01-08 20:26:10,578 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_40.pickle
 - val_f1: 0.9773
Epoch 42/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 43/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 44/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 45/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 46/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 47/200
 - 55s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 48/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 49/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 50/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 51/200
 - 55s - loss: 0.0080 - val_loss: 0.0101
 - val_f1: 0.9728
Epoch 52/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 53/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 54/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 55/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 56/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 57/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 58/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 59/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 60/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 61/200
 - 55s - loss: 0.0080 - val_loss: 0.0077
2020-01-08 20:48:50,451 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 63/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 64/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 65/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 66/200
 - 55s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 67/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 68/200
 - 55s - loss: 0.0080 - val_loss: 0.0093
 - val_f1: 0.9749
Epoch 69/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 70/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 71/200
 - 55s - loss: 0.0079 - val_loss: 0.0313
 - val_f1: 0.9221
Epoch 72/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9790
Epoch 73/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 74/200
 - 55s - loss: 0.0079 - val_loss: 0.0091
 - val_f1: 0.9739
Epoch 75/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 76/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 77/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 78/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 79/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 80/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 81/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
2020-01-08 21:11:30,849 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_80.pickle
 - val_f1: 0.9778
Epoch 82/200
 - 55s - loss: 0.0079 - val_loss: 0.0141
 - val_f1: 0.9621
Epoch 83/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 84/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 85/200
 - 55s - loss: 0.0079 - val_loss: 0.0109
 - val_f1: 0.9677
Epoch 86/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 87/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 88/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 89/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 90/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 91/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 92/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 93/200
 - 55s - loss: 0.0079 - val_loss: 0.0099
 - val_f1: 0.9739
Epoch 94/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 95/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 96/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 97/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 98/200
 - 55s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9767
Epoch 99/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 100/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 101/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 21:34:11,683 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 103/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 104/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 105/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 106/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 107/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 108/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 109/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 110/200
 - 55s - loss: 0.0079 - val_loss: 0.0117
 - val_f1: 0.9707
Epoch 111/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 112/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 113/200
 - 55s - loss: 0.0079 - val_loss: 0.0223
 - val_f1: 0.9597
Epoch 114/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 115/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 116/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 117/200
 - 55s - loss: 0.0079 - val_loss: 0.0131
 - val_f1: 0.9651
Epoch 118/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 119/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 120/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 121/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 21:56:53,151 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_120.pickle
 - val_f1: 0.9781
Epoch 122/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 123/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 124/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 125/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 126/200
 - 55s - loss: 0.0079 - val_loss: 0.0144
 - val_f1: 0.9630
Epoch 127/200
 - 55s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9759
Epoch 128/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 129/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 130/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 131/200
 - 55s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9769
Epoch 132/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 133/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 134/200
 - 55s - loss: 0.0079 - val_loss: 0.0086
 - val_f1: 0.9755
Epoch 135/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 136/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 137/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9777
Epoch 138/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 139/200
 - 55s - loss: 0.0079 - val_loss: 0.0100
 - val_f1: 0.9745
Epoch 140/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 141/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 22:19:34,630 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 143/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 144/200
 - 55s - loss: 0.0079 - val_loss: 0.0092
 - val_f1: 0.9754
Epoch 145/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 146/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 147/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 148/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 149/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 150/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9775
Epoch 151/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 152/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 153/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 154/200
 - 55s - loss: 0.0079 - val_loss: 0.0086
 - val_f1: 0.9758
Epoch 155/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 156/200
 - 55s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9768
Epoch 157/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 158/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 159/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 160/200
 - 55s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 161/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
2020-01-08 22:42:15,639 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_160.pickle
 - val_f1: 0.9779
Epoch 162/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 163/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 164/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 165/200
 - 55s - loss: 0.0079 - val_loss: 0.0383
 - val_f1: 0.9108
Epoch 166/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 167/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 168/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 169/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 170/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 171/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 172/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 173/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 174/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 175/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 176/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 177/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 178/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 179/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 180/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 181/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 23:04:56,320 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 183/200
 - 55s - loss: 0.0078 - val_loss: 0.0101
 - val_f1: 0.9749
Epoch 184/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 185/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 186/200
 - 55s - loss: 0.0078 - val_loss: 0.0139
 - val_f1: 0.9626
Epoch 187/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 188/200
 - 55s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 189/200
 - 55s - loss: 0.0078 - val_loss: 0.0119
 - val_f1: 0.9653
Epoch 190/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 191/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 192/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 193/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 194/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 195/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 196/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 197/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 198/200
 - 55s - loss: 0.0078 - val_loss: 0.0419
 - val_f1: 0.8567
Epoch 199/200
 - 55s - loss: 0.0078 - val_loss: 0.0139
 - val_f1: 0.9486
Epoch 200/200
 - 55s - loss: 0.0078 - val_loss: 0.0077
2020-01-08 23:26:42,488 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 23:27:40,468 [INFO] Last epoch loss evaluation: train_loss = 0.007642, val_loss = 0.007663
2020-01-08 23:27:40,468 [INFO] Training complete. time_to_train = 13660.33 sec, 227.67 min
2020-01-08 23:27:40,480 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_7/best_model.pickle
2020-01-08 23:27:40,482 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_error_history.csv
2020-01-08 23:27:40,628 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_error_history.png
2020-01-08 23:27:40,763 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/training_f1_history.png
2020-01-08 23:27:40,764 [INFO] Making predictions on training, validation, testing data
2020-01-08 23:28:43,162 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 23:28:55,291 [INFO] Dataset: Testing. Classification report below
2020-01-08 23:28:55,291 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.60      0.33      0.43         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.66      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.95      1.00      0.97       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.43      0.01      0.03      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.74      0.71      0.70    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 23:28:55,291 [INFO] Overall accuracy (micro avg): 0.9832746697072603
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 23:29:09,073 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7369                       0.7112                0.0044                   0.2888  0.7024
2  Weighted avg        0.9910         0.9781                       0.9833                0.0490                   0.0167  0.9782
2020-01-08 23:29:21,198 [INFO] Dataset: Validation. Classification report below
2020-01-08 23:29:21,198 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.46      0.67      0.55         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.93      1.00      0.96       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.50      0.01      0.03      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.74      0.73      0.71    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 23:29:21,198 [INFO] Overall accuracy (micro avg): 0.9834218194944282
2020-01-08 23:29:34,983 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7353                       0.7338                0.0044                   0.2662  0.7119
2  Weighted avg        0.9911         0.9790                       0.9834                0.0488                   0.0166  0.9783
2020-01-08 23:30:14,532 [INFO] Dataset: Training. Classification report below
2020-01-08 23:30:14,533 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.48      0.50      0.49        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.69      1.00      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.95      1.00      0.97      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.51      0.02      0.03     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.74      0.72      0.71   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 23:30:14,533 [INFO] Overall accuracy (micro avg): 0.9833588265610169
2020-01-08 23:30:59,459 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7369                       0.7222                0.0044                   0.2778  0.7082
2  Weighted avg        0.9911         0.9790                       0.9834                0.0488                   0.0166  0.9783
2020-01-08 23:30:59,485 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_7/ann_depth_ids18_subset_layers_7_results.xlsx
2020-01-08 23:30:59,492 [INFO] ================= Finished running experiment no. 7 ================= 

2020-01-08 23:30:59,569 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_8
2020-01-08 23:30:59,569 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_8/run_log.log
2020-01-08 23:30:59,569 [INFO] ================= Running experiment no. 8  ================= 

2020-01-08 23:30:59,569 [INFO] Experiment parameters given below
2020-01-08 23:30:59,569 [INFO] 
{'experiment_num': 8, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_8', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_8'}
2020-01-08 23:30:59,569 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_8/tf_logs_run_2020_01_08-23_30_59
2020-01-08 23:30:59,569 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 23:30:59,570 [INFO] Reading X, y files
2020-01-08 23:30:59,570 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 23:31:04,047 [INFO] Reading complete. time_to_read=4.48 seconds
2020-01-08 23:31:04,047 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 23:31:05,591 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-08 23:31:05,591 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 23:31:07,136 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-08 23:31:07,136 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 23:31:07,401 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-08 23:31:07,401 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 23:31:07,486 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-08 23:31:07,486 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 23:31:07,572 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-08 23:31:11,448 [INFO] Initializing model
2020-01-08 23:31:12,198 [INFO] _________________________________________________________________
2020-01-08 23:31:12,198 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 23:31:12,198 [INFO] =================================================================
2020-01-08 23:31:12,198 [INFO] dense_16 (Dense)             (None, 64)                4992      
2020-01-08 23:31:12,198 [INFO] _________________________________________________________________
2020-01-08 23:31:12,198 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-08 23:31:12,198 [INFO] _________________________________________________________________
2020-01-08 23:31:12,198 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,198 [INFO] _________________________________________________________________
2020-01-08 23:31:12,198 [INFO] dense_17 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,198 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] batch_normalization_15 (Batc (None, 64)                256       
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dropout_15 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dense_18 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] batch_normalization_16 (Batc (None, 64)                256       
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dropout_16 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dense_19 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] batch_normalization_17 (Batc (None, 64)                256       
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dropout_17 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,199 [INFO] dense_20 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,199 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] batch_normalization_18 (Batc (None, 64)                256       
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dropout_18 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dense_21 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] batch_normalization_19 (Batc (None, 64)                256       
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dropout_19 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dense_22 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] batch_normalization_20 (Batc (None, 64)                256       
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dropout_20 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,200 [INFO] dense_23 (Dense)             (None, 64)                4160      
2020-01-08 23:31:12,200 [INFO] _________________________________________________________________
2020-01-08 23:31:12,201 [INFO] batch_normalization_21 (Batc (None, 64)                256       
2020-01-08 23:31:12,201 [INFO] _________________________________________________________________
2020-01-08 23:31:12,201 [INFO] dropout_21 (Dropout)         (None, 64)                0         
2020-01-08 23:31:12,201 [INFO] _________________________________________________________________
2020-01-08 23:31:12,201 [INFO] dense_24 (Dense)             (None, 15)                975       
2020-01-08 23:31:12,201 [INFO] =================================================================
2020-01-08 23:31:12,201 [INFO] Total params: 37,135
2020-01-08 23:31:12,201 [INFO] Trainable params: 36,111
2020-01-08 23:31:12,201 [INFO] Non-trainable params: 1,024
2020-01-08 23:31:12,201 [INFO] _________________________________________________________________
2020-01-08 23:31:12,201 [INFO] Training model
 - val_f1: 0.9778
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 61s - loss: 0.0181 - val_loss: 0.0093
 - val_f1: 0.9738
Epoch 2/200
 - 59s - loss: 0.0098 - val_loss: 0.0088
 - val_f1: 0.9745
Epoch 3/200
 - 60s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9752
Epoch 4/200
 - 60s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9751
Epoch 5/200
 - 60s - loss: 0.0087 - val_loss: 0.0085
 - val_f1: 0.9748
Epoch 6/200
 - 60s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 7/200
 - 60s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 8/200
 - 60s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 9/200
 - 60s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 10/200
 - 60s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9752
Epoch 11/200
 - 60s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 12/200
 - 60s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 13/200
 - 60s - loss: 0.0084 - val_loss: 0.0088
 - val_f1: 0.9714
Epoch 14/200
 - 60s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9752
Epoch 15/200
 - 60s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9723
Epoch 16/200
 - 60s - loss: 0.0083 - val_loss: 0.0089
 - val_f1: 0.9728
Epoch 17/200
 - 60s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9701
Epoch 18/200
 - 60s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 19/200
 - 60s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 20/200
 - 60s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 21/200
 - 60s - loss: 0.0083 - val_loss: 0.0081
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 23:57:24,417 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_20.pickle
 - val_f1: 0.9753
Epoch 22/200
 - 60s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9718
Epoch 23/200
 - 60s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 24/200
 - 60s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 25/200
 - 60s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 26/200
 - 60s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 27/200
 - 60s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 28/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 29/200
 - 60s - loss: 0.0081 - val_loss: 0.0151
 - val_f1: 0.9550
Epoch 30/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 31/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 32/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 33/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 34/200
 - 60s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 35/200
 - 60s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 36/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 37/200
 - 60s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 38/200
 - 60s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 39/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 40/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9773
Epoch 41/200
 - 60s - loss: 0.0081 - val_loss: 0.0079
2020-01-09 00:22:31,496 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_40.pickle
 - val_f1: 0.9776
Epoch 42/200
 - 60s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 43/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 44/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 45/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 46/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 47/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 48/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 49/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 50/200
 - 60s - loss: 0.0080 - val_loss: 0.0173
 - val_f1: 0.9416
Epoch 51/200
 - 60s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 52/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 53/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 54/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 55/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 56/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 57/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 58/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 59/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 60/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 61/200
 - 60s - loss: 0.0080 - val_loss: 0.0265
2020-01-09 00:47:38,096 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_60.pickle
 - val_f1: 0.9189
Epoch 62/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 63/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 64/200
 - 60s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 65/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 66/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 67/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 68/200
 - 60s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9766
Epoch 69/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 70/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 71/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 72/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 73/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 74/200
 - 60s - loss: 0.0080 - val_loss: 0.0430
 - val_f1: 0.9190
Epoch 75/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 76/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 77/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 78/200
 - 60s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 79/200
 - 60s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 80/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 81/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 01:12:45,579 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_80.pickle
 - val_f1: 0.9779
Epoch 82/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 83/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 84/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 85/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 86/200
 - 60s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 87/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 88/200
 - 60s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 89/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 90/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 91/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 92/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 93/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9793
Epoch 94/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 95/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 96/200
 - 60s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 97/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 98/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 99/200
 - 60s - loss: 0.0079 - val_loss: 0.0097
 - val_f1: 0.9708
Epoch 100/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 101/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 01:37:53,485 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 103/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 104/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 105/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 106/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 107/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 108/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 109/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 110/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 111/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 112/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 113/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9776
Epoch 114/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 115/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 116/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 117/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 118/200
 - 60s - loss: 0.0079 - val_loss: 0.0113
 - val_f1: 0.9656
Epoch 119/200
 - 60s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 120/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 121/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 02:03:02,279 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_120.pickle
 - val_f1: 0.9778
Epoch 122/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 123/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 124/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 125/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9773
Epoch 126/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 127/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 128/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 129/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 130/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 131/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 132/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 133/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 134/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 135/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 136/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 137/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 138/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 139/200
 - 60s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 140/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 141/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 02:28:11,654 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_140.pickle
 - val_f1: 0.9779
Epoch 142/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 143/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 144/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 145/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 146/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 147/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 148/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 149/200
 - 60s - loss: 0.0079 - val_loss: 0.0084
 - val_f1: 0.9723
Epoch 150/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9777
Epoch 151/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 152/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 153/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 154/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 155/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 156/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9777
Epoch 157/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 158/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 159/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 160/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 161/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 02:53:20,856 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_160.pickle
 - val_f1: 0.9779
Epoch 162/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 163/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 164/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 165/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 166/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 167/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 168/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 169/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 170/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 171/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 172/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 173/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 174/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 175/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 176/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 177/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 178/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 179/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 180/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 181/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 03:18:29,420 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 183/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 184/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 185/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 186/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 187/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 188/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 189/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 190/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 191/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 192/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 193/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 194/200
 - 60s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 195/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 196/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 197/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 198/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 199/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 200/200
 - 60s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 03:42:37,808 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 03:43:46,170 [INFO] Last epoch loss evaluation: train_loss = 0.007676, val_loss = 0.007683
2020-01-09 03:43:46,171 [INFO] Training complete. time_to_train = 15153.97 sec, 252.57 min
2020-01-09 03:43:46,183 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_8/best_model.pickle
2020-01-09 03:43:46,186 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_error_history.csv
2020-01-09 03:43:46,330 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_error_history.png
2020-01-09 03:43:46,464 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/training_f1_history.png
2020-01-09 03:43:46,464 [INFO] Making predictions on training, validation, testing data
2020-01-09 03:45:02,040 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-09 03:45:14,240 [INFO] Dataset: Testing. Classification report below
2020-01-09 03:45:14,240 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.67      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.92      0.98      0.95       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.42      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.76      0.71      0.70    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-09 03:45:14,240 [INFO] Overall accuracy (micro avg): 0.9832483330441465
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-09 03:45:28,094 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7612                       0.7093                0.0044                   0.2907  0.7047
2  Weighted avg        0.9910         0.9780                       0.9832                0.0493                   0.0168  0.9780
2020-01-09 03:45:40,225 [INFO] Dataset: Validation. Classification report below
2020-01-09 03:45:40,225 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.91      0.97      0.94       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.40      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.76      0.73      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-09 03:45:40,225 [INFO] Overall accuracy (micro avg): 0.9833598507793341
2020-01-09 03:45:54,035 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7625                       0.7317                0.0044                   0.2683  0.7261
2  Weighted avg        0.9910         0.9779                       0.9834                0.0492                   0.0166  0.9781
2020-01-09 03:46:33,601 [INFO] Dataset: Training. Classification report below
2020-01-09 03:46:33,601 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.93      0.50      0.65        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      1.00      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.93      0.99      0.96      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.46      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.76      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-09 03:46:33,601 [INFO] Overall accuracy (micro avg): 0.9833159648885441
2020-01-09 03:47:18,561 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7622                       0.7212                0.0044                   0.2788  0.7169
2  Weighted avg        0.9910         0.9784                       0.9833                0.0491                   0.0167  0.9781
2020-01-09 03:47:18,588 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_8/ann_depth_ids18_subset_layers_8_results.xlsx
2020-01-09 03:47:18,593 [INFO] ================= Finished running experiment no. 8 ================= 

2020-01-09 03:47:18,672 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_9
2020-01-09 03:47:18,673 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_9/run_log.log
2020-01-09 03:47:18,673 [INFO] ================= Running experiment no. 9  ================= 

2020-01-09 03:47:18,673 [INFO] Experiment parameters given below
2020-01-09 03:47:18,673 [INFO] 
{'experiment_num': 9, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_9', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_9'}
2020-01-09 03:47:18,673 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_9/tf_logs_run_2020_01_09-03_47_18
2020-01-09 03:47:18,673 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-09 03:47:18,673 [INFO] Reading X, y files
2020-01-09 03:47:18,673 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-09 03:47:23,113 [INFO] Reading complete. time_to_read=4.44 seconds
2020-01-09 03:47:23,113 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-09 03:47:24,656 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-09 03:47:24,657 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-09 03:47:26,198 [INFO] Reading complete. time_to_read=1.54 seconds
2020-01-09 03:47:26,198 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-09 03:47:26,466 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-09 03:47:26,467 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-09 03:47:26,552 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-09 03:47:26,552 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-09 03:47:26,638 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-09 03:47:30,531 [INFO] Initializing model
2020-01-09 03:47:31,247 [INFO] _________________________________________________________________
2020-01-09 03:47:31,247 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-09 03:47:31,247 [INFO] =================================================================
2020-01-09 03:47:31,247 [INFO] dense_25 (Dense)             (None, 64)                4992      
2020-01-09 03:47:31,247 [INFO] _________________________________________________________________
2020-01-09 03:47:31,247 [INFO] batch_normalization_22 (Batc (None, 64)                256       
2020-01-09 03:47:31,247 [INFO] _________________________________________________________________
2020-01-09 03:47:31,247 [INFO] dropout_22 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,247 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dense_26 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] batch_normalization_23 (Batc (None, 64)                256       
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dropout_23 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dense_27 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] batch_normalization_24 (Batc (None, 64)                256       
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dropout_24 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dense_28 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] batch_normalization_25 (Batc (None, 64)                256       
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,248 [INFO] dropout_25 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,248 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dense_29 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dense_30 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] batch_normalization_27 (Batc (None, 64)                256       
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dropout_27 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dense_31 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] batch_normalization_28 (Batc (None, 64)                256       
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,249 [INFO] dropout_28 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,249 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] dense_32 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] batch_normalization_29 (Batc (None, 64)                256       
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] dropout_29 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] dense_33 (Dense)             (None, 64)                4160      
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] batch_normalization_30 (Batc (None, 64)                256       
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] dropout_30 (Dropout)         (None, 64)                0         
2020-01-09 03:47:31,250 [INFO] _________________________________________________________________
2020-01-09 03:47:31,250 [INFO] dense_34 (Dense)             (None, 15)                975       
2020-01-09 03:47:31,250 [INFO] =================================================================
2020-01-09 03:47:31,251 [INFO] Total params: 41,551
2020-01-09 03:47:31,251 [INFO] Trainable params: 40,399
2020-01-09 03:47:31,251 [INFO] Non-trainable params: 1,152
2020-01-09 03:47:31,251 [INFO] _________________________________________________________________
2020-01-09 03:47:31,251 [INFO] Training model
 - val_f1: 0.9780
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 67s - loss: 0.0193 - val_loss: 0.0095
 - val_f1: 0.9712
Epoch 2/200
 - 66s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9716
Epoch 3/200
 - 66s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 4/200
 - 66s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 5/200
 - 66s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9723
Epoch 6/200
 - 66s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9750
Epoch 7/200
 - 66s - loss: 0.0086 - val_loss: 0.0184
 - val_f1: 0.9517
Epoch 8/200
 - 66s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 9/200
 - 66s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9722
Epoch 10/200
 - 66s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9751
Epoch 11/200
 - 66s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 12/200
 - 66s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 13/200
 - 66s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9752
Epoch 14/200
 - 66s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9724
Epoch 15/200
 - 66s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9725
Epoch 16/200
 - 66s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9746
Epoch 17/200
 - 66s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9752
Epoch 18/200
 - 66s - loss: 0.0084 - val_loss: 0.0145
 - val_f1: 0.9602
Epoch 19/200
 - 66s - loss: 0.0083 - val_loss: 0.0195
 - val_f1: 0.9213
Epoch 20/200
 - 66s - loss: 0.0083 - val_loss: 0.0175
 - val_f1: 0.9307
Epoch 21/200
 - 66s - loss: 0.0082 - val_loss: 0.0155
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-09 04:17:00,301 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_20.pickle
 - val_f1: 0.9443
Epoch 22/200
 - 66s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 23/200
 - 66s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 24/200
 - 66s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 25/200
 - 66s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 26/200
 - 66s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 27/200
 - 66s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 28/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 29/200
 - 66s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 30/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 31/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 32/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 33/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 34/200
 - 66s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 35/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 36/200
 - 66s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 37/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 38/200
 - 66s - loss: 0.0081 - val_loss: 0.0134
 - val_f1: 0.9628
Epoch 39/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 40/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 41/200
 - 66s - loss: 0.0081 - val_loss: 0.0078
2020-01-09 04:45:12,698 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_40.pickle
 - val_f1: 0.9777
Epoch 42/200
 - 66s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 43/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 44/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 45/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 46/200
 - 66s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 47/200
 - 66s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 48/200
 - 66s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 49/200
 - 66s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 50/200
 - 66s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 51/200
 - 66s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 52/200
 - 66s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 53/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 54/200
 - 66s - loss: 0.0080 - val_loss: 0.0157
 - val_f1: 0.9617
Epoch 55/200
 - 66s - loss: 0.0080 - val_loss: 0.0166
 - val_f1: 0.9543
Epoch 56/200
 - 66s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9771
Epoch 57/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 58/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 59/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 60/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 61/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
2020-01-09 05:13:23,165 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_60.pickle
 - val_f1: 0.9778
Epoch 62/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 63/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 64/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 65/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 66/200
 - 66s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 67/200
 - 66s - loss: 0.0080 - val_loss: 0.0199
 - val_f1: 0.9544
Epoch 68/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 69/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 70/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 71/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 72/200
 - 66s - loss: 0.0080 - val_loss: 0.0088
 - val_f1: 0.9768
Epoch 73/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 74/200
 - 66s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9754
Epoch 75/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 76/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 77/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 78/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 79/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 80/200
 - 66s - loss: 0.0080 - val_loss: 0.0213
 - val_f1: 0.9525
Epoch 81/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
2020-01-09 05:41:35,591 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_80.pickle
 - val_f1: 0.9778
Epoch 82/200
 - 66s - loss: 0.0080 - val_loss: 0.0094
 - val_f1: 0.9745
Epoch 83/200
 - 66s - loss: 0.0080 - val_loss: 0.0243
 - val_f1: 0.9245
Epoch 84/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 85/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 86/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 87/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 88/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 89/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 90/200
 - 66s - loss: 0.0080 - val_loss: 0.0132
 - val_f1: 0.9629
Epoch 91/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 92/200
 - 66s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 93/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 94/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9798
Epoch 95/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9795
Epoch 96/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 97/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 98/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 99/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 100/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 101/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
2020-01-09 06:09:46,721 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 103/200
 - 66s - loss: 0.0080 - val_loss: 0.0110
 - val_f1: 0.9697
Epoch 104/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 105/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 106/200
 - 66s - loss: 0.0079 - val_loss: 0.0120
 - val_f1: 0.9694
Epoch 107/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 108/200
 - 66s - loss: 0.0080 - val_loss: 0.0282
 - val_f1: 0.9251
Epoch 109/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 110/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 111/200
 - 66s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9769
Epoch 112/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 113/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 114/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 115/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 116/200
 - 66s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9798
Epoch 117/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 118/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 119/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 120/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 121/200
 - 66s - loss: 0.0079 - val_loss: 0.0080
2020-01-09 06:37:58,562 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_120.pickle
 - val_f1: 0.9762
Epoch 122/200
 - 66s - loss: 0.0080 - val_loss: 0.0105
 - val_f1: 0.9723
Epoch 123/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 124/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9797
Epoch 125/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 126/200
 - 66s - loss: 0.0079 - val_loss: 0.0109
 - val_f1: 0.9678
Epoch 127/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 128/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 129/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 130/200
 - 67s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 131/200
 - 67s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 132/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 133/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 134/200
 - 67s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 135/200
 - 67s - loss: 0.0079 - val_loss: 0.0105
 - val_f1: 0.9732
Epoch 136/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 137/200
 - 67s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 138/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 139/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 140/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 141/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 07:06:13,835 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 143/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 144/200
 - 66s - loss: 0.0079 - val_loss: 0.0097
 - val_f1: 0.9748
Epoch 145/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 146/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 147/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 148/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 149/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 150/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 151/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 152/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 153/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 154/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 155/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 156/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 157/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 158/200
 - 66s - loss: 0.0079 - val_loss: 0.0098
 - val_f1: 0.9736
Epoch 159/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 160/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 161/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
2020-01-09 07:34:26,261 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_160.pickle
 - val_f1: 0.9777
Epoch 162/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 163/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 164/200
 - 66s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9769
Epoch 165/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 166/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 167/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 168/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 169/200
 - 66s - loss: 0.0079 - val_loss: 0.0101
 - val_f1: 0.9730
Epoch 170/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 171/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 172/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 173/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 174/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9777
Epoch 175/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 176/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 177/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 178/200
 - 66s - loss: 0.0079 - val_loss: 0.0098
 - val_f1: 0.9744
Epoch 179/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 180/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 181/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 08:02:36,155 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 183/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 184/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9778
Epoch 185/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 186/200
 - 66s - loss: 0.0079 - val_loss: 0.0116
 - val_f1: 0.9710
Epoch 187/200
 - 66s - loss: 0.0079 - val_loss: 0.0123
 - val_f1: 0.9709
Epoch 188/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 189/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 190/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 191/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9797
Epoch 192/200
 - 66s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9772
Epoch 193/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 194/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 195/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 196/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 197/200
 - 66s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 198/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9780
Epoch 199/200
 - 66s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 200/200
 - 67s - loss: 0.0079 - val_loss: 0.0077
2020-01-09 08:29:41,210 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 08:31:01,290 [INFO] Last epoch loss evaluation: train_loss = 0.007692, val_loss = 0.007695
2020-01-09 08:31:01,290 [INFO] Training complete. time_to_train = 17010.04 sec, 283.50 min
2020-01-09 08:31:01,305 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_9/best_model.pickle
2020-01-09 08:31:01,308 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_error_history.csv
2020-01-09 08:31:01,442 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_error_history.png
2020-01-09 08:31:01,576 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/training_f1_history.png
2020-01-09 08:31:01,576 [INFO] Making predictions on training, validation, testing data
2020-01-09 08:32:30,136 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-09 08:32:42,439 [INFO] Dataset: Testing. Classification report below
2020-01-09 08:32:42,439 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.50      0.33      0.40         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.67      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       440
          FTP-BruteForce       0.68      0.90      0.78      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.70      0.71      0.70    645488
            weighted avg       0.97      0.98      0.98    645488

2020-01-09 08:32:42,439 [INFO] Overall accuracy (micro avg): 0.9833025555858513
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-09 08:32:56,402 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7022                       0.7098                0.0044                   0.2902  0.6987
2  Weighted avg        0.9911         0.9737                       0.9833                0.0497                   0.0167  0.9779
2020-01-09 08:33:08,551 [INFO] Dataset: Validation. Classification report below
2020-01-09 08:33:08,551 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.60      0.67      0.63         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.77      0.43      0.55      5596
   DoS attacks-Slowloris       0.93      1.00      0.96       439
          FTP-BruteForce       0.69      0.91      0.78      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.71      0.73      0.72    645487
            weighted avg       0.97      0.98      0.98    645487

2020-01-09 08:33:08,552 [INFO] Overall accuracy (micro avg): 0.9833939335726358
2020-01-09 08:33:22,367 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7109                       0.7326                0.0044                   0.2674  0.7155
2  Weighted avg        0.9911         0.9739                       0.9834                0.0496                   0.0166  0.9780
2020-01-09 08:34:02,214 [INFO] Dataset: Training. Classification report below
2020-01-09 08:34:02,214 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.59      0.50      0.54        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.43      0.55     16787
   DoS attacks-Slowloris       0.95      0.99      0.97      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.72      0.71   1936462
            weighted avg       0.97      0.98      0.98   1936462

2020-01-09 08:34:02,214 [INFO] Overall accuracy (micro avg): 0.9833278422194703
2020-01-09 08:34:47,582 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7106                       0.7204                0.0044                   0.2796  0.7094
2  Weighted avg        0.9911         0.9738                       0.9833                0.0497                   0.0167  0.9779
2020-01-09 08:34:47,608 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_9/ann_depth_ids18_subset_layers_9_results.xlsx
2020-01-09 08:34:47,617 [INFO] ================= Finished running experiment no. 9 ================= 

2020-01-09 08:34:47,695 [INFO] Created directory: results_additional_exps/ann_depth_ids18_subset_layers_10
2020-01-09 08:34:47,696 [INFO] Initialized logging. log_filename = results_additional_exps/ann_depth_ids18_subset_layers_10/run_log.log
2020-01-09 08:34:47,696 [INFO] ================= Running experiment no. 10  ================= 

2020-01-09 08:34:47,696 [INFO] Experiment parameters given below
2020-01-09 08:34:47,696 [INFO] 
{'experiment_num': 10, 'results_dir': 'results_additional_exps/ann_depth_ids18_subset_layers_10', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 64, 64, 64, 64, 64, 64, 64, 64, 64], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'ann_depth_ids18_subset_layers_10'}
2020-01-09 08:34:47,696 [INFO] Created tensorboard log directory: results_additional_exps/ann_depth_ids18_subset_layers_10/tf_logs_run_2020_01_09-08_34_47
2020-01-09 08:34:47,696 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-09 08:34:47,696 [INFO] Reading X, y files
2020-01-09 08:34:47,696 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-09 08:34:52,228 [INFO] Reading complete. time_to_read=4.53 seconds
2020-01-09 08:34:52,228 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-09 08:34:53,783 [INFO] Reading complete. time_to_read=1.55 seconds
2020-01-09 08:34:53,783 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-09 08:34:55,336 [INFO] Reading complete. time_to_read=1.55 seconds
2020-01-09 08:34:55,336 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-09 08:34:55,598 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-09 08:34:55,598 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-09 08:34:55,684 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-09 08:34:55,684 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-09 08:34:55,770 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-09 08:34:59,641 [INFO] Initializing model
2020-01-09 08:35:00,439 [INFO] _________________________________________________________________
2020-01-09 08:35:00,439 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-09 08:35:00,439 [INFO] =================================================================
2020-01-09 08:35:00,440 [INFO] dense_35 (Dense)             (None, 64)                4992      
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] batch_normalization_31 (Batc (None, 64)                256       
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] dropout_31 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] dense_36 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] batch_normalization_32 (Batc (None, 64)                256       
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] dropout_32 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] dense_37 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] batch_normalization_33 (Batc (None, 64)                256       
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,440 [INFO] dropout_33 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,440 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dense_38 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] batch_normalization_34 (Batc (None, 64)                256       
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dropout_34 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dense_39 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] batch_normalization_35 (Batc (None, 64)                256       
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dropout_35 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dense_40 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] batch_normalization_36 (Batc (None, 64)                256       
2020-01-09 08:35:00,441 [INFO] _________________________________________________________________
2020-01-09 08:35:00,441 [INFO] dropout_36 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dense_41 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] batch_normalization_37 (Batc (None, 64)                256       
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dropout_37 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dense_42 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] batch_normalization_38 (Batc (None, 64)                256       
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dropout_38 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dense_43 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] batch_normalization_39 (Batc (None, 64)                256       
2020-01-09 08:35:00,442 [INFO] _________________________________________________________________
2020-01-09 08:35:00,442 [INFO] dropout_39 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,443 [INFO] _________________________________________________________________
2020-01-09 08:35:00,443 [INFO] dense_44 (Dense)             (None, 64)                4160      
2020-01-09 08:35:00,443 [INFO] _________________________________________________________________
2020-01-09 08:35:00,443 [INFO] batch_normalization_40 (Batc (None, 64)                256       
2020-01-09 08:35:00,443 [INFO] _________________________________________________________________
2020-01-09 08:35:00,443 [INFO] dropout_40 (Dropout)         (None, 64)                0         
2020-01-09 08:35:00,443 [INFO] _________________________________________________________________
2020-01-09 08:35:00,443 [INFO] dense_45 (Dense)             (None, 15)                975       
2020-01-09 08:35:00,443 [INFO] =================================================================
2020-01-09 08:35:00,443 [INFO] Total params: 45,967
2020-01-09 08:35:00,443 [INFO] Trainable params: 44,687
2020-01-09 08:35:00,443 [INFO] Non-trainable params: 1,280
2020-01-09 08:35:00,443 [INFO] _________________________________________________________________
2020-01-09 08:35:00,444 [INFO] Training model
 - val_f1: 0.9779
Train on 1936462 samples, validate on 645487 samples
Epoch 1/200
 - 74s - loss: 0.0220 - val_loss: 0.0100
 - val_f1: 0.9730
Epoch 2/200
 - 72s - loss: 0.0105 - val_loss: 0.0102
 - val_f1: 0.9728
Epoch 3/200
 - 72s - loss: 0.0097 - val_loss: 0.0097
 - val_f1: 0.9729
Epoch 4/200
 - 72s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9749
Epoch 5/200
 - 72s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 6/200
 - 72s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9751
Epoch 7/200
 - 72s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9751
Epoch 8/200
 - 72s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 9/200
 - 72s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9747
Epoch 10/200
 - 72s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9722
Epoch 11/200
 - 72s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9724
Epoch 12/200
 - 72s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 13/200
 - 72s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 14/200
 - 72s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 15/200
 - 72s - loss: 0.0085 - val_loss: 0.0113
 - val_f1: 0.9702
Epoch 16/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 17/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 18/200
 - 72s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9723
Epoch 19/200
 - 72s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 20/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 21/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-09 09:07:30,140 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_20.pickle
 - val_f1: 0.9753
Epoch 22/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 23/200
 - 72s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 24/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 25/200
 - 72s - loss: 0.0083 - val_loss: 0.0142
 - val_f1: 0.9625
Epoch 26/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 27/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 28/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9752
Epoch 29/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 30/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 31/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9723
Epoch 32/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 33/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 34/200
 - 72s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 35/200
 - 72s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9719
Epoch 36/200
 - 72s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 37/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 38/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 39/200
 - 72s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 40/200
 - 72s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 41/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
2020-01-09 09:38:35,791 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_40.pickle
 - val_f1: 0.9753
Epoch 42/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 43/200
 - 72s - loss: 0.0082 - val_loss: 0.0103
 - val_f1: 0.9731
Epoch 44/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 45/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 46/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 47/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 48/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 49/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9724
Epoch 50/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 51/200
 - 72s - loss: 0.0082 - val_loss: 0.0105
 - val_f1: 0.9683
Epoch 52/200
 - 72s - loss: 0.0082 - val_loss: 0.0124
 - val_f1: 0.9613
Epoch 53/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 54/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 55/200
 - 72s - loss: 0.0082 - val_loss: 0.0124
 - val_f1: 0.9681
Epoch 56/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 57/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 58/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 59/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 60/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9758
Epoch 61/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
2020-01-09 10:09:41,666 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_60.pickle
 - val_f1: 0.9740
Epoch 62/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 63/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 64/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 65/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 66/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 67/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9723
Epoch 68/200
 - 72s - loss: 0.0082 - val_loss: 0.0122
 - val_f1: 0.9661
Epoch 69/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 70/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 71/200
 - 72s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9723
Epoch 72/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 73/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 74/200
 - 72s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9722
Epoch 75/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 76/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 77/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 78/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 79/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 80/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 81/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
2020-01-09 10:40:48,235 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_80.pickle
 - val_f1: 0.9754
Epoch 82/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 83/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 84/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 85/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9756
Epoch 86/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 87/200
 - 72s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 88/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 89/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 90/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 91/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 92/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 93/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 94/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 95/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 96/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 97/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 98/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9758
Epoch 99/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 100/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9722
Epoch 101/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
2020-01-09 11:11:55,236 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_100.pickle
 - val_f1: 0.9755
Epoch 102/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 103/200
 - 72s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9746
Epoch 104/200
 - 72s - loss: 0.0081 - val_loss: 0.0123
 - val_f1: 0.9635
Epoch 105/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 106/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 107/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 108/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 109/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 110/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 111/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 112/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 113/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 114/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 115/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9753
Epoch 116/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 117/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 118/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 119/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 120/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 121/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
2020-01-09 11:43:03,595 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_120.pickle
 - val_f1: 0.9754
Epoch 122/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 123/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 124/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 125/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9772
Epoch 126/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 127/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 128/200
 - 72s - loss: 0.0081 - val_loss: 0.0142
 - val_f1: 0.9547
Epoch 129/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 130/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9736
Epoch 131/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 132/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9724
Epoch 133/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9752
Epoch 134/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 135/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 136/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 137/200
 - 72s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9723
Epoch 138/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 139/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9724
Epoch 140/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 141/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
2020-01-09 12:14:11,975 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_140.pickle
 - val_f1: 0.9724
Epoch 142/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 143/200
 - 72s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9749
Epoch 144/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 145/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9724
Epoch 146/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 147/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 148/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 149/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 150/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 151/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 152/200
 - 72s - loss: 0.0081 - val_loss: 0.0106
 - val_f1: 0.9734
Epoch 153/200
 - 72s - loss: 0.0081 - val_loss: 0.0149
 - val_f1: 0.9526
Epoch 154/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 155/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9725
Epoch 156/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9753
Epoch 157/200
 - 72s - loss: 0.0081 - val_loss: 0.0102
 - val_f1: 0.9726
Epoch 158/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 159/200
 - 72s - loss: 0.0081 - val_loss: 0.0109
 - val_f1: 0.9706
Epoch 160/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 161/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
2020-01-09 12:45:19,776 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_160.pickle
 - val_f1: 0.9756
Epoch 162/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9757
Epoch 163/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 164/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9726
Epoch 165/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9724
Epoch 166/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9725
Epoch 167/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9723
Epoch 168/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 169/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 170/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 171/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9725
Epoch 172/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 173/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 174/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 175/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 176/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 177/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 178/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9725
Epoch 179/200
 - 72s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9725
Epoch 180/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 181/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
2020-01-09 13:16:27,155 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/ann_model_epoch_180.pickle
 - val_f1: 0.9754
Epoch 182/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 183/200
 - 72s - loss: 0.0080 - val_loss: 0.0112
 - val_f1: 0.9687
Epoch 184/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9757
Epoch 185/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 186/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 187/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9774
Epoch 188/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 189/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 190/200
 - 72s - loss: 0.0081 - val_loss: 0.0091
 - val_f1: 0.9711
Epoch 191/200
 - 72s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 192/200
 - 72s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9738
Epoch 193/200
 - 72s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 194/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9725
Epoch 195/200
 - 72s - loss: 0.0080 - val_loss: 0.0108
 - val_f1: 0.9691
Epoch 196/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9754
Epoch 197/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9755
Epoch 198/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9725
Epoch 199/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9768
Epoch 200/200
 - 72s - loss: 0.0080 - val_loss: 0.0079
2020-01-09 13:46:22,638 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-09 13:47:53,857 [INFO] Last epoch loss evaluation: train_loss = 0.007853, val_loss = 0.007874
2020-01-09 13:47:53,857 [INFO] Training complete. time_to_train = 18773.41 sec, 312.89 min
2020-01-09 13:47:53,876 [INFO] Model saved to results_additional_exps/ann_depth_ids18_subset_layers_10/best_model.pickle
2020-01-09 13:47:53,879 [INFO] Training history saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_error_history.csv
2020-01-09 13:47:54,036 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_error_history.png
2020-01-09 13:47:54,166 [INFO] Plot saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/training_f1_history.png
2020-01-09 13:47:54,166 [INFO] Making predictions on training, validation, testing data
2020-01-09 13:49:37,424 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-09 13:49:49,578 [INFO] Dataset: Testing. Classification report below
2020-01-09 13:49:49,578 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.66      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.52      0.99      0.68      5596
   DoS attacks-Slowloris       0.87      0.98      0.92       440
          FTP-BruteForce       0.98      0.34      0.50      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.67      0.69      0.66    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-09 13:49:49,578 [INFO] Overall accuracy (micro avg): 0.9812668864487024
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-09 13:50:03,376 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9813         0.9813                       0.9813                0.0013                   0.0187  0.9813
1     Macro avg        0.9975         0.6672                       0.6863                0.0046                   0.3137  0.6587
2  Weighted avg        0.9909         0.9751                       0.9813                0.0502                   0.0187  0.9756
2020-01-09 13:50:15,488 [INFO] Dataset: Validation. Classification report below
2020-01-09 13:50:15,489 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.52      0.99      0.68      5596
   DoS attacks-Slowloris       0.89      0.98      0.93       439
          FTP-BruteForce       0.98      0.33      0.49      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.69      0.66    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-09 13:50:15,489 [INFO] Overall accuracy (micro avg): 0.981197142622547
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-09 13:50:29,264 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9812         0.9812                       0.9812                0.0013                   0.0188  0.9812
1     Macro avg        0.9975         0.6706                       0.6861                0.0046                   0.3139  0.6604
2  Weighted avg        0.9909         0.9751                       0.9812                0.0501                   0.0188  0.9755
2020-01-09 13:51:08,855 [INFO] Dataset: Training. Classification report below
2020-01-09 13:51:08,855 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      1.00      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.52      0.99      0.68     16787
   DoS attacks-Slowloris       0.90      0.99      0.94      1318
          FTP-BruteForce       0.98      0.33      0.49     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.67      0.69      0.66   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-09 13:51:08,855 [INFO] Overall accuracy (micro avg): 0.9812286530796887
2020-01-09 13:51:53,847 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9812         0.9812                       0.9812                0.0013                   0.0188  0.9812
1     Macro avg        0.9975         0.6716                       0.6869                0.0046                   0.3131  0.6613
2  Weighted avg        0.9909         0.9751                       0.9812                0.0501                   0.0188  0.9755
2020-01-09 13:51:53,874 [INFO] Results saved to: results_additional_exps/ann_depth_ids18_subset_layers_10/ann_depth_ids18_subset_layers_10_results.xlsx
2020-01-09 13:51:53,881 [INFO] ================= Finished running experiment no. 10 ================= 

2020-01-09 13:51:53,958 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9756
