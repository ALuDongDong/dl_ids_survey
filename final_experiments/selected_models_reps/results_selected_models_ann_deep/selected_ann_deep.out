Using TensorFlow backend.
2019-12-20 18:33:58,156 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids2017_ann_deep_rep1/run_log.log
2019-12-20 18:33:58,156 [INFO] ================= Running experiment no. 1  ================= 

2019-12-20 18:33:58,156 [INFO] Experiment parameters given below
2019-12-20 18:33:58,156 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids2017_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids2017_ann_deep_rep1'}
2019-12-20 18:33:58,157 [INFO] Created tensorboard log directory: results_selected_models/selected_ids2017_ann_deep_rep1/tf_logs_run_2019_12_20-18_33_58
2019-12-20 18:33:58,157 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-20 18:33:58,157 [INFO] Reading X, y files
2019-12-20 18:33:58,157 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-20 18:34:02,355 [INFO] Reading complete. time_to_read=4.20 seconds
2019-12-20 18:34:02,356 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-20 18:34:03,780 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-20 18:34:03,780 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-20 18:34:05,198 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-20 18:34:05,198 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-20 18:34:05,445 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-20 18:34:05,445 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-20 18:34:05,521 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-20 18:34:05,521 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-20 18:34:05,598 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-20 18:34:09,102 [INFO] Initializing model
2019-12-20 18:34:09,102 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-20 18:34:09,112 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-20 18:34:09,113 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-20 18:34:09,171 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-20 18:34:09,186 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-20 18:34:09,428 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-20 18:34:09,440 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-20 18:34:09,443 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-20 18:34:09,452 [INFO] _________________________________________________________________
2019-12-20 18:34:09,452 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 18:34:09,452 [INFO] =================================================================
2019-12-20 18:34:09,452 [INFO] dense_1 (Dense)              (None, 256)               20224     
2019-12-20 18:34:09,452 [INFO] _________________________________________________________________
2019-12-20 18:34:09,452 [INFO] batch_normalization_1 (Batch (None, 256)               1024      
2019-12-20 18:34:09,452 [INFO] _________________________________________________________________
2019-12-20 18:34:09,453 [INFO] dropout_1 (Dropout)          (None, 256)               0         
2019-12-20 18:34:09,453 [INFO] _________________________________________________________________
2019-12-20 18:34:09,453 [INFO] dense_2 (Dense)              (None, 128)               32896     
2019-12-20 18:34:09,453 [INFO] _________________________________________________________________
2019-12-20 18:34:09,453 [INFO] batch_normalization_2 (Batch (None, 128)               512       
2019-12-20 18:34:09,453 [INFO] _________________________________________________________________
2019-12-20 18:34:09,453 [INFO] dropout_2 (Dropout)          (None, 128)               0         
2019-12-20 18:34:09,453 [INFO] _________________________________________________________________
2019-12-20 18:34:09,453 [INFO] dense_3 (Dense)              (None, 64)                8256      
2019-12-20 18:34:09,453 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2019-12-20 18:34:09,454 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2019-12-20 18:34:09,454 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] dense_4 (Dense)              (None, 32)                2080      
2019-12-20 18:34:09,454 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-20 18:34:09,454 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-20 18:34:09,454 [INFO] _________________________________________________________________
2019-12-20 18:34:09,454 [INFO] dense_5 (Dense)              (None, 12)                396       
2019-12-20 18:34:09,455 [INFO] =================================================================
2019-12-20 18:34:09,455 [INFO] Total params: 65,772
2019-12-20 18:34:09,455 [INFO] Trainable params: 64,812
2019-12-20 18:34:09,455 [INFO] Non-trainable params: 960
2019-12-20 18:34:09,455 [INFO] _________________________________________________________________
2019-12-20 18:34:09,455 [INFO] Training model
2019-12-20 18:34:10.765405: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-20 18:34:10.788955: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2019-12-20 18:34:10.789223: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b5ba4491f0 executing computations on platform Host. Devices:
2019-12-20 18:34:10.789253: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-20 18:34:11.073019: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-20 18:34:11,082 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-20 18:34:11,082 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Train on 1696684 samples, validate on 565562 samples
Epoch 1/300
 - 45s - loss: 0.0186 - val_loss: 0.0087
 - val_f1: 0.9781
Epoch 2/300
 - 44s - loss: 0.0091 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 3/300
 - 44s - loss: 0.0071 - val_loss: 0.0038
 - val_f1: 0.9902
Epoch 4/300
 - 44s - loss: 0.0068 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 5/300
 - 44s - loss: 0.0054 - val_loss: 0.0100
 - val_f1: 0.9679
Epoch 6/300
 - 44s - loss: 0.0050 - val_loss: 0.0065
 - val_f1: 0.9824
Epoch 7/300
 - 44s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 8/300
 - 44s - loss: 0.0044 - val_loss: 0.0083
 - val_f1: 0.9807
Epoch 9/300
 - 44s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 10/300
 - 44s - loss: 0.0041 - val_loss: 0.0055
 - val_f1: 0.9862
Epoch 11/300
 - 45s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 12/300
 - 44s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 13/300
 - 44s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 14/300
 - 44s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9909
Epoch 15/300
 - 44s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 16/300
 - 44s - loss: 0.0036 - val_loss: 0.0057
 - val_f1: 0.9888
Epoch 17/300
 - 45s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 18/300
 - 44s - loss: 0.0037 - val_loss: 0.0052
 - val_f1: 0.9877
Epoch 19/300
 - 45s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 20/300
 - 45s - loss: 0.0034 - val_loss: 0.0080
 - val_f1: 0.9825
Epoch 21/300
 - 44s - loss: 0.0033 - val_loss: 0.0093
 - val_f1: 0.9741
Epoch 22/300
 - 44s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9894
Epoch 23/300
 - 44s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 24/300
 - 44s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 25/300
 - 44s - loss: 0.0036 - val_loss: 0.0043
 - val_f1: 0.9878
Epoch 26/300
 - 44s - loss: 0.0035 - val_loss: 0.0049
 - val_f1: 0.9891
Epoch 27/300
 - 44s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 28/300
 - 44s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 29/300
 - 45s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 30/300
 - 45s - loss: 0.0031 - val_loss: 0.0055
 - val_f1: 0.9895
Epoch 31/300
 - 45s - loss: 0.0032 - val_loss: 0.0026
2019-12-20 19:01:38,865 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9939
Epoch 32/300
 - 45s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 33/300
 - 45s - loss: 0.0032 - val_loss: 0.0088
 - val_f1: 0.9827
Epoch 34/300
 - 45s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 35/300
 - 44s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9946
Epoch 36/300
 - 44s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 37/300
 - 45s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 38/300
 - 44s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 39/300
 - 44s - loss: 0.0031 - val_loss: 0.0082
 - val_f1: 0.9815
Epoch 40/300
 - 45s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9879
Epoch 41/300
 - 44s - loss: 0.0031 - val_loss: 0.0035
 - val_f1: 0.9927
Epoch 42/300
 - 44s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 43/300
 - 45s - loss: 0.0031 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 44/300
 - 44s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 45/300
 - 45s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 46/300
 - 45s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 47/300
 - 44s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 48/300
 - 45s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 49/300
 - 44s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 50/300
 - 45s - loss: 0.0029 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 51/300
 - 44s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 52/300
 - 45s - loss: 0.0029 - val_loss: 0.0087
 - val_f1: 0.9804
Epoch 53/300
 - 45s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 54/300
 - 45s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 55/300
 - 45s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 56/300
 - 44s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 57/300
 - 44s - loss: 0.0028 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 58/300
 - 45s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9959
Epoch 59/300
 - 45s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 60/300
 - 45s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9932
Epoch 61/300
 - 44s - loss: 0.0028 - val_loss: 0.0023
2019-12-20 19:28:25,647 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9954
Epoch 62/300
 - 44s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 63/300
 - 44s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 64/300
 - 44s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 65/300
 - 44s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 66/300
 - 44s - loss: 0.0027 - val_loss: 0.0073
 - val_f1: 0.9754
Epoch 67/300
 - 44s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 68/300
 - 44s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 69/300
 - 45s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 70/300
 - 44s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 71/300
 - 45s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 72/300
 - 45s - loss: 0.0027 - val_loss: 0.0087
 - val_f1: 0.9822
Epoch 73/300
 - 44s - loss: 0.0027 - val_loss: 0.0055
 - val_f1: 0.9881
Epoch 74/300
 - 44s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9957
Epoch 75/300
 - 44s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9961
Epoch 76/300
 - 44s - loss: 0.0028 - val_loss: 0.0057
 - val_f1: 0.9868
Epoch 77/300
 - 44s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9959
Epoch 78/300
 - 44s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9959
Epoch 79/300
 - 44s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 80/300
 - 44s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 81/300
 - 44s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9957
Epoch 82/300
 - 44s - loss: 0.0030 - val_loss: 0.0098
 - val_f1: 0.9837
Epoch 83/300
 - 44s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 84/300
 - 44s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 85/300
 - 45s - loss: 0.0027 - val_loss: 0.0049
 - val_f1: 0.9904
Epoch 86/300
 - 44s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9960
Epoch 87/300
 - 44s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 88/300
 - 44s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 89/300
 - 44s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 90/300
 - 45s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9959
Epoch 91/300
 - 45s - loss: 0.0026 - val_loss: 0.0069
2019-12-20 19:55:09,639 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9838
Epoch 92/300
 - 45s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 93/300
 - 45s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 94/300
 - 45s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 95/300
 - 45s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 96/300
 - 45s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 97/300
 - 45s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 98/300
 - 45s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 99/300
 - 45s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 100/300
 - 45s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 101/300
 - 45s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 102/300
 - 45s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9957
Epoch 103/300
 - 45s - loss: 0.0027 - val_loss: 0.0083
 - val_f1: 0.9848
Epoch 104/300
 - 45s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 105/300
 - 45s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 106/300
 - 45s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9939
Epoch 107/300
 - 45s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 108/300
 - 45s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9937
Epoch 109/300
 - 45s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9961
Epoch 110/300
 - 44s - loss: 0.0026 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 111/300
 - 45s - loss: 0.0027 - val_loss: 0.0364
 - val_f1: 0.9670
Epoch 112/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 113/300
 - 45s - loss: 0.0026 - val_loss: 0.0075
 - val_f1: 0.9871
Epoch 114/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 115/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 116/300
 - 44s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 117/300
 - 44s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 118/300
 - 44s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9961
Epoch 119/300
 - 45s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 120/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9964
Epoch 121/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
2019-12-20 20:21:57,390 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9957
Epoch 122/300
 - 44s - loss: 0.0026 - val_loss: 0.0068
 - val_f1: 0.9870
Epoch 123/300
 - 44s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 124/300
 - 44s - loss: 0.0026 - val_loss: 0.0072
 - val_f1: 0.9892
Epoch 125/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9963
Epoch 126/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9959
Epoch 127/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 128/300
 - 44s - loss: 0.0026 - val_loss: 0.0044
 - val_f1: 0.9893
Epoch 129/300
 - 44s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9895
Epoch 130/300
 - 44s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 131/300
 - 45s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9957
Epoch 132/300
 - 44s - loss: 0.0028 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 133/300
 - 44s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 134/300
 - 44s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 135/300
 - 44s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 136/300
 - 44s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 137/300
 - 44s - loss: 0.0025 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 138/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 139/300
 - 45s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9960
Epoch 140/300
 - 45s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9957
Epoch 141/300
 - 45s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 142/300
 - 44s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 143/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9957
Epoch 144/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9962
Epoch 145/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9959
Epoch 146/300
 - 44s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 147/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 148/300
 - 45s - loss: 0.0025 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 149/300
 - 45s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9954
Epoch 150/300
 - 45s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 151/300
 - 45s - loss: 0.0026 - val_loss: 0.0021
2019-12-20 20:48:39,077 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9959
Epoch 152/300
 - 45s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 153/300
 - 44s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 154/300
 - 44s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 155/300
 - 45s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9957
Epoch 156/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 157/300
 - 45s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9955
Epoch 158/300
 - 44s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 159/300
 - 45s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 160/300
 - 44s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9961
Epoch 161/300
 - 45s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 162/300
 - 44s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 163/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 164/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9962
Epoch 165/300
 - 44s - loss: 0.0025 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 166/300
 - 44s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 167/300
 - 44s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 168/300
 - 44s - loss: 0.0025 - val_loss: 0.0111
 - val_f1: 0.9675
Epoch 169/300
 - 44s - loss: 0.0025 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 170/300
 - 44s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 171/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 172/300
 - 44s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 173/300
 - 44s - loss: 0.0025 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 174/300
 - 44s - loss: 0.0025 - val_loss: 0.0019
 - val_f1: 0.9963
Epoch 175/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 176/300
 - 45s - loss: 0.0025 - val_loss: 0.0047
 - val_f1: 0.9856
Epoch 177/300
 - 44s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 178/300
 - 44s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9933
Epoch 179/300
 - 44s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 180/300
 - 45s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9962
Epoch 181/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
2019-12-20 21:15:20,724 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9957
Epoch 182/300
 - 44s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9961
Epoch 183/300
 - 45s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9963
Epoch 184/300
 - 44s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9961
Epoch 185/300
 - 44s - loss: 0.0025 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 186/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 187/300
 - 44s - loss: 0.0024 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 188/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 189/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9959
Epoch 190/300
 - 45s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9962
Epoch 191/300
 - 44s - loss: 0.0024 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 192/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9963
Epoch 193/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 194/300
 - 44s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 195/300
 - 44s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 196/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 197/300
 - 45s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 198/300
 - 44s - loss: 0.0024 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 199/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 200/300
 - 44s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9956
Epoch 201/300
 - 45s - loss: 0.0025 - val_loss: 0.0019
 - val_f1: 0.9962
Epoch 202/300
 - 44s - loss: 0.0025 - val_loss: 0.0019
 - val_f1: 0.9961
Epoch 203/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9961
Epoch 204/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9959
Epoch 205/300
 - 44s - loss: 0.0025 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 206/300
 - 44s - loss: 0.0024 - val_loss: 0.0046
 - val_f1: 0.9896
Epoch 207/300
 - 44s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 208/300
 - 44s - loss: 0.0025 - val_loss: 0.0020
 - val_f1: 0.9958
Epoch 209/300
 - 44s - loss: 0.0024 - val_loss: 0.0019
 - val_f1: 0.9962
Epoch 210/300
 - 44s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9932
Epoch 211/300
 - 44s - loss: 0.0024 - val_loss: 0.0019
2019-12-20 21:42:01,095 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9963
Epoch 212/300
 - 44s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9963
Epoch 213/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 214/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9937
Epoch 215/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9955
Epoch 216/300
 - 44s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 217/300
 - 44s - loss: 0.0023 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 218/300
 - 44s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 219/300
 - 44s - loss: 0.0024 - val_loss: 0.0040
 - val_f1: 0.9879
Epoch 220/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 221/300
 - 44s - loss: 0.0024 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 222/300
 - 44s - loss: 0.0024 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 223/300
 - 44s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9931
Epoch 224/300
 - 44s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 225/300
 - 44s - loss: 0.0024 - val_loss: 0.0019
 - val_f1: 0.9961
Epoch 226/300
 - 45s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 227/300
 - 45s - loss: 0.0024 - val_loss: 0.0019
 - val_f1: 0.9960
Epoch 228/300
 - 45s - loss: 0.0023 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 229/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9958
Epoch 230/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 231/300
 - 45s - loss: 0.0024 - val_loss: 0.0082
 - val_f1: 0.9836
Epoch 232/300
 - 45s - loss: 0.0024 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 233/300
 - 45s - loss: 0.0023 - val_loss: 0.0020
 - val_f1: 0.9960
Epoch 234/300
 - 45s - loss: 0.0023 - val_loss: 0.0019
 - val_f1: 0.9963
Epoch 235/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9964
Epoch 236/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9960
Epoch 237/300
 - 45s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9957
Epoch 238/300
 - 45s - loss: 0.0024 - val_loss: 0.0049
 - val_f1: 0.9883
Epoch 239/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9938
Epoch 240/300
 - 45s - loss: 0.0023 - val_loss: 0.0021
 - val_f1: 0.9956
Epoch 241/300
 - 45s - loss: 0.0024 - val_loss: 0.0024
2019-12-20 22:08:45,155 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9943
Epoch 242/300
 - 45s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 243/300
 - 45s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 244/300
 - 45s - loss: 0.0026 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 245/300
 - 45s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 246/300
 - 45s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9963
Epoch 247/300
 - 45s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 248/300
 - 45s - loss: 0.0024 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 249/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 250/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9960
Epoch 251/300
 - 45s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 252/300
 - 45s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 253/300
 - 45s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 254/300
 - 45s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 255/300
 - 45s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9963
Epoch 256/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 257/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9953
Epoch 258/300
 - 45s - loss: 0.0024 - val_loss: 0.0022
 - val_f1: 0.9957
Epoch 259/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 260/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 261/300
 - 45s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 262/300
 - 45s - loss: 0.0024 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 263/300
 - 45s - loss: 0.0025 - val_loss: 0.0034
 - val_f1: 0.9905
Epoch 264/300
 - 45s - loss: 0.0024 - val_loss: 0.0021
 - val_f1: 0.9962
Epoch 265/300
 - 45s - loss: 0.0024 - val_loss: 0.0020
 - val_f1: 0.9962
Epoch 266/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 267/300
 - 45s - loss: 0.0024 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 268/300
 - 45s - loss: 0.0024 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 269/300
 - 45s - loss: 0.0024 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 270/300
 - 45s - loss: 0.0024 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 271/300
 - 45s - loss: 0.0024 - val_loss: 0.0025
2019-12-20 22:35:35,258 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9939
Epoch 272/300
 - 45s - loss: 0.0024 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 273/300
 - 45s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 274/300
 - 45s - loss: 0.0025 - val_loss: 0.0021
 - val_f1: 0.9953
Epoch 275/300
 - 45s - loss: 0.0025 - val_loss: 0.0023
2019-12-20 22:39:18,675 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 22:40:02,494 [INFO] Last epoch loss evaluation: train_loss = 0.001821, val_loss = 0.001858
2019-12-20 22:40:02,495 [INFO] Training complete. time_to_train = 14753.04 sec, 245.88 min
2019-12-20 22:40:02,502 [INFO] Model saved to results_selected_models/selected_ids2017_ann_deep_rep1/best_model.pickle
2019-12-20 22:40:02,653 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep1/training_error_history.png
2019-12-20 22:40:02,783 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep1/training_f1_history.png
2019-12-20 22:40:02,783 [INFO] Making predictions on training, validation, testing data
2019-12-20 22:40:45,332 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-20 22:40:55,663 [INFO] Dataset: Testing. Classification report below
2019-12-20 22:40:55,663 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.39      0.56       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.99      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       0.98      0.14      0.24       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.79      0.81    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-20 22:40:55,663 [INFO] Overall accuracy (micro avg): 0.9960906142916249
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-20 22:41:07,387 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9993         0.8954                       0.7894                0.0008                   0.2106  0.8058
2  Weighted avg        0.9968         0.9959                       0.9961                0.0059                   0.0039  0.9957
2019-12-20 22:41:17,972 [INFO] Dataset: Validation. Classification report below
2019-12-20 22:41:17,972 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.95      0.12      0.21       301
        Web Attack XSS       1.00      0.03      0.06       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.98      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-20 22:41:17,972 [INFO] Overall accuracy (micro avg): 0.9961224410409468
2019-12-20 22:41:30,009 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9994         0.9763                       0.7865                0.0008                   0.2135  0.8048
2  Weighted avg        0.9968         0.9961                       0.9961                0.0058                   0.0039  0.9957
2019-12-20 22:42:04,578 [INFO] Dataset: Training. Classification report below
2019-12-20 22:42:04,578 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.91      0.99      0.95      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.99      0.98      3538
Web Attack Brute Force       0.99      0.12      0.22       904
        Web Attack XSS       1.00      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.98      0.79      0.81   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-20 22:42:04,578 [INFO] Overall accuracy (micro avg): 0.9962403134584873
2019-12-20 22:42:43,847 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0003                   0.0038  0.9962
1     Macro avg        0.9994         0.9825                       0.7893                0.0008                   0.2107  0.8084
2  Weighted avg        0.9969         0.9963                       0.9962                0.0058                   0.0038  0.9959
2019-12-20 22:42:43,873 [INFO] Results saved to: results_selected_models/selected_ids2017_ann_deep_rep1/selected_ids2017_ann_deep_rep1_results.xlsx
2019-12-20 22:42:43,880 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-20 22:42:43,956 [INFO] Created directory: results_selected_models/selected_ids2017_ann_deep_rep2
2019-12-20 22:42:43,956 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids2017_ann_deep_rep2/run_log.log
2019-12-20 22:42:43,956 [INFO] ================= Running experiment no. 2  ================= 

2019-12-20 22:42:43,956 [INFO] Experiment parameters given below
2019-12-20 22:42:43,956 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids2017_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids2017_ann_deep_rep2'}
2019-12-20 22:42:43,956 [INFO] Created tensorboard log directory: results_selected_models/selected_ids2017_ann_deep_rep2/tf_logs_run_2019_12_20-22_42_43
2019-12-20 22:42:43,956 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-20 22:42:43,957 [INFO] Reading X, y files
2019-12-20 22:42:43,957 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-20 22:42:48,125 [INFO] Reading complete. time_to_read=4.17 seconds
2019-12-20 22:42:48,125 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-20 22:42:49,544 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-20 22:42:49,544 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-20 22:42:50,965 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-20 22:42:50,965 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-20 22:42:51,197 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-20 22:42:51,197 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-20 22:42:51,270 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-20 22:42:51,271 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-20 22:42:51,343 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-20 22:42:54,776 [INFO] Initializing model
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,205 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 22:42:55,205 [INFO] =================================================================
2019-12-20 22:42:55,205 [INFO] dense_6 (Dense)              (None, 256)               20224     
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,205 [INFO] batch_normalization_5 (Batch (None, 256)               1024      
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,205 [INFO] dropout_5 (Dropout)          (None, 256)               0         
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,205 [INFO] dense_7 (Dense)              (None, 128)               32896     
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,205 [INFO] batch_normalization_6 (Batch (None, 128)               512       
2019-12-20 22:42:55,205 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dropout_6 (Dropout)          (None, 128)               0         
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dense_8 (Dense)              (None, 64)                8256      
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dense_9 (Dense)              (None, 32)                2080      
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-20 22:42:55,206 [INFO] _________________________________________________________________
2019-12-20 22:42:55,206 [INFO] dense_10 (Dense)             (None, 12)                396       
2019-12-20 22:42:55,206 [INFO] =================================================================
2019-12-20 22:42:55,207 [INFO] Total params: 65,772
2019-12-20 22:42:55,207 [INFO] Trainable params: 64,812
2019-12-20 22:42:55,207 [INFO] Non-trainable params: 960
2019-12-20 22:42:55,207 [INFO] _________________________________________________________________
2019-12-20 22:42:55,207 [INFO] Training model
 - val_f1: 0.9942
Epoch 00275: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/300
 - 46s - loss: 0.0180 - val_loss: 0.0195
 - val_f1: 0.9489
Epoch 2/300
 - 46s - loss: 0.0088 - val_loss: 0.0091
 - val_f1: 0.9796
Epoch 3/300
 - 46s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9891
Epoch 4/300
 - 46s - loss: 0.0060 - val_loss: 0.0041
 - val_f1: 0.9896
Epoch 5/300
 - 46s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9893
Epoch 6/300
 - 46s - loss: 0.0046 - val_loss: 0.0039
 - val_f1: 0.9903
Epoch 7/300
 - 46s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9909
Epoch 8/300
 - 46s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9903
Epoch 9/300
 - 45s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9895
Epoch 10/300
 - 46s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 11/300
 - 46s - loss: 0.0037 - val_loss: 0.0040
 - val_f1: 0.9905
Epoch 12/300
 - 46s - loss: 0.0037 - val_loss: 0.0058
 - val_f1: 0.9863
Epoch 13/300
 - 46s - loss: 0.0042 - val_loss: 0.0055
 - val_f1: 0.9883
Epoch 14/300
 - 46s - loss: 0.0042 - val_loss: 0.0042
 - val_f1: 0.9926
Epoch 15/300
 - 45s - loss: 0.0053 - val_loss: 0.0060
 - val_f1: 0.9833
Epoch 16/300
 - 46s - loss: 0.0047 - val_loss: 0.0110
 - val_f1: 0.9575
Epoch 17/300
 - 45s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 18/300
 - 46s - loss: 0.0041 - val_loss: 0.0045
 - val_f1: 0.9892
Epoch 19/300
 - 46s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 20/300
 - 46s - loss: 0.0036 - val_loss: 0.0039
 - val_f1: 0.9912
Epoch 21/300
 - 46s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 22/300
 - 46s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9905
Epoch 23/300
 - 46s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 24/300
 - 46s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 25/300
 - 45s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 26/300
 - 45s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9955
Epoch 27/300
 - 45s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 28/300
 - 46s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9884
Epoch 29/300
 - 45s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 30/300
 - 46s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 31/300
 - 46s - loss: 0.0031 - val_loss: 0.0026
2019-12-20 23:11:23,896 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9941
Epoch 32/300
 - 45s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 33/300
 - 46s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 34/300
 - 46s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 35/300
 - 46s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 36/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 37/300
 - 46s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9914
Epoch 38/300
 - 46s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 39/300
 - 46s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 40/300
 - 46s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 41/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 42/300
 - 46s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9914
Epoch 43/300
 - 46s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 44/300
 - 46s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 45/300
 - 46s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 46/300
 - 46s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 47/300
 - 46s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 48/300
 - 46s - loss: 0.0032 - val_loss: 0.0065
 - val_f1: 0.9844
Epoch 49/300
 - 46s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 50/300
 - 46s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9926
Epoch 51/300
 - 46s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 52/300
 - 46s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 53/300
 - 46s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 54/300
 - 46s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9896
Epoch 55/300
 - 46s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 56/300
 - 46s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 57/300
 - 46s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 58/300
 - 46s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 59/300
 - 46s - loss: 0.0030 - val_loss: 0.0161
 - val_f1: 0.9652
Epoch 60/300
 - 46s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 61/300
 - 46s - loss: 0.0030 - val_loss: 0.0035
2019-12-20 23:39:10,405 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9927
Epoch 62/300
 - 45s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 63/300
 - 46s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 64/300
 - 46s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 65/300
 - 46s - loss: 0.0031 - val_loss: 0.0057
 - val_f1: 0.9878
Epoch 66/300
 - 46s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9887
Epoch 67/300
 - 46s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 68/300
 - 46s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 69/300
 - 46s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 70/300
 - 45s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9912
Epoch 71/300
 - 46s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 72/300
 - 46s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 73/300
 - 46s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 74/300
 - 45s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 75/300
 - 46s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9960
Epoch 76/300
 - 46s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 77/300
 - 46s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 78/300
 - 45s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 79/300
 - 46s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9932
Epoch 80/300
 - 46s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 81/300
 - 46s - loss: 0.0029 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 82/300
 - 46s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 83/300
 - 46s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 84/300
 - 46s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 85/300
 - 46s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 86/300
 - 45s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9958
Epoch 87/300
 - 46s - loss: 0.0029 - val_loss: 0.0077
 - val_f1: 0.9725
Epoch 88/300
 - 46s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9934
Epoch 89/300
 - 46s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 90/300
 - 46s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9958
Epoch 91/300
 - 46s - loss: 0.0027 - val_loss: 0.0025
2019-12-21 00:06:56,340 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9947
Epoch 92/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 93/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 94/300
 - 46s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 95/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 96/300
 - 46s - loss: 0.0028 - val_loss: 0.0104
 - val_f1: 0.9668
Epoch 97/300
 - 46s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 98/300
 - 46s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 99/300
 - 46s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 100/300
 - 46s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 101/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 102/300
 - 45s - loss: 0.0029 - val_loss: 0.0034
 - val_f1: 0.9911
Epoch 103/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 104/300
 - 46s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 105/300
 - 46s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 106/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 107/300
 - 46s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 108/300
 - 46s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 109/300
 - 46s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9896
Epoch 110/300
 - 46s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9960
Epoch 111/300
 - 46s - loss: 0.0028 - val_loss: 0.0037
 - val_f1: 0.9904
Epoch 112/300
 - 46s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 113/300
 - 46s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9912
Epoch 114/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 115/300
 - 45s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9961
Epoch 116/300
 - 45s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 117/300
 - 46s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 118/300
 - 46s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 119/300
 - 46s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9917
Epoch 120/300
 - 46s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 121/300
 - 46s - loss: 0.0027 - val_loss: 0.0024
2019-12-21 00:34:42,792 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9947
Epoch 122/300
 - 46s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 123/300
 - 46s - loss: 0.0027 - val_loss: 0.0087
 - val_f1: 0.9702
Epoch 124/300
 - 46s - loss: 0.0026 - val_loss: 0.0062
 - val_f1: 0.9808
Epoch 125/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 126/300
 - 46s - loss: 0.0027 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 127/300
 - 46s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9935
Epoch 128/300
 - 46s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 129/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 130/300
 - 46s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 131/300
 - 46s - loss: 0.0027 - val_loss: 0.0038
 - val_f1: 0.9902
Epoch 132/300
 - 46s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 133/300
 - 46s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9960
Epoch 134/300
 - 46s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 135/300
 - 45s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 136/300
 - 45s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 137/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 138/300
 - 45s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 139/300
 - 46s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 140/300
 - 46s - loss: 0.0027 - val_loss: 0.0028
2019-12-21 00:52:28,109 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 00:53:11,522 [INFO] Last epoch loss evaluation: train_loss = 0.002117, val_loss = 0.002151
2019-12-21 00:53:11,523 [INFO] Training complete. time_to_train = 7816.32 sec, 130.27 min
2019-12-21 00:53:11,531 [INFO] Model saved to results_selected_models/selected_ids2017_ann_deep_rep2/best_model.pickle
2019-12-21 00:53:11,685 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep2/training_error_history.png
2019-12-21 00:53:11,812 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep2/training_f1_history.png
2019-12-21 00:53:11,812 [INFO] Making predictions on training, validation, testing data
2019-12-21 00:53:59,611 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 00:54:09,918 [INFO] Dataset: Testing. Classification report below
2019-12-21 00:54:09,918 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       1.00      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 00:54:09,918 [INFO] Overall accuracy (micro avg): 0.9957157659107224
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-21 00:54:21,638 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8966                       0.7857                0.0009                   0.2143  0.8007
2  Weighted avg        0.9965         0.9955                       0.9957                0.0062                   0.0043  0.9953
2019-12-21 00:54:32,116 [INFO] Dataset: Validation. Classification report below
2019-12-21 00:54:32,116 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.35      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.92      0.08      0.14       301
        Web Attack XSS       1.00      0.03      0.06       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.97      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 00:54:32,116 [INFO] Overall accuracy (micro avg): 0.9957670423401855
2019-12-21 00:54:44,034 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.9737                       0.7816                0.0009                   0.2184  0.7974
2  Weighted avg        0.9965         0.9958                       0.9958                0.0062                   0.0042  0.9954
2019-12-21 00:55:18,576 [INFO] Dataset: Training. Classification report below
2019-12-21 00:55:18,576 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.98      0.99      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.99      0.09      0.17       904
        Web Attack XSS       1.00      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.98      0.79      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-21 00:55:18,576 [INFO] Overall accuracy (micro avg): 0.995880199259261
2019-12-21 00:55:57,811 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0004                   0.0041  0.9959
1     Macro avg        0.9993         0.9815                       0.7860                0.0009                   0.2140  0.8033
2  Weighted avg        0.9966         0.9959                       0.9959                0.0061                   0.0041  0.9955
2019-12-21 00:55:57,838 [INFO] Results saved to: results_selected_models/selected_ids2017_ann_deep_rep2/selected_ids2017_ann_deep_rep2_results.xlsx
2019-12-21 00:55:57,842 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-21 00:55:57,917 [INFO] Created directory: results_selected_models/selected_ids2017_ann_deep_rep3
2019-12-21 00:55:57,917 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids2017_ann_deep_rep3/run_log.log
2019-12-21 00:55:57,917 [INFO] ================= Running experiment no. 3  ================= 

2019-12-21 00:55:57,917 [INFO] Experiment parameters given below
2019-12-21 00:55:57,917 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids2017_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids2017_ann_deep_rep3'}
2019-12-21 00:55:57,918 [INFO] Created tensorboard log directory: results_selected_models/selected_ids2017_ann_deep_rep3/tf_logs_run_2019_12_21-00_55_57
2019-12-21 00:55:57,918 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 00:55:57,918 [INFO] Reading X, y files
2019-12-21 00:55:57,918 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 00:56:02,124 [INFO] Reading complete. time_to_read=4.21 seconds
2019-12-21 00:56:02,125 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 00:56:03,555 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 00:56:03,555 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 00:56:04,988 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 00:56:04,988 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 00:56:05,218 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-21 00:56:05,218 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 00:56:05,292 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 00:56:05,292 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 00:56:05,366 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 00:56:08,806 [INFO] Initializing model
2019-12-21 00:56:09,246 [INFO] _________________________________________________________________
2019-12-21 00:56:09,246 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 00:56:09,246 [INFO] =================================================================
2019-12-21 00:56:09,246 [INFO] dense_11 (Dense)             (None, 256)               20224     
2019-12-21 00:56:09,246 [INFO] _________________________________________________________________
2019-12-21 00:56:09,246 [INFO] batch_normalization_9 (Batch (None, 256)               1024      
2019-12-21 00:56:09,246 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dropout_9 (Dropout)          (None, 256)               0         
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dense_12 (Dense)             (None, 128)               32896     
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] batch_normalization_10 (Batc (None, 128)               512       
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dropout_10 (Dropout)         (None, 128)               0         
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dense_13 (Dense)             (None, 64)                8256      
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] dense_14 (Dense)             (None, 32)                2080      
2019-12-21 00:56:09,247 [INFO] _________________________________________________________________
2019-12-21 00:56:09,247 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2019-12-21 00:56:09,248 [INFO] _________________________________________________________________
2019-12-21 00:56:09,248 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2019-12-21 00:56:09,248 [INFO] _________________________________________________________________
2019-12-21 00:56:09,248 [INFO] dense_15 (Dense)             (None, 12)                396       
2019-12-21 00:56:09,248 [INFO] =================================================================
2019-12-21 00:56:09,248 [INFO] Total params: 65,772
2019-12-21 00:56:09,248 [INFO] Trainable params: 64,812
2019-12-21 00:56:09,248 [INFO] Non-trainable params: 960
2019-12-21 00:56:09,248 [INFO] _________________________________________________________________
2019-12-21 00:56:09,248 [INFO] Training model
 - val_f1: 0.9933
Epoch 00140: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/300
 - 47s - loss: 0.0179 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 2/300
 - 46s - loss: 0.0091 - val_loss: 0.0073
 - val_f1: 0.9810
Epoch 3/300
 - 46s - loss: 0.0073 - val_loss: 0.0044
 - val_f1: 0.9899
Epoch 4/300
 - 46s - loss: 0.0057 - val_loss: 0.0039
 - val_f1: 0.9903
Epoch 5/300
 - 46s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9914
Epoch 6/300
 - 46s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 7/300
 - 46s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9908
Epoch 8/300
 - 46s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9897
Epoch 9/300
 - 46s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 10/300
 - 46s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 11/300
 - 46s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 12/300
 - 46s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 13/300
 - 46s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 14/300
 - 46s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 15/300
 - 46s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 16/300
 - 46s - loss: 0.0036 - val_loss: 0.0111
 - val_f1: 0.9778
Epoch 17/300
 - 46s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 18/300
 - 46s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 19/300
 - 46s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 20/300
 - 46s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9901
Epoch 21/300
 - 46s - loss: 0.0034 - val_loss: 0.0054
 - val_f1: 0.9889
Epoch 22/300
 - 46s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 23/300
 - 46s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 24/300
 - 46s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9955
Epoch 25/300
 - 46s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 26/300
 - 46s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 27/300
 - 46s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9925
Epoch 28/300
 - 46s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 29/300
 - 46s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 30/300
 - 46s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 31/300
 - 46s - loss: 0.0034 - val_loss: 0.0028
2019-12-21 01:25:31,421 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9938
Epoch 32/300
 - 46s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 33/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 34/300
 - 46s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 35/300
 - 46s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 36/300
 - 47s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 37/300
 - 46s - loss: 0.0031 - val_loss: 0.0196
 - val_f1: 0.9676
Epoch 38/300
 - 46s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 39/300
 - 46s - loss: 0.0031 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 40/300
 - 46s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9914
Epoch 41/300
 - 46s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 42/300
 - 46s - loss: 0.0032 - val_loss: 0.0132
 - val_f1: 0.9712
Epoch 43/300
 - 46s - loss: 0.0031 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 44/300
 - 46s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 45/300
 - 46s - loss: 0.0035 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 46/300
 - 46s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 47/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 48/300
 - 46s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 49/300
 - 46s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 50/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 51/300
 - 46s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 52/300
 - 46s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 53/300
 - 46s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 54/300
 - 46s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 55/300
 - 46s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9909
Epoch 56/300
 - 46s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9933
Epoch 57/300
 - 46s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 58/300
 - 46s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9915
Epoch 59/300
 - 46s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 60/300
 - 46s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 61/300
 - 46s - loss: 0.0032 - val_loss: 0.0025
2019-12-21 01:54:05,195 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9945
Epoch 62/300
 - 46s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 63/300
 - 46s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 64/300
 - 46s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 65/300
 - 46s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 66/300
 - 46s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 67/300
 - 46s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 68/300
 - 46s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 69/300
 - 46s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9958
Epoch 70/300
 - 46s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 71/300
 - 46s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 72/300
 - 46s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 73/300
 - 46s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 74/300
 - 46s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 75/300
 - 46s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9905
Epoch 76/300
 - 46s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 77/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 78/300
 - 46s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 79/300
 - 47s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 80/300
 - 46s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 81/300
 - 46s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 82/300
 - 46s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9961
Epoch 83/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 84/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 85/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 86/300
 - 46s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 87/300
 - 46s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 88/300
 - 46s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 89/300
 - 46s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 90/300
 - 46s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 91/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
2019-12-21 02:22:43,556 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9950
Epoch 92/300
 - 46s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 93/300
 - 46s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 94/300
 - 46s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 95/300
 - 46s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9960
Epoch 96/300
 - 46s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 97/300
 - 46s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 98/300
 - 46s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 99/300
 - 46s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 100/300
 - 46s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 101/300
 - 46s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 102/300
 - 46s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 103/300
 - 46s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 104/300
 - 47s - loss: 0.0027 - val_loss: 0.0193
 - val_f1: 0.9662
Epoch 105/300
 - 47s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 106/300
 - 47s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 107/300
 - 47s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 108/300
 - 47s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 109/300
 - 47s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 110/300
 - 47s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 111/300
 - 47s - loss: 0.0027 - val_loss: 0.0159
 - val_f1: 0.9663
Epoch 112/300
 - 47s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 113/300
 - 47s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 114/300
 - 47s - loss: 0.0026 - val_loss: 0.0035
 - val_f1: 0.9904
Epoch 115/300
 - 47s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 116/300
 - 47s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 117/300
 - 47s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 118/300
 - 46s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 119/300
 - 47s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 120/300
 - 47s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 121/300
 - 46s - loss: 0.0026 - val_loss: 0.0027
2019-12-21 02:51:24,542 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9932
Epoch 122/300
 - 47s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 123/300
 - 47s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 124/300
 - 47s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 125/300
 - 47s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 126/300
 - 47s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 127/300
 - 47s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 128/300
 - 47s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 129/300
 - 47s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 130/300
 - 47s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 131/300
 - 47s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 132/300
 - 47s - loss: 0.0025 - val_loss: 0.0053
2019-12-21 03:02:07,895 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 03:02:54,924 [INFO] Last epoch loss evaluation: train_loss = 0.002096, val_loss = 0.002160
2019-12-21 03:02:54,925 [INFO] Training complete. time_to_train = 7605.68 sec, 126.76 min
2019-12-21 03:02:54,933 [INFO] Model saved to results_selected_models/selected_ids2017_ann_deep_rep3/best_model.pickle
2019-12-21 03:02:55,081 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep3/training_error_history.png
2019-12-21 03:02:55,216 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep3/training_f1_history.png
2019-12-21 03:02:55,216 [INFO] Making predictions on training, validation, testing data
2019-12-21 03:03:47,231 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 03:03:57,530 [INFO] Dataset: Testing. Classification report below
2019-12-21 03:03:57,530 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.96      0.99      0.97      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.97      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 03:03:57,530 [INFO] Overall accuracy (micro avg): 0.9960428741676421
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-21 03:04:09,225 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8917                       0.7858                0.0008                   0.2142  0.7996
2  Weighted avg        0.9968         0.9958                       0.9960                0.0055                   0.0040  0.9957
2019-12-21 03:04:19,658 [INFO] Dataset: Validation. Classification report below
2019-12-21 03:04:19,658 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.90      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.94      1099
         DoS slowloris       0.96      0.98      0.97      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.85      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 03:04:19,658 [INFO] Overall accuracy (micro avg): 0.9960534830840827
2019-12-21 03:04:31,524 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0004                   0.0039  0.9961
1     Macro avg        0.9993         0.8766                       0.7797                0.0008                   0.2203  0.7912
2  Weighted avg        0.9968         0.9958                       0.9961                0.0055                   0.0039  0.9956
2019-12-21 03:05:06,025 [INFO] Dataset: Training. Classification report below
2019-12-21 03:05:06,026 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.96      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.91      0.99      0.94      3300
         DoS slowloris       0.97      0.99      0.98      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.87      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-21 03:05:06,026 [INFO] Overall accuracy (micro avg): 0.9961577995666842
2019-12-21 03:05:45,215 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0003                   0.0038  0.9962
1     Macro avg        0.9994         0.8849                       0.7832                0.0008                   0.2168  0.7971
2  Weighted avg        0.9969         0.9959                       0.9962                0.0055                   0.0038  0.9958
2019-12-21 03:05:45,263 [INFO] Results saved to: results_selected_models/selected_ids2017_ann_deep_rep3/selected_ids2017_ann_deep_rep3_results.xlsx
2019-12-21 03:05:45,267 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-21 03:05:45,341 [INFO] Created directory: results_selected_models/selected_ids2017_ann_deep_rep4
2019-12-21 03:05:45,342 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids2017_ann_deep_rep4/run_log.log
2019-12-21 03:05:45,342 [INFO] ================= Running experiment no. 4  ================= 

2019-12-21 03:05:45,342 [INFO] Experiment parameters given below
2019-12-21 03:05:45,342 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids2017_ann_deep_rep4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids2017_ann_deep_rep4'}
2019-12-21 03:05:45,342 [INFO] Created tensorboard log directory: results_selected_models/selected_ids2017_ann_deep_rep4/tf_logs_run_2019_12_21-03_05_45
2019-12-21 03:05:45,342 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 03:05:45,342 [INFO] Reading X, y files
2019-12-21 03:05:45,342 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 03:05:49,502 [INFO] Reading complete. time_to_read=4.16 seconds
2019-12-21 03:05:49,502 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 03:05:50,931 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 03:05:50,931 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 03:05:52,364 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 03:05:52,364 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 03:05:52,584 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-21 03:05:52,584 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 03:05:52,658 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 03:05:52,659 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 03:05:52,732 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 03:05:56,175 [INFO] Initializing model
2019-12-21 03:05:56,634 [INFO] _________________________________________________________________
2019-12-21 03:05:56,634 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 03:05:56,634 [INFO] =================================================================
2019-12-21 03:05:56,634 [INFO] dense_16 (Dense)             (None, 256)               20224     
2019-12-21 03:05:56,634 [INFO] _________________________________________________________________
2019-12-21 03:05:56,634 [INFO] batch_normalization_13 (Batc (None, 256)               1024      
2019-12-21 03:05:56,634 [INFO] _________________________________________________________________
2019-12-21 03:05:56,634 [INFO] dropout_13 (Dropout)         (None, 256)               0         
2019-12-21 03:05:56,634 [INFO] _________________________________________________________________
2019-12-21 03:05:56,634 [INFO] dense_17 (Dense)             (None, 128)               32896     
2019-12-21 03:05:56,634 [INFO] _________________________________________________________________
2019-12-21 03:05:56,634 [INFO] batch_normalization_14 (Batc (None, 128)               512       
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dropout_14 (Dropout)         (None, 128)               0         
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dense_18 (Dense)             (None, 64)                8256      
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] batch_normalization_15 (Batc (None, 64)                256       
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dropout_15 (Dropout)         (None, 64)                0         
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dense_19 (Dense)             (None, 32)                2080      
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] batch_normalization_16 (Batc (None, 32)                128       
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dropout_16 (Dropout)         (None, 32)                0         
2019-12-21 03:05:56,635 [INFO] _________________________________________________________________
2019-12-21 03:05:56,635 [INFO] dense_20 (Dense)             (None, 12)                396       
2019-12-21 03:05:56,635 [INFO] =================================================================
2019-12-21 03:05:56,636 [INFO] Total params: 65,772
2019-12-21 03:05:56,636 [INFO] Trainable params: 64,812
2019-12-21 03:05:56,636 [INFO] Non-trainable params: 960
2019-12-21 03:05:56,636 [INFO] _________________________________________________________________
2019-12-21 03:05:56,636 [INFO] Training model
 - val_f1: 0.9870
Epoch 00132: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/300
 - 47s - loss: 0.0181 - val_loss: 0.0091
 - val_f1: 0.9771
Epoch 2/300
 - 47s - loss: 0.0095 - val_loss: 0.0075
 - val_f1: 0.9804
Epoch 3/300
 - 47s - loss: 0.0079 - val_loss: 0.0068
 - val_f1: 0.9851
Epoch 4/300
 - 47s - loss: 0.0059 - val_loss: 0.0101
 - val_f1: 0.9747
Epoch 5/300
 - 47s - loss: 0.0051 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 6/300
 - 47s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9906
Epoch 7/300
 - 47s - loss: 0.0044 - val_loss: 0.0062
 - val_f1: 0.9849
Epoch 8/300
 - 47s - loss: 0.0049 - val_loss: 0.0047
 - val_f1: 0.9894
Epoch 9/300
 - 47s - loss: 0.0044 - val_loss: 0.0056
 - val_f1: 0.9852
Epoch 10/300
 - 47s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 11/300
 - 47s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 12/300
 - 47s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 13/300
 - 47s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9870
Epoch 14/300
 - 47s - loss: 0.0039 - val_loss: 0.0041
 - val_f1: 0.9895
Epoch 15/300
 - 47s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 16/300
 - 47s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9913
Epoch 17/300
 - 47s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 18/300
 - 47s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 19/300
 - 47s - loss: 0.0039 - val_loss: 0.0057
 - val_f1: 0.9852
Epoch 20/300
 - 47s - loss: 0.0039 - val_loss: 0.0052
 - val_f1: 0.9897
Epoch 21/300
 - 47s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9897
Epoch 22/300
 - 47s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 23/300
 - 47s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 24/300
 - 47s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 25/300
 - 47s - loss: 0.0037 - val_loss: 0.0071
 - val_f1: 0.9803
Epoch 26/300
 - 47s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 27/300
 - 47s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9886
Epoch 28/300
 - 47s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9908
Epoch 29/300
 - 47s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 30/300
 - 47s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9911
Epoch 31/300
 - 47s - loss: 0.0036 - val_loss: 0.0028
2019-12-21 03:36:09,408 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9951
Epoch 32/300
 - 47s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9890
Epoch 33/300
 - 47s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 34/300
 - 47s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9923
Epoch 35/300
 - 47s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 36/300
 - 47s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9930
Epoch 37/300
 - 47s - loss: 0.0034 - val_loss: 0.0049
 - val_f1: 0.9916
Epoch 38/300
 - 47s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9936
Epoch 39/300
 - 47s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 40/300
 - 47s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 41/300
 - 47s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 42/300
 - 47s - loss: 0.0032 - val_loss: 0.0056
 - val_f1: 0.9864
Epoch 43/300
 - 47s - loss: 0.0031 - val_loss: 0.0040
 - val_f1: 0.9929
Epoch 44/300
 - 47s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 45/300
 - 47s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 46/300
 - 47s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9917
Epoch 47/300
 - 47s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 48/300
 - 47s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 49/300
 - 47s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9950
Epoch 50/300
 - 47s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 51/300
 - 47s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 52/300
 - 47s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 53/300
 - 47s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 54/300
 - 47s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 55/300
 - 47s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9944
Epoch 56/300
 - 47s - loss: 0.0035 - val_loss: 0.0063
 - val_f1: 0.9816
Epoch 57/300
 - 47s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 58/300
 - 47s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 59/300
 - 47s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 60/300
 - 47s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9892
Epoch 61/300
 - 47s - loss: 0.0032 - val_loss: 0.0037
2019-12-21 04:05:32,090 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9925
Epoch 62/300
 - 47s - loss: 0.0031 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 63/300
 - 47s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 64/300
 - 47s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 65/300
 - 47s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 66/300
 - 47s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 67/300
 - 47s - loss: 0.0032 - val_loss: 0.0106
 - val_f1: 0.9823
Epoch 68/300
 - 47s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 69/300
 - 47s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 70/300
 - 47s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 71/300
 - 47s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 72/300
 - 47s - loss: 0.0031 - val_loss: 0.0047
2019-12-21 04:16:30,497 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 04:17:21,455 [INFO] Last epoch loss evaluation: train_loss = 0.002428, val_loss = 0.002468
2019-12-21 04:17:21,455 [INFO] Training complete. time_to_train = 4284.82 sec, 71.41 min
2019-12-21 04:17:21,464 [INFO] Model saved to results_selected_models/selected_ids2017_ann_deep_rep4/best_model.pickle
2019-12-21 04:17:21,616 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep4/training_error_history.png
2019-12-21 04:17:21,762 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep4/training_f1_history.png
2019-12-21 04:17:21,762 [INFO] Making predictions on training, validation, testing data
2019-12-21 04:18:18,891 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 04:18:29,177 [INFO] Dataset: Testing. Classification report below
2019-12-21 04:18:29,177 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.97      0.96      1179
Web Attack Brute Force       1.00      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 04:18:29,177 [INFO] Overall accuracy (micro avg): 0.9947839494166865
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-21 04:18:40,870 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0005                   0.0052  0.9948
1     Macro avg        0.9991         0.8941                       0.7826                0.0011                   0.2174  0.7976
2  Weighted avg        0.9957         0.9946                       0.9948                0.0078                   0.0052  0.9944
2019-12-21 04:18:51,317 [INFO] Dataset: Validation. Classification report below
2019-12-21 04:18:51,317 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.34      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.97      0.95      1180
Web Attack Brute Force       0.82      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 04:18:51,317 [INFO] Overall accuracy (micro avg): 0.9948635162899911
2019-12-21 04:19:03,200 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8783                       0.7758                0.0011                   0.2242  0.7885
2  Weighted avg        0.9958         0.9946                       0.9949                0.0075                   0.0051  0.9945
2019-12-21 04:19:37,654 [INFO] Dataset: Training. Classification report below
2019-12-21 04:19:37,654 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.98      0.98      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.97      0.96      3538
Web Attack Brute Force       0.86      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-21 04:19:37,654 [INFO] Overall accuracy (micro avg): 0.9949737252193102
2019-12-21 04:20:16,784 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.8850                       0.7805                0.0010                   0.2195  0.7955
2  Weighted avg        0.9958         0.9947                       0.9950                0.0075                   0.0050  0.9946
2019-12-21 04:20:16,808 [INFO] Results saved to: results_selected_models/selected_ids2017_ann_deep_rep4/selected_ids2017_ann_deep_rep4_results.xlsx
2019-12-21 04:20:16,812 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-21 04:20:16,887 [INFO] Created directory: results_selected_models/selected_ids2017_ann_deep_rep5
2019-12-21 04:20:16,888 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids2017_ann_deep_rep5/run_log.log
2019-12-21 04:20:16,888 [INFO] ================= Running experiment no. 5  ================= 

2019-12-21 04:20:16,888 [INFO] Experiment parameters given below
2019-12-21 04:20:16,888 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids2017_ann_deep_rep5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [256, 128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids2017_ann_deep_rep5'}
2019-12-21 04:20:16,888 [INFO] Created tensorboard log directory: results_selected_models/selected_ids2017_ann_deep_rep5/tf_logs_run_2019_12_21-04_20_16
2019-12-21 04:20:16,888 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 04:20:16,888 [INFO] Reading X, y files
2019-12-21 04:20:16,888 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 04:20:21,035 [INFO] Reading complete. time_to_read=4.15 seconds
2019-12-21 04:20:21,035 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 04:20:22,470 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 04:20:22,470 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 04:20:23,907 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-21 04:20:23,907 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 04:20:24,129 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-21 04:20:24,129 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 04:20:24,204 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 04:20:24,204 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 04:20:24,278 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 04:20:27,748 [INFO] Initializing model
2019-12-21 04:20:28,093 [INFO] _________________________________________________________________
2019-12-21 04:20:28,093 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 04:20:28,093 [INFO] =================================================================
2019-12-21 04:20:28,094 [INFO] dense_21 (Dense)             (None, 256)               20224     
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] batch_normalization_17 (Batc (None, 256)               1024      
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] dropout_17 (Dropout)         (None, 256)               0         
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] dense_22 (Dense)             (None, 128)               32896     
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] batch_normalization_18 (Batc (None, 128)               512       
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] dropout_18 (Dropout)         (None, 128)               0         
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] dense_23 (Dense)             (None, 64)                8256      
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] batch_normalization_19 (Batc (None, 64)                256       
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,094 [INFO] dropout_19 (Dropout)         (None, 64)                0         
2019-12-21 04:20:28,094 [INFO] _________________________________________________________________
2019-12-21 04:20:28,095 [INFO] dense_24 (Dense)             (None, 32)                2080      
2019-12-21 04:20:28,095 [INFO] _________________________________________________________________
2019-12-21 04:20:28,095 [INFO] batch_normalization_20 (Batc (None, 32)                128       
2019-12-21 04:20:28,095 [INFO] _________________________________________________________________
2019-12-21 04:20:28,095 [INFO] dropout_20 (Dropout)         (None, 32)                0         
2019-12-21 04:20:28,095 [INFO] _________________________________________________________________
2019-12-21 04:20:28,095 [INFO] dense_25 (Dense)             (None, 12)                396       
2019-12-21 04:20:28,095 [INFO] =================================================================
2019-12-21 04:20:28,095 [INFO] Total params: 65,772
2019-12-21 04:20:28,095 [INFO] Trainable params: 64,812
2019-12-21 04:20:28,095 [INFO] Non-trainable params: 960
2019-12-21 04:20:28,095 [INFO] _________________________________________________________________
2019-12-21 04:20:28,095 [INFO] Training model
 - val_f1: 0.9881
Epoch 00072: early stopping
Train on 1696684 samples, validate on 565562 samples
Epoch 1/300
 - 48s - loss: 0.0181 - val_loss: 0.0089
 - val_f1: 0.9767
Epoch 2/300
 - 48s - loss: 0.0094 - val_loss: 0.0073
 - val_f1: 0.9805
Epoch 3/300
 - 48s - loss: 0.0075 - val_loss: 0.0052
 - val_f1: 0.9841
Epoch 4/300
 - 48s - loss: 0.0055 - val_loss: 0.0222
 - val_f1: 0.9638
Epoch 5/300
 - 48s - loss: 0.0064 - val_loss: 0.0071
 - val_f1: 0.9858
Epoch 6/300
 - 48s - loss: 0.0052 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 7/300
 - 48s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9900
Epoch 8/300
 - 48s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9931
Epoch 9/300
 - 48s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 10/300
 - 48s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 11/300
 - 48s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 12/300
 - 48s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9912
Epoch 13/300
 - 48s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 14/300
 - 48s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9905
Epoch 15/300
 - 48s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9912
Epoch 16/300
 - 48s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 17/300
 - 48s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 18/300
 - 48s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 19/300
 - 48s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 20/300
 - 48s - loss: 0.0039 - val_loss: 0.0136
 - val_f1: 0.9697
Epoch 21/300
 - 48s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 22/300
 - 48s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 23/300
 - 48s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 24/300
 - 48s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 25/300
 - 48s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 26/300
 - 48s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 27/300
 - 48s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9868
Epoch 28/300
 - 48s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 29/300
 - 48s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 30/300
 - 48s - loss: 0.0034 - val_loss: 0.0036
 - val_f1: 0.9901
Epoch 31/300
 - 48s - loss: 0.0034 - val_loss: 0.0027
2019-12-21 04:51:28,460 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9934
Epoch 32/300
 - 48s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 33/300
 - 48s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 34/300
 - 48s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 35/300
 - 48s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9860
Epoch 36/300
 - 48s - loss: 0.0037 - val_loss: 0.0044
 - val_f1: 0.9896
Epoch 37/300
 - 48s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 38/300
 - 48s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 39/300
 - 48s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 40/300
 - 48s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 41/300
 - 48s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 42/300
 - 48s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9931
Epoch 43/300
 - 48s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 44/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 45/300
 - 48s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 46/300
 - 48s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 47/300
 - 48s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 48/300
 - 48s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 49/300
 - 48s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 50/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 51/300
 - 48s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 52/300
 - 48s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 53/300
 - 48s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 54/300
 - 48s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 55/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 56/300
 - 48s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 57/300
 - 48s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 58/300
 - 48s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 59/300
 - 48s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 60/300
 - 48s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 61/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
2019-12-21 05:21:38,565 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9952
Epoch 62/300
 - 48s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 63/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 64/300
 - 48s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 65/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 66/300
 - 48s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 67/300
 - 48s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9962
Epoch 68/300
 - 48s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 69/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 70/300
 - 48s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 71/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 72/300
 - 48s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 73/300
 - 48s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 74/300
 - 48s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 75/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 76/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 77/300
 - 48s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 78/300
 - 48s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 79/300
 - 48s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 80/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 81/300
 - 48s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 82/300
 - 48s - loss: 0.0029 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 83/300
 - 48s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 84/300
 - 48s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 85/300
 - 48s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 86/300
 - 48s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 87/300
 - 48s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 88/300
 - 48s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 89/300
 - 48s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 90/300
 - 48s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 91/300
 - 48s - loss: 0.0031 - val_loss: 0.0025
2019-12-21 05:51:48,704 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids2017_ann_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9941
Epoch 92/300
 - 48s - loss: 0.0030 - val_loss: 0.0047
 - val_f1: 0.9883
Epoch 93/300
 - 48s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 94/300
 - 48s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 95/300
 - 48s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 96/300
 - 48s - loss: 0.0029 - val_loss: 0.0150
 - val_f1: 0.9632
Epoch 97/300
 - 48s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9897
Epoch 98/300
 - 48s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 99/300
 - 48s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 100/300
 - 48s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 101/300
 - 48s - loss: 0.0029 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 102/300
 - 48s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 103/300
 - 48s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 104/300
 - 48s - loss: 0.0029 - val_loss: 0.0034
 - val_f1: 0.9911
Epoch 105/300
 - 48s - loss: 0.0028 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 106/300
 - 48s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 107/300
 - 48s - loss: 0.0028 - val_loss: 0.0035
 - val_f1: 0.9903
Epoch 108/300
 - 48s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 109/300
 - 48s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9899
Epoch 110/300
 - 48s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 111/300
 - 48s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 112/300
 - 48s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 113/300
 - 48s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 114/300
 - 48s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 115/300
 - 48s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 116/300
 - 48s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 117/300
 - 48s - loss: 0.0028 - val_loss: 0.0025
2019-12-21 06:18:09,749 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 06:19:04,282 [INFO] Last epoch loss evaluation: train_loss = 0.002177, val_loss = 0.002217
2019-12-21 06:19:04,282 [INFO] Training complete. time_to_train = 7116.19 sec, 118.60 min
2019-12-21 06:19:04,293 [INFO] Model saved to results_selected_models/selected_ids2017_ann_deep_rep5/best_model.pickle
2019-12-21 06:19:04,448 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep5/training_error_history.png
2019-12-21 06:19:04,579 [INFO] Plot saved to: results_selected_models/selected_ids2017_ann_deep_rep5/training_f1_history.png
2019-12-21 06:19:04,579 [INFO] Making predictions on training, validation, testing data
2019-12-21 06:20:05,685 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 06:20:16,005 [INFO] Dataset: Testing. Classification report below
2019-12-21 06:20:16,005 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.98      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       0.97      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 06:20:16,005 [INFO] Overall accuracy (micro avg): 0.9961825582341105
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-21 06:20:27,722 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0003                   0.0038  0.9962
1     Macro avg        0.9994         0.8928                       0.7857                0.0008                   0.2143  0.8000
2  Weighted avg        0.9969         0.9960                       0.9962                0.0062                   0.0038  0.9958
2019-12-21 06:20:38,185 [INFO] Dataset: Validation. Classification report below
2019-12-21 06:20:38,185 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1099
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       0.98      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.82      0.08      0.14       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-21 06:20:38,185 [INFO] Overall accuracy (micro avg): 0.9962356028163137
2019-12-21 06:20:50,082 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0003                   0.0038  0.9962
1     Macro avg        0.9994         0.8814                       0.7798                0.0008                   0.2202  0.7928
2  Weighted avg        0.9969         0.9960                       0.9962                0.0061                   0.0038  0.9958
2019-12-21 06:21:24,598 [INFO] Dataset: Training. Classification report below
2019-12-21 06:21:24,598 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.87      0.09      0.17       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-21 06:21:24,598 [INFO] Overall accuracy (micro avg): 0.9963599586016018
2019-12-21 06:22:03,783 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9964         0.9964                       0.9964                0.0003                   0.0036  0.9964
1     Macro avg        0.9994         0.8873                       0.7837                0.0008                   0.2163  0.7981
2  Weighted avg        0.9970         0.9961                       0.9964                0.0061                   0.0036  0.9960
2019-12-21 06:22:03,807 [INFO] Results saved to: results_selected_models/selected_ids2017_ann_deep_rep5/selected_ids2017_ann_deep_rep5_results.xlsx
2019-12-21 06:22:03,811 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-21 06:22:03,889 [INFO] Created directory: results_selected_models/selected_kdd99_ann_deep_rep1
2019-12-21 06:22:03,889 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ann_deep_rep1/run_log.log
2019-12-21 06:22:03,889 [INFO] ================= Running experiment no. 1  ================= 

2019-12-21 06:22:03,889 [INFO] Experiment parameters given below
2019-12-21 06:22:03,889 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 64], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ann_deep_rep1'}
2019-12-21 06:22:03,889 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ann_deep_rep1/tf_logs_run_2019_12_21-06_22_03
2019-12-21 06:22:03,889 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 06:22:03,906 [INFO] Reading X, y files
2019-12-21 06:22:03,906 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 06:22:12,512 [INFO] Reading complete. time_to_read=8.61 seconds
2019-12-21 06:22:12,512 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 06:22:14,722 [INFO] Reading complete. time_to_read=2.21 seconds
2019-12-21 06:22:14,723 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 06:22:15,385 [INFO] Reading complete. time_to_read=0.66 seconds
2019-12-21 06:22:15,385 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 06:22:15,810 [INFO] Reading complete. time_to_read=0.43 seconds
2019-12-21 06:22:15,810 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 06:22:15,928 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-21 06:22:15,928 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 06:22:15,974 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-21 06:23:10,567 [INFO] Initializing model
2019-12-21 06:23:14,479 [INFO] _________________________________________________________________
2019-12-21 06:23:14,482 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 06:23:14,483 [INFO] =================================================================
2019-12-21 06:23:14,484 [INFO] dense_26 (Dense)             (None, 64)                7936      
2019-12-21 06:23:14,485 [INFO] _________________________________________________________________
2019-12-21 06:23:14,485 [INFO] batch_normalization_21 (Batc (None, 64)                256       
2019-12-21 06:23:14,486 [INFO] _________________________________________________________________
2019-12-21 06:23:14,486 [INFO] dropout_21 (Dropout)         (None, 64)                0         
2019-12-21 06:23:14,487 [INFO] _________________________________________________________________
2019-12-21 06:23:14,487 [INFO] dense_27 (Dense)             (None, 32)                2080      
2019-12-21 06:23:14,488 [INFO] _________________________________________________________________
2019-12-21 06:23:14,489 [INFO] batch_normalization_22 (Batc (None, 32)                128       
2019-12-21 06:23:14,490 [INFO] _________________________________________________________________
2019-12-21 06:23:14,490 [INFO] dropout_22 (Dropout)         (None, 32)                0         
2019-12-21 06:23:14,491 [INFO] _________________________________________________________________
2019-12-21 06:23:14,492 [INFO] dense_28 (Dense)             (None, 64)                2112      
2019-12-21 06:23:14,492 [INFO] _________________________________________________________________
2019-12-21 06:23:14,493 [INFO] batch_normalization_23 (Batc (None, 64)                256       
2019-12-21 06:23:14,493 [INFO] _________________________________________________________________
2019-12-21 06:23:14,494 [INFO] dropout_23 (Dropout)         (None, 64)                0         
2019-12-21 06:23:14,495 [INFO] _________________________________________________________________
2019-12-21 06:23:14,495 [INFO] dense_29 (Dense)             (None, 5)                 325       
2019-12-21 06:23:14,496 [INFO] =================================================================
2019-12-21 06:23:14,514 [INFO] Total params: 13,093
2019-12-21 06:23:14,514 [INFO] Trainable params: 12,773
2019-12-21 06:23:14,515 [INFO] Non-trainable params: 320
2019-12-21 06:23:14,515 [INFO] _________________________________________________________________
2019-12-21 06:23:14,516 [INFO] Training model
 - val_f1: 0.9943
Epoch 00117: early stopping
Train on 3918744 samples, validate on 979687 samples
Epoch 1/300
 - 197s - loss: 0.0039 - val_loss: 5.6129e-04
 - val_f1: 0.9997
Epoch 2/300
 - 79s - loss: 6.8787e-04 - val_loss: 4.6393e-04
 - val_f1: 0.9997
Epoch 3/300
 - 79s - loss: 5.6918e-04 - val_loss: 4.3069e-04
 - val_f1: 0.9997
Epoch 4/300
 - 79s - loss: 5.1015e-04 - val_loss: 4.4866e-04
 - val_f1: 0.9997
Epoch 5/300
 - 79s - loss: 4.7909e-04 - val_loss: 3.7741e-04
 - val_f1: 0.9998
Epoch 6/300
 - 79s - loss: 4.3918e-04 - val_loss: 3.7419e-04
 - val_f1: 0.9997
Epoch 7/300
 - 79s - loss: 4.2566e-04 - val_loss: 3.9403e-04
 - val_f1: 0.9998
Epoch 8/300
 - 79s - loss: 3.9690e-04 - val_loss: 3.5744e-04
 - val_f1: 0.9998
Epoch 9/300
 - 79s - loss: 3.8919e-04 - val_loss: 3.4909e-04
 - val_f1: 0.9998
Epoch 10/300
 - 79s - loss: 3.7882e-04 - val_loss: 3.2149e-04
 - val_f1: 0.9998
Epoch 11/300
 - 79s - loss: 3.7363e-04 - val_loss: 3.4040e-04
 - val_f1: 0.9998
Epoch 12/300
 - 79s - loss: 3.5945e-04 - val_loss: 3.1143e-04
 - val_f1: 0.9998
Epoch 13/300
 - 79s - loss: 3.5010e-04 - val_loss: 2.8981e-04
 - val_f1: 0.9998
Epoch 14/300
 - 79s - loss: 3.3912e-04 - val_loss: 2.8555e-04
 - val_f1: 0.9998
Epoch 15/300
 - 79s - loss: 3.3711e-04 - val_loss: 3.0568e-04
 - val_f1: 0.9998
Epoch 16/300
 - 79s - loss: 3.2866e-04 - val_loss: 2.9110e-04
 - val_f1: 0.9998
Epoch 17/300
 - 79s - loss: 3.2695e-04 - val_loss: 3.0504e-04
 - val_f1: 0.9998
Epoch 18/300
 - 79s - loss: 3.1237e-04 - val_loss: 2.7155e-04
 - val_f1: 0.9998
Epoch 19/300
 - 79s - loss: 3.1227e-04 - val_loss: 3.1415e-04
 - val_f1: 0.9998
Epoch 20/300
 - 79s - loss: 3.1252e-04 - val_loss: 2.9402e-04
 - val_f1: 0.9998
Epoch 21/300
 - 79s - loss: 3.1129e-04 - val_loss: 2.9058e-04
 - val_f1: 0.9998
Epoch 22/300
 - 79s - loss: 3.0592e-04 - val_loss: 2.8304e-04
 - val_f1: 0.9998
Epoch 23/300
 - 79s - loss: 2.9403e-04 - val_loss: 2.5497e-04
 - val_f1: 0.9999
Epoch 24/300
 - 79s - loss: 2.9896e-04 - val_loss: 2.4597e-04
 - val_f1: 0.9998
Epoch 25/300
 - 79s - loss: 2.9427e-04 - val_loss: 2.6097e-04
 - val_f1: 0.9998
Epoch 26/300
 - 79s - loss: 2.7931e-04 - val_loss: 2.8230e-04
 - val_f1: 0.9998
Epoch 27/300
 - 79s - loss: 2.9417e-04 - val_loss: 2.7650e-04
 - val_f1: 0.9998
Epoch 28/300
 - 79s - loss: 2.8619e-04 - val_loss: 2.7384e-04
 - val_f1: 0.9999
Epoch 29/300
 - 79s - loss: 2.9265e-04 - val_loss: 2.8392e-04
 - val_f1: 0.9998
Epoch 30/300
 - 79s - loss: 2.8414e-04 - val_loss: 2.3910e-04
 - val_f1: 0.9999
Epoch 31/300
 - 79s - loss: 2.7679e-04 - val_loss: 2.7603e-04
2019-12-21 07:17:21,448 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 79s - loss: 2.7811e-04 - val_loss: 2.4459e-04
 - val_f1: 0.9999
Epoch 33/300
 - 79s - loss: 2.8059e-04 - val_loss: 2.5101e-04
 - val_f1: 0.9999
Epoch 34/300
 - 79s - loss: 2.6532e-04 - val_loss: 2.6127e-04
 - val_f1: 0.9998
Epoch 35/300
 - 79s - loss: 2.7040e-04 - val_loss: 2.8292e-04
 - val_f1: 0.9998
Epoch 36/300
 - 79s - loss: 2.7582e-04 - val_loss: 2.4549e-04
 - val_f1: 0.9999
Epoch 37/300
 - 79s - loss: 2.6797e-04 - val_loss: 2.5838e-04
 - val_f1: 0.9999
Epoch 38/300
 - 79s - loss: 2.5885e-04 - val_loss: 2.4752e-04
 - val_f1: 0.9999
Epoch 39/300
 - 79s - loss: 2.7433e-04 - val_loss: 2.4139e-04
 - val_f1: 0.9999
Epoch 40/300
 - 79s - loss: 2.6631e-04 - val_loss: 2.4137e-04
 - val_f1: 0.9999
Epoch 41/300
 - 79s - loss: 2.7330e-04 - val_loss: 2.4752e-04
 - val_f1: 0.9999
Epoch 42/300
 - 78s - loss: 2.6775e-04 - val_loss: 2.5282e-04
 - val_f1: 0.9998
Epoch 43/300
 - 79s - loss: 2.6486e-04 - val_loss: 2.7154e-04
 - val_f1: 0.9999
Epoch 44/300
 - 79s - loss: 2.6124e-04 - val_loss: 2.7063e-04
 - val_f1: 0.9998
Epoch 45/300
 - 79s - loss: 2.6059e-04 - val_loss: 2.7512e-04
 - val_f1: 0.9999
Epoch 46/300
 - 79s - loss: 2.4464e-04 - val_loss: 2.5462e-04
 - val_f1: 0.9999
Epoch 47/300
 - 79s - loss: 2.6705e-04 - val_loss: 2.5280e-04
 - val_f1: 0.9999
Epoch 48/300
 - 79s - loss: 2.5676e-04 - val_loss: 2.4476e-04
 - val_f1: 0.9999
Epoch 49/300
 - 79s - loss: 2.6471e-04 - val_loss: 2.4397e-04
 - val_f1: 0.9998
Epoch 50/300
 - 79s - loss: 2.7079e-04 - val_loss: 2.7140e-04
 - val_f1: 0.9999
Epoch 51/300
 - 79s - loss: 2.5999e-04 - val_loss: 2.9264e-04
 - val_f1: 0.9998
Epoch 52/300
 - 79s - loss: 2.5677e-04 - val_loss: 2.3679e-04
 - val_f1: 0.9999
Epoch 53/300
 - 79s - loss: 2.5700e-04 - val_loss: 2.4551e-04
 - val_f1: 0.9999
Epoch 54/300
 - 79s - loss: 2.4461e-04 - val_loss: 2.4562e-04
 - val_f1: 0.9999
Epoch 55/300
 - 79s - loss: 2.4751e-04 - val_loss: 2.1583e-04
 - val_f1: 0.9999
Epoch 56/300
 - 79s - loss: 2.6112e-04 - val_loss: 2.6280e-04
 - val_f1: 0.9998
Epoch 57/300
 - 79s - loss: 2.5974e-04 - val_loss: 2.2547e-04
 - val_f1: 0.9999
Epoch 58/300
 - 79s - loss: 2.5262e-04 - val_loss: 2.4241e-04
 - val_f1: 0.9999
Epoch 59/300
 - 79s - loss: 2.5007e-04 - val_loss: 2.5204e-04
 - val_f1: 0.9998
Epoch 60/300
 - 79s - loss: 2.5103e-04 - val_loss: 2.3959e-04
 - val_f1: 0.9999
Epoch 61/300
 - 79s - loss: 2.4453e-04 - val_loss: 2.4245e-04
2019-12-21 08:08:05,527 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9999
Epoch 62/300
 - 79s - loss: 2.5324e-04 - val_loss: 2.3549e-04
 - val_f1: 0.9999
Epoch 63/300
 - 79s - loss: 2.4808e-04 - val_loss: 2.5125e-04
 - val_f1: 0.9999
Epoch 64/300
 - 79s - loss: 2.3784e-04 - val_loss: 2.3394e-04
 - val_f1: 0.9999
Epoch 65/300
 - 79s - loss: 2.4301e-04 - val_loss: 2.3489e-04
 - val_f1: 0.9999
Epoch 66/300
 - 79s - loss: 2.4032e-04 - val_loss: 2.6131e-04
 - val_f1: 0.9998
Epoch 67/300
 - 79s - loss: 2.4181e-04 - val_loss: 2.5083e-04
 - val_f1: 0.9998
Epoch 68/300
 - 79s - loss: 2.4668e-04 - val_loss: 2.3864e-04
 - val_f1: 0.9999
Epoch 69/300
 - 79s - loss: 2.4649e-04 - val_loss: 2.5987e-04
 - val_f1: 0.9999
Epoch 70/300
 - 79s - loss: 2.4207e-04 - val_loss: 2.5099e-04
 - val_f1: 0.9998
Epoch 71/300
 - 79s - loss: 2.3881e-04 - val_loss: 2.4698e-04
 - val_f1: 0.9999
Epoch 72/300
 - 79s - loss: 2.4704e-04 - val_loss: 2.3244e-04
 - val_f1: 0.9999
Epoch 73/300
 - 79s - loss: 2.4791e-04 - val_loss: 2.5673e-04
 - val_f1: 0.9999
Epoch 74/300
 - 79s - loss: 2.3817e-04 - val_loss: 2.3025e-04
 - val_f1: 0.9999
Epoch 75/300
 - 79s - loss: 2.4022e-04 - val_loss: 3.0820e-04
 - val_f1: 0.9998
Epoch 76/300
 - 79s - loss: 2.3279e-04 - val_loss: 2.5099e-04
 - val_f1: 0.9999
Epoch 77/300
 - 79s - loss: 2.4249e-04 - val_loss: 2.4457e-04
 - val_f1: 0.9999
Epoch 78/300
 - 79s - loss: 2.3860e-04 - val_loss: 2.4742e-04
 - val_f1: 0.9999
Epoch 79/300
 - 79s - loss: 2.4008e-04 - val_loss: 2.4286e-04
 - val_f1: 0.9999
Epoch 80/300
 - 79s - loss: 2.4066e-04 - val_loss: 2.5925e-04
 - val_f1: 0.9998
Epoch 81/300
 - 79s - loss: 2.3883e-04 - val_loss: 2.5077e-04
 - val_f1: 0.9999
Epoch 82/300
 - 79s - loss: 2.3738e-04 - val_loss: 2.4370e-04
 - val_f1: 0.9998
Epoch 83/300
 - 79s - loss: 2.3795e-04 - val_loss: 3.0084e-04
 - val_f1: 0.9998
Epoch 84/300
 - 79s - loss: 2.4324e-04 - val_loss: 2.5623e-04
 - val_f1: 0.9999
Epoch 85/300
 - 79s - loss: 2.4208e-04 - val_loss: 2.4279e-04
 - val_f1: 0.9999
Epoch 86/300
 - 79s - loss: 2.3571e-04 - val_loss: 2.5383e-04
 - val_f1: 0.9999
Epoch 87/300
 - 79s - loss: 2.3270e-04 - val_loss: 2.5230e-04
 - val_f1: 0.9999
Epoch 88/300
 - 79s - loss: 2.3246e-04 - val_loss: 2.5927e-04
 - val_f1: 0.9999
Epoch 89/300
 - 79s - loss: 2.3690e-04 - val_loss: 2.5577e-04
 - val_f1: 0.9999
Epoch 90/300
 - 79s - loss: 2.3480e-04 - val_loss: 2.4428e-04
 - val_f1: 0.9999
Epoch 91/300
 - 79s - loss: 2.3412e-04 - val_loss: 2.5147e-04
2019-12-21 08:58:53,348 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9999
Epoch 92/300
 - 79s - loss: 2.3471e-04 - val_loss: 2.3121e-04
 - val_f1: 0.9998
Epoch 93/300
 - 79s - loss: 2.3084e-04 - val_loss: 2.2567e-04
 - val_f1: 0.9999
Epoch 94/300
 - 79s - loss: 2.2739e-04 - val_loss: 2.3174e-04
 - val_f1: 0.9999
Epoch 95/300
 - 79s - loss: 2.2879e-04 - val_loss: 2.4397e-04
 - val_f1: 0.9999
Epoch 96/300
 - 79s - loss: 2.3494e-04 - val_loss: 2.4258e-04
 - val_f1: 0.9999
Epoch 97/300
 - 79s - loss: 2.3537e-04 - val_loss: 2.3241e-04
 - val_f1: 0.9999
Epoch 98/300
 - 79s - loss: 2.2813e-04 - val_loss: 2.5230e-04
 - val_f1: 0.9999
Epoch 99/300
 - 79s - loss: 2.3712e-04 - val_loss: 2.3472e-04
 - val_f1: 0.9999
Epoch 100/300
 - 79s - loss: 2.2691e-04 - val_loss: 2.3603e-04
 - val_f1: 0.9999
Epoch 101/300
 - 79s - loss: 2.3528e-04 - val_loss: 2.4812e-04
 - val_f1: 0.9998
Epoch 102/300
 - 79s - loss: 2.3366e-04 - val_loss: 2.4472e-04
 - val_f1: 0.9999
Epoch 103/300
 - 79s - loss: 2.3517e-04 - val_loss: 2.2905e-04
 - val_f1: 0.9999
Epoch 104/300
 - 79s - loss: 2.3371e-04 - val_loss: 2.3863e-04
 - val_f1: 0.9999
Epoch 105/300
 - 79s - loss: 2.3757e-04 - val_loss: 2.5715e-04
2019-12-21 09:22:58,932 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 09:24:53,606 [INFO] Last epoch loss evaluation: train_loss = 0.000171, val_loss = 0.000216
2019-12-21 09:24:53,606 [INFO] Training complete. time_to_train = 10899.09 sec, 181.65 min
2019-12-21 09:24:53,613 [INFO] Model saved to results_selected_models/selected_kdd99_ann_deep_rep1/best_model.pickle
2019-12-21 09:24:54,190 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep1/training_error_history.png
2019-12-21 09:24:54,312 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep1/training_f1_history.png
2019-12-21 09:24:54,312 [INFO] Making predictions on training, validation, testing data
2019-12-21 09:26:51,929 [INFO] Evaluating predictions (results)
2019-12-21 09:26:56,606 [INFO] Dataset: Testing. Classification report below
2019-12-21 09:26:56,606 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.99      0.84     60593
       probe       0.79      0.81      0.80      4166
         r2l       0.94      0.03      0.05     13781
         u2r       0.78      0.01      0.01      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.85      0.56      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-21 09:26:56,607 [INFO] Overall accuracy (micro avg): 0.9237466602792666
2019-12-21 09:27:02,043 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9237         0.9237                       0.9237                0.0191                   0.0763  0.9237
1     Macro avg        0.9695         0.8475                       0.5606                0.0193                   0.4394  0.5371
2  Weighted avg        0.9682         0.9385                       0.9237                0.0203                   0.0763  0.9047
2019-12-21 09:27:18,404 [INFO] Dataset: Validation. Classification report below
2019-12-21 09:27:18,404 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.97      0.80      0.88       225
         u2r       0.50      0.30      0.37        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.89      0.82      0.85    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-21 09:27:18,404 [INFO] Overall accuracy (micro avg): 0.9998652630891295
2019-12-21 09:27:36,994 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.8931                       0.8189                0.0000                   0.1811  0.8494
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 09:28:49,047 [INFO] Dataset: Training. Classification report below
2019-12-21 09:28:49,047 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      1.00      1.00     32881
         r2l       0.97      0.86      0.91       901
         u2r       0.96      0.60      0.74        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.99      0.89      0.93   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-21 09:28:49,047 [INFO] Overall accuracy (micro avg): 0.9998925676186043
2019-12-21 09:30:10,947 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9862                       0.8906                0.0000                   0.1094  0.9291
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 09:30:11,023 [INFO] Results saved to: results_selected_models/selected_kdd99_ann_deep_rep1/selected_kdd99_ann_deep_rep1_results.xlsx
2019-12-21 09:30:11,034 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-21 09:30:11,312 [INFO] Created directory: results_selected_models/selected_kdd99_ann_deep_rep2
2019-12-21 09:30:11,326 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ann_deep_rep2/run_log.log
2019-12-21 09:30:11,326 [INFO] ================= Running experiment no. 2  ================= 

2019-12-21 09:30:11,326 [INFO] Experiment parameters given below
2019-12-21 09:30:11,326 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_kdd99_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 65], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ann_deep_rep2'}
2019-12-21 09:30:11,326 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ann_deep_rep2/tf_logs_run_2019_12_21-09_30_11
2019-12-21 09:30:11,326 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 09:30:11,334 [INFO] Reading X, y files
2019-12-21 09:30:11,335 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 09:30:20,403 [INFO] Reading complete. time_to_read=9.07 seconds
2019-12-21 09:30:20,403 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 09:30:22,568 [INFO] Reading complete. time_to_read=2.17 seconds
2019-12-21 09:30:22,572 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 09:30:23,249 [INFO] Reading complete. time_to_read=0.68 seconds
2019-12-21 09:30:23,249 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 09:30:23,707 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-21 09:30:23,707 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 09:30:23,830 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-21 09:30:23,830 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 09:30:23,885 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-21 09:31:13,019 [INFO] Initializing model
2019-12-21 09:31:15,256 [INFO] _________________________________________________________________
2019-12-21 09:31:15,258 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 09:31:15,259 [INFO] =================================================================
2019-12-21 09:31:15,261 [INFO] dense_30 (Dense)             (None, 64)                7936      
2019-12-21 09:31:15,262 [INFO] _________________________________________________________________
2019-12-21 09:31:15,263 [INFO] batch_normalization_24 (Batc (None, 64)                256       
2019-12-21 09:31:15,264 [INFO] _________________________________________________________________
2019-12-21 09:31:15,265 [INFO] dropout_24 (Dropout)         (None, 64)                0         
2019-12-21 09:31:15,266 [INFO] _________________________________________________________________
2019-12-21 09:31:15,267 [INFO] dense_31 (Dense)             (None, 32)                2080      
2019-12-21 09:31:15,268 [INFO] _________________________________________________________________
2019-12-21 09:31:15,269 [INFO] batch_normalization_25 (Batc (None, 32)                128       
2019-12-21 09:31:15,270 [INFO] _________________________________________________________________
2019-12-21 09:31:15,271 [INFO] dropout_25 (Dropout)         (None, 32)                0         
2019-12-21 09:31:15,272 [INFO] _________________________________________________________________
2019-12-21 09:31:15,273 [INFO] dense_32 (Dense)             (None, 65)                2145      
2019-12-21 09:31:15,274 [INFO] _________________________________________________________________
2019-12-21 09:31:15,275 [INFO] batch_normalization_26 (Batc (None, 65)                260       
2019-12-21 09:31:15,276 [INFO] _________________________________________________________________
2019-12-21 09:31:15,277 [INFO] dropout_26 (Dropout)         (None, 65)                0         
2019-12-21 09:31:15,277 [INFO] _________________________________________________________________
2019-12-21 09:31:15,278 [INFO] dense_33 (Dense)             (None, 5)                 330       
2019-12-21 09:31:15,280 [INFO] =================================================================
2019-12-21 09:31:15,281 [INFO] Total params: 13,135
2019-12-21 09:31:15,282 [INFO] Trainable params: 12,813
2019-12-21 09:31:15,283 [INFO] Non-trainable params: 322
2019-12-21 09:31:15,284 [INFO] _________________________________________________________________
2019-12-21 09:31:15,285 [INFO] Training model
 - val_f1: 0.9999
Epoch 00105: early stopping
Train on 3918744 samples, validate on 979687 samples
Epoch 1/300
 - 199s - loss: 0.0037 - val_loss: 6.1322e-04
 - val_f1: 0.9997
Epoch 2/300
 - 80s - loss: 7.1749e-04 - val_loss: 4.7719e-04
 - val_f1: 0.9997
Epoch 3/300
 - 81s - loss: 5.6002e-04 - val_loss: 4.4590e-04
 - val_f1: 0.9997
Epoch 4/300
 - 81s - loss: 5.0563e-04 - val_loss: 4.3664e-04
 - val_f1: 0.9997
Epoch 5/300
 - 81s - loss: 4.5164e-04 - val_loss: 3.9579e-04
 - val_f1: 0.9997
Epoch 6/300
 - 81s - loss: 4.3848e-04 - val_loss: 3.9126e-04
 - val_f1: 0.9998
Epoch 7/300
 - 81s - loss: 4.2076e-04 - val_loss: 3.6199e-04
 - val_f1: 0.9998
Epoch 8/300
 - 81s - loss: 4.1424e-04 - val_loss: 3.5588e-04
 - val_f1: 0.9998
Epoch 9/300
 - 81s - loss: 3.8776e-04 - val_loss: 3.3215e-04
 - val_f1: 0.9998
Epoch 10/300
 - 81s - loss: 3.8035e-04 - val_loss: 3.2995e-04
 - val_f1: 0.9998
Epoch 11/300
 - 81s - loss: 3.6697e-04 - val_loss: 3.2197e-04
 - val_f1: 0.9998
Epoch 12/300
 - 81s - loss: 3.5887e-04 - val_loss: 3.2727e-04
 - val_f1: 0.9998
Epoch 13/300
 - 81s - loss: 3.5048e-04 - val_loss: 3.3541e-04
 - val_f1: 0.9998
Epoch 14/300
 - 81s - loss: 3.3127e-04 - val_loss: 3.1057e-04
 - val_f1: 0.9998
Epoch 15/300
 - 81s - loss: 3.4247e-04 - val_loss: 3.0292e-04
 - val_f1: 0.9998
Epoch 16/300
 - 81s - loss: 3.3714e-04 - val_loss: 3.1944e-04
 - val_f1: 0.9998
Epoch 17/300
 - 81s - loss: 3.2542e-04 - val_loss: 3.0239e-04
 - val_f1: 0.9998
Epoch 18/300
 - 81s - loss: 3.1756e-04 - val_loss: 2.8862e-04
 - val_f1: 0.9998
Epoch 19/300
 - 81s - loss: 3.2334e-04 - val_loss: 2.8685e-04
 - val_f1: 0.9998
Epoch 20/300
 - 81s - loss: 3.0592e-04 - val_loss: 3.1967e-04
 - val_f1: 0.9998
Epoch 21/300
 - 81s - loss: 3.1455e-04 - val_loss: 2.8253e-04
 - val_f1: 0.9998
Epoch 22/300
 - 81s - loss: 3.0822e-04 - val_loss: 2.8620e-04
 - val_f1: 0.9998
Epoch 23/300
 - 81s - loss: 3.0241e-04 - val_loss: 2.9838e-04
 - val_f1: 0.9998
Epoch 24/300
 - 81s - loss: 2.9637e-04 - val_loss: 2.6383e-04
 - val_f1: 0.9998
Epoch 25/300
 - 81s - loss: 3.0238e-04 - val_loss: 3.0614e-04
 - val_f1: 0.9998
Epoch 26/300
 - 81s - loss: 2.8919e-04 - val_loss: 2.7584e-04
 - val_f1: 0.9998
Epoch 27/300
 - 81s - loss: 2.9277e-04 - val_loss: 2.5740e-04
 - val_f1: 0.9999
Epoch 28/300
 - 81s - loss: 2.9501e-04 - val_loss: 2.8432e-04
 - val_f1: 0.9998
Epoch 29/300
 - 81s - loss: 2.7905e-04 - val_loss: 2.8243e-04
 - val_f1: 0.9998
Epoch 30/300
 - 81s - loss: 2.7204e-04 - val_loss: 2.9072e-04
 - val_f1: 0.9999
Epoch 31/300
 - 81s - loss: 2.8119e-04 - val_loss: 3.1683e-04
2019-12-21 10:27:21,942 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 81s - loss: 2.7508e-04 - val_loss: 2.6170e-04
 - val_f1: 0.9999
Epoch 33/300
 - 81s - loss: 2.7622e-04 - val_loss: 2.7068e-04
 - val_f1: 0.9998
Epoch 34/300
 - 80s - loss: 2.7881e-04 - val_loss: 2.9049e-04
 - val_f1: 0.9998
Epoch 35/300
 - 81s - loss: 2.6673e-04 - val_loss: 2.7937e-04
 - val_f1: 0.9998
Epoch 36/300
 - 81s - loss: 2.7339e-04 - val_loss: 2.9428e-04
 - val_f1: 0.9998
Epoch 37/300
 - 81s - loss: 2.7446e-04 - val_loss: 2.9661e-04
 - val_f1: 0.9998
Epoch 38/300
 - 81s - loss: 2.6550e-04 - val_loss: 3.1276e-04
 - val_f1: 0.9998
Epoch 39/300
 - 81s - loss: 2.7228e-04 - val_loss: 2.7078e-04
 - val_f1: 0.9998
Epoch 40/300
 - 81s - loss: 2.7461e-04 - val_loss: 2.5987e-04
 - val_f1: 0.9999
Epoch 41/300
 - 81s - loss: 2.7362e-04 - val_loss: 3.1730e-04
 - val_f1: 0.9998
Epoch 42/300
 - 80s - loss: 2.6537e-04 - val_loss: 2.8386e-04
 - val_f1: 0.9998
Epoch 43/300
 - 81s - loss: 2.6058e-04 - val_loss: 2.8413e-04
 - val_f1: 0.9998
Epoch 44/300
 - 80s - loss: 2.6569e-04 - val_loss: 2.5662e-04
 - val_f1: 0.9999
Epoch 45/300
 - 81s - loss: 2.6186e-04 - val_loss: 2.4581e-04
 - val_f1: 0.9999
Epoch 46/300
 - 81s - loss: 2.6764e-04 - val_loss: 2.7214e-04
 - val_f1: 0.9999
Epoch 47/300
 - 81s - loss: 2.6360e-04 - val_loss: 2.6469e-04
 - val_f1: 0.9998
Epoch 48/300
 - 81s - loss: 2.5015e-04 - val_loss: 2.8021e-04
 - val_f1: 0.9998
Epoch 49/300
 - 81s - loss: 2.5579e-04 - val_loss: 2.6624e-04
 - val_f1: 0.9999
Epoch 50/300
 - 81s - loss: 2.5981e-04 - val_loss: 2.9327e-04
 - val_f1: 0.9999
Epoch 51/300
 - 81s - loss: 2.5834e-04 - val_loss: 2.7578e-04
 - val_f1: 0.9998
Epoch 52/300
 - 81s - loss: 2.6171e-04 - val_loss: 2.6712e-04
 - val_f1: 0.9999
Epoch 53/300
 - 81s - loss: 2.5766e-04 - val_loss: 2.7389e-04
 - val_f1: 0.9999
Epoch 54/300
 - 81s - loss: 2.6092e-04 - val_loss: 2.6859e-04
 - val_f1: 0.9999
Epoch 55/300
 - 81s - loss: 2.5169e-04 - val_loss: 2.5556e-04
 - val_f1: 0.9999
Epoch 56/300
 - 81s - loss: 2.6104e-04 - val_loss: 2.6625e-04
 - val_f1: 0.9998
Epoch 57/300
 - 81s - loss: 2.5860e-04 - val_loss: 2.6202e-04
 - val_f1: 0.9998
Epoch 58/300
 - 81s - loss: 2.4610e-04 - val_loss: 2.6724e-04
 - val_f1: 0.9998
Epoch 59/300
 - 81s - loss: 2.5720e-04 - val_loss: 2.7298e-04
 - val_f1: 0.9999
Epoch 60/300
 - 81s - loss: 2.4935e-04 - val_loss: 3.1601e-04
 - val_f1: 0.9998
Epoch 61/300
 - 81s - loss: 2.5429e-04 - val_loss: 2.4956e-04
2019-12-21 11:19:56,510 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 81s - loss: 2.4262e-04 - val_loss: 2.8340e-04
 - val_f1: 0.9998
Epoch 63/300
 - 81s - loss: 2.4331e-04 - val_loss: 2.7902e-04
 - val_f1: 0.9998
Epoch 64/300
 - 81s - loss: 2.4467e-04 - val_loss: 2.9411e-04
 - val_f1: 0.9998
Epoch 65/300
 - 81s - loss: 2.5241e-04 - val_loss: 3.1326e-04
 - val_f1: 0.9999
Epoch 66/300
 - 81s - loss: 2.4086e-04 - val_loss: 3.3994e-04
 - val_f1: 0.9998
Epoch 67/300
 - 81s - loss: 2.4037e-04 - val_loss: 3.2570e-04
 - val_f1: 0.9998
Epoch 68/300
 - 81s - loss: 2.4610e-04 - val_loss: 2.7853e-04
 - val_f1: 0.9999
Epoch 69/300
 - 81s - loss: 2.4293e-04 - val_loss: 2.7989e-04
 - val_f1: 0.9999
Epoch 70/300
 - 81s - loss: 2.5411e-04 - val_loss: 3.7725e-04
 - val_f1: 0.9998
Epoch 71/300
 - 81s - loss: 2.4436e-04 - val_loss: 2.6714e-04
 - val_f1: 0.9999
Epoch 72/300
 - 81s - loss: 2.4363e-04 - val_loss: 2.6542e-04
 - val_f1: 0.9999
Epoch 73/300
 - 81s - loss: 2.3737e-04 - val_loss: 3.5337e-04
 - val_f1: 0.9998
Epoch 74/300
 - 81s - loss: 2.4550e-04 - val_loss: 2.9612e-04
 - val_f1: 0.9998
Epoch 75/300
 - 81s - loss: 2.3799e-04 - val_loss: 3.0316e-04
 - val_f1: 0.9998
Epoch 76/300
 - 81s - loss: 2.3845e-04 - val_loss: 2.7285e-04
 - val_f1: 0.9999
Epoch 77/300
 - 81s - loss: 2.2608e-04 - val_loss: 2.8739e-04
 - val_f1: 0.9999
Epoch 78/300
 - 80s - loss: 2.3993e-04 - val_loss: 2.6316e-04
 - val_f1: 0.9999
Epoch 79/300
 - 81s - loss: 2.4408e-04 - val_loss: 2.5381e-04
 - val_f1: 0.9999
Epoch 80/300
 - 81s - loss: 2.3906e-04 - val_loss: 2.6105e-04
 - val_f1: 0.9999
Epoch 81/300
 - 81s - loss: 2.4058e-04 - val_loss: 2.5096e-04
 - val_f1: 0.9999
Epoch 82/300
 - 81s - loss: 2.4679e-04 - val_loss: 2.7883e-04
 - val_f1: 0.9998
Epoch 83/300
 - 81s - loss: 2.4218e-04 - val_loss: 2.6618e-04
 - val_f1: 0.9999
Epoch 84/300
 - 81s - loss: 2.3755e-04 - val_loss: 2.6003e-04
 - val_f1: 0.9999
Epoch 85/300
 - 81s - loss: 2.4099e-04 - val_loss: 2.6006e-04
 - val_f1: 0.9999
Epoch 86/300
 - 81s - loss: 2.3113e-04 - val_loss: 2.7674e-04
 - val_f1: 0.9999
Epoch 87/300
 - 81s - loss: 2.3898e-04 - val_loss: 2.4750e-04
 - val_f1: 0.9999
Epoch 88/300
 - 81s - loss: 2.3903e-04 - val_loss: 2.7473e-04
 - val_f1: 0.9998
Epoch 89/300
 - 81s - loss: 2.4211e-04 - val_loss: 2.4396e-04
 - val_f1: 0.9999
Epoch 90/300
 - 81s - loss: 2.3858e-04 - val_loss: 2.9676e-04
 - val_f1: 0.9998
Epoch 91/300
 - 81s - loss: 2.3551e-04 - val_loss: 2.8010e-04
2019-12-21 12:12:36,149 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 81s - loss: 2.2876e-04 - val_loss: 2.7832e-04
 - val_f1: 0.9999
Epoch 93/300
 - 81s - loss: 2.3107e-04 - val_loss: 2.5117e-04
 - val_f1: 0.9999
Epoch 94/300
 - 81s - loss: 2.3357e-04 - val_loss: 2.5776e-04
 - val_f1: 0.9999
Epoch 95/300
 - 81s - loss: 2.3086e-04 - val_loss: 2.9337e-04
 - val_f1: 0.9998
Epoch 96/300
 - 80s - loss: 2.3871e-04 - val_loss: 2.6759e-04
 - val_f1: 0.9999
Epoch 97/300
 - 81s - loss: 2.3226e-04 - val_loss: 2.9021e-04
 - val_f1: 0.9999
Epoch 98/300
 - 81s - loss: 2.3730e-04 - val_loss: 3.3295e-04
 - val_f1: 0.9998
Epoch 99/300
 - 81s - loss: 2.3302e-04 - val_loss: 3.0656e-04
 - val_f1: 0.9999
Epoch 100/300
 - 81s - loss: 2.3613e-04 - val_loss: 2.7692e-04
 - val_f1: 0.9999
Epoch 101/300
 - 81s - loss: 2.3239e-04 - val_loss: 2.8938e-04
 - val_f1: 0.9999
Epoch 102/300
 - 81s - loss: 2.3184e-04 - val_loss: 4.2505e-04
 - val_f1: 0.9998
Epoch 103/300
 - 81s - loss: 2.2687e-04 - val_loss: 3.0524e-04
 - val_f1: 0.9999
Epoch 104/300
 - 81s - loss: 2.2735e-04 - val_loss: 2.8465e-04
 - val_f1: 0.9999
Epoch 105/300
 - 81s - loss: 2.2383e-04 - val_loss: 2.9391e-04
 - val_f1: 0.9998
Epoch 106/300
 - 81s - loss: 2.3517e-04 - val_loss: 8.2023e-04
 - val_f1: 0.9995
Epoch 107/300
 - 81s - loss: 2.3111e-04 - val_loss: 3.0804e-04
 - val_f1: 0.9999
Epoch 108/300
 - 81s - loss: 2.3365e-04 - val_loss: 2.9096e-04
 - val_f1: 0.9999
Epoch 109/300
 - 81s - loss: 2.2609e-04 - val_loss: 2.9451e-04
 - val_f1: 0.9999
Epoch 110/300
 - 81s - loss: 2.3465e-04 - val_loss: 2.8222e-04
 - val_f1: 0.9999
Epoch 111/300
 - 81s - loss: 2.3800e-04 - val_loss: 2.9029e-04
 - val_f1: 0.9999
Epoch 112/300
 - 81s - loss: 2.3237e-04 - val_loss: 2.8971e-04
 - val_f1: 0.9999
Epoch 113/300
 - 81s - loss: 2.3799e-04 - val_loss: 2.5046e-04
 - val_f1: 0.9999
Epoch 114/300
 - 81s - loss: 2.3091e-04 - val_loss: 2.6649e-04
 - val_f1: 0.9999
Epoch 115/300
 - 81s - loss: 2.3297e-04 - val_loss: 2.9282e-04
 - val_f1: 0.9999
Epoch 116/300
 - 81s - loss: 2.3497e-04 - val_loss: 2.6524e-04
 - val_f1: 0.9999
Epoch 117/300
 - 81s - loss: 2.2899e-04 - val_loss: 2.8318e-04
 - val_f1: 0.9998
Epoch 118/300
 - 81s - loss: 2.2828e-04 - val_loss: 2.7027e-04
 - val_f1: 0.9999
Epoch 119/300
 - 81s - loss: 2.2961e-04 - val_loss: 2.7412e-04
 - val_f1: 0.9999
Epoch 120/300
 - 80s - loss: 2.1834e-04 - val_loss: 2.6762e-04
 - val_f1: 0.9999
Epoch 121/300
 - 81s - loss: 2.2675e-04 - val_loss: 2.6966e-04
2019-12-21 13:05:14,925 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9999
Epoch 122/300
 - 81s - loss: 2.3295e-04 - val_loss: 2.7133e-04
 - val_f1: 0.9999
Epoch 123/300
 - 81s - loss: 2.2223e-04 - val_loss: 2.5949e-04
 - val_f1: 0.9999
Epoch 124/300
 - 81s - loss: 2.1775e-04 - val_loss: 2.9440e-04
 - val_f1: 0.9999
Epoch 125/300
 - 81s - loss: 2.2438e-04 - val_loss: 2.7268e-04
 - val_f1: 0.9999
Epoch 126/300
 - 81s - loss: 2.2007e-04 - val_loss: 3.8428e-04
 - val_f1: 0.9998
Epoch 127/300
 - 81s - loss: 2.2427e-04 - val_loss: 2.5137e-04
 - val_f1: 0.9999
Epoch 128/300
 - 81s - loss: 2.2812e-04 - val_loss: 2.6589e-04
 - val_f1: 0.9999
Epoch 129/300
 - 81s - loss: 2.1560e-04 - val_loss: 2.7536e-04
 - val_f1: 0.9999
Epoch 130/300
 - 81s - loss: 2.2763e-04 - val_loss: 3.7816e-04
 - val_f1: 0.9998
Epoch 131/300
 - 81s - loss: 2.2762e-04 - val_loss: 2.8107e-04
 - val_f1: 0.9999
Epoch 132/300
 - 81s - loss: 2.1781e-04 - val_loss: 2.9029e-04
 - val_f1: 0.9998
Epoch 133/300
 - 81s - loss: 2.1576e-04 - val_loss: 2.6546e-04
 - val_f1: 0.9998
Epoch 134/300
 - 81s - loss: 2.1692e-04 - val_loss: 2.4557e-04
 - val_f1: 0.9999
Epoch 135/300
 - 81s - loss: 2.3064e-04 - val_loss: 2.6633e-04
 - val_f1: 0.9999
Epoch 136/300
 - 81s - loss: 2.2355e-04 - val_loss: 2.6706e-04
 - val_f1: 0.9999
Epoch 137/300
 - 81s - loss: 2.2371e-04 - val_loss: 2.6715e-04
 - val_f1: 0.9999
Epoch 138/300
 - 81s - loss: 2.3339e-04 - val_loss: 2.8418e-04
 - val_f1: 0.9999
Epoch 139/300
 - 81s - loss: 2.1719e-04 - val_loss: 2.9381e-04
2019-12-21 13:37:16,175 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 13:39:20,261 [INFO] Last epoch loss evaluation: train_loss = 0.000178, val_loss = 0.000244
2019-12-21 13:39:20,261 [INFO] Training complete. time_to_train = 14884.98 sec, 248.08 min
2019-12-21 13:39:20,268 [INFO] Model saved to results_selected_models/selected_kdd99_ann_deep_rep2/best_model.pickle
2019-12-21 13:39:20,698 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep2/training_error_history.png
2019-12-21 13:39:20,836 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep2/training_f1_history.png
2019-12-21 13:39:20,836 [INFO] Making predictions on training, validation, testing data
2019-12-21 13:41:28,688 [INFO] Evaluating predictions (results)
2019-12-21 13:41:33,345 [INFO] Dataset: Testing. Classification report below
2019-12-21 13:41:33,345 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      1.00      0.84     60593
       probe       0.90      0.81      0.85      4166
         r2l       0.98      0.03      0.05     13781
         u2r       0.84      0.01      0.02      2636

   micro avg       0.93      0.93      0.93    311029
   macro avg       0.89      0.56      0.55    311029
weighted avg       0.94      0.93      0.91    311029

2019-12-21 13:41:33,345 [INFO] Overall accuracy (micro avg): 0.925113092348302
2019-12-21 13:41:38,718 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9251         0.9251                       0.9251                0.0187                   0.0749  0.9251
1     Macro avg        0.9700         0.8901                       0.5620                0.0190                   0.4380  0.5494
2  Weighted avg        0.9683         0.9424                       0.9251                0.0203                   0.0749  0.9061
2019-12-21 13:41:55,087 [INFO] Dataset: Validation. Classification report below
2019-12-21 13:41:55,087 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.92      0.90      0.91       225
         u2r       0.50      0.40      0.44        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.88      0.86      0.87    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-21 13:41:55,087 [INFO] Overall accuracy (micro avg): 0.9998642423549562
2019-12-21 13:42:13,707 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.8832                       0.8584                0.0000                   0.1416  0.8697
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 13:43:25,659 [INFO] Dataset: Training. Classification report below
2019-12-21 13:43:25,659 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      1.00      1.00     32881
         r2l       0.90      0.93      0.92       901
         u2r       0.88      0.52      0.66        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.96      0.89      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-21 13:43:25,659 [INFO] Overall accuracy (micro avg): 0.9998882294939399
2019-12-21 13:44:47,478 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9561                       0.8900                0.0000                   0.1100  0.9140
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 13:44:47,509 [INFO] Results saved to: results_selected_models/selected_kdd99_ann_deep_rep2/selected_kdd99_ann_deep_rep2_results.xlsx
2019-12-21 13:44:47,517 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-21 13:44:47,791 [INFO] Created directory: results_selected_models/selected_kdd99_ann_deep_rep3
2019-12-21 13:44:47,792 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ann_deep_rep3/run_log.log
2019-12-21 13:44:47,792 [INFO] ================= Running experiment no. 3  ================= 

2019-12-21 13:44:47,792 [INFO] Experiment parameters given below
2019-12-21 13:44:47,792 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_kdd99_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 66], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ann_deep_rep3'}
2019-12-21 13:44:47,792 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ann_deep_rep3/tf_logs_run_2019_12_21-13_44_47
2019-12-21 13:44:47,792 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 13:44:47,804 [INFO] Reading X, y files
2019-12-21 13:44:47,804 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 13:44:56,938 [INFO] Reading complete. time_to_read=9.13 seconds
2019-12-21 13:44:56,939 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 13:44:59,180 [INFO] Reading complete. time_to_read=2.24 seconds
2019-12-21 13:44:59,180 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 13:44:59,850 [INFO] Reading complete. time_to_read=0.67 seconds
2019-12-21 13:44:59,850 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 13:45:00,379 [INFO] Reading complete. time_to_read=0.53 seconds
2019-12-21 13:45:00,379 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 13:45:00,501 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-21 13:45:00,501 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 13:45:00,548 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-21 13:45:47,891 [INFO] Initializing model
2019-12-21 13:45:50,270 [INFO] _________________________________________________________________
2019-12-21 13:45:50,272 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 13:45:50,273 [INFO] =================================================================
2019-12-21 13:45:50,275 [INFO] dense_34 (Dense)             (None, 64)                7936      
2019-12-21 13:45:50,277 [INFO] _________________________________________________________________
2019-12-21 13:45:50,278 [INFO] batch_normalization_27 (Batc (None, 64)                256       
2019-12-21 13:45:50,279 [INFO] _________________________________________________________________
2019-12-21 13:45:50,280 [INFO] dropout_27 (Dropout)         (None, 64)                0         
2019-12-21 13:45:50,280 [INFO] _________________________________________________________________
2019-12-21 13:45:50,282 [INFO] dense_35 (Dense)             (None, 32)                2080      
2019-12-21 13:45:50,283 [INFO] _________________________________________________________________
2019-12-21 13:45:50,283 [INFO] batch_normalization_28 (Batc (None, 32)                128       
2019-12-21 13:45:50,285 [INFO] _________________________________________________________________
2019-12-21 13:45:50,286 [INFO] dropout_28 (Dropout)         (None, 32)                0         
2019-12-21 13:45:50,287 [INFO] _________________________________________________________________
2019-12-21 13:45:50,288 [INFO] dense_36 (Dense)             (None, 66)                2178      
2019-12-21 13:45:50,289 [INFO] _________________________________________________________________
2019-12-21 13:45:50,290 [INFO] batch_normalization_29 (Batc (None, 66)                264       
2019-12-21 13:45:50,291 [INFO] _________________________________________________________________
2019-12-21 13:45:50,292 [INFO] dropout_29 (Dropout)         (None, 66)                0         
2019-12-21 13:45:50,293 [INFO] _________________________________________________________________
2019-12-21 13:45:50,294 [INFO] dense_37 (Dense)             (None, 5)                 335       
2019-12-21 13:45:50,295 [INFO] =================================================================
2019-12-21 13:45:50,297 [INFO] Total params: 13,177
2019-12-21 13:45:50,298 [INFO] Trainable params: 12,853
2019-12-21 13:45:50,299 [INFO] Non-trainable params: 324
2019-12-21 13:45:50,300 [INFO] _________________________________________________________________
2019-12-21 13:45:50,301 [INFO] Training model
 - val_f1: 0.9999
Epoch 00139: early stopping
Train on 3918744 samples, validate on 979687 samples
Epoch 1/300
 - 202s - loss: 0.0040 - val_loss: 5.9460e-04
 - val_f1: 0.9996
Epoch 2/300
 - 81s - loss: 6.9259e-04 - val_loss: 5.2332e-04
 - val_f1: 0.9997
Epoch 3/300
 - 81s - loss: 5.7498e-04 - val_loss: 4.6579e-04
 - val_f1: 0.9997
Epoch 4/300
 - 81s - loss: 5.1433e-04 - val_loss: 4.2569e-04
 - val_f1: 0.9997
Epoch 5/300
 - 82s - loss: 4.7915e-04 - val_loss: 3.7705e-04
 - val_f1: 0.9998
Epoch 6/300
 - 81s - loss: 4.4124e-04 - val_loss: 4.1016e-04
 - val_f1: 0.9997
Epoch 7/300
 - 81s - loss: 4.1655e-04 - val_loss: 3.4932e-04
 - val_f1: 0.9998
Epoch 8/300
 - 81s - loss: 4.0187e-04 - val_loss: 3.2197e-04
 - val_f1: 0.9998
Epoch 9/300
 - 81s - loss: 3.8807e-04 - val_loss: 3.2502e-04
 - val_f1: 0.9998
Epoch 10/300
 - 81s - loss: 3.8284e-04 - val_loss: 3.2696e-04
 - val_f1: 0.9998
Epoch 11/300
 - 81s - loss: 3.7382e-04 - val_loss: 3.3747e-04
 - val_f1: 0.9998
Epoch 12/300
 - 81s - loss: 3.5968e-04 - val_loss: 3.3209e-04
 - val_f1: 0.9998
Epoch 13/300
 - 82s - loss: 3.6106e-04 - val_loss: 3.1521e-04
 - val_f1: 0.9998
Epoch 14/300
 - 81s - loss: 3.4324e-04 - val_loss: 3.2606e-04
 - val_f1: 0.9998
Epoch 15/300
 - 82s - loss: 3.3636e-04 - val_loss: 3.2408e-04
 - val_f1: 0.9998
Epoch 16/300
 - 81s - loss: 3.2807e-04 - val_loss: 3.3903e-04
 - val_f1: 0.9998
Epoch 17/300
 - 82s - loss: 3.2020e-04 - val_loss: 3.0543e-04
 - val_f1: 0.9998
Epoch 18/300
 - 80s - loss: 3.2003e-04 - val_loss: 3.2684e-04
 - val_f1: 0.9998
Epoch 19/300
 - 81s - loss: 3.1559e-04 - val_loss: 3.1457e-04
 - val_f1: 0.9998
Epoch 20/300
 - 81s - loss: 3.1260e-04 - val_loss: 2.9564e-04
 - val_f1: 0.9998
Epoch 21/300
 - 82s - loss: 3.2214e-04 - val_loss: 2.8912e-04
 - val_f1: 0.9998
Epoch 22/300
 - 81s - loss: 3.0350e-04 - val_loss: 3.2889e-04
 - val_f1: 0.9998
Epoch 23/300
 - 82s - loss: 3.0747e-04 - val_loss: 2.8547e-04
 - val_f1: 0.9998
Epoch 24/300
 - 81s - loss: 2.9503e-04 - val_loss: 3.1670e-04
 - val_f1: 0.9998
Epoch 25/300
 - 82s - loss: 2.9139e-04 - val_loss: 3.1353e-04
 - val_f1: 0.9998
Epoch 26/300
 - 81s - loss: 2.8913e-04 - val_loss: 2.9545e-04
 - val_f1: 0.9998
Epoch 27/300
 - 82s - loss: 2.9758e-04 - val_loss: 2.8086e-04
 - val_f1: 0.9999
Epoch 28/300
 - 81s - loss: 3.0452e-04 - val_loss: 3.1691e-04
 - val_f1: 0.9998
Epoch 29/300
 - 82s - loss: 2.9101e-04 - val_loss: 3.0265e-04
 - val_f1: 0.9999
Epoch 30/300
 - 81s - loss: 2.9288e-04 - val_loss: 3.2354e-04
 - val_f1: 0.9998
Epoch 31/300
 - 82s - loss: 2.9642e-04 - val_loss: 2.7046e-04
2019-12-21 14:42:32,704 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9999
Epoch 32/300
 - 81s - loss: 2.9487e-04 - val_loss: 2.8264e-04
 - val_f1: 0.9998
Epoch 33/300
 - 82s - loss: 2.8358e-04 - val_loss: 3.6085e-04
 - val_f1: 0.9998
Epoch 34/300
 - 81s - loss: 2.7687e-04 - val_loss: 2.8000e-04
 - val_f1: 0.9998
Epoch 35/300
 - 82s - loss: 2.8363e-04 - val_loss: 2.5701e-04
 - val_f1: 0.9999
Epoch 36/300
 - 81s - loss: 2.8920e-04 - val_loss: 2.6349e-04
 - val_f1: 0.9999
Epoch 37/300
 - 82s - loss: 2.7989e-04 - val_loss: 2.7696e-04
 - val_f1: 0.9998
Epoch 38/300
 - 81s - loss: 2.8664e-04 - val_loss: 2.7665e-04
 - val_f1: 0.9998
Epoch 39/300
 - 82s - loss: 2.7180e-04 - val_loss: 2.8826e-04
 - val_f1: 0.9998
Epoch 40/300
 - 81s - loss: 2.7435e-04 - val_loss: 3.1284e-04
 - val_f1: 0.9998
Epoch 41/300
 - 82s - loss: 2.7344e-04 - val_loss: 2.6972e-04
 - val_f1: 0.9998
Epoch 42/300
 - 81s - loss: 2.7233e-04 - val_loss: 2.6640e-04
 - val_f1: 0.9998
Epoch 43/300
 - 82s - loss: 2.6752e-04 - val_loss: 3.1797e-04
 - val_f1: 0.9998
Epoch 44/300
 - 81s - loss: 2.6999e-04 - val_loss: 3.0179e-04
 - val_f1: 0.9998
Epoch 45/300
 - 81s - loss: 2.7313e-04 - val_loss: 2.6600e-04
 - val_f1: 0.9998
Epoch 46/300
 - 81s - loss: 2.6866e-04 - val_loss: 3.1592e-04
 - val_f1: 0.9998
Epoch 47/300
 - 82s - loss: 2.5758e-04 - val_loss: 2.8828e-04
 - val_f1: 0.9999
Epoch 48/300
 - 80s - loss: 2.6030e-04 - val_loss: 2.8807e-04
 - val_f1: 0.9999
Epoch 49/300
 - 82s - loss: 2.5882e-04 - val_loss: 2.7345e-04
 - val_f1: 0.9999
Epoch 50/300
 - 81s - loss: 2.4997e-04 - val_loss: 2.6838e-04
 - val_f1: 0.9999
Epoch 51/300
 - 82s - loss: 2.6535e-04 - val_loss: 2.8133e-04
 - val_f1: 0.9999
Epoch 52/300
 - 81s - loss: 2.7204e-04 - val_loss: 2.4743e-04
 - val_f1: 0.9999
Epoch 53/300
 - 82s - loss: 2.6329e-04 - val_loss: 2.8911e-04
 - val_f1: 0.9998
Epoch 54/300
 - 81s - loss: 2.5827e-04 - val_loss: 2.6467e-04
 - val_f1: 0.9998
Epoch 55/300
 - 82s - loss: 2.5062e-04 - val_loss: 2.5730e-04
 - val_f1: 0.9999
Epoch 56/300
 - 81s - loss: 2.6505e-04 - val_loss: 2.7903e-04
 - val_f1: 0.9998
Epoch 57/300
 - 82s - loss: 2.4884e-04 - val_loss: 2.6805e-04
 - val_f1: 0.9999
Epoch 58/300
 - 81s - loss: 2.5399e-04 - val_loss: 2.4730e-04
 - val_f1: 0.9999
Epoch 59/300
 - 82s - loss: 2.4966e-04 - val_loss: 2.8335e-04
 - val_f1: 0.9998
Epoch 60/300
 - 81s - loss: 2.5150e-04 - val_loss: 2.6925e-04
 - val_f1: 0.9998
Epoch 61/300
 - 82s - loss: 2.5407e-04 - val_loss: 2.7565e-04
2019-12-21 15:35:40,113 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9999
Epoch 62/300
 - 81s - loss: 2.5098e-04 - val_loss: 2.8172e-04
 - val_f1: 0.9998
Epoch 63/300
 - 82s - loss: 2.4920e-04 - val_loss: 2.8049e-04
 - val_f1: 0.9999
Epoch 64/300
 - 81s - loss: 2.5277e-04 - val_loss: 2.5340e-04
 - val_f1: 0.9999
Epoch 65/300
 - 82s - loss: 2.5253e-04 - val_loss: 2.7830e-04
 - val_f1: 0.9999
Epoch 66/300
 - 81s - loss: 2.5449e-04 - val_loss: 2.5826e-04
 - val_f1: 0.9999
Epoch 67/300
 - 82s - loss: 2.5199e-04 - val_loss: 2.8567e-04
 - val_f1: 0.9998
Epoch 68/300
 - 81s - loss: 2.4494e-04 - val_loss: 3.0364e-04
 - val_f1: 0.9998
Epoch 69/300
 - 82s - loss: 2.4256e-04 - val_loss: 2.6672e-04
 - val_f1: 0.9998
Epoch 70/300
 - 81s - loss: 2.4779e-04 - val_loss: 2.8804e-04
 - val_f1: 0.9998
Epoch 71/300
 - 82s - loss: 2.4708e-04 - val_loss: 2.6976e-04
 - val_f1: 0.9998
Epoch 72/300
 - 81s - loss: 2.4269e-04 - val_loss: 2.7865e-04
 - val_f1: 0.9998
Epoch 73/300
 - 82s - loss: 2.4189e-04 - val_loss: 2.7883e-04
 - val_f1: 0.9999
Epoch 74/300
 - 81s - loss: 2.4128e-04 - val_loss: 2.8179e-04
 - val_f1: 0.9998
Epoch 75/300
 - 82s - loss: 2.4659e-04 - val_loss: 2.7906e-04
 - val_f1: 0.9999
Epoch 76/300
 - 81s - loss: 2.4698e-04 - val_loss: 2.9850e-04
 - val_f1: 0.9999
Epoch 77/300
 - 82s - loss: 2.4941e-04 - val_loss: 3.0283e-04
 - val_f1: 0.9999
Epoch 78/300
 - 81s - loss: 2.4439e-04 - val_loss: 2.7062e-04
 - val_f1: 0.9999
Epoch 79/300
 - 82s - loss: 2.4988e-04 - val_loss: 2.7316e-04
 - val_f1: 0.9999
Epoch 80/300
 - 81s - loss: 2.4798e-04 - val_loss: 2.8238e-04
 - val_f1: 0.9999
Epoch 81/300
 - 82s - loss: 2.4632e-04 - val_loss: 2.6149e-04
 - val_f1: 0.9999
Epoch 82/300
 - 81s - loss: 2.3414e-04 - val_loss: 2.5988e-04
 - val_f1: 0.9999
Epoch 83/300
 - 82s - loss: 2.4361e-04 - val_loss: 2.5282e-04
 - val_f1: 0.9999
Epoch 84/300
 - 81s - loss: 2.4072e-04 - val_loss: 2.8097e-04
 - val_f1: 0.9999
Epoch 85/300
 - 82s - loss: 2.4136e-04 - val_loss: 2.7115e-04
 - val_f1: 0.9999
Epoch 86/300
 - 81s - loss: 2.4918e-04 - val_loss: 2.6389e-04
 - val_f1: 0.9999
Epoch 87/300
 - 82s - loss: 2.3868e-04 - val_loss: 2.8154e-04
 - val_f1: 0.9999
Epoch 88/300
 - 81s - loss: 2.4300e-04 - val_loss: 2.5666e-04
 - val_f1: 0.9999
Epoch 89/300
 - 82s - loss: 2.2686e-04 - val_loss: 2.8937e-04
 - val_f1: 0.9999
Epoch 90/300
 - 81s - loss: 2.3695e-04 - val_loss: 2.8887e-04
 - val_f1: 0.9999
Epoch 91/300
 - 82s - loss: 2.3373e-04 - val_loss: 2.6694e-04
2019-12-21 16:28:50,945 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9999
Epoch 92/300
 - 80s - loss: 2.3237e-04 - val_loss: 2.7544e-04
 - val_f1: 0.9999
Epoch 93/300
 - 82s - loss: 2.4134e-04 - val_loss: 2.9186e-04
 - val_f1: 0.9999
Epoch 94/300
 - 81s - loss: 2.4136e-04 - val_loss: 2.7972e-04
 - val_f1: 0.9999
Epoch 95/300
 - 82s - loss: 2.3272e-04 - val_loss: 2.9240e-04
 - val_f1: 0.9999
Epoch 96/300
 - 81s - loss: 2.3454e-04 - val_loss: 2.5985e-04
 - val_f1: 0.9999
Epoch 97/300
 - 82s - loss: 2.3316e-04 - val_loss: 2.9786e-04
 - val_f1: 0.9998
Epoch 98/300
 - 81s - loss: 2.3389e-04 - val_loss: 2.8074e-04
 - val_f1: 0.9999
Epoch 99/300
 - 82s - loss: 2.3527e-04 - val_loss: 2.6956e-04
 - val_f1: 0.9999
Epoch 100/300
 - 81s - loss: 2.3820e-04 - val_loss: 2.5667e-04
 - val_f1: 0.9999
Epoch 101/300
 - 82s - loss: 2.3257e-04 - val_loss: 2.8231e-04
 - val_f1: 0.9998
Epoch 102/300
 - 81s - loss: 2.3170e-04 - val_loss: 2.8273e-04
 - val_f1: 0.9999
Epoch 103/300
 - 82s - loss: 2.2790e-04 - val_loss: 2.7514e-04
 - val_f1: 0.9999
Epoch 104/300
 - 81s - loss: 2.3075e-04 - val_loss: 2.7722e-04
 - val_f1: 0.9999
Epoch 105/300
 - 82s - loss: 2.3031e-04 - val_loss: 2.9165e-04
 - val_f1: 0.9999
Epoch 106/300
 - 81s - loss: 2.3660e-04 - val_loss: 2.7727e-04
 - val_f1: 0.9999
Epoch 107/300
 - 82s - loss: 2.3459e-04 - val_loss: 2.6943e-04
 - val_f1: 0.9999
Epoch 108/300
 - 81s - loss: 2.3491e-04 - val_loss: 2.7939e-04
2019-12-21 16:59:22,450 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 17:01:31,672 [INFO] Last epoch loss evaluation: train_loss = 0.000192, val_loss = 0.000247
2019-12-21 17:01:31,673 [INFO] Training complete. time_to_train = 11741.37 sec, 195.69 min
2019-12-21 17:01:31,682 [INFO] Model saved to results_selected_models/selected_kdd99_ann_deep_rep3/best_model.pickle
2019-12-21 17:01:32,244 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep3/training_error_history.png
2019-12-21 17:01:32,368 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep3/training_f1_history.png
2019-12-21 17:01:32,371 [INFO] Making predictions on training, validation, testing data
2019-12-21 17:03:44,480 [INFO] Evaluating predictions (results)
2019-12-21 17:03:49,154 [INFO] Dataset: Testing. Classification report below
2019-12-21 17:03:49,154 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.77      0.83      0.80      4166
         r2l       0.97      0.04      0.07     13781
         u2r       0.95      0.01      0.02      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.89      0.57      0.54    311029
weighted avg       0.94      0.92      0.91    311029

2019-12-21 17:03:49,155 [INFO] Overall accuracy (micro avg): 0.9246983400261712
2019-12-21 17:03:54,597 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9247         0.9247                       0.9247                0.0188                   0.0753  0.9247
1     Macro avg        0.9699         0.8855                       0.5660                0.0192                   0.4340  0.5420
2  Weighted avg        0.9688         0.9415                       0.9247                0.0207                   0.0753  0.9062
2019-12-21 17:04:10,960 [INFO] Dataset: Validation. Classification report below
2019-12-21 17:04:10,960 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.90      0.90      0.90       225
         u2r       0.57      0.40      0.47        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.89      0.86      0.87    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-21 17:04:10,960 [INFO] Overall accuracy (micro avg): 0.9998642423549562
2019-12-21 17:04:29,547 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.8942                       0.8593                0.0000                   0.1407  0.8737
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 17:05:41,550 [INFO] Dataset: Training. Classification report below
2019-12-21 17:05:41,550 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      1.00      1.00     32881
         r2l       0.88      0.94      0.91       901
         u2r       0.83      0.60      0.69        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.94      0.91      0.92   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-21 17:05:41,550 [INFO] Overall accuracy (micro avg): 0.9998828706340603
2019-12-21 17:07:03,456 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9430                       0.9065                0.0000                   0.0935  0.9206
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 17:07:03,507 [INFO] Results saved to: results_selected_models/selected_kdd99_ann_deep_rep3/selected_kdd99_ann_deep_rep3_results.xlsx
2019-12-21 17:07:03,515 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-21 17:07:03,788 [INFO] Created directory: results_selected_models/selected_kdd99_ann_deep_rep4
2019-12-21 17:07:03,803 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ann_deep_rep4/run_log.log
2019-12-21 17:07:03,803 [INFO] ================= Running experiment no. 4  ================= 

2019-12-21 17:07:03,803 [INFO] Experiment parameters given below
2019-12-21 17:07:03,803 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_kdd99_ann_deep_rep4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 67], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ann_deep_rep4'}
2019-12-21 17:07:03,803 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ann_deep_rep4/tf_logs_run_2019_12_21-17_07_03
2019-12-21 17:07:03,804 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 17:07:03,812 [INFO] Reading X, y files
2019-12-21 17:07:03,812 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 17:07:12,988 [INFO] Reading complete. time_to_read=9.18 seconds
2019-12-21 17:07:12,989 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 17:07:15,241 [INFO] Reading complete. time_to_read=2.25 seconds
2019-12-21 17:07:15,241 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 17:07:15,917 [INFO] Reading complete. time_to_read=0.68 seconds
2019-12-21 17:07:15,917 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 17:07:16,510 [INFO] Reading complete. time_to_read=0.59 seconds
2019-12-21 17:07:16,510 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 17:07:16,633 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-21 17:07:16,633 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 17:07:16,679 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-21 17:08:07,688 [INFO] Initializing model
2019-12-21 17:08:10,210 [INFO] _________________________________________________________________
2019-12-21 17:08:10,213 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 17:08:10,214 [INFO] =================================================================
2019-12-21 17:08:10,216 [INFO] dense_38 (Dense)             (None, 64)                7936      
2019-12-21 17:08:10,218 [INFO] _________________________________________________________________
2019-12-21 17:08:10,219 [INFO] batch_normalization_30 (Batc (None, 64)                256       
2019-12-21 17:08:10,219 [INFO] _________________________________________________________________
2019-12-21 17:08:10,219 [INFO] dropout_30 (Dropout)         (None, 64)                0         
2019-12-21 17:08:10,219 [INFO] _________________________________________________________________
2019-12-21 17:08:10,219 [INFO] dense_39 (Dense)             (None, 32)                2080      
2019-12-21 17:08:10,219 [INFO] _________________________________________________________________
2019-12-21 17:08:10,220 [INFO] batch_normalization_31 (Batc (None, 32)                128       
2019-12-21 17:08:10,220 [INFO] _________________________________________________________________
2019-12-21 17:08:10,220 [INFO] dropout_31 (Dropout)         (None, 32)                0         
2019-12-21 17:08:10,220 [INFO] _________________________________________________________________
2019-12-21 17:08:10,220 [INFO] dense_40 (Dense)             (None, 67)                2211      
2019-12-21 17:08:10,220 [INFO] _________________________________________________________________
2019-12-21 17:08:10,220 [INFO] batch_normalization_32 (Batc (None, 67)                268       
2019-12-21 17:08:10,220 [INFO] _________________________________________________________________
2019-12-21 17:08:10,220 [INFO] dropout_32 (Dropout)         (None, 67)                0         
2019-12-21 17:08:10,221 [INFO] _________________________________________________________________
2019-12-21 17:08:10,221 [INFO] dense_41 (Dense)             (None, 5)                 340       
2019-12-21 17:08:10,221 [INFO] =================================================================
2019-12-21 17:08:10,221 [INFO] Total params: 13,219
2019-12-21 17:08:10,222 [INFO] Trainable params: 12,893
2019-12-21 17:08:10,222 [INFO] Non-trainable params: 326
2019-12-21 17:08:10,222 [INFO] _________________________________________________________________
2019-12-21 17:08:10,222 [INFO] Training model
 - val_f1: 0.9999
Epoch 00108: early stopping
Train on 3918744 samples, validate on 979687 samples
Epoch 1/300
 - 201s - loss: 0.0035 - val_loss: 6.4263e-04
 - val_f1: 0.9996
Epoch 2/300
 - 80s - loss: 6.9243e-04 - val_loss: 4.6251e-04
 - val_f1: 0.9997
Epoch 3/300
 - 80s - loss: 5.4996e-04 - val_loss: 4.5300e-04
 - val_f1: 0.9997
Epoch 4/300
 - 80s - loss: 5.0013e-04 - val_loss: 4.5265e-04
 - val_f1: 0.9997
Epoch 5/300
 - 80s - loss: 4.6437e-04 - val_loss: 3.8622e-04
 - val_f1: 0.9998
Epoch 6/300
 - 80s - loss: 4.4348e-04 - val_loss: 3.7645e-04
 - val_f1: 0.9998
Epoch 7/300
 - 80s - loss: 4.1350e-04 - val_loss: 3.4564e-04
 - val_f1: 0.9998
Epoch 8/300
 - 80s - loss: 3.9659e-04 - val_loss: 3.3287e-04
 - val_f1: 0.9998
Epoch 9/300
 - 80s - loss: 3.9281e-04 - val_loss: 3.5047e-04
 - val_f1: 0.9998
Epoch 10/300
 - 80s - loss: 3.8302e-04 - val_loss: 3.4024e-04
 - val_f1: 0.9998
Epoch 11/300
 - 80s - loss: 3.6848e-04 - val_loss: 3.4655e-04
 - val_f1: 0.9998
Epoch 12/300
 - 80s - loss: 3.6227e-04 - val_loss: 3.0966e-04
 - val_f1: 0.9998
Epoch 13/300
 - 80s - loss: 3.4790e-04 - val_loss: 2.9037e-04
 - val_f1: 0.9998
Epoch 14/300
 - 80s - loss: 3.4101e-04 - val_loss: 2.9155e-04
 - val_f1: 0.9998
Epoch 15/300
 - 80s - loss: 3.3556e-04 - val_loss: 2.7431e-04
 - val_f1: 0.9998
Epoch 16/300
 - 80s - loss: 3.2304e-04 - val_loss: 2.9808e-04
 - val_f1: 0.9999
Epoch 17/300
 - 80s - loss: 3.2631e-04 - val_loss: 2.8171e-04
 - val_f1: 0.9998
Epoch 18/300
 - 80s - loss: 3.1816e-04 - val_loss: 2.7335e-04
 - val_f1: 0.9998
Epoch 19/300
 - 80s - loss: 3.2140e-04 - val_loss: 2.7513e-04
 - val_f1: 0.9998
Epoch 20/300
 - 80s - loss: 3.0694e-04 - val_loss: 3.1190e-04
 - val_f1: 0.9998
Epoch 21/300
 - 80s - loss: 3.0612e-04 - val_loss: 2.7018e-04
 - val_f1: 0.9998
Epoch 22/300
 - 80s - loss: 3.0511e-04 - val_loss: 2.6592e-04
 - val_f1: 0.9999
Epoch 23/300
 - 80s - loss: 2.9459e-04 - val_loss: 2.6340e-04
 - val_f1: 0.9999
Epoch 24/300
 - 80s - loss: 3.0060e-04 - val_loss: 2.4701e-04
 - val_f1: 0.9998
Epoch 25/300
 - 80s - loss: 2.8557e-04 - val_loss: 2.3927e-04
 - val_f1: 0.9999
Epoch 26/300
 - 80s - loss: 2.7253e-04 - val_loss: 2.9540e-04
 - val_f1: 0.9998
Epoch 27/300
 - 80s - loss: 2.9509e-04 - val_loss: 2.3463e-04
 - val_f1: 0.9999
Epoch 28/300
 - 80s - loss: 2.8769e-04 - val_loss: 2.5816e-04
 - val_f1: 0.9999
Epoch 29/300
 - 80s - loss: 2.8309e-04 - val_loss: 2.6371e-04
 - val_f1: 0.9998
Epoch 30/300
 - 80s - loss: 2.7727e-04 - val_loss: 2.7639e-04
 - val_f1: 0.9998
Epoch 31/300
 - 80s - loss: 2.7763e-04 - val_loss: 2.4804e-04
2019-12-21 18:05:00,056 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9999
Epoch 32/300
 - 80s - loss: 2.8346e-04 - val_loss: 2.4613e-04
 - val_f1: 0.9998
Epoch 33/300
 - 80s - loss: 2.7862e-04 - val_loss: 2.4947e-04
 - val_f1: 0.9998
Epoch 34/300
 - 80s - loss: 2.6868e-04 - val_loss: 2.5539e-04
 - val_f1: 0.9999
Epoch 35/300
 - 80s - loss: 2.7411e-04 - val_loss: 2.5970e-04
 - val_f1: 0.9999
Epoch 36/300
 - 82s - loss: 2.8304e-04 - val_loss: 2.5141e-04
 - val_f1: 0.9999
Epoch 37/300
 - 80s - loss: 2.6454e-04 - val_loss: 2.4630e-04
 - val_f1: 0.9999
Epoch 38/300
 - 80s - loss: 2.6033e-04 - val_loss: 2.5547e-04
 - val_f1: 0.9998
Epoch 39/300
 - 80s - loss: 2.6493e-04 - val_loss: 2.4959e-04
 - val_f1: 0.9999
Epoch 40/300
 - 80s - loss: 2.6866e-04 - val_loss: 2.6853e-04
 - val_f1: 0.9998
Epoch 41/300
 - 80s - loss: 2.7294e-04 - val_loss: 2.5817e-04
 - val_f1: 0.9999
Epoch 42/300
 - 80s - loss: 2.7094e-04 - val_loss: 2.3523e-04
 - val_f1: 0.9999
Epoch 43/300
 - 80s - loss: 2.6442e-04 - val_loss: 2.4421e-04
 - val_f1: 0.9999
Epoch 44/300
 - 80s - loss: 2.6499e-04 - val_loss: 2.4855e-04
 - val_f1: 0.9999
Epoch 45/300
 - 80s - loss: 2.6228e-04 - val_loss: 2.3388e-04
 - val_f1: 0.9999
Epoch 46/300
 - 80s - loss: 2.5561e-04 - val_loss: 2.4336e-04
 - val_f1: 0.9999
Epoch 47/300
 - 80s - loss: 2.6359e-04 - val_loss: 2.4018e-04
 - val_f1: 0.9999
Epoch 48/300
 - 80s - loss: 2.6382e-04 - val_loss: 2.7157e-04
 - val_f1: 0.9998
Epoch 49/300
 - 80s - loss: 2.6261e-04 - val_loss: 2.7845e-04
 - val_f1: 0.9998
Epoch 50/300
 - 80s - loss: 2.5869e-04 - val_loss: 2.3845e-04
 - val_f1: 0.9999
Epoch 51/300
 - 80s - loss: 2.6297e-04 - val_loss: 2.2758e-04
 - val_f1: 0.9999
Epoch 52/300
 - 80s - loss: 2.6165e-04 - val_loss: 2.3890e-04
 - val_f1: 0.9999
Epoch 53/300
 - 80s - loss: 2.4770e-04 - val_loss: 2.5013e-04
 - val_f1: 0.9999
Epoch 54/300
 - 80s - loss: 2.5275e-04 - val_loss: 2.4834e-04
 - val_f1: 0.9999
Epoch 55/300
 - 80s - loss: 2.5326e-04 - val_loss: 2.2871e-04
 - val_f1: 0.9999
Epoch 56/300
 - 82s - loss: 2.4711e-04 - val_loss: 2.3513e-04
 - val_f1: 0.9999
Epoch 57/300
 - 80s - loss: 2.5846e-04 - val_loss: 2.5850e-04
 - val_f1: 0.9999
Epoch 58/300
 - 80s - loss: 2.5611e-04 - val_loss: 2.3175e-04
 - val_f1: 0.9999
Epoch 59/300
 - 80s - loss: 2.5557e-04 - val_loss: 2.4102e-04
 - val_f1: 0.9999
Epoch 60/300
 - 80s - loss: 2.4170e-04 - val_loss: 2.6816e-04
 - val_f1: 0.9998
Epoch 61/300
 - 80s - loss: 2.4925e-04 - val_loss: 2.4327e-04
2019-12-21 18:58:34,838 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9999
Epoch 62/300
 - 81s - loss: 2.4471e-04 - val_loss: 2.6218e-04
 - val_f1: 0.9999
Epoch 63/300
 - 80s - loss: 2.5415e-04 - val_loss: 2.2510e-04
 - val_f1: 0.9999
Epoch 64/300
 - 81s - loss: 2.4297e-04 - val_loss: 2.3430e-04
 - val_f1: 0.9999
Epoch 65/300
 - 80s - loss: 2.5432e-04 - val_loss: 2.4181e-04
 - val_f1: 0.9998
Epoch 66/300
 - 80s - loss: 2.5034e-04 - val_loss: 2.2161e-04
 - val_f1: 0.9999
Epoch 67/300
 - 80s - loss: 2.4429e-04 - val_loss: 2.5274e-04
 - val_f1: 0.9998
Epoch 68/300
 - 80s - loss: 2.4200e-04 - val_loss: 2.3345e-04
 - val_f1: 0.9999
Epoch 69/300
 - 80s - loss: 2.5074e-04 - val_loss: 2.2494e-04
 - val_f1: 0.9999
Epoch 70/300
 - 80s - loss: 2.4338e-04 - val_loss: 2.5977e-04
 - val_f1: 0.9998
Epoch 71/300
 - 80s - loss: 2.4684e-04 - val_loss: 2.1462e-04
 - val_f1: 0.9999
Epoch 72/300
 - 80s - loss: 2.4127e-04 - val_loss: 2.4453e-04
 - val_f1: 0.9999
Epoch 73/300
 - 80s - loss: 2.4609e-04 - val_loss: 2.4615e-04
 - val_f1: 0.9999
Epoch 74/300
 - 80s - loss: 2.3930e-04 - val_loss: 2.3405e-04
 - val_f1: 0.9999
Epoch 75/300
 - 80s - loss: 2.3917e-04 - val_loss: 2.4578e-04
 - val_f1: 0.9998
Epoch 76/300
 - 80s - loss: 2.4571e-04 - val_loss: 2.3879e-04
 - val_f1: 0.9999
Epoch 77/300
 - 80s - loss: 2.3365e-04 - val_loss: 2.4227e-04
 - val_f1: 0.9999
Epoch 78/300
 - 80s - loss: 2.5697e-04 - val_loss: 2.3689e-04
 - val_f1: 0.9999
Epoch 79/300
 - 80s - loss: 2.4184e-04 - val_loss: 2.4145e-04
 - val_f1: 0.9998
Epoch 80/300
 - 80s - loss: 2.4026e-04 - val_loss: 2.2206e-04
 - val_f1: 0.9999
Epoch 81/300
 - 80s - loss: 2.3311e-04 - val_loss: 2.4264e-04
 - val_f1: 0.9999
Epoch 82/300
 - 81s - loss: 2.4694e-04 - val_loss: 2.3672e-04
 - val_f1: 0.9999
Epoch 83/300
 - 80s - loss: 2.3998e-04 - val_loss: 2.3154e-04
 - val_f1: 0.9999
Epoch 84/300
 - 81s - loss: 2.4958e-04 - val_loss: 2.3629e-04
 - val_f1: 0.9999
Epoch 85/300
 - 80s - loss: 2.3442e-04 - val_loss: 2.2662e-04
 - val_f1: 0.9999
Epoch 86/300
 - 82s - loss: 2.3889e-04 - val_loss: 2.2999e-04
 - val_f1: 0.9999
Epoch 87/300
 - 80s - loss: 2.4258e-04 - val_loss: 2.4877e-04
 - val_f1: 0.9999
Epoch 88/300
 - 80s - loss: 2.3839e-04 - val_loss: 2.2720e-04
 - val_f1: 0.9999
Epoch 89/300
 - 80s - loss: 2.3490e-04 - val_loss: 2.2951e-04
 - val_f1: 0.9999
Epoch 90/300
 - 81s - loss: 2.3284e-04 - val_loss: 2.3742e-04
 - val_f1: 0.9999
Epoch 91/300
 - 80s - loss: 2.4024e-04 - val_loss: 2.2959e-04
2019-12-21 19:52:14,444 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9999
Epoch 92/300
 - 80s - loss: 2.2987e-04 - val_loss: 2.1149e-04
 - val_f1: 0.9999
Epoch 93/300
 - 80s - loss: 2.3409e-04 - val_loss: 2.4093e-04
 - val_f1: 0.9999
Epoch 94/300
 - 80s - loss: 2.4379e-04 - val_loss: 2.2832e-04
 - val_f1: 0.9999
Epoch 95/300
 - 80s - loss: 2.3175e-04 - val_loss: 2.4818e-04
 - val_f1: 0.9999
Epoch 96/300
 - 81s - loss: 2.3833e-04 - val_loss: 2.2352e-04
 - val_f1: 0.9999
Epoch 97/300
 - 80s - loss: 2.2977e-04 - val_loss: 2.2700e-04
 - val_f1: 0.9999
Epoch 98/300
 - 81s - loss: 2.3502e-04 - val_loss: 2.5878e-04
 - val_f1: 0.9999
Epoch 99/300
 - 80s - loss: 2.3645e-04 - val_loss: 2.2061e-04
 - val_f1: 0.9999
Epoch 100/300
 - 80s - loss: 2.3705e-04 - val_loss: 2.3862e-04
 - val_f1: 0.9999
Epoch 101/300
 - 80s - loss: 2.3708e-04 - val_loss: 2.0700e-04
 - val_f1: 0.9999
Epoch 102/300
 - 80s - loss: 2.3449e-04 - val_loss: 2.3428e-04
 - val_f1: 0.9999
Epoch 103/300
 - 80s - loss: 2.4027e-04 - val_loss: 2.2804e-04
 - val_f1: 0.9999
Epoch 104/300
 - 80s - loss: 2.3881e-04 - val_loss: 2.3077e-04
 - val_f1: 0.9999
Epoch 105/300
 - 80s - loss: 2.3812e-04 - val_loss: 2.4740e-04
 - val_f1: 0.9999
Epoch 106/300
 - 80s - loss: 2.3165e-04 - val_loss: 2.4013e-04
 - val_f1: 0.9999
Epoch 107/300
 - 80s - loss: 2.2831e-04 - val_loss: 2.1993e-04
 - val_f1: 0.9999
Epoch 108/300
 - 81s - loss: 2.3630e-04 - val_loss: 2.3394e-04
 - val_f1: 0.9999
Epoch 109/300
 - 80s - loss: 2.3154e-04 - val_loss: 2.4958e-04
 - val_f1: 0.9999
Epoch 110/300
 - 80s - loss: 2.2781e-04 - val_loss: 2.1860e-04
 - val_f1: 0.9999
Epoch 111/300
 - 80s - loss: 2.2551e-04 - val_loss: 2.2267e-04
 - val_f1: 0.9999
Epoch 112/300
 - 81s - loss: 2.3299e-04 - val_loss: 2.3582e-04
 - val_f1: 0.9999
Epoch 113/300
 - 80s - loss: 2.2145e-04 - val_loss: 2.4033e-04
 - val_f1: 0.9999
Epoch 114/300
 - 80s - loss: 2.2952e-04 - val_loss: 2.2718e-04
 - val_f1: 0.9999
Epoch 115/300
 - 80s - loss: 2.2801e-04 - val_loss: 2.2452e-04
 - val_f1: 0.9999
Epoch 116/300
 - 80s - loss: 2.3388e-04 - val_loss: 2.2911e-04
 - val_f1: 0.9999
Epoch 117/300
 - 80s - loss: 2.3550e-04 - val_loss: 2.1660e-04
 - val_f1: 0.9999
Epoch 118/300
 - 80s - loss: 2.3074e-04 - val_loss: 2.3302e-04
 - val_f1: 0.9999
Epoch 119/300
 - 80s - loss: 2.3583e-04 - val_loss: 2.4196e-04
 - val_f1: 0.9999
Epoch 120/300
 - 80s - loss: 2.3057e-04 - val_loss: 2.3969e-04
 - val_f1: 0.9999
Epoch 121/300
 - 80s - loss: 2.3209e-04 - val_loss: 2.5137e-04
2019-12-21 20:45:50,366 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 80s - loss: 2.2870e-04 - val_loss: 2.4270e-04
 - val_f1: 0.9999
Epoch 123/300
 - 80s - loss: 2.3000e-04 - val_loss: 2.3327e-04
 - val_f1: 0.9999
Epoch 124/300
 - 80s - loss: 2.3629e-04 - val_loss: 2.3472e-04
 - val_f1: 0.9999
Epoch 125/300
 - 80s - loss: 2.2951e-04 - val_loss: 2.4158e-04
 - val_f1: 0.9999
Epoch 126/300
 - 81s - loss: 2.2723e-04 - val_loss: 2.3480e-04
 - val_f1: 0.9999
Epoch 127/300
 - 80s - loss: 2.2346e-04 - val_loss: 2.4284e-04
 - val_f1: 0.9999
Epoch 128/300
 - 81s - loss: 2.3069e-04 - val_loss: 2.4373e-04
 - val_f1: 0.9999
Epoch 129/300
 - 80s - loss: 2.2803e-04 - val_loss: 2.3552e-04
 - val_f1: 0.9999
Epoch 130/300
 - 81s - loss: 2.2665e-04 - val_loss: 2.2968e-04
 - val_f1: 0.9999
Epoch 131/300
 - 80s - loss: 2.1961e-04 - val_loss: 2.3968e-04
 - val_f1: 0.9999
Epoch 132/300
 - 82s - loss: 2.3244e-04 - val_loss: 3.0206e-04
 - val_f1: 0.9998
Epoch 133/300
 - 80s - loss: 2.2991e-04 - val_loss: 2.7784e-04
 - val_f1: 0.9998
Epoch 134/300
 - 80s - loss: 2.2382e-04 - val_loss: 2.6178e-04
 - val_f1: 0.9999
Epoch 135/300
 - 80s - loss: 2.3227e-04 - val_loss: 2.4396e-04
 - val_f1: 0.9999
Epoch 136/300
 - 80s - loss: 2.2980e-04 - val_loss: 2.5777e-04
 - val_f1: 0.9999
Epoch 137/300
 - 80s - loss: 2.1534e-04 - val_loss: 2.2554e-04
 - val_f1: 0.9999
Epoch 138/300
 - 80s - loss: 2.2464e-04 - val_loss: 2.2603e-04
 - val_f1: 0.9999
Epoch 139/300
 - 80s - loss: 2.2708e-04 - val_loss: 2.2668e-04
 - val_f1: 0.9999
Epoch 140/300
 - 80s - loss: 2.2897e-04 - val_loss: 2.5047e-04
 - val_f1: 0.9998
Epoch 141/300
 - 80s - loss: 2.1888e-04 - val_loss: 2.2914e-04
 - val_f1: 0.9999
Epoch 142/300
 - 80s - loss: 2.2152e-04 - val_loss: 2.0508e-04
 - val_f1: 0.9999
Epoch 143/300
 - 80s - loss: 2.2437e-04 - val_loss: 2.3473e-04
 - val_f1: 0.9999
Epoch 144/300
 - 80s - loss: 2.1981e-04 - val_loss: 2.5294e-04
 - val_f1: 0.9999
Epoch 145/300
 - 80s - loss: 2.1596e-04 - val_loss: 2.2702e-04
 - val_f1: 0.9999
Epoch 146/300
 - 80s - loss: 2.1777e-04 - val_loss: 2.3647e-04
 - val_f1: 0.9999
Epoch 147/300
 - 80s - loss: 2.2384e-04 - val_loss: 2.4397e-04
 - val_f1: 0.9999
Epoch 148/300
 - 80s - loss: 2.2370e-04 - val_loss: 2.6526e-04
 - val_f1: 0.9999
Epoch 149/300
 - 80s - loss: 2.2035e-04 - val_loss: 2.4146e-04
 - val_f1: 0.9999
Epoch 150/300
 - 80s - loss: 2.2070e-04 - val_loss: 2.2321e-04
 - val_f1: 0.9999
Epoch 151/300
 - 80s - loss: 2.2537e-04 - val_loss: 2.3339e-04
2019-12-21 21:39:29,846 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9999
Epoch 152/300
 - 82s - loss: 2.1721e-04 - val_loss: 2.2432e-04
 - val_f1: 0.9999
Epoch 153/300
 - 80s - loss: 2.2763e-04 - val_loss: 2.3211e-04
 - val_f1: 0.9999
Epoch 154/300
 - 80s - loss: 2.0915e-04 - val_loss: 2.2206e-04
 - val_f1: 0.9999
Epoch 155/300
 - 80s - loss: 2.2201e-04 - val_loss: 2.3827e-04
 - val_f1: 0.9999
Epoch 156/300
 - 80s - loss: 2.2460e-04 - val_loss: 2.4793e-04
 - val_f1: 0.9998
Epoch 157/300
 - 80s - loss: 2.2463e-04 - val_loss: 2.3489e-04
 - val_f1: 0.9999
Epoch 158/300
 - 80s - loss: 2.1893e-04 - val_loss: 2.5068e-04
 - val_f1: 0.9999
Epoch 159/300
 - 80s - loss: 2.2670e-04 - val_loss: 2.2883e-04
 - val_f1: 0.9999
Epoch 160/300
 - 80s - loss: 2.1945e-04 - val_loss: 2.3477e-04
 - val_f1: 0.9999
Epoch 161/300
 - 80s - loss: 2.2160e-04 - val_loss: 2.3072e-04
 - val_f1: 0.9999
Epoch 162/300
 - 80s - loss: 2.1698e-04 - val_loss: 2.1544e-04
 - val_f1: 0.9999
Epoch 163/300
 - 80s - loss: 2.2156e-04 - val_loss: 2.2628e-04
 - val_f1: 0.9999
Epoch 164/300
 - 80s - loss: 2.1717e-04 - val_loss: 2.2010e-04
 - val_f1: 0.9999
Epoch 165/300
 - 80s - loss: 2.1893e-04 - val_loss: 2.2659e-04
 - val_f1: 0.9999
Epoch 166/300
 - 80s - loss: 2.2811e-04 - val_loss: 2.3381e-04
 - val_f1: 0.9999
Epoch 167/300
 - 80s - loss: 2.1810e-04 - val_loss: 2.1058e-04
 - val_f1: 0.9999
Epoch 168/300
 - 80s - loss: 2.1414e-04 - val_loss: 2.5987e-04
 - val_f1: 0.9998
Epoch 169/300
 - 80s - loss: 2.2890e-04 - val_loss: 2.2711e-04
 - val_f1: 0.9999
Epoch 170/300
 - 80s - loss: 2.1571e-04 - val_loss: 2.1936e-04
 - val_f1: 0.9999
Epoch 171/300
 - 80s - loss: 2.2089e-04 - val_loss: 2.1468e-04
 - val_f1: 0.9999
Epoch 172/300
 - 80s - loss: 2.2650e-04 - val_loss: 2.3525e-04
 - val_f1: 0.9999
Epoch 173/300
 - 80s - loss: 2.1473e-04 - val_loss: 2.2873e-04
 - val_f1: 0.9999
Epoch 174/300
 - 80s - loss: 2.1576e-04 - val_loss: 2.1947e-04
 - val_f1: 0.9999
Epoch 175/300
 - 80s - loss: 2.1144e-04 - val_loss: 2.4704e-04
 - val_f1: 0.9999
Epoch 176/300
 - 80s - loss: 2.1092e-04 - val_loss: 2.3070e-04
 - val_f1: 0.9999
Epoch 177/300
 - 80s - loss: 2.2011e-04 - val_loss: 2.3439e-04
 - val_f1: 0.9999
Epoch 178/300
 - 80s - loss: 2.1904e-04 - val_loss: 2.1928e-04
 - val_f1: 0.9999
Epoch 179/300
 - 80s - loss: 2.1720e-04 - val_loss: 2.2206e-04
 - val_f1: 0.9999
Epoch 180/300
 - 80s - loss: 2.1300e-04 - val_loss: 2.2395e-04
 - val_f1: 0.9999
Epoch 181/300
 - 80s - loss: 2.1305e-04 - val_loss: 2.1141e-04
2019-12-21 22:33:06,690 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9999
Epoch 182/300
 - 80s - loss: 2.2099e-04 - val_loss: 2.2323e-04
 - val_f1: 0.9999
Epoch 183/300
 - 80s - loss: 2.1440e-04 - val_loss: 2.2289e-04
 - val_f1: 0.9999
Epoch 184/300
 - 80s - loss: 2.0872e-04 - val_loss: 2.3196e-04
 - val_f1: 0.9999
Epoch 185/300
 - 80s - loss: 2.2074e-04 - val_loss: 2.3280e-04
 - val_f1: 0.9999
Epoch 186/300
 - 80s - loss: 2.1722e-04 - val_loss: 2.2953e-04
 - val_f1: 0.9999
Epoch 187/300
 - 80s - loss: 2.1609e-04 - val_loss: 2.1073e-04
 - val_f1: 0.9999
Epoch 188/300
 - 80s - loss: 2.0698e-04 - val_loss: 2.2943e-04
 - val_f1: 0.9998
Epoch 189/300
 - 80s - loss: 2.1080e-04 - val_loss: 2.2547e-04
 - val_f1: 0.9999
Epoch 190/300
 - 80s - loss: 2.1805e-04 - val_loss: 2.1801e-04
 - val_f1: 0.9999
Epoch 191/300
 - 80s - loss: 2.1276e-04 - val_loss: 2.1389e-04
 - val_f1: 0.9999
Epoch 192/300
 - 80s - loss: 2.1114e-04 - val_loss: 2.4408e-04
2019-12-21 22:53:13,374 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 22:55:27,264 [INFO] Last epoch loss evaluation: train_loss = 0.000171, val_loss = 0.000205
2019-12-21 22:55:27,264 [INFO] Training complete. time_to_train = 20837.04 sec, 347.28 min
2019-12-21 22:55:27,275 [INFO] Model saved to results_selected_models/selected_kdd99_ann_deep_rep4/best_model.pickle
2019-12-21 22:55:27,836 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep4/training_error_history.png
2019-12-21 22:55:27,974 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep4/training_f1_history.png
2019-12-21 22:55:27,977 [INFO] Making predictions on training, validation, testing data
2019-12-21 22:57:54,137 [INFO] Evaluating predictions (results)
2019-12-21 22:57:58,786 [INFO] Dataset: Testing. Classification report below
2019-12-21 22:57:58,786 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.77      0.81      0.79      4166
         r2l       0.92      0.03      0.06     13781
         u2r       0.67      0.01      0.01      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.82      0.56      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-21 22:57:58,786 [INFO] Overall accuracy (micro avg): 0.9233094020171753
2019-12-21 22:58:04,133 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9233         0.9233                       0.9233                0.0192                   0.0767  0.9233
1     Macro avg        0.9693         0.8151                       0.5600                0.0193                   0.4400  0.5355
2  Weighted avg        0.9682         0.9361                       0.9233                0.0200                   0.0767  0.9046
2019-12-21 22:58:20,475 [INFO] Dataset: Validation. Classification report below
2019-12-21 22:58:20,475 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.92      0.91      0.91       225
         u2r       0.50      0.50      0.50        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.88      0.88      0.88    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-21 22:58:20,475 [INFO] Overall accuracy (micro avg): 0.999871387494169
2019-12-21 22:58:39,138 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.8825                       0.8811                0.0000                   0.1189  0.8818
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 22:59:51,109 [INFO] Dataset: Training. Classification report below
2019-12-21 22:59:51,110 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      1.00      1.00     32881
         r2l       0.88      0.95      0.91       901
         u2r       0.67      0.67      0.67        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.91      0.92      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-21 22:59:51,110 [INFO] Overall accuracy (micro avg): 0.9998866983911171
2019-12-21 23:01:12,994 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9085                       0.9217                0.0000                   0.0783  0.9149
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-21 23:01:13,047 [INFO] Results saved to: results_selected_models/selected_kdd99_ann_deep_rep4/selected_kdd99_ann_deep_rep4_results.xlsx
2019-12-21 23:01:13,055 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-21 23:01:13,331 [INFO] Created directory: results_selected_models/selected_kdd99_ann_deep_rep5
2019-12-21 23:01:13,332 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ann_deep_rep5/run_log.log
2019-12-21 23:01:13,332 [INFO] ================= Running experiment no. 5  ================= 

2019-12-21 23:01:13,332 [INFO] Experiment parameters given below
2019-12-21 23:01:13,332 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_kdd99_ann_deep_rep5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 68], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ann_deep_rep5'}
2019-12-21 23:01:13,332 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ann_deep_rep5/tf_logs_run_2019_12_21-23_01_13
2019-12-21 23:01:13,332 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 23:01:13,344 [INFO] Reading X, y files
2019-12-21 23:01:13,344 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 23:01:22,503 [INFO] Reading complete. time_to_read=9.16 seconds
2019-12-21 23:01:22,504 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 23:01:24,753 [INFO] Reading complete. time_to_read=2.25 seconds
2019-12-21 23:01:24,753 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 23:01:25,434 [INFO] Reading complete. time_to_read=0.68 seconds
2019-12-21 23:01:25,434 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 23:01:26,131 [INFO] Reading complete. time_to_read=0.70 seconds
2019-12-21 23:01:26,131 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 23:01:26,250 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-21 23:01:26,250 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 23:01:26,302 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-21 23:02:07,881 [INFO] Initializing model
2019-12-21 23:02:10,607 [INFO] _________________________________________________________________
2019-12-21 23:02:10,609 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 23:02:10,609 [INFO] =================================================================
2019-12-21 23:02:10,610 [INFO] dense_42 (Dense)             (None, 64)                7936      
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,610 [INFO] batch_normalization_33 (Batc (None, 64)                256       
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,610 [INFO] dropout_33 (Dropout)         (None, 64)                0         
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,610 [INFO] dense_43 (Dense)             (None, 32)                2080      
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,610 [INFO] batch_normalization_34 (Batc (None, 32)                128       
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,610 [INFO] dropout_34 (Dropout)         (None, 32)                0         
2019-12-21 23:02:10,610 [INFO] _________________________________________________________________
2019-12-21 23:02:10,611 [INFO] dense_44 (Dense)             (None, 68)                2244      
2019-12-21 23:02:10,611 [INFO] _________________________________________________________________
2019-12-21 23:02:10,611 [INFO] batch_normalization_35 (Batc (None, 68)                272       
2019-12-21 23:02:10,611 [INFO] _________________________________________________________________
2019-12-21 23:02:10,611 [INFO] dropout_35 (Dropout)         (None, 68)                0         
2019-12-21 23:02:10,611 [INFO] _________________________________________________________________
2019-12-21 23:02:10,611 [INFO] dense_45 (Dense)             (None, 5)                 345       
2019-12-21 23:02:10,611 [INFO] =================================================================
2019-12-21 23:02:10,612 [INFO] Total params: 13,261
2019-12-21 23:02:10,612 [INFO] Trainable params: 12,933
2019-12-21 23:02:10,612 [INFO] Non-trainable params: 328
2019-12-21 23:02:10,612 [INFO] _________________________________________________________________
2019-12-21 23:02:10,612 [INFO] Training model
 - val_f1: 0.9999
Epoch 00192: early stopping
Train on 3918744 samples, validate on 979687 samples
Epoch 1/300
 - 196s - loss: 0.0037 - val_loss: 5.9373e-04
 - val_f1: 0.9997
Epoch 2/300
 - 81s - loss: 7.1233e-04 - val_loss: 4.7207e-04
 - val_f1: 0.9997
Epoch 3/300
 - 81s - loss: 5.8026e-04 - val_loss: 4.3699e-04
 - val_f1: 0.9997
Epoch 4/300
 - 81s - loss: 5.0143e-04 - val_loss: 3.9497e-04
 - val_f1: 0.9997
Epoch 5/300
 - 81s - loss: 4.5472e-04 - val_loss: 4.1164e-04
 - val_f1: 0.9998
Epoch 6/300
 - 81s - loss: 4.3051e-04 - val_loss: 3.8108e-04
 - val_f1: 0.9998
Epoch 7/300
 - 81s - loss: 4.2739e-04 - val_loss: 3.5101e-04
 - val_f1: 0.9998
Epoch 8/300
 - 81s - loss: 3.9639e-04 - val_loss: 3.7187e-04
 - val_f1: 0.9998
Epoch 9/300
 - 81s - loss: 3.7963e-04 - val_loss: 3.4957e-04
 - val_f1: 0.9998
Epoch 10/300
 - 81s - loss: 3.7521e-04 - val_loss: 3.3661e-04
 - val_f1: 0.9998
Epoch 11/300
 - 81s - loss: 3.7186e-04 - val_loss: 3.0512e-04
 - val_f1: 0.9998
Epoch 12/300
 - 81s - loss: 3.5250e-04 - val_loss: 3.1092e-04
 - val_f1: 0.9998
Epoch 13/300
 - 81s - loss: 3.6932e-04 - val_loss: 2.9351e-04
 - val_f1: 0.9998
Epoch 14/300
 - 81s - loss: 3.4928e-04 - val_loss: 3.1139e-04
 - val_f1: 0.9998
Epoch 15/300
 - 81s - loss: 3.3422e-04 - val_loss: 2.9599e-04
 - val_f1: 0.9998
Epoch 16/300
 - 81s - loss: 3.3118e-04 - val_loss: 3.4156e-04
 - val_f1: 0.9998
Epoch 17/300
 - 81s - loss: 3.2830e-04 - val_loss: 2.8848e-04
 - val_f1: 0.9998
Epoch 18/300
 - 81s - loss: 3.1428e-04 - val_loss: 2.8341e-04
 - val_f1: 0.9998
Epoch 19/300
 - 81s - loss: 3.1532e-04 - val_loss: 2.7879e-04
 - val_f1: 0.9999
Epoch 20/300
 - 81s - loss: 3.1353e-04 - val_loss: 2.7850e-04
 - val_f1: 0.9998
Epoch 21/300
 - 81s - loss: 3.0836e-04 - val_loss: 2.6628e-04
 - val_f1: 0.9998
Epoch 22/300
 - 81s - loss: 3.0382e-04 - val_loss: 2.8082e-04
 - val_f1: 0.9998
Epoch 23/300
 - 81s - loss: 3.0293e-04 - val_loss: 3.0547e-04
 - val_f1: 0.9998
Epoch 24/300
 - 81s - loss: 3.0523e-04 - val_loss: 2.8183e-04
 - val_f1: 0.9998
Epoch 25/300
 - 81s - loss: 3.0165e-04 - val_loss: 3.1732e-04
 - val_f1: 0.9998
Epoch 26/300
 - 81s - loss: 2.9012e-04 - val_loss: 2.8162e-04
 - val_f1: 0.9999
Epoch 27/300
 - 81s - loss: 2.9893e-04 - val_loss: 2.8732e-04
 - val_f1: 0.9998
Epoch 28/300
 - 81s - loss: 3.0162e-04 - val_loss: 2.8234e-04
 - val_f1: 0.9998
Epoch 29/300
 - 81s - loss: 2.9341e-04 - val_loss: 2.6665e-04
 - val_f1: 0.9998
Epoch 30/300
 - 81s - loss: 2.7934e-04 - val_loss: 3.0330e-04
 - val_f1: 0.9998
Epoch 31/300
 - 81s - loss: 2.8126e-04 - val_loss: 2.6513e-04
2019-12-21 23:59:36,417 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 81s - loss: 2.8791e-04 - val_loss: 2.3980e-04
 - val_f1: 0.9999
Epoch 33/300
 - 81s - loss: 2.8091e-04 - val_loss: 2.9638e-04
 - val_f1: 0.9998
Epoch 34/300
 - 81s - loss: 2.8536e-04 - val_loss: 2.6035e-04
 - val_f1: 0.9998
Epoch 35/300
 - 81s - loss: 2.7783e-04 - val_loss: 2.5099e-04
 - val_f1: 0.9999
Epoch 36/300
 - 81s - loss: 2.8316e-04 - val_loss: 2.6489e-04
 - val_f1: 0.9998
Epoch 37/300
 - 81s - loss: 2.7700e-04 - val_loss: 2.6554e-04
 - val_f1: 0.9998
Epoch 38/300
 - 81s - loss: 2.7289e-04 - val_loss: 2.6211e-04
 - val_f1: 0.9999
Epoch 39/300
 - 81s - loss: 2.7378e-04 - val_loss: 2.4534e-04
 - val_f1: 0.9998
Epoch 40/300
 - 81s - loss: 2.7559e-04 - val_loss: 2.7099e-04
 - val_f1: 0.9999
Epoch 41/300
 - 81s - loss: 2.8214e-04 - val_loss: 2.4979e-04
 - val_f1: 0.9998
Epoch 42/300
 - 81s - loss: 2.6716e-04 - val_loss: 2.5831e-04
 - val_f1: 0.9998
Epoch 43/300
 - 81s - loss: 2.6865e-04 - val_loss: 2.7308e-04
 - val_f1: 0.9999
Epoch 44/300
 - 81s - loss: 2.7769e-04 - val_loss: 2.6187e-04
 - val_f1: 0.9998
Epoch 45/300
 - 81s - loss: 2.6976e-04 - val_loss: 2.5788e-04
 - val_f1: 0.9998
Epoch 46/300
 - 81s - loss: 2.5533e-04 - val_loss: 2.7495e-04
 - val_f1: 0.9998
Epoch 47/300
 - 81s - loss: 2.6014e-04 - val_loss: 2.9502e-04
 - val_f1: 0.9999
Epoch 48/300
 - 81s - loss: 2.7043e-04 - val_loss: 2.6770e-04
 - val_f1: 0.9998
Epoch 49/300
 - 81s - loss: 2.5870e-04 - val_loss: 2.7868e-04
 - val_f1: 0.9999
Epoch 50/300
 - 81s - loss: 2.6387e-04 - val_loss: 2.6664e-04
 - val_f1: 0.9999
Epoch 51/300
 - 81s - loss: 2.6686e-04 - val_loss: 2.4747e-04
 - val_f1: 0.9999
Epoch 52/300
 - 81s - loss: 2.6384e-04 - val_loss: 2.7281e-04
 - val_f1: 0.9998
Epoch 53/300
 - 81s - loss: 2.6378e-04 - val_loss: 2.6101e-04
 - val_f1: 0.9999
Epoch 54/300
 - 81s - loss: 2.6017e-04 - val_loss: 3.6441e-04
 - val_f1: 0.9998
Epoch 55/300
 - 81s - loss: 2.5207e-04 - val_loss: 2.5398e-04
 - val_f1: 0.9999
Epoch 56/300
 - 81s - loss: 2.5821e-04 - val_loss: 2.7552e-04
 - val_f1: 0.9999
Epoch 57/300
 - 81s - loss: 2.5899e-04 - val_loss: 3.1234e-04
 - val_f1: 0.9998
Epoch 58/300
 - 81s - loss: 2.5437e-04 - val_loss: 2.7275e-04
 - val_f1: 0.9998
Epoch 59/300
 - 81s - loss: 2.5265e-04 - val_loss: 2.3233e-04
 - val_f1: 0.9999
Epoch 60/300
 - 81s - loss: 2.6581e-04 - val_loss: 2.4685e-04
 - val_f1: 0.9999
Epoch 61/300
 - 81s - loss: 2.6080e-04 - val_loss: 2.4602e-04
2019-12-22 00:54:03,042 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 81s - loss: 2.4423e-04 - val_loss: 2.6376e-04
 - val_f1: 0.9998
Epoch 63/300
 - 81s - loss: 2.4745e-04 - val_loss: 2.4119e-04
 - val_f1: 0.9999
Epoch 64/300
 - 81s - loss: 2.5203e-04 - val_loss: 2.5985e-04
 - val_f1: 0.9999
Epoch 65/300
 - 81s - loss: 2.4997e-04 - val_loss: 2.5132e-04
 - val_f1: 0.9999
Epoch 66/300
 - 81s - loss: 2.5755e-04 - val_loss: 3.0297e-04
 - val_f1: 0.9998
Epoch 67/300
 - 81s - loss: 2.4175e-04 - val_loss: 2.7618e-04
 - val_f1: 0.9998
Epoch 68/300
 - 81s - loss: 2.4370e-04 - val_loss: 2.5414e-04
 - val_f1: 0.9999
Epoch 69/300
 - 81s - loss: 2.5063e-04 - val_loss: 2.7152e-04
 - val_f1: 0.9998
Epoch 70/300
 - 81s - loss: 2.4793e-04 - val_loss: 2.9308e-04
 - val_f1: 0.9998
Epoch 71/300
 - 81s - loss: 2.5202e-04 - val_loss: 2.5282e-04
 - val_f1: 0.9999
Epoch 72/300
 - 81s - loss: 2.4701e-04 - val_loss: 2.5624e-04
 - val_f1: 0.9999
Epoch 73/300
 - 81s - loss: 2.4240e-04 - val_loss: 2.3285e-04
 - val_f1: 0.9999
Epoch 74/300
 - 81s - loss: 2.4430e-04 - val_loss: 2.5450e-04
 - val_f1: 0.9999
Epoch 75/300
 - 81s - loss: 2.3931e-04 - val_loss: 2.5292e-04
 - val_f1: 0.9998
Epoch 76/300
 - 81s - loss: 2.4392e-04 - val_loss: 2.3785e-04
 - val_f1: 0.9999
Epoch 77/300
 - 81s - loss: 2.4099e-04 - val_loss: 2.6275e-04
 - val_f1: 0.9999
Epoch 78/300
 - 81s - loss: 2.4745e-04 - val_loss: 2.4739e-04
 - val_f1: 0.9999
Epoch 79/300
 - 81s - loss: 2.4626e-04 - val_loss: 2.6333e-04
 - val_f1: 0.9999
Epoch 80/300
 - 81s - loss: 2.3529e-04 - val_loss: 2.6283e-04
 - val_f1: 0.9999
Epoch 81/300
 - 81s - loss: 2.3594e-04 - val_loss: 2.5407e-04
 - val_f1: 0.9999
Epoch 82/300
 - 81s - loss: 2.4014e-04 - val_loss: 2.6098e-04
 - val_f1: 0.9999
Epoch 83/300
 - 81s - loss: 2.4871e-04 - val_loss: 2.4148e-04
 - val_f1: 0.9999
Epoch 84/300
 - 81s - loss: 2.4026e-04 - val_loss: 2.9504e-04
 - val_f1: 0.9999
Epoch 85/300
 - 81s - loss: 2.3836e-04 - val_loss: 2.8707e-04
 - val_f1: 0.9999
Epoch 86/300
 - 81s - loss: 2.3781e-04 - val_loss: 2.5966e-04
 - val_f1: 0.9999
Epoch 87/300
 - 81s - loss: 2.3872e-04 - val_loss: 2.4152e-04
 - val_f1: 0.9999
Epoch 88/300
 - 81s - loss: 2.3650e-04 - val_loss: 2.9595e-04
 - val_f1: 0.9999
Epoch 89/300
 - 81s - loss: 2.2854e-04 - val_loss: 2.5593e-04
 - val_f1: 0.9999
Epoch 90/300
 - 81s - loss: 2.4052e-04 - val_loss: 2.4968e-04
 - val_f1: 0.9999
Epoch 91/300
 - 81s - loss: 2.3519e-04 - val_loss: 2.6326e-04
2019-12-22 01:48:32,940 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9999
Epoch 92/300
 - 81s - loss: 2.4104e-04 - val_loss: 2.3667e-04
 - val_f1: 0.9999
Epoch 93/300
 - 81s - loss: 2.3630e-04 - val_loss: 2.6284e-04
 - val_f1: 0.9999
Epoch 94/300
 - 81s - loss: 2.4131e-04 - val_loss: 2.5357e-04
 - val_f1: 0.9999
Epoch 95/300
 - 81s - loss: 2.3091e-04 - val_loss: 2.7012e-04
 - val_f1: 0.9999
Epoch 96/300
 - 81s - loss: 2.3345e-04 - val_loss: 2.7239e-04
 - val_f1: 0.9999
Epoch 97/300
 - 81s - loss: 2.3092e-04 - val_loss: 2.4173e-04
 - val_f1: 0.9999
Epoch 98/300
 - 81s - loss: 2.3757e-04 - val_loss: 2.4769e-04
 - val_f1: 0.9999
Epoch 99/300
 - 81s - loss: 2.3489e-04 - val_loss: 2.6019e-04
 - val_f1: 0.9999
Epoch 100/300
 - 81s - loss: 2.3298e-04 - val_loss: 3.1477e-04
 - val_f1: 0.9998
Epoch 101/300
 - 81s - loss: 2.3578e-04 - val_loss: 2.5170e-04
 - val_f1: 0.9999
Epoch 102/300
 - 81s - loss: 2.2668e-04 - val_loss: 2.3492e-04
 - val_f1: 0.9999
Epoch 103/300
 - 81s - loss: 2.2993e-04 - val_loss: 2.6674e-04
 - val_f1: 0.9998
Epoch 104/300
 - 81s - loss: 2.3744e-04 - val_loss: 2.3037e-04
 - val_f1: 0.9999
Epoch 105/300
 - 81s - loss: 2.4282e-04 - val_loss: 2.4818e-04
 - val_f1: 0.9999
Epoch 106/300
 - 81s - loss: 2.3228e-04 - val_loss: 2.3219e-04
 - val_f1: 0.9999
Epoch 107/300
 - 81s - loss: 2.3573e-04 - val_loss: 2.3111e-04
 - val_f1: 0.9999
Epoch 108/300
 - 81s - loss: 2.3088e-04 - val_loss: 2.6046e-04
 - val_f1: 0.9999
Epoch 109/300
 - 81s - loss: 2.3339e-04 - val_loss: 2.5912e-04
 - val_f1: 0.9999
Epoch 110/300
 - 81s - loss: 2.4326e-04 - val_loss: 2.6589e-04
 - val_f1: 0.9999
Epoch 111/300
 - 81s - loss: 2.2730e-04 - val_loss: 2.6063e-04
 - val_f1: 0.9999
Epoch 112/300
 - 81s - loss: 2.4398e-04 - val_loss: 2.6466e-04
 - val_f1: 0.9999
Epoch 113/300
 - 81s - loss: 2.3659e-04 - val_loss: 2.5081e-04
 - val_f1: 0.9999
Epoch 114/300
 - 81s - loss: 2.2916e-04 - val_loss: 2.5519e-04
 - val_f1: 0.9999
Epoch 115/300
 - 81s - loss: 2.2629e-04 - val_loss: 2.5806e-04
 - val_f1: 0.9999
Epoch 116/300
 - 81s - loss: 2.2875e-04 - val_loss: 2.5827e-04
 - val_f1: 0.9999
Epoch 117/300
 - 81s - loss: 2.2724e-04 - val_loss: 2.4646e-04
 - val_f1: 0.9999
Epoch 118/300
 - 81s - loss: 2.3365e-04 - val_loss: 2.3963e-04
 - val_f1: 0.9999
Epoch 119/300
 - 81s - loss: 2.2571e-04 - val_loss: 2.2449e-04
 - val_f1: 0.9999
Epoch 120/300
 - 81s - loss: 2.3034e-04 - val_loss: 2.5264e-04
 - val_f1: 0.9999
Epoch 121/300
 - 81s - loss: 2.3101e-04 - val_loss: 2.5737e-04
2019-12-22 02:43:06,138 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9999
Epoch 122/300
 - 81s - loss: 2.2275e-04 - val_loss: 2.6633e-04
 - val_f1: 0.9999
Epoch 123/300
 - 81s - loss: 2.3206e-04 - val_loss: 2.6504e-04
 - val_f1: 0.9999
Epoch 124/300
 - 81s - loss: 2.3373e-04 - val_loss: 2.3526e-04
 - val_f1: 0.9999
Epoch 125/300
 - 81s - loss: 2.2928e-04 - val_loss: 2.3566e-04
 - val_f1: 0.9999
Epoch 126/300
 - 81s - loss: 2.1940e-04 - val_loss: 2.2880e-04
 - val_f1: 0.9999
Epoch 127/300
 - 81s - loss: 2.3064e-04 - val_loss: 2.4214e-04
 - val_f1: 0.9999
Epoch 128/300
 - 81s - loss: 2.3287e-04 - val_loss: 2.2439e-04
 - val_f1: 0.9999
Epoch 129/300
 - 81s - loss: 2.1910e-04 - val_loss: 2.4301e-04
 - val_f1: 0.9999
Epoch 130/300
 - 81s - loss: 2.2702e-04 - val_loss: 2.3197e-04
 - val_f1: 0.9999
Epoch 131/300
 - 81s - loss: 2.2626e-04 - val_loss: 2.7413e-04
 - val_f1: 0.9999
Epoch 132/300
 - 81s - loss: 2.2816e-04 - val_loss: 2.4515e-04
 - val_f1: 0.9999
Epoch 133/300
 - 81s - loss: 2.2473e-04 - val_loss: 2.5123e-04
 - val_f1: 0.9999
Epoch 134/300
 - 81s - loss: 2.2396e-04 - val_loss: 2.9354e-04
 - val_f1: 0.9999
Epoch 135/300
 - 81s - loss: 2.2147e-04 - val_loss: 2.7301e-04
 - val_f1: 0.9999
Epoch 136/300
 - 81s - loss: 2.2542e-04 - val_loss: 2.4912e-04
 - val_f1: 0.9999
Epoch 137/300
 - 81s - loss: 2.2963e-04 - val_loss: 2.4180e-04
 - val_f1: 0.9999
Epoch 138/300
 - 81s - loss: 2.2575e-04 - val_loss: 2.5187e-04
 - val_f1: 0.9998
Epoch 139/300
 - 81s - loss: 2.1719e-04 - val_loss: 2.5175e-04
 - val_f1: 0.9999
Epoch 140/300
 - 81s - loss: 2.3291e-04 - val_loss: 2.2882e-04
 - val_f1: 0.9999
Epoch 141/300
 - 81s - loss: 2.1826e-04 - val_loss: 2.3667e-04
 - val_f1: 0.9999
Epoch 142/300
 - 81s - loss: 2.2121e-04 - val_loss: 2.8709e-04
 - val_f1: 0.9998
Epoch 143/300
 - 81s - loss: 2.2661e-04 - val_loss: 2.3688e-04
 - val_f1: 0.9999
Epoch 144/300
 - 81s - loss: 2.2537e-04 - val_loss: 2.5280e-04
 - val_f1: 0.9999
Epoch 145/300
 - 81s - loss: 2.2845e-04 - val_loss: 2.2421e-04
 - val_f1: 0.9999
Epoch 146/300
 - 81s - loss: 2.2557e-04 - val_loss: 2.4165e-04
 - val_f1: 0.9999
Epoch 147/300
 - 81s - loss: 2.2397e-04 - val_loss: 2.4653e-04
 - val_f1: 0.9999
Epoch 148/300
 - 81s - loss: 2.2116e-04 - val_loss: 2.4649e-04
 - val_f1: 0.9999
Epoch 149/300
 - 81s - loss: 2.2290e-04 - val_loss: 2.4585e-04
 - val_f1: 0.9999
Epoch 150/300
 - 81s - loss: 2.2515e-04 - val_loss: 2.5784e-04
 - val_f1: 0.9998
Epoch 151/300
 - 81s - loss: 2.2156e-04 - val_loss: 2.4075e-04
2019-12-22 03:37:39,549 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9999
Epoch 152/300
 - 81s - loss: 2.2674e-04 - val_loss: 2.1894e-04
 - val_f1: 0.9999
Epoch 153/300
 - 81s - loss: 2.2229e-04 - val_loss: 2.7771e-04
 - val_f1: 0.9999
Epoch 154/300
 - 81s - loss: 2.2376e-04 - val_loss: 2.3216e-04
 - val_f1: 0.9999
Epoch 155/300
 - 81s - loss: 2.2215e-04 - val_loss: 2.4559e-04
 - val_f1: 0.9999
Epoch 156/300
 - 81s - loss: 2.2005e-04 - val_loss: 2.4683e-04
 - val_f1: 0.9999
Epoch 157/300
 - 81s - loss: 2.2079e-04 - val_loss: 2.4620e-04
 - val_f1: 0.9998
Epoch 158/300
 - 81s - loss: 2.2551e-04 - val_loss: 2.6481e-04
 - val_f1: 0.9999
Epoch 159/300
 - 81s - loss: 2.2615e-04 - val_loss: 2.3078e-04
 - val_f1: 0.9999
Epoch 160/300
 - 81s - loss: 2.1389e-04 - val_loss: 2.5379e-04
 - val_f1: 0.9999
Epoch 161/300
 - 81s - loss: 2.2044e-04 - val_loss: 2.3826e-04
 - val_f1: 0.9999
Epoch 162/300
 - 81s - loss: 2.1550e-04 - val_loss: 2.3239e-04
 - val_f1: 0.9999
Epoch 163/300
 - 81s - loss: 2.2364e-04 - val_loss: 2.4247e-04
 - val_f1: 0.9999
Epoch 164/300
 - 81s - loss: 2.2417e-04 - val_loss: 2.4567e-04
 - val_f1: 0.9999
Epoch 165/300
 - 81s - loss: 2.2147e-04 - val_loss: 2.4232e-04
 - val_f1: 0.9999
Epoch 166/300
 - 81s - loss: 2.2605e-04 - val_loss: 2.1923e-04
 - val_f1: 0.9999
Epoch 167/300
 - 81s - loss: 2.2236e-04 - val_loss: 2.4978e-04
 - val_f1: 0.9999
Epoch 168/300
 - 81s - loss: 2.1595e-04 - val_loss: 2.3735e-04
 - val_f1: 0.9999
Epoch 169/300
 - 81s - loss: 2.2558e-04 - val_loss: 2.5183e-04
 - val_f1: 0.9999
Epoch 170/300
 - 81s - loss: 2.2551e-04 - val_loss: 2.3542e-04
 - val_f1: 0.9999
Epoch 171/300
 - 81s - loss: 2.1566e-04 - val_loss: 2.2109e-04
 - val_f1: 0.9999
Epoch 172/300
 - 81s - loss: 2.2087e-04 - val_loss: 2.5112e-04
 - val_f1: 0.9999
Epoch 173/300
 - 81s - loss: 2.1891e-04 - val_loss: 2.2427e-04
 - val_f1: 0.9999
Epoch 174/300
 - 81s - loss: 2.1411e-04 - val_loss: 2.3016e-04
 - val_f1: 0.9999
Epoch 175/300
 - 81s - loss: 2.2161e-04 - val_loss: 2.7358e-04
 - val_f1: 0.9999
Epoch 176/300
 - 81s - loss: 2.1486e-04 - val_loss: 2.4264e-04
 - val_f1: 0.9999
Epoch 177/300
 - 81s - loss: 2.1471e-04 - val_loss: 2.5579e-04
 - val_f1: 0.9999
Epoch 178/300
 - 81s - loss: 2.2896e-04 - val_loss: 2.5876e-04
 - val_f1: 0.9999
Epoch 179/300
 - 81s - loss: 2.1160e-04 - val_loss: 2.9953e-04
 - val_f1: 0.9999
Epoch 180/300
 - 81s - loss: 2.1533e-04 - val_loss: 2.2313e-04
 - val_f1: 0.9999
Epoch 181/300
 - 81s - loss: 2.1365e-04 - val_loss: 2.4160e-04
2019-12-22 04:32:15,521 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9999
Epoch 182/300
 - 81s - loss: 2.0669e-04 - val_loss: 2.3439e-04
 - val_f1: 0.9999
Epoch 183/300
 - 81s - loss: 2.1572e-04 - val_loss: 2.4032e-04
 - val_f1: 0.9999
Epoch 184/300
 - 81s - loss: 2.2533e-04 - val_loss: 2.4131e-04
 - val_f1: 0.9999
Epoch 185/300
 - 81s - loss: 2.1453e-04 - val_loss: 2.5847e-04
 - val_f1: 0.9999
Epoch 186/300
 - 81s - loss: 2.1867e-04 - val_loss: 2.5472e-04
 - val_f1: 0.9999
Epoch 187/300
 - 81s - loss: 2.1538e-04 - val_loss: 2.3176e-04
 - val_f1: 0.9999
Epoch 188/300
 - 81s - loss: 2.1506e-04 - val_loss: 2.2924e-04
 - val_f1: 0.9999
Epoch 189/300
 - 81s - loss: 2.1205e-04 - val_loss: 2.7086e-04
 - val_f1: 0.9999
Epoch 190/300
 - 81s - loss: 2.2102e-04 - val_loss: 2.3722e-04
 - val_f1: 0.9999
Epoch 191/300
 - 81s - loss: 2.0495e-04 - val_loss: 2.4146e-04
 - val_f1: 0.9999
Epoch 192/300
 - 81s - loss: 2.1594e-04 - val_loss: 2.6304e-04
 - val_f1: 0.9999
Epoch 193/300
 - 81s - loss: 2.1608e-04 - val_loss: 2.5224e-04
 - val_f1: 0.9999
Epoch 194/300
 - 81s - loss: 2.2107e-04 - val_loss: 2.3061e-04
 - val_f1: 0.9999
Epoch 195/300
 - 81s - loss: 2.1896e-04 - val_loss: 2.2694e-04
 - val_f1: 0.9999
Epoch 196/300
 - 81s - loss: 2.1545e-04 - val_loss: 2.9529e-04
 - val_f1: 0.9999
Epoch 197/300
 - 81s - loss: 2.0960e-04 - val_loss: 2.3444e-04
 - val_f1: 0.9999
Epoch 198/300
 - 81s - loss: 2.1231e-04 - val_loss: 2.1805e-04
 - val_f1: 0.9999
Epoch 199/300
 - 81s - loss: 2.1101e-04 - val_loss: 2.2742e-04
 - val_f1: 0.9999
Epoch 200/300
 - 81s - loss: 2.2058e-04 - val_loss: 2.1794e-04
 - val_f1: 0.9999
Epoch 201/300
 - 81s - loss: 2.1413e-04 - val_loss: 2.4832e-04
 - val_f1: 0.9999
Epoch 202/300
 - 81s - loss: 2.1603e-04 - val_loss: 2.2940e-04
 - val_f1: 0.9999
Epoch 203/300
 - 81s - loss: 2.2135e-04 - val_loss: 2.2653e-04
 - val_f1: 0.9999
Epoch 204/300
 - 81s - loss: 2.1232e-04 - val_loss: 2.2189e-04
 - val_f1: 0.9999
Epoch 205/300
 - 81s - loss: 2.1771e-04 - val_loss: 2.1997e-04
 - val_f1: 0.9999
Epoch 206/300
 - 81s - loss: 2.2034e-04 - val_loss: 2.1686e-04
 - val_f1: 0.9999
Epoch 207/300
 - 81s - loss: 2.1299e-04 - val_loss: 2.1896e-04
 - val_f1: 0.9999
Epoch 208/300
 - 81s - loss: 2.1464e-04 - val_loss: 2.4052e-04
 - val_f1: 0.9999
Epoch 209/300
 - 81s - loss: 2.1291e-04 - val_loss: 2.2634e-04
 - val_f1: 0.9999
Epoch 210/300
 - 81s - loss: 2.0945e-04 - val_loss: 2.2359e-04
 - val_f1: 0.9999
Epoch 211/300
 - 81s - loss: 2.1011e-04 - val_loss: 2.0916e-04
2019-12-22 05:26:47,820 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9999
Epoch 212/300
 - 81s - loss: 2.0611e-04 - val_loss: 2.2621e-04
 - val_f1: 0.9999
Epoch 213/300
 - 81s - loss: 2.1440e-04 - val_loss: 2.3426e-04
 - val_f1: 0.9999
Epoch 214/300
 - 81s - loss: 2.1119e-04 - val_loss: 2.4962e-04
 - val_f1: 0.9999
Epoch 215/300
 - 81s - loss: 2.0816e-04 - val_loss: 2.4024e-04
 - val_f1: 0.9999
Epoch 216/300
 - 81s - loss: 2.1742e-04 - val_loss: 2.2951e-04
 - val_f1: 0.9999
Epoch 217/300
 - 81s - loss: 2.1194e-04 - val_loss: 2.1843e-04
 - val_f1: 0.9999
Epoch 218/300
 - 81s - loss: 2.1392e-04 - val_loss: 2.2133e-04
 - val_f1: 0.9999
Epoch 219/300
 - 81s - loss: 2.1230e-04 - val_loss: 2.1860e-04
 - val_f1: 0.9999
Epoch 220/300
 - 81s - loss: 2.2193e-04 - val_loss: 2.4379e-04
 - val_f1: 0.9999
Epoch 221/300
 - 81s - loss: 2.1128e-04 - val_loss: 2.3056e-04
 - val_f1: 0.9999
Epoch 222/300
 - 81s - loss: 2.0666e-04 - val_loss: 2.5758e-04
 - val_f1: 0.9999
Epoch 223/300
 - 81s - loss: 2.1076e-04 - val_loss: 2.3339e-04
 - val_f1: 0.9999
Epoch 224/300
 - 81s - loss: 2.0905e-04 - val_loss: 2.2405e-04
 - val_f1: 0.9999
Epoch 225/300
 - 81s - loss: 2.0523e-04 - val_loss: 2.3209e-04
 - val_f1: 0.9999
Epoch 226/300
 - 81s - loss: 2.1621e-04 - val_loss: 2.1881e-04
 - val_f1: 0.9999
Epoch 227/300
 - 81s - loss: 2.1149e-04 - val_loss: 2.3077e-04
 - val_f1: 0.9999
Epoch 228/300
 - 81s - loss: 2.0918e-04 - val_loss: 2.2851e-04
 - val_f1: 0.9999
Epoch 229/300
 - 81s - loss: 2.2454e-04 - val_loss: 2.3311e-04
 - val_f1: 0.9999
Epoch 230/300
 - 81s - loss: 2.0848e-04 - val_loss: 2.5671e-04
 - val_f1: 0.9998
Epoch 231/300
 - 81s - loss: 2.0985e-04 - val_loss: 2.3497e-04
 - val_f1: 0.9999
Epoch 232/300
 - 81s - loss: 2.0757e-04 - val_loss: 2.5069e-04
 - val_f1: 0.9999
Epoch 233/300
 - 81s - loss: 2.1014e-04 - val_loss: 2.4061e-04
 - val_f1: 0.9999
Epoch 234/300
 - 81s - loss: 2.1594e-04 - val_loss: 2.3779e-04
 - val_f1: 0.9999
Epoch 235/300
 - 81s - loss: 2.0284e-04 - val_loss: 2.2895e-04
 - val_f1: 0.9999
Epoch 236/300
 - 81s - loss: 2.0907e-04 - val_loss: 2.2608e-04
 - val_f1: 0.9999
Epoch 237/300
 - 81s - loss: 2.0725e-04 - val_loss: 2.3784e-04
 - val_f1: 0.9999
Epoch 238/300
 - 81s - loss: 2.0249e-04 - val_loss: 2.4417e-04
 - val_f1: 0.9999
Epoch 239/300
 - 81s - loss: 2.0947e-04 - val_loss: 2.1776e-04
 - val_f1: 0.9999
Epoch 240/300
 - 81s - loss: 2.1494e-04 - val_loss: 2.2029e-04
 - val_f1: 0.9999
Epoch 241/300
 - 81s - loss: 2.0304e-04 - val_loss: 2.3843e-04
2019-12-22 06:21:19,796 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_ann_deep_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9999
Epoch 242/300
 - 81s - loss: 2.0536e-04 - val_loss: 2.8783e-04
 - val_f1: 0.9999
Epoch 243/300
 - 81s - loss: 2.0649e-04 - val_loss: 2.1478e-04
 - val_f1: 0.9999
Epoch 244/300
 - 81s - loss: 2.0620e-04 - val_loss: 2.2169e-04
 - val_f1: 0.9999
Epoch 245/300
 - 81s - loss: 2.1613e-04 - val_loss: 2.3075e-04
 - val_f1: 0.9999
Epoch 246/300
 - 81s - loss: 2.0910e-04 - val_loss: 2.5030e-04
 - val_f1: 0.9999
Epoch 247/300
 - 81s - loss: 2.0049e-04 - val_loss: 2.2184e-04
 - val_f1: 0.9999
Epoch 248/300
 - 81s - loss: 2.0735e-04 - val_loss: 2.5390e-04
 - val_f1: 0.9999
Epoch 249/300
 - 81s - loss: 2.1583e-04 - val_loss: 2.2596e-04
 - val_f1: 0.9999
Epoch 250/300
 - 81s - loss: 2.1342e-04 - val_loss: 2.3130e-04
 - val_f1: 0.9999
Epoch 251/300
 - 81s - loss: 2.1320e-04 - val_loss: 2.3003e-04
 - val_f1: 0.9999
Epoch 252/300
 - 81s - loss: 2.0399e-04 - val_loss: 2.3053e-04
 - val_f1: 0.9999
Epoch 253/300
 - 81s - loss: 2.1005e-04 - val_loss: 2.2889e-04
 - val_f1: 0.9999
Epoch 254/300
 - 81s - loss: 2.0679e-04 - val_loss: 2.1994e-04
 - val_f1: 0.9999
Epoch 255/300
 - 81s - loss: 2.1718e-04 - val_loss: 2.3226e-04
 - val_f1: 0.9999
Epoch 256/300
 - 81s - loss: 2.1669e-04 - val_loss: 2.1753e-04
 - val_f1: 0.9999
Epoch 257/300
 - 81s - loss: 2.0949e-04 - val_loss: 2.1492e-04
 - val_f1: 0.9999
Epoch 258/300
 - 81s - loss: 2.0221e-04 - val_loss: 2.3243e-04
 - val_f1: 0.9999
Epoch 259/300
 - 81s - loss: 2.0705e-04 - val_loss: 2.2046e-04
 - val_f1: 0.9999
Epoch 260/300
 - 81s - loss: 2.0751e-04 - val_loss: 2.3003e-04
 - val_f1: 0.9999
Epoch 261/300
 - 81s - loss: 2.1321e-04 - val_loss: 2.4446e-04
2019-12-22 06:58:10,512 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 07:00:31,208 [INFO] Last epoch loss evaluation: train_loss = 0.000156, val_loss = 0.000209
2019-12-22 07:00:31,208 [INFO] Training complete. time_to_train = 28700.60 sec, 478.34 min
2019-12-22 07:00:31,217 [INFO] Model saved to results_selected_models/selected_kdd99_ann_deep_rep5/best_model.pickle
2019-12-22 07:00:31,709 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep5/training_error_history.png
2019-12-22 07:00:31,832 [INFO] Plot saved to: results_selected_models/selected_kdd99_ann_deep_rep5/training_f1_history.png
2019-12-22 07:00:31,833 [INFO] Making predictions on training, validation, testing data
2019-12-22 07:02:59,160 [INFO] Evaluating predictions (results)
2019-12-22 07:03:03,824 [INFO] Dataset: Testing. Classification report below
2019-12-22 07:03:03,825 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.73      0.80      0.77      4166
         r2l       0.88      0.02      0.04     13781
         u2r       0.59      0.01      0.02      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.79      0.56      0.53    311029
weighted avg       0.93      0.92      0.90    311029

2019-12-22 07:03:03,825 [INFO] Overall accuracy (micro avg): 0.9232515296001338
2019-12-22 07:03:09,267 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9233         0.9233                       0.9233                0.0192                   0.0767  0.9233
1     Macro avg        0.9693         0.7868                       0.5581                0.0194                   0.4419  0.5296
2  Weighted avg        0.9684         0.9338                       0.9233                0.0202                   0.0767  0.9040
2019-12-22 07:03:25,657 [INFO] Dataset: Validation. Classification report below
2019-12-22 07:03:25,657 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      1.00      1.00      8221
         r2l       0.92      0.90      0.91       225
         u2r       0.57      0.40      0.47        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.90      0.86      0.88    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-22 07:03:25,657 [INFO] Overall accuracy (micro avg): 0.9998754704308621
2019-12-22 07:03:44,278 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.8983                       0.8585                0.0000                   0.1415  0.8754
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-22 07:04:56,149 [INFO] Dataset: Training. Classification report below
2019-12-22 07:04:56,149 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      1.00      1.00     32881
         r2l       0.91      0.94      0.92       901
         u2r       0.93      0.64      0.76        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.97      0.92      0.94   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-22 07:04:56,149 [INFO] Overall accuracy (micro avg): 0.9998984368460915
2019-12-22 07:06:17,904 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9675                       0.9153                0.0000                   0.0847  0.9360
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-22 07:06:17,985 [INFO] Results saved to: results_selected_models/selected_kdd99_ann_deep_rep5/selected_kdd99_ann_deep_rep5_results.xlsx
2019-12-22 07:06:17,992 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-22 07:06:18,260 [INFO] Created directory: results_selected_models/selected_ids18_subset_ann_deep_rep1
2019-12-22 07:06:18,274 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ann_deep_rep1/run_log.log
2019-12-22 07:06:18,274 [INFO] ================= Running experiment no. 1  ================= 

2019-12-22 07:06:18,274 [INFO] Experiment parameters given below
2019-12-22 07:06:18,274 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ann_deep_rep1'}
2019-12-22 07:06:18,275 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ann_deep_rep1/tf_logs_run_2019_12_22-07_06_18
2019-12-22 07:06:18,275 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 07:06:18,289 [INFO] Reading X, y files
2019-12-22 07:06:18,289 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 07:06:24,541 [INFO] Reading complete. time_to_read=6.25 seconds
2019-12-22 07:06:24,542 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 07:06:26,206 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-22 07:06:26,209 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 07:06:27,894 [INFO] Reading complete. time_to_read=1.68 seconds
2019-12-22 07:06:27,894 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 07:06:28,526 [INFO] Reading complete. time_to_read=0.63 seconds
2019-12-22 07:06:28,526 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 07:06:28,712 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-22 07:06:28,712 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 07:06:28,890 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-22 07:06:32,776 [INFO] Initializing model
2019-12-22 07:06:33,151 [INFO] _________________________________________________________________
2019-12-22 07:06:33,151 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 07:06:33,151 [INFO] =================================================================
2019-12-22 07:06:33,151 [INFO] dense_46 (Dense)             (None, 128)               9984      
2019-12-22 07:06:33,151 [INFO] _________________________________________________________________
2019-12-22 07:06:33,151 [INFO] batch_normalization_36 (Batc (None, 128)               512       
2019-12-22 07:06:33,151 [INFO] _________________________________________________________________
2019-12-22 07:06:33,151 [INFO] dropout_36 (Dropout)         (None, 128)               0         
2019-12-22 07:06:33,151 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dense_47 (Dense)             (None, 64)                8256      
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] batch_normalization_37 (Batc (None, 64)                256       
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dropout_37 (Dropout)         (None, 64)                0         
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dense_48 (Dense)             (None, 32)                2080      
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] batch_normalization_38 (Batc (None, 32)                128       
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dropout_38 (Dropout)         (None, 32)                0         
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dense_49 (Dense)             (None, 16)                528       
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] batch_normalization_39 (Batc (None, 16)                64        
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,152 [INFO] dropout_39 (Dropout)         (None, 16)                0         
2019-12-22 07:06:33,152 [INFO] _________________________________________________________________
2019-12-22 07:06:33,153 [INFO] dense_50 (Dense)             (None, 15)                255       
2019-12-22 07:06:33,153 [INFO] =================================================================
2019-12-22 07:06:33,153 [INFO] Total params: 22,063
2019-12-22 07:06:33,153 [INFO] Trainable params: 21,583
2019-12-22 07:06:33,153 [INFO] Non-trainable params: 480
2019-12-22 07:06:33,153 [INFO] _________________________________________________________________
2019-12-22 07:06:33,153 [INFO] Training model
 - val_f1: 0.9999
Epoch 00261: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/300
 - 45s - loss: 0.0162 - val_loss: 0.0087
 - val_f1: 0.9801
Epoch 2/300
 - 44s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9809
Epoch 3/300
 - 44s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9823
Epoch 4/300
 - 44s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 5/300
 - 44s - loss: 0.0086 - val_loss: 0.0122
 - val_f1: 0.9703
Epoch 6/300
 - 44s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 7/300
 - 44s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 8/300
 - 44s - loss: 0.0084 - val_loss: 0.0961
 - val_f1: 0.8327
Epoch 9/300
 - 44s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 10/300
 - 44s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 11/300
 - 44s - loss: 0.0083 - val_loss: 0.0166
 - val_f1: 0.9640
Epoch 12/300
 - 44s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 13/300
 - 44s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 14/300
 - 44s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 15/300
 - 44s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 16/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 17/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 18/300
 - 44s - loss: 0.0082 - val_loss: 0.0118
 - val_f1: 0.9735
Epoch 19/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 20/300
 - 44s - loss: 0.0082 - val_loss: 0.0105
 - val_f1: 0.9768
Epoch 21/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 22/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 23/300
 - 44s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 24/300
 - 44s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 25/300
 - 44s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 26/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 27/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 28/300
 - 44s - loss: 0.0081 - val_loss: 0.0098
 - val_f1: 0.9792
Epoch 29/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 30/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 31/300
 - 44s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 07:38:38,617 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9829
Epoch 32/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 33/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 34/300
 - 44s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 35/300
 - 44s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9829
Epoch 36/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 37/300
 - 44s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 38/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 39/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 40/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 41/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 42/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9829
Epoch 43/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 44/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 45/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 46/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 47/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 48/300
 - 44s - loss: 0.0080 - val_loss: 0.0288
 - val_f1: 0.9028
Epoch 49/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 50/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 51/300
 - 44s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 52/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 53/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9813
Epoch 54/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 55/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 56/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 57/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 58/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 59/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 60/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 61/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
2019-12-22 08:09:55,965 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9835
Epoch 62/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 63/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 64/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 65/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9838
Epoch 66/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 67/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 68/300
 - 44s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9825
Epoch 69/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 70/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 71/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 72/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 73/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 74/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 75/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 76/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 77/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 78/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 79/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 80/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 81/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 82/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 83/300
 - 44s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9838
Epoch 84/300
 - 44s - loss: 0.0080 - val_loss: 0.0307
 - val_f1: 0.9123
Epoch 85/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 86/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 87/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 88/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 89/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 90/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 91/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
2019-12-22 08:41:11,449 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9837
Epoch 92/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 93/300
 - 44s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9800
Epoch 94/300
 - 44s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9828
Epoch 95/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 96/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 97/300
 - 44s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 98/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 99/300
 - 44s - loss: 0.0079 - val_loss: 0.0204
 - val_f1: 0.9561
Epoch 100/300
 - 44s - loss: 0.0079 - val_loss: 0.0805
 - val_f1: 0.8430
Epoch 101/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 102/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 103/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 104/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 105/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 106/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 107/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 108/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 109/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 110/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 111/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 112/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 113/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 114/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 115/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 116/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 117/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 118/300
 - 44s - loss: 0.0079 - val_loss: 0.0160
 - val_f1: 0.9628
Epoch 119/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 120/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 121/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
2019-12-22 09:12:29,037 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9838
Epoch 122/300
 - 44s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9829
Epoch 123/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 124/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 125/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 126/300
 - 44s - loss: 0.0079 - val_loss: 0.0138
 - val_f1: 0.9675
Epoch 127/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 128/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 129/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 130/300
 - 44s - loss: 0.0079 - val_loss: 0.0366
 - val_f1: 0.8906
Epoch 131/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 132/300
 - 44s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9813
Epoch 133/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 134/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 135/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 136/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 137/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 138/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 139/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 140/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 141/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 142/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 143/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 144/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 145/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 146/300
 - 44s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9830
Epoch 147/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 148/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 149/300
 - 44s - loss: 0.0079 - val_loss: 0.0381
 - val_f1: 0.9200
Epoch 150/300
 - 44s - loss: 0.0079 - val_loss: 0.0159
 - val_f1: 0.9665
Epoch 151/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
2019-12-22 09:43:45,783 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9838
Epoch 152/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 153/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 154/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 155/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 156/300
 - 44s - loss: 0.0079 - val_loss: 0.0256
 - val_f1: 0.9452
Epoch 157/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 158/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 159/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 160/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 161/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 162/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 163/300
 - 44s - loss: 0.0079 - val_loss: 0.0422
 - val_f1: 0.9096
Epoch 164/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 165/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 166/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 167/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9830
Epoch 168/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 169/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 170/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 171/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 172/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 173/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 174/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 175/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 176/300
 - 44s - loss: 0.0079 - val_loss: 0.0296
 - val_f1: 0.9281
Epoch 177/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 178/300
 - 44s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9828
Epoch 179/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 180/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 181/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
2019-12-22 10:15:03,148 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9837
Epoch 182/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 183/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 184/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 185/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 186/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 187/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 188/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 189/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 190/300
 - 44s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 191/300
 - 44s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9830
Epoch 192/300
 - 44s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9823
Epoch 193/300
 - 44s - loss: 0.0078 - val_loss: 0.0195
 - val_f1: 0.9564
Epoch 194/300
 - 44s - loss: 0.0079 - val_loss: 0.0229
 - val_f1: 0.9538
Epoch 195/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 196/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 197/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 198/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 199/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 200/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 201/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 202/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 203/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 204/300
 - 44s - loss: 0.0078 - val_loss: 0.0207
 - val_f1: 0.9602
Epoch 205/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 206/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 207/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 208/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 209/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 210/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 211/300
 - 44s - loss: 0.0078 - val_loss: 0.0256
2019-12-22 10:46:19,339 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9370
Epoch 212/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 213/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 214/300
 - 44s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 215/300
 - 44s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 216/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 217/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9830
Epoch 218/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 219/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 220/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 221/300
 - 44s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9827
Epoch 222/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 223/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 224/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 225/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9830
Epoch 226/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 227/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 228/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 229/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 230/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 231/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 232/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 233/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 234/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 235/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 236/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 237/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 238/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 239/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 240/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 241/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 11:17:36,994 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9838
Epoch 242/300
 - 44s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9840
Epoch 243/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 244/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 245/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 246/300
 - 44s - loss: 0.0078 - val_loss: 0.0277
 - val_f1: 0.9032
Epoch 247/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 248/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 249/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 250/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 251/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 252/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 253/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 254/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 255/300
 - 44s - loss: 0.0078 - val_loss: 0.0267
 - val_f1: 0.9280
Epoch 256/300
 - 44s - loss: 0.0078 - val_loss: 0.0137
 - val_f1: 0.9701
Epoch 257/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 258/300
 - 44s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9839
Epoch 259/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 260/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 261/300
 - 44s - loss: 0.0078 - val_loss: 0.0691
 - val_f1: 0.8735
Epoch 262/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 263/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 264/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 265/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 266/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 267/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 268/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 269/300
 - 44s - loss: 0.0078 - val_loss: 0.0195
 - val_f1: 0.9420
Epoch 270/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 271/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 11:48:53,848 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9839
Epoch 272/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 273/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 274/300
 - 44s - loss: 0.0078 - val_loss: 0.0102
 - val_f1: 0.9782
Epoch 275/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 276/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 277/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 278/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 279/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 280/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 281/300
 - 44s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9841
Epoch 282/300
 - 44s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9839
Epoch 283/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 284/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 285/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 286/300
 - 44s - loss: 0.0078 - val_loss: 0.0188
 - val_f1: 0.9619
Epoch 287/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 288/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 289/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 290/300
 - 44s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 291/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 292/300
 - 44s - loss: 0.0078 - val_loss: 0.0468
 - val_f1: 0.8734
Epoch 293/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 294/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 295/300
 - 44s - loss: 0.0078 - val_loss: 0.0094
 - val_f1: 0.9793
Epoch 296/300
 - 44s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9829
Epoch 297/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 298/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 299/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 300/300
 - 44s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 12:19:27,471 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 12:20:47,763 [INFO] Last epoch loss evaluation: train_loss = 0.007474, val_loss = 0.007511
2019-12-22 12:20:47,763 [INFO] Training complete. time_to_train = 18854.61 sec, 314.24 min
2019-12-22 12:20:47,774 [INFO] Model saved to results_selected_models/selected_ids18_subset_ann_deep_rep1/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-22 12:20:47,931 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep1/training_error_history.png
2019-12-22 12:20:48,067 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep1/training_f1_history.png
2019-12-22 12:20:48,067 [INFO] Making predictions on training, validation, testing data
2019-12-22 12:22:16,965 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 12:22:29,125 [INFO] Dataset: Testing. Classification report below
2019-12-22 12:22:29,126 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.21      0.34        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.73      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.85      0.73      0.73    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 12:22:29,129 [INFO] Overall accuracy (micro avg): 0.9839671690256054
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-22 12:22:42,937 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8548                       0.7274                0.0044                   0.2726  0.7346
2  Weighted avg        0.9912         0.9815                       0.9840                0.0494                   0.0160  0.9788
2019-12-22 12:22:55,126 [INFO] Dataset: Validation. Classification report below
2019-12-22 12:22:55,126 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.28      0.44        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.56      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.85      0.75      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 12:22:55,126 [INFO] Overall accuracy (micro avg): 0.9840786878744266
2019-12-22 12:23:08,983 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9841         0.9841                       0.9841                0.0011                   0.0159  0.9841
1     Macro avg        0.9979         0.8466                       0.7542                0.0043                   0.2458  0.7628
2  Weighted avg        0.9913         0.9799                       0.9841                0.0492                   0.0159  0.9789
2019-12-22 12:23:48,614 [INFO] Dataset: Training. Classification report below
2019-12-22 12:23:48,614 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.26      0.41        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.82       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.70      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.86      0.74      0.75   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 12:23:48,614 [INFO] Overall accuracy (micro avg): 0.9840373836408873
2019-12-22 12:24:33,603 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8553                       0.7414                0.0044                   0.2586  0.7514
2  Weighted avg        0.9913         0.9814                       0.9840                0.0493                   0.0160  0.9789
2019-12-22 12:24:33,630 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ann_deep_rep1/selected_ids18_subset_ann_deep_rep1_results.xlsx
2019-12-22 12:24:33,635 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-22 12:24:33,719 [INFO] Created directory: results_selected_models/selected_ids18_subset_ann_deep_rep2
2019-12-22 12:24:33,719 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ann_deep_rep2/run_log.log
2019-12-22 12:24:33,719 [INFO] ================= Running experiment no. 2  ================= 

2019-12-22 12:24:33,719 [INFO] Experiment parameters given below
2019-12-22 12:24:33,719 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids18_subset_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ann_deep_rep2'}
2019-12-22 12:24:33,719 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ann_deep_rep2/tf_logs_run_2019_12_22-12_24_33
2019-12-22 12:24:33,720 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 12:24:33,720 [INFO] Reading X, y files
2019-12-22 12:24:33,720 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 12:24:38,261 [INFO] Reading complete. time_to_read=4.54 seconds
2019-12-22 12:24:38,261 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 12:24:39,829 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-22 12:24:39,829 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 12:24:41,398 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-22 12:24:41,398 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 12:24:41,641 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-22 12:24:41,641 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 12:24:41,735 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-22 12:24:41,735 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 12:24:41,822 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-22 12:24:45,770 [INFO] Initializing model
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 12:24:46,165 [INFO] =================================================================
2019-12-22 12:24:46,165 [INFO] dense_51 (Dense)             (None, 128)               9984      
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] batch_normalization_40 (Batc (None, 128)               512       
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] dropout_40 (Dropout)         (None, 128)               0         
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] dense_52 (Dense)             (None, 64)                8256      
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] batch_normalization_41 (Batc (None, 64)                256       
2019-12-22 12:24:46,165 [INFO] _________________________________________________________________
2019-12-22 12:24:46,165 [INFO] dropout_41 (Dropout)         (None, 64)                0         
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] dense_53 (Dense)             (None, 32)                2080      
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] batch_normalization_42 (Batc (None, 32)                128       
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] dropout_42 (Dropout)         (None, 32)                0         
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] dense_54 (Dense)             (None, 16)                528       
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] batch_normalization_43 (Batc (None, 16)                64        
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] dropout_43 (Dropout)         (None, 16)                0         
2019-12-22 12:24:46,166 [INFO] _________________________________________________________________
2019-12-22 12:24:46,166 [INFO] dense_55 (Dense)             (None, 15)                255       
2019-12-22 12:24:46,166 [INFO] =================================================================
2019-12-22 12:24:46,167 [INFO] Total params: 22,063
2019-12-22 12:24:46,167 [INFO] Trainable params: 21,583
2019-12-22 12:24:46,167 [INFO] Non-trainable params: 480
2019-12-22 12:24:46,167 [INFO] _________________________________________________________________
2019-12-22 12:24:46,167 [INFO] Training model
 - val_f1: 0.9838
Train on 1936462 samples, validate on 645487 samples
Epoch 1/300
 - 45s - loss: 0.0164 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 2/300
 - 44s - loss: 0.0092 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 3/300
 - 45s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9824
Epoch 4/300
 - 45s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 5/300
 - 45s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 6/300
 - 45s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 7/300
 - 45s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 8/300
 - 45s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 9/300
 - 45s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 10/300
 - 45s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 11/300
 - 45s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 12/300
 - 45s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 13/300
 - 45s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 14/300
 - 45s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9819
Epoch 15/300
 - 45s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 16/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 17/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 18/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 19/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 20/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 21/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 22/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 23/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 24/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 25/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 26/300
 - 45s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 27/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 28/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 29/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 30/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 31/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
2019-12-22 12:57:50,999 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9833
Epoch 32/300
 - 45s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 33/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 34/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 35/300
 - 45s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 36/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 37/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 38/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 39/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 40/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 41/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 42/300
 - 45s - loss: 0.0080 - val_loss: 0.0732
 - val_f1: 0.8443
Epoch 43/300
 - 45s - loss: 0.0080 - val_loss: 0.0126
 - val_f1: 0.9714
Epoch 44/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 45/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 46/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 47/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 48/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 49/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 50/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 51/300
 - 45s - loss: 0.0080 - val_loss: 0.0550
 - val_f1: 0.8458
Epoch 52/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 53/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 54/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 55/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 56/300
 - 45s - loss: 0.0080 - val_loss: 0.0640
 - val_f1: 0.8445
Epoch 57/300
 - 45s - loss: 0.0080 - val_loss: 0.0658
 - val_f1: 0.8393
Epoch 58/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 59/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 60/300
 - 45s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9793
Epoch 61/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
2019-12-22 13:30:09,914 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9833
Epoch 62/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9831
Epoch 63/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 64/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 65/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 66/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 67/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 68/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 69/300
 - 45s - loss: 0.0080 - val_loss: 0.0586
 - val_f1: 0.8427
Epoch 70/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 71/300
 - 45s - loss: 0.0080 - val_loss: 0.0743
 - val_f1: 0.8409
Epoch 72/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 73/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 74/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 75/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 76/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 77/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 78/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 79/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 80/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 81/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9831
Epoch 82/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 83/300
 - 45s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9826
Epoch 84/300
 - 45s - loss: 0.0080 - val_loss: 0.0640
 - val_f1: 0.8346
Epoch 85/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 86/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 87/300
 - 45s - loss: 0.0079 - val_loss: 0.0084
 - val_f1: 0.9806
Epoch 88/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 89/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 90/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 91/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
2019-12-22 14:02:26,527 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9835
Epoch 92/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 93/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 94/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 95/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 96/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 97/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 98/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 99/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 100/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 101/300
 - 45s - loss: 0.0079 - val_loss: 0.0125
 - val_f1: 0.9687
Epoch 102/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 103/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 104/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 105/300
 - 45s - loss: 0.0079 - val_loss: 0.0310
 - val_f1: 0.8850
Epoch 106/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 107/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 108/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 109/300
 - 45s - loss: 0.0079 - val_loss: 0.0114
 - val_f1: 0.9787
Epoch 110/300
 - 45s - loss: 0.0079 - val_loss: 0.0166
 - val_f1: 0.9566
Epoch 111/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9833
Epoch 112/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 113/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 114/300
 - 45s - loss: 0.0079 - val_loss: 0.0421
 - val_f1: 0.8880
Epoch 115/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 116/300
 - 45s - loss: 0.0079 - val_loss: 0.0208
 - val_f1: 0.9489
Epoch 117/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 118/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 119/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 120/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 121/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
2019-12-22 14:34:35,821 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9838
Epoch 122/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 123/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 124/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 125/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 126/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 127/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 128/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 129/300
 - 45s - loss: 0.0079 - val_loss: 0.0333
 - val_f1: 0.9099
Epoch 130/300
 - 45s - loss: 0.0079 - val_loss: 0.0713
 - val_f1: 0.8454
Epoch 131/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 132/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 133/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 134/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 135/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 136/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 137/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 138/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 139/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 140/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 141/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9831
Epoch 142/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 143/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 144/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 145/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 146/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 147/300
 - 45s - loss: 0.0079 - val_loss: 0.0229
 - val_f1: 0.9446
Epoch 148/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 149/300
 - 45s - loss: 0.0079 - val_loss: 0.0336
 - val_f1: 0.9071
Epoch 150/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 151/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
2019-12-22 15:06:42,419 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9839
Epoch 152/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 153/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 154/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 155/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 156/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 157/300
 - 45s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9813
Epoch 158/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 159/300
 - 45s - loss: 0.0078 - val_loss: 0.0385
 - val_f1: 0.9080
Epoch 160/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 161/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 162/300
 - 45s - loss: 0.0078 - val_loss: 0.0316
 - val_f1: 0.8915
Epoch 163/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 164/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 165/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 166/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 167/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 168/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 169/300
 - 45s - loss: 0.0079 - val_loss: 0.0300
 - val_f1: 0.9186
Epoch 170/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 171/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 172/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 173/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 174/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 175/300
 - 45s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9826
Epoch 176/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 177/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 178/300
 - 45s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 179/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 180/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 181/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
2019-12-22 15:38:50,937 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9832
Epoch 182/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 183/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 184/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 185/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 186/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 187/300
 - 45s - loss: 0.0078 - val_loss: 0.0100
 - val_f1: 0.9714
Epoch 188/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 189/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 190/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 191/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 192/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 193/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 194/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 195/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 196/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 197/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 198/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9833
Epoch 199/300
 - 45s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9810
Epoch 200/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 201/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 202/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 203/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 204/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 205/300
 - 45s - loss: 0.0078 - val_loss: 0.0436
 - val_f1: 0.9082
Epoch 206/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 207/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 208/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 209/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 210/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 211/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 16:10:58,910 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9836
Epoch 212/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 213/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 214/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 215/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 216/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 217/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 218/300
 - 45s - loss: 0.0078 - val_loss: 0.0458
 - val_f1: 0.9105
Epoch 219/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 220/300
 - 45s - loss: 0.0078 - val_loss: 0.0160
 - val_f1: 0.9579
Epoch 221/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 222/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 223/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 224/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 225/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 226/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 227/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 228/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 229/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 230/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 231/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 232/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 233/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 234/300
 - 45s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9840
Epoch 235/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 236/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 237/300
 - 45s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 238/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 239/300
 - 45s - loss: 0.0078 - val_loss: 0.0121
 - val_f1: 0.9720
Epoch 240/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 241/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 16:43:07,294 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9838
Epoch 242/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 243/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 244/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 245/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 246/300
 - 45s - loss: 0.0078 - val_loss: 0.0144
 - val_f1: 0.9702
Epoch 247/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 248/300
 - 45s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 249/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 250/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 251/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 252/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 253/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 254/300
 - 45s - loss: 0.0078 - val_loss: 0.0136
 - val_f1: 0.9668
Epoch 255/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 256/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 257/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 258/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 259/300
 - 45s - loss: 0.0078 - val_loss: 0.0425
 - val_f1: 0.9146
Epoch 260/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 261/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 262/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 263/300
 - 45s - loss: 0.0078 - val_loss: 0.0652
 - val_f1: 0.8636
Epoch 264/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 265/300
 - 45s - loss: 0.0078 - val_loss: 0.0364
 - val_f1: 0.9031
Epoch 266/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 267/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 268/300
 - 45s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9840
Epoch 269/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 270/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 271/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 17:15:13,796 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9835
Epoch 272/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 273/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 274/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 275/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 276/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 277/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 278/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 279/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 280/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 281/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 282/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 283/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 284/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 285/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 286/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 287/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 288/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 289/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 290/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 291/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 292/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 293/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 294/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 295/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 296/300
 - 45s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9807
Epoch 297/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 298/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9841
Epoch 299/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 300/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
2019-12-22 17:46:35,555 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 17:48:00,367 [INFO] Last epoch loss evaluation: train_loss = 0.007491, val_loss = 0.007529
2019-12-22 17:48:00,367 [INFO] Training complete. time_to_train = 19394.20 sec, 323.24 min
2019-12-22 17:48:00,376 [INFO] Model saved to results_selected_models/selected_ids18_subset_ann_deep_rep2/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-22 17:48:00,583 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep2/training_error_history.png
2019-12-22 17:48:00,725 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep2/training_f1_history.png
2019-12-22 17:48:00,725 [INFO] Making predictions on training, validation, testing data
2019-12-22 17:49:35,777 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 17:49:47,912 [INFO] Dataset: Testing. Classification report below
2019-12-22 17:49:47,913 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.83      0.21      0.33        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.97      0.99      0.98       440
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.43      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.82      0.73      0.73    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 17:49:47,913 [INFO] Overall accuracy (micro avg): 0.9839160449148551
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-22 17:50:01,747 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.8237                       0.7283                0.0043                   0.2717  0.7349
2  Weighted avg        0.9912         0.9786                       0.9839                0.0490                   0.0161  0.9789
2019-12-22 17:50:13,949 [INFO] Dataset: Validation. Classification report below
2019-12-22 17:50:13,950 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.28      0.44        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.76      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.89      0.79      7718
           Infilteration       0.41      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.84      0.76      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 17:50:13,950 [INFO] Overall accuracy (micro avg): 0.9840012269805589
2019-12-22 17:50:27,815 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8357                       0.7556                0.0043                   0.2444  0.7632
2  Weighted avg        0.9912         0.9785                       0.9840                0.0489                   0.0160  0.9790
2019-12-22 17:51:07,496 [INFO] Dataset: Training. Classification report below
2019-12-22 17:51:07,496 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.95      0.26      0.41        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.76      0.51      0.61     16787
   DoS attacks-Slowloris       0.96      1.00      0.98      1318
          FTP-BruteForce       0.71      0.88      0.79     23153
           Infilteration       0.50      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.74      0.75   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 17:51:07,496 [INFO] Overall accuracy (micro avg): 0.9840120797619576
2019-12-22 17:51:52,462 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0011                   0.0160  0.9840
1     Macro avg        0.9979         0.8378                       0.7428                0.0043                   0.2572  0.7523
2  Weighted avg        0.9913         0.9794                       0.9840                0.0488                   0.0160  0.9790
2019-12-22 17:51:52,490 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ann_deep_rep2/selected_ids18_subset_ann_deep_rep2_results.xlsx
2019-12-22 17:51:52,495 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-22 17:51:52,578 [INFO] Created directory: results_selected_models/selected_ids18_subset_ann_deep_rep3
2019-12-22 17:51:52,578 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ann_deep_rep3/run_log.log
2019-12-22 17:51:52,578 [INFO] ================= Running experiment no. 3  ================= 

2019-12-22 17:51:52,578 [INFO] Experiment parameters given below
2019-12-22 17:51:52,578 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids18_subset_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ann_deep_rep3'}
2019-12-22 17:51:52,578 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ann_deep_rep3/tf_logs_run_2019_12_22-17_51_52
2019-12-22 17:51:52,578 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 17:51:52,579 [INFO] Reading X, y files
2019-12-22 17:51:52,579 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 17:51:57,444 [INFO] Reading complete. time_to_read=4.87 seconds
2019-12-22 17:51:57,444 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 17:51:59,225 [INFO] Reading complete. time_to_read=1.78 seconds
2019-12-22 17:51:59,225 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 17:52:01,034 [INFO] Reading complete. time_to_read=1.81 seconds
2019-12-22 17:52:01,034 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 17:52:01,312 [INFO] Reading complete. time_to_read=0.28 seconds
2019-12-22 17:52:01,312 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 17:52:01,445 [INFO] Reading complete. time_to_read=0.13 seconds
2019-12-22 17:52:01,445 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 17:52:01,567 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-22 17:52:05,485 [INFO] Initializing model
2019-12-22 17:52:05,850 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 17:52:05,851 [INFO] =================================================================
2019-12-22 17:52:05,851 [INFO] dense_56 (Dense)             (None, 128)               9984      
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] batch_normalization_44 (Batc (None, 128)               512       
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] dropout_44 (Dropout)         (None, 128)               0         
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] dense_57 (Dense)             (None, 64)                8256      
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] batch_normalization_45 (Batc (None, 64)                256       
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] dropout_45 (Dropout)         (None, 64)                0         
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] dense_58 (Dense)             (None, 32)                2080      
2019-12-22 17:52:05,851 [INFO] _________________________________________________________________
2019-12-22 17:52:05,851 [INFO] batch_normalization_46 (Batc (None, 32)                128       
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,852 [INFO] dropout_46 (Dropout)         (None, 32)                0         
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,852 [INFO] dense_59 (Dense)             (None, 16)                528       
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,852 [INFO] batch_normalization_47 (Batc (None, 16)                64        
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,852 [INFO] dropout_47 (Dropout)         (None, 16)                0         
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,852 [INFO] dense_60 (Dense)             (None, 15)                255       
2019-12-22 17:52:05,852 [INFO] =================================================================
2019-12-22 17:52:05,852 [INFO] Total params: 22,063
2019-12-22 17:52:05,852 [INFO] Trainable params: 21,583
2019-12-22 17:52:05,852 [INFO] Non-trainable params: 480
2019-12-22 17:52:05,852 [INFO] _________________________________________________________________
2019-12-22 17:52:05,853 [INFO] Training model
 - val_f1: 0.9840
Train on 1936462 samples, validate on 645487 samples
Epoch 1/300
 - 46s - loss: 0.0169 - val_loss: 0.0085
 - val_f1: 0.9807
Epoch 2/300
 - 45s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9809
Epoch 3/300
 - 45s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 4/300
 - 45s - loss: 0.0087 - val_loss: 0.0246
 - val_f1: 0.9371
Epoch 5/300
 - 45s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 6/300
 - 45s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 7/300
 - 45s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 8/300
 - 45s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 9/300
 - 45s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 10/300
 - 45s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 11/300
 - 45s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 12/300
 - 45s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 13/300
 - 45s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 14/300
 - 45s - loss: 0.0083 - val_loss: 0.0360
 - val_f1: 0.8806
Epoch 15/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 16/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 17/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 18/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 19/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 20/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 21/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 22/300
 - 45s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9825
Epoch 23/300
 - 45s - loss: 0.0082 - val_loss: 0.0734
 - val_f1: 0.8461
Epoch 24/300
 - 45s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 25/300
 - 45s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 26/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 27/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 28/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 29/300
 - 45s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 30/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 31/300
 - 45s - loss: 0.0081 - val_loss: 0.0445
2019-12-22 18:25:52,816 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.8894
Epoch 32/300
 - 45s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 33/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 34/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 35/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 36/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 37/300
 - 45s - loss: 0.0081 - val_loss: 0.0725
 - val_f1: 0.8421
Epoch 38/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 39/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 40/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 41/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9811
Epoch 42/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 43/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 44/300
 - 45s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 45/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 46/300
 - 45s - loss: 0.0080 - val_loss: 0.0676
 - val_f1: 0.8555
Epoch 47/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 48/300
 - 45s - loss: 0.0080 - val_loss: 0.0093
 - val_f1: 0.9802
Epoch 49/300
 - 45s - loss: 0.0081 - val_loss: 0.0458
 - val_f1: 0.8660
Epoch 50/300
 - 45s - loss: 0.0080 - val_loss: 0.0271
 - val_f1: 0.9289
Epoch 51/300
 - 45s - loss: 0.0080 - val_loss: 0.0492
 - val_f1: 0.8674
Epoch 52/300
 - 45s - loss: 0.0080 - val_loss: 0.0243
 - val_f1: 0.9270
Epoch 53/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 54/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 55/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 56/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 57/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 58/300
 - 45s - loss: 0.0080 - val_loss: 0.0167
 - val_f1: 0.9525
Epoch 59/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 60/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 61/300
 - 45s - loss: 0.0080 - val_loss: 0.0326
2019-12-22 18:58:58,667 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.8928
Epoch 62/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 63/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 64/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 65/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 66/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 67/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 68/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 69/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 70/300
 - 45s - loss: 0.0080 - val_loss: 0.0295
 - val_f1: 0.9380
Epoch 71/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 72/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 73/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 74/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 75/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 76/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 77/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 78/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 79/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 80/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9831
Epoch 81/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 82/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 83/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 84/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 85/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 86/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 87/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 88/300
 - 45s - loss: 0.0079 - val_loss: 0.0119
 - val_f1: 0.9692
Epoch 89/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 90/300
 - 45s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 91/300
 - 45s - loss: 0.0080 - val_loss: 0.0080
2019-12-22 19:32:04,477 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9829
Epoch 92/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 93/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 94/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 95/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 96/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 97/300
 - 45s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 98/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 99/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 100/300
 - 45s - loss: 0.0079 - val_loss: 0.0123
 - val_f1: 0.9634
Epoch 101/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 102/300
 - 45s - loss: 0.0079 - val_loss: 0.0152
 - val_f1: 0.9587
Epoch 103/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 104/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 105/300
 - 45s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9806
Epoch 106/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 107/300
 - 45s - loss: 0.0079 - val_loss: 0.0149
 - val_f1: 0.9542
Epoch 108/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 109/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 110/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 111/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 112/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 113/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 114/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 115/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 116/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 117/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 118/300
 - 45s - loss: 0.0079 - val_loss: 0.0234
 - val_f1: 0.9340
Epoch 119/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 120/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 121/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
2019-12-22 20:05:09,687 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9837
Epoch 122/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 123/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 124/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 125/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 126/300
 - 45s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 127/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 128/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 129/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 130/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 131/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 132/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 133/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 134/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 135/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 136/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 137/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 138/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 139/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 140/300
 - 45s - loss: 0.0079 - val_loss: 0.0271
 - val_f1: 0.9290
Epoch 141/300
 - 45s - loss: 0.0079 - val_loss: 0.0253
 - val_f1: 0.9089
Epoch 142/300
 - 45s - loss: 0.0079 - val_loss: 0.0209
 - val_f1: 0.9262
Epoch 143/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 144/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 145/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 146/300
 - 45s - loss: 0.0079 - val_loss: 0.0263
 - val_f1: 0.8894
Epoch 147/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 148/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 149/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 150/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 151/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
2019-12-22 20:38:15,243 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9838
Epoch 152/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 153/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 154/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 155/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 156/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 157/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 158/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 159/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 160/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 161/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 162/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 163/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 164/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 165/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 166/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 167/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 168/300
 - 45s - loss: 0.0079 - val_loss: 0.0422
 - val_f1: 0.9014
Epoch 169/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 170/300
 - 45s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 171/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 172/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 173/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 174/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 175/300
 - 45s - loss: 0.0079 - val_loss: 0.0268
 - val_f1: 0.9074
Epoch 176/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 177/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 178/300
 - 45s - loss: 0.0078 - val_loss: 0.0244
 - val_f1: 0.8997
Epoch 179/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 180/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 181/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
2019-12-22 21:11:21,356 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9831
Epoch 182/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 183/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 184/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 185/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9833
Epoch 186/300
 - 45s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 187/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 188/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 189/300
 - 45s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9826
Epoch 190/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 191/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 192/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 193/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 194/300
 - 45s - loss: 0.0079 - val_loss: 0.0102
 - val_f1: 0.9763
Epoch 195/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 196/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 197/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 198/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 199/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 200/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 201/300
 - 45s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 202/300
 - 45s - loss: 0.0078 - val_loss: 0.0239
 - val_f1: 0.9113
Epoch 203/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 204/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 205/300
 - 45s - loss: 0.0078 - val_loss: 0.0108
 - val_f1: 0.9769
Epoch 206/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 207/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 208/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 209/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 210/300
 - 45s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 211/300
 - 45s - loss: 0.0078 - val_loss: 0.0078
2019-12-22 21:44:27,226 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9834
Epoch 212/300
 - 45s - loss: 0.0078 - val_loss: 0.0237
 - val_f1: 0.9359
Epoch 213/300
 - 45s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 214/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 215/300
 - 45s - loss: 0.0078 - val_loss: 0.0121
 - val_f1: 0.9634
Epoch 216/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 217/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 218/300
 - 45s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 219/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 220/300
 - 45s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 221/300
 - 45s - loss: 0.0078 - val_loss: 0.0250
 - val_f1: 0.9122
Epoch 222/300
 - 45s - loss: 0.0078 - val_loss: 0.0106
2019-12-22 21:56:56,209 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 21:58:23,341 [INFO] Last epoch loss evaluation: train_loss = 0.007564, val_loss = 0.007598
2019-12-22 21:58:23,341 [INFO] Training complete. time_to_train = 14777.49 sec, 246.29 min
2019-12-22 21:58:23,355 [INFO] Model saved to results_selected_models/selected_ids18_subset_ann_deep_rep3/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-22 21:58:23,491 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep3/training_error_history.png
2019-12-22 21:58:23,624 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep3/training_f1_history.png
2019-12-22 21:58:23,624 [INFO] Making predictions on training, validation, testing data
2019-12-22 22:00:06,764 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 22:00:18,962 [INFO] Dataset: Testing. Classification report below
2019-12-22 22:00:18,962 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.80      0.33      0.47        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.39      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.82      0.74      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 22:00:18,962 [INFO] Overall accuracy (micro avg): 0.9837611233671268
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-22 22:00:32,817 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.8170                       0.7359                0.0043                   0.2641  0.7431
2  Weighted avg        0.9911         0.9780                       0.9838                0.0489                   0.0162  0.9788
2019-12-22 22:00:44,978 [INFO] Dataset: Validation. Classification report below
2019-12-22 22:00:44,978 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.92      0.48      0.63        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      0.99      0.83        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.50      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.83      0.77      0.78    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 22:00:44,978 [INFO] Overall accuracy (micro avg): 0.9838943309470214
2019-12-22 22:00:58,804 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0012                   0.0161  0.9839
1     Macro avg        0.9979         0.8349                       0.7675                0.0043                   0.2325  0.7753
2  Weighted avg        0.9912         0.9792                       0.9839                0.0487                   0.0161  0.9789
2019-12-22 22:01:38,534 [INFO] Dataset: Training. Classification report below
2019-12-22 22:01:38,534 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.93      0.37      0.53        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.51      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 22:01:38,534 [INFO] Overall accuracy (micro avg): 0.9838700681965358
2019-12-22 22:02:23,652 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0012                   0.0161  0.9839
1     Macro avg        0.9978         0.8364                       0.7492                0.0043                   0.2508  0.7598
2  Weighted avg        0.9912         0.9793                       0.9839                0.0486                   0.0161  0.9789
2019-12-22 22:02:23,688 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ann_deep_rep3/selected_ids18_subset_ann_deep_rep3_results.xlsx
2019-12-22 22:02:23,693 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-22 22:02:23,774 [INFO] Created directory: results_selected_models/selected_ids18_subset_ann_deep_rep4
2019-12-22 22:02:23,774 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ann_deep_rep4/run_log.log
2019-12-22 22:02:23,774 [INFO] ================= Running experiment no. 4  ================= 

2019-12-22 22:02:23,774 [INFO] Experiment parameters given below
2019-12-22 22:02:23,774 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids18_subset_ann_deep_rep4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ann_deep_rep4'}
2019-12-22 22:02:23,775 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ann_deep_rep4/tf_logs_run_2019_12_22-22_02_23
2019-12-22 22:02:23,775 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 22:02:23,775 [INFO] Reading X, y files
2019-12-22 22:02:23,775 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 22:02:28,344 [INFO] Reading complete. time_to_read=4.57 seconds
2019-12-22 22:02:28,344 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 22:02:29,904 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-22 22:02:29,904 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 22:02:31,465 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-22 22:02:31,465 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 22:02:31,716 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-22 22:02:31,716 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 22:02:31,803 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-22 22:02:31,803 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 22:02:31,889 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-22 22:02:35,815 [INFO] Initializing model
2019-12-22 22:02:36,175 [INFO] _________________________________________________________________
2019-12-22 22:02:36,175 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 22:02:36,175 [INFO] =================================================================
2019-12-22 22:02:36,175 [INFO] dense_61 (Dense)             (None, 128)               9984      
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] batch_normalization_48 (Batc (None, 128)               512       
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] dropout_48 (Dropout)         (None, 128)               0         
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] dense_62 (Dense)             (None, 64)                8256      
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] batch_normalization_49 (Batc (None, 64)                256       
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] dropout_49 (Dropout)         (None, 64)                0         
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] dense_63 (Dense)             (None, 32)                2080      
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] batch_normalization_50 (Batc (None, 32)                128       
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,176 [INFO] dropout_50 (Dropout)         (None, 32)                0         
2019-12-22 22:02:36,176 [INFO] _________________________________________________________________
2019-12-22 22:02:36,177 [INFO] dense_64 (Dense)             (None, 16)                528       
2019-12-22 22:02:36,177 [INFO] _________________________________________________________________
2019-12-22 22:02:36,177 [INFO] batch_normalization_51 (Batc (None, 16)                64        
2019-12-22 22:02:36,177 [INFO] _________________________________________________________________
2019-12-22 22:02:36,177 [INFO] dropout_51 (Dropout)         (None, 16)                0         
2019-12-22 22:02:36,177 [INFO] _________________________________________________________________
2019-12-22 22:02:36,177 [INFO] dense_65 (Dense)             (None, 15)                255       
2019-12-22 22:02:36,177 [INFO] =================================================================
2019-12-22 22:02:36,177 [INFO] Total params: 22,063
2019-12-22 22:02:36,177 [INFO] Trainable params: 21,583
2019-12-22 22:02:36,177 [INFO] Non-trainable params: 480
2019-12-22 22:02:36,177 [INFO] _________________________________________________________________
2019-12-22 22:02:36,177 [INFO] Training model
 - val_f1: 0.9752
Epoch 00222: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/300
 - 47s - loss: 0.0167 - val_loss: 0.0084
 - val_f1: 0.9823
Epoch 2/300
 - 46s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 3/300
 - 46s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9818
Epoch 4/300
 - 46s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9822
Epoch 5/300
 - 46s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 6/300
 - 46s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 7/300
 - 46s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 8/300
 - 46s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 9/300
 - 46s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 10/300
 - 46s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 11/300
 - 46s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 12/300
 - 46s - loss: 0.0083 - val_loss: 0.0139
 - val_f1: 0.9709
Epoch 13/300
 - 46s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9810
Epoch 14/300
 - 46s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 15/300
 - 46s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 16/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 17/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 18/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 19/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 20/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 21/300
 - 46s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 22/300
 - 46s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 23/300
 - 46s - loss: 0.0082 - val_loss: 0.0141
 - val_f1: 0.9689
Epoch 24/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 25/300
 - 46s - loss: 0.0081 - val_loss: 0.0155
 - val_f1: 0.9673
Epoch 26/300
 - 46s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 27/300
 - 46s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 28/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 29/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 30/300
 - 46s - loss: 0.0081 - val_loss: 0.0117
 - val_f1: 0.9742
Epoch 31/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
2019-12-22 22:37:25,919 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9836
Epoch 32/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 33/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 34/300
 - 46s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 35/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 36/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 37/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 38/300
 - 46s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 39/300
 - 46s - loss: 0.0081 - val_loss: 0.0212
 - val_f1: 0.9571
Epoch 40/300
 - 46s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 41/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 42/300
 - 46s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 43/300
 - 46s - loss: 0.0081 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 44/300
 - 46s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 45/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 46/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 47/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 48/300
 - 46s - loss: 0.0080 - val_loss: 0.0165
 - val_f1: 0.9586
Epoch 49/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 50/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 51/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 52/300
 - 46s - loss: 0.0080 - val_loss: 0.0098
 - val_f1: 0.9794
Epoch 53/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 54/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 55/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 56/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 57/300
 - 46s - loss: 0.0080 - val_loss: 0.0104
 - val_f1: 0.9748
Epoch 58/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 59/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 60/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 61/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
2019-12-22 23:11:30,613 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9836
Epoch 62/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 63/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 64/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 65/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 66/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 67/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 68/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 69/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 70/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 71/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 72/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 73/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 74/300
 - 46s - loss: 0.0080 - val_loss: 0.0091
 - val_f1: 0.9817
Epoch 75/300
 - 46s - loss: 0.0080 - val_loss: 0.0196
 - val_f1: 0.9361
Epoch 76/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 77/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 78/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 79/300
 - 46s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 80/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 81/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 82/300
 - 46s - loss: 0.0080 - val_loss: 0.0091
 - val_f1: 0.9803
Epoch 83/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 84/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 85/300
 - 46s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 86/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 87/300
 - 46s - loss: 0.0080 - val_loss: 0.0126
 - val_f1: 0.9661
Epoch 88/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 89/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 90/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 91/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
2019-12-22 23:45:25,148 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9837
Epoch 92/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 93/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 94/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 95/300
 - 46s - loss: 0.0079 - val_loss: 0.0133
 - val_f1: 0.9609
Epoch 96/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 97/300
 - 46s - loss: 0.0079 - val_loss: 0.0134
 - val_f1: 0.9649
Epoch 98/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 99/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 100/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 101/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 102/300
 - 46s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 103/300
 - 46s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 104/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 105/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 106/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 107/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 108/300
 - 46s - loss: 0.0079 - val_loss: 0.0110
 - val_f1: 0.9729
Epoch 109/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 110/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 111/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 112/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 113/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 114/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 115/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 116/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 117/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 118/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 119/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 120/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 121/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
2019-12-23 00:19:35,518 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9837
Epoch 122/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 123/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 124/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 125/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 126/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 127/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 128/300
 - 46s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 129/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 130/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 131/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 132/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 133/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 134/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9839
Epoch 135/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 136/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 137/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 138/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 139/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 140/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 141/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 142/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 143/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 144/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9833
Epoch 145/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 146/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 147/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 148/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 149/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 150/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 151/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
2019-12-23 00:53:56,036 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9839
Epoch 152/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 153/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 154/300
 - 46s - loss: 0.0079 - val_loss: 0.0121
 - val_f1: 0.9751
Epoch 155/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 156/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 157/300
 - 46s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 158/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 159/300
 - 46s - loss: 0.0079 - val_loss: 0.0168
 - val_f1: 0.9574
Epoch 160/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 161/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9840
Epoch 162/300
 - 46s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9795
Epoch 163/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 164/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 165/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 166/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 167/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 168/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 169/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 170/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 171/300
 - 46s - loss: 0.0079 - val_loss: 0.0160
 - val_f1: 0.9607
Epoch 172/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 173/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 174/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 175/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 176/300
 - 46s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9830
Epoch 177/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 178/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 179/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 180/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 181/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
2019-12-23 01:28:19,585 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9839
Epoch 182/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 183/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9840
Epoch 184/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 185/300
 - 46s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 186/300
 - 46s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 187/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 188/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 189/300
 - 46s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 190/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 191/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 192/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 193/300
 - 46s - loss: 0.0079 - val_loss: 0.0100
 - val_f1: 0.9793
Epoch 194/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 195/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 196/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 197/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 198/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 199/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 200/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 201/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 202/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 203/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 204/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 205/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 206/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 207/300
 - 46s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 208/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 209/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 210/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 211/300
 - 46s - loss: 0.0078 - val_loss: 0.0172
2019-12-23 02:02:44,086 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9555
Epoch 212/300
 - 46s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9799
Epoch 213/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 214/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 215/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 216/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 217/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 218/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 219/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 220/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 221/300
 - 46s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 222/300
 - 46s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 223/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 224/300
 - 46s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 225/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 226/300
 - 46s - loss: 0.0078 - val_loss: 0.0120
 - val_f1: 0.9747
Epoch 227/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 228/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 229/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 230/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 231/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 232/300
 - 46s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 233/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 234/300
 - 46s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 235/300
 - 46s - loss: 0.0078 - val_loss: 0.0161
 - val_f1: 0.9559
Epoch 236/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 237/300
 - 46s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 238/300
 - 46s - loss: 0.0078 - val_loss: 0.0077
2019-12-23 02:34:05,172 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 02:35:38,702 [INFO] Last epoch loss evaluation: train_loss = 0.007526, val_loss = 0.007569
2019-12-23 02:35:38,702 [INFO] Training complete. time_to_train = 16382.52 sec, 273.04 min
2019-12-23 02:35:38,713 [INFO] Model saved to results_selected_models/selected_ids18_subset_ann_deep_rep4/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-23 02:35:38,871 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep4/training_error_history.png
2019-12-23 02:35:38,994 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep4/training_f1_history.png
2019-12-23 02:35:38,994 [INFO] Making predictions on training, validation, testing data
2019-12-23 02:37:30,459 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 02:37:42,601 [INFO] Dataset: Testing. Classification report below
2019-12-23 02:37:42,601 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.95      0.98      0.97       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.52      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.71      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-23 02:37:42,601 [INFO] Overall accuracy (micro avg): 0.9838261904171728
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 02:37:56,406 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7056                       0.6908                0.0044                   0.3092  0.6779
2  Weighted avg        0.9912         0.9792                       0.9838                0.0491                   0.0162  0.9788
2019-12-23 02:38:08,589 [INFO] Dataset: Validation. Classification report below
2019-12-23 02:38:08,589 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.85        68
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.94      0.98      0.96       439
          FTP-BruteForce       0.72      0.87      0.78      7718
           Infilteration       0.45      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.70      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-23 02:38:08,590 [INFO] Overall accuracy (micro avg): 0.9839129215615496
2019-12-23 02:38:22,443 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.7047                       0.6903                0.0043                   0.3097  0.6803
2  Weighted avg        0.9912         0.9786                       0.9839                0.0490                   0.0161  0.9789
2019-12-23 02:39:02,221 [INFO] Dataset: Training. Classification report below
2019-12-23 02:39:02,221 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       1.00      1.00      1.00     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.96      0.99      0.97      1318
          FTP-BruteForce       0.71      0.86      0.78     23153
           Infilteration       0.54      0.00      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-23 02:39:02,221 [INFO] Overall accuracy (micro avg): 0.9839010525380824
2019-12-23 02:39:47,395 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9839         0.9839                       0.9839                0.0011                   0.0161  0.9839
1     Macro avg        0.9979         0.7090                       0.6907                0.0043                   0.3093  0.6793
2  Weighted avg        0.9912         0.9795                       0.9839                0.0490                   0.0161  0.9788
2019-12-23 02:39:47,429 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ann_deep_rep4/selected_ids18_subset_ann_deep_rep4_results.xlsx
2019-12-23 02:39:47,437 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-23 02:39:47,518 [INFO] Created directory: results_selected_models/selected_ids18_subset_ann_deep_rep5
2019-12-23 02:39:47,518 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ann_deep_rep5/run_log.log
2019-12-23 02:39:47,518 [INFO] ================= Running experiment no. 5  ================= 

2019-12-23 02:39:47,518 [INFO] Experiment parameters given below
2019-12-23 02:39:47,518 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids18_subset_ann_deep_rep5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [128, 64, 32, 16], 'ann_layer_activations': ['relu', 'relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ann_deep_rep5'}
2019-12-23 02:39:47,519 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ann_deep_rep5/tf_logs_run_2019_12_23-02_39_47
2019-12-23 02:39:47,519 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-23 02:39:47,519 [INFO] Reading X, y files
2019-12-23 02:39:47,519 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-23 02:39:52,083 [INFO] Reading complete. time_to_read=4.56 seconds
2019-12-23 02:39:52,083 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-23 02:39:53,650 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-23 02:39:53,651 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-23 02:39:55,221 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-23 02:39:55,221 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-23 02:39:55,489 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-23 02:39:55,489 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-23 02:39:55,576 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-23 02:39:55,576 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-23 02:39:55,670 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-23 02:39:59,601 [INFO] Initializing model
2019-12-23 02:39:59,967 [INFO] _________________________________________________________________
2019-12-23 02:39:59,967 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 02:39:59,967 [INFO] =================================================================
2019-12-23 02:39:59,967 [INFO] dense_66 (Dense)             (None, 128)               9984      
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] batch_normalization_52 (Batc (None, 128)               512       
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] dropout_52 (Dropout)         (None, 128)               0         
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] dense_67 (Dense)             (None, 64)                8256      
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] batch_normalization_53 (Batc (None, 64)                256       
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] dropout_53 (Dropout)         (None, 64)                0         
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] dense_68 (Dense)             (None, 32)                2080      
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] batch_normalization_54 (Batc (None, 32)                128       
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,968 [INFO] dropout_54 (Dropout)         (None, 32)                0         
2019-12-23 02:39:59,968 [INFO] _________________________________________________________________
2019-12-23 02:39:59,969 [INFO] dense_69 (Dense)             (None, 16)                528       
2019-12-23 02:39:59,969 [INFO] _________________________________________________________________
2019-12-23 02:39:59,969 [INFO] batch_normalization_55 (Batc (None, 16)                64        
2019-12-23 02:39:59,969 [INFO] _________________________________________________________________
2019-12-23 02:39:59,969 [INFO] dropout_55 (Dropout)         (None, 16)                0         
2019-12-23 02:39:59,969 [INFO] _________________________________________________________________
2019-12-23 02:39:59,969 [INFO] dense_70 (Dense)             (None, 15)                255       
2019-12-23 02:39:59,969 [INFO] =================================================================
2019-12-23 02:39:59,969 [INFO] Total params: 22,063
2019-12-23 02:39:59,969 [INFO] Trainable params: 21,583
2019-12-23 02:39:59,969 [INFO] Non-trainable params: 480
2019-12-23 02:39:59,969 [INFO] _________________________________________________________________
2019-12-23 02:39:59,969 [INFO] Training model
 - val_f1: 0.9836
Epoch 00238: early stopping
Train on 1936462 samples, validate on 645487 samples
Epoch 1/300
 - 48s - loss: 0.0165 - val_loss: 0.0088
 - val_f1: 0.9819
Epoch 2/300
 - 47s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 3/300
 - 47s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 4/300
 - 47s - loss: 0.0087 - val_loss: 0.0905
 - val_f1: 0.8522
Epoch 5/300
 - 47s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 6/300
 - 47s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 7/300
 - 47s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 8/300
 - 47s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 9/300
 - 47s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 10/300
 - 47s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 11/300
 - 47s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 12/300
 - 47s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 13/300
 - 47s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 14/300
 - 47s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 15/300
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 16/300
 - 47s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 17/300
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 18/300
 - 47s - loss: 0.0082 - val_loss: 0.0103
 - val_f1: 0.9778
Epoch 19/300
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 20/300
 - 47s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 21/300
 - 47s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 22/300
 - 47s - loss: 0.0082 - val_loss: 0.0829
 - val_f1: 0.8451
Epoch 23/300
 - 47s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 24/300
 - 47s - loss: 0.0081 - val_loss: 0.0110
 - val_f1: 0.9757
Epoch 25/300
 - 47s - loss: 0.0081 - val_loss: 0.0545
 - val_f1: 0.8674
Epoch 26/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 27/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 28/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 29/300
 - 47s - loss: 0.0081 - val_loss: 0.0110
 - val_f1: 0.9787
Epoch 30/300
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 31/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
2019-12-23 03:16:16,621 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9831
Epoch 32/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 33/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 34/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 35/300
 - 47s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 36/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 37/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 38/300
 - 47s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 39/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 40/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 41/300
 - 47s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 42/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9832
Epoch 43/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 44/300
 - 47s - loss: 0.0080 - val_loss: 0.0544
 - val_f1: 0.8765
Epoch 45/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 46/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9832
Epoch 47/300
 - 48s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 48/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 49/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9833
Epoch 50/300
 - 47s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 51/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 52/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 53/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 54/300
 - 47s - loss: 0.0080 - val_loss: 0.0939
 - val_f1: 0.8350
Epoch 55/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 56/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 57/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 58/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 59/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 60/300
 - 47s - loss: 0.0080 - val_loss: 0.0468
 - val_f1: 0.8882
Epoch 61/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
2019-12-23 03:51:43,345 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9836
Epoch 62/300
 - 47s - loss: 0.0080 - val_loss: 0.0112
 - val_f1: 0.9758
Epoch 63/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9837
Epoch 64/300
 - 47s - loss: 0.0080 - val_loss: 0.0994
 - val_f1: 0.8402
Epoch 65/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 66/300
 - 47s - loss: 0.0080 - val_loss: 0.0087
 - val_f1: 0.9805
Epoch 67/300
 - 47s - loss: 0.0080 - val_loss: 0.0101
 - val_f1: 0.9797
Epoch 68/300
 - 47s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 69/300
 - 47s - loss: 0.0080 - val_loss: 0.0643
 - val_f1: 0.8597
Epoch 70/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 71/300
 - 47s - loss: 0.0080 - val_loss: 0.0235
 - val_f1: 0.9358
Epoch 72/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 73/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 74/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 75/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 76/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 77/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 78/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 79/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 80/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 81/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 82/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 83/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 84/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 85/300
 - 47s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 86/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9834
Epoch 87/300
 - 47s - loss: 0.0079 - val_loss: 0.1010
 - val_f1: 0.8353
Epoch 88/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 89/300
 - 47s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 90/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 91/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
2019-12-23 04:27:09,090 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9837
Epoch 92/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 93/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 94/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 95/300
 - 47s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 96/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 97/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 98/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 99/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 100/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 101/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 102/300
 - 47s - loss: 0.0079 - val_loss: 0.0162
 - val_f1: 0.9638
Epoch 103/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 104/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 105/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 106/300
 - 47s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 107/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 108/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 109/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 110/300
 - 47s - loss: 0.0079 - val_loss: 0.0087
 - val_f1: 0.9811
Epoch 111/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 112/300
 - 47s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 113/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 114/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 115/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9833
Epoch 116/300
 - 47s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9836
Epoch 117/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 118/300
 - 47s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9828
Epoch 119/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 120/300
 - 47s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9827
Epoch 121/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
2019-12-23 05:02:37,379 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9838
Epoch 122/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 123/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 124/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 125/300
 - 47s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9819
Epoch 126/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 127/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 128/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 129/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 130/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 131/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 132/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 133/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 134/300
 - 47s - loss: 0.0079 - val_loss: 0.0107
 - val_f1: 0.9719
Epoch 135/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 136/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 137/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 138/300
 - 47s - loss: 0.0079 - val_loss: 0.0566
 - val_f1: 0.8625
Epoch 139/300
 - 47s - loss: 0.0079 - val_loss: 0.0589
 - val_f1: 0.8763
Epoch 140/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 141/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 142/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 143/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9835
Epoch 144/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 145/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 146/300
 - 47s - loss: 0.0079 - val_loss: 0.0842
 - val_f1: 0.8700
Epoch 147/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 148/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 149/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 150/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 151/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
2019-12-23 05:37:58,849 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9838
Epoch 152/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 153/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 154/300
 - 47s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 155/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 156/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 157/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 158/300
 - 47s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9818
Epoch 159/300
 - 47s - loss: 0.0079 - val_loss: 0.0098
 - val_f1: 0.9807
Epoch 160/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 161/300
 - 47s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 162/300
 - 47s - loss: 0.0078 - val_loss: 0.0113
 - val_f1: 0.9728
Epoch 163/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 164/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 165/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 166/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 167/300
 - 47s - loss: 0.0078 - val_loss: 0.0206
 - val_f1: 0.9390
Epoch 168/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 169/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 170/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 171/300
 - 47s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 172/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 173/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 174/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 175/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 176/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 177/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 178/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 179/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 180/300
 - 47s - loss: 0.0078 - val_loss: 0.0317
 - val_f1: 0.9196
Epoch 181/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
2019-12-23 06:13:13,264 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9837
Epoch 182/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 183/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 184/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 185/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 186/300
 - 47s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9823
Epoch 187/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 188/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 189/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 190/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 191/300
 - 47s - loss: 0.0078 - val_loss: 0.0332
 - val_f1: 0.9260
Epoch 192/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 193/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9834
Epoch 194/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 195/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 196/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 197/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 198/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 199/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 200/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 201/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 202/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 203/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 204/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 205/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 206/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 207/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 208/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 209/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 210/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 211/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
2019-12-23 06:48:27,078 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9837
Epoch 212/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 213/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 214/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 215/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 216/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 217/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 218/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9835
Epoch 219/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 220/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 221/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 222/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 223/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 224/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 225/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 226/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 227/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 228/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 229/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 230/300
 - 47s - loss: 0.0078 - val_loss: 0.0172
 - val_f1: 0.9523
Epoch 231/300
 - 47s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9808
Epoch 232/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9837
Epoch 233/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 234/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 235/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 236/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 237/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 238/300
 - 47s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 239/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 240/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 241/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
2019-12-23 07:23:41,969 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9837
Epoch 242/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 243/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 244/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 245/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 246/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 247/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 248/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 249/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 250/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 251/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 252/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 253/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 254/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 255/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 256/300
 - 47s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9821
Epoch 257/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 258/300
 - 47s - loss: 0.0078 - val_loss: 0.0105
 - val_f1: 0.9787
Epoch 259/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 260/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 261/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 262/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 263/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9838
Epoch 264/300
 - 47s - loss: 0.0078 - val_loss: 0.0193
 - val_f1: 0.9525
Epoch 265/300
 - 47s - loss: 0.0078 - val_loss: 0.0102
 - val_f1: 0.9782
Epoch 266/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 267/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 268/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 269/300
 - 47s - loss: 0.0078 - val_loss: 0.0095
 - val_f1: 0.9809
Epoch 270/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 271/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
2019-12-23 07:58:55,787 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9837
Epoch 272/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 273/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 274/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 275/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 276/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 277/300
 - 47s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 278/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 279/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 280/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 281/300
 - 47s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9834
Epoch 282/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 283/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 284/300
 - 47s - loss: 0.0078 - val_loss: 0.0111
 - val_f1: 0.9769
Epoch 285/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9837
Epoch 286/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 287/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 288/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 289/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 290/300
 - 47s - loss: 0.0078 - val_loss: 0.0211
 - val_f1: 0.9392
Epoch 291/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 292/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 293/300
 - 47s - loss: 0.0078 - val_loss: 0.0142
 - val_f1: 0.9622
Epoch 294/300
 - 47s - loss: 0.0078 - val_loss: 0.0144
 - val_f1: 0.9639
Epoch 295/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9838
Epoch 296/300
 - 47s - loss: 0.0078 - val_loss: 0.0154
 - val_f1: 0.9645
Epoch 297/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 298/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9839
Epoch 299/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
 - val_f1: 0.9836
Epoch 300/300
 - 47s - loss: 0.0078 - val_loss: 0.0076
2019-12-23 08:33:24,429 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 08:35:03,874 [INFO] Last epoch loss evaluation: train_loss = 0.007517, val_loss = 0.007562
2019-12-23 08:35:03,875 [INFO] Training complete. time_to_train = 21303.91 sec, 355.07 min
2019-12-23 08:35:03,886 [INFO] Model saved to results_selected_models/selected_ids18_subset_ann_deep_rep5/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-23 08:35:04,021 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep5/training_error_history.png
2019-12-23 08:35:04,158 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ann_deep_rep5/training_f1_history.png
2019-12-23 08:35:04,159 [INFO] Making predictions on training, validation, testing data
2019-12-23 08:36:58,046 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 08:37:10,206 [INFO] Dataset: Testing. Classification report below
2019-12-23 08:37:10,206 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.75      0.12      0.21        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.53      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.86      0.78      7718
           Infilteration       0.43      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.82      0.72      0.73    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-23 08:37:10,206 [INFO] Overall accuracy (micro avg): 0.9836759165158764
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 08:37:24,022 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.8166                       0.7216                0.0044                   0.2784  0.7261
2  Weighted avg        0.9911         0.9784                       0.9837                0.0491                   0.0163  0.9787
2019-12-23 08:37:36,160 [INFO] Dataset: Validation. Classification report below
2019-12-23 08:37:36,161 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.16      0.28        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.98      0.97       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.44      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.84      0.75      0.75    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-23 08:37:36,161 [INFO] Overall accuracy (micro avg): 0.9837889841313613
2019-12-23 08:37:49,961 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.8368                       0.7469                0.0043                   0.2531  0.7522
2  Weighted avg        0.9911         0.9786                       0.9838                0.0490                   0.0162  0.9788
2019-12-23 08:38:29,662 [INFO] Dataset: Training. Classification report below
2019-12-23 08:38:29,662 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.90      0.12      0.22        73
        Brute Force -XSS       1.00      0.46      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.51      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.83      0.73      0.74   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-23 08:38:29,662 [INFO] Overall accuracy (micro avg): 0.9837704018978942
2019-12-23 08:39:14,744 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.8337                       0.7308                0.0043                   0.2692  0.7370
2  Weighted avg        0.9911         0.9792                       0.9838                0.0489                   0.0162  0.9788
2019-12-23 08:39:14,779 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ann_deep_rep5/selected_ids18_subset_ann_deep_rep5_results.xlsx
2019-12-23 08:39:14,784 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-23 08:39:14,865 [INFO] ================= Finished running 15 experiments ================= 

 - val_f1: 0.9838
2019-12-20 17:23:53,970 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ann_deep_rep1/run_log.log
2019-12-20 17:23:53,970 [INFO] ================= Running experiment no. 1  ================= 

2019-12-20 17:23:53,970 [INFO] Experiment parameters given below
2019-12-20 17:23:53,970 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 64], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ann_deep_rep1'}
2019-12-20 17:23:53,970 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ann_deep_rep1/tf_logs_run_2019_12_20-17_23_53
2019-12-20 17:23:53,971 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-20 17:23:53,980 [INFO] Reading X, y files
2019-12-20 17:23:53,980 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-20 17:23:54,474 [INFO] Reading complete. time_to_read=0.49 seconds
2019-12-20 17:23:54,474 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-20 17:23:54,609 [INFO] Reading complete. time_to_read=0.14 seconds
2019-12-20 17:23:54,609 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-20 17:23:54,725 [INFO] Reading complete. time_to_read=0.12 seconds
2019-12-20 17:23:54,726 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-20 17:23:54,751 [INFO] Reading complete. time_to_read=0.03 seconds
2019-12-20 17:23:54,751 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-20 17:23:54,770 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-20 17:23:54,770 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-20 17:23:54,787 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-20 17:23:54,991 [INFO] Initializing model
2019-12-20 17:23:54,991 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-20 17:23:55,000 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-20 17:23:55,001 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-20 17:23:55,053 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-20 17:23:55,066 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-20 17:23:55,224 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-20 17:23:55,236 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-20 17:23:55,239 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-20 17:23:55,248 [INFO] _________________________________________________________________
2019-12-20 17:23:55,248 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 17:23:55,248 [INFO] =================================================================
2019-12-20 17:23:55,248 [INFO] dense_1 (Dense)              (None, 64)                7872      
2019-12-20 17:23:55,248 [INFO] _________________________________________________________________
2019-12-20 17:23:55,248 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2019-12-20 17:23:55,248 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] dense_2 (Dense)              (None, 32)                2080      
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] dense_3 (Dense)              (None, 64)                2112      
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2019-12-20 17:23:55,249 [INFO] _________________________________________________________________
2019-12-20 17:23:55,249 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2019-12-20 17:23:55,250 [INFO] _________________________________________________________________
2019-12-20 17:23:55,250 [INFO] dense_4 (Dense)              (None, 5)                 325       
2019-12-20 17:23:55,250 [INFO] =================================================================
2019-12-20 17:23:55,250 [INFO] Total params: 13,029
2019-12-20 17:23:55,250 [INFO] Trainable params: 12,709
2019-12-20 17:23:55,250 [INFO] Non-trainable params: 320
2019-12-20 17:23:55,250 [INFO] _________________________________________________________________
2019-12-20 17:23:55,250 [INFO] Training model
2019-12-20 17:23:58,495 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-20 17:23:58,495 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

2019-12-20 17:24:53,153 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep1/ann_model_epoch_30.pickle
2019-12-20 17:25:45,684 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep1/ann_model_epoch_60.pickle
2019-12-20 17:26:38,434 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep1/ann_model_epoch_90.pickle
2019-12-20 17:27:31,062 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep1/ann_model_epoch_120.pickle
2019-12-20 17:28:23,871 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep1/ann_model_epoch_150.pickle
2019-12-20 17:28:24,226 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 17:28:26,213 [INFO] Last epoch loss evaluation: train_loss = 0.002651, val_loss = 0.004081
2019-12-20 17:28:26,214 [INFO] Training complete. time_to_train = 270.96 sec, 4.52 min
2019-12-20 17:28:26,219 [INFO] Model saved to results_selected_models/selected_nsl_ann_deep_rep1/best_model.pickle
2019-12-20 17:28:26,412 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep1/training_error_history.png
2019-12-20 17:28:26,560 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep1/training_f1_history.png
2019-12-20 17:28:26,560 [INFO] Making predictions on training, validation, testing data
2019-12-20 17:28:28,555 [INFO] Evaluating predictions (results)
2019-12-20 17:28:28,874 [INFO] Dataset: Testing. Classification report below
2019-12-20 17:28:28,874 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.90      7458
      normal       0.68      0.97      0.80      9711
       probe       0.87      0.69      0.77      2421
         r2l       0.87      0.08      0.14      2421
         u2r       0.91      0.02      0.04       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.86      0.52      0.53     22544
weighted avg       0.82      0.78      0.74     22544

2019-12-20 17:28:28,874 [INFO] Overall accuracy (micro avg): 0.7805180979418027
2019-12-20 17:28:29,197 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7805         0.7805                       0.7805                0.0549                   0.2195  0.7805
1     Macro avg        0.9122         0.8588                       0.5198                0.0750                   0.4802  0.5294
2  Weighted avg        0.8736         0.8197                       0.7805                0.1553                   0.2195  0.7409
2019-12-20 17:28:29,560 [INFO] Dataset: Validation. Classification report below
2019-12-20 17:28:29,560 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.89      0.93       199
         u2r       1.00      0.30      0.46        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.99      0.84      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-20 17:28:29,560 [INFO] Overall accuracy (micro avg): 0.9967850764040485
2019-12-20 17:28:29,938 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9968         0.9968                       0.9968                0.0008                   0.0032  0.9968
1     Macro avg        0.9987         0.9910                       0.8358                0.0011                   0.1642  0.8754
2  Weighted avg        0.9980         0.9968                       0.9968                0.0024                   0.0032  0.9967
2019-12-20 17:28:31,451 [INFO] Dataset: Training. Classification report below
2019-12-20 17:28:31,451 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.97      0.89      0.93       796
         u2r       1.00      0.50      0.67        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.99      0.88      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-20 17:28:31,451 [INFO] Overall accuracy (micro avg): 0.9975391454484114
2019-12-20 17:28:33,161 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9933                       0.8769                0.0009                   0.1231  0.9181
2  Weighted avg        0.9985         0.9975                       0.9975                0.0022                   0.0025  0.9975
2019-12-20 17:28:33,181 [INFO] Results saved to: results_selected_models/selected_nsl_ann_deep_rep1/selected_nsl_ann_deep_rep1_results.xlsx
2019-12-20 17:28:33,181 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-20 17:28:33,186 [INFO] Created directory: results_selected_models/selected_nsl_ann_deep_rep2
2019-12-20 17:28:33,186 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ann_deep_rep2/run_log.log
2019-12-20 17:28:33,186 [INFO] ================= Running experiment no. 2  ================= 

2019-12-20 17:28:33,186 [INFO] Experiment parameters given below
2019-12-20 17:28:33,186 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_nsl_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 65], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ann_deep_rep2'}
2019-12-20 17:28:33,186 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ann_deep_rep2/tf_logs_run_2019_12_20-17_28_33
2019-12-20 17:28:33,187 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-20 17:28:33,187 [INFO] Reading X, y files
2019-12-20 17:28:33,187 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-20 17:28:33,449 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-20 17:28:33,449 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-20 17:28:33,516 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-20 17:28:33,516 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-20 17:28:33,578 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:28:33,578 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-20 17:28:33,586 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-20 17:28:33,587 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-20 17:28:33,591 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:28:33,591 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-20 17:28:33,594 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:28:33,792 [INFO] Initializing model
2019-12-20 17:28:34,039 [INFO] _________________________________________________________________
2019-12-20 17:28:34,039 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 17:28:34,039 [INFO] =================================================================
2019-12-20 17:28:34,040 [INFO] dense_5 (Dense)              (None, 64)                7872      
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] dense_6 (Dense)              (None, 32)                2080      
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-20 17:28:34,040 [INFO] _________________________________________________________________
2019-12-20 17:28:34,040 [INFO] dense_7 (Dense)              (None, 65)                2145      
2019-12-20 17:28:34,041 [INFO] _________________________________________________________________
2019-12-20 17:28:34,041 [INFO] batch_normalization_6 (Batch (None, 65)                260       
2019-12-20 17:28:34,041 [INFO] _________________________________________________________________
2019-12-20 17:28:34,041 [INFO] dropout_6 (Dropout)          (None, 65)                0         
2019-12-20 17:28:34,041 [INFO] _________________________________________________________________
2019-12-20 17:28:34,041 [INFO] dense_8 (Dense)              (None, 5)                 330       
2019-12-20 17:28:34,041 [INFO] =================================================================
2019-12-20 17:28:34,041 [INFO] Total params: 13,071
2019-12-20 17:28:34,041 [INFO] Trainable params: 12,749
2019-12-20 17:28:34,041 [INFO] Non-trainable params: 322
2019-12-20 17:28:34,041 [INFO] _________________________________________________________________
2019-12-20 17:28:34,041 [INFO] Training model
2019-12-20 17:29:32,250 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_30.pickle
2019-12-20 17:30:26,633 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_60.pickle
2019-12-20 17:31:21,438 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_90.pickle
2019-12-20 17:32:16,390 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_120.pickle
2019-12-20 17:33:11,455 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_150.pickle
2019-12-20 17:34:06,448 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_180.pickle
2019-12-20 17:35:01,382 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_210.pickle
2019-12-20 17:35:56,465 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_240.pickle
2019-12-20 17:36:51,390 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep2/ann_model_epoch_270.pickle
2019-12-20 17:37:44,925 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 17:37:47,200 [INFO] Last epoch loss evaluation: train_loss = 0.001939, val_loss = 0.003855
2019-12-20 17:37:47,200 [INFO] Training complete. time_to_train = 553.16 sec, 9.22 min
2019-12-20 17:37:47,208 [INFO] Model saved to results_selected_models/selected_nsl_ann_deep_rep2/best_model.pickle
2019-12-20 17:37:47,343 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep2/training_error_history.png
2019-12-20 17:37:47,463 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep2/training_f1_history.png
2019-12-20 17:37:47,463 [INFO] Making predictions on training, validation, testing data
2019-12-20 17:37:49,697 [INFO] Evaluating predictions (results)
2019-12-20 17:37:49,983 [INFO] Dataset: Testing. Classification report below
2019-12-20 17:37:49,983 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.89      7458
      normal       0.66      0.93      0.77      9711
       probe       0.70      0.66      0.68      2421
         r2l       0.92      0.06      0.10      2421
         u2r       0.88      0.04      0.08       533

   micro avg       0.75      0.75      0.75     22544
   macro avg       0.82      0.50      0.50     22544
weighted avg       0.80      0.75      0.71     22544

2019-12-20 17:37:49,983 [INFO] Overall accuracy (micro avg): 0.7521291696238467
2019-12-20 17:37:50,306 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7521         0.7521                       0.7521                0.0620                   0.2479  0.7521
1     Macro avg        0.9009         0.8247                       0.5027                0.0826                   0.4973  0.5045
2  Weighted avg        0.8570         0.7989                       0.7521                0.1653                   0.2479  0.7133
2019-12-20 17:37:50,646 [INFO] Dataset: Validation. Classification report below
2019-12-20 17:37:50,647 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.90      0.94       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.88      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-20 17:37:50,647 [INFO] Overall accuracy (micro avg): 0.9972216709664616
2019-12-20 17:37:51,023 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9972         0.9972                       0.9972                0.0007                   0.0028  0.9972
1     Macro avg        0.9989         0.9583                       0.8790                0.0010                   0.1210  0.9101
2  Weighted avg        0.9983         0.9972                       0.9972                0.0021                   0.0028  0.9972
2019-12-20 17:37:52,545 [INFO] Dataset: Training. Classification report below
2019-12-20 17:37:52,545 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.91      0.95       796
         u2r       0.91      0.74      0.82        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.93      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-20 17:37:52,545 [INFO] Overall accuracy (micro avg): 0.9979955942765286
2019-12-20 17:37:54,255 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9980         0.9980                       0.9980                0.0005                   0.0020  0.9980
1     Macro avg        0.9992         0.9778                       0.9289                0.0008                   0.0711  0.9512
2  Weighted avg        0.9987         0.9980                       0.9980                0.0018                   0.0020  0.9980
2019-12-20 17:37:54,274 [INFO] Results saved to: results_selected_models/selected_nsl_ann_deep_rep2/selected_nsl_ann_deep_rep2_results.xlsx
2019-12-20 17:37:54,275 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-20 17:37:54,278 [INFO] Created directory: results_selected_models/selected_nsl_ann_deep_rep3
2019-12-20 17:37:54,279 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ann_deep_rep3/run_log.log
2019-12-20 17:37:54,279 [INFO] ================= Running experiment no. 3  ================= 

2019-12-20 17:37:54,279 [INFO] Experiment parameters given below
2019-12-20 17:37:54,279 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_nsl_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 66], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ann_deep_rep3'}
2019-12-20 17:37:54,279 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ann_deep_rep3/tf_logs_run_2019_12_20-17_37_54
2019-12-20 17:37:54,279 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-20 17:37:54,279 [INFO] Reading X, y files
2019-12-20 17:37:54,280 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-20 17:37:54,541 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-20 17:37:54,541 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-20 17:37:54,604 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:37:54,604 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-20 17:37:54,666 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:37:54,666 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-20 17:37:54,674 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-20 17:37:54,674 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-20 17:37:54,678 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:37:54,678 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-20 17:37:54,682 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:37:54,880 [INFO] Initializing model
2019-12-20 17:37:55,128 [INFO] _________________________________________________________________
2019-12-20 17:37:55,128 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 17:37:55,128 [INFO] =================================================================
2019-12-20 17:37:55,128 [INFO] dense_9 (Dense)              (None, 64)                7872      
2019-12-20 17:37:55,128 [INFO] _________________________________________________________________
2019-12-20 17:37:55,128 [INFO] batch_normalization_7 (Batch (None, 64)                256       
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] dropout_7 (Dropout)          (None, 64)                0         
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] dense_10 (Dense)             (None, 32)                2080      
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] dense_11 (Dense)             (None, 66)                2178      
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,129 [INFO] batch_normalization_9 (Batch (None, 66)                264       
2019-12-20 17:37:55,129 [INFO] _________________________________________________________________
2019-12-20 17:37:55,130 [INFO] dropout_9 (Dropout)          (None, 66)                0         
2019-12-20 17:37:55,130 [INFO] _________________________________________________________________
2019-12-20 17:37:55,130 [INFO] dense_12 (Dense)             (None, 5)                 335       
2019-12-20 17:37:55,130 [INFO] =================================================================
2019-12-20 17:37:55,130 [INFO] Total params: 13,113
2019-12-20 17:37:55,130 [INFO] Trainable params: 12,789
2019-12-20 17:37:55,130 [INFO] Non-trainable params: 324
2019-12-20 17:37:55,130 [INFO] _________________________________________________________________
2019-12-20 17:37:55,130 [INFO] Training model
2019-12-20 17:38:56,381 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_30.pickle
2019-12-20 17:39:53,653 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_60.pickle
2019-12-20 17:40:50,867 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_90.pickle
2019-12-20 17:41:48,203 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_120.pickle
2019-12-20 17:42:45,647 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_150.pickle
2019-12-20 17:43:43,082 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_180.pickle
2019-12-20 17:44:40,504 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_210.pickle
2019-12-20 17:45:38,132 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep3/ann_model_epoch_240.pickle
2019-12-20 17:46:22,646 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 17:46:25,060 [INFO] Last epoch loss evaluation: train_loss = 0.001939, val_loss = 0.003552
2019-12-20 17:46:25,061 [INFO] Training complete. time_to_train = 509.93 sec, 8.50 min
2019-12-20 17:46:25,068 [INFO] Model saved to results_selected_models/selected_nsl_ann_deep_rep3/best_model.pickle
2019-12-20 17:46:25,203 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep3/training_error_history.png
2019-12-20 17:46:25,330 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep3/training_f1_history.png
2019-12-20 17:46:25,330 [INFO] Making predictions on training, validation, testing data
2019-12-20 17:46:27,767 [INFO] Evaluating predictions (results)
2019-12-20 17:46:28,050 [INFO] Dataset: Testing. Classification report below
2019-12-20 17:46:28,050 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.90      7458
      normal       0.69      0.97      0.80      9711
       probe       0.87      0.71      0.78      2421
         r2l       0.96      0.10      0.18      2421
         u2r       0.77      0.05      0.09       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.85      0.53      0.55     22544
weighted avg       0.83      0.78      0.75     22544

2019-12-20 17:46:28,050 [INFO] Overall accuracy (micro avg): 0.7839336408800568
2019-12-20 17:46:28,374 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7839         0.7839                       0.7839                0.0540                   0.2161  0.7839
1     Macro avg        0.9136         0.8495                       0.5324                0.0737                   0.4676  0.5482
2  Weighted avg        0.8750         0.8276                       0.7839                0.1527                   0.2161  0.7474
2019-12-20 17:46:28,716 [INFO] Dataset: Validation. Classification report below
2019-12-20 17:46:28,716 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       1.00      0.99      0.99      2331
         r2l       0.96      0.92      0.94       199
         u2r       0.75      0.60      0.67        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.94      0.90      0.92     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-20 17:46:28,716 [INFO] Overall accuracy (micro avg): 0.9973804326255209
2019-12-20 17:46:29,094 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9974         0.9974                       0.9974                0.0007                   0.0026  0.9974
1     Macro avg        0.9990         0.9400                       0.9031                0.0009                   0.0969  0.9198
2  Weighted avg        0.9984         0.9973                       0.9974                0.0019                   0.0026  0.9974
2019-12-20 17:46:30,604 [INFO] Dataset: Training. Classification report below
2019-12-20 17:46:30,604 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.92      0.95       796
         u2r       0.91      0.74      0.82        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.93      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-20 17:46:30,604 [INFO] Overall accuracy (micro avg): 0.998094822282641
2019-12-20 17:46:32,312 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9981         0.9981                       0.9981                0.0005                   0.0019  0.9981
1     Macro avg        0.9992         0.9767                       0.9310                0.0007                   0.0690  0.9518
2  Weighted avg        0.9988         0.9981                       0.9981                0.0016                   0.0019  0.9981
2019-12-20 17:46:32,331 [INFO] Results saved to: results_selected_models/selected_nsl_ann_deep_rep3/selected_nsl_ann_deep_rep3_results.xlsx
2019-12-20 17:46:32,332 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-20 17:46:32,335 [INFO] Created directory: results_selected_models/selected_nsl_ann_deep_rep4
2019-12-20 17:46:32,336 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ann_deep_rep4/run_log.log
2019-12-20 17:46:32,336 [INFO] ================= Running experiment no. 4  ================= 

2019-12-20 17:46:32,336 [INFO] Experiment parameters given below
2019-12-20 17:46:32,336 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_nsl_ann_deep_rep4', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 67], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ann_deep_rep4'}
2019-12-20 17:46:32,336 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ann_deep_rep4/tf_logs_run_2019_12_20-17_46_32
2019-12-20 17:46:32,336 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-20 17:46:32,337 [INFO] Reading X, y files
2019-12-20 17:46:32,337 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-20 17:46:32,603 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-20 17:46:32,603 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-20 17:46:32,667 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:46:32,667 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-20 17:46:32,724 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:46:32,724 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-20 17:46:32,732 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-20 17:46:32,732 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-20 17:46:32,737 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:46:32,737 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-20 17:46:32,741 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:46:32,937 [INFO] Initializing model
2019-12-20 17:46:33,188 [INFO] _________________________________________________________________
2019-12-20 17:46:33,188 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 17:46:33,188 [INFO] =================================================================
2019-12-20 17:46:33,189 [INFO] dense_13 (Dense)             (None, 64)                7872      
2019-12-20 17:46:33,189 [INFO] _________________________________________________________________
2019-12-20 17:46:33,189 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2019-12-20 17:46:33,189 [INFO] _________________________________________________________________
2019-12-20 17:46:33,189 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2019-12-20 17:46:33,189 [INFO] _________________________________________________________________
2019-12-20 17:46:33,189 [INFO] dense_14 (Dense)             (None, 32)                2080      
2019-12-20 17:46:33,189 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] batch_normalization_11 (Batc (None, 32)                128       
2019-12-20 17:46:33,190 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] dropout_11 (Dropout)         (None, 32)                0         
2019-12-20 17:46:33,190 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] dense_15 (Dense)             (None, 67)                2211      
2019-12-20 17:46:33,190 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] batch_normalization_12 (Batc (None, 67)                268       
2019-12-20 17:46:33,190 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] dropout_12 (Dropout)         (None, 67)                0         
2019-12-20 17:46:33,190 [INFO] _________________________________________________________________
2019-12-20 17:46:33,190 [INFO] dense_16 (Dense)             (None, 5)                 340       
2019-12-20 17:46:33,190 [INFO] =================================================================
2019-12-20 17:46:33,190 [INFO] Total params: 13,155
2019-12-20 17:46:33,191 [INFO] Trainable params: 12,829
2019-12-20 17:46:33,191 [INFO] Non-trainable params: 326
2019-12-20 17:46:33,191 [INFO] _________________________________________________________________
2019-12-20 17:46:33,191 [INFO] Training model
2019-12-20 17:47:36,347 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_30.pickle
2019-12-20 17:48:34,148 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_60.pickle
2019-12-20 17:49:31,621 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_90.pickle
2019-12-20 17:50:29,280 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_120.pickle
2019-12-20 17:51:26,977 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_150.pickle
2019-12-20 17:52:24,528 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_180.pickle
2019-12-20 17:53:22,561 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep4/ann_model_epoch_210.pickle
2019-12-20 17:54:15,095 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 17:54:17,828 [INFO] Last epoch loss evaluation: train_loss = 0.002137, val_loss = 0.003861
2019-12-20 17:54:17,829 [INFO] Training complete. time_to_train = 464.64 sec, 7.74 min
2019-12-20 17:54:17,836 [INFO] Model saved to results_selected_models/selected_nsl_ann_deep_rep4/best_model.pickle
2019-12-20 17:54:17,958 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep4/training_error_history.png
2019-12-20 17:54:18,083 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep4/training_f1_history.png
2019-12-20 17:54:18,083 [INFO] Making predictions on training, validation, testing data
2019-12-20 17:54:20,757 [INFO] Evaluating predictions (results)
2019-12-20 17:54:21,040 [INFO] Dataset: Testing. Classification report below
2019-12-20 17:54:21,040 [INFO] 
              precision    recall  f1-score   support

         dos       0.98      0.85      0.91      7458
      normal       0.67      0.97      0.79      9711
       probe       0.85      0.68      0.76      2421
         r2l       0.76      0.07      0.13      2421
         u2r       0.82      0.04      0.08       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.82      0.52      0.53     22544
weighted avg       0.81      0.78      0.74     22544

2019-12-20 17:54:21,040 [INFO] Overall accuracy (micro avg): 0.7775904897090135
2019-12-20 17:54:21,364 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7776         0.7776                       0.7776                0.0556                   0.2224  0.7776
1     Macro avg        0.9110         0.8169                       0.5208                0.0759                   0.4792  0.5335
2  Weighted avg        0.8717         0.8065                       0.7776                0.1570                   0.2224  0.7392
2019-12-20 17:54:21,705 [INFO] Dataset: Validation. Classification report below
2019-12-20 17:54:21,705 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.88      0.92       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.87      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-20 17:54:21,705 [INFO] Overall accuracy (micro avg): 0.9969835284778726
2019-12-20 17:54:22,082 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0008                   0.0030  0.9970
1     Macro avg        0.9988         0.9580                       0.8749                0.0011                   0.1251  0.9078
2  Weighted avg        0.9982         0.9969                       0.9970                0.0023                   0.0030  0.9969
2019-12-20 17:54:23,589 [INFO] Dataset: Training. Classification report below
2019-12-20 17:54:23,589 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.98      0.90      0.94       796
         u2r       0.91      0.71      0.80        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.92      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-20 17:54:23,589 [INFO] Overall accuracy (micro avg): 0.9978963662704161
2019-12-20 17:54:25,296 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9979         0.9979                       0.9979                0.0005                   0.0021  0.9979
1     Macro avg        0.9992         0.9770                       0.9213                0.0008                   0.0787  0.9465
2  Weighted avg        0.9987         0.9979                       0.9979                0.0019                   0.0021  0.9979
2019-12-20 17:54:25,316 [INFO] Results saved to: results_selected_models/selected_nsl_ann_deep_rep4/selected_nsl_ann_deep_rep4_results.xlsx
2019-12-20 17:54:25,316 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-20 17:54:25,320 [INFO] Created directory: results_selected_models/selected_nsl_ann_deep_rep5
2019-12-20 17:54:25,320 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ann_deep_rep5/run_log.log
2019-12-20 17:54:25,320 [INFO] ================= Running experiment no. 5  ================= 

2019-12-20 17:54:25,320 [INFO] Experiment parameters given below
2019-12-20 17:54:25,320 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_nsl_ann_deep_rep5', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'scaling_type': 'NA', 'ann_layer_units': [64, 32, 68], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ann_deep_rep5'}
2019-12-20 17:54:25,320 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ann_deep_rep5/tf_logs_run_2019_12_20-17_54_25
2019-12-20 17:54:25,320 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-20 17:54:25,321 [INFO] Reading X, y files
2019-12-20 17:54:25,321 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-20 17:54:25,588 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-20 17:54:25,589 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-20 17:54:25,652 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:54:25,652 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-20 17:54:25,711 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-20 17:54:25,711 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-20 17:54:25,719 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-20 17:54:25,719 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-20 17:54:25,724 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:54:25,724 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-20 17:54:25,728 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-20 17:54:25,928 [INFO] Initializing model
2019-12-20 17:54:26,287 [INFO] _________________________________________________________________
2019-12-20 17:54:26,287 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-20 17:54:26,288 [INFO] =================================================================
2019-12-20 17:54:26,288 [INFO] dense_17 (Dense)             (None, 64)                7872      
2019-12-20 17:54:26,288 [INFO] _________________________________________________________________
2019-12-20 17:54:26,288 [INFO] batch_normalization_13 (Batc (None, 64)                256       
2019-12-20 17:54:26,288 [INFO] _________________________________________________________________
2019-12-20 17:54:26,288 [INFO] dropout_13 (Dropout)         (None, 64)                0         
2019-12-20 17:54:26,288 [INFO] _________________________________________________________________
2019-12-20 17:54:26,288 [INFO] dense_18 (Dense)             (None, 32)                2080      
2019-12-20 17:54:26,288 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2019-12-20 17:54:26,289 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2019-12-20 17:54:26,289 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] dense_19 (Dense)             (None, 68)                2244      
2019-12-20 17:54:26,289 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] batch_normalization_15 (Batc (None, 68)                272       
2019-12-20 17:54:26,289 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] dropout_15 (Dropout)         (None, 68)                0         
2019-12-20 17:54:26,289 [INFO] _________________________________________________________________
2019-12-20 17:54:26,289 [INFO] dense_20 (Dense)             (None, 5)                 345       
2019-12-20 17:54:26,289 [INFO] =================================================================
2019-12-20 17:54:26,289 [INFO] Total params: 13,197
2019-12-20 17:54:26,290 [INFO] Trainable params: 12,869
2019-12-20 17:54:26,290 [INFO] Non-trainable params: 328
2019-12-20 17:54:26,290 [INFO] _________________________________________________________________
2019-12-20 17:54:26,290 [INFO] Training model
2019-12-20 17:55:31,477 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_30.pickle
2019-12-20 17:56:31,563 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_60.pickle
2019-12-20 17:57:31,703 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_90.pickle
2019-12-20 17:58:31,951 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_120.pickle
2019-12-20 17:59:32,254 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_150.pickle
2019-12-20 18:00:32,411 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_180.pickle
2019-12-20 18:01:32,761 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_210.pickle
2019-12-20 18:02:32,980 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_240.pickle
2019-12-20 18:03:33,336 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_nsl_ann_deep_rep5/ann_model_epoch_270.pickle
2019-12-20 18:04:28,224 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-20 18:04:31,122 [INFO] Last epoch loss evaluation: train_loss = 0.002092, val_loss = 0.003783
2019-12-20 18:04:31,122 [INFO] Training complete. time_to_train = 604.83 sec, 10.08 min
2019-12-20 18:04:31,129 [INFO] Model saved to results_selected_models/selected_nsl_ann_deep_rep5/best_model.pickle
2019-12-20 18:04:31,267 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep5/training_error_history.png
2019-12-20 18:04:31,402 [INFO] Plot saved to: results_selected_models/selected_nsl_ann_deep_rep5/training_f1_history.png
2019-12-20 18:04:31,402 [INFO] Making predictions on training, validation, testing data
2019-12-20 18:04:34,282 [INFO] Evaluating predictions (results)
2019-12-20 18:04:34,567 [INFO] Dataset: Testing. Classification report below
2019-12-20 18:04:34,567 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.67      0.97      0.79      9711
       probe       0.84      0.64      0.73      2421
         r2l       0.91      0.03      0.06      2421
         u2r       0.73      0.04      0.07       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.82      0.50      0.51     22544
weighted avg       0.81      0.77      0.72     22544

2019-12-20 18:04:34,567 [INFO] Overall accuracy (micro avg): 0.7689850958126331
2019-12-20 18:04:34,891 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7690         0.7690                       0.7690                0.0578                   0.2310  0.7690
1     Macro avg        0.9076         0.8239                       0.5046                0.0790                   0.4954  0.5107
2  Weighted avg        0.8667         0.8130                       0.7690                0.1638                   0.2310  0.7250
2019-12-20 18:04:35,233 [INFO] Dataset: Validation. Classification report below
2019-12-20 18:04:35,233 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.88      0.92       199
         u2r       0.71      0.50      0.59        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.94      0.87      0.90     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-20 18:04:35,233 [INFO] Overall accuracy (micro avg): 0.9971025997221671
2019-12-20 18:04:35,611 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9971         0.9971                       0.9971                0.0007                   0.0029  0.9971
1     Macro avg        0.9988         0.9354                       0.8741                0.0010                   0.1259  0.9005
2  Weighted avg        0.9982         0.9970                       0.9971                0.0023                   0.0029  0.9970
2019-12-20 18:04:37,126 [INFO] Dataset: Training. Classification report below
2019-12-20 18:04:37,126 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      1.00      1.00      9325
         r2l       0.98      0.90      0.94       796
         u2r       0.97      0.74      0.84        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.99      0.93      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-20 18:04:37,126 [INFO] Overall accuracy (micro avg): 0.9980551310801961
2019-12-20 18:04:38,852 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9981         0.9981                       0.9981                0.0005                   0.0019  0.9981
1     Macro avg        0.9992         0.9888                       0.9273                0.0007                   0.0727  0.9547
2  Weighted avg        0.9988         0.9980                       0.9981                0.0017                   0.0019  0.9980
2019-12-20 18:04:38,872 [INFO] Results saved to: results_selected_models/selected_nsl_ann_deep_rep5/selected_nsl_ann_deep_rep5_results.xlsx
2019-12-20 18:04:38,872 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-20 18:04:38,876 [INFO] Created directory: results_selected_models/selected_ids2017_ann_deep_rep1
