Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-07 20:57:02,229 [INFO] Read 6 experiments from file: experiment_specs/additional_exps/semi_sup_perf_ann.csv
2020-01-07 20:57:02,229 [INFO] ================= Started running experiments ================= 

2020-01-07 20:57:02,229 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_ann_rep1
2020-01-07 20:57:02,229 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep1/run_log.log
2020-01-07 20:57:02,229 [INFO] ================= Running experiment no. 1  ================= 

2020-01-07 20:57:02,229 [INFO] Experiment parameters given below
2020-01-07 20:57:02,229 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep1'}
2020-01-07 20:57:02,230 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep1/tf_logs_run_2020_01_07-20_57_02
2020-01-07 20:57:02,230 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-07 20:57:02,230 [INFO] Reading X, y files
2020-01-07 20:57:02,231 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-07 20:57:02,239 [INFO] NumExpr defaulting to 8 threads.
2020-01-07 20:57:02,477 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-07 20:57:02,477 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-07 20:57:02,539 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 20:57:02,539 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-07 20:57:02,595 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 20:57:02,595 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-07 20:57:02,603 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-07 20:57:02,603 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-07 20:57:02,608 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 20:57:02,608 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-07 20:57:02,612 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 20:57:02,725 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-07 20:57:02,740 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-07 20:57:02,812 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-07 20:57:02,855 [INFO] _________________________________________________________________
2020-01-07 20:57:02,855 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 20:57:02,855 [INFO] =================================================================
2020-01-07 20:57:02,855 [INFO] dense_1 (Dense)              (None, 64)                7872      
2020-01-07 20:57:02,855 [INFO] _________________________________________________________________
2020-01-07 20:57:02,855 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-07 20:57:02,855 [INFO] _________________________________________________________________
2020-01-07 20:57:02,856 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-07 20:57:02,856 [INFO] _________________________________________________________________
2020-01-07 20:57:02,856 [INFO] dense_2 (Dense)              (None, 5)                 325       
2020-01-07 20:57:02,856 [INFO] =================================================================
2020-01-07 20:57:02,856 [INFO] Total params: 8,453
2020-01-07 20:57:02,856 [INFO] Trainable params: 8,325
2020-01-07 20:57:02,856 [INFO] Non-trainable params: 128
2020-01-07 20:57:02,856 [INFO] _________________________________________________________________
2020-01-07 20:57:02,856 [INFO] Training model
2020-01-07 20:57:02,856 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30462 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30474 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30475 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30476 thread 3 bound to OS proc set 3
2020-01-07 20:57:03,937 [INFO] Split sizes (instances). total = 100778, set1 = 75583, set2 = 25195, set1 dataset hash = ae4213cf8e706d08135096bdf69e103f9b07b1e6
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-07 20:57:04,341 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-07 20:57:04.655059: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-07 20:57:04.657732: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-07 20:57:04.657817: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5651cbb727e0 executing computations on platform Host. Devices:
2020-01-07 20:57:04.657831: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-07 20:57:04.657892: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30484 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30502 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30503 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30504 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30505 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30483 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30507 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30506 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30510 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30509 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30508 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30512 thread 16 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30511 thread 15 bound to OS proc set 7
Train on 25195 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1800 - val_loss: 0.0595
 - val_f1: 0.9634
Epoch 2/300
 - 0s - loss: 0.0549 - val_loss: 0.0389
 - val_f1: 0.9702
Epoch 3/300
 - 0s - loss: 0.0400 - val_loss: 0.0309
 - val_f1: 0.9754
Epoch 4/300
 - 0s - loss: 0.0327 - val_loss: 0.0247
 - val_f1: 0.9788
Epoch 5/300
 - 0s - loss: 0.0271 - val_loss: 0.0196
 - val_f1: 0.9826
Epoch 6/300
 - 0s - loss: 0.0224 - val_loss: 0.0167
 - val_f1: 0.9881
Epoch 7/300
 - 0s - loss: 0.0203 - val_loss: 0.0147
 - val_f1: 0.9898
Epoch 8/300
 - 0s - loss: 0.0173 - val_loss: 0.0138
 - val_f1: 0.9891
Epoch 9/300
 - 0s - loss: 0.0166 - val_loss: 0.0129
 - val_f1: 0.9911
Epoch 10/300
 - 0s - loss: 0.0155 - val_loss: 0.0128
 - val_f1: 0.9906
Epoch 11/300
 - 0s - loss: 0.0149 - val_loss: 0.0117
 - val_f1: 0.9919
Epoch 12/300
 - 0s - loss: 0.0133 - val_loss: 0.0123
 - val_f1: 0.9902
Epoch 13/300
 - 0s - loss: 0.0141 - val_loss: 0.0117
 - val_f1: 0.9927
Epoch 14/300
 - 0s - loss: 0.0127 - val_loss: 0.0117
 - val_f1: 0.9926
Epoch 15/300
 - 0s - loss: 0.0123 - val_loss: 0.0114
 - val_f1: 0.9925
Epoch 16/300
 - 0s - loss: 0.0120 - val_loss: 0.0113
 - val_f1: 0.9929
Epoch 17/300
 - 0s - loss: 0.0119 - val_loss: 0.0112
 - val_f1: 0.9928
Epoch 18/300
 - 0s - loss: 0.0113 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 19/300
 - 0s - loss: 0.0110 - val_loss: 0.0104
 - val_f1: 0.9929
Epoch 20/300
 - 0s - loss: 0.0105 - val_loss: 0.0104
 - val_f1: 0.9929
Epoch 21/300
 - 0s - loss: 0.0103 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 22/300
 - 0s - loss: 0.0099 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 23/300
 - 0s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9925
Epoch 24/300
 - 0s - loss: 0.0097 - val_loss: 0.0105
 - val_f1: 0.9925
Epoch 25/300
 - 0s - loss: 0.0104 - val_loss: 0.0100
 - val_f1: 0.9926
Epoch 26/300
 - 0s - loss: 0.0093 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 27/300
 - 0s - loss: 0.0089 - val_loss: 0.0092
 - val_f1: 0.9929
Epoch 28/300
 - 0s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 29/300
 - 0s - loss: 0.0090 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 30/300
 - 0s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9934
Epoch 31/300
 - 0s - loss: 0.0085 - val_loss: 0.0093
2020-01-07 20:57:28,210 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9935
Epoch 32/300
 - 0s - loss: 0.0086 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 33/300
 - 0s - loss: 0.0088 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 34/300
 - 0s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 35/300
 - 0s - loss: 0.0081 - val_loss: 0.0097
 - val_f1: 0.9940
Epoch 36/300
 - 0s - loss: 0.0088 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 37/300
 - 0s - loss: 0.0082 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 38/300
 - 0s - loss: 0.0087 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 39/300
 - 0s - loss: 0.0083 - val_loss: 0.0091
 - val_f1: 0.9938
Epoch 40/300
 - 0s - loss: 0.0078 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 41/300
 - 0s - loss: 0.0078 - val_loss: 0.0092
 - val_f1: 0.9938
Epoch 42/300
 - 0s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9939
Epoch 43/300
 - 0s - loss: 0.0078 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 44/300
 - 0s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 45/300
 - 0s - loss: 0.0080 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 46/300
 - 0s - loss: 0.0079 - val_loss: 0.0101
 - val_f1: 0.9942
Epoch 47/300
 - 0s - loss: 0.0073 - val_loss: 0.0102
 - val_f1: 0.9939
Epoch 48/300
 - 0s - loss: 0.0074 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 49/300
 - 0s - loss: 0.0073 - val_loss: 0.0100
 - val_f1: 0.9942
Epoch 50/300
 - 0s - loss: 0.0073 - val_loss: 0.0102
 - val_f1: 0.9939
Epoch 51/300
 - 0s - loss: 0.0076 - val_loss: 0.0097
 - val_f1: 0.9942
Epoch 52/300
 - 0s - loss: 0.0071 - val_loss: 0.0098
 - val_f1: 0.9941
Epoch 53/300
 - 0s - loss: 0.0074 - val_loss: 0.0088
 - val_f1: 0.9941
Epoch 54/300
 - 0s - loss: 0.0071 - val_loss: 0.0091
 - val_f1: 0.9942
Epoch 55/300
 - 0s - loss: 0.0075 - val_loss: 0.0085
 - val_f1: 0.9946
Epoch 56/300
 - 0s - loss: 0.0064 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 57/300
 - 0s - loss: 0.0063 - val_loss: 0.0081
 - val_f1: 0.9944
Epoch 58/300
 - 0s - loss: 0.0069 - val_loss: 0.0083
 - val_f1: 0.9945
Epoch 59/300
 - 0s - loss: 0.0068 - val_loss: 0.0088
 - val_f1: 0.9943
Epoch 60/300
 - 0s - loss: 0.0066 - val_loss: 0.0084
 - val_f1: 0.9941
Epoch 61/300
 - 0s - loss: 0.0067 - val_loss: 0.0083
2020-01-07 20:57:50,017 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9944
Epoch 62/300
 - 0s - loss: 0.0064 - val_loss: 0.0086
 - val_f1: 0.9940
Epoch 63/300
 - 0s - loss: 0.0060 - val_loss: 0.0085
 - val_f1: 0.9947
Epoch 64/300
 - 0s - loss: 0.0063 - val_loss: 0.0081
 - val_f1: 0.9944
Epoch 65/300
 - 0s - loss: 0.0064 - val_loss: 0.0082
 - val_f1: 0.9947
Epoch 66/300
 - 0s - loss: 0.0063 - val_loss: 0.0081
 - val_f1: 0.9949
Epoch 67/300
 - 0s - loss: 0.0067 - val_loss: 0.0081
 - val_f1: 0.9945
Epoch 68/300
 - 0s - loss: 0.0060 - val_loss: 0.0086
 - val_f1: 0.9949
Epoch 69/300
 - 0s - loss: 0.0063 - val_loss: 0.0085
 - val_f1: 0.9950
Epoch 70/300
 - 0s - loss: 0.0060 - val_loss: 0.0083
 - val_f1: 0.9948
Epoch 71/300
 - 0s - loss: 0.0065 - val_loss: 0.0091
 - val_f1: 0.9948
Epoch 72/300
 - 0s - loss: 0.0061 - val_loss: 0.0083
 - val_f1: 0.9948
Epoch 73/300
 - 0s - loss: 0.0059 - val_loss: 0.0092
 - val_f1: 0.9946
Epoch 74/300
 - 0s - loss: 0.0057 - val_loss: 0.0081
 - val_f1: 0.9948
Epoch 75/300
 - 0s - loss: 0.0064 - val_loss: 0.0083
 - val_f1: 0.9948
Epoch 76/300
 - 0s - loss: 0.0061 - val_loss: 0.0082
 - val_f1: 0.9948
Epoch 77/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9949
Epoch 78/300
 - 0s - loss: 0.0062 - val_loss: 0.0090
 - val_f1: 0.9949
Epoch 79/300
 - 0s - loss: 0.0061 - val_loss: 0.0082
 - val_f1: 0.9948
Epoch 80/300
 - 0s - loss: 0.0058 - val_loss: 0.0095
 - val_f1: 0.9946
Epoch 81/300
 - 0s - loss: 0.0060 - val_loss: 0.0099
 - val_f1: 0.9947
Epoch 82/300
 - 0s - loss: 0.0062 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 83/300
 - 0s - loss: 0.0057 - val_loss: 0.0086
 - val_f1: 0.9944
Epoch 84/300
 - 0s - loss: 0.0057 - val_loss: 0.0080
 - val_f1: 0.9951
Epoch 85/300
 - 0s - loss: 0.0057 - val_loss: 0.0081
 - val_f1: 0.9952
Epoch 86/300
 - 0s - loss: 0.0059 - val_loss: 0.0086
 - val_f1: 0.9947
Epoch 87/300
 - 0s - loss: 0.0053 - val_loss: 0.0089
 - val_f1: 0.9944
Epoch 88/300
 - 0s - loss: 0.0056 - val_loss: 0.0086
 - val_f1: 0.9944
Epoch 89/300
 - 0s - loss: 0.0060 - val_loss: 0.0095
 - val_f1: 0.9950
Epoch 90/300
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9944
Epoch 91/300
 - 0s - loss: 0.0055 - val_loss: 0.0085
2020-01-07 20:58:11,966 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9954
Epoch 92/300
 - 0s - loss: 0.0051 - val_loss: 0.0082
 - val_f1: 0.9949
Epoch 93/300
 - 0s - loss: 0.0050 - val_loss: 0.0085
 - val_f1: 0.9953
Epoch 94/300
 - 0s - loss: 0.0053 - val_loss: 0.0081
 - val_f1: 0.9952
Epoch 95/300
 - 0s - loss: 0.0049 - val_loss: 0.0083
 - val_f1: 0.9948
Epoch 96/300
 - 0s - loss: 0.0056 - val_loss: 0.0089
 - val_f1: 0.9950
Epoch 97/300
 - 0s - loss: 0.0056 - val_loss: 0.0082
 - val_f1: 0.9951
Epoch 98/300
 - 0s - loss: 0.0053 - val_loss: 0.0088
 - val_f1: 0.9951
Epoch 99/300
 - 0s - loss: 0.0048 - val_loss: 0.0084
 - val_f1: 0.9954
Epoch 100/300
 - 0s - loss: 0.0050 - val_loss: 0.0093
 - val_f1: 0.9951
Epoch 101/300
 - 0s - loss: 0.0057 - val_loss: 0.0091
 - val_f1: 0.9950
Epoch 102/300
 - 0s - loss: 0.0052 - val_loss: 0.0089
 - val_f1: 0.9953
Epoch 103/300
 - 0s - loss: 0.0050 - val_loss: 0.0090
 - val_f1: 0.9952
Epoch 104/300
 - 0s - loss: 0.0045 - val_loss: 0.0084
 - val_f1: 0.9954
Epoch 105/300
 - 0s - loss: 0.0051 - val_loss: 0.0088
 - val_f1: 0.9952
Epoch 106/300
 - 0s - loss: 0.0052 - val_loss: 0.0097
 - val_f1: 0.9950
Epoch 107/300
 - 0s - loss: 0.0050 - val_loss: 0.0090
 - val_f1: 0.9951
Epoch 108/300
 - 0s - loss: 0.0047 - val_loss: 0.0091
 - val_f1: 0.9948
Epoch 109/300
 - 0s - loss: 0.0050 - val_loss: 0.0091
 - val_f1: 0.9950
Epoch 110/300
 - 0s - loss: 0.0048 - val_loss: 0.0093
 - val_f1: 0.9951
Epoch 111/300
 - 0s - loss: 0.0050 - val_loss: 0.0092
 - val_f1: 0.9957
Epoch 112/300
 - 0s - loss: 0.0044 - val_loss: 0.0089
 - val_f1: 0.9952
Epoch 113/300
 - 0s - loss: 0.0050 - val_loss: 0.0089
 - val_f1: 0.9950
Epoch 114/300
 - 0s - loss: 0.0044 - val_loss: 0.0100
 - val_f1: 0.9953
Epoch 115/300
 - 0s - loss: 0.0048 - val_loss: 0.0092
 - val_f1: 0.9955
Epoch 116/300
 - 0s - loss: 0.0046 - val_loss: 0.0086
 - val_f1: 0.9957
Epoch 117/300
 - 0s - loss: 0.0042 - val_loss: 0.0092
 - val_f1: 0.9954
Epoch 118/300
 - 0s - loss: 0.0045 - val_loss: 0.0087
 - val_f1: 0.9955
Epoch 119/300
 - 0s - loss: 0.0050 - val_loss: 0.0088
 - val_f1: 0.9953
Epoch 120/300
 - 0s - loss: 0.0042 - val_loss: 0.0094
 - val_f1: 0.9957
Epoch 121/300
 - 0s - loss: 0.0044 - val_loss: 0.0091
2020-01-07 20:58:33,801 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9950
Epoch 122/300
 - 0s - loss: 0.0040 - val_loss: 0.0094
 - val_f1: 0.9947
Epoch 123/300
 - 0s - loss: 0.0047 - val_loss: 0.0089
 - val_f1: 0.9953
Epoch 124/300
 - 0s - loss: 0.0042 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 125/300
 - 0s - loss: 0.0040 - val_loss: 0.0091
 - val_f1: 0.9951
Epoch 126/300
 - 0s - loss: 0.0048 - val_loss: 0.0096
 - val_f1: 0.9957
Epoch 127/300
 - 0s - loss: 0.0047 - val_loss: 0.0090
 - val_f1: 0.9955
Epoch 128/300
 - 0s - loss: 0.0040 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 129/300
 - 0s - loss: 0.0043 - val_loss: 0.0091
 - val_f1: 0.9951
Epoch 130/300
 - 0s - loss: 0.0046 - val_loss: 0.0090
 - val_f1: 0.9955
Epoch 131/300
 - 0s - loss: 0.0041 - val_loss: 0.0098
 - val_f1: 0.9947
Epoch 132/300
 - 0s - loss: 0.0043 - val_loss: 0.0100
 - val_f1: 0.9947
Epoch 133/300
 - 0s - loss: 0.0041 - val_loss: 0.0093
 - val_f1: 0.9955
Epoch 134/300
 - 0s - loss: 0.0042 - val_loss: 0.0093
2020-01-07 20:58:43,649 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-07 20:58:44,568 [INFO] Last epoch loss evaluation: train_loss = 0.004064, val_loss = 0.008003
2020-01-07 20:58:44,569 [INFO] Training complete. time_to_train = 101.71 sec, 1.70 min
2020-01-07 20:58:44,572 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/best_model.pickle
2020-01-07 20:58:44,575 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/training_error_history.csv
2020-01-07 20:58:44,774 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/training_error_history.png
2020-01-07 20:58:44,949 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/training_f1_history.png
2020-01-07 20:58:44,949 [INFO] Making predictions on training, validation, testing data
2020-01-07 20:58:47,053 [INFO] Evaluating predictions (results)
2020-01-07 20:58:47,708 [INFO] Dataset: Testing. Classification report below
2020-01-07 20:58:47,708 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.85      0.91      7458
      normal       0.68      0.96      0.80      9711
       probe       0.78      0.66      0.71      2421
         r2l       0.68      0.07      0.13      2421
         u2r       0.85      0.04      0.08       533

    accuracy                           0.78     22544
   macro avg       0.79      0.52      0.53     22544
weighted avg       0.79      0.78      0.74     22544

2020-01-07 20:58:47,709 [INFO] Overall accuracy (micro avg): 0.7756831085876508
2020-01-07 20:58:48,306 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7757         0.7757                       0.7757                0.0561                   0.2243  0.7757
1     Macro avg        0.9103         0.7934                       0.5165                0.0755                   0.4835  0.5252
2  Weighted avg        0.8734         0.7933                       0.7757                0.1530                   0.2243  0.7367
2020-01-07 20:58:48,983 [INFO] Dataset: Validation. Classification report below
2020-01-07 20:58:48,983 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.92      0.82      0.87       199
         u2r       0.80      0.40      0.53        10

    accuracy                           1.00     25195
   macro avg       0.94      0.84      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2020-01-07 20:58:48,983 [INFO] Overall accuracy (micro avg): 0.9951180789839253
2020-01-07 20:58:49,656 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0012                   0.0049  0.9951
1     Macro avg        0.9980         0.9404                       0.8424                0.0017                   0.1576  0.8776
2  Weighted avg        0.9969         0.9950                       0.9951                0.0034                   0.0049  0.9950
2020-01-07 20:58:52,491 [INFO] Dataset: Training. Classification report below
2020-01-07 20:58:52,492 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.91      0.82      0.86       796
         u2r       0.76      0.52      0.62        42

    accuracy                           1.00    100778
   macro avg       0.93      0.87      0.89    100778
weighted avg       0.99      1.00      1.00    100778

2020-01-07 20:58:52,492 [INFO] Overall accuracy (micro avg): 0.9950882136974339
2020-01-07 20:58:55,528 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0012                   0.0049  0.9951
1     Macro avg        0.9980         0.9299                       0.8659                0.0017                   0.1341  0.8931
2  Weighted avg        0.9969         0.9950                       0.9951                0.0037                   0.0049  0.9950
2020-01-07 20:58:55,646 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/semi_sup_perf_nsl_ann_rep1_results.xlsx
2020-01-07 20:58:55,646 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-07 20:58:55,647 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_ann_rep2
2020-01-07 20:58:55,647 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep2/run_log.log
2020-01-07 20:58:55,647 [INFO] ================= Running experiment no. 2  ================= 

2020-01-07 20:58:55,647 [INFO] Experiment parameters given below
2020-01-07 20:58:55,647 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep2'}
2020-01-07 20:58:55,648 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep2/tf_logs_run_2020_01_07-20_58_55
2020-01-07 20:58:55,648 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-07 20:58:55,648 [INFO] Reading X, y files
2020-01-07 20:58:55,648 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-07 20:58:55,873 [INFO] Reading complete. time_to_read=0.22 seconds
2020-01-07 20:58:55,873 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-07 20:58:55,935 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 20:58:55,935 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-07 20:58:55,991 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 20:58:55,991 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-07 20:58:55,999 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-07 20:58:55,999 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-07 20:58:56,004 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 20:58:56,004 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-07 20:58:56,008 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 20:58:56,122 [INFO] Initializing model
2020-01-07 20:58:56,242 [INFO] _________________________________________________________________
2020-01-07 20:58:56,242 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 20:58:56,242 [INFO] =================================================================
2020-01-07 20:58:56,242 [INFO] dense_3 (Dense)              (None, 64)                7872      
2020-01-07 20:58:56,242 [INFO] _________________________________________________________________
2020-01-07 20:58:56,242 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-07 20:58:56,242 [INFO] _________________________________________________________________
2020-01-07 20:58:56,242 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-07 20:58:56,242 [INFO] _________________________________________________________________
2020-01-07 20:58:56,243 [INFO] dense_4 (Dense)              (None, 5)                 325       
2020-01-07 20:58:56,243 [INFO] =================================================================
2020-01-07 20:58:56,243 [INFO] Total params: 8,453
2020-01-07 20:58:56,243 [INFO] Trainable params: 8,325
2020-01-07 20:58:56,243 [INFO] Non-trainable params: 128
2020-01-07 20:58:56,243 [INFO] _________________________________________________________________
2020-01-07 20:58:56,243 [INFO] Training model
2020-01-07 20:58:56,243 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-07 20:58:57,271 [INFO] Split sizes (instances). total = 100778, set1 = 75583, set2 = 25195, set1 dataset hash = 40fcc5b399aca9d2e6f9581990505c20b3f01fda
 - val_f1: 0.9957
Epoch 00134: early stopping
Train on 25195 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.2456 - val_loss: 0.0665
 - val_f1: 0.9584
Epoch 2/300
 - 0s - loss: 0.0628 - val_loss: 0.0430
 - val_f1: 0.9694
Epoch 3/300
 - 0s - loss: 0.0447 - val_loss: 0.0342
 - val_f1: 0.9758
Epoch 4/300
 - 0s - loss: 0.0356 - val_loss: 0.0279
 - val_f1: 0.9780
Epoch 5/300
 - 0s - loss: 0.0290 - val_loss: 0.0225
 - val_f1: 0.9792
Epoch 6/300
 - 0s - loss: 0.0247 - val_loss: 0.0179
 - val_f1: 0.9860
Epoch 7/300
 - 0s - loss: 0.0209 - val_loss: 0.0158
 - val_f1: 0.9865
Epoch 8/300
 - 0s - loss: 0.0186 - val_loss: 0.0143
 - val_f1: 0.9909
Epoch 9/300
 - 0s - loss: 0.0175 - val_loss: 0.0137
 - val_f1: 0.9914
Epoch 10/300
 - 0s - loss: 0.0159 - val_loss: 0.0134
 - val_f1: 0.9912
Epoch 11/300
 - 0s - loss: 0.0144 - val_loss: 0.0120
 - val_f1: 0.9917
Epoch 12/300
 - 0s - loss: 0.0145 - val_loss: 0.0117
 - val_f1: 0.9924
Epoch 13/300
 - 0s - loss: 0.0135 - val_loss: 0.0115
 - val_f1: 0.9920
Epoch 14/300
 - 0s - loss: 0.0131 - val_loss: 0.0114
 - val_f1: 0.9919
Epoch 15/300
 - 0s - loss: 0.0122 - val_loss: 0.0108
 - val_f1: 0.9926
Epoch 16/300
 - 0s - loss: 0.0124 - val_loss: 0.0108
 - val_f1: 0.9934
Epoch 17/300
 - 0s - loss: 0.0118 - val_loss: 0.0110
 - val_f1: 0.9907
Epoch 18/300
 - 0s - loss: 0.0116 - val_loss: 0.0104
 - val_f1: 0.9932
Epoch 19/300
 - 0s - loss: 0.0108 - val_loss: 0.0105
 - val_f1: 0.9923
Epoch 20/300
 - 0s - loss: 0.0105 - val_loss: 0.0103
 - val_f1: 0.9923
Epoch 21/300
 - 0s - loss: 0.0106 - val_loss: 0.0107
 - val_f1: 0.9932
Epoch 22/300
 - 0s - loss: 0.0107 - val_loss: 0.0106
 - val_f1: 0.9930
Epoch 23/300
 - 0s - loss: 0.0102 - val_loss: 0.0105
 - val_f1: 0.9937
Epoch 24/300
 - 0s - loss: 0.0098 - val_loss: 0.0104
 - val_f1: 0.9938
Epoch 25/300
 - 0s - loss: 0.0099 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 26/300
 - 0s - loss: 0.0092 - val_loss: 0.0105
 - val_f1: 0.9914
Epoch 27/300
 - 0s - loss: 0.0096 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 28/300
 - 0s - loss: 0.0091 - val_loss: 0.0095
 - val_f1: 0.9934
Epoch 29/300
 - 0s - loss: 0.0087 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 30/300
 - 0s - loss: 0.0083 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 31/300
 - 0s - loss: 0.0087 - val_loss: 0.0101
2020-01-07 20:59:22,076 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9939
Epoch 32/300
 - 0s - loss: 0.0087 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 33/300
 - 0s - loss: 0.0080 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 34/300
 - 0s - loss: 0.0085 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 35/300
 - 0s - loss: 0.0076 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 36/300
 - 0s - loss: 0.0085 - val_loss: 0.0095
 - val_f1: 0.9939
Epoch 37/300
 - 0s - loss: 0.0083 - val_loss: 0.0106
 - val_f1: 0.9936
Epoch 38/300
 - 0s - loss: 0.0077 - val_loss: 0.0101
 - val_f1: 0.9939
Epoch 39/300
 - 0s - loss: 0.0083 - val_loss: 0.0103
 - val_f1: 0.9930
Epoch 40/300
 - 0s - loss: 0.0086 - val_loss: 0.0102
 - val_f1: 0.9932
Epoch 41/300
 - 0s - loss: 0.0079 - val_loss: 0.0112
 - val_f1: 0.9913
Epoch 42/300
 - 0s - loss: 0.0080 - val_loss: 0.0099
 - val_f1: 0.9939
Epoch 43/300
 - 0s - loss: 0.0076 - val_loss: 0.0102
 - val_f1: 0.9932
Epoch 44/300
 - 0s - loss: 0.0076 - val_loss: 0.0102
 - val_f1: 0.9932
Epoch 45/300
 - 0s - loss: 0.0071 - val_loss: 0.0100
 - val_f1: 0.9937
Epoch 46/300
 - 0s - loss: 0.0072 - val_loss: 0.0092
 - val_f1: 0.9938
Epoch 47/300
 - 0s - loss: 0.0073 - val_loss: 0.0096
 - val_f1: 0.9943
Epoch 48/300
 - 0s - loss: 0.0071 - val_loss: 0.0094
 - val_f1: 0.9942
Epoch 49/300
 - 0s - loss: 0.0069 - val_loss: 0.0095
 - val_f1: 0.9939
Epoch 50/300
 - 0s - loss: 0.0075 - val_loss: 0.0102
 - val_f1: 0.9940
Epoch 51/300
 - 0s - loss: 0.0073 - val_loss: 0.0093
 - val_f1: 0.9941
Epoch 52/300
 - 0s - loss: 0.0074 - val_loss: 0.0101
 - val_f1: 0.9940
Epoch 53/300
 - 0s - loss: 0.0071 - val_loss: 0.0105
 - val_f1: 0.9937
Epoch 54/300
 - 0s - loss: 0.0066 - val_loss: 0.0096
 - val_f1: 0.9929
Epoch 55/300
 - 0s - loss: 0.0072 - val_loss: 0.0099
 - val_f1: 0.9941
Epoch 56/300
 - 0s - loss: 0.0068 - val_loss: 0.0096
 - val_f1: 0.9941
Epoch 57/300
 - 0s - loss: 0.0075 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 58/300
 - 0s - loss: 0.0069 - val_loss: 0.0088
 - val_f1: 0.9942
Epoch 59/300
 - 0s - loss: 0.0065 - val_loss: 0.0093
 - val_f1: 0.9941
Epoch 60/300
 - 0s - loss: 0.0069 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 61/300
 - 0s - loss: 0.0066 - val_loss: 0.0099
2020-01-07 20:59:45,017 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9932
Epoch 62/300
 - 0s - loss: 0.0066 - val_loss: 0.0096
 - val_f1: 0.9944
Epoch 63/300
 - 0s - loss: 0.0065 - val_loss: 0.0096
 - val_f1: 0.9944
Epoch 64/300
 - 0s - loss: 0.0062 - val_loss: 0.0094
 - val_f1: 0.9944
Epoch 65/300
 - 0s - loss: 0.0063 - val_loss: 0.0094
 - val_f1: 0.9943
Epoch 66/300
 - 0s - loss: 0.0062 - val_loss: 0.0095
 - val_f1: 0.9947
Epoch 67/300
 - 0s - loss: 0.0064 - val_loss: 0.0089
 - val_f1: 0.9941
Epoch 68/300
 - 0s - loss: 0.0061 - val_loss: 0.0095
 - val_f1: 0.9947
Epoch 69/300
 - 0s - loss: 0.0067 - val_loss: 0.0098
 - val_f1: 0.9940
Epoch 70/300
 - 0s - loss: 0.0064 - val_loss: 0.0098
 - val_f1: 0.9945
Epoch 71/300
 - 0s - loss: 0.0063 - val_loss: 0.0095
 - val_f1: 0.9945
Epoch 72/300
 - 0s - loss: 0.0061 - val_loss: 0.0091
 - val_f1: 0.9942
Epoch 73/300
 - 0s - loss: 0.0064 - val_loss: 0.0093
 - val_f1: 0.9950
Epoch 74/300
 - 0s - loss: 0.0058 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 75/300
 - 0s - loss: 0.0056 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 76/300
 - 0s - loss: 0.0060 - val_loss: 0.0091
 - val_f1: 0.9942
Epoch 77/300
 - 0s - loss: 0.0063 - val_loss: 0.0098
 - val_f1: 0.9941
Epoch 78/300
 - 0s - loss: 0.0064 - val_loss: 0.0094
 - val_f1: 0.9948
Epoch 79/300
 - 0s - loss: 0.0058 - val_loss: 0.0099
 - val_f1: 0.9942
Epoch 80/300
 - 0s - loss: 0.0061 - val_loss: 0.0093
 - val_f1: 0.9945
Epoch 81/300
 - 0s - loss: 0.0055 - val_loss: 0.0093
 - val_f1: 0.9949
Epoch 82/300
 - 0s - loss: 0.0055 - val_loss: 0.0095
 - val_f1: 0.9950
Epoch 83/300
 - 0s - loss: 0.0058 - val_loss: 0.0097
 - val_f1: 0.9944
Epoch 84/300
 - 0s - loss: 0.0056 - val_loss: 0.0091
 - val_f1: 0.9947
Epoch 85/300
 - 0s - loss: 0.0053 - val_loss: 0.0100
 - val_f1: 0.9940
Epoch 86/300
 - 0s - loss: 0.0059 - val_loss: 0.0094
 - val_f1: 0.9947
Epoch 87/300
 - 0s - loss: 0.0054 - val_loss: 0.0096
 - val_f1: 0.9947
Epoch 88/300
 - 0s - loss: 0.0060 - val_loss: 0.0099
 - val_f1: 0.9946
Epoch 89/300
 - 0s - loss: 0.0056 - val_loss: 0.0088
 - val_f1: 0.9949
Epoch 90/300
 - 0s - loss: 0.0053 - val_loss: 0.0089
 - val_f1: 0.9946
Epoch 91/300
 - 0s - loss: 0.0051 - val_loss: 0.0090
2020-01-07 21:00:07,918 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9943
Epoch 92/300
 - 0s - loss: 0.0059 - val_loss: 0.0095
 - val_f1: 0.9950
Epoch 93/300
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9947
Epoch 94/300
 - 0s - loss: 0.0052 - val_loss: 0.0098
 - val_f1: 0.9946
Epoch 95/300
 - 0s - loss: 0.0050 - val_loss: 0.0097
 - val_f1: 0.9951
Epoch 96/300
 - 0s - loss: 0.0058 - val_loss: 0.0098
 - val_f1: 0.9947
Epoch 97/300
 - 0s - loss: 0.0051 - val_loss: 0.0099
 - val_f1: 0.9953
Epoch 98/300
 - 0s - loss: 0.0052 - val_loss: 0.0102
 - val_f1: 0.9944
Epoch 99/300
 - 0s - loss: 0.0051 - val_loss: 0.0095
 - val_f1: 0.9945
Epoch 100/300
 - 0s - loss: 0.0053 - val_loss: 0.0102
 - val_f1: 0.9946
Epoch 101/300
 - 0s - loss: 0.0053 - val_loss: 0.0094
 - val_f1: 0.9943
Epoch 102/300
 - 0s - loss: 0.0055 - val_loss: 0.0100
 - val_f1: 0.9946
Epoch 103/300
 - 0s - loss: 0.0048 - val_loss: 0.0098
 - val_f1: 0.9948
Epoch 104/300
 - 0s - loss: 0.0052 - val_loss: 0.0107
 - val_f1: 0.9940
Epoch 105/300
 - 0s - loss: 0.0048 - val_loss: 0.0095
 - val_f1: 0.9951
Epoch 106/300
 - 0s - loss: 0.0049 - val_loss: 0.0099
 - val_f1: 0.9944
Epoch 107/300
 - 0s - loss: 0.0043 - val_loss: 0.0099
 - val_f1: 0.9947
Epoch 108/300
 - 0s - loss: 0.0052 - val_loss: 0.0100
2020-01-07 21:00:21,282 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-07 21:00:22,300 [INFO] Last epoch loss evaluation: train_loss = 0.004682, val_loss = 0.008785
2020-01-07 21:00:22,301 [INFO] Training complete. time_to_train = 86.06 sec, 1.43 min
2020-01-07 21:00:22,305 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/best_model.pickle
2020-01-07 21:00:22,307 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/training_error_history.csv
2020-01-07 21:00:22,484 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/training_error_history.png
2020-01-07 21:00:22,660 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/training_f1_history.png
2020-01-07 21:00:22,660 [INFO] Making predictions on training, validation, testing data
2020-01-07 21:00:24,947 [INFO] Evaluating predictions (results)
2020-01-07 21:00:25,499 [INFO] Dataset: Testing. Classification report below
2020-01-07 21:00:25,499 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.86      0.91      7458
      normal       0.69      0.95      0.80      9711
       probe       0.79      0.72      0.75      2421
         r2l       0.95      0.07      0.14      2421
         u2r       0.68      0.07      0.12       533

    accuracy                           0.78     22544
   macro avg       0.81      0.53      0.54     22544
weighted avg       0.82      0.78      0.74     22544

2020-01-07 21:00:25,499 [INFO] Overall accuracy (micro avg): 0.7793647977288858
2020-01-07 21:00:26,095 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7794         0.7794                       0.7794                0.0552                   0.2206  0.7794
1     Macro avg        0.9117         0.8130                       0.5331                0.0741                   0.4669  0.5427
2  Weighted avg        0.8740         0.8165                       0.7794                0.1498                   0.2206  0.7413
2020-01-07 21:00:26,773 [INFO] Dataset: Validation. Classification report below
2020-01-07 21:00:26,773 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      1.00      0.99     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.93      0.81      0.87       199
         u2r       0.43      0.30      0.35        10

    accuracy                           0.99     25195
   macro avg       0.87      0.82      0.84     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-07 21:00:26,773 [INFO] Overall accuracy (micro avg): 0.9943242706886287
2020-01-07 21:00:27,445 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9943         0.9943                       0.9943                0.0014                   0.0057  0.9943
1     Macro avg        0.9977         0.8662                       0.8194                0.0019                   0.1806  0.8399
2  Weighted avg        0.9965         0.9942                       0.9943                0.0038                   0.0057  0.9942
2020-01-07 21:00:30,285 [INFO] Dataset: Training. Classification report below
2020-01-07 21:00:30,286 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.92      0.82      0.86       796
         u2r       0.61      0.45      0.52        42

    accuracy                           0.99    100778
   macro avg       0.90      0.85      0.87    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-07 21:00:30,286 [INFO] Overall accuracy (micro avg): 0.9946714560717617
2020-01-07 21:00:33,329 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0013                   0.0053  0.9947
1     Macro avg        0.9979         0.9017                       0.8502                0.0018                   0.1498  0.8729
2  Weighted avg        0.9967         0.9946                       0.9947                0.0037                   0.0053  0.9946
2020-01-07 21:00:33,376 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/semi_sup_perf_nsl_ann_rep2_results.xlsx
2020-01-07 21:00:33,376 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-07 21:00:33,377 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_ann_rep3
2020-01-07 21:00:33,377 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep3/run_log.log
2020-01-07 21:00:33,377 [INFO] ================= Running experiment no. 3  ================= 

2020-01-07 21:00:33,377 [INFO] Experiment parameters given below
2020-01-07 21:00:33,377 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep3'}
2020-01-07 21:00:33,377 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep3/tf_logs_run_2020_01_07-21_00_33
2020-01-07 21:00:33,377 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-07 21:00:33,378 [INFO] Reading X, y files
2020-01-07 21:00:33,378 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-07 21:00:33,605 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-07 21:00:33,605 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-07 21:00:33,667 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 21:00:33,667 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-07 21:00:33,723 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-07 21:00:33,723 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-07 21:00:33,731 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-07 21:00:33,732 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-07 21:00:33,736 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 21:00:33,736 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-07 21:00:33,740 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-07 21:00:33,854 [INFO] Initializing model
2020-01-07 21:00:33,974 [INFO] _________________________________________________________________
2020-01-07 21:00:33,974 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 21:00:33,974 [INFO] =================================================================
2020-01-07 21:00:33,974 [INFO] dense_5 (Dense)              (None, 64)                7872      
2020-01-07 21:00:33,974 [INFO] _________________________________________________________________
2020-01-07 21:00:33,974 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-07 21:00:33,974 [INFO] _________________________________________________________________
2020-01-07 21:00:33,975 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-07 21:00:33,975 [INFO] _________________________________________________________________
2020-01-07 21:00:33,975 [INFO] dense_6 (Dense)              (None, 5)                 325       
2020-01-07 21:00:33,975 [INFO] =================================================================
2020-01-07 21:00:33,975 [INFO] Total params: 8,453
2020-01-07 21:00:33,975 [INFO] Trainable params: 8,325
2020-01-07 21:00:33,975 [INFO] Non-trainable params: 128
2020-01-07 21:00:33,975 [INFO] _________________________________________________________________
2020-01-07 21:00:33,975 [INFO] Training model
2020-01-07 21:00:33,975 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-07 21:00:34,999 [INFO] Split sizes (instances). total = 100778, set1 = 75583, set2 = 25195, set1 dataset hash = 40fcc5b399aca9d2e6f9581990505c20b3f01fda
 - val_f1: 0.9951
Epoch 00108: early stopping
Train on 25195 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.2682 - val_loss: 0.0734
 - val_f1: 0.9550
Epoch 2/300
 - 0s - loss: 0.0627 - val_loss: 0.0443
 - val_f1: 0.9713
Epoch 3/300
 - 0s - loss: 0.0459 - val_loss: 0.0346
 - val_f1: 0.9761
Epoch 4/300
 - 0s - loss: 0.0372 - val_loss: 0.0286
 - val_f1: 0.9788
Epoch 5/300
 - 0s - loss: 0.0291 - val_loss: 0.0230
 - val_f1: 0.9776
Epoch 6/300
 - 0s - loss: 0.0254 - val_loss: 0.0195
 - val_f1: 0.9840
Epoch 7/300
 - 0s - loss: 0.0215 - val_loss: 0.0167
 - val_f1: 0.9889
Epoch 8/300
 - 0s - loss: 0.0192 - val_loss: 0.0153
 - val_f1: 0.9898
Epoch 9/300
 - 0s - loss: 0.0178 - val_loss: 0.0139
 - val_f1: 0.9910
Epoch 10/300
 - 0s - loss: 0.0169 - val_loss: 0.0138
 - val_f1: 0.9906
Epoch 11/300
 - 0s - loss: 0.0156 - val_loss: 0.0127
 - val_f1: 0.9914
Epoch 12/300
 - 0s - loss: 0.0140 - val_loss: 0.0122
 - val_f1: 0.9918
Epoch 13/300
 - 0s - loss: 0.0138 - val_loss: 0.0114
 - val_f1: 0.9929
Epoch 14/300
 - 0s - loss: 0.0138 - val_loss: 0.0116
 - val_f1: 0.9927
Epoch 15/300
 - 0s - loss: 0.0127 - val_loss: 0.0116
 - val_f1: 0.9926
Epoch 16/300
 - 0s - loss: 0.0117 - val_loss: 0.0106
 - val_f1: 0.9932
Epoch 17/300
 - 0s - loss: 0.0120 - val_loss: 0.0108
 - val_f1: 0.9929
Epoch 18/300
 - 0s - loss: 0.0119 - val_loss: 0.0105
 - val_f1: 0.9932
Epoch 19/300
 - 0s - loss: 0.0103 - val_loss: 0.0106
 - val_f1: 0.9933
Epoch 20/300
 - 0s - loss: 0.0107 - val_loss: 0.0108
 - val_f1: 0.9924
Epoch 21/300
 - 0s - loss: 0.0107 - val_loss: 0.0104
 - val_f1: 0.9930
Epoch 22/300
 - 0s - loss: 0.0100 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 23/300
 - 0s - loss: 0.0107 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 24/300
 - 0s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 25/300
 - 0s - loss: 0.0090 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 26/300
 - 0s - loss: 0.0092 - val_loss: 0.0091
 - val_f1: 0.9934
Epoch 27/300
 - 0s - loss: 0.0091 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 28/300
 - 0s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 29/300
 - 0s - loss: 0.0089 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 30/300
 - 0s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 31/300
 - 0s - loss: 0.0079 - val_loss: 0.0091
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 21:01:01,004 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9942
Epoch 32/300
 - 0s - loss: 0.0085 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 33/300
 - 0s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9942
Epoch 34/300
 - 0s - loss: 0.0082 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 35/300
 - 0s - loss: 0.0080 - val_loss: 0.0092
 - val_f1: 0.9944
Epoch 36/300
 - 0s - loss: 0.0083 - val_loss: 0.0089
 - val_f1: 0.9942
Epoch 37/300
 - 0s - loss: 0.0083 - val_loss: 0.0095
 - val_f1: 0.9939
Epoch 38/300
 - 0s - loss: 0.0081 - val_loss: 0.0093
 - val_f1: 0.9943
Epoch 39/300
 - 0s - loss: 0.0075 - val_loss: 0.0090
 - val_f1: 0.9942
Epoch 40/300
 - 0s - loss: 0.0073 - val_loss: 0.0090
 - val_f1: 0.9946
Epoch 41/300
 - 0s - loss: 0.0073 - val_loss: 0.0093
 - val_f1: 0.9942
Epoch 42/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 43/300
 - 0s - loss: 0.0068 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 44/300
 - 0s - loss: 0.0070 - val_loss: 0.0091
 - val_f1: 0.9944
Epoch 45/300
 - 0s - loss: 0.0072 - val_loss: 0.0094
 - val_f1: 0.9940
Epoch 46/300
 - 0s - loss: 0.0067 - val_loss: 0.0091
 - val_f1: 0.9941
Epoch 47/300
 - 0s - loss: 0.0063 - val_loss: 0.0089
 - val_f1: 0.9939
Epoch 48/300
 - 0s - loss: 0.0071 - val_loss: 0.0089
 - val_f1: 0.9945
Epoch 49/300
 - 0s - loss: 0.0066 - val_loss: 0.0090
 - val_f1: 0.9944
Epoch 50/300
 - 0s - loss: 0.0073 - val_loss: 0.0087
 - val_f1: 0.9945
Epoch 51/300
 - 0s - loss: 0.0072 - val_loss: 0.0098
 - val_f1: 0.9944
Epoch 52/300
 - 0s - loss: 0.0064 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 53/300
 - 0s - loss: 0.0066 - val_loss: 0.0093
 - val_f1: 0.9950
Epoch 54/300
 - 0s - loss: 0.0062 - val_loss: 0.0089
 - val_f1: 0.9946
Epoch 55/300
 - 0s - loss: 0.0067 - val_loss: 0.0094
 - val_f1: 0.9939
Epoch 56/300
 - 0s - loss: 0.0063 - val_loss: 0.0089
 - val_f1: 0.9945
Epoch 57/300
 - 0s - loss: 0.0058 - val_loss: 0.0089
 - val_f1: 0.9943
Epoch 58/300
 - 0s - loss: 0.0061 - val_loss: 0.0090
 - val_f1: 0.9946
Epoch 59/300
 - 0s - loss: 0.0061 - val_loss: 0.0094
 - val_f1: 0.9943
Epoch 60/300
 - 0s - loss: 0.0061 - val_loss: 0.0092
 - val_f1: 0.9945
Epoch 61/300
 - 0s - loss: 0.0062 - val_loss: 0.0087
2020-01-07 21:01:24,827 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9946
Epoch 62/300
 - 0s - loss: 0.0056 - val_loss: 0.0088
 - val_f1: 0.9944
Epoch 63/300
 - 0s - loss: 0.0059 - val_loss: 0.0091
 - val_f1: 0.9944
Epoch 64/300
 - 0s - loss: 0.0061 - val_loss: 0.0091
 - val_f1: 0.9947
Epoch 65/300
 - 0s - loss: 0.0061 - val_loss: 0.0092
 - val_f1: 0.9946
Epoch 66/300
 - 0s - loss: 0.0057 - val_loss: 0.0089
 - val_f1: 0.9947
Epoch 67/300
 - 0s - loss: 0.0057 - val_loss: 0.0088
 - val_f1: 0.9952
Epoch 68/300
 - 0s - loss: 0.0056 - val_loss: 0.0088
 - val_f1: 0.9947
Epoch 69/300
 - 0s - loss: 0.0051 - val_loss: 0.0087
 - val_f1: 0.9948
Epoch 70/300
 - 0s - loss: 0.0054 - val_loss: 0.0086
 - val_f1: 0.9948
Epoch 71/300
 - 0s - loss: 0.0060 - val_loss: 0.0086
 - val_f1: 0.9954
Epoch 72/300
 - 0s - loss: 0.0054 - val_loss: 0.0090
 - val_f1: 0.9941
Epoch 73/300
 - 0s - loss: 0.0056 - val_loss: 0.0089
 - val_f1: 0.9954
Epoch 74/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9947
Epoch 75/300
 - 0s - loss: 0.0053 - val_loss: 0.0089
 - val_f1: 0.9952
Epoch 76/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9952
Epoch 77/300
 - 0s - loss: 0.0050 - val_loss: 0.0086
 - val_f1: 0.9956
Epoch 78/300
 - 0s - loss: 0.0051 - val_loss: 0.0095
 - val_f1: 0.9946
Epoch 79/300
 - 0s - loss: 0.0051 - val_loss: 0.0087
 - val_f1: 0.9957
Epoch 80/300
 - 0s - loss: 0.0053 - val_loss: 0.0091
 - val_f1: 0.9950
Epoch 81/300
 - 0s - loss: 0.0050 - val_loss: 0.0088
 - val_f1: 0.9947
Epoch 82/300
 - 0s - loss: 0.0050 - val_loss: 0.0086
 - val_f1: 0.9953
Epoch 83/300
 - 0s - loss: 0.0047 - val_loss: 0.0092
 - val_f1: 0.9957
Epoch 84/300
 - 0s - loss: 0.0050 - val_loss: 0.0089
 - val_f1: 0.9952
Epoch 85/300
 - 0s - loss: 0.0053 - val_loss: 0.0090
 - val_f1: 0.9948
Epoch 86/300
 - 0s - loss: 0.0053 - val_loss: 0.0091
 - val_f1: 0.9948
Epoch 87/300
 - 0s - loss: 0.0055 - val_loss: 0.0096
 - val_f1: 0.9949
Epoch 88/300
 - 0s - loss: 0.0048 - val_loss: 0.0088
 - val_f1: 0.9956
Epoch 89/300
 - 0s - loss: 0.0046 - val_loss: 0.0088
 - val_f1: 0.9956
Epoch 90/300
 - 0s - loss: 0.0047 - val_loss: 0.0086
 - val_f1: 0.9956
Epoch 91/300
 - 0s - loss: 0.0047 - val_loss: 0.0094
2020-01-07 21:01:48,627 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9955
Epoch 92/300
 - 0s - loss: 0.0049 - val_loss: 0.0094
 - val_f1: 0.9953
Epoch 93/300
 - 0s - loss: 0.0043 - val_loss: 0.0086
 - val_f1: 0.9959
Epoch 94/300
 - 0s - loss: 0.0049 - val_loss: 0.0089
 - val_f1: 0.9956
Epoch 95/300
 - 0s - loss: 0.0048 - val_loss: 0.0092
 - val_f1: 0.9948
Epoch 96/300
 - 0s - loss: 0.0046 - val_loss: 0.0088
 - val_f1: 0.9958
Epoch 97/300
 - 0s - loss: 0.0048 - val_loss: 0.0094
 - val_f1: 0.9951
Epoch 98/300
 - 0s - loss: 0.0044 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 99/300
 - 0s - loss: 0.0043 - val_loss: 0.0089
 - val_f1: 0.9954
Epoch 100/300
 - 0s - loss: 0.0047 - val_loss: 0.0089
 - val_f1: 0.9957
Epoch 101/300
 - 0s - loss: 0.0044 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 102/300
 - 0s - loss: 0.0040 - val_loss: 0.0090
 - val_f1: 0.9952
Epoch 103/300
 - 0s - loss: 0.0049 - val_loss: 0.0089
 - val_f1: 0.9958
Epoch 104/300
 - 0s - loss: 0.0043 - val_loss: 0.0085
 - val_f1: 0.9955
Epoch 105/300
 - 0s - loss: 0.0045 - val_loss: 0.0088
 - val_f1: 0.9951
Epoch 106/300
 - 0s - loss: 0.0039 - val_loss: 0.0085
 - val_f1: 0.9957
Epoch 107/300
 - 0s - loss: 0.0042 - val_loss: 0.0086
 - val_f1: 0.9958
Epoch 108/300
 - 0s - loss: 0.0040 - val_loss: 0.0093
 - val_f1: 0.9958
Epoch 109/300
 - 0s - loss: 0.0044 - val_loss: 0.0088
 - val_f1: 0.9959
Epoch 110/300
 - 0s - loss: 0.0045 - val_loss: 0.0091
 - val_f1: 0.9958
Epoch 111/300
 - 0s - loss: 0.0044 - val_loss: 0.0093
 - val_f1: 0.9955
Epoch 112/300
 - 0s - loss: 0.0040 - val_loss: 0.0089
 - val_f1: 0.9959
Epoch 113/300
 - 0s - loss: 0.0041 - val_loss: 0.0087
 - val_f1: 0.9959
Epoch 114/300
 - 0s - loss: 0.0041 - val_loss: 0.0088
 - val_f1: 0.9953
Epoch 115/300
 - 0s - loss: 0.0043 - val_loss: 0.0095
 - val_f1: 0.9952
Epoch 116/300
 - 0s - loss: 0.0046 - val_loss: 0.0087
 - val_f1: 0.9956
Epoch 117/300
 - 0s - loss: 0.0043 - val_loss: 0.0086
 - val_f1: 0.9960
Epoch 118/300
 - 0s - loss: 0.0042 - val_loss: 0.0086
 - val_f1: 0.9959
Epoch 119/300
 - 0s - loss: 0.0042 - val_loss: 0.0088
 - val_f1: 0.9957
Epoch 120/300
 - 0s - loss: 0.0038 - val_loss: 0.0093
 - val_f1: 0.9957
Epoch 121/300
 - 0s - loss: 0.0044 - val_loss: 0.0090
2020-01-07 21:02:12,468 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9957
Epoch 122/300
 - 0s - loss: 0.0042 - val_loss: 0.0092
 - val_f1: 0.9956
Epoch 123/300
 - 0s - loss: 0.0048 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 124/300
 - 0s - loss: 0.0043 - val_loss: 0.0086
 - val_f1: 0.9961
Epoch 125/300
 - 0s - loss: 0.0041 - val_loss: 0.0087
 - val_f1: 0.9956
Epoch 126/300
 - 0s - loss: 0.0039 - val_loss: 0.0087
 - val_f1: 0.9959
Epoch 127/300
 - 0s - loss: 0.0035 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 128/300
 - 0s - loss: 0.0036 - val_loss: 0.0089
 - val_f1: 0.9956
Epoch 129/300
 - 0s - loss: 0.0038 - val_loss: 0.0092
 - val_f1: 0.9948
Epoch 130/300
 - 0s - loss: 0.0038 - val_loss: 0.0094
 - val_f1: 0.9945
Epoch 131/300
 - 0s - loss: 0.0044 - val_loss: 0.0090
 - val_f1: 0.9950
Epoch 132/300
 - 0s - loss: 0.0037 - val_loss: 0.0088
 - val_f1: 0.9960
Epoch 133/300
 - 0s - loss: 0.0042 - val_loss: 0.0089
 - val_f1: 0.9959
Epoch 134/300
 - 0s - loss: 0.0039 - val_loss: 0.0090
 - val_f1: 0.9957
Epoch 135/300
 - 0s - loss: 0.0042 - val_loss: 0.0090
 - val_f1: 0.9957
Epoch 136/300
 - 0s - loss: 0.0036 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 137/300
 - 0s - loss: 0.0044 - val_loss: 0.0088
 - val_f1: 0.9956
Epoch 138/300
 - 0s - loss: 0.0041 - val_loss: 0.0090
 - val_f1: 0.9956
Epoch 139/300
 - 0s - loss: 0.0039 - val_loss: 0.0092
 - val_f1: 0.9957
Epoch 140/300
 - 0s - loss: 0.0040 - val_loss: 0.0090
 - val_f1: 0.9958
Epoch 141/300
 - 0s - loss: 0.0037 - val_loss: 0.0090
 - val_f1: 0.9954
Epoch 142/300
 - 0s - loss: 0.0041 - val_loss: 0.0091
 - val_f1: 0.9959
Epoch 143/300
 - 0s - loss: 0.0037 - val_loss: 0.0090
 - val_f1: 0.9956
Epoch 144/300
 - 0s - loss: 0.0037 - val_loss: 0.0092
 - val_f1: 0.9957
Epoch 145/300
 - 0s - loss: 0.0041 - val_loss: 0.0091
 - val_f1: 0.9954
Epoch 146/300
 - 0s - loss: 0.0039 - val_loss: 0.0095
 - val_f1: 0.9950
Epoch 147/300
 - 0s - loss: 0.0037 - val_loss: 0.0097
 - val_f1: 0.9958
Epoch 148/300
 - 0s - loss: 0.0038 - val_loss: 0.0099
 - val_f1: 0.9950
Epoch 149/300
 - 0s - loss: 0.0041 - val_loss: 0.0093
 - val_f1: 0.9954
Epoch 150/300
 - 0s - loss: 0.0042 - val_loss: 0.0105
 - val_f1: 0.9946
Epoch 151/300
 - 0s - loss: 0.0040 - val_loss: 0.0099
2020-01-07 21:02:36,272 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9953
Epoch 152/300
 - 0s - loss: 0.0037 - val_loss: 0.0099
 - val_f1: 0.9954
Epoch 153/300
 - 0s - loss: 0.0038 - val_loss: 0.0102
 - val_f1: 0.9947
Epoch 154/300
 - 0s - loss: 0.0040 - val_loss: 0.0096
 - val_f1: 0.9952
Epoch 155/300
 - 0s - loss: 0.0037 - val_loss: 0.0095
 - val_f1: 0.9951
Epoch 156/300
 - 0s - loss: 0.0038 - val_loss: 0.0095
2020-01-07 21:02:40,645 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-07 21:02:41,706 [INFO] Last epoch loss evaluation: train_loss = 0.002606, val_loss = 0.008487
2020-01-07 21:02:41,707 [INFO] Training complete. time_to_train = 127.73 sec, 2.13 min
2020-01-07 21:02:41,711 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/best_model.pickle
2020-01-07 21:02:41,714 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/training_error_history.csv
2020-01-07 21:02:41,904 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/training_error_history.png
2020-01-07 21:02:42,075 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/training_f1_history.png
2020-01-07 21:02:42,075 [INFO] Making predictions on training, validation, testing data
2020-01-07 21:02:44,488 [INFO] Evaluating predictions (results)
2020-01-07 21:02:45,045 [INFO] Dataset: Testing. Classification report below
2020-01-07 21:02:45,045 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.85      0.91      7458
      normal       0.69      0.97      0.81      9711
       probe       0.86      0.71      0.78      2421
         r2l       0.88      0.10      0.18      2421
         u2r       0.79      0.06      0.11       533

    accuracy                           0.79     22544
   macro avg       0.84      0.54      0.56     22544
weighted avg       0.82      0.79      0.75     22544

2020-01-07 21:02:45,045 [INFO] Overall accuracy (micro avg): 0.7890347764371894
2020-01-07 21:02:45,643 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7890         0.7890                       0.7890                0.0527                   0.2110  0.7890
1     Macro avg        0.9156         0.8377                       0.5391                0.0717                   0.4609  0.5564
2  Weighted avg        0.8792         0.8231                       0.7890                0.1478                   0.2110  0.7533
2020-01-07 21:02:46,324 [INFO] Dataset: Validation. Classification report below
2020-01-07 21:02:46,324 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.89      0.92       199
         u2r       0.67      0.40      0.50        10

    accuracy                           1.00     25195
   macro avg       0.92      0.86      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2020-01-07 21:02:46,324 [INFO] Overall accuracy (micro avg): 0.9957531256201627
2020-01-07 21:02:47,000 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0011                   0.0042  0.9958
1     Macro avg        0.9983         0.9212                       0.8551                0.0015                   0.1449  0.8812
2  Weighted avg        0.9973         0.9957                       0.9958                0.0030                   0.0042  0.9957
2020-01-07 21:02:49,849 [INFO] Dataset: Training. Classification report below
2020-01-07 21:02:49,851 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.97      0.90      0.93       796
         u2r       0.81      0.60      0.68        42

    accuracy                           1.00    100778
   macro avg       0.95      0.90      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2020-01-07 21:02:49,851 [INFO] Overall accuracy (micro avg): 0.9963583321756733
2020-01-07 21:02:52,902 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9964         0.9964                       0.9964                0.0009                   0.0036  0.9964
1     Macro avg        0.9985         0.9525                       0.8953                0.0013                   0.1047  0.9205
2  Weighted avg        0.9977         0.9963                       0.9964                0.0028                   0.0036  0.9963
2020-01-07 21:02:52,949 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/semi_sup_perf_nsl_ann_rep3_results.xlsx
2020-01-07 21:02:52,949 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-07 21:02:52,950 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_ann_rep1
2020-01-07 21:02:52,950 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep1/run_log.log
2020-01-07 21:02:52,950 [INFO] ================= Running experiment no. 1  ================= 

2020-01-07 21:02:52,950 [INFO] Experiment parameters given below
2020-01-07 21:02:52,950 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep1'}
2020-01-07 21:02:52,950 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep1/tf_logs_run_2020_01_07-21_02_52
2020-01-07 21:02:52,951 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-07 21:02:52,951 [INFO] Reading X, y files
2020-01-07 21:02:52,951 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-07 21:02:56,731 [INFO] Reading complete. time_to_read=3.78 seconds
2020-01-07 21:02:56,731 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-07 21:02:58,003 [INFO] Reading complete. time_to_read=1.27 seconds
2020-01-07 21:02:58,003 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-07 21:02:59,275 [INFO] Reading complete. time_to_read=1.27 seconds
2020-01-07 21:02:59,275 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-07 21:02:59,541 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-07 21:02:59,541 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-07 21:02:59,623 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 21:02:59,623 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-07 21:02:59,705 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 21:03:02,659 [INFO] Initializing model
2020-01-07 21:03:02,780 [INFO] _________________________________________________________________
2020-01-07 21:03:02,780 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 21:03:02,780 [INFO] =================================================================
2020-01-07 21:03:02,781 [INFO] dense_7 (Dense)              (None, 64)                5056      
2020-01-07 21:03:02,781 [INFO] _________________________________________________________________
2020-01-07 21:03:02,781 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-07 21:03:02,781 [INFO] _________________________________________________________________
2020-01-07 21:03:02,781 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-07 21:03:02,781 [INFO] _________________________________________________________________
2020-01-07 21:03:02,781 [INFO] dense_8 (Dense)              (None, 12)                780       
2020-01-07 21:03:02,781 [INFO] =================================================================
2020-01-07 21:03:02,781 [INFO] Total params: 6,092
2020-01-07 21:03:02,781 [INFO] Trainable params: 5,964
2020-01-07 21:03:02,781 [INFO] Non-trainable params: 128
2020-01-07 21:03:02,781 [INFO] _________________________________________________________________
2020-01-07 21:03:02,782 [INFO] Training model
2020-01-07 21:03:02,782 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-07 21:03:26,833 [INFO] Split sizes (instances). total = 1696684, set1 = 1272513, set2 = 424171, set1 dataset hash = 07eca414d7fa8ed059bf34ec454d369f9e002f85
 - val_f1: 0.9956
Epoch 00156: early stopping
Train on 424171 samples, validate on 565562 samples
Epoch 1/300
 - 8s - loss: 0.0365 - val_loss: 0.0155
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30711 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30712 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 30462 tid 30713 thread 19 bound to OS proc set 3
 - val_f1: 0.9601
Epoch 2/300
 - 7s - loss: 0.0153 - val_loss: 0.0240
 - val_f1: 0.9346
Epoch 3/300
 - 7s - loss: 0.0124 - val_loss: 0.0102
 - val_f1: 0.9738
Epoch 4/300
 - 7s - loss: 0.0110 - val_loss: 0.0115
 - val_f1: 0.9615
Epoch 5/300
 - 7s - loss: 0.0096 - val_loss: 0.0123
 - val_f1: 0.9584
Epoch 6/300
 - 7s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9849
Epoch 7/300
 - 7s - loss: 0.0079 - val_loss: 0.0135
 - val_f1: 0.9524
Epoch 8/300
 - 7s - loss: 0.0075 - val_loss: 0.0082
 - val_f1: 0.9791
Epoch 9/300
 - 7s - loss: 0.0073 - val_loss: 0.0161
 - val_f1: 0.9516
Epoch 10/300
 - 7s - loss: 0.0069 - val_loss: 0.0100
 - val_f1: 0.9594
Epoch 11/300
 - 7s - loss: 0.0068 - val_loss: 0.0054
 - val_f1: 0.9871
Epoch 12/300
 - 7s - loss: 0.0066 - val_loss: 0.0133
 - val_f1: 0.9525
Epoch 13/300
 - 7s - loss: 0.0065 - val_loss: 0.0165
 - val_f1: 0.9510
Epoch 14/300
 - 7s - loss: 0.0063 - val_loss: 0.0053
 - val_f1: 0.9902
Epoch 15/300
 - 7s - loss: 0.0063 - val_loss: 0.0096
 - val_f1: 0.9617
Epoch 16/300
 - 7s - loss: 0.0063 - val_loss: 0.0193
 - val_f1: 0.9485
Epoch 17/300
 - 7s - loss: 0.0060 - val_loss: 0.0145
 - val_f1: 0.9532
Epoch 18/300
 - 7s - loss: 0.0061 - val_loss: 0.0199
 - val_f1: 0.9491
Epoch 19/300
 - 7s - loss: 0.0063 - val_loss: 0.0051
 - val_f1: 0.9912
Epoch 20/300
 - 7s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9903
Epoch 21/300
 - 7s - loss: 0.0054 - val_loss: 0.0070
 - val_f1: 0.9824
Epoch 22/300
 - 7s - loss: 0.0052 - val_loss: 0.0083
 - val_f1: 0.9820
Epoch 23/300
 - 7s - loss: 0.0052 - val_loss: 0.0057
 - val_f1: 0.9873
Epoch 24/300
 - 7s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9845
Epoch 25/300
 - 7s - loss: 0.0053 - val_loss: 0.0045
 - val_f1: 0.9903
Epoch 26/300
 - 7s - loss: 0.0053 - val_loss: 0.0057
 - val_f1: 0.9859
Epoch 27/300
 - 7s - loss: 0.0052 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 28/300
 - 7s - loss: 0.0051 - val_loss: 0.0094
 - val_f1: 0.9741
Epoch 29/300
 - 7s - loss: 0.0050 - val_loss: 0.0041
 - val_f1: 0.9912
Epoch 30/300
 - 7s - loss: 0.0052 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 31/300
 - 7s - loss: 0.0048 - val_loss: 0.0037
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 21:12:36,139 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9927
Epoch 32/300
 - 7s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 33/300
 - 7s - loss: 0.0050 - val_loss: 0.0077
 - val_f1: 0.9816
Epoch 34/300
 - 7s - loss: 0.0048 - val_loss: 0.0094
 - val_f1: 0.9805
Epoch 35/300
 - 7s - loss: 0.0050 - val_loss: 0.0060
 - val_f1: 0.9863
Epoch 36/300
 - 7s - loss: 0.0049 - val_loss: 0.0107
 - val_f1: 0.9793
Epoch 37/300
 - 7s - loss: 0.0048 - val_loss: 0.0069
 - val_f1: 0.9831
Epoch 38/300
 - 7s - loss: 0.0047 - val_loss: 0.0068
 - val_f1: 0.9842
Epoch 39/300
 - 7s - loss: 0.0048 - val_loss: 0.0058
 - val_f1: 0.9855
Epoch 40/300
 - 7s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 41/300
 - 7s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 42/300
 - 7s - loss: 0.0047 - val_loss: 0.0040
 - val_f1: 0.9904
Epoch 43/300
 - 7s - loss: 0.0045 - val_loss: 0.0080
 - val_f1: 0.9812
Epoch 44/300
 - 7s - loss: 0.0046 - val_loss: 0.0091
 - val_f1: 0.9819
Epoch 45/300
 - 7s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9936
Epoch 46/300
 - 7s - loss: 0.0048 - val_loss: 0.0051
 - val_f1: 0.9874
Epoch 47/300
 - 7s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9863
Epoch 48/300
 - 7s - loss: 0.0045 - val_loss: 0.0124
 - val_f1: 0.9763
Epoch 49/300
 - 7s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9903
Epoch 50/300
 - 7s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 51/300
 - 7s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9914
Epoch 52/300
 - 7s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9885
Epoch 53/300
 - 7s - loss: 0.0044 - val_loss: 0.0045
 - val_f1: 0.9897
Epoch 54/300
 - 7s - loss: 0.0043 - val_loss: 0.0128
 - val_f1: 0.9734
Epoch 55/300
 - 7s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9882
Epoch 56/300
 - 7s - loss: 0.0042 - val_loss: 0.0106
 - val_f1: 0.9695
Epoch 57/300
 - 7s - loss: 0.0044 - val_loss: 0.0064
 - val_f1: 0.9864
Epoch 58/300
 - 7s - loss: 0.0042 - val_loss: 0.0100
 - val_f1: 0.9809
Epoch 59/300
 - 7s - loss: 0.0042 - val_loss: 0.0112
 - val_f1: 0.9743
Epoch 60/300
 - 7s - loss: 0.0042 - val_loss: 0.0114
 - val_f1: 0.9770
Epoch 61/300
 - 7s - loss: 0.0041 - val_loss: 0.0047
2020-01-07 21:21:33,664 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9894
Epoch 62/300
 - 7s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9894
Epoch 63/300
 - 7s - loss: 0.0041 - val_loss: 0.0055
 - val_f1: 0.9873
Epoch 64/300
 - 7s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9938
Epoch 65/300
 - 7s - loss: 0.0041 - val_loss: 0.0060
 - val_f1: 0.9877
Epoch 66/300
 - 7s - loss: 0.0041 - val_loss: 0.0070
 - val_f1: 0.9855
Epoch 67/300
 - 7s - loss: 0.0040 - val_loss: 0.0059
 - val_f1: 0.9855
Epoch 68/300
 - 7s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9875
Epoch 69/300
 - 7s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9896
Epoch 70/300
 - 7s - loss: 0.0039 - val_loss: 0.0057
 - val_f1: 0.9874
Epoch 71/300
 - 7s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9878
Epoch 72/300
 - 7s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9891
Epoch 73/300
 - 7s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9912
Epoch 74/300
 - 7s - loss: 0.0039 - val_loss: 0.0039
 - val_f1: 0.9915
Epoch 75/300
 - 7s - loss: 0.0040 - val_loss: 0.0053
 - val_f1: 0.9871
Epoch 76/300
 - 7s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9906
Epoch 77/300
 - 7s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9885
Epoch 78/300
 - 7s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 79/300
 - 7s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 80/300
 - 7s - loss: 0.0039 - val_loss: 0.0044
 - val_f1: 0.9904
Epoch 81/300
 - 7s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9911
Epoch 82/300
 - 7s - loss: 0.0038 - val_loss: 0.0062
 - val_f1: 0.9869
Epoch 83/300
 - 7s - loss: 0.0037 - val_loss: 0.0041
 - val_f1: 0.9906
Epoch 84/300
 - 7s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 85/300
 - 7s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9868
Epoch 86/300
 - 7s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9903
Epoch 87/300
 - 7s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9939
Epoch 88/300
 - 7s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9911
Epoch 89/300
 - 7s - loss: 0.0038 - val_loss: 0.0051
 - val_f1: 0.9896
Epoch 90/300
 - 7s - loss: 0.0037 - val_loss: 0.0044
 - val_f1: 0.9905
Epoch 91/300
 - 7s - loss: 0.0039 - val_loss: 0.0048
2020-01-07 21:30:28,945 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9893
Epoch 92/300
 - 7s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9886
Epoch 93/300
 - 7s - loss: 0.0039 - val_loss: 0.0053
 - val_f1: 0.9889
Epoch 94/300
 - 7s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9906
Epoch 95/300
 - 7s - loss: 0.0039 - val_loss: 0.0053
 - val_f1: 0.9883
Epoch 96/300
 - 7s - loss: 0.0039 - val_loss: 0.0053
 - val_f1: 0.9874
Epoch 97/300
 - 7s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 98/300
 - 7s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 99/300
 - 7s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9893
Epoch 100/300
 - 7s - loss: 0.0037 - val_loss: 0.0082
2020-01-07 21:33:20,156 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-07 21:33:40,255 [INFO] Last epoch loss evaluation: train_loss = 0.003215, val_loss = 0.003418
2020-01-07 21:33:40,258 [INFO] Training complete. time_to_train = 1837.48 sec, 30.62 min
2020-01-07 21:33:40,263 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/best_model.pickle
2020-01-07 21:33:40,265 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/training_error_history.csv
2020-01-07 21:33:40,451 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/training_error_history.png
2020-01-07 21:33:40,620 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/training_f1_history.png
2020-01-07 21:33:40,620 [INFO] Making predictions on training, validation, testing data
2020-01-07 21:34:30,404 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 21:34:50,284 [INFO] Dataset: Testing. Classification report below
2020-01-07 21:34:50,284 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.96      0.98      0.97     46025
      DoS Slowhttptest       0.87      0.97      0.91      1100
         DoS slowloris       0.98      0.92      0.95      1159
           FTP-Patator       0.98      0.99      0.98      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.92      0.99      0.95      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-07 21:34:50,284 [INFO] Overall accuracy (micro avg): 0.9930034196073994
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-07 21:35:11,662 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9930         0.9930                       0.9930                0.0006                   0.0070  0.9930
1     Macro avg        0.9988         0.8052                       0.7632                0.0016                   0.2368  0.7720
2  Weighted avg        0.9941         0.9923                       0.9930                0.0127                   0.0070  0.9925
2020-01-07 21:35:31,637 [INFO] Dataset: Validation. Classification report below
2020-01-07 21:35:31,637 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.48       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.97      2059
              DoS Hulk       0.96      0.98      0.97     46025
      DoS Slowhttptest       0.87      0.96      0.91      1099
         DoS slowloris       0.98      0.91      0.95      1159
           FTP-Patator       0.98      0.98      0.98      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.92      0.98      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       1.00      0.02      0.04       131

              accuracy                           0.99    565562
             macro avg       0.89      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-07 21:35:31,638 [INFO] Overall accuracy (micro avg): 0.9931324947574272
2020-01-07 21:35:53,150 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9931         0.9931                       0.9931                0.0006                   0.0069  0.9931
1     Macro avg        0.9989         0.8882                       0.7599                0.0016                   0.2401  0.7709
2  Weighted avg        0.9943         0.9927                       0.9931                0.0122                   0.0069  0.9927
2020-01-07 21:36:59,948 [INFO] Dataset: Training. Classification report below
2020-01-07 21:36:59,949 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.35      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.97      0.98      0.97    138074
      DoS Slowhttptest       0.88      0.97      0.92      3300
         DoS slowloris       0.98      0.92      0.95      3478
           FTP-Patator       0.98      0.98      0.98      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.93      0.98      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.92      0.03      0.06       391

              accuracy                           0.99   1696684
             macro avg       0.88      0.77      0.78   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-07 21:36:59,949 [INFO] Overall accuracy (micro avg): 0.993152525750228
2020-01-07 21:38:11,935 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9932         0.9932                       0.9932                0.0006                   0.0068  0.9932
1     Macro avg        0.9989         0.8839                       0.7656                0.0016                   0.2344  0.7777
2  Weighted avg        0.9943         0.9927                       0.9932                0.0125                   0.0068  0.9927
2020-01-07 21:38:11,999 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/semi_sup_perf_ids17_ann_rep1_results.xlsx
2020-01-07 21:38:12,003 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-07 21:38:12,045 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_ann_rep2
2020-01-07 21:38:12,045 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep2/run_log.log
2020-01-07 21:38:12,045 [INFO] ================= Running experiment no. 2  ================= 

2020-01-07 21:38:12,045 [INFO] Experiment parameters given below
2020-01-07 21:38:12,045 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep2'}
2020-01-07 21:38:12,045 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep2/tf_logs_run_2020_01_07-21_38_12
2020-01-07 21:38:12,046 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-07 21:38:12,046 [INFO] Reading X, y files
2020-01-07 21:38:12,046 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-07 21:38:15,793 [INFO] Reading complete. time_to_read=3.75 seconds
2020-01-07 21:38:15,793 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-07 21:38:17,070 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-07 21:38:17,070 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-07 21:38:18,349 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-07 21:38:18,349 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-07 21:38:18,605 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-07 21:38:18,606 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-07 21:38:18,687 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 21:38:18,687 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-07 21:38:18,771 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 21:38:21,714 [INFO] Initializing model
2020-01-07 21:38:21,836 [INFO] _________________________________________________________________
2020-01-07 21:38:21,836 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 21:38:21,836 [INFO] =================================================================
2020-01-07 21:38:21,837 [INFO] dense_9 (Dense)              (None, 64)                5056      
2020-01-07 21:38:21,837 [INFO] _________________________________________________________________
2020-01-07 21:38:21,837 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2020-01-07 21:38:21,837 [INFO] _________________________________________________________________
2020-01-07 21:38:21,837 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2020-01-07 21:38:21,837 [INFO] _________________________________________________________________
2020-01-07 21:38:21,837 [INFO] dense_10 (Dense)             (None, 12)                780       
2020-01-07 21:38:21,837 [INFO] =================================================================
2020-01-07 21:38:21,837 [INFO] Total params: 6,092
2020-01-07 21:38:21,837 [INFO] Trainable params: 5,964
2020-01-07 21:38:21,837 [INFO] Non-trainable params: 128
2020-01-07 21:38:21,838 [INFO] _________________________________________________________________
2020-01-07 21:38:21,838 [INFO] Training model
2020-01-07 21:38:21,838 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-07 21:38:45,960 [INFO] Split sizes (instances). total = 1696684, set1 = 1272513, set2 = 424171, set1 dataset hash = 07eca414d7fa8ed059bf34ec454d369f9e002f85
 - val_f1: 0.9855
Epoch 00100: early stopping
Train on 424171 samples, validate on 565562 samples
Epoch 1/300
 - 8s - loss: 0.0362 - val_loss: 0.0171
 - val_f1: 0.9583
Epoch 2/300
 - 7s - loss: 0.0151 - val_loss: 0.0116
 - val_f1: 0.9697
Epoch 3/300
 - 7s - loss: 0.0121 - val_loss: 0.0115
 - val_f1: 0.9663
Epoch 4/300
 - 7s - loss: 0.0109 - val_loss: 0.0117
 - val_f1: 0.9605
Epoch 5/300
 - 7s - loss: 0.0103 - val_loss: 0.0093
 - val_f1: 0.9763
Epoch 6/300
 - 7s - loss: 0.0096 - val_loss: 0.0102
 - val_f1: 0.9748
Epoch 7/300
 - 7s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9825
Epoch 8/300
 - 7s - loss: 0.0075 - val_loss: 0.0083
 - val_f1: 0.9796
Epoch 9/300
 - 7s - loss: 0.0069 - val_loss: 0.0063
 - val_f1: 0.9870
Epoch 10/300
 - 7s - loss: 0.0068 - val_loss: 0.0079
 - val_f1: 0.9809
Epoch 11/300
 - 7s - loss: 0.0064 - val_loss: 0.0048
 - val_f1: 0.9914
Epoch 12/300
 - 7s - loss: 0.0062 - val_loss: 0.0094
 - val_f1: 0.9780
Epoch 13/300
 - 7s - loss: 0.0062 - val_loss: 0.0046
 - val_f1: 0.9918
Epoch 14/300
 - 7s - loss: 0.0061 - val_loss: 0.0045
 - val_f1: 0.9916
Epoch 15/300
 - 7s - loss: 0.0060 - val_loss: 0.0061
 - val_f1: 0.9823
Epoch 16/300
 - 7s - loss: 0.0060 - val_loss: 0.0057
 - val_f1: 0.9872
Epoch 17/300
 - 7s - loss: 0.0058 - val_loss: 0.0065
 - val_f1: 0.9833
Epoch 18/300
 - 7s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9901
Epoch 19/300
 - 7s - loss: 0.0057 - val_loss: 0.0048
 - val_f1: 0.9870
Epoch 20/300
 - 7s - loss: 0.0055 - val_loss: 0.0056
 - val_f1: 0.9882
Epoch 21/300
 - 7s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 22/300
 - 7s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9890
Epoch 23/300
 - 7s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9936
Epoch 24/300
 - 7s - loss: 0.0052 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 25/300
 - 7s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9913
Epoch 26/300
 - 7s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 27/300
 - 7s - loss: 0.0050 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 28/300
 - 7s - loss: 0.0050 - val_loss: 0.0084
 - val_f1: 0.9805
Epoch 29/300
 - 7s - loss: 0.0049 - val_loss: 0.0059
 - val_f1: 0.9852
Epoch 30/300
 - 7s - loss: 0.0048 - val_loss: 0.0046
 - val_f1: 0.9877
Epoch 31/300
 - 7s - loss: 0.0047 - val_loss: 0.0037
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 21:48:13,760 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9938
Epoch 32/300
 - 7s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9928
Epoch 33/300
 - 7s - loss: 0.0049 - val_loss: 0.0094
 - val_f1: 0.9819
Epoch 34/300
 - 7s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9899
Epoch 35/300
 - 7s - loss: 0.0047 - val_loss: 0.0045
 - val_f1: 0.9905
Epoch 36/300
 - 7s - loss: 0.0046 - val_loss: 0.0116
 - val_f1: 0.9546
Epoch 37/300
 - 7s - loss: 0.0046 - val_loss: 0.0048
 - val_f1: 0.9880
Epoch 38/300
 - 7s - loss: 0.0046 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 39/300
 - 7s - loss: 0.0046 - val_loss: 0.0053
 - val_f1: 0.9883
Epoch 40/300
 - 7s - loss: 0.0045 - val_loss: 0.0050
 - val_f1: 0.9886
Epoch 41/300
 - 7s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 42/300
 - 7s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9893
Epoch 43/300
 - 7s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9940
Epoch 44/300
 - 7s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 45/300
 - 7s - loss: 0.0044 - val_loss: 0.0048
 - val_f1: 0.9875
Epoch 46/300
 - 7s - loss: 0.0044 - val_loss: 0.0042
 - val_f1: 0.9900
Epoch 47/300
 - 7s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9915
Epoch 48/300
 - 7s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 49/300
 - 7s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 50/300
 - 7s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9874
Epoch 51/300
 - 7s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9921
Epoch 52/300
 - 7s - loss: 0.0045 - val_loss: 0.0057
 - val_f1: 0.9872
Epoch 53/300
 - 7s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 54/300
 - 7s - loss: 0.0043 - val_loss: 0.0086
 - val_f1: 0.9802
Epoch 55/300
 - 7s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 56/300
 - 7s - loss: 0.0044 - val_loss: 0.0046
 - val_f1: 0.9887
Epoch 57/300
 - 7s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9907
Epoch 58/300
 - 7s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9907
Epoch 59/300
 - 7s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9879
Epoch 60/300
 - 7s - loss: 0.0041 - val_loss: 0.0062
 - val_f1: 0.9844
Epoch 61/300
 - 7s - loss: 0.0041 - val_loss: 0.0046
2020-01-07 21:57:32,532 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9913
Epoch 62/300
 - 7s - loss: 0.0042 - val_loss: 0.0088
 - val_f1: 0.9814
Epoch 63/300
 - 7s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9915
Epoch 64/300
 - 7s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 65/300
 - 7s - loss: 0.0040 - val_loss: 0.0084
 - val_f1: 0.9631
Epoch 66/300
 - 7s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9905
Epoch 67/300
 - 7s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9927
Epoch 68/300
 - 7s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 69/300
 - 7s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 70/300
 - 7s - loss: 0.0042 - val_loss: 0.0110
 - val_f1: 0.9549
Epoch 71/300
 - 7s - loss: 0.0041 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 72/300
 - 7s - loss: 0.0041 - val_loss: 0.0063
 - val_f1: 0.9850
Epoch 73/300
 - 7s - loss: 0.0043 - val_loss: 0.0101
 - val_f1: 0.9583
Epoch 74/300
 - 7s - loss: 0.0041 - val_loss: 0.0063
 - val_f1: 0.9846
Epoch 75/300
 - 7s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9902
Epoch 76/300
 - 7s - loss: 0.0040 - val_loss: 0.0073
 - val_f1: 0.9854
Epoch 77/300
 - 7s - loss: 0.0040 - val_loss: 0.0043
 - val_f1: 0.9897
Epoch 78/300
 - 7s - loss: 0.0041 - val_loss: 0.0057
 - val_f1: 0.9906
Epoch 79/300
 - 7s - loss: 0.0042 - val_loss: 0.0060
 - val_f1: 0.9879
Epoch 80/300
 - 7s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9934
Epoch 81/300
 - 7s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 82/300
 - 7s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 83/300
 - 7s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 84/300
 - 7s - loss: 0.0039 - val_loss: 0.0037
 - val_f1: 0.9906
Epoch 85/300
 - 7s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 86/300
 - 7s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 87/300
 - 7s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9929
Epoch 88/300
 - 7s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9899
Epoch 89/300
 - 7s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 90/300
 - 7s - loss: 0.0040 - val_loss: 0.0060
 - val_f1: 0.9864
Epoch 91/300
 - 7s - loss: 0.0039 - val_loss: 0.0055
2020-01-07 22:06:50,040 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9889
Epoch 92/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 93/300
 - 7s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9879
Epoch 94/300
 - 7s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 95/300
 - 7s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9888
Epoch 96/300
 - 7s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9926
Epoch 97/300
 - 7s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9935
Epoch 98/300
 - 7s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9880
Epoch 99/300
 - 7s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9937
Epoch 100/300
 - 7s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 101/300
 - 7s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9899
Epoch 102/300
 - 7s - loss: 0.0039 - val_loss: 0.0059
 - val_f1: 0.9876
Epoch 103/300
 - 7s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9898
Epoch 104/300
 - 7s - loss: 0.0038 - val_loss: 0.0042
 - val_f1: 0.9913
Epoch 105/300
 - 7s - loss: 0.0039 - val_loss: 0.0054
 - val_f1: 0.9877
Epoch 106/300
 - 7s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 107/300
 - 7s - loss: 0.0038 - val_loss: 0.0064
 - val_f1: 0.9846
Epoch 108/300
 - 7s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9899
Epoch 109/300
 - 7s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 110/300
 - 7s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 111/300
 - 7s - loss: 0.0039 - val_loss: 0.0037
 - val_f1: 0.9905
Epoch 112/300
 - 7s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 113/300
 - 7s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9886
Epoch 114/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 115/300
 - 7s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9890
Epoch 116/300
 - 7s - loss: 0.0038 - val_loss: 0.0051
 - val_f1: 0.9894
Epoch 117/300
 - 7s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 118/300
 - 7s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 119/300
 - 7s - loss: 0.0039 - val_loss: 0.0055
 - val_f1: 0.9877
Epoch 120/300
 - 7s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 121/300
 - 7s - loss: 0.0038 - val_loss: 0.0060
2020-01-07 22:16:07,649 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9862
Epoch 122/300
 - 7s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 123/300
 - 7s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 124/300
 - 7s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 125/300
 - 7s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 126/300
 - 7s - loss: 0.0038 - val_loss: 0.0043
 - val_f1: 0.9903
Epoch 127/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 128/300
 - 7s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 129/300
 - 7s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 130/300
 - 7s - loss: 0.0041 - val_loss: 0.0044
 - val_f1: 0.9894
Epoch 131/300
 - 7s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9913
Epoch 132/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 133/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 134/300
 - 7s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9942
Epoch 135/300
 - 7s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9931
Epoch 136/300
 - 7s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 137/300
 - 7s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9905
Epoch 138/300
 - 7s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 139/300
 - 7s - loss: 0.0037 - val_loss: 0.0063
 - val_f1: 0.9875
Epoch 140/300
 - 7s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9925
Epoch 141/300
 - 7s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9893
Epoch 142/300
 - 7s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9896
Epoch 143/300
 - 7s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9917
Epoch 144/300
 - 7s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 145/300
 - 7s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 146/300
 - 7s - loss: 0.0037 - val_loss: 0.0076
 - val_f1: 0.9853
Epoch 147/300
 - 7s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9907
Epoch 148/300
 - 7s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9888
Epoch 149/300
 - 7s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 150/300
 - 7s - loss: 0.0036 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 151/300
 - 7s - loss: 0.0037 - val_loss: 0.0034
2020-01-07 22:25:25,132 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9919
Epoch 152/300
 - 7s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 153/300
 - 7s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 154/300
 - 7s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9929
Epoch 155/300
 - 7s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 156/300
 - 7s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9929
Epoch 157/300
 - 7s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 158/300
 - 7s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9886
Epoch 159/300
 - 7s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 160/300
 - 7s - loss: 0.0037 - val_loss: 0.0043
 - val_f1: 0.9894
Epoch 161/300
 - 7s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 162/300
 - 7s - loss: 0.0036 - val_loss: 0.0061
 - val_f1: 0.9871
Epoch 163/300
 - 7s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 164/300
 - 7s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9913
Epoch 165/300
 - 7s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 166/300
 - 7s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 167/300
 - 7s - loss: 0.0035 - val_loss: 0.0032
2020-01-07 22:30:33,983 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-07 22:30:55,197 [INFO] Last epoch loss evaluation: train_loss = 0.002648, val_loss = 0.002873
2020-01-07 22:30:55,201 [INFO] Training complete. time_to_train = 3153.36 sec, 52.56 min
2020-01-07 22:30:55,205 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/best_model.pickle
2020-01-07 22:30:55,208 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/training_error_history.csv
2020-01-07 22:30:55,397 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/training_error_history.png
2020-01-07 22:30:55,588 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/training_f1_history.png
2020-01-07 22:30:55,588 [INFO] Making predictions on training, validation, testing data
2020-01-07 22:31:48,330 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 22:32:08,159 [INFO] Dataset: Testing. Classification report below
2020-01-07 22:32:08,159 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.91      0.36      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.98      2058
              DoS Hulk       0.98      0.98      0.98     46025
      DoS Slowhttptest       0.89      0.98      0.93      1100
         DoS slowloris       0.98      0.94      0.96      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1179
Web Attack Brute Force       1.00      0.08      0.15       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.89      0.77      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-07 22:32:08,160 [INFO] Overall accuracy (micro avg): 0.994543480644032
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-07 22:32:29,469 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9945         0.9945                       0.9945                0.0005                   0.0055  0.9945
1     Macro avg        0.9991         0.8912                       0.7722                0.0015                   0.2278  0.7885
2  Weighted avg        0.9955         0.9943                       0.9945                0.0129                   0.0055  0.9941
2020-01-07 22:32:49,468 [INFO] Dataset: Validation. Classification report below
2020-01-07 22:32:49,469 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.87      0.31      0.46       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.96      0.98      2059
              DoS Hulk       0.98      0.98      0.98     46025
      DoS Slowhttptest       0.89      0.97      0.93      1099
         DoS slowloris       0.98      0.94      0.96      1159
           FTP-Patator       0.98      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.97      0.97      0.97      1180
Web Attack Brute Force       1.00      0.04      0.08       301
        Web Attack XSS       0.80      0.03      0.06       131

              accuracy                           0.99    565562
             macro avg       0.95      0.77      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-07 22:32:49,469 [INFO] Overall accuracy (micro avg): 0.9947556589728447
2020-01-07 22:33:11,014 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0005                   0.0052  0.9948
1     Macro avg        0.9991         0.9544                       0.7669                0.0015                   0.2331  0.7832
2  Weighted avg        0.9957         0.9947                       0.9948                0.0123                   0.0052  0.9943
2020-01-07 22:34:17,718 [INFO] Dataset: Training. Classification report below
2020-01-07 22:34:17,718 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.91      0.35      0.50      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.98      0.98      0.98    138074
      DoS Slowhttptest       0.90      0.97      0.93      3300
         DoS slowloris       0.98      0.95      0.96      3478
           FTP-Patator       0.98      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       1.00      0.07      0.12       904
        Web Attack XSS       0.87      0.03      0.06       391

              accuracy                           0.99   1696684
             macro avg       0.96      0.77      0.79   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-07 22:34:17,718 [INFO] Overall accuracy (micro avg): 0.9947562421759149
2020-01-07 22:35:29,574 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0005                   0.0052  0.9948
1     Macro avg        0.9991         0.9647                       0.7731                0.0015                   0.2269  0.7918
2  Weighted avg        0.9956         0.9947                       0.9948                0.0126                   0.0052  0.9943
2020-01-07 22:35:29,639 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/semi_sup_perf_ids17_ann_rep2_results.xlsx
2020-01-07 22:35:29,642 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-07 22:35:29,685 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_ann_rep3
2020-01-07 22:35:29,685 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep3/run_log.log
2020-01-07 22:35:29,685 [INFO] ================= Running experiment no. 3  ================= 

2020-01-07 22:35:29,685 [INFO] Experiment parameters given below
2020-01-07 22:35:29,685 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep3'}
2020-01-07 22:35:29,686 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep3/tf_logs_run_2020_01_07-22_35_29
2020-01-07 22:35:29,686 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-07 22:35:29,686 [INFO] Reading X, y files
2020-01-07 22:35:29,686 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-07 22:35:33,447 [INFO] Reading complete. time_to_read=3.76 seconds
2020-01-07 22:35:33,447 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-07 22:35:34,722 [INFO] Reading complete. time_to_read=1.27 seconds
2020-01-07 22:35:34,725 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-07 22:35:36,002 [INFO] Reading complete. time_to_read=1.28 seconds
2020-01-07 22:35:36,002 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-07 22:35:36,252 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-07 22:35:36,252 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-07 22:35:36,334 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 22:35:36,334 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-07 22:35:36,415 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-07 22:35:39,334 [INFO] Initializing model
2020-01-07 22:35:39,456 [INFO] _________________________________________________________________
2020-01-07 22:35:39,456 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-07 22:35:39,457 [INFO] =================================================================
2020-01-07 22:35:39,457 [INFO] dense_11 (Dense)             (None, 64)                5056      
2020-01-07 22:35:39,457 [INFO] _________________________________________________________________
2020-01-07 22:35:39,457 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-07 22:35:39,457 [INFO] _________________________________________________________________
2020-01-07 22:35:39,457 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-07 22:35:39,457 [INFO] _________________________________________________________________
2020-01-07 22:35:39,457 [INFO] dense_12 (Dense)             (None, 12)                780       
2020-01-07 22:35:39,457 [INFO] =================================================================
2020-01-07 22:35:39,457 [INFO] Total params: 6,092
2020-01-07 22:35:39,458 [INFO] Trainable params: 5,964
2020-01-07 22:35:39,458 [INFO] Non-trainable params: 128
2020-01-07 22:35:39,458 [INFO] _________________________________________________________________
2020-01-07 22:35:39,458 [INFO] Training model
2020-01-07 22:35:39,458 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-07 22:36:03,990 [INFO] Split sizes (instances). total = 1696684, set1 = 1272513, set2 = 424171, set1 dataset hash = 07eca414d7fa8ed059bf34ec454d369f9e002f85
 - val_f1: 0.9937
Epoch 00167: early stopping
Train on 424171 samples, validate on 565562 samples
Epoch 1/300
 - 8s - loss: 0.0372 - val_loss: 0.0153
 - val_f1: 0.9621
Epoch 2/300
 - 7s - loss: 0.0152 - val_loss: 0.0117
 - val_f1: 0.9693
Epoch 3/300
 - 7s - loss: 0.0126 - val_loss: 0.0104
 - val_f1: 0.9725
Epoch 4/300
 - 7s - loss: 0.0110 - val_loss: 0.0116
 - val_f1: 0.9629
Epoch 5/300
 - 7s - loss: 0.0102 - val_loss: 0.0102
 - val_f1: 0.9704
Epoch 6/300
 - 7s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9711
Epoch 7/300
 - 7s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9696
Epoch 8/300
 - 7s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9791
Epoch 9/300
 - 7s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9760
Epoch 10/300
 - 7s - loss: 0.0071 - val_loss: 0.0074
 - val_f1: 0.9817
Epoch 11/300
 - 7s - loss: 0.0070 - val_loss: 0.0061
 - val_f1: 0.9842
Epoch 12/300
 - 7s - loss: 0.0067 - val_loss: 0.0057
 - val_f1: 0.9883
Epoch 13/300
 - 7s - loss: 0.0065 - val_loss: 0.0094
 - val_f1: 0.9762
Epoch 14/300
 - 7s - loss: 0.0064 - val_loss: 0.0086
 - val_f1: 0.9810
Epoch 15/300
 - 7s - loss: 0.0064 - val_loss: 0.0060
 - val_f1: 0.9852
Epoch 16/300
 - 7s - loss: 0.0061 - val_loss: 0.0057
 - val_f1: 0.9875
Epoch 17/300
 - 7s - loss: 0.0062 - val_loss: 0.0057
 - val_f1: 0.9880
Epoch 18/300
 - 7s - loss: 0.0062 - val_loss: 0.0096
 - val_f1: 0.9782
Epoch 19/300
 - 7s - loss: 0.0061 - val_loss: 0.0062
 - val_f1: 0.9888
Epoch 20/300
 - 7s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9890
Epoch 21/300
 - 7s - loss: 0.0057 - val_loss: 0.0057
 - val_f1: 0.9872
Epoch 22/300
 - 7s - loss: 0.0057 - val_loss: 0.0053
 - val_f1: 0.9895
Epoch 23/300
 - 7s - loss: 0.0058 - val_loss: 0.0051
 - val_f1: 0.9896
Epoch 24/300
 - 7s - loss: 0.0057 - val_loss: 0.0074
 - val_f1: 0.9823
Epoch 25/300
 - 7s - loss: 0.0055 - val_loss: 0.0060
 - val_f1: 0.9873
Epoch 26/300
 - 7s - loss: 0.0055 - val_loss: 0.0056
 - val_f1: 0.9868
Epoch 27/300
 - 7s - loss: 0.0055 - val_loss: 0.0101
 - val_f1: 0.9611
Epoch 28/300
 - 7s - loss: 0.0059 - val_loss: 0.0074
 - val_f1: 0.9842
Epoch 29/300
 - 7s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9919
Epoch 30/300
 - 7s - loss: 0.0053 - val_loss: 0.0051
 - val_f1: 0.9911
Epoch 31/300
 - 7s - loss: 0.0050 - val_loss: 0.0058
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-07 22:45:51,421 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9889
Epoch 32/300
 - 7s - loss: 0.0049 - val_loss: 0.0045
 - val_f1: 0.9908
Epoch 33/300
 - 7s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9874
Epoch 34/300
 - 7s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9898
Epoch 35/300
 - 7s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9914
Epoch 36/300
 - 7s - loss: 0.0047 - val_loss: 0.0096
 - val_f1: 0.9624
Epoch 37/300
 - 7s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 38/300
 - 7s - loss: 0.0046 - val_loss: 0.0045
 - val_f1: 0.9888
Epoch 39/300
 - 7s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 40/300
 - 7s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9909
Epoch 41/300
 - 7s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9926
Epoch 42/300
 - 7s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9921
Epoch 43/300
 - 7s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9935
Epoch 44/300
 - 7s - loss: 0.0044 - val_loss: 0.0073
 - val_f1: 0.9851
Epoch 45/300
 - 7s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 46/300
 - 7s - loss: 0.0043 - val_loss: 0.0060
 - val_f1: 0.9891
Epoch 47/300
 - 7s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 48/300
 - 7s - loss: 0.0043 - val_loss: 0.0107
 - val_f1: 0.9602
Epoch 49/300
 - 7s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9887
Epoch 50/300
 - 7s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9917
Epoch 51/300
 - 7s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 52/300
 - 7s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9901
Epoch 53/300
 - 7s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9905
Epoch 54/300
 - 7s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9916
Epoch 55/300
 - 7s - loss: 0.0041 - val_loss: 0.0045
 - val_f1: 0.9884
Epoch 56/300
 - 7s - loss: 0.0040 - val_loss: 0.0060
 - val_f1: 0.9850
Epoch 57/300
 - 7s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9935
Epoch 58/300
 - 7s - loss: 0.0044 - val_loss: 0.0044
 - val_f1: 0.9898
Epoch 59/300
 - 7s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 60/300
 - 7s - loss: 0.0041 - val_loss: 0.0054
 - val_f1: 0.9875
Epoch 61/300
 - 7s - loss: 0.0041 - val_loss: 0.0038
2020-01-07 22:55:29,304 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9925
Epoch 62/300
 - 7s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9868
Epoch 63/300
 - 7s - loss: 0.0041 - val_loss: 0.0056
 - val_f1: 0.9901
Epoch 64/300
 - 7s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 65/300
 - 7s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9882
Epoch 66/300
 - 7s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 67/300
 - 7s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 68/300
 - 7s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9901
Epoch 69/300
 - 7s - loss: 0.0041 - val_loss: 0.0044
 - val_f1: 0.9920
Epoch 70/300
 - 7s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9869
Epoch 71/300
 - 7s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9907
Epoch 72/300
 - 7s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 73/300
 - 7s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 74/300
 - 7s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9897
Epoch 75/300
 - 7s - loss: 0.0040 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 76/300
 - 7s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9912
Epoch 77/300
 - 7s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9909
Epoch 78/300
 - 7s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 79/300
 - 7s - loss: 0.0041 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 80/300
 - 7s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 81/300
 - 7s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9935
Epoch 82/300
 - 7s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9912
Epoch 83/300
 - 7s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9897
Epoch 84/300
 - 7s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9906
Epoch 85/300
 - 7s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9908
Epoch 86/300
 - 7s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9910
Epoch 87/300
 - 7s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9927
Epoch 88/300
 - 7s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 89/300
 - 7s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 90/300
 - 7s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9908
Epoch 91/300
 - 7s - loss: 0.0041 - val_loss: 0.0054
2020-01-07 23:05:06,365 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9896
Epoch 92/300
 - 7s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9919
Epoch 93/300
 - 7s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 94/300
 - 7s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9907
Epoch 95/300
 - 7s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9874
Epoch 96/300
 - 7s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9914
Epoch 97/300
 - 7s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 98/300
 - 7s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 99/300
 - 7s - loss: 0.0040 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 100/300
 - 7s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 101/300
 - 7s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 102/300
 - 7s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9913
Epoch 103/300
 - 7s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9895
Epoch 104/300
 - 7s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9896
Epoch 105/300
 - 7s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9908
Epoch 106/300
 - 7s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9919
Epoch 107/300
 - 7s - loss: 0.0043 - val_loss: 0.0090
 - val_f1: 0.9684
Epoch 108/300
 - 7s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9904
Epoch 109/300
 - 7s - loss: 0.0043 - val_loss: 0.0044
 - val_f1: 0.9928
Epoch 110/300
 - 7s - loss: 0.0041 - val_loss: 0.0043
 - val_f1: 0.9889
Epoch 111/300
 - 7s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9935
Epoch 112/300
 - 7s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 113/300
 - 7s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9943
Epoch 114/300
 - 7s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 115/300
 - 7s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 116/300
 - 7s - loss: 0.0038 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 117/300
 - 7s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9886
Epoch 118/300
 - 7s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9946
Epoch 119/300
 - 7s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9944
Epoch 120/300
 - 7s - loss: 0.0040 - val_loss: 0.0043
 - val_f1: 0.9881
Epoch 121/300
 - 7s - loss: 0.0039 - val_loss: 0.0037
2020-01-07 23:14:43,759 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9903
Epoch 122/300
 - 7s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 123/300
 - 7s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 124/300
 - 7s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 125/300
 - 7s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 126/300
 - 7s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 127/300
 - 7s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9936
Epoch 128/300
 - 7s - loss: 0.0039 - val_loss: 0.0066
 - val_f1: 0.9863
Epoch 129/300
 - 7s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 130/300
 - 7s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9893
Epoch 131/300
 - 7s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 132/300
 - 7s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 133/300
 - 7s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 134/300
 - 7s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 135/300
 - 7s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9930
Epoch 136/300
 - 7s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 137/300
 - 7s - loss: 0.0038 - val_loss: 0.0071
 - val_f1: 0.9783
Epoch 138/300
 - 7s - loss: 0.0037 - val_loss: 0.0044
 - val_f1: 0.9872
Epoch 139/300
 - 7s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 140/300
 - 7s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 141/300
 - 7s - loss: 0.0037 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 142/300
 - 7s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 143/300
 - 7s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 144/300
 - 7s - loss: 0.0037 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 145/300
 - 7s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 146/300
 - 7s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 147/300
 - 7s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9903
Epoch 148/300
 - 7s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 149/300
 - 7s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 150/300
 - 7s - loss: 0.0037 - val_loss: 0.0087
 - val_f1: 0.9822
Epoch 151/300
 - 7s - loss: 0.0037 - val_loss: 0.0036
2020-01-07 23:24:21,688 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9920
Epoch 152/300
 - 7s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 153/300
 - 7s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 154/300
 - 7s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 155/300
 - 7s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 156/300
 - 7s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 157/300
 - 7s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9914
Epoch 158/300
 - 7s - loss: 0.0036 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 159/300
 - 7s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 160/300
 - 7s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 161/300
 - 7s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9902
Epoch 162/300
 - 7s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 163/300
 - 7s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9926
Epoch 164/300
 - 7s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 165/300
 - 7s - loss: 0.0036 - val_loss: 0.0055
 - val_f1: 0.9878
Epoch 166/300
 - 7s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9903
Epoch 167/300
 - 7s - loss: 0.0036 - val_loss: 0.0039
 - val_f1: 0.9908
Epoch 168/300
 - 7s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 169/300
 - 7s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 170/300
 - 7s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 171/300
 - 7s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 172/300
 - 7s - loss: 0.0036 - val_loss: 0.0039
 - val_f1: 0.9910
Epoch 173/300
 - 7s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 174/300
 - 7s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 175/300
 - 7s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9909
Epoch 176/300
 - 7s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9928
Epoch 177/300
 - 7s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 178/300
 - 7s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9945
Epoch 179/300
 - 7s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9913
Epoch 180/300
 - 7s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 181/300
 - 7s - loss: 0.0035 - val_loss: 0.0029
2020-01-07 23:33:59,280 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9943
Epoch 182/300
 - 7s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 183/300
 - 7s - loss: 0.0035 - val_loss: 0.0096
 - val_f1: 0.9818
Epoch 184/300
 - 7s - loss: 0.0035 - val_loss: 0.0054
 - val_f1: 0.9918
Epoch 185/300
 - 7s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 186/300
 - 7s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 187/300
 - 7s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 188/300
 - 7s - loss: 0.0034 - val_loss: 0.0058
 - val_f1: 0.9816
Epoch 189/300
 - 7s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 190/300
 - 7s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9910
Epoch 191/300
 - 7s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 192/300
 - 7s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 193/300
 - 7s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 194/300
 - 7s - loss: 0.0034 - val_loss: 0.0057
 - val_f1: 0.9920
Epoch 195/300
 - 7s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 196/300
 - 7s - loss: 0.0034 - val_loss: 0.0119
 - val_f1: 0.9805
Epoch 197/300
 - 7s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 198/300
 - 7s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 199/300
 - 7s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 200/300
 - 7s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 201/300
 - 7s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 202/300
 - 7s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 203/300
 - 7s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 204/300
 - 7s - loss: 0.0034 - val_loss: 0.0068
 - val_f1: 0.9667
Epoch 205/300
 - 7s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 206/300
 - 7s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 207/300
 - 7s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 208/300
 - 7s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 209/300
 - 7s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9931
Epoch 210/300
 - 7s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 211/300
 - 7s - loss: 0.0035 - val_loss: 0.0035
2020-01-07 23:43:36,475 [INFO] epoch = 210. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9930
Epoch 212/300
 - 7s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 213/300
 - 7s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 214/300
 - 7s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9910
Epoch 215/300
 - 7s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9906
Epoch 216/300
 - 7s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 217/300
 - 7s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9929
Epoch 218/300
 - 7s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 219/300
 - 7s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 220/300
 - 7s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 221/300
 - 7s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9944
Epoch 222/300
 - 7s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 223/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9946
Epoch 224/300
 - 7s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9920
Epoch 225/300
 - 7s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9908
Epoch 226/300
 - 7s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 227/300
 - 7s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 228/300
 - 7s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 229/300
 - 7s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9930
Epoch 230/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 231/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 232/300
 - 7s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9912
Epoch 233/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 234/300
 - 7s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 235/300
 - 7s - loss: 0.0033 - val_loss: 0.0038
 - val_f1: 0.9928
Epoch 236/300
 - 7s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9908
Epoch 237/300
 - 7s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 238/300
 - 7s - loss: 0.0033 - val_loss: 0.0051
 - val_f1: 0.9902
Epoch 239/300
 - 7s - loss: 0.0033 - val_loss: 0.0045
 - val_f1: 0.9903
Epoch 240/300
 - 7s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 241/300
 - 7s - loss: 0.0033 - val_loss: 0.0062
2020-01-07 23:53:13,530 [INFO] epoch = 240. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9865
Epoch 242/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 243/300
 - 7s - loss: 0.0033 - val_loss: 0.0043
 - val_f1: 0.9901
Epoch 244/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 245/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 246/300
 - 7s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 247/300
 - 7s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 248/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9946
Epoch 249/300
 - 7s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9914
Epoch 250/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 251/300
 - 7s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 252/300
 - 7s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 253/300
 - 7s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9900
Epoch 254/300
 - 7s - loss: 0.0034 - val_loss: 0.0054
 - val_f1: 0.9896
Epoch 255/300
 - 7s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 256/300
 - 7s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 257/300
 - 7s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 258/300
 - 7s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 259/300
 - 7s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 260/300
 - 7s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 261/300
 - 7s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 262/300
 - 7s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 263/300
 - 7s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 264/300
 - 7s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 265/300
 - 7s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9920
Epoch 266/300
 - 7s - loss: 0.0032 - val_loss: 0.0054
 - val_f1: 0.9877
Epoch 267/300
 - 7s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 268/300
 - 7s - loss: 0.0033 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 269/300
 - 7s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 270/300
 - 7s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9911
Epoch 271/300
 - 7s - loss: 0.0032 - val_loss: 0.0028
2020-01-08 00:02:50,456 [INFO] epoch = 270. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9937
Epoch 272/300
 - 7s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 273/300
 - 7s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 274/300
 - 7s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 275/300
 - 7s - loss: 0.0031 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 276/300
 - 7s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 277/300
 - 7s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 278/300
 - 7s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 279/300
 - 7s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 280/300
 - 7s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 281/300
 - 7s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 282/300
 - 7s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 283/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 284/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 285/300
 - 7s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 286/300
 - 7s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9923
Epoch 287/300
 - 7s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 288/300
 - 7s - loss: 0.0033 - val_loss: 0.0040
 - val_f1: 0.9925
Epoch 289/300
 - 7s - loss: 0.0032 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 290/300
 - 7s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 291/300
 - 7s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9921
Epoch 292/300
 - 7s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 293/300
 - 7s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 294/300
 - 7s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 295/300
 - 7s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 296/300
 - 7s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 297/300
 - 7s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 298/300
 - 7s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 299/300
 - 7s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 300/300
 - 7s - loss: 0.0032 - val_loss: 0.0038
2020-01-08 00:12:20,493 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 00:12:42,657 [INFO] Last epoch loss evaluation: train_loss = 0.002407, val_loss = 0.002608
2020-01-08 00:12:42,661 [INFO] Training complete. time_to_train = 5823.20 sec, 97.05 min
2020-01-08 00:12:42,666 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/best_model.pickle
2020-01-08 00:12:42,670 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/training_error_history.csv
2020-01-08 00:12:42,860 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/training_error_history.png
2020-01-08 00:12:43,047 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/training_f1_history.png
2020-01-08 00:12:43,047 [INFO] Making predictions on training, validation, testing data
2020-01-08 00:13:38,511 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 00:13:58,441 [INFO] Dataset: Testing. Classification report below
2020-01-08 00:13:58,441 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.96      0.98      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1179
Web Attack Brute Force       0.89      0.10      0.18       302
        Web Attack XSS       0.00      0.00      0.00       130

              accuracy                           0.99    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 00:13:58,441 [INFO] Overall accuracy (micro avg): 0.9945293354221111
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 00:14:19,870 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9945         0.9945                       0.9945                0.0005                   0.0055  0.9945
1     Macro avg        0.9991         0.8869                       0.7787                0.0012                   0.2213  0.7952
2  Weighted avg        0.9954         0.9943                       0.9945                0.0084                   0.0055  0.9941
2020-01-08 00:14:39,850 [INFO] Dataset: Validation. Classification report below
2020-01-08 00:14:39,850 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.95      0.97      2059
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.97      0.97      0.97      1180
Web Attack Brute Force       0.91      0.07      0.13       301
        Web Attack XSS       1.00      0.03      0.06       131

              accuracy                           0.99    565562
             macro avg       0.97      0.77      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2020-01-08 00:14:39,850 [INFO] Overall accuracy (micro avg): 0.994592988920755
2020-01-08 00:15:01,373 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0005                   0.0054  0.9946
1     Macro avg        0.9991         0.9737                       0.7734                0.0011                   0.2266  0.7915
2  Weighted avg        0.9955         0.9946                       0.9946                0.0084                   0.0054  0.9942
2020-01-08 00:16:08,353 [INFO] Dataset: Training. Classification report below
2020-01-08 00:16:08,353 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       1.00      0.96      0.98      6176
              DoS Hulk       0.97      0.99      0.98    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.99      0.98      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.95      0.09      0.16       904
        Web Attack XSS       1.00      0.03      0.06       391

              accuracy                           0.99   1696684
             macro avg       0.98      0.78      0.80   1696684
          weighted avg       0.99      0.99      0.99   1696684

2020-01-08 00:16:08,353 [INFO] Overall accuracy (micro avg): 0.9946784433636434
2020-01-08 00:17:20,536 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.9788                       0.7798                0.0011                   0.2202  0.7993
2  Weighted avg        0.9955         0.9947                       0.9947                0.0082                   0.0053  0.9943
2020-01-08 00:17:20,601 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/semi_sup_perf_ids17_ann_rep3_results.xlsx
2020-01-08 00:17:20,605 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-08 00:17:20,646 [INFO] ================= Finished running 6 experiments ================= 

 - val_f1: 0.9917
Using TensorFlow backend.
2020-01-08 10:21:53,866 [INFO] Read 3 experiments from file: experiment_specs/additional_exps/semi_sup_perf_ann.csv
2020-01-08 10:21:53,867 [INFO] ================= Started running experiments ================= 

2020-01-08 10:21:53,867 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1
2020-01-08 10:21:53,867 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/run_log.log
2020-01-08 10:21:53,867 [INFO] ================= Running experiment no. 1  ================= 

2020-01-08 10:21:53,867 [INFO] Experiment parameters given below
2020-01-08 10:21:53,867 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep1'}
2020-01-08 10:21:53,867 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/tf_logs_run_2020_01_08-10_21_53
2020-01-08 10:21:53,867 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 10:21:53,868 [INFO] Reading X, y files
2020-01-08 10:21:53,868 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 10:21:58,191 [INFO] Reading complete. time_to_read=4.32 seconds
2020-01-08 10:21:58,191 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 10:21:59,678 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-08 10:21:59,678 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 10:22:01,168 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-08 10:22:01,169 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 10:22:01,438 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-08 10:22:01,438 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 10:22:01,513 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 10:22:01,513 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 10:22:01,589 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 10:22:05,223 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-08 10:22:05,236 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 10:22:05,298 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-08 10:22:05,336 [INFO] _________________________________________________________________
2020-01-08 10:22:05,336 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 10:22:05,336 [INFO] =================================================================
2020-01-08 10:22:05,336 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-08 10:22:05,336 [INFO] _________________________________________________________________
2020-01-08 10:22:05,336 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-08 10:22:05,336 [INFO] _________________________________________________________________
2020-01-08 10:22:05,336 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-08 10:22:05,336 [INFO] _________________________________________________________________
2020-01-08 10:22:05,336 [INFO] dense_2 (Dense)              (None, 15)                975       
2020-01-08 10:22:05,336 [INFO] =================================================================
2020-01-08 10:22:05,336 [INFO] Total params: 6,223
2020-01-08 10:22:05,336 [INFO] Trainable params: 6,095
2020-01-08 10:22:05,337 [INFO] Non-trainable params: 128
2020-01-08 10:22:05,337 [INFO] _________________________________________________________________
2020-01-08 10:22:05,337 [INFO] Training model
2020-01-08 10:22:05,337 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-08 10:22:26,265 [INFO] Split sizes (instances). total = 1936462, set1 = 1452346, set2 = 484116, set1 dataset hash = 380d72269f5bf1f4655cd65f184fdaf215e4cb4b
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 10:22:26,665 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-08 10:22:26.936387: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-08 10:22:26.956722: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2020-01-08 10:22:26.956912: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x53b8680 executing computations on platform Host. Devices:
2020-01-08 10:22:26.956937: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 6s - loss: 0.0291 - val_loss: 0.0098
 - val_f1: 0.9752
Epoch 2/200
 - 5s - loss: 0.0103 - val_loss: 0.0092
 - val_f1: 0.9759
Epoch 3/200
 - 6s - loss: 0.0094 - val_loss: 0.0087
 - val_f1: 0.9774
Epoch 4/200
 - 6s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9757
Epoch 5/200
 - 6s - loss: 0.0089 - val_loss: 0.0090
 - val_f1: 0.9764
Epoch 6/200
 - 5s - loss: 0.0087 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 7/200
 - 5s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 8/200
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 9/200
 - 5s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 10/200
 - 6s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 11/200
 - 5s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 12/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 13/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9753
Epoch 14/200
 - 5s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9780
Epoch 15/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 16/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 17/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 18/200
 - 5s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 19/200
 - 6s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9780
Epoch 20/200
 - 6s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9774
Epoch 21/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 10:26:15,473 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9755
Epoch 22/200
 - 6s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9750
Epoch 23/200
 - 5s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 24/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 25/200
 - 6s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9780
Epoch 26/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 27/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 28/200
 - 5s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 29/200
 - 5s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 30/200
 - 6s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 31/200
 - 5s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 32/200
 - 5s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 33/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 34/200
 - 5s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 35/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 36/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 37/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 38/200
 - 5s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 39/200
 - 5s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 40/200
 - 5s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 41/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
2020-01-08 10:29:58,974 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9782
Epoch 42/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 43/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 44/200
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 45/200
 - 5s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 46/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 47/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 48/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 49/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 50/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9765
Epoch 51/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 52/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 53/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 54/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 55/200
 - 5s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 56/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 57/200
 - 5s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 58/200
 - 5s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 59/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 60/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 61/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
2020-01-08 10:33:42,450 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 63/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 64/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 65/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 66/200
 - 5s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 67/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9766
Epoch 68/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 69/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 70/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 71/200
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 72/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 73/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 74/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 75/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 76/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 77/200
 - 5s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 78/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 79/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 80/200
 - 5s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 81/200
 - 5s - loss: 0.0081 - val_loss: 0.0083
2020-01-08 10:37:25,864 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9777
Epoch 82/200
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 83/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 84/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 85/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 86/200
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9763
Epoch 87/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 88/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 89/200
 - 5s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9763
Epoch 90/200
 - 5s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 91/200
 - 5s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 92/200
 - 5s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 93/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 94/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 95/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 96/200
 - 5s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 97/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9762
Epoch 98/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 99/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9769
Epoch 100/200
 - 5s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 101/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 10:41:09,231 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9783
Epoch 102/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 103/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 104/200
 - 5s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 105/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 106/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 10:42:10,800 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 10:42:22,905 [INFO] Last epoch loss evaluation: train_loss = 0.007898, val_loss = 0.007962
2020-01-08 10:42:22,946 [INFO] Training complete. time_to_train = 1217.61 sec, 20.29 min
2020-01-08 10:42:22,949 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/best_model.pickle
2020-01-08 10:42:22,951 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_error_history.csv
2020-01-08 10:42:23,131 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_error_history.png
2020-01-08 10:42:23,309 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_f1_history.png
2020-01-08 10:42:23,309 [INFO] Making predictions on training, validation, testing data
2020-01-08 10:42:48,583 [INFO] Evaluating predictions (results)
2020-01-08 10:43:00,742 [INFO] Dataset: Testing. Classification report below
2020-01-08 10:43:00,743 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.12      0.22        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.00      0.00      0.00        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.56      5596
   DoS attacks-Slowloris       0.81      0.95      0.87       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.38      0.01      0.02      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.84      0.68      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 10:43:00,743 [INFO] Overall accuracy (micro avg): 0.9829384899486899
/home/sunanda/test/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-08 10:43:14,400 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.8376                       0.6830                0.0044                   0.3170  0.7060
2  Weighted avg        0.9908         0.9771                       0.9829                0.0493                   0.0171  0.9778
2020-01-08 10:43:26,453 [INFO] Dataset: Validation. Classification report below
2020-01-08 10:43:26,453 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.20      0.33        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.11      0.01      0.03        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.45      0.56      5596
   DoS attacks-Slowloris       0.81      0.95      0.87       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.43      0.01      0.02      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.85      0.69      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 10:43:26,453 [INFO] Overall accuracy (micro avg): 0.9830097275390519
2020-01-08 10:43:40,124 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.8487                       0.6942                0.0044                   0.3058  0.7173
2  Weighted avg        0.9909         0.9777                       0.9830                0.0491                   0.0170  0.9779
2020-01-08 10:44:19,412 [INFO] Dataset: Training. Classification report below
2020-01-08 10:44:19,412 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.82      0.12      0.21        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.18      0.01      0.03       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.45      0.56     16787
   DoS attacks-Slowloris       0.84      0.97      0.90      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.42      0.01      0.02     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.69      0.71   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 10:44:19,412 [INFO] Overall accuracy (micro avg): 0.9830164495869271
2020-01-08 10:45:03,977 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.8423                       0.6853                0.0044                   0.3147  0.7091
2  Weighted avg        0.9909         0.9776                       0.9830                0.0492                   0.0170  0.9779
2020-01-08 10:45:04,036 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/semi_sup_perf_ids18_subset_ann_rep1_results.xlsx
2020-01-08 10:45:04,045 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-08 10:45:04,124 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2
2020-01-08 10:45:04,124 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/run_log.log
2020-01-08 10:45:04,124 [INFO] ================= Running experiment no. 2  ================= 

2020-01-08 10:45:04,124 [INFO] Experiment parameters given below
2020-01-08 10:45:04,124 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep2'}
2020-01-08 10:45:04,124 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/tf_logs_run_2020_01_08-10_45_04
2020-01-08 10:45:04,124 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 10:45:04,125 [INFO] Reading X, y files
2020-01-08 10:45:04,125 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 10:45:08,431 [INFO] Reading complete. time_to_read=4.31 seconds
2020-01-08 10:45:08,431 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 10:45:09,907 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-08 10:45:09,907 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 10:45:11,395 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-08 10:45:11,395 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 10:45:11,651 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-08 10:45:11,651 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 10:45:11,728 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 10:45:11,728 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 10:45:11,806 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 10:45:15,435 [INFO] Initializing model
2020-01-08 10:45:15,538 [INFO] _________________________________________________________________
2020-01-08 10:45:15,538 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 10:45:15,538 [INFO] =================================================================
2020-01-08 10:45:15,538 [INFO] dense_3 (Dense)              (None, 64)                4992      
2020-01-08 10:45:15,538 [INFO] _________________________________________________________________
2020-01-08 10:45:15,538 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-08 10:45:15,538 [INFO] _________________________________________________________________
2020-01-08 10:45:15,538 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-08 10:45:15,538 [INFO] _________________________________________________________________
2020-01-08 10:45:15,538 [INFO] dense_4 (Dense)              (None, 15)                975       
2020-01-08 10:45:15,538 [INFO] =================================================================
2020-01-08 10:45:15,538 [INFO] Total params: 6,223
2020-01-08 10:45:15,538 [INFO] Trainable params: 6,095
2020-01-08 10:45:15,538 [INFO] Non-trainable params: 128
2020-01-08 10:45:15,538 [INFO] _________________________________________________________________
2020-01-08 10:45:15,538 [INFO] Training model
2020-01-08 10:45:15,539 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-08 10:45:36,468 [INFO] Split sizes (instances). total = 1936462, set1 = 1452346, set2 = 484116, set1 dataset hash = 451b88645977a5a563e4faa1956ec3ea034501bc
 - val_f1: 0.9782
Epoch 00106: early stopping
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 6s - loss: 0.0302 - val_loss: 0.0101
 - val_f1: 0.9722
Epoch 2/200
 - 6s - loss: 0.0104 - val_loss: 0.0090
 - val_f1: 0.9762
Epoch 3/200
 - 6s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 4/200
 - 6s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 5/200
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 6/200
 - 6s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 7/200
 - 6s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 8/200
 - 6s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 9/200
 - 6s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9759
Epoch 10/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 11/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 12/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 13/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 14/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 15/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 16/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 17/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 18/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 19/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9763
Epoch 20/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 21/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 10:49:34,698 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9760
Epoch 22/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 23/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 24/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 25/200
 - 6s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9763
Epoch 26/200
 - 6s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 27/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 28/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9763
Epoch 29/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 30/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 31/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 32/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 33/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 34/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 35/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 36/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 37/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 38/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 39/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 40/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 41/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
2020-01-08 10:53:26,913 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9777
Epoch 42/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 43/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 44/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 45/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 46/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9760
Epoch 47/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 48/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 49/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 50/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 51/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 52/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 53/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 54/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 55/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 56/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 57/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 58/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 59/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 60/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 61/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
2020-01-08 10:57:19,253 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9780
Epoch 62/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 63/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9762
Epoch 64/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 65/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 66/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 67/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 68/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 69/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 70/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 71/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 72/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 73/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 74/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 75/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 76/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 77/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 78/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 79/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9770
Epoch 80/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 81/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
2020-01-08 11:01:11,324 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9762
Epoch 82/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 83/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 84/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 85/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 86/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 87/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 88/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 89/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 90/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 91/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9787
Epoch 92/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 93/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 94/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 95/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 96/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 97/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 98/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 99/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 100/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 101/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 11:05:03,885 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9780
Epoch 102/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 103/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 104/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 105/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 106/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 107/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 108/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 109/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 110/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 111/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 112/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 113/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 114/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 115/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 116/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 117/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 118/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 119/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 120/200
 - 6s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 121/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 11:08:55,512 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9780
Epoch 122/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 123/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 124/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 125/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 126/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 127/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 128/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9763
Epoch 129/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 130/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 131/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 132/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 133/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 134/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 135/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 136/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 137/200
 - 6s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 138/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 139/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 140/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 141/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
2020-01-08 11:12:47,282 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9782
Epoch 142/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 143/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 144/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 145/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9762
Epoch 146/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 147/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 148/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 149/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 150/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 151/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 152/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 153/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 154/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 155/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 156/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 157/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 158/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 159/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 160/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 161/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
2020-01-08 11:16:39,775 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9779
Epoch 162/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 163/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 164/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 165/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 166/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 167/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 168/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 169/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 170/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 171/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 172/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 173/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 174/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 175/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 176/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 177/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 178/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 179/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 180/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 181/200
 - 6s - loss: 0.0079 - val_loss: 0.0082
2020-01-08 11:20:32,017 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9777
Epoch 182/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 183/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 184/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 185/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 186/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 187/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 188/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
2020-01-08 11:21:59,632 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 11:22:12,400 [INFO] Last epoch loss evaluation: train_loss = 0.007781, val_loss = 0.007882
2020-01-08 11:22:12,443 [INFO] Training complete. time_to_train = 2216.90 sec, 36.95 min
2020-01-08 11:22:12,446 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/best_model.pickle
2020-01-08 11:22:12,448 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_error_history.csv
2020-01-08 11:22:12,625 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_error_history.png
2020-01-08 11:22:12,806 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_f1_history.png
2020-01-08 11:22:12,806 [INFO] Making predictions on training, validation, testing data
2020-01-08 11:22:40,156 [INFO] Evaluating predictions (results)
2020-01-08 11:22:52,271 [INFO] Dataset: Testing. Classification report below
2020-01-08 11:22:52,271 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.12      0.22        24
        Brute Force -XSS       0.75      0.33      0.46         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.95      0.94      0.94       440
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.45      0.00      0.01      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.88      0.75      0.77    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 11:22:52,271 [INFO] Overall accuracy (micro avg): 0.9836216939741714
2020-01-08 11:23:06,038 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.8836                       0.7518                0.0044                   0.2482  0.7658
2  Weighted avg        0.9910         0.9784                       0.9836                0.0497                   0.0164  0.9785
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 11:23:18,267 [INFO] Dataset: Validation. Classification report below
2020-01-08 11:23:18,267 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.20      0.33        25
        Brute Force -XSS       0.67      0.67      0.67         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.51      0.61      5596
   DoS attacks-Slowloris       0.94      0.96      0.95       439
          FTP-BruteForce       0.71      0.88      0.79      7718
           Infilteration       0.44      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.81      0.75      0.74    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 11:23:18,267 [INFO] Overall accuracy (micro avg): 0.9836758912263144
/home/sunanda/test/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-08 11:23:32,140 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.8135                       0.7473                0.0044                   0.2527  0.7448
2  Weighted avg        0.9910         0.9784                       0.9837                0.0495                   0.0163  0.9786
2020-01-08 11:24:11,467 [INFO] Dataset: Training. Classification report below
2020-01-08 11:24:11,467 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.12      0.22        73
        Brute Force -XSS       0.93      0.50      0.65        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.75      0.51      0.61     16787
   DoS attacks-Slowloris       0.95      0.98      0.97      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.47      0.00      0.01     19210
           SQL Injection       0.75      0.25      0.38        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.88      0.75      0.76   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 11:24:11,467 [INFO] Overall accuracy (micro avg): 0.9836666043537131
2020-01-08 11:24:56,114 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.8828                       0.7481                0.0044                   0.2519  0.7610
2  Weighted avg        0.9910         0.9787                       0.9837                0.0495                   0.0163  0.9786
2020-01-08 11:24:56,174 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/semi_sup_perf_ids18_subset_ann_rep2_results.xlsx
2020-01-08 11:24:56,178 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-08 11:24:56,258 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3
2020-01-08 11:24:56,259 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/run_log.log
2020-01-08 11:24:56,259 [INFO] ================= Running experiment no. 3  ================= 

2020-01-08 11:24:56,259 [INFO] Experiment parameters given below
2020-01-08 11:24:56,259 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.75, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep3'}
2020-01-08 11:24:56,259 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/tf_logs_run_2020_01_08-11_24_56
2020-01-08 11:24:56,259 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-08 11:24:56,259 [INFO] Reading X, y files
2020-01-08 11:24:56,259 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-08 11:25:00,583 [INFO] Reading complete. time_to_read=4.32 seconds
2020-01-08 11:25:00,583 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-08 11:25:02,064 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-08 11:25:02,065 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-08 11:25:03,546 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-08 11:25:03,547 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-08 11:25:03,790 [INFO] Reading complete. time_to_read=0.24 seconds
2020-01-08 11:25:03,790 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-08 11:25:03,868 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 11:25:03,868 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-08 11:25:03,945 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-08 11:25:07,562 [INFO] Initializing model
2020-01-08 11:25:07,665 [INFO] _________________________________________________________________
2020-01-08 11:25:07,665 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-08 11:25:07,665 [INFO] =================================================================
2020-01-08 11:25:07,666 [INFO] dense_5 (Dense)              (None, 64)                4992      
2020-01-08 11:25:07,666 [INFO] _________________________________________________________________
2020-01-08 11:25:07,666 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-08 11:25:07,666 [INFO] _________________________________________________________________
2020-01-08 11:25:07,666 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-08 11:25:07,666 [INFO] _________________________________________________________________
2020-01-08 11:25:07,666 [INFO] dense_6 (Dense)              (None, 15)                975       
2020-01-08 11:25:07,666 [INFO] =================================================================
2020-01-08 11:25:07,666 [INFO] Total params: 6,223
2020-01-08 11:25:07,666 [INFO] Trainable params: 6,095
2020-01-08 11:25:07,666 [INFO] Non-trainable params: 128
2020-01-08 11:25:07,666 [INFO] _________________________________________________________________
2020-01-08 11:25:07,666 [INFO] Training model
2020-01-08 11:25:07,666 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-08 11:25:29,099 [INFO] Split sizes (instances). total = 1936462, set1 = 1452346, set2 = 484116, set1 dataset hash = 451b88645977a5a563e4faa1956ec3ea034501bc
 - val_f1: 0.9781
Epoch 00188: early stopping
Train on 484116 samples, validate on 645487 samples
Epoch 1/200
 - 6s - loss: 0.0303 - val_loss: 0.0100
 - val_f1: 0.9749
Epoch 2/200
 - 6s - loss: 0.0101 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 3/200
 - 6s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 4/200
 - 6s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 5/200
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 6/200
 - 6s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 7/200
 - 6s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 8/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 9/200
 - 6s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 10/200
 - 6s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 11/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 12/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 13/200
 - 6s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 14/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 15/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 16/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 17/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 18/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 19/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 20/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 21/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-08 11:29:34,709 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9783
Epoch 22/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 23/200
 - 6s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9770
Epoch 24/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9755
Epoch 25/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9760
Epoch 26/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 27/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 28/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 29/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 30/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 31/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 32/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 33/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 34/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9763
Epoch 35/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 36/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 37/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 38/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 39/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 40/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 41/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
2020-01-08 11:33:33,417 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9778
Epoch 42/200
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 43/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 44/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 45/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 46/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 47/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 48/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9753
Epoch 49/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 50/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 51/200
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 52/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 53/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 54/200
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 55/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 56/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 57/200
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 58/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 59/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 60/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 61/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
2020-01-08 11:37:32,912 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9777
Epoch 62/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 63/200
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 64/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 65/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 66/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 67/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 68/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 69/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 70/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 71/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 72/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 73/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 74/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 75/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 76/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 77/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 78/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 79/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9759
Epoch 80/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 81/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
2020-01-08 11:41:31,305 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9781
Epoch 82/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 83/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 84/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 85/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 86/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 87/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 88/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 89/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 90/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 91/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 92/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 93/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 94/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 95/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 96/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 97/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 98/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 99/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 100/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 101/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 11:45:30,027 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9780
Epoch 102/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 103/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 104/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 105/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 106/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 107/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 108/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 109/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 110/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 111/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 112/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 113/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 114/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 115/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 116/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 117/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 118/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 119/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 120/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 121/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
2020-01-08 11:49:28,526 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9784
Epoch 122/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 123/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 124/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 125/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 126/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 127/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 128/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 129/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 130/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 131/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 132/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 133/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9765
Epoch 134/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 135/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 136/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 137/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 138/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 139/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 140/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 141/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
2020-01-08 11:53:27,240 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 143/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 144/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 145/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 146/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 147/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 148/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 149/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 150/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 151/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 152/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 153/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 154/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 155/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 156/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 157/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 158/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 159/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 160/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 161/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 11:57:26,949 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9778
Epoch 162/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 163/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 164/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 165/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 166/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 167/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 168/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 169/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 170/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 171/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 172/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 173/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9786
Epoch 174/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 175/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 176/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 177/200
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 178/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 179/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 180/200
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 181/200
 - 6s - loss: 0.0080 - val_loss: 0.0080
2020-01-08 12:01:26,670 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9780
Epoch 182/200
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 183/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 184/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 185/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 186/200
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 187/200
 - 6s - loss: 0.0079 - val_loss: 0.0080
2020-01-08 12:02:44,313 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-08 12:02:57,727 [INFO] Last epoch loss evaluation: train_loss = 0.007792, val_loss = 0.007883
2020-01-08 12:02:57,767 [INFO] Training complete. time_to_train = 2270.10 sec, 37.84 min
2020-01-08 12:02:57,770 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/best_model.pickle
2020-01-08 12:02:57,773 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_error_history.csv
2020-01-08 12:02:57,948 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_error_history.png
2020-01-08 12:02:58,134 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_f1_history.png
2020-01-08 12:02:58,134 [INFO] Making predictions on training, validation, testing data
2020-01-08 12:03:26,501 [INFO] Evaluating predictions (results)
2020-01-08 12:03:38,580 [INFO] Dataset: Testing. Classification report below
2020-01-08 12:03:38,580 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.12      0.22        24
        Brute Force -XSS       0.75      0.33      0.46         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.67      0.12      0.20        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.57      5596
   DoS attacks-Slowloris       0.96      0.95      0.96       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.34      0.01      0.02      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.87      0.69      0.72    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-08 12:03:38,580 [INFO] Overall accuracy (micro avg): 0.9830872146345091
2020-01-08 12:03:52,333 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.8741                       0.6911                0.0044                   0.3089  0.7233
2  Weighted avg        0.9909         0.9770                       0.9831                0.0496                   0.0169  0.9781
2020-01-08 12:04:04,319 [INFO] Dataset: Validation. Classification report below
2020-01-08 12:04:04,319 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.16      0.28        25
        Brute Force -XSS       0.86      0.67      0.75         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.57      0.12      0.20        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.56      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.35      0.01      0.02      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.88      0.70      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-08 12:04:04,319 [INFO] Overall accuracy (micro avg): 0.9831243696619761
2020-01-08 12:04:17,919 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.8753                       0.6999                0.0044                   0.3001  0.7281
2  Weighted avg        0.9909         0.9771                       0.9831                0.0494                   0.0169  0.9781
2020-01-08 12:04:57,713 [INFO] Dataset: Training. Classification report below
2020-01-08 12:04:57,713 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.12      0.22        73
        Brute Force -XSS       0.81      0.50      0.62        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.63      0.11      0.18       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.46      0.56     16787
   DoS attacks-Slowloris       0.97      0.97      0.97      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.36      0.01      0.02     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.88      0.69      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-08 12:04:57,714 [INFO] Overall accuracy (micro avg): 0.9831259275937251
2020-01-08 12:05:42,904 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9978         0.8773                       0.6920                0.0044                   0.3080  0.7223
2  Weighted avg        0.9909         0.9772                       0.9831                0.0494                   0.0169  0.9781
2020-01-08 12:05:42,960 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/semi_sup_perf_ids18_subset_ann_rep3_results.xlsx
2020-01-08 12:05:42,965 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-08 12:05:43,046 [INFO] ================= Finished running 3 experiments ================= 

 - val_f1: 0.9779
Epoch 00187: early stopping
