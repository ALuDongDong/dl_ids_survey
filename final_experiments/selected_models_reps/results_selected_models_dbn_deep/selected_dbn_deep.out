Using TensorFlow backend.
2019-12-24 10:45:36,995 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_deep_rep1/run_log.log
2019-12-24 10:45:36,995 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 10:45:36,995 [INFO] Experiment parameters given below
2019-12-24 10:45:36,995 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_deep_rep1'}
2019-12-24 10:45:36,995 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_deep_rep1/tf_logs_run_2019_12_24-10_45_36
2019-12-24 10:45:36,995 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-24 10:45:36,996 [INFO] Reading X, y files
2019-12-24 10:45:36,996 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-24 10:45:37,267 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-24 10:45:37,267 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-24 10:45:37,334 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 10:45:37,334 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-24 10:45:37,394 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 10:45:37,394 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-24 10:45:37,401 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-24 10:45:37,401 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-24 10:45:37,405 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 10:45:37,405 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-24 10:45:37,408 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 10:45:37,620 [INFO] Initializing model
2019-12-24 10:45:37,620 [INFO] Training model
2019-12-24 10:45:37,620 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 10:45:38,413 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 803dd960711af56339061c14185bc8c0e993768f
2019-12-24 10:45:38,413 [INFO] Pretraining Deep Belief Network
[BernoulliRBM] Iteration 1, pseudo-likelihood = -54.08, time = 0.38s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -54.83, time = 0.68s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -60.25, time = 0.68s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -66.28, time = 0.68s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -71.59, time = 0.68s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -75.93, time = 0.68s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -79.50, time = 0.68s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -82.42, time = 0.68s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -84.85, time = 0.68s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -86.88, time = 0.68s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -88.56, time = 0.67s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -89.93, time = 0.67s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -91.05, time = 0.67s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -91.85, time = 0.66s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -92.43, time = 0.66s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -92.82, time = 0.65s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -93.03, time = 0.65s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -93.11, time = 0.65s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -93.16, time = 0.65s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -93.17, time = 0.65s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -93.18, time = 0.64s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -93.28, time = 0.65s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -93.40, time = 0.64s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -93.61, time = 0.64s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -93.89, time = 0.64s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -94.24, time = 0.64s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -94.73, time = 0.64s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -95.30, time = 0.64s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -95.99, time = 0.64s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -96.85, time = 0.64s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -97.84, time = 0.64s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -99.03, time = 0.64s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -100.35, time = 0.64s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -101.80, time = 0.64s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -103.33, time = 0.64s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -104.92, time = 0.64s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -106.55, time = 0.64s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -108.22, time = 0.64s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -109.87, time = 0.64s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -111.60, time = 0.64s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -113.23, time = 0.64s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -114.91, time = 0.63s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -116.64, time = 0.64s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -118.37, time = 0.64s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -120.06, time = 0.63s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -121.74, time = 0.64s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -123.42, time = 0.64s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -125.16, time = 0.64s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -126.86, time = 0.64s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -128.54, time = 0.63s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -84.69, time = 0.23s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -80.17, time = 0.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -78.33, time = 0.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -77.65, time = 0.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -77.28, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -76.95, time = 0.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -76.59, time = 0.37s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -76.08, time = 0.38s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -75.41, time = 0.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.66, time = 0.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -73.81, time = 0.37s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -72.87, time = 0.38s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -71.72, time = 0.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -70.29, time = 0.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -68.64, time = 0.37s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -66.92, time = 0.38s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -65.27, time = 0.37s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -63.59, time = 0.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -62.05, time = 0.37s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -60.58, time = 0.37s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -59.24, time = 0.37s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -58.09, time = 0.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -57.06, time = 0.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.18, time = 0.37s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -55.34, time = 0.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -54.61, time = 0.37s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -53.85, time = 0.37s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -53.20, time = 0.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -52.44, time = 0.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -51.63, time = 0.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -50.62, time = 0.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -49.30, time = 0.37s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -48.16, time = 0.37s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -47.71, time = 0.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -46.35, time = 0.37s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -44.98, time = 0.37s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.98, time = 0.36s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -43.25, time = 0.37s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.69, time = 0.36s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -42.22, time = 0.36s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.83, time = 0.37s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -41.51, time = 0.36s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -41.28, time = 0.36s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -40.99, time = 0.36s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -40.73, time = 0.37s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -40.57, time = 0.36s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -40.47, time = 0.36s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -40.37, time = 0.36s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -40.17, time = 0.37s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -39.97, time = 0.36s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -41.93, time = 0.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.17, time = 0.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -37.05, time = 0.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.77, time = 0.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.05, time = 0.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.62, time = 0.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -34.34, time = 0.19s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -34.12, time = 0.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -33.94, time = 0.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -33.78, time = 0.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.61, time = 0.19s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -33.44, time = 0.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -33.26, time = 0.20s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -33.06, time = 0.19s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -32.83, time = 0.19s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -32.58, time = 0.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -32.31, time = 0.19s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -31.99, time = 0.19s2019-12-24 10:46:39,026 [INFO] Pretraining Complete
2019-12-24 10:46:39,026 [INFO] Getting pretrained weights
2019-12-24 10:46:39,026 [INFO] Creating and initializing feed forward neural network
2019-12-24 10:46:39,027 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-24 10:46:39,102 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-24 10:46:39,103 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-24 10:46:39,161 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-24 10:46:39,176 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-24 10:46:39,340 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-24 10:46:39,353 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-24 10:46:39,356 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-24 10:46:39,365 [INFO] _________________________________________________________________
2019-12-24 10:46:39,365 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 10:46:39,365 [INFO] =================================================================
2019-12-24 10:46:39,365 [INFO] dense_1 (Dense)              (None, 128)               15744     
2019-12-24 10:46:39,365 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] batch_normalization_1 (Batch (None, 128)               512       
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] dropout_1 (Dropout)          (None, 128)               0         
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] dense_2 (Dense)              (None, 64)                8256      
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] dense_3 (Dense)              (None, 32)                2080      
2019-12-24 10:46:39,366 [INFO] _________________________________________________________________
2019-12-24 10:46:39,366 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-24 10:46:39,367 [INFO] _________________________________________________________________
2019-12-24 10:46:39,367 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-24 10:46:39,367 [INFO] _________________________________________________________________
2019-12-24 10:46:39,367 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-24 10:46:39,367 [INFO] =================================================================
2019-12-24 10:46:39,367 [INFO] Total params: 27,141
2019-12-24 10:46:39,367 [INFO] Trainable params: 26,693
2019-12-24 10:46:39,367 [INFO] Non-trainable params: 448
2019-12-24 10:46:39,367 [INFO] _________________________________________________________________
2019-12-24 10:46:39.378616: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-24 10:46:39.544956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2019-12-24 10:46:39.545199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563c4c92b9e0 executing computations on platform Host. Devices:
2019-12-24 10:46:39.545227: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-24 10:46:39.682678: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-24 10:46:39,747 [INFO] Fine-tuning final neural network
2019-12-24 10:46:42,800 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-24 10:46:42,800 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.


[BernoulliRBM] Iteration 19, pseudo-likelihood = -31.64, time = 0.19s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -31.24, time = 0.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -30.79, time = 0.19s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -30.29, time = 0.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -29.74, time = 0.19s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -29.13, time = 0.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.48, time = 0.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -27.83, time = 0.19s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -27.12, time = 0.19s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -26.38, time = 0.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -25.61, time = 0.19s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -24.79, time = 0.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -23.94, time = 0.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -23.06, time = 0.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -22.19, time = 0.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -21.41, time = 0.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -20.65, time = 0.19s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -19.98, time = 0.19s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -19.34, time = 0.19s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -18.86, time = 0.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -18.34, time = 0.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -17.89, time = 0.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -17.63, time = 0.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -17.33, time = 0.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -17.03, time = 0.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -16.71, time = 0.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -16.44, time = 0.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -16.21, time = 0.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -15.99, time = 0.19s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -15.80, time = 0.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -15.63, time = 0.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -15.48, time = 0.19s
Train on 75584 samples, validate on 25195 samples
Epoch 1/300
 - 2s - loss: 0.1803 - val_loss: 0.0918
 - val_f1: 0.8922
Epoch 2/300
 - 1s - loss: 0.0716 - val_loss: 0.0432
 - val_f1: 0.9678
Epoch 3/300
 - 1s - loss: 0.0432 - val_loss: 0.0286
 - val_f1: 0.9692
Epoch 4/300
 - 1s - loss: 0.0328 - val_loss: 0.0205
 - val_f1: 0.9759
Epoch 5/300
 - 1s - loss: 0.0272 - val_loss: 0.0188
 - val_f1: 0.9831
Epoch 6/300
 - 1s - loss: 0.0248 - val_loss: 0.0150
 - val_f1: 0.9865
Epoch 7/300
 - 1s - loss: 0.0221 - val_loss: 0.0137
 - val_f1: 0.9869
Epoch 8/300
 - 1s - loss: 0.0195 - val_loss: 0.0125
 - val_f1: 0.9875
Epoch 9/300
 - 1s - loss: 0.0184 - val_loss: 0.0115
 - val_f1: 0.9889
Epoch 10/300
 - 1s - loss: 0.0169 - val_loss: 0.0111
 - val_f1: 0.9913
Epoch 11/300
 - 1s - loss: 0.0160 - val_loss: 0.0108
 - val_f1: 0.9901
Epoch 12/300
 - 1s - loss: 0.0157 - val_loss: 0.0106
 - val_f1: 0.9905
Epoch 13/300
 - 1s - loss: 0.0148 - val_loss: 0.0097
 - val_f1: 0.9926
Epoch 14/300
 - 1s - loss: 0.0146 - val_loss: 0.0096
 - val_f1: 0.9919
Epoch 15/300
 - 1s - loss: 0.0139 - val_loss: 0.0096
 - val_f1: 0.9926
Epoch 16/300
 - 1s - loss: 0.0135 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 17/300
 - 1s - loss: 0.0125 - val_loss: 0.0092
 - val_f1: 0.9928
Epoch 18/300
 - 1s - loss: 0.0123 - val_loss: 0.0096
 - val_f1: 0.9921
Epoch 19/300
 - 1s - loss: 0.0124 - val_loss: 0.0090
 - val_f1: 0.9931
Epoch 20/300
 - 1s - loss: 0.0121 - val_loss: 0.0089
 - val_f1: 0.9930
Epoch 21/300
 - 1s - loss: 0.0117 - val_loss: 0.0089
 - val_f1: 0.9934
Epoch 22/300
 - 1s - loss: 0.0114 - val_loss: 0.0093
 - val_f1: 0.9926
Epoch 23/300
 - 1s - loss: 0.0114 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 24/300
 - 1s - loss: 0.0110 - val_loss: 0.0083
 - val_f1: 0.9934
Epoch 25/300
 - 1s - loss: 0.0103 - val_loss: 0.0083
 - val_f1: 0.9933
Epoch 26/300
 - 1s - loss: 0.0107 - val_loss: 0.0081
 - val_f1: 0.9942
Epoch 27/300
 - 1s - loss: 0.0098 - val_loss: 0.0082
 - val_f1: 0.9936
Epoch 28/300
 - 1s - loss: 0.0102 - val_loss: 0.0083
 - val_f1: 0.9930
Epoch 29/300
 - 1s - loss: 0.0099 - val_loss: 0.0079
 - val_f1: 0.9946
Epoch 30/300
 - 1s - loss: 0.0097 - val_loss: 0.0084
 - val_f1: 0.9941
Epoch 31/300
 - 1s - loss: 0.0096 - val_loss: 0.0081
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 10:47:32,499 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9945
Epoch 32/300
 - 1s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9947
Epoch 33/300
 - 1s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9948
Epoch 34/300
 - 1s - loss: 0.0096 - val_loss: 0.0078
 - val_f1: 0.9947
Epoch 35/300
 - 1s - loss: 0.0086 - val_loss: 0.0077
 - val_f1: 0.9935
Epoch 36/300
 - 1s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 37/300
 - 1s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9944
Epoch 38/300
 - 1s - loss: 0.0089 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 39/300
 - 1s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9947
Epoch 40/300
 - 1s - loss: 0.0083 - val_loss: 0.0074
 - val_f1: 0.9945
Epoch 41/300
 - 1s - loss: 0.0078 - val_loss: 0.0074
 - val_f1: 0.9951
Epoch 42/300
 - 1s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9950
Epoch 43/300
 - 1s - loss: 0.0082 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 44/300
 - 1s - loss: 0.0077 - val_loss: 0.0069
 - val_f1: 0.9944
Epoch 45/300
 - 1s - loss: 0.0075 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 46/300
 - 1s - loss: 0.0079 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 47/300
 - 1s - loss: 0.0077 - val_loss: 0.0066
 - val_f1: 0.9952
Epoch 48/300
 - 1s - loss: 0.0075 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 49/300
 - 1s - loss: 0.0076 - val_loss: 0.0068
 - val_f1: 0.9950
Epoch 50/300
 - 1s - loss: 0.0079 - val_loss: 0.0066
 - val_f1: 0.9949
Epoch 51/300
 - 1s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9943
Epoch 52/300
 - 1s - loss: 0.0070 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 53/300
 - 1s - loss: 0.0071 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 54/300
 - 1s - loss: 0.0069 - val_loss: 0.0063
 - val_f1: 0.9953
Epoch 55/300
 - 1s - loss: 0.0067 - val_loss: 0.0062
 - val_f1: 0.9960
Epoch 56/300
 - 1s - loss: 0.0067 - val_loss: 0.0068
 - val_f1: 0.9949
Epoch 57/300
 - 1s - loss: 0.0070 - val_loss: 0.0062
 - val_f1: 0.9962
Epoch 58/300
 - 1s - loss: 0.0065 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 59/300
 - 1s - loss: 0.0067 - val_loss: 0.0062
 - val_f1: 0.9959
Epoch 60/300
 - 1s - loss: 0.0064 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 61/300
 - 1s - loss: 0.0065 - val_loss: 0.0058
2019-12-24 10:48:19,166 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9958
Epoch 62/300
 - 1s - loss: 0.0063 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 63/300
 - 1s - loss: 0.0063 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 64/300
 - 1s - loss: 0.0063 - val_loss: 0.0058
 - val_f1: 0.9961
Epoch 65/300
 - 1s - loss: 0.0061 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 66/300
 - 1s - loss: 0.0062 - val_loss: 0.0059
 - val_f1: 0.9963
Epoch 67/300
 - 1s - loss: 0.0060 - val_loss: 0.0061
 - val_f1: 0.9960
Epoch 68/300
 - 1s - loss: 0.0060 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 69/300
 - 1s - loss: 0.0061 - val_loss: 0.0061
 - val_f1: 0.9954
Epoch 70/300
 - 1s - loss: 0.0062 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 71/300
 - 1s - loss: 0.0059 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 72/300
 - 1s - loss: 0.0059 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 73/300
 - 1s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 74/300
 - 1s - loss: 0.0058 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 75/300
 - 1s - loss: 0.0055 - val_loss: 0.0058
 - val_f1: 0.9964
Epoch 76/300
 - 1s - loss: 0.0055 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 77/300
 - 1s - loss: 0.0058 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 78/300
 - 1s - loss: 0.0054 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 79/300
 - 1s - loss: 0.0056 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 80/300
 - 1s - loss: 0.0056 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 81/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 82/300
 - 1s - loss: 0.0055 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 83/300
 - 1s - loss: 0.0054 - val_loss: 0.0061
 - val_f1: 0.9959
Epoch 84/300
 - 1s - loss: 0.0052 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 85/300
 - 1s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 86/300
 - 1s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 87/300
 - 1s - loss: 0.0054 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 88/300
 - 1s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 89/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 90/300
 - 1s - loss: 0.0051 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 91/300
 - 1s - loss: 0.0051 - val_loss: 0.0054
2019-12-24 10:49:05,898 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9962
Epoch 92/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 93/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 94/300
 - 1s - loss: 0.0052 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 95/300
 - 1s - loss: 0.0048 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 96/300
 - 1s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 97/300
 - 1s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 98/300
 - 1s - loss: 0.0049 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 99/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 100/300
 - 1s - loss: 0.0049 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 101/300
 - 1s - loss: 0.0048 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 102/300
 - 1s - loss: 0.0046 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 103/300
 - 1s - loss: 0.0050 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 104/300
 - 1s - loss: 0.0052 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 105/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 106/300
 - 1s - loss: 0.0049 - val_loss: 0.0058
 - val_f1: 0.9961
Epoch 107/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 108/300
 - 1s - loss: 0.0049 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 109/300
 - 1s - loss: 0.0047 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 110/300
 - 1s - loss: 0.0047 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 111/300
 - 1s - loss: 0.0049 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 112/300
 - 1s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 113/300
 - 1s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 114/300
 - 1s - loss: 0.0045 - val_loss: 0.0056
 - val_f1: 0.9963
Epoch 115/300
 - 1s - loss: 0.0049 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 116/300
 - 1s - loss: 0.0045 - val_loss: 0.0053
 - val_f1: 0.9967
Epoch 117/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 118/300
 - 1s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 119/300
 - 1s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 120/300
 - 1s - loss: 0.0046 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 121/300
 - 1s - loss: 0.0044 - val_loss: 0.0059
2019-12-24 10:49:52,368 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9961
Epoch 122/300
 - 1s - loss: 0.0046 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 123/300
 - 1s - loss: 0.0046 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 124/300
 - 1s - loss: 0.0045 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 125/300
 - 1s - loss: 0.0044 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 126/300
 - 1s - loss: 0.0045 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 127/300
 - 1s - loss: 0.0050 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 128/300
 - 1s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 129/300
 - 1s - loss: 0.0042 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 130/300
 - 1s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 131/300
 - 1s - loss: 0.0045 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 132/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 133/300
 - 1s - loss: 0.0044 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 134/300
 - 1s - loss: 0.0043 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 135/300
 - 1s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9967
Epoch 136/300
 - 1s - loss: 0.0043 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 137/300
 - 1s - loss: 0.0043 - val_loss: 0.0053
 - val_f1: 0.9967
Epoch 138/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 139/300
 - 1s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 140/300
 - 1s - loss: 0.0042 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 141/300
 - 1s - loss: 0.0041 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 142/300
 - 1s - loss: 0.0041 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 143/300
 - 1s - loss: 0.0040 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 144/300
 - 1s - loss: 0.0042 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 145/300
 - 1s - loss: 0.0040 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 146/300
 - 1s - loss: 0.0043 - val_loss: 0.0053
 - val_f1: 0.9967
Epoch 147/300
 - 1s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 148/300
 - 1s - loss: 0.0043 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 149/300
 - 1s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 150/300
 - 1s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 151/300
 - 1s - loss: 0.0040 - val_loss: 0.0052
2019-12-24 10:50:38,830 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9965
Epoch 152/300
 - 1s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 153/300
 - 1s - loss: 0.0044 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 154/300
 - 1s - loss: 0.0042 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 155/300
 - 1s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 156/300
 - 1s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 157/300
 - 1s - loss: 0.0038 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 158/300
 - 1s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 159/300
 - 1s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 160/300
 - 1s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 161/300
 - 1s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 162/300
 - 1s - loss: 0.0039 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 163/300
 - 1s - loss: 0.0039 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 164/300
 - 1s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 165/300
 - 1s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 166/300
 - 1s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 167/300
 - 1s - loss: 0.0040 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 168/300
 - 1s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 169/300
 - 1s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 170/300
 - 1s - loss: 0.0041 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 171/300
 - 1s - loss: 0.0041 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 172/300
 - 1s - loss: 0.0037 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 173/300
 - 1s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 174/300
 - 1s - loss: 0.0038 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 175/300
 - 1s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 176/300
 - 1s - loss: 0.0039 - val_loss: 0.0053
 - val_f1: 0.9967
Epoch 177/300
 - 1s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 178/300
 - 1s - loss: 0.0038 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 179/300
 - 1s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 180/300
 - 1s - loss: 0.0036 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 181/300
 - 1s - loss: 0.0039 - val_loss: 0.0056
2019-12-24 10:51:25,644 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9964
Epoch 182/300
 - 1s - loss: 0.0037 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 183/300
 - 1s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 184/300
 - 1s - loss: 0.0039 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 185/300
 - 1s - loss: 0.0038 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 186/300
 - 1s - loss: 0.0038 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 187/300
 - 1s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9968
Epoch 188/300
 - 1s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 189/300
 - 1s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 190/300
 - 1s - loss: 0.0037 - val_loss: 0.0056
 - val_f1: 0.9963
Epoch 191/300
 - 1s - loss: 0.0038 - val_loss: 0.0052
 - val_f1: 0.9967
Epoch 192/300
 - 1s - loss: 0.0034 - val_loss: 0.0056
 - val_f1: 0.9967
Epoch 193/300
 - 1s - loss: 0.0038 - val_loss: 0.0054
 - val_f1: 0.9969
Epoch 194/300
 - 1s - loss: 0.0037 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 195/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9970
Epoch 196/300
 - 1s - loss: 0.0037 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 197/300
 - 1s - loss: 0.0037 - val_loss: 0.0052
 - val_f1: 0.9967
Epoch 198/300
 - 1s - loss: 0.0036 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 199/300
 - 1s - loss: 0.0037 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 200/300
 - 1s - loss: 0.0036 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 201/300
 - 1s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 202/300
 - 1s - loss: 0.0035 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 203/300
 - 1s - loss: 0.0037 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 204/300
 - 1s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 205/300
 - 1s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 206/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 207/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 208/300
 - 1s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9970
Epoch 209/300
 - 1s - loss: 0.0035 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 210/300
 - 1s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 211/300
 - 1s - loss: 0.0034 - val_loss: 0.0053
2019-12-24 10:52:12,205 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9968
Epoch 212/300
 - 1s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 213/300
 - 1s - loss: 0.0036 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 214/300
 - 1s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 215/300
 - 1s - loss: 0.0037 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 216/300
 - 1s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9970
Epoch 217/300
 - 1s - loss: 0.0035 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 218/300
 - 1s - loss: 0.0034 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 219/300
 - 1s - loss: 0.0034 - val_loss: 0.0057
 - val_f1: 0.9967
Epoch 220/300
 - 1s - loss: 0.0037 - val_loss: 0.0057
 - val_f1: 0.9968
Epoch 221/300
 - 1s - loss: 0.0036 - val_loss: 0.0056
 - val_f1: 0.9968
Epoch 222/300
 - 1s - loss: 0.0036 - val_loss: 0.0056
 - val_f1: 0.9967
Epoch 223/300
 - 1s - loss: 0.0035 - val_loss: 0.0061
 - val_f1: 0.9965
Epoch 224/300
 - 1s - loss: 0.0037 - val_loss: 0.0057
 - val_f1: 0.9967
Epoch 225/300
 - 1s - loss: 0.0034 - val_loss: 0.0057
 - val_f1: 0.9967
Epoch 226/300
 - 1s - loss: 0.0035 - val_loss: 0.0057
 - val_f1: 0.9968
Epoch 227/300
 - 1s - loss: 0.0035 - val_loss: 0.0053
 - val_f1: 0.9966
Epoch 228/300
 - 1s - loss: 0.0033 - val_loss: 0.0062
 - val_f1: 0.9962
Epoch 229/300
 - 1s - loss: 0.0033 - val_loss: 0.0058
 - val_f1: 0.9969
Epoch 230/300
 - 1s - loss: 0.0035 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 231/300
 - 1s - loss: 0.0034 - val_loss: 0.0058
 - val_f1: 0.9966
Epoch 232/300
 - 1s - loss: 0.0033 - val_loss: 0.0057
 - val_f1: 0.9968
Epoch 233/300
 - 1s - loss: 0.0033 - val_loss: 0.0053
 - val_f1: 0.9969
Epoch 234/300
 - 1s - loss: 0.0035 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 235/300
 - 1s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 236/300
 - 1s - loss: 0.0035 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 237/300
 - 1s - loss: 0.0035 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 238/300
 - 1s - loss: 0.0032 - val_loss: 0.0055
 - val_f1: 0.9968
Epoch 239/300
 - 1s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9969
Epoch 240/300
 - 1s - loss: 0.0033 - val_loss: 0.0049
 - val_f1: 0.9971
Epoch 241/300
 - 1s - loss: 0.0035 - val_loss: 0.0051
2019-12-24 10:52:58,874 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9966
Epoch 242/300
 - 1s - loss: 0.0033 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 243/300
 - 1s - loss: 0.0034 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 244/300
 - 1s - loss: 0.0032 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 245/300
 - 1s - loss: 0.0033 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 246/300
 - 1s - loss: 0.0033 - val_loss: 0.0051
 - val_f1: 0.9968
Epoch 247/300
 - 1s - loss: 0.0033 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 248/300
 - 1s - loss: 0.0033 - val_loss: 0.0053
 - val_f1: 0.9970
Epoch 249/300
 - 1s - loss: 0.0035 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 250/300
 - 1s - loss: 0.0032 - val_loss: 0.0055
 - val_f1: 0.9968
Epoch 251/300
 - 1s - loss: 0.0031 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 252/300
 - 1s - loss: 0.0033 - val_loss: 0.0052
 - val_f1: 0.9969
Epoch 253/300
 - 1s - loss: 0.0032 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 254/300
 - 1s - loss: 0.0033 - val_loss: 0.0055
 - val_f1: 0.9967
Epoch 255/300
 - 1s - loss: 0.0034 - val_loss: 0.0057
 - val_f1: 0.9968
Epoch 256/300
 - 1s - loss: 0.0034 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 257/300
 - 1s - loss: 0.0031 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 258/300
 - 1s - loss: 0.0033 - val_loss: 0.0052
2019-12-24 10:53:25,594 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 10:53:27,296 [INFO] Last epoch loss evaluation: train_loss = 0.002108, val_loss = 0.004744
2019-12-24 10:53:27,299 [INFO] Training complete. time_to_train = 469.68 sec, 7.83 min
2019-12-24 10:53:27,305 [INFO] Model saved to results_selected_models/selected_nsl_dbn_deep_rep1/best_model.pickle
2019-12-24 10:53:27,359 [INFO] Training history saved to: results_selected_models/selected_nsl_dbn_deep_rep1/training_error_history.csv
2019-12-24 10:53:27,559 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep1/training_error_history.png
2019-12-24 10:53:27,681 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep1/training_f1_history.png
2019-12-24 10:53:27,681 [INFO] Making predictions on training, validation, testing data
2019-12-24 10:53:29,729 [INFO] Evaluating predictions (results)
2019-12-24 10:53:30,041 [INFO] Dataset: Testing. Classification report below
2019-12-24 10:53:30,041 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.81      0.88      7458
      normal       0.67      0.96      0.79      9711
       probe       0.81      0.74      0.77      2421
         r2l       0.92      0.11      0.19      2421
         u2r       0.86      0.03      0.06       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.84      0.53      0.54     22544
weighted avg       0.82      0.77      0.74     22544

2019-12-24 10:53:30,041 [INFO] Overall accuracy (micro avg): 0.7716909155429382
2019-12-24 10:53:30,363 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7717         0.7717                       0.7717                0.0571                   0.2283  0.7717
1     Macro avg        0.9087         0.8444                       0.5288                0.0772                   0.4712  0.5397
2  Weighted avg        0.8664         0.8153                       0.7717                0.1575                   0.2283  0.7372
2019-12-24 10:53:30,713 [INFO] Dataset: Validation. Classification report below
2019-12-24 10:53:30,713 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.89      0.93       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.88      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-24 10:53:30,713 [INFO] Overall accuracy (micro avg): 0.9970232188926375
2019-12-24 10:53:31,090 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0007                   0.0030  0.9970
1     Macro avg        0.9988         0.9571                       0.8768                0.0011                   0.1232  0.9084
2  Weighted avg        0.9982         0.9970                       0.9970                0.0023                   0.0030  0.9970
2019-12-24 10:53:32,597 [INFO] Dataset: Training. Classification report below
2019-12-24 10:53:32,597 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      0.99      9325
         r2l       0.97      0.92      0.94       796
         u2r       0.97      0.67      0.79        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.99      0.92      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-24 10:53:32,597 [INFO] Overall accuracy (micro avg): 0.9977772926630812
2019-12-24 10:53:34,303 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9978         0.9978                       0.9978                0.0006                   0.0022  0.9978
1     Macro avg        0.9991         0.9863                       0.9152                0.0008                   0.0848  0.9451
2  Weighted avg        0.9986         0.9978                       0.9978                0.0019                   0.0022  0.9978
2019-12-24 10:53:34,324 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_deep_rep1/selected_nsl_dbn_deep_rep1_results.xlsx
2019-12-24 10:53:34,325 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 10:53:34,329 [INFO] Created directory: results_selected_models/selected_nsl_dbn_deep_rep2
2019-12-24 10:53:34,329 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_deep_rep2/run_log.log
2019-12-24 10:53:34,329 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 10:53:34,329 [INFO] Experiment parameters given below
2019-12-24 10:53:34,329 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_deep_rep2'}
2019-12-24 10:53:34,330 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_deep_rep2/tf_logs_run_2019_12_24-10_53_34
2019-12-24 10:53:34,330 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-24 10:53:34,330 [INFO] Reading X, y files
2019-12-24 10:53:34,330 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-24 10:53:34,586 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-24 10:53:34,586 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-24 10:53:34,652 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 10:53:34,652 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-24 10:53:34,708 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 10:53:34,708 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-24 10:53:34,716 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-24 10:53:34,716 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-24 10:53:34,720 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 10:53:34,720 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-24 10:53:34,724 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 10:53:34,924 [INFO] Initializing model
2019-12-24 10:53:34,924 [INFO] Training model
2019-12-24 10:53:34,924 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 10:53:35,666 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 1b352bf700d864d5bd536a195cc9470a3677be36
2019-12-24 10:53:35,666 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9965
Epoch 00258: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -55.15, time = 0.34s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -56.80, time = 0.67s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -63.02, time = 0.66s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.70, time = 0.66s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -75.53, time = 0.67s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -80.23, time = 0.66s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -84.04, time = 0.67s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -87.10, time = 0.67s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -89.57, time = 0.67s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -91.56, time = 0.66s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -93.10, time = 0.66s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -94.27, time = 0.65s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -95.11, time = 0.65s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -95.56, time = 0.64s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -95.80, time = 0.64s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -95.81, time = 0.64s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -95.63, time = 0.63s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -95.33, time = 0.63s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -94.99, time = 0.63s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -94.62, time = 0.63s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -94.25, time = 0.63s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -93.96, time = 0.63s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -93.71, time = 0.63s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -93.53, time = 0.63s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -93.44, time = 0.62s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -93.43, time = 0.63s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -93.58, time = 0.62s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -93.82, time = 0.63s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -94.21, time = 0.62s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -94.77, time = 0.62s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -95.51, time = 0.63s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -96.45, time = 0.62s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -97.56, time = 0.63s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -98.83, time = 0.62s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -100.18, time = 0.62s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -101.62, time = 0.62s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -103.10, time = 0.62s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -104.65, time = 0.62s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -106.17, time = 0.62s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -107.76, time = 0.62s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -109.31, time = 0.62s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -110.87, time = 0.62s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -112.52, time = 0.62s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -114.16, time = 0.62s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -115.72, time = 0.62s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -117.30, time = 0.62s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -118.87, time = 0.62s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -120.53, time = 0.62s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -122.14, time = 0.62s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -123.78, time = 0.63s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -84.37, time = 0.23s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -79.77, time = 0.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -77.99, time = 0.38s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -77.35, time = 0.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -76.99, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -76.68, time = 0.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -76.36, time = 0.38s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -75.92, time = 0.37s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -75.33, time = 0.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.61, time = 0.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -73.67, time = 0.38s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -72.52, time = 0.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -71.11, time = 0.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -69.57, time = 0.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -67.91, time = 0.38s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -66.17, time = 0.37s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -64.49, time = 0.37s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -62.77, time = 0.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -61.14, time = 0.38s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -59.59, time = 0.37s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -58.18, time = 0.37s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.97, time = 0.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.91, time = 0.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -55.03, time = 0.37s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -54.15, time = 0.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -53.28, time = 0.37s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -52.35, time = 0.37s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -51.57, time = 0.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -50.39, time = 0.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -48.95, time = 0.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -47.68, time = 0.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -46.66, time = 0.37s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -45.95, time = 0.37s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.27, time = 0.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.62, time = 0.37s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.86, time = 0.37s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.29, time = 0.36s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.79, time = 0.36s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.46, time = 0.36s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -42.21, time = 0.36s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.85, time = 0.36s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -41.50, time = 0.36s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -41.31, time = 0.36s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -41.20, time = 0.37s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -40.93, time = 0.36s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -40.75, time = 0.36s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -40.69, time = 0.36s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -40.63, time = 0.37s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -40.38, time = 0.36s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -40.26, time = 0.36s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -41.75, time = 0.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -38.91, time = 0.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.82, time = 0.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.60, time = 0.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -34.93, time = 0.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.55, time = 0.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -34.30, time = 0.19s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -34.11, time = 0.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -33.95, time = 0.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -33.81, time = 0.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.67, time = 0.20s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -33.51, time = 0.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -33.34, time = 0.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -33.14, time = 0.19s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -32.90, time = 0.19s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -32.63, time = 0.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -32.31, time = 0.19s2019-12-24 10:54:35,449 [INFO] Pretraining Complete
2019-12-24 10:54:35,450 [INFO] Getting pretrained weights
2019-12-24 10:54:35,450 [INFO] Creating and initializing feed forward neural network
2019-12-24 10:54:35,717 [INFO] _________________________________________________________________
2019-12-24 10:54:35,717 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 10:54:35,717 [INFO] =================================================================
2019-12-24 10:54:35,717 [INFO] dense_5 (Dense)              (None, 128)               15744     
2019-12-24 10:54:35,717 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] batch_normalization_4 (Batch (None, 128)               512       
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] dropout_4 (Dropout)          (None, 128)               0         
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] dense_6 (Dense)              (None, 64)                8256      
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] dense_7 (Dense)              (None, 32)                2080      
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,718 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2019-12-24 10:54:35,718 [INFO] _________________________________________________________________
2019-12-24 10:54:35,719 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2019-12-24 10:54:35,719 [INFO] _________________________________________________________________
2019-12-24 10:54:35,719 [INFO] dense_8 (Dense)              (None, 5)                 165       
2019-12-24 10:54:35,719 [INFO] =================================================================
2019-12-24 10:54:35,719 [INFO] Total params: 27,141
2019-12-24 10:54:35,719 [INFO] Trainable params: 26,693
2019-12-24 10:54:35,719 [INFO] Non-trainable params: 448
2019-12-24 10:54:35,719 [INFO] _________________________________________________________________
2019-12-24 10:54:36,128 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 18, pseudo-likelihood = -31.94, time = 0.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -31.51, time = 0.19s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -31.01, time = 0.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -30.43, time = 0.19s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -29.77, time = 0.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -29.05, time = 0.19s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.25, time = 0.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -27.39, time = 0.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -26.52, time = 0.19s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -25.58, time = 0.19s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -24.64, time = 0.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -23.68, time = 0.19s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -22.72, time = 0.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -21.73, time = 0.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -20.77, time = 0.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -19.88, time = 0.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -19.10, time = 0.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -18.41, time = 0.19s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -17.73, time = 0.19s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -17.08, time = 0.19s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -16.64, time = 0.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -16.28, time = 0.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -15.88, time = 0.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -15.51, time = 0.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -15.16, time = 0.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -14.89, time = 0.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -14.65, time = 0.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -14.46, time = 0.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -14.27, time = 0.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -14.11, time = 0.19s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -13.95, time = 0.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -13.79, time = 0.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -13.65, time = 0.19s
Train on 75584 samples, validate on 25195 samples
Epoch 1/300
 - 2s - loss: 0.2529 - val_loss: 0.1040
 - val_f1: 0.8964
Epoch 2/300
 - 1s - loss: 0.0879 - val_loss: 0.0654
 - val_f1: 0.9507
Epoch 3/300
 - 1s - loss: 0.0580 - val_loss: 0.0350
 - val_f1: 0.9691
Epoch 4/300
 - 1s - loss: 0.0410 - val_loss: 0.0251
 - val_f1: 0.9720
Epoch 5/300
 - 1s - loss: 0.0324 - val_loss: 0.0200
 - val_f1: 0.9824
Epoch 6/300
 - 1s - loss: 0.0274 - val_loss: 0.0156
 - val_f1: 0.9883
Epoch 7/300
 - 1s - loss: 0.0235 - val_loss: 0.0133
 - val_f1: 0.9894
Epoch 8/300
 - 1s - loss: 0.0205 - val_loss: 0.0129
 - val_f1: 0.9897
Epoch 9/300
 - 1s - loss: 0.0185 - val_loss: 0.0120
 - val_f1: 0.9916
Epoch 10/300
 - 1s - loss: 0.0175 - val_loss: 0.0111
 - val_f1: 0.9907
Epoch 11/300
 - 1s - loss: 0.0167 - val_loss: 0.0110
 - val_f1: 0.9909
Epoch 12/300
 - 1s - loss: 0.0160 - val_loss: 0.0108
 - val_f1: 0.9909
Epoch 13/300
 - 1s - loss: 0.0146 - val_loss: 0.0106
 - val_f1: 0.9928
Epoch 14/300
 - 1s - loss: 0.0149 - val_loss: 0.0108
 - val_f1: 0.9904
Epoch 15/300
 - 1s - loss: 0.0140 - val_loss: 0.0108
 - val_f1: 0.9918
Epoch 16/300
 - 1s - loss: 0.0137 - val_loss: 0.0096
 - val_f1: 0.9925
Epoch 17/300
 - 1s - loss: 0.0131 - val_loss: 0.0101
 - val_f1: 0.9928
Epoch 18/300
 - 1s - loss: 0.0126 - val_loss: 0.0094
 - val_f1: 0.9930
Epoch 19/300
 - 1s - loss: 0.0123 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 20/300
 - 1s - loss: 0.0119 - val_loss: 0.0090
 - val_f1: 0.9932
Epoch 21/300
 - 1s - loss: 0.0118 - val_loss: 0.0091
 - val_f1: 0.9935
Epoch 22/300
 - 1s - loss: 0.0115 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 23/300
 - 1s - loss: 0.0111 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 24/300
 - 1s - loss: 0.0111 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 25/300
 - 1s - loss: 0.0105 - val_loss: 0.0087
 - val_f1: 0.9941
Epoch 26/300
 - 1s - loss: 0.0104 - val_loss: 0.0083
 - val_f1: 0.9937
Epoch 27/300
 - 1s - loss: 0.0102 - val_loss: 0.0082
 - val_f1: 0.9940
Epoch 28/300
 - 1s - loss: 0.0102 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 29/300
 - 1s - loss: 0.0098 - val_loss: 0.0079
 - val_f1: 0.9941
Epoch 30/300
 - 1s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9946
Epoch 31/300
 - 1s - loss: 0.0093 - val_loss: 0.0077
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 10:55:28,606 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9947
Epoch 32/300
 - 1s - loss: 0.0094 - val_loss: 0.0078
 - val_f1: 0.9938
Epoch 33/300
 - 1s - loss: 0.0092 - val_loss: 0.0076
 - val_f1: 0.9950
Epoch 34/300
 - 1s - loss: 0.0091 - val_loss: 0.0080
 - val_f1: 0.9940
Epoch 35/300
 - 1s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9943
Epoch 36/300
 - 1s - loss: 0.0093 - val_loss: 0.0071
 - val_f1: 0.9941
Epoch 37/300
 - 1s - loss: 0.0090 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 38/300
 - 1s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 39/300
 - 1s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 40/300
 - 1s - loss: 0.0082 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 41/300
 - 1s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 42/300
 - 1s - loss: 0.0082 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 43/300
 - 1s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 44/300
 - 1s - loss: 0.0081 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 45/300
 - 1s - loss: 0.0079 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 46/300
 - 1s - loss: 0.0078 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 47/300
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9945
Epoch 48/300
 - 1s - loss: 0.0079 - val_loss: 0.0065
 - val_f1: 0.9947
Epoch 49/300
 - 1s - loss: 0.0077 - val_loss: 0.0068
 - val_f1: 0.9949
Epoch 50/300
 - 1s - loss: 0.0076 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 51/300
 - 1s - loss: 0.0076 - val_loss: 0.0062
 - val_f1: 0.9955
Epoch 52/300
 - 1s - loss: 0.0074 - val_loss: 0.0065
 - val_f1: 0.9951
Epoch 53/300
 - 1s - loss: 0.0071 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 54/300
 - 1s - loss: 0.0071 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 55/300
 - 1s - loss: 0.0070 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 56/300
 - 1s - loss: 0.0070 - val_loss: 0.0061
 - val_f1: 0.9955
Epoch 57/300
 - 1s - loss: 0.0071 - val_loss: 0.0059
 - val_f1: 0.9958
Epoch 58/300
 - 1s - loss: 0.0070 - val_loss: 0.0066
 - val_f1: 0.9944
Epoch 59/300
 - 1s - loss: 0.0069 - val_loss: 0.0062
 - val_f1: 0.9950
Epoch 60/300
 - 1s - loss: 0.0068 - val_loss: 0.0060
 - val_f1: 0.9959
Epoch 61/300
 - 1s - loss: 0.0066 - val_loss: 0.0058
2019-12-24 10:56:17,366 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9962
Epoch 62/300
 - 1s - loss: 0.0067 - val_loss: 0.0060
 - val_f1: 0.9959
Epoch 63/300
 - 1s - loss: 0.0064 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 64/300
 - 1s - loss: 0.0066 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 65/300
 - 1s - loss: 0.0065 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 66/300
 - 1s - loss: 0.0062 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 67/300
 - 1s - loss: 0.0063 - val_loss: 0.0056
 - val_f1: 0.9963
Epoch 68/300
 - 1s - loss: 0.0059 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 69/300
 - 1s - loss: 0.0065 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 70/300
 - 1s - loss: 0.0060 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 71/300
 - 1s - loss: 0.0062 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 72/300
 - 1s - loss: 0.0062 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 73/300
 - 1s - loss: 0.0060 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 74/300
 - 1s - loss: 0.0060 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 75/300
 - 1s - loss: 0.0060 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 76/300
 - 1s - loss: 0.0059 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 77/300
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 78/300
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 79/300
 - 1s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 80/300
 - 1s - loss: 0.0057 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 81/300
 - 1s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 82/300
 - 1s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 83/300
 - 1s - loss: 0.0054 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 84/300
 - 1s - loss: 0.0056 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 85/300
 - 1s - loss: 0.0059 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 86/300
 - 1s - loss: 0.0053 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 87/300
 - 1s - loss: 0.0055 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 88/300
 - 1s - loss: 0.0055 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 89/300
 - 1s - loss: 0.0053 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 90/300
 - 1s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 91/300
 - 1s - loss: 0.0053 - val_loss: 0.0058
2019-12-24 10:57:06,143 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9963
Epoch 92/300
 - 1s - loss: 0.0051 - val_loss: 0.0058
 - val_f1: 0.9961
Epoch 93/300
 - 1s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 94/300
 - 1s - loss: 0.0054 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 95/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 96/300
 - 1s - loss: 0.0049 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 97/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 98/300
 - 1s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 99/300
 - 1s - loss: 0.0053 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 100/300
 - 1s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 101/300
 - 1s - loss: 0.0049 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 102/300
 - 1s - loss: 0.0052 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 103/300
 - 1s - loss: 0.0047 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 104/300
 - 1s - loss: 0.0050 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 105/300
 - 1s - loss: 0.0047 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 106/300
 - 1s - loss: 0.0048 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 107/300
 - 1s - loss: 0.0052 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 108/300
 - 1s - loss: 0.0053 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 109/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 110/300
 - 1s - loss: 0.0049 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 111/300
 - 1s - loss: 0.0048 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 112/300
 - 1s - loss: 0.0049 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 113/300
 - 1s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 114/300
 - 1s - loss: 0.0048 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 115/300
 - 1s - loss: 0.0048 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 116/300
 - 1s - loss: 0.0044 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 117/300
 - 1s - loss: 0.0046 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 118/300
 - 1s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 119/300
 - 1s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 120/300
 - 1s - loss: 0.0047 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 121/300
 - 1s - loss: 0.0045 - val_loss: 0.0049
2019-12-24 10:57:54,837 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9966
Epoch 122/300
 - 1s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 123/300
 - 1s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 124/300
 - 1s - loss: 0.0044 - val_loss: 0.0049
 - val_f1: 0.9963
Epoch 125/300
 - 1s - loss: 0.0045 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 126/300
 - 1s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 127/300
 - 1s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 128/300
 - 1s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 129/300
 - 1s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9963
Epoch 130/300
 - 1s - loss: 0.0044 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 131/300
 - 1s - loss: 0.0048 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 132/300
 - 1s - loss: 0.0044 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 133/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 134/300
 - 1s - loss: 0.0044 - val_loss: 0.0048
 - val_f1: 0.9963
Epoch 135/300
 - 1s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 136/300
 - 1s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 137/300
 - 1s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 138/300
 - 1s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 139/300
 - 1s - loss: 0.0042 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 140/300
 - 1s - loss: 0.0042 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 141/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 142/300
 - 1s - loss: 0.0040 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 143/300
 - 1s - loss: 0.0040 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 144/300
 - 1s - loss: 0.0044 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 145/300
 - 1s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 146/300
 - 1s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 147/300
 - 1s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 148/300
 - 1s - loss: 0.0040 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 149/300
 - 1s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 150/300
 - 1s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 151/300
 - 1s - loss: 0.0041 - val_loss: 0.0046
2019-12-24 10:58:43,592 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9967
Epoch 152/300
 - 1s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9969
Epoch 153/300
 - 1s - loss: 0.0042 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 154/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 155/300
 - 1s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 156/300
 - 1s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 157/300
 - 1s - loss: 0.0038 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 158/300
 - 1s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9964
Epoch 159/300
 - 1s - loss: 0.0040 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 160/300
 - 1s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 161/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 162/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 163/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 164/300
 - 1s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 165/300
 - 1s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 166/300
 - 1s - loss: 0.0037 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 167/300
 - 1s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 168/300
 - 1s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 169/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 170/300
 - 1s - loss: 0.0036 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 171/300
 - 1s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 172/300
 - 1s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 173/300
 - 1s - loss: 0.0038 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 174/300
 - 1s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 175/300
 - 1s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 176/300
 - 1s - loss: 0.0040 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 177/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 178/300
 - 1s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 179/300
 - 1s - loss: 0.0038 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 180/300
 - 1s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 181/300
 - 1s - loss: 0.0037 - val_loss: 0.0050
2019-12-24 10:59:32,279 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9968
Epoch 182/300
 - 1s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 183/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 184/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 185/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 186/300
 - 1s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 187/300
 - 1s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 188/300
 - 1s - loss: 0.0038 - val_loss: 0.0043
 - val_f1: 0.9968
Epoch 189/300
 - 1s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9969
Epoch 190/300
 - 1s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 191/300
 - 1s - loss: 0.0035 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 192/300
 - 1s - loss: 0.0036 - val_loss: 0.0043
 - val_f1: 0.9970
Epoch 193/300
 - 1s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 194/300
 - 1s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 195/300
 - 1s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 196/300
 - 1s - loss: 0.0034 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 197/300
 - 1s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 198/300
 - 1s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 199/300
 - 1s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 200/300
 - 1s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 201/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 202/300
 - 1s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9968
Epoch 203/300
 - 1s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 204/300
 - 1s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9967
Epoch 205/300
 - 1s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9967
Epoch 206/300
 - 1s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 207/300
 - 1s - loss: 0.0032 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 208/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 209/300
 - 1s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 210/300
 - 1s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9969
Epoch 211/300
 - 1s - loss: 0.0036 - val_loss: 0.0048
2019-12-24 11:00:21,114 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9966
Epoch 212/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 213/300
 - 1s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9969
Epoch 214/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 215/300
 - 1s - loss: 0.0034 - val_loss: 0.0062
 - val_f1: 0.9945
Epoch 216/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 217/300
 - 1s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 218/300
 - 1s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 219/300
 - 1s - loss: 0.0033 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 220/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 221/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 222/300
 - 1s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 223/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 224/300
 - 1s - loss: 0.0035 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 225/300
 - 1s - loss: 0.0034 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 226/300
 - 1s - loss: 0.0036 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 227/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 228/300
 - 1s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 229/300
 - 1s - loss: 0.0032 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 230/300
 - 1s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 231/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 232/300
 - 1s - loss: 0.0032 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 233/300
 - 1s - loss: 0.0033 - val_loss: 0.0048
 - val_f1: 0.9968
Epoch 234/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 235/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 236/300
 - 1s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 237/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 238/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 239/300
 - 1s - loss: 0.0031 - val_loss: 0.0049
2019-12-24 11:01:06,868 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 11:01:08,708 [INFO] Last epoch loss evaluation: train_loss = 0.001966, val_loss = 0.004275
2019-12-24 11:01:08,711 [INFO] Training complete. time_to_train = 453.79 sec, 7.56 min
2019-12-24 11:01:08,718 [INFO] Model saved to results_selected_models/selected_nsl_dbn_deep_rep2/best_model.pickle
2019-12-24 11:01:08,721 [INFO] Training history saved to: results_selected_models/selected_nsl_dbn_deep_rep2/training_error_history.csv
2019-12-24 11:01:08,853 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep2/training_error_history.png
2019-12-24 11:01:08,974 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep2/training_f1_history.png
2019-12-24 11:01:08,974 [INFO] Making predictions on training, validation, testing data
2019-12-24 11:01:11,342 [INFO] Evaluating predictions (results)
2019-12-24 11:01:11,627 [INFO] Dataset: Testing. Classification report below
2019-12-24 11:01:11,627 [INFO] 
              precision    recall  f1-score   support

         dos       0.94      0.83      0.88      7458
      normal       0.68      0.93      0.78      9711
       probe       0.78      0.69      0.73      2421
         r2l       0.58      0.10      0.18      2421
         u2r       0.53      0.04      0.07       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.70      0.52      0.53     22544
weighted avg       0.76      0.76      0.73     22544

2019-12-24 11:01:11,627 [INFO] Overall accuracy (micro avg): 0.7609119943222143
2019-12-24 11:01:11,951 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7609         0.7609                       0.7609                0.0598                   0.2391  0.7609
1     Macro avg        0.9044         0.7001                       0.5177                0.0792                   0.4823  0.5279
2  Weighted avg        0.8625         0.7599                       0.7609                0.1568                   0.2391  0.7278
2019-12-24 11:01:12,293 [INFO] Dataset: Validation. Classification report below
2019-12-24 11:01:12,293 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.91      0.94       199
         u2r       0.80      0.40      0.53        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.95      0.86      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-24 11:01:12,293 [INFO] Overall accuracy (micro avg): 0.9969041476483429
2019-12-24 11:01:12,670 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9969         0.9969                       0.9969                0.0008                   0.0031  0.9969
1     Macro avg        0.9988         0.9506                       0.8604                0.0011                   0.1396  0.8921
2  Weighted avg        0.9981         0.9969                       0.9969                0.0024                   0.0031  0.9968
2019-12-24 11:01:14,186 [INFO] Dataset: Training. Classification report below
2019-12-24 11:01:14,186 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.97      0.91      0.94       796
         u2r       0.90      0.67      0.77        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.91      0.94    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-24 11:01:14,186 [INFO] Overall accuracy (micro avg): 0.9978765206691936
2019-12-24 11:01:15,900 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9979         0.9979                       0.9979                0.0005                   0.0021  0.9979
1     Macro avg        0.9992         0.9733                       0.9142                0.0008                   0.0858  0.9400
2  Weighted avg        0.9987         0.9979                       0.9979                0.0018                   0.0021  0.9979
2019-12-24 11:01:15,920 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_deep_rep2/selected_nsl_dbn_deep_rep2_results.xlsx
2019-12-24 11:01:15,921 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 11:01:15,924 [INFO] Created directory: results_selected_models/selected_nsl_dbn_deep_rep3
2019-12-24 11:01:15,925 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_deep_rep3/run_log.log
2019-12-24 11:01:15,925 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 11:01:15,925 [INFO] Experiment parameters given below
2019-12-24 11:01:15,925 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_deep_rep3'}
2019-12-24 11:01:15,925 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_deep_rep3/tf_logs_run_2019_12_24-11_01_15
2019-12-24 11:01:15,925 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-24 11:01:15,925 [INFO] Reading X, y files
2019-12-24 11:01:15,926 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-24 11:01:16,193 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-24 11:01:16,193 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-24 11:01:16,257 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:01:16,257 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-24 11:01:16,314 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:01:16,314 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-24 11:01:16,322 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-24 11:01:16,323 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-24 11:01:16,327 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:01:16,327 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-24 11:01:16,331 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:01:16,538 [INFO] Initializing model
2019-12-24 11:01:16,538 [INFO] Training model
2019-12-24 11:01:16,538 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 11:01:17,405 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 7f942fc07e62dfd80de98928958701dfc4526678
2019-12-24 11:01:17,406 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9967
Epoch 00239: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -56.96, time = 0.34s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -59.65, time = 0.68s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -66.61, time = 0.67s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -73.90, time = 0.67s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -80.24, time = 0.67s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.39, time = 0.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -89.59, time = 0.67s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -93.02, time = 0.67s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -95.85, time = 0.67s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -98.21, time = 0.67s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -100.15, time = 0.66s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -101.71, time = 0.65s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -102.96, time = 0.65s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -103.82, time = 0.65s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -104.43, time = 0.65s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -104.79, time = 0.64s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -104.90, time = 0.64s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -104.86, time = 0.64s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -104.71, time = 0.63s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -104.51, time = 0.63s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -104.25, time = 0.63s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -104.04, time = 0.64s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -103.83, time = 0.63s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -103.65, time = 0.63s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -103.52, time = 0.63s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -103.44, time = 0.63s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -103.52, time = 0.63s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -103.69, time = 0.63s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -104.06, time = 0.63s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -104.69, time = 0.63s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -105.61, time = 0.63s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -106.78, time = 0.63s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -108.14, time = 0.63s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -109.64, time = 0.63s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -111.22, time = 0.62s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -112.83, time = 0.63s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -114.50, time = 0.63s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -116.22, time = 0.62s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -117.91, time = 0.62s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -119.69, time = 0.62s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -121.44, time = 0.63s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -123.21, time = 0.62s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -125.06, time = 0.62s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -126.92, time = 0.63s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -128.78, time = 0.62s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -130.64, time = 0.63s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -132.58, time = 0.62s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -134.46, time = 0.62s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -136.45, time = 0.63s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -138.45, time = 0.62s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -84.70, time = 0.23s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -79.96, time = 0.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -77.84, time = 0.38s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -76.99, time = 0.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -76.50, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -76.06, time = 0.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -75.55, time = 0.37s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -74.87, time = 0.37s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -73.92, time = 0.38s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -72.64, time = 0.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -70.96, time = 0.37s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -69.08, time = 0.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -67.07, time = 0.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -65.12, time = 0.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -63.23, time = 0.37s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.44, time = 0.37s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -59.88, time = 0.37s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -58.39, time = 0.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -57.07, time = 0.37s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -55.79, time = 0.37s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -54.71, time = 0.37s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -53.74, time = 0.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -52.80, time = 0.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -51.89, time = 0.37s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -50.84, time = 0.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -49.10, time = 0.37s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.60, time = 0.37s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -46.70, time = 0.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -45.87, time = 0.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -45.22, time = 0.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -44.53, time = 0.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -44.05, time = 0.37s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -43.54, time = 0.37s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -43.15, time = 0.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -42.74, time = 0.37s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -42.33, time = 0.37s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.12, time = 0.37s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.95, time = 0.37s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -41.84, time = 0.37s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.75, time = 0.37s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.52, time = 0.37s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -41.24, time = 0.37s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -41.15, time = 0.37s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -41.08, time = 0.37s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -41.08, time = 0.37s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -40.96, time = 0.37s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -40.95, time = 0.37s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -40.80, time = 0.37s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -40.50, time = 0.37s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -40.31, time = 0.36s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.20, time = 0.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.79, time = 0.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -37.83, time = 0.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.53, time = 0.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.72, time = 0.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.18, time = 0.20s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -34.79, time = 0.19s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -34.47, time = 0.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -34.19, time = 0.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -33.92, time = 0.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.65, time = 0.19s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -33.36, time = 0.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -33.06, time = 0.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -32.73, time = 0.20s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -32.37, time = 0.19s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -31.97, time = 0.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -31.52, time = 0.19s2019-12-24 11:02:17,489 [INFO] Pretraining Complete
2019-12-24 11:02:17,489 [INFO] Getting pretrained weights
2019-12-24 11:02:17,489 [INFO] Creating and initializing feed forward neural network
2019-12-24 11:02:17,760 [INFO] _________________________________________________________________
2019-12-24 11:02:17,760 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 11:02:17,760 [INFO] =================================================================
2019-12-24 11:02:17,761 [INFO] dense_9 (Dense)              (None, 128)               15744     
2019-12-24 11:02:17,761 [INFO] _________________________________________________________________
2019-12-24 11:02:17,761 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2019-12-24 11:02:17,761 [INFO] _________________________________________________________________
2019-12-24 11:02:17,761 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2019-12-24 11:02:17,761 [INFO] _________________________________________________________________
2019-12-24 11:02:17,761 [INFO] dense_10 (Dense)             (None, 64)                8256      
2019-12-24 11:02:17,761 [INFO] _________________________________________________________________
2019-12-24 11:02:17,761 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2019-12-24 11:02:17,761 [INFO] _________________________________________________________________
2019-12-24 11:02:17,761 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2019-12-24 11:02:17,762 [INFO] _________________________________________________________________
2019-12-24 11:02:17,762 [INFO] dense_11 (Dense)             (None, 32)                2080      
2019-12-24 11:02:17,762 [INFO] _________________________________________________________________
2019-12-24 11:02:17,762 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-24 11:02:17,762 [INFO] _________________________________________________________________
2019-12-24 11:02:17,762 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-24 11:02:17,762 [INFO] _________________________________________________________________
2019-12-24 11:02:17,762 [INFO] dense_12 (Dense)             (None, 5)                 165       
2019-12-24 11:02:17,762 [INFO] =================================================================
2019-12-24 11:02:17,762 [INFO] Total params: 27,141
2019-12-24 11:02:17,762 [INFO] Trainable params: 26,693
2019-12-24 11:02:17,762 [INFO] Non-trainable params: 448
2019-12-24 11:02:17,763 [INFO] _________________________________________________________________
2019-12-24 11:02:18,464 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 18, pseudo-likelihood = -31.02, time = 0.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -30.45, time = 0.19s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -29.79, time = 0.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -29.05, time = 0.19s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.21, time = 0.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -27.32, time = 0.19s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -26.34, time = 0.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -25.33, time = 0.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -24.30, time = 0.19s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -23.23, time = 0.19s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -22.16, time = 0.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -21.08, time = 0.20s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -20.03, time = 0.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -19.03, time = 0.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -18.21, time = 0.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -17.38, time = 0.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -16.88, time = 0.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -16.34, time = 0.19s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -15.74, time = 0.19s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -15.26, time = 0.19s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -14.85, time = 0.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -14.51, time = 0.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -14.22, time = 0.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -13.95, time = 0.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -13.71, time = 0.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -13.50, time = 0.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -13.31, time = 0.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -13.15, time = 0.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -13.00, time = 0.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -12.86, time = 0.19s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -12.74, time = 0.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -12.63, time = 0.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -12.53, time = 0.19s
Train on 75584 samples, validate on 25195 samples
Epoch 1/300
 - 2s - loss: 0.2250 - val_loss: 0.0960
 - val_f1: 0.9011
Epoch 2/300
 - 1s - loss: 0.0694 - val_loss: 0.0409
 - val_f1: 0.9677
Epoch 3/300
 - 1s - loss: 0.0438 - val_loss: 0.0283
 - val_f1: 0.9705
Epoch 4/300
 - 1s - loss: 0.0317 - val_loss: 0.0205
 - val_f1: 0.9757
Epoch 5/300
 - 1s - loss: 0.0271 - val_loss: 0.0174
 - val_f1: 0.9830
Epoch 6/300
 - 1s - loss: 0.0229 - val_loss: 0.0146
 - val_f1: 0.9868
Epoch 7/300
 - 1s - loss: 0.0208 - val_loss: 0.0134
 - val_f1: 0.9890
Epoch 8/300
 - 1s - loss: 0.0197 - val_loss: 0.0128
 - val_f1: 0.9886
Epoch 9/300
 - 1s - loss: 0.0176 - val_loss: 0.0124
 - val_f1: 0.9904
Epoch 10/300
 - 1s - loss: 0.0168 - val_loss: 0.0123
 - val_f1: 0.9900
Epoch 11/300
 - 1s - loss: 0.0160 - val_loss: 0.0117
 - val_f1: 0.9912
Epoch 12/300
 - 1s - loss: 0.0145 - val_loss: 0.0109
 - val_f1: 0.9917
Epoch 13/300
 - 1s - loss: 0.0147 - val_loss: 0.0107
 - val_f1: 0.9921
Epoch 14/300
 - 1s - loss: 0.0137 - val_loss: 0.0109
 - val_f1: 0.9913
Epoch 15/300
 - 1s - loss: 0.0133 - val_loss: 0.0100
 - val_f1: 0.9920
Epoch 16/300
 - 1s - loss: 0.0126 - val_loss: 0.0095
 - val_f1: 0.9928
Epoch 17/300
 - 1s - loss: 0.0128 - val_loss: 0.0096
 - val_f1: 0.9924
Epoch 18/300
 - 1s - loss: 0.0119 - val_loss: 0.0096
 - val_f1: 0.9930
Epoch 19/300
 - 1s - loss: 0.0115 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 20/300
 - 1s - loss: 0.0110 - val_loss: 0.0087
 - val_f1: 0.9933
Epoch 21/300
 - 1s - loss: 0.0110 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 22/300
 - 1s - loss: 0.0107 - val_loss: 0.0098
 - val_f1: 0.9927
Epoch 23/300
 - 1s - loss: 0.0103 - val_loss: 0.0083
 - val_f1: 0.9939
Epoch 24/300
 - 1s - loss: 0.0103 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 25/300
 - 1s - loss: 0.0101 - val_loss: 0.0090
 - val_f1: 0.9934
Epoch 26/300
 - 1s - loss: 0.0099 - val_loss: 0.0079
 - val_f1: 0.9943
Epoch 27/300
 - 1s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9939
Epoch 28/300
 - 1s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9938
Epoch 29/300
 - 1s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9936
Epoch 30/300
 - 1s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9939
Epoch 31/300
 - 1s - loss: 0.0087 - val_loss: 0.0076
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 11:03:13,158 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9945
Epoch 32/300
 - 1s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9942
Epoch 33/300
 - 1s - loss: 0.0084 - val_loss: 0.0075
 - val_f1: 0.9942
Epoch 34/300
 - 1s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9940
Epoch 35/300
 - 1s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9940
Epoch 36/300
 - 1s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9941
Epoch 37/300
 - 1s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 38/300
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 39/300
 - 1s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9942
Epoch 40/300
 - 1s - loss: 0.0082 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 41/300
 - 1s - loss: 0.0076 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 42/300
 - 1s - loss: 0.0077 - val_loss: 0.0068
 - val_f1: 0.9950
Epoch 43/300
 - 1s - loss: 0.0074 - val_loss: 0.0072
 - val_f1: 0.9941
Epoch 44/300
 - 1s - loss: 0.0075 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 45/300
 - 1s - loss: 0.0072 - val_loss: 0.0068
 - val_f1: 0.9948
Epoch 46/300
 - 1s - loss: 0.0070 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 47/300
 - 1s - loss: 0.0069 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 48/300
 - 1s - loss: 0.0067 - val_loss: 0.0067
 - val_f1: 0.9953
Epoch 49/300
 - 1s - loss: 0.0069 - val_loss: 0.0064
 - val_f1: 0.9950
Epoch 50/300
 - 1s - loss: 0.0066 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 51/300
 - 1s - loss: 0.0066 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 52/300
 - 1s - loss: 0.0067 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 53/300
 - 1s - loss: 0.0067 - val_loss: 0.0061
 - val_f1: 0.9956
Epoch 54/300
 - 1s - loss: 0.0065 - val_loss: 0.0061
 - val_f1: 0.9957
Epoch 55/300
 - 1s - loss: 0.0066 - val_loss: 0.0062
 - val_f1: 0.9958
Epoch 56/300
 - 1s - loss: 0.0065 - val_loss: 0.0062
 - val_f1: 0.9952
Epoch 57/300
 - 1s - loss: 0.0063 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 58/300
 - 1s - loss: 0.0065 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 59/300
 - 1s - loss: 0.0061 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 60/300
 - 1s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 61/300
 - 1s - loss: 0.0060 - val_loss: 0.0061
2019-12-24 11:04:03,361 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9959
Epoch 62/300
 - 1s - loss: 0.0058 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 63/300
 - 1s - loss: 0.0060 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 64/300
 - 1s - loss: 0.0058 - val_loss: 0.0063
 - val_f1: 0.9960
Epoch 65/300
 - 1s - loss: 0.0059 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 66/300
 - 1s - loss: 0.0056 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 67/300
 - 1s - loss: 0.0057 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 68/300
 - 1s - loss: 0.0057 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 69/300
 - 1s - loss: 0.0060 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 70/300
 - 1s - loss: 0.0055 - val_loss: 0.0061
 - val_f1: 0.9960
Epoch 71/300
 - 1s - loss: 0.0056 - val_loss: 0.0058
 - val_f1: 0.9963
Epoch 72/300
 - 1s - loss: 0.0054 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 73/300
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9957
Epoch 74/300
 - 1s - loss: 0.0058 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 75/300
 - 1s - loss: 0.0055 - val_loss: 0.0064
 - val_f1: 0.9953
Epoch 76/300
 - 1s - loss: 0.0055 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 77/300
 - 1s - loss: 0.0057 - val_loss: 0.0061
 - val_f1: 0.9957
Epoch 78/300
 - 1s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 79/300
 - 1s - loss: 0.0055 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 80/300
 - 1s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 81/300
 - 1s - loss: 0.0054 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 82/300
 - 1s - loss: 0.0054 - val_loss: 0.0059
 - val_f1: 0.9956
Epoch 83/300
 - 1s - loss: 0.0052 - val_loss: 0.0062
 - val_f1: 0.9959
Epoch 84/300
 - 1s - loss: 0.0050 - val_loss: 0.0061
 - val_f1: 0.9959
Epoch 85/300
 - 1s - loss: 0.0051 - val_loss: 0.0059
 - val_f1: 0.9959
Epoch 86/300
 - 1s - loss: 0.0051 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 87/300
 - 1s - loss: 0.0054 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 88/300
 - 1s - loss: 0.0050 - val_loss: 0.0069
 - val_f1: 0.9947
Epoch 89/300
 - 1s - loss: 0.0052 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 90/300
 - 1s - loss: 0.0052 - val_loss: 0.0061
 - val_f1: 0.9957
Epoch 91/300
 - 1s - loss: 0.0055 - val_loss: 0.0057
2019-12-24 11:04:53,606 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9962
Epoch 92/300
 - 1s - loss: 0.0049 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 93/300
 - 1s - loss: 0.0049 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 94/300
 - 1s - loss: 0.0049 - val_loss: 0.0059
 - val_f1: 0.9957
Epoch 95/300
 - 1s - loss: 0.0050 - val_loss: 0.0059
 - val_f1: 0.9963
Epoch 96/300
 - 1s - loss: 0.0050 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 97/300
 - 1s - loss: 0.0047 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 98/300
 - 1s - loss: 0.0048 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 99/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 100/300
 - 1s - loss: 0.0049 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 101/300
 - 1s - loss: 0.0047 - val_loss: 0.0059
 - val_f1: 0.9957
Epoch 102/300
 - 1s - loss: 0.0048 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 103/300
 - 1s - loss: 0.0046 - val_loss: 0.0056
 - val_f1: 0.9956
Epoch 104/300
 - 1s - loss: 0.0047 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 105/300
 - 1s - loss: 0.0046 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 106/300
 - 1s - loss: 0.0047 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 107/300
 - 1s - loss: 0.0048 - val_loss: 0.0062
 - val_f1: 0.9958
Epoch 108/300
 - 1s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 109/300
 - 1s - loss: 0.0045 - val_loss: 0.0058
 - val_f1: 0.9965
Epoch 110/300
 - 1s - loss: 0.0050 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 111/300
 - 1s - loss: 0.0047 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 112/300
 - 1s - loss: 0.0048 - val_loss: 0.0058
 - val_f1: 0.9956
Epoch 113/300
 - 1s - loss: 0.0045 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 114/300
 - 1s - loss: 0.0045 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 115/300
 - 1s - loss: 0.0046 - val_loss: 0.0058
 - val_f1: 0.9963
Epoch 116/300
 - 1s - loss: 0.0044 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 117/300
 - 1s - loss: 0.0047 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 118/300
 - 1s - loss: 0.0045 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 119/300
 - 1s - loss: 0.0047 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 120/300
 - 1s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 121/300
 - 1s - loss: 0.0044 - val_loss: 0.0056
2019-12-24 11:05:43,940 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9963
Epoch 122/300
 - 1s - loss: 0.0044 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 123/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 124/300
 - 1s - loss: 0.0046 - val_loss: 0.0058
 - val_f1: 0.9962
Epoch 125/300
 - 1s - loss: 0.0045 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 126/300
 - 1s - loss: 0.0043 - val_loss: 0.0058
 - val_f1: 0.9965
Epoch 127/300
 - 1s - loss: 0.0042 - val_loss: 0.0062
 - val_f1: 0.9959
Epoch 128/300
 - 1s - loss: 0.0044 - val_loss: 0.0058
 - val_f1: 0.9965
Epoch 129/300
 - 1s - loss: 0.0044 - val_loss: 0.0061
 - val_f1: 0.9962
Epoch 130/300
 - 1s - loss: 0.0044 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 131/300
 - 1s - loss: 0.0045 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 132/300
 - 1s - loss: 0.0042 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 133/300
 - 1s - loss: 0.0041 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 134/300
 - 1s - loss: 0.0043 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 135/300
 - 1s - loss: 0.0043 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 136/300
 - 1s - loss: 0.0042 - val_loss: 0.0063
 - val_f1: 0.9960
Epoch 137/300
 - 1s - loss: 0.0043 - val_loss: 0.0058
 - val_f1: 0.9965
Epoch 138/300
 - 1s - loss: 0.0043 - val_loss: 0.0058
 - val_f1: 0.9966
Epoch 139/300
 - 1s - loss: 0.0042 - val_loss: 0.0059
 - val_f1: 0.9961
Epoch 140/300
 - 1s - loss: 0.0040 - val_loss: 0.0061
 - val_f1: 0.9962
Epoch 141/300
 - 1s - loss: 0.0041 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 142/300
 - 1s - loss: 0.0043 - val_loss: 0.0061
 - val_f1: 0.9963
Epoch 143/300
 - 1s - loss: 0.0042 - val_loss: 0.0058
 - val_f1: 0.9963
Epoch 144/300
 - 1s - loss: 0.0039 - val_loss: 0.0058
 - val_f1: 0.9966
Epoch 145/300
 - 1s - loss: 0.0041 - val_loss: 0.0062
 - val_f1: 0.9959
Epoch 146/300
 - 1s - loss: 0.0041 - val_loss: 0.0059
 - val_f1: 0.9964
Epoch 147/300
 - 1s - loss: 0.0040 - val_loss: 0.0059
 - val_f1: 0.9965
Epoch 148/300
 - 1s - loss: 0.0041 - val_loss: 0.0060
 - val_f1: 0.9963
Epoch 149/300
 - 1s - loss: 0.0042 - val_loss: 0.0061
 - val_f1: 0.9962
Epoch 150/300
 - 1s - loss: 0.0040 - val_loss: 0.0058
 - val_f1: 0.9964
Epoch 151/300
 - 1s - loss: 0.0039 - val_loss: 0.0060
2019-12-24 11:06:34,353 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9961
Epoch 152/300
 - 1s - loss: 0.0039 - val_loss: 0.0059
 - val_f1: 0.9963
Epoch 153/300
 - 1s - loss: 0.0043 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 154/300
 - 1s - loss: 0.0038 - val_loss: 0.0057
 - val_f1: 0.9965
Epoch 155/300
 - 1s - loss: 0.0037 - val_loss: 0.0058
 - val_f1: 0.9964
Epoch 156/300
 - 1s - loss: 0.0039 - val_loss: 0.0057
2019-12-24 11:06:43,179 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 11:06:45,241 [INFO] Last epoch loss evaluation: train_loss = 0.002736, val_loss = 0.005161
2019-12-24 11:06:45,245 [INFO] Training complete. time_to_train = 328.71 sec, 5.48 min
2019-12-24 11:06:45,251 [INFO] Model saved to results_selected_models/selected_nsl_dbn_deep_rep3/best_model.pickle
2019-12-24 11:06:45,254 [INFO] Training history saved to: results_selected_models/selected_nsl_dbn_deep_rep3/training_error_history.csv
2019-12-24 11:06:45,392 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep3/training_error_history.png
2019-12-24 11:06:45,524 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep3/training_f1_history.png
2019-12-24 11:06:45,524 [INFO] Making predictions on training, validation, testing data
2019-12-24 11:06:48,023 [INFO] Evaluating predictions (results)
2019-12-24 11:06:48,308 [INFO] Dataset: Testing. Classification report below
2019-12-24 11:06:48,308 [INFO] 
              precision    recall  f1-score   support

         dos       0.91      0.77      0.83      7458
      normal       0.66      0.93      0.77      9711
       probe       0.84      0.78      0.81      2421
         r2l       0.98      0.10      0.18      2421
         u2r       0.61      0.03      0.05       533

   micro avg       0.75      0.75      0.75     22544
   macro avg       0.80      0.52      0.53     22544
weighted avg       0.79      0.75      0.72     22544

2019-12-24 11:06:48,308 [INFO] Overall accuracy (micro avg): 0.7500887154009936
2019-12-24 11:06:48,631 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7501         0.7501                       0.7501                0.0625                   0.2499  0.7501
1     Macro avg        0.9000         0.7984                       0.5215                0.0843                   0.4785  0.5290
2  Weighted avg        0.8484         0.7932                       0.7501                0.1718                   0.2499  0.7151
2019-12-24 11:06:48,973 [INFO] Dataset: Validation. Classification report below
2019-12-24 11:06:48,973 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.89      0.93       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.88      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-24 11:06:48,973 [INFO] Overall accuracy (micro avg): 0.9966660051597539
2019-12-24 11:06:49,351 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9967         0.9967                       0.9967                0.0008                   0.0033  0.9967
1     Macro avg        0.9987         0.9578                       0.8766                0.0012                   0.1234  0.9086
2  Weighted avg        0.9979         0.9966                       0.9967                0.0026                   0.0033  0.9966
2019-12-24 11:06:50,862 [INFO] Dataset: Training. Classification report below
2019-12-24 11:06:50,863 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      0.99      9325
         r2l       0.97      0.90      0.94       796
         u2r       0.83      0.60      0.69        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.96      0.90      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-24 11:06:50,863 [INFO] Overall accuracy (micro avg): 0.9973406894361865
2019-12-24 11:06:52,571 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9973         0.9973                       0.9973                0.0007                   0.0027  0.9973
1     Macro avg        0.9989         0.9599                       0.8974                0.0010                   0.1026  0.9244
2  Weighted avg        0.9983         0.9973                       0.9973                0.0022                   0.0027  0.9973
2019-12-24 11:06:52,592 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_deep_rep3/selected_nsl_dbn_deep_rep3_results.xlsx
2019-12-24 11:06:52,592 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 11:06:52,596 [INFO] Created directory: results_selected_models/selected_nsl_dbn_deep_rep4
2019-12-24 11:06:52,596 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_deep_rep4/run_log.log
2019-12-24 11:06:52,597 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 11:06:52,597 [INFO] Experiment parameters given below
2019-12-24 11:06:52,597 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_deep_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_deep_rep4'}
2019-12-24 11:06:52,597 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_deep_rep4/tf_logs_run_2019_12_24-11_06_52
2019-12-24 11:06:52,597 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-24 11:06:52,597 [INFO] Reading X, y files
2019-12-24 11:06:52,597 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-24 11:06:52,864 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-24 11:06:52,864 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-24 11:06:52,928 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:06:52,928 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-24 11:06:52,985 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:06:52,985 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-24 11:06:52,993 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-24 11:06:52,993 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-24 11:06:52,998 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:06:52,998 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-24 11:06:53,002 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:06:53,200 [INFO] Initializing model
2019-12-24 11:06:53,200 [INFO] Training model
2019-12-24 11:06:53,200 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 11:06:53,991 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 3d1e82a8c8b3f80d0f3b58231a37e7ddfdaf1977
2019-12-24 11:06:53,991 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9966
Epoch 00156: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -56.67, time = 0.34s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -59.35, time = 0.67s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -66.36, time = 0.66s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -73.70, time = 0.66s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -80.08, time = 0.67s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -85.26, time = 0.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -89.48, time = 0.67s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -92.93, time = 0.67s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -95.78, time = 0.66s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -98.15, time = 0.66s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -100.08, time = 0.66s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -101.60, time = 0.65s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -102.83, time = 0.65s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -103.66, time = 0.65s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -104.25, time = 0.64s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -104.60, time = 0.64s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -104.76, time = 0.63s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -104.77, time = 0.63s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -104.72, time = 0.63s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -104.64, time = 0.63s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -104.53, time = 0.63s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -104.48, time = 0.63s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -104.45, time = 0.63s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -104.48, time = 0.63s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -104.58, time = 0.63s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -104.74, time = 0.63s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -105.05, time = 0.62s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -105.41, time = 0.63s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -105.91, time = 0.62s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -106.62, time = 0.62s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -107.50, time = 0.62s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -108.63, time = 0.62s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -109.91, time = 0.63s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -111.35, time = 0.62s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -112.88, time = 0.62s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -114.49, time = 0.62s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -116.14, time = 0.62s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -117.87, time = 0.63s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -119.59, time = 0.62s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -121.40, time = 0.62s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -123.14, time = 0.63s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -124.91, time = 0.62s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -126.77, time = 0.63s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -128.60, time = 0.62s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -130.40, time = 0.63s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -132.19, time = 0.62s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -133.96, time = 0.62s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -135.79, time = 0.62s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -137.60, time = 0.62s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -139.41, time = 0.62s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -84.55, time = 0.23s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -80.00, time = 0.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -78.19, time = 0.38s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -77.52, time = 0.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -77.14, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -76.80, time = 0.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -76.45, time = 0.38s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -75.98, time = 0.37s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -75.35, time = 0.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.53, time = 0.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -73.35, time = 0.37s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -71.93, time = 0.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -70.35, time = 0.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -68.75, time = 0.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -67.08, time = 0.37s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -65.37, time = 0.37s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -63.75, time = 0.37s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -62.09, time = 0.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -60.57, time = 0.37s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -59.17, time = 0.37s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.96, time = 0.37s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.92, time = 0.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.96, time = 0.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -55.12, time = 0.37s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -54.30, time = 0.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -53.54, time = 0.37s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -52.73, time = 0.37s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -51.76, time = 0.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -50.36, time = 0.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.03, time = 0.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -47.87, time = 0.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -46.83, time = 0.37s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -45.92, time = 0.37s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.22, time = 0.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.55, time = 0.37s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.97, time = 0.37s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.60, time = 0.37s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -43.29, time = 0.37s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -43.07, time = 0.37s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -42.69, time = 0.37s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -42.36, time = 0.37s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -42.09, time = 0.36s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -41.94, time = 0.37s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -41.85, time = 0.37s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -41.80, time = 0.37s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -41.77, time = 0.37s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -41.66, time = 0.37s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -41.35, time = 0.37s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -40.98, time = 0.37s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -40.85, time = 0.37s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -41.79, time = 0.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.00, time = 0.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.93, time = 0.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.71, time = 0.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.04, time = 0.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.65, time = 0.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -34.40, time = 0.19s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -34.21, time = 0.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -34.05, time = 0.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -33.91, time = 0.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.77, time = 0.20s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -33.61, time = 0.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -33.44, time = 0.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -33.24, time = 0.19s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -33.02, time = 0.19s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -32.75, time = 0.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -32.45, time = 0.19s2019-12-24 11:07:53,926 [INFO] Pretraining Complete
2019-12-24 11:07:53,926 [INFO] Getting pretrained weights
2019-12-24 11:07:53,926 [INFO] Creating and initializing feed forward neural network
2019-12-24 11:07:54,199 [INFO] _________________________________________________________________
2019-12-24 11:07:54,199 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 11:07:54,199 [INFO] =================================================================
2019-12-24 11:07:54,200 [INFO] dense_13 (Dense)             (None, 128)               15744     
2019-12-24 11:07:54,200 [INFO] _________________________________________________________________
2019-12-24 11:07:54,200 [INFO] batch_normalization_10 (Batc (None, 128)               512       
2019-12-24 11:07:54,200 [INFO] _________________________________________________________________
2019-12-24 11:07:54,200 [INFO] dropout_10 (Dropout)         (None, 128)               0         
2019-12-24 11:07:54,200 [INFO] _________________________________________________________________
2019-12-24 11:07:54,200 [INFO] dense_14 (Dense)             (None, 64)                8256      
2019-12-24 11:07:54,200 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2019-12-24 11:07:54,201 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2019-12-24 11:07:54,201 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] dense_15 (Dense)             (None, 32)                2080      
2019-12-24 11:07:54,201 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2019-12-24 11:07:54,201 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2019-12-24 11:07:54,201 [INFO] _________________________________________________________________
2019-12-24 11:07:54,201 [INFO] dense_16 (Dense)             (None, 5)                 165       
2019-12-24 11:07:54,201 [INFO] =================================================================
2019-12-24 11:07:54,202 [INFO] Total params: 27,141
2019-12-24 11:07:54,202 [INFO] Trainable params: 26,693
2019-12-24 11:07:54,202 [INFO] Non-trainable params: 448
2019-12-24 11:07:54,202 [INFO] _________________________________________________________________
2019-12-24 11:07:55,237 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 18, pseudo-likelihood = -32.09, time = 0.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -31.68, time = 0.20s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -31.20, time = 0.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -30.64, time = 0.19s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -30.01, time = 0.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -29.31, time = 0.19s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.53, time = 0.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -27.69, time = 0.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -26.83, time = 0.19s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -25.90, time = 0.19s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -24.98, time = 0.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -24.03, time = 0.19s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -23.08, time = 0.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -22.13, time = 0.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -21.17, time = 0.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -20.24, time = 0.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -19.42, time = 0.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -18.72, time = 0.19s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -17.91, time = 0.19s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -17.40, time = 0.19s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -16.99, time = 0.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -16.49, time = 0.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -16.00, time = 0.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -15.59, time = 0.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -15.23, time = 0.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -14.96, time = 0.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -14.73, time = 0.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -14.53, time = 0.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -14.35, time = 0.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -14.18, time = 0.19s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -14.03, time = 0.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -13.89, time = 0.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -13.77, time = 0.19s
Train on 75584 samples, validate on 25195 samples
Epoch 1/300
 - 2s - loss: 0.1571 - val_loss: 0.0931
 - val_f1: 0.8898
Epoch 2/300
 - 1s - loss: 0.0790 - val_loss: 0.0484
 - val_f1: 0.9572
Epoch 3/300
 - 1s - loss: 0.0555 - val_loss: 0.0322
 - val_f1: 0.9699
Epoch 4/300
 - 1s - loss: 0.0415 - val_loss: 0.0225
 - val_f1: 0.9807
Epoch 5/300
 - 1s - loss: 0.0319 - val_loss: 0.0174
 - val_f1: 0.9828
Epoch 6/300
 - 1s - loss: 0.0268 - val_loss: 0.0147
 - val_f1: 0.9886
Epoch 7/300
 - 1s - loss: 0.0233 - val_loss: 0.0130
 - val_f1: 0.9873
Epoch 8/300
 - 1s - loss: 0.0215 - val_loss: 0.0128
 - val_f1: 0.9884
Epoch 9/300
 - 1s - loss: 0.0194 - val_loss: 0.0122
 - val_f1: 0.9868
Epoch 10/300
 - 1s - loss: 0.0182 - val_loss: 0.0116
 - val_f1: 0.9891
Epoch 11/300
 - 1s - loss: 0.0171 - val_loss: 0.0116
 - val_f1: 0.9900
Epoch 12/300
 - 1s - loss: 0.0163 - val_loss: 0.0106
 - val_f1: 0.9902
Epoch 13/300
 - 1s - loss: 0.0163 - val_loss: 0.0103
 - val_f1: 0.9921
Epoch 14/300
 - 1s - loss: 0.0152 - val_loss: 0.0107
 - val_f1: 0.9897
Epoch 15/300
 - 1s - loss: 0.0153 - val_loss: 0.0101
 - val_f1: 0.9918
Epoch 16/300
 - 1s - loss: 0.0142 - val_loss: 0.0099
 - val_f1: 0.9912
Epoch 17/300
 - 1s - loss: 0.0136 - val_loss: 0.0097
 - val_f1: 0.9918
Epoch 18/300
 - 1s - loss: 0.0133 - val_loss: 0.0096
 - val_f1: 0.9911
Epoch 19/300
 - 1s - loss: 0.0125 - val_loss: 0.0093
 - val_f1: 0.9924
Epoch 20/300
 - 1s - loss: 0.0125 - val_loss: 0.0091
 - val_f1: 0.9934
Epoch 21/300
 - 1s - loss: 0.0126 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 22/300
 - 1s - loss: 0.0121 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 23/300
 - 1s - loss: 0.0119 - val_loss: 0.0090
 - val_f1: 0.9919
Epoch 24/300
 - 1s - loss: 0.0111 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 25/300
 - 1s - loss: 0.0108 - val_loss: 0.0085
 - val_f1: 0.9932
Epoch 26/300
 - 1s - loss: 0.0110 - val_loss: 0.0083
 - val_f1: 0.9936
Epoch 27/300
 - 1s - loss: 0.0106 - val_loss: 0.0081
 - val_f1: 0.9939
Epoch 28/300
 - 1s - loss: 0.0102 - val_loss: 0.0080
 - val_f1: 0.9937
Epoch 29/300
 - 1s - loss: 0.0099 - val_loss: 0.0082
 - val_f1: 0.9937
Epoch 30/300
 - 1s - loss: 0.0103 - val_loss: 0.0080
 - val_f1: 0.9943
Epoch 31/300
 - 1s - loss: 0.0099 - val_loss: 0.0078
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 11:08:52,398 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9942
Epoch 32/300
 - 1s - loss: 0.0095 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 33/300
 - 1s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9938
Epoch 34/300
 - 1s - loss: 0.0090 - val_loss: 0.0078
 - val_f1: 0.9935
Epoch 35/300
 - 1s - loss: 0.0093 - val_loss: 0.0074
 - val_f1: 0.9939
Epoch 36/300
 - 1s - loss: 0.0094 - val_loss: 0.0075
 - val_f1: 0.9950
Epoch 37/300
 - 1s - loss: 0.0094 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 38/300
 - 1s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 39/300
 - 1s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9948
Epoch 40/300
 - 1s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 41/300
 - 1s - loss: 0.0081 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 42/300
 - 1s - loss: 0.0081 - val_loss: 0.0066
 - val_f1: 0.9953
Epoch 43/300
 - 1s - loss: 0.0081 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 44/300
 - 1s - loss: 0.0076 - val_loss: 0.0064
 - val_f1: 0.9955
Epoch 45/300
 - 1s - loss: 0.0076 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 46/300
 - 1s - loss: 0.0077 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 47/300
 - 1s - loss: 0.0076 - val_loss: 0.0064
 - val_f1: 0.9955
Epoch 48/300
 - 1s - loss: 0.0074 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 49/300
 - 1s - loss: 0.0076 - val_loss: 0.0063
 - val_f1: 0.9954
Epoch 50/300
 - 1s - loss: 0.0072 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 51/300
 - 1s - loss: 0.0072 - val_loss: 0.0063
 - val_f1: 0.9952
Epoch 52/300
 - 1s - loss: 0.0072 - val_loss: 0.0065
 - val_f1: 0.9948
Epoch 53/300
 - 1s - loss: 0.0071 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 54/300
 - 1s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 55/300
 - 1s - loss: 0.0066 - val_loss: 0.0061
 - val_f1: 0.9959
Epoch 56/300
 - 1s - loss: 0.0065 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 57/300
 - 1s - loss: 0.0067 - val_loss: 0.0058
 - val_f1: 0.9956
Epoch 58/300
 - 1s - loss: 0.0067 - val_loss: 0.0060
 - val_f1: 0.9964
Epoch 59/300
 - 1s - loss: 0.0067 - val_loss: 0.0059
 - val_f1: 0.9959
Epoch 60/300
 - 1s - loss: 0.0066 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 61/300
 - 1s - loss: 0.0066 - val_loss: 0.0063
2019-12-24 11:09:45,134 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9951
Epoch 62/300
 - 1s - loss: 0.0064 - val_loss: 0.0058
 - val_f1: 0.9957
Epoch 63/300
 - 1s - loss: 0.0063 - val_loss: 0.0056
 - val_f1: 0.9963
Epoch 64/300
 - 1s - loss: 0.0062 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 65/300
 - 1s - loss: 0.0062 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 66/300
 - 1s - loss: 0.0063 - val_loss: 0.0064
 - val_f1: 0.9947
Epoch 67/300
 - 1s - loss: 0.0061 - val_loss: 0.0056
 - val_f1: 0.9961
Epoch 68/300
 - 1s - loss: 0.0061 - val_loss: 0.0057
 - val_f1: 0.9957
Epoch 69/300
 - 1s - loss: 0.0058 - val_loss: 0.0055
 - val_f1: 0.9960
Epoch 70/300
 - 1s - loss: 0.0061 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 71/300
 - 1s - loss: 0.0060 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 72/300
 - 1s - loss: 0.0057 - val_loss: 0.0059
 - val_f1: 0.9960
Epoch 73/300
 - 1s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 74/300
 - 1s - loss: 0.0059 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 75/300
 - 1s - loss: 0.0058 - val_loss: 0.0056
 - val_f1: 0.9962
Epoch 76/300
 - 1s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 77/300
 - 1s - loss: 0.0055 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 78/300
 - 1s - loss: 0.0057 - val_loss: 0.0063
 - val_f1: 0.9959
Epoch 79/300
 - 1s - loss: 0.0054 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 80/300
 - 1s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 81/300
 - 1s - loss: 0.0057 - val_loss: 0.0060
 - val_f1: 0.9957
Epoch 82/300
 - 1s - loss: 0.0053 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 83/300
 - 1s - loss: 0.0052 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 84/300
 - 1s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 85/300
 - 1s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 86/300
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 87/300
 - 1s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9965
Epoch 88/300
 - 1s - loss: 0.0052 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 89/300
 - 1s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 90/300
 - 1s - loss: 0.0051 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 91/300
 - 1s - loss: 0.0048 - val_loss: 0.0049
2019-12-24 11:10:37,785 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9966
Epoch 92/300
 - 1s - loss: 0.0052 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 93/300
 - 1s - loss: 0.0049 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 94/300
 - 1s - loss: 0.0052 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 95/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 96/300
 - 1s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 97/300
 - 1s - loss: 0.0053 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 98/300
 - 1s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 99/300
 - 1s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 100/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 101/300
 - 1s - loss: 0.0048 - val_loss: 0.0051
 - val_f1: 0.9961
Epoch 102/300
 - 1s - loss: 0.0048 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 103/300
 - 1s - loss: 0.0045 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 104/300
 - 1s - loss: 0.0046 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 105/300
 - 1s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9965
Epoch 106/300
 - 1s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 107/300
 - 1s - loss: 0.0047 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 108/300
 - 1s - loss: 0.0047 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 109/300
 - 1s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 110/300
 - 1s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 111/300
 - 1s - loss: 0.0048 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 112/300
 - 1s - loss: 0.0046 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 113/300
 - 1s - loss: 0.0045 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 114/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 115/300
 - 1s - loss: 0.0044 - val_loss: 0.0053
 - val_f1: 0.9968
Epoch 116/300
 - 1s - loss: 0.0044 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 117/300
 - 1s - loss: 0.0046 - val_loss: 0.0059
 - val_f1: 0.9962
Epoch 118/300
 - 1s - loss: 0.0047 - val_loss: 0.0056
 - val_f1: 0.9965
Epoch 119/300
 - 1s - loss: 0.0044 - val_loss: 0.0057
 - val_f1: 0.9964
Epoch 120/300
 - 1s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 121/300
 - 1s - loss: 0.0040 - val_loss: 0.0058
2019-12-24 11:11:30,363 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9962
Epoch 122/300
 - 1s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9967
Epoch 123/300
 - 1s - loss: 0.0042 - val_loss: 0.0056
 - val_f1: 0.9966
Epoch 124/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 125/300
 - 1s - loss: 0.0045 - val_loss: 0.0059
 - val_f1: 0.9962
Epoch 126/300
 - 1s - loss: 0.0048 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 127/300
 - 1s - loss: 0.0042 - val_loss: 0.0054
 - val_f1: 0.9966
Epoch 128/300
 - 1s - loss: 0.0044 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 129/300
 - 1s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 130/300
 - 1s - loss: 0.0045 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 131/300
 - 1s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9966
Epoch 132/300
 - 1s - loss: 0.0040 - val_loss: 0.0058
 - val_f1: 0.9964
Epoch 133/300
 - 1s - loss: 0.0044 - val_loss: 0.0053
 - val_f1: 0.9967
Epoch 134/300
 - 1s - loss: 0.0042 - val_loss: 0.0055
 - val_f1: 0.9967
Epoch 135/300
 - 1s - loss: 0.0043 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 136/300
 - 1s - loss: 0.0041 - val_loss: 0.0055
 - val_f1: 0.9964
Epoch 137/300
 - 1s - loss: 0.0044 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 138/300
 - 1s - loss: 0.0040 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 139/300
 - 1s - loss: 0.0044 - val_loss: 0.0052
 - val_f1: 0.9968
Epoch 140/300
 - 1s - loss: 0.0041 - val_loss: 0.0054
 - val_f1: 0.9967
Epoch 141/300
 - 1s - loss: 0.0042 - val_loss: 0.0055
2019-12-24 11:12:05,943 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 11:12:08,103 [INFO] Last epoch loss evaluation: train_loss = 0.003039, val_loss = 0.004944
2019-12-24 11:12:08,107 [INFO] Training complete. time_to_train = 314.91 sec, 5.25 min
2019-12-24 11:12:08,114 [INFO] Model saved to results_selected_models/selected_nsl_dbn_deep_rep4/best_model.pickle
2019-12-24 11:12:08,116 [INFO] Training history saved to: results_selected_models/selected_nsl_dbn_deep_rep4/training_error_history.csv
2019-12-24 11:12:08,262 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep4/training_error_history.png
2019-12-24 11:12:08,391 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep4/training_f1_history.png
2019-12-24 11:12:08,391 [INFO] Making predictions on training, validation, testing data
2019-12-24 11:12:11,157 [INFO] Evaluating predictions (results)
2019-12-24 11:12:11,441 [INFO] Dataset: Testing. Classification report below
2019-12-24 11:12:11,441 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.90      7458
      normal       0.68      0.93      0.79      9711
       probe       0.73      0.77      0.75      2421
         r2l       0.98      0.10      0.18      2421
         u2r       0.65      0.04      0.07       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.80      0.54      0.54     22544
weighted avg       0.81      0.77      0.74     22544

2019-12-24 11:12:11,441 [INFO] Overall accuracy (micro avg): 0.772888573456352
2019-12-24 11:12:11,766 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7729         0.7729                       0.7729                0.0568                   0.2271  0.7729
1     Macro avg        0.9092         0.8005                       0.5361                0.0753                   0.4639  0.5378
2  Weighted avg        0.8691         0.8115                       0.7729                0.1491                   0.2271  0.7380
2019-12-24 11:12:12,107 [INFO] Dataset: Validation. Classification report below
2019-12-24 11:12:12,107 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.90      0.93       199
         u2r       0.67      0.40      0.50        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.92      0.86      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-24 11:12:12,107 [INFO] Overall accuracy (micro avg): 0.9966660051597539
2019-12-24 11:12:12,485 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9967         0.9967                       0.9967                0.0008                   0.0033  0.9967
1     Macro avg        0.9987         0.9237                       0.8572                0.0012                   0.1428  0.8836
2  Weighted avg        0.9979         0.9966                       0.9967                0.0026                   0.0033  0.9966
2019-12-24 11:12:13,998 [INFO] Dataset: Training. Classification report below
2019-12-24 11:12:13,998 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      0.99      9325
         r2l       0.98      0.90      0.94       796
         u2r       0.87      0.62      0.72        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.90      0.93    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-24 11:12:13,998 [INFO] Overall accuracy (micro avg): 0.9971323106233503
2019-12-24 11:12:15,711 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9971         0.9971                       0.9971                0.0007                   0.0029  0.9971
1     Macro avg        0.9989         0.9669                       0.9021                0.0011                   0.0979  0.9301
2  Weighted avg        0.9981         0.9971                       0.9971                0.0025                   0.0029  0.9971
2019-12-24 11:12:15,731 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_deep_rep4/selected_nsl_dbn_deep_rep4_results.xlsx
2019-12-24 11:12:15,732 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 11:12:15,736 [INFO] Created directory: results_selected_models/selected_nsl_dbn_deep_rep5
2019-12-24 11:12:15,736 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_deep_rep5/run_log.log
2019-12-24 11:12:15,736 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 11:12:15,736 [INFO] Experiment parameters given below
2019-12-24 11:12:15,736 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_deep_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_deep_rep5'}
2019-12-24 11:12:15,736 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_deep_rep5/tf_logs_run_2019_12_24-11_12_15
2019-12-24 11:12:15,736 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-24 11:12:15,737 [INFO] Reading X, y files
2019-12-24 11:12:15,737 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-24 11:12:16,010 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-24 11:12:16,010 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-24 11:12:16,074 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:12:16,074 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-24 11:12:16,131 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-24 11:12:16,131 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-24 11:12:16,139 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-24 11:12:16,139 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-24 11:12:16,143 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:12:16,144 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-24 11:12:16,147 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-24 11:12:16,348 [INFO] Initializing model
2019-12-24 11:12:16,348 [INFO] Training model
2019-12-24 11:12:16,348 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 11:12:17,093 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = b365e1a275ca65ba07544e435bb45d8049a3b4b3
2019-12-24 11:12:17,093 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9964
Epoch 00141: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -55.73, time = 0.34s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.73, time = 0.67s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -64.20, time = 0.67s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.06, time = 0.67s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -77.03, time = 0.66s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -81.86, time = 0.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.79, time = 0.66s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -88.99, time = 0.67s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -91.65, time = 0.66s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -93.85, time = 0.66s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -95.67, time = 0.66s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -97.17, time = 0.65s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -98.40, time = 0.65s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -99.32, time = 0.64s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -100.07, time = 0.64s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -100.67, time = 0.64s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -101.12, time = 0.63s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -101.48, time = 0.63s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -101.84, time = 0.63s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -102.17, time = 0.63s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -102.52, time = 0.63s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -102.94, time = 0.63s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -103.39, time = 0.63s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -103.88, time = 0.63s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -104.44, time = 0.62s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -105.05, time = 0.62s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -105.79, time = 0.63s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -106.56, time = 0.62s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -107.47, time = 0.62s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -108.54, time = 0.62s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -109.76, time = 0.62s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -111.20, time = 0.63s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -112.76, time = 0.62s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -114.52, time = 0.62s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -116.36, time = 0.62s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -118.29, time = 0.62s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -120.27, time = 0.63s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -122.33, time = 0.62s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -124.36, time = 0.62s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -126.44, time = 0.62s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -128.53, time = 0.62s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -130.62, time = 0.62s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -132.78, time = 0.62s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -134.93, time = 0.62s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -137.03, time = 0.62s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -139.14, time = 0.62s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -141.25, time = 0.62s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -143.43, time = 0.62s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -145.56, time = 0.62s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -147.69, time = 0.62s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -84.21, time = 0.23s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -79.51, time = 0.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -77.75, time = 0.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -77.12, time = 0.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -76.78, time = 0.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -76.49, time = 0.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -76.23, time = 0.37s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -75.88, time = 0.37s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -75.43, time = 0.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.96, time = 0.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -74.34, time = 0.37s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -73.63, time = 0.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -72.81, time = 0.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -71.86, time = 0.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -70.77, time = 0.37s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -69.55, time = 0.37s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -68.26, time = 0.37s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -66.75, time = 0.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -65.27, time = 0.37s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -63.77, time = 0.37s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -62.29, time = 0.37s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -60.92, time = 0.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -59.63, time = 0.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -58.46, time = 0.37s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.27, time = 0.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -56.19, time = 0.37s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -55.16, time = 0.37s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -54.31, time = 0.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -53.56, time = 0.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -52.86, time = 0.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -52.22, time = 0.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -51.39, time = 0.37s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -50.61, time = 0.37s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -49.68, time = 0.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -48.12, time = 0.37s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -47.34, time = 0.37s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -46.19, time = 0.37s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -45.26, time = 0.37s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -44.42, time = 0.37s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -43.74, time = 0.37s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -43.01, time = 0.37s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -42.46, time = 0.37s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -42.04, time = 0.37s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -41.67, time = 0.37s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -41.40, time = 0.37s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -41.22, time = 0.37s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -41.12, time = 0.37s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -40.84, time = 0.37s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -40.65, time = 0.36s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -40.36, time = 0.37s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -41.84, time = 0.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.01, time = 0.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.84, time = 0.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.51, time = 0.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -34.76, time = 0.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.29, time = 0.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -33.98, time = 0.20s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -33.73, time = 0.20s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -33.53, time = 0.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -33.34, time = 0.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -33.14, time = 0.19s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -32.94, time = 0.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -32.73, time = 0.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -32.50, time = 0.19s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -32.24, time = 0.20s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -31.96, time = 0.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -31.65, time = 0.19s2019-12-24 11:13:16,997 [INFO] Pretraining Complete
2019-12-24 11:13:16,997 [INFO] Getting pretrained weights
2019-12-24 11:13:16,997 [INFO] Creating and initializing feed forward neural network
2019-12-24 11:13:17,372 [INFO] _________________________________________________________________
2019-12-24 11:13:17,372 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 11:13:17,372 [INFO] =================================================================
2019-12-24 11:13:17,372 [INFO] dense_17 (Dense)             (None, 128)               15744     
2019-12-24 11:13:17,372 [INFO] _________________________________________________________________
2019-12-24 11:13:17,372 [INFO] batch_normalization_13 (Batc (None, 128)               512       
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,373 [INFO] dropout_13 (Dropout)         (None, 128)               0         
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,373 [INFO] dense_18 (Dense)             (None, 64)                8256      
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,373 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,373 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,373 [INFO] dense_19 (Dense)             (None, 32)                2080      
2019-12-24 11:13:17,373 [INFO] _________________________________________________________________
2019-12-24 11:13:17,374 [INFO] batch_normalization_15 (Batc (None, 32)                128       
2019-12-24 11:13:17,374 [INFO] _________________________________________________________________
2019-12-24 11:13:17,374 [INFO] dropout_15 (Dropout)         (None, 32)                0         
2019-12-24 11:13:17,374 [INFO] _________________________________________________________________
2019-12-24 11:13:17,374 [INFO] dense_20 (Dense)             (None, 5)                 165       
2019-12-24 11:13:17,374 [INFO] =================================================================
2019-12-24 11:13:17,374 [INFO] Total params: 27,141
2019-12-24 11:13:17,374 [INFO] Trainable params: 26,693
2019-12-24 11:13:17,374 [INFO] Non-trainable params: 448
2019-12-24 11:13:17,374 [INFO] _________________________________________________________________
2019-12-24 11:13:18,729 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 18, pseudo-likelihood = -31.30, time = 0.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -30.92, time = 0.19s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -30.49, time = 0.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -30.02, time = 0.19s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -29.48, time = 0.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.90, time = 0.19s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.26, time = 0.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -27.57, time = 0.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -26.87, time = 0.19s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -26.10, time = 0.19s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -25.32, time = 0.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -24.49, time = 0.19s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -23.63, time = 0.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -22.76, time = 0.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -21.87, time = 0.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -21.03, time = 0.19s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -20.28, time = 0.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -19.58, time = 0.19s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -18.89, time = 0.19s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -18.33, time = 0.19s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -17.98, time = 0.19s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -17.36, time = 0.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -16.94, time = 0.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -16.63, time = 0.19s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -16.35, time = 0.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -16.11, time = 0.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -15.88, time = 0.19s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -15.68, time = 0.19s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -15.43, time = 0.19s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -15.21, time = 0.19s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -15.00, time = 0.19s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -14.82, time = 0.19s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -14.68, time = 0.19s
Train on 75584 samples, validate on 25195 samples
Epoch 1/300
 - 2s - loss: 0.2034 - val_loss: 0.0844
 - val_f1: 0.9158
Epoch 2/300
 - 1s - loss: 0.0658 - val_loss: 0.0352
 - val_f1: 0.9695
Epoch 3/300
 - 1s - loss: 0.0397 - val_loss: 0.0227
 - val_f1: 0.9771
Epoch 4/300
 - 1s - loss: 0.0302 - val_loss: 0.0168
 - val_f1: 0.9862
Epoch 5/300
 - 1s - loss: 0.0244 - val_loss: 0.0143
 - val_f1: 0.9881
Epoch 6/300
 - 1s - loss: 0.0224 - val_loss: 0.0158
 - val_f1: 0.9882
Epoch 7/300
 - 1s - loss: 0.0198 - val_loss: 0.0129
 - val_f1: 0.9883
Epoch 8/300
 - 1s - loss: 0.0188 - val_loss: 0.0118
 - val_f1: 0.9900
Epoch 9/300
 - 1s - loss: 0.0172 - val_loss: 0.0108
 - val_f1: 0.9918
Epoch 10/300
 - 1s - loss: 0.0165 - val_loss: 0.0104
 - val_f1: 0.9927
Epoch 11/300
 - 1s - loss: 0.0152 - val_loss: 0.0109
 - val_f1: 0.9924
Epoch 12/300
 - 1s - loss: 0.0143 - val_loss: 0.0098
 - val_f1: 0.9928
Epoch 13/300
 - 1s - loss: 0.0140 - val_loss: 0.0095
 - val_f1: 0.9927
Epoch 14/300
 - 1s - loss: 0.0136 - val_loss: 0.0096
 - val_f1: 0.9912
Epoch 15/300
 - 1s - loss: 0.0127 - val_loss: 0.0104
 - val_f1: 0.9917
Epoch 16/300
 - 1s - loss: 0.0129 - val_loss: 0.0096
 - val_f1: 0.9926
Epoch 17/300
 - 1s - loss: 0.0122 - val_loss: 0.0085
 - val_f1: 0.9930
Epoch 18/300
 - 1s - loss: 0.0118 - val_loss: 0.0086
 - val_f1: 0.9936
Epoch 19/300
 - 1s - loss: 0.0112 - val_loss: 0.0087
 - val_f1: 0.9932
Epoch 20/300
 - 1s - loss: 0.0113 - val_loss: 0.0083
 - val_f1: 0.9938
Epoch 21/300
 - 1s - loss: 0.0108 - val_loss: 0.0087
 - val_f1: 0.9931
Epoch 22/300
 - 1s - loss: 0.0105 - val_loss: 0.0083
 - val_f1: 0.9941
Epoch 23/300
 - 1s - loss: 0.0100 - val_loss: 0.0080
 - val_f1: 0.9945
Epoch 24/300
 - 1s - loss: 0.0103 - val_loss: 0.0080
 - val_f1: 0.9936
Epoch 25/300
 - 1s - loss: 0.0097 - val_loss: 0.0077
 - val_f1: 0.9946
Epoch 26/300
 - 1s - loss: 0.0100 - val_loss: 0.0083
 - val_f1: 0.9940
Epoch 27/300
 - 1s - loss: 0.0095 - val_loss: 0.0077
 - val_f1: 0.9940
Epoch 28/300
 - 1s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9946
Epoch 29/300
 - 1s - loss: 0.0094 - val_loss: 0.0075
 - val_f1: 0.9946
Epoch 30/300
 - 1s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 31/300
 - 1s - loss: 0.0087 - val_loss: 0.0073
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 11:14:17,854 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9946
Epoch 32/300
 - 1s - loss: 0.0093 - val_loss: 0.0075
 - val_f1: 0.9937
Epoch 33/300
 - 1s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9945
Epoch 34/300
 - 1s - loss: 0.0083 - val_loss: 0.0074
 - val_f1: 0.9941
Epoch 35/300
 - 1s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9946
Epoch 36/300
 - 1s - loss: 0.0081 - val_loss: 0.0073
 - val_f1: 0.9948
Epoch 37/300
 - 1s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 38/300
 - 1s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 39/300
 - 1s - loss: 0.0080 - val_loss: 0.0066
 - val_f1: 0.9953
Epoch 40/300
 - 1s - loss: 0.0080 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 41/300
 - 1s - loss: 0.0076 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 42/300
 - 1s - loss: 0.0075 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 43/300
 - 1s - loss: 0.0074 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 44/300
 - 1s - loss: 0.0076 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 45/300
 - 1s - loss: 0.0071 - val_loss: 0.0066
 - val_f1: 0.9953
Epoch 46/300
 - 1s - loss: 0.0071 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 47/300
 - 1s - loss: 0.0070 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 48/300
 - 1s - loss: 0.0067 - val_loss: 0.0067
 - val_f1: 0.9949
Epoch 49/300
 - 1s - loss: 0.0068 - val_loss: 0.0063
 - val_f1: 0.9955
Epoch 50/300
 - 1s - loss: 0.0066 - val_loss: 0.0063
 - val_f1: 0.9959
Epoch 51/300
 - 1s - loss: 0.0067 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 52/300
 - 1s - loss: 0.0070 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 53/300
 - 1s - loss: 0.0065 - val_loss: 0.0064
 - val_f1: 0.9957
Epoch 54/300
 - 1s - loss: 0.0063 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 55/300
 - 1s - loss: 0.0067 - val_loss: 0.0062
 - val_f1: 0.9956
Epoch 56/300
 - 1s - loss: 0.0061 - val_loss: 0.0057
 - val_f1: 0.9963
Epoch 57/300
 - 1s - loss: 0.0065 - val_loss: 0.0058
 - val_f1: 0.9961
Epoch 58/300
 - 1s - loss: 0.0065 - val_loss: 0.0064
 - val_f1: 0.9946
Epoch 59/300
 - 1s - loss: 0.0061 - val_loss: 0.0060
 - val_f1: 0.9957
Epoch 60/300
 - 1s - loss: 0.0060 - val_loss: 0.0060
 - val_f1: 0.9958
Epoch 61/300
 - 1s - loss: 0.0061 - val_loss: 0.0063
2019-12-24 11:15:12,353 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9949
Epoch 62/300
 - 1s - loss: 0.0063 - val_loss: 0.0059
 - val_f1: 0.9958
Epoch 63/300
 - 1s - loss: 0.0061 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 64/300
 - 1s - loss: 0.0060 - val_loss: 0.0060
 - val_f1: 0.9953
Epoch 65/300
 - 1s - loss: 0.0062 - val_loss: 0.0059
 - val_f1: 0.9958
Epoch 66/300
 - 1s - loss: 0.0058 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 67/300
 - 1s - loss: 0.0057 - val_loss: 0.0057
 - val_f1: 0.9962
Epoch 68/300
 - 1s - loss: 0.0059 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 69/300
 - 1s - loss: 0.0056 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 70/300
 - 1s - loss: 0.0057 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 71/300
 - 1s - loss: 0.0056 - val_loss: 0.0057
 - val_f1: 0.9959
Epoch 72/300
 - 1s - loss: 0.0054 - val_loss: 0.0059
 - val_f1: 0.9956
Epoch 73/300
 - 1s - loss: 0.0056 - val_loss: 0.0059
 - val_f1: 0.9957
Epoch 74/300
 - 1s - loss: 0.0060 - val_loss: 0.0054
 - val_f1: 0.9957
Epoch 75/300
 - 1s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 76/300
 - 1s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9959
Epoch 77/300
 - 1s - loss: 0.0053 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 78/300
 - 1s - loss: 0.0054 - val_loss: 0.0058
 - val_f1: 0.9959
Epoch 79/300
 - 1s - loss: 0.0052 - val_loss: 0.0056
 - val_f1: 0.9964
Epoch 80/300
 - 1s - loss: 0.0056 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 81/300
 - 1s - loss: 0.0052 - val_loss: 0.0061
 - val_f1: 0.9958
Epoch 82/300
 - 1s - loss: 0.0053 - val_loss: 0.0057
 - val_f1: 0.9961
Epoch 83/300
 - 1s - loss: 0.0052 - val_loss: 0.0057
 - val_f1: 0.9960
Epoch 84/300
 - 1s - loss: 0.0054 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 85/300
 - 1s - loss: 0.0054 - val_loss: 0.0057
 - val_f1: 0.9958
Epoch 86/300
 - 1s - loss: 0.0051 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 87/300
 - 1s - loss: 0.0052 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 88/300
 - 1s - loss: 0.0051 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 89/300
 - 1s - loss: 0.0053 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 90/300
 - 1s - loss: 0.0055 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 91/300
 - 1s - loss: 0.0052 - val_loss: 0.0053
2019-12-24 11:16:06,859 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9961
Epoch 92/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 93/300
 - 1s - loss: 0.0050 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 94/300
 - 1s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9964
Epoch 95/300
 - 1s - loss: 0.0049 - val_loss: 0.0053
 - val_f1: 0.9965
Epoch 96/300
 - 1s - loss: 0.0048 - val_loss: 0.0056
 - val_f1: 0.9959
Epoch 97/300
 - 1s - loss: 0.0052 - val_loss: 0.0056
 - val_f1: 0.9960
Epoch 98/300
 - 1s - loss: 0.0049 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 99/300
 - 1s - loss: 0.0052 - val_loss: 0.0055
 - val_f1: 0.9963
Epoch 100/300
 - 1s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9963
Epoch 101/300
 - 1s - loss: 0.0048 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 102/300
 - 1s - loss: 0.0049 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 103/300
 - 1s - loss: 0.0050 - val_loss: 0.0053
 - val_f1: 0.9963
Epoch 104/300
 - 1s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 105/300
 - 1s - loss: 0.0052 - val_loss: 0.0053
 - val_f1: 0.9960
Epoch 106/300
 - 1s - loss: 0.0048 - val_loss: 0.0053
 - val_f1: 0.9961
Epoch 107/300
 - 1s - loss: 0.0046 - val_loss: 0.0055
 - val_f1: 0.9961
Epoch 108/300
 - 1s - loss: 0.0047 - val_loss: 0.0060
 - val_f1: 0.9956
Epoch 109/300
 - 1s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 110/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9962
Epoch 111/300
 - 1s - loss: 0.0048 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 112/300
 - 1s - loss: 0.0045 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 113/300
 - 1s - loss: 0.0046 - val_loss: 0.0053
 - val_f1: 0.9962
Epoch 114/300
 - 1s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 115/300
 - 1s - loss: 0.0046 - val_loss: 0.0054
 - val_f1: 0.9960
Epoch 116/300
 - 1s - loss: 0.0046 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 117/300
 - 1s - loss: 0.0052 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 118/300
 - 1s - loss: 0.0044 - val_loss: 0.0050
 - val_f1: 0.9962
Epoch 119/300
 - 1s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 120/300
 - 1s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9963
Epoch 121/300
 - 1s - loss: 0.0049 - val_loss: 0.0052
2019-12-24 11:17:01,431 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9961
Epoch 122/300
 - 1s - loss: 0.0046 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 123/300
 - 1s - loss: 0.0047 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 124/300
 - 1s - loss: 0.0042 - val_loss: 0.0052
 - val_f1: 0.9961
Epoch 125/300
 - 1s - loss: 0.0046 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 126/300
 - 1s - loss: 0.0044 - val_loss: 0.0054
 - val_f1: 0.9961
Epoch 127/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9965
Epoch 128/300
 - 1s - loss: 0.0044 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 129/300
 - 1s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9965
Epoch 130/300
 - 1s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9964
Epoch 131/300
 - 1s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 132/300
 - 1s - loss: 0.0047 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 133/300
 - 1s - loss: 0.0045 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 134/300
 - 1s - loss: 0.0043 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 135/300
 - 1s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 136/300
 - 1s - loss: 0.0046 - val_loss: 0.0051
 - val_f1: 0.9966
Epoch 137/300
 - 1s - loss: 0.0046 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 138/300
 - 1s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 139/300
 - 1s - loss: 0.0043 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 140/300
 - 1s - loss: 0.0043 - val_loss: 0.0051
 - val_f1: 0.9964
Epoch 141/300
 - 1s - loss: 0.0044 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 142/300
 - 1s - loss: 0.0044 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 143/300
 - 1s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 144/300
 - 1s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 145/300
 - 1s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 146/300
 - 1s - loss: 0.0041 - val_loss: 0.0052
 - val_f1: 0.9960
Epoch 147/300
 - 1s - loss: 0.0044 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 148/300
 - 1s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 149/300
 - 1s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 150/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9967
Epoch 151/300
 - 1s - loss: 0.0041 - val_loss: 0.0051
2019-12-24 11:17:55,957 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9967
Epoch 152/300
 - 1s - loss: 0.0041 - val_loss: 0.0052
 - val_f1: 0.9966
Epoch 153/300
 - 1s - loss: 0.0043 - val_loss: 0.0055
 - val_f1: 0.9962
Epoch 154/300
 - 1s - loss: 0.0043 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 155/300
 - 1s - loss: 0.0040 - val_loss: 0.0052
 - val_f1: 0.9962
Epoch 156/300
 - 1s - loss: 0.0046 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 157/300
 - 1s - loss: 0.0040 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 158/300
 - 1s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 159/300
 - 1s - loss: 0.0041 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 160/300
 - 1s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 161/300
 - 1s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 162/300
 - 1s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 163/300
 - 1s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 164/300
 - 1s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 165/300
 - 1s - loss: 0.0042 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 166/300
 - 1s - loss: 0.0041 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 167/300
 - 1s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 168/300
 - 1s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 169/300
 - 1s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 170/300
 - 1s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9962
Epoch 171/300
 - 1s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9965
Epoch 172/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9965
Epoch 173/300
 - 1s - loss: 0.0040 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 174/300
 - 1s - loss: 0.0039 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 175/300
 - 1s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 176/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 177/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 178/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 179/300
 - 1s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9966
Epoch 180/300
 - 1s - loss: 0.0038 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 181/300
 - 1s - loss: 0.0040 - val_loss: 0.0055
2019-12-24 11:18:50,531 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9961
Epoch 182/300
 - 1s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 183/300
 - 1s - loss: 0.0039 - val_loss: 0.0046
 - val_f1: 0.9964
Epoch 184/300
 - 1s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 185/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 186/300
 - 1s - loss: 0.0037 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 187/300
 - 1s - loss: 0.0040 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 188/300
 - 1s - loss: 0.0037 - val_loss: 0.0045
 - val_f1: 0.9970
Epoch 189/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 190/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9968
Epoch 191/300
 - 1s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9964
Epoch 192/300
 - 1s - loss: 0.0037 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 193/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 194/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 195/300
 - 1s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 196/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 197/300
 - 1s - loss: 0.0042 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 198/300
 - 1s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 199/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 200/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 201/300
 - 1s - loss: 0.0038 - val_loss: 0.0045
 - val_f1: 0.9966
Epoch 202/300
 - 1s - loss: 0.0037 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 203/300
 - 1s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 204/300
 - 1s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 205/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9965
Epoch 206/300
 - 1s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9966
Epoch 207/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 208/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 209/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9964
Epoch 210/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9964
Epoch 211/300
 - 1s - loss: 0.0032 - val_loss: 0.0049
2019-12-24 11:19:44,952 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_dbn_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9965
Epoch 212/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9965
Epoch 213/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 214/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 215/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 216/300
 - 1s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9968
Epoch 217/300
 - 1s - loss: 0.0037 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 218/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9966
Epoch 219/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 220/300
 - 1s - loss: 0.0036 - val_loss: 0.0047
 - val_f1: 0.9967
Epoch 221/300
 - 1s - loss: 0.0034 - val_loss: 0.0050
 - val_f1: 0.9963
Epoch 222/300
 - 1s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9966
Epoch 223/300
 - 1s - loss: 0.0032 - val_loss: 0.0049
 - val_f1: 0.9967
Epoch 224/300
 - 1s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9969
Epoch 225/300
 - 1s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9968
Epoch 226/300
 - 1s - loss: 0.0032 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 227/300
 - 1s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 228/300
 - 1s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9966
Epoch 229/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 230/300
 - 1s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9967
Epoch 231/300
 - 1s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 232/300
 - 1s - loss: 0.0033 - val_loss: 0.0046
 - val_f1: 0.9968
Epoch 233/300
 - 1s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9965
Epoch 234/300
 - 1s - loss: 0.0033 - val_loss: 0.0052
 - val_f1: 0.9964
Epoch 235/300
 - 1s - loss: 0.0032 - val_loss: 0.0060
 - val_f1: 0.9955
Epoch 236/300
 - 1s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9967
Epoch 237/300
 - 1s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9963
Epoch 238/300
 - 1s - loss: 0.0034 - val_loss: 0.0046
2019-12-24 11:20:34,606 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 11:20:37,035 [INFO] Last epoch loss evaluation: train_loss = 0.002206, val_loss = 0.004486
2019-12-24 11:20:37,039 [INFO] Training complete. time_to_train = 500.69 sec, 8.34 min
2019-12-24 11:20:37,046 [INFO] Model saved to results_selected_models/selected_nsl_dbn_deep_rep5/best_model.pickle
2019-12-24 11:20:37,049 [INFO] Training history saved to: results_selected_models/selected_nsl_dbn_deep_rep5/training_error_history.csv
2019-12-24 11:20:37,188 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep5/training_error_history.png
2019-12-24 11:20:37,315 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_deep_rep5/training_f1_history.png
2019-12-24 11:20:37,316 [INFO] Making predictions on training, validation, testing data
2019-12-24 11:20:40,294 [INFO] Evaluating predictions (results)
2019-12-24 11:20:40,577 [INFO] Dataset: Testing. Classification report below
2019-12-24 11:20:40,577 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.81      0.88      7458
      normal       0.68      0.93      0.79      9711
       probe       0.72      0.75      0.74      2421
         r2l       0.60      0.11      0.18      2421
         u2r       0.25      0.04      0.07       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.64      0.53      0.53     22544
weighted avg       0.76      0.76      0.73     22544

2019-12-24 11:20:40,577 [INFO] Overall accuracy (micro avg): 0.7610450674237047
2019-12-24 11:20:40,900 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7610         0.7610                       0.7610                0.0597                   0.2390  0.7610
1     Macro avg        0.9044         0.6416                       0.5283                0.0779                   0.4717  0.5313
2  Weighted avg        0.8642         0.7591                       0.7610                0.1506                   0.2390  0.7301
2019-12-24 11:20:41,241 [INFO] Dataset: Validation. Classification report below
2019-12-24 11:20:41,241 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.90      0.93       199
         u2r       0.67      0.60      0.63        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.92      0.90      0.91     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-24 11:20:41,241 [INFO] Overall accuracy (micro avg): 0.9970232188926375
2019-12-24 11:20:41,618 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0007                   0.0030  0.9970
1     Macro avg        0.9988         0.9238                       0.8988                0.0010                   0.1012  0.9108
2  Weighted avg        0.9982         0.9970                       0.9970                0.0022                   0.0030  0.9970
2019-12-24 11:20:43,130 [INFO] Dataset: Training. Classification report below
2019-12-24 11:20:43,130 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      1.00      9325
         r2l       0.97      0.91      0.94       796
         u2r       0.91      0.74      0.82        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.98      0.93      0.95    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-24 11:20:43,130 [INFO] Overall accuracy (micro avg): 0.99768798745758
2019-12-24 11:20:44,840 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9977         0.9977                       0.9977                0.0006                   0.0023  0.9977
1     Macro avg        0.9991         0.9757                       0.9288                0.0009                   0.0712  0.9502
2  Weighted avg        0.9985         0.9977                       0.9977                0.0020                   0.0023  0.9977
2019-12-24 11:20:44,862 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_deep_rep5/selected_nsl_dbn_deep_rep5_results.xlsx
2019-12-24 11:20:44,863 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 11:20:44,867 [INFO] Created directory: results_selected_models/selected_ids17_dbn_deep_rep1
2019-12-24 11:20:44,867 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_deep_rep1/run_log.log
2019-12-24 11:20:44,867 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 11:20:44,867 [INFO] Experiment parameters given below
2019-12-24 11:20:44,867 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_deep_rep1'}
2019-12-24 11:20:44,868 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_deep_rep1/tf_logs_run_2019_12_24-11_20_44
2019-12-24 11:20:44,868 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 11:20:44,871 [INFO] Reading X, y files
2019-12-24 11:20:44,871 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 11:20:50,696 [INFO] Reading complete. time_to_read=5.82 seconds
2019-12-24 11:20:50,696 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 11:20:52,275 [INFO] Reading complete. time_to_read=1.58 seconds
2019-12-24 11:20:52,275 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 11:20:53,860 [INFO] Reading complete. time_to_read=1.59 seconds
2019-12-24 11:20:53,860 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 11:20:54,305 [INFO] Reading complete. time_to_read=0.44 seconds
2019-12-24 11:20:54,305 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 11:20:54,464 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-24 11:20:54,464 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 11:20:54,625 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-24 11:20:58,040 [INFO] Initializing model
2019-12-24 11:20:58,041 [INFO] Training model
2019-12-24 11:20:58,041 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 11:21:17,269 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 2d7bb6ea42a5960d5f9b1205b7371db6c20c0ffc
2019-12-24 11:21:17,269 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9966
Epoch 00238: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.77, time = 9.71s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.44, time = 19.79s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.62, time = 18.83s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.85, time = 18.64s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.48, time = 18.60s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.09, time = 18.52s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.86, time = 18.44s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -63.80, time = 18.40s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -67.82, time = 18.38s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -71.90, time = 18.34s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -76.03, time = 18.30s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -80.20, time = 18.28s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -84.40, time = 18.26s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -88.62, time = 18.23s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -92.88, time = 18.22s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -97.17, time = 18.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -101.46, time = 18.18s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -105.80, time = 18.16s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -110.15, time = 18.14s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -114.51, time = 18.15s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -118.87, time = 18.14s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -123.28, time = 18.13s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -127.69, time = 17.88s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -132.08, time = 17.73s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -136.51, time = 17.48s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -140.92, time = 17.24s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -145.35, time = 17.12s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -149.79, time = 16.98s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -154.23, time = 16.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -158.67, time = 16.88s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -163.10, time = 16.84s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -167.55, time = 16.81s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -171.98, time = 16.78s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -176.42, time = 16.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -180.87, time = 16.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -185.32, time = 16.73s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -189.76, time = 16.72s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -194.20, time = 16.71s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -198.65, time = 16.70s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -203.10, time = 16.76s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -207.55, time = 16.71s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -212.00, time = 16.71s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -216.44, time = 16.70s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -220.90, time = 16.70s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -225.34, time = 16.70s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -229.80, time = 16.72s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -234.26, time = 16.68s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -238.71, time = 16.67s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -243.16, time = 16.68s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -247.62, time = 16.67s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.98, time = 7.61s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.56, time = 12.40s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.23, time = 12.38s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.92, time = 12.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.59, time = 12.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.26, time = 12.36s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.92, time = 12.36s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.57, time = 12.36s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -55.21, time = 12.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.86, time = 12.36s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.50, time = 12.36s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.11, time = 12.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.74, time = 12.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -53.35, time = 12.36s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -52.96, time = 12.37s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.56, time = 12.40s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.16, time = 12.41s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -51.75, time = 12.43s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.33, time = 12.44s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -50.89, time = 12.43s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -50.47, time = 12.42s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -50.04, time = 12.40s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -49.61, time = 12.39s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -49.16, time = 12.39s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -48.70, time = 12.39s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -48.24, time = 12.40s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.79, time = 12.40s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -47.33, time = 12.40s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -46.86, time = 12.40s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -46.40, time = 12.40s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -45.92, time = 12.40s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -45.44, time = 12.38s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -44.96, time = 12.27s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -44.47, time = 12.21s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -43.99, time = 12.20s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.52, time = 12.20s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.03, time = 12.20s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.53, time = 12.20s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.05, time = 12.19s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.55, time = 12.19s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.07, time = 12.20s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -40.59, time = 12.19s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -40.10, time = 12.19s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -39.61, time = 12.20s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.14, time = 12.20s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -38.65, time = 12.20s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -38.19, time = 12.22s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -37.70, time = 12.20s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -37.23, time = 12.20s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -36.77, time = 12.19s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.44, time = 4.01s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.41, time = 6.45s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.30, time = 6.45s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.26, time = 6.44s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.21, time = 6.45s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.16, time = 6.45s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.12, time = 6.44s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.07, time = 6.43s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.02, time = 6.43s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.97, time = 6.44s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.92, time = 6.43s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -28.87, time = 6.43s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -28.82, time = 6.45s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -28.78, time = 6.43s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -28.72, time = 6.43s2019-12-24 11:51:34,755 [INFO] Pretraining Complete
2019-12-24 11:51:34,777 [INFO] Getting pretrained weights
2019-12-24 11:51:34,777 [INFO] Creating and initializing feed forward neural network
2019-12-24 11:51:35,061 [INFO] _________________________________________________________________
2019-12-24 11:51:35,061 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 11:51:35,061 [INFO] =================================================================
2019-12-24 11:51:35,061 [INFO] dense_21 (Dense)             (None, 128)               10112     
2019-12-24 11:51:35,061 [INFO] _________________________________________________________________
2019-12-24 11:51:35,061 [INFO] batch_normalization_16 (Batc (None, 128)               512       
2019-12-24 11:51:35,061 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] dropout_16 (Dropout)         (None, 128)               0         
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] dense_22 (Dense)             (None, 64)                8256      
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] batch_normalization_17 (Batc (None, 64)                256       
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] dropout_17 (Dropout)         (None, 64)                0         
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] dense_23 (Dense)             (None, 32)                2080      
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] batch_normalization_18 (Batc (None, 32)                128       
2019-12-24 11:51:35,062 [INFO] _________________________________________________________________
2019-12-24 11:51:35,062 [INFO] dropout_18 (Dropout)         (None, 32)                0         
2019-12-24 11:51:35,063 [INFO] _________________________________________________________________
2019-12-24 11:51:35,063 [INFO] dense_24 (Dense)             (None, 12)                396       
2019-12-24 11:51:35,063 [INFO] =================================================================
2019-12-24 11:51:35,063 [INFO] Total params: 21,740
2019-12-24 11:51:35,063 [INFO] Trainable params: 21,292
2019-12-24 11:51:35,063 [INFO] Non-trainable params: 448
2019-12-24 11:51:35,063 [INFO] _________________________________________________________________
2019-12-24 11:51:36,731 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 16, pseudo-likelihood = -28.67, time = 6.45s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -28.62, time = 6.43s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -28.56, time = 6.43s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -28.51, time = 6.43s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -28.45, time = 6.44s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -28.39, time = 6.44s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.34, time = 6.43s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.27, time = 6.44s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.21, time = 6.43s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.15, time = 6.44s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -28.09, time = 6.43s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -28.03, time = 6.43s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -27.97, time = 6.43s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -27.90, time = 6.43s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -27.83, time = 6.43s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -27.77, time = 6.43s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -27.70, time = 6.43s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -27.63, time = 6.43s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -27.57, time = 6.44s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.49, time = 6.44s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -27.42, time = 6.44s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -27.34, time = 6.43s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -27.28, time = 6.45s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -27.20, time = 6.45s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.11, time = 6.44s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.04, time = 6.44s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.96, time = 6.45s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.88, time = 6.45s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.80, time = 6.45s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.72, time = 6.45s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.64, time = 6.45s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.55, time = 6.45s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.47, time = 6.46s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.38, time = 6.47s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.29, time = 6.46s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 18s - loss: 0.0978 - val_loss: 0.0695
 - val_f1: 0.7399
Epoch 2/300
 - 17s - loss: 0.0621 - val_loss: 0.0498
 - val_f1: 0.8233
Epoch 3/300
 - 17s - loss: 0.0517 - val_loss: 0.0458
 - val_f1: 0.8463
Epoch 4/300
 - 17s - loss: 0.0487 - val_loss: 0.0446
 - val_f1: 0.8464
Epoch 5/300
 - 17s - loss: 0.0473 - val_loss: 0.0433
 - val_f1: 0.8471
Epoch 6/300
 - 17s - loss: 0.0459 - val_loss: 0.0417
 - val_f1: 0.8482
Epoch 7/300
 - 17s - loss: 0.0440 - val_loss: 0.0398
 - val_f1: 0.8508
Epoch 8/300
 - 17s - loss: 0.0382 - val_loss: 0.0238
 - val_f1: 0.9441
Epoch 9/300
 - 17s - loss: 0.0277 - val_loss: 0.0202
 - val_f1: 0.9489
Epoch 10/300
 - 17s - loss: 0.0240 - val_loss: 0.0172
 - val_f1: 0.9566
Epoch 11/300
 - 17s - loss: 0.0213 - val_loss: 0.0151
 - val_f1: 0.9597
Epoch 12/300
 - 17s - loss: 0.0193 - val_loss: 0.0138
 - val_f1: 0.9650
Epoch 13/300
 - 17s - loss: 0.0182 - val_loss: 0.0132
 - val_f1: 0.9687
Epoch 14/300
 - 17s - loss: 0.0174 - val_loss: 0.0128
 - val_f1: 0.9701
Epoch 15/300
 - 17s - loss: 0.0160 - val_loss: 0.0106
 - val_f1: 0.9742
Epoch 16/300
 - 17s - loss: 0.0148 - val_loss: 0.0100
 - val_f1: 0.9735
Epoch 17/300
 - 17s - loss: 0.0142 - val_loss: 0.0095
 - val_f1: 0.9775
Epoch 18/300
 - 17s - loss: 0.0135 - val_loss: 0.0089
 - val_f1: 0.9756
Epoch 19/300
 - 17s - loss: 0.0129 - val_loss: 0.0087
 - val_f1: 0.9796
Epoch 20/300
 - 17s - loss: 0.0122 - val_loss: 0.0075
 - val_f1: 0.9838
Epoch 21/300
 - 17s - loss: 0.0116 - val_loss: 0.0070
 - val_f1: 0.9837
Epoch 22/300
 - 17s - loss: 0.0110 - val_loss: 0.0063
 - val_f1: 0.9857
Epoch 23/300
 - 17s - loss: 0.0103 - val_loss: 0.0060
 - val_f1: 0.9842
Epoch 24/300
 - 17s - loss: 0.0098 - val_loss: 0.0059
 - val_f1: 0.9869
Epoch 25/300
 - 17s - loss: 0.0094 - val_loss: 0.0057
 - val_f1: 0.9863
Epoch 26/300
 - 17s - loss: 0.0090 - val_loss: 0.0056
 - val_f1: 0.9859
Epoch 27/300
 - 17s - loss: 0.0086 - val_loss: 0.0054
 - val_f1: 0.9877
Epoch 28/300
 - 17s - loss: 0.0084 - val_loss: 0.0053
 - val_f1: 0.9879
Epoch 29/300
 - 17s - loss: 0.0082 - val_loss: 0.0052
 - val_f1: 0.9883
Epoch 30/300
 - 17s - loss: 0.0079 - val_loss: 0.0051
 - val_f1: 0.9884
Epoch 31/300
 - 17s - loss: 0.0077 - val_loss: 0.0050
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 12:06:32,592 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9883
Epoch 32/300
 - 17s - loss: 0.0075 - val_loss: 0.0049
 - val_f1: 0.9885
Epoch 33/300
 - 17s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9889
Epoch 34/300
 - 17s - loss: 0.0071 - val_loss: 0.0048
 - val_f1: 0.9885
Epoch 35/300
 - 17s - loss: 0.0070 - val_loss: 0.0046
 - val_f1: 0.9888
Epoch 36/300
 - 17s - loss: 0.0068 - val_loss: 0.0046
 - val_f1: 0.9887
Epoch 37/300
 - 17s - loss: 0.0066 - val_loss: 0.0045
 - val_f1: 0.9897
Epoch 38/300
 - 17s - loss: 0.0066 - val_loss: 0.0043
 - val_f1: 0.9902
Epoch 39/300
 - 17s - loss: 0.0064 - val_loss: 0.0044
 - val_f1: 0.9894
Epoch 40/300
 - 17s - loss: 0.0063 - val_loss: 0.0042
 - val_f1: 0.9903
Epoch 41/300
 - 17s - loss: 0.0061 - val_loss: 0.0043
 - val_f1: 0.9923
Epoch 42/300
 - 17s - loss: 0.0060 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 43/300
 - 17s - loss: 0.0059 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 44/300
 - 17s - loss: 0.0056 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 45/300
 - 17s - loss: 0.0055 - val_loss: 0.0035
 - val_f1: 0.9914
Epoch 46/300
 - 17s - loss: 0.0054 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 47/300
 - 17s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 48/300
 - 17s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 49/300
 - 17s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 50/300
 - 17s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 51/300
 - 17s - loss: 0.0048 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 52/300
 - 17s - loss: 0.0047 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 53/300
 - 17s - loss: 0.0047 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 54/300
 - 17s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 55/300
 - 17s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 56/300
 - 17s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 57/300
 - 17s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 58/300
 - 17s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 59/300
 - 17s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 60/300
 - 17s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 61/300
 - 17s - loss: 0.0042 - val_loss: 0.0029
2019-12-24 12:21:08,754 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9929
Epoch 62/300
 - 17s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 63/300
 - 17s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 64/300
 - 17s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 65/300
 - 17s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9920
Epoch 66/300
 - 17s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 67/300
 - 17s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 68/300
 - 17s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 69/300
 - 17s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 70/300
 - 17s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 71/300
 - 17s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 72/300
 - 17s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 73/300
 - 17s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 74/300
 - 17s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 75/300
 - 17s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 76/300
 - 17s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 77/300
 - 17s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 78/300
 - 17s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 79/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 80/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 81/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 82/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 83/300
 - 17s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 84/300
 - 17s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 85/300
 - 17s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 86/300
 - 17s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 87/300
 - 17s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 88/300
 - 17s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 89/300
 - 17s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 90/300
 - 17s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 91/300
 - 17s - loss: 0.0035 - val_loss: 0.0026
2019-12-24 12:35:44,502 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9941
Epoch 92/300
 - 17s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 93/300
 - 17s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 94/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 95/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 96/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 97/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 98/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 99/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 100/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 101/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 102/300
 - 17s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 103/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 104/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 105/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 106/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 107/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 108/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 109/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 110/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 111/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 112/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 113/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 114/300
 - 17s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9918
Epoch 115/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 116/300
 - 17s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 117/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 118/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 119/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 120/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 121/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
2019-12-24 12:50:20,089 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9946
Epoch 122/300
 - 17s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 123/300
 - 17s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 124/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 125/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 126/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 127/300
 - 17s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 128/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 129/300
 - 17s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 130/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 131/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 132/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 133/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 134/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 135/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 136/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 137/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 138/300
 - 17s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 139/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 140/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 141/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 142/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 143/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 144/300
 - 17s - loss: 0.0031 - val_loss: 0.0046
 - val_f1: 0.9918
Epoch 145/300
 - 17s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 146/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 147/300
 - 17s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 148/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 149/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9927
Epoch 150/300
 - 17s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 151/300
 - 17s - loss: 0.0031 - val_loss: 0.0026
2019-12-24 13:04:55,741 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9941
Epoch 152/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 153/300
 - 17s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 154/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 155/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 156/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 157/300
 - 17s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 158/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9926
Epoch 159/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 160/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 161/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 162/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 163/300
 - 17s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 164/300
 - 17s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 165/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 166/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 167/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 168/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 169/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 170/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 171/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 172/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 173/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 174/300
 - 17s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 175/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 176/300
 - 17s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 177/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 178/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 179/300
 - 17s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 180/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 181/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
2019-12-24 13:19:31,822 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9950
Epoch 182/300
 - 17s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 183/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 184/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9930
Epoch 185/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 186/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 187/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 188/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 189/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 190/300
 - 17s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 191/300
 - 17s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 192/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 193/300
 - 17s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 194/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 195/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 196/300
 - 17s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 197/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 198/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 199/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 200/300
 - 17s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 201/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 202/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 203/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 204/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 205/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 206/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 207/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 208/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 209/300
 - 17s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 210/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 211/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
2019-12-24 13:34:08,873 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9949
Epoch 212/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 213/300
 - 17s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 214/300
 - 17s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 215/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 216/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 217/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 218/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 219/300
 - 17s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 220/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 221/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 222/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 223/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 224/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 225/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 226/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 227/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 228/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 229/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 230/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 231/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 232/300
 - 17s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 233/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 234/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 235/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 236/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 237/300
 - 17s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 238/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 239/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 240/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 241/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
2019-12-24 13:48:44,990 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9952
Epoch 242/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 243/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 244/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 245/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 246/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 247/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 248/300
 - 17s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 249/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 250/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 251/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 252/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 253/300
 - 17s - loss: 0.0028 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 254/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 255/300
 - 17s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 256/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 257/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 258/300
 - 17s - loss: 0.0028 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 259/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 260/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 261/300
 - 17s - loss: 0.0029 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 262/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 263/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 264/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 265/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 266/300
 - 17s - loss: 0.0029 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 267/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 268/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 269/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 270/300
 - 17s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 271/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
2019-12-24 14:03:21,580 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9952
Epoch 272/300
 - 17s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 273/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9930
Epoch 274/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9956
Epoch 275/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 276/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 277/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 278/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9958
Epoch 279/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 280/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 281/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 282/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 283/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 284/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 285/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 286/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 287/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 288/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 289/300
 - 17s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 290/300
 - 17s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 291/300
 - 17s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 292/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9960
Epoch 293/300
 - 17s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 294/300
 - 17s - loss: 0.0028 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 295/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 296/300
 - 17s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 297/300
 - 17s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 298/300
 - 17s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 299/300
 - 17s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 300/300
 - 17s - loss: 0.0027 - val_loss: 0.0024
2019-12-24 14:17:40,450 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 14:18:12,625 [INFO] Last epoch loss evaluation: train_loss = 0.002058, val_loss = 0.002181
2019-12-24 14:18:12,663 [INFO] Training complete. time_to_train = 10634.62 sec, 177.24 min
2019-12-24 14:18:12,669 [INFO] Model saved to results_selected_models/selected_ids17_dbn_deep_rep1/best_model.pickle
2019-12-24 14:18:12,696 [INFO] Training history saved to: results_selected_models/selected_ids17_dbn_deep_rep1/training_error_history.csv
2019-12-24 14:18:12,892 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep1/training_error_history.png
2019-12-24 14:18:13,018 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep1/training_f1_history.png
2019-12-24 14:18:13,018 [INFO] Making predictions on training, validation, testing data
2019-12-24 14:19:11,037 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 14:19:21,331 [INFO] Dataset: Testing. Classification report below
2019-12-24 14:19:21,331 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.99      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.93      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.97      0.13      0.23       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.79      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 14:19:21,331 [INFO] Overall accuracy (micro avg): 0.9955902270661748
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-24 14:19:33,059 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8927                       0.7856                0.0010                   0.2144  0.8014
2  Weighted avg        0.9964         0.9954                       0.9956                0.0079                   0.0044  0.9952
2019-12-24 14:19:43,483 [INFO] Dataset: Validation. Classification report below
2019-12-24 14:19:43,483 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.34      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.84      0.11      0.19       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 14:19:43,483 [INFO] Overall accuracy (micro avg): 0.9956503442593385
2019-12-24 14:19:55,339 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8822                       0.7789                0.0010                   0.2211  0.7938
2  Weighted avg        0.9964         0.9954                       0.9957                0.0078                   0.0043  0.9953
2019-12-24 14:20:29,686 [INFO] Dataset: Training. Classification report below
2019-12-24 14:20:29,686 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.99      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.98      0.98      0.98      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.89      0.12      0.21       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.89      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-24 14:20:29,686 [INFO] Overall accuracy (micro avg): 0.9957764675095657
2019-12-24 14:21:08,726 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8879                       0.7838                0.0010                   0.2162  0.7995
2  Weighted avg        0.9965         0.9955                       0.9958                0.0077                   0.0042  0.9954
2019-12-24 14:21:08,755 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_deep_rep1/selected_ids17_dbn_deep_rep1_results.xlsx
2019-12-24 14:21:08,762 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 14:21:08,842 [INFO] Created directory: results_selected_models/selected_ids17_dbn_deep_rep2
2019-12-24 14:21:08,842 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_deep_rep2/run_log.log
2019-12-24 14:21:08,842 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 14:21:08,842 [INFO] Experiment parameters given below
2019-12-24 14:21:08,842 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_deep_rep2'}
2019-12-24 14:21:08,842 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_deep_rep2/tf_logs_run_2019_12_24-14_21_08
2019-12-24 14:21:08,842 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 14:21:08,843 [INFO] Reading X, y files
2019-12-24 14:21:08,843 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 14:21:14,542 [INFO] Reading complete. time_to_read=5.70 seconds
2019-12-24 14:21:14,542 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 14:21:16,111 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-24 14:21:16,111 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 14:21:17,629 [INFO] Reading complete. time_to_read=1.52 seconds
2019-12-24 14:21:17,630 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 14:21:17,856 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-24 14:21:17,856 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 14:21:17,931 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 14:21:17,931 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 14:21:18,005 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 14:21:21,436 [INFO] Initializing model
2019-12-24 14:21:21,436 [INFO] Training model
2019-12-24 14:21:21,436 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 14:21:40,166 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 78a758abe435aa855559273fe6616096e464a07c
2019-12-24 14:21:40,166 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9945
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.58, time = 9.75s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.16, time = 19.81s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.30, time = 18.87s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.52, time = 18.69s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.18, time = 18.64s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.84, time = 18.55s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.68, time = 18.47s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -63.67, time = 18.43s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -67.74, time = 18.40s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -71.87, time = 18.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -76.04, time = 18.34s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -80.24, time = 18.32s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -84.47, time = 18.30s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -88.71, time = 18.27s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -92.99, time = 18.25s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -97.28, time = 18.23s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -101.58, time = 18.21s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -105.90, time = 18.20s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -110.25, time = 18.18s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -114.60, time = 18.18s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -118.94, time = 18.18s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -123.33, time = 18.17s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -127.72, time = 17.91s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -132.10, time = 17.78s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -136.50, time = 17.52s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -140.89, time = 17.26s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -145.29, time = 17.15s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -149.71, time = 17.03s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -154.12, time = 16.97s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -158.54, time = 16.92s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -162.95, time = 16.88s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -167.37, time = 16.85s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -171.78, time = 16.82s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -176.19, time = 16.80s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -180.62, time = 16.79s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -185.05, time = 16.77s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -189.47, time = 16.75s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -193.89, time = 16.75s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -198.32, time = 16.74s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -202.75, time = 16.79s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -207.18, time = 16.74s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -211.61, time = 16.74s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -216.04, time = 16.74s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -220.49, time = 16.74s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -224.91, time = 16.73s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -229.36, time = 16.76s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -233.80, time = 16.71s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -238.24, time = 16.71s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -242.68, time = 16.71s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -247.12, time = 16.71s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -58.03, time = 7.62s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.61, time = 12.41s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.29, time = 12.39s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.97, time = 12.38s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.64, time = 12.37s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.31, time = 12.37s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.97, time = 12.38s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.62, time = 12.38s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -55.26, time = 12.37s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.90, time = 12.37s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.54, time = 12.37s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.16, time = 12.37s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.78, time = 12.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -53.40, time = 12.38s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -53.00, time = 12.38s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.60, time = 12.40s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.20, time = 12.42s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -51.79, time = 12.44s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.37, time = 12.45s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -50.93, time = 12.45s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -50.51, time = 12.43s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -50.08, time = 12.43s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -49.64, time = 12.40s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -49.19, time = 12.39s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -48.73, time = 12.40s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -48.27, time = 12.41s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.82, time = 12.42s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -47.35, time = 12.41s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -46.88, time = 12.41s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -46.42, time = 12.41s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -45.94, time = 12.41s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -45.46, time = 12.38s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -44.97, time = 12.28s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -44.48, time = 12.22s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.00, time = 12.21s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.53, time = 12.20s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.04, time = 12.21s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.54, time = 12.21s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.06, time = 12.21s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.56, time = 12.20s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.08, time = 12.21s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -40.59, time = 12.20s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -40.10, time = 12.21s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -39.61, time = 12.21s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.14, time = 12.21s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -38.65, time = 12.21s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -38.19, time = 12.20s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -37.70, time = 12.22s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -37.22, time = 12.22s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -36.76, time = 12.21s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.39, time = 4.07s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.40, time = 6.57s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.30, time = 6.57s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.25, time = 6.58s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.21, time = 6.57s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.16, time = 6.58s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.12, time = 6.57s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.07, time = 6.57s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.02, time = 6.57s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.97, time = 6.57s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.92, time = 6.57s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -28.87, time = 6.58s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -28.82, time = 6.57s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -28.77, time = 6.57s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -28.71, time = 6.57s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -28.66, time = 6.56s2019-12-24 14:52:06,296 [INFO] Pretraining Complete
2019-12-24 14:52:06,313 [INFO] Getting pretrained weights
2019-12-24 14:52:06,313 [INFO] Creating and initializing feed forward neural network
2019-12-24 14:52:06,584 [INFO] _________________________________________________________________
2019-12-24 14:52:06,584 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 14:52:06,584 [INFO] =================================================================
2019-12-24 14:52:06,585 [INFO] dense_25 (Dense)             (None, 128)               10112     
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] batch_normalization_19 (Batc (None, 128)               512       
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] dropout_19 (Dropout)         (None, 128)               0         
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] dense_26 (Dense)             (None, 64)                8256      
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] batch_normalization_20 (Batc (None, 64)                256       
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] dropout_20 (Dropout)         (None, 64)                0         
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] dense_27 (Dense)             (None, 33)                2145      
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] batch_normalization_21 (Batc (None, 33)                132       
2019-12-24 14:52:06,585 [INFO] _________________________________________________________________
2019-12-24 14:52:06,585 [INFO] dropout_21 (Dropout)         (None, 33)                0         
2019-12-24 14:52:06,586 [INFO] _________________________________________________________________
2019-12-24 14:52:06,586 [INFO] dense_28 (Dense)             (None, 12)                408       
2019-12-24 14:52:06,586 [INFO] =================================================================
2019-12-24 14:52:06,586 [INFO] Total params: 21,821
2019-12-24 14:52:06,586 [INFO] Trainable params: 21,371
2019-12-24 14:52:06,586 [INFO] Non-trainable params: 450
2019-12-24 14:52:06,586 [INFO] _________________________________________________________________
2019-12-24 14:52:08,585 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -28.61, time = 6.57s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -28.55, time = 6.56s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -28.50, time = 6.57s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -28.44, time = 6.57s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -28.38, time = 6.56s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.33, time = 6.57s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.26, time = 6.56s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.20, time = 6.56s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.14, time = 6.56s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -28.08, time = 6.56s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -28.02, time = 6.56s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -27.96, time = 6.56s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -27.89, time = 6.56s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -27.82, time = 6.56s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -27.75, time = 6.56s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -27.68, time = 6.56s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -27.62, time = 6.56s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -27.55, time = 6.56s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.47, time = 6.56s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -27.41, time = 6.57s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -27.33, time = 6.56s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -27.26, time = 6.57s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -27.18, time = 6.56s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.10, time = 6.56s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.03, time = 6.56s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.95, time = 6.57s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.87, time = 6.56s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.79, time = 6.56s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.70, time = 6.58s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.62, time = 6.57s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.53, time = 6.58s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.45, time = 6.59s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.36, time = 6.58s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.27, time = 6.59s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 18s - loss: 0.0972 - val_loss: 0.0658
 - val_f1: 0.7604
Epoch 2/300
 - 17s - loss: 0.0625 - val_loss: 0.0519
 - val_f1: 0.8147
Epoch 3/300
 - 18s - loss: 0.0536 - val_loss: 0.0468
 - val_f1: 0.8455
Epoch 4/300
 - 18s - loss: 0.0503 - val_loss: 0.0449
 - val_f1: 0.8512
Epoch 5/300
 - 18s - loss: 0.0486 - val_loss: 0.0438
 - val_f1: 0.8465
Epoch 6/300
 - 18s - loss: 0.0475 - val_loss: 0.0435
 - val_f1: 0.8471
Epoch 7/300
 - 17s - loss: 0.0457 - val_loss: 0.0389
 - val_f1: 0.8606
Epoch 8/300
 - 17s - loss: 0.0407 - val_loss: 0.0317
 - val_f1: 0.8920
Epoch 9/300
 - 17s - loss: 0.0331 - val_loss: 0.0219
 - val_f1: 0.9455
Epoch 10/300
 - 17s - loss: 0.0276 - val_loss: 0.0193
 - val_f1: 0.9520
Epoch 11/300
 - 18s - loss: 0.0237 - val_loss: 0.0157
 - val_f1: 0.9541
Epoch 12/300
 - 17s - loss: 0.0207 - val_loss: 0.0145
 - val_f1: 0.9619
Epoch 13/300
 - 17s - loss: 0.0191 - val_loss: 0.0133
 - val_f1: 0.9656
Epoch 14/300
 - 18s - loss: 0.0180 - val_loss: 0.0129
 - val_f1: 0.9661
Epoch 15/300
 - 18s - loss: 0.0168 - val_loss: 0.0121
 - val_f1: 0.9673
Epoch 16/300
 - 18s - loss: 0.0160 - val_loss: 0.0119
 - val_f1: 0.9692
Epoch 17/300
 - 17s - loss: 0.0151 - val_loss: 0.0101
 - val_f1: 0.9772
Epoch 18/300
 - 18s - loss: 0.0143 - val_loss: 0.0091
 - val_f1: 0.9803
Epoch 19/300
 - 18s - loss: 0.0135 - val_loss: 0.0080
 - val_f1: 0.9825
Epoch 20/300
 - 17s - loss: 0.0125 - val_loss: 0.0072
 - val_f1: 0.9831
Epoch 21/300
 - 17s - loss: 0.0117 - val_loss: 0.0066
 - val_f1: 0.9834
Epoch 22/300
 - 17s - loss: 0.0109 - val_loss: 0.0066
 - val_f1: 0.9837
Epoch 23/300
 - 18s - loss: 0.0103 - val_loss: 0.0064
 - val_f1: 0.9844
Epoch 24/300
 - 17s - loss: 0.0099 - val_loss: 0.0061
 - val_f1: 0.9862
Epoch 25/300
 - 17s - loss: 0.0094 - val_loss: 0.0061
 - val_f1: 0.9856
Epoch 26/300
 - 18s - loss: 0.0091 - val_loss: 0.0060
 - val_f1: 0.9874
Epoch 27/300
 - 17s - loss: 0.0088 - val_loss: 0.0060
 - val_f1: 0.9874
Epoch 28/300
 - 18s - loss: 0.0086 - val_loss: 0.0055
 - val_f1: 0.9869
Epoch 29/300
 - 17s - loss: 0.0083 - val_loss: 0.0054
 - val_f1: 0.9875
Epoch 30/300
 - 17s - loss: 0.0082 - val_loss: 0.0052
 - val_f1: 0.9882
Epoch 31/300
 - 17s - loss: 0.0080 - val_loss: 0.0054
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 15:07:48,989 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9871
Epoch 32/300
 - 17s - loss: 0.0079 - val_loss: 0.0052
 - val_f1: 0.9888
Epoch 33/300
 - 18s - loss: 0.0077 - val_loss: 0.0053
 - val_f1: 0.9878
Epoch 34/300
 - 18s - loss: 0.0074 - val_loss: 0.0051
 - val_f1: 0.9885
Epoch 35/300
 - 18s - loss: 0.0074 - val_loss: 0.0049
 - val_f1: 0.9890
Epoch 36/300
 - 18s - loss: 0.0072 - val_loss: 0.0048
 - val_f1: 0.9889
Epoch 37/300
 - 18s - loss: 0.0072 - val_loss: 0.0048
 - val_f1: 0.9894
Epoch 38/300
 - 18s - loss: 0.0070 - val_loss: 0.0048
 - val_f1: 0.9888
Epoch 39/300
 - 18s - loss: 0.0069 - val_loss: 0.0047
 - val_f1: 0.9887
Epoch 40/300
 - 17s - loss: 0.0067 - val_loss: 0.0046
 - val_f1: 0.9897
Epoch 41/300
 - 18s - loss: 0.0067 - val_loss: 0.0047
 - val_f1: 0.9891
Epoch 42/300
 - 17s - loss: 0.0066 - val_loss: 0.0045
 - val_f1: 0.9894
Epoch 43/300
 - 18s - loss: 0.0065 - val_loss: 0.0044
 - val_f1: 0.9896
Epoch 44/300
 - 18s - loss: 0.0065 - val_loss: 0.0045
 - val_f1: 0.9894
Epoch 45/300
 - 18s - loss: 0.0063 - val_loss: 0.0043
 - val_f1: 0.9892
Epoch 46/300
 - 18s - loss: 0.0062 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 47/300
 - 18s - loss: 0.0061 - val_loss: 0.0042
 - val_f1: 0.9904
Epoch 48/300
 - 18s - loss: 0.0060 - val_loss: 0.0041
 - val_f1: 0.9909
Epoch 49/300
 - 18s - loss: 0.0059 - val_loss: 0.0041
 - val_f1: 0.9895
Epoch 50/300
 - 17s - loss: 0.0058 - val_loss: 0.0040
 - val_f1: 0.9906
Epoch 51/300
 - 18s - loss: 0.0058 - val_loss: 0.0039
 - val_f1: 0.9903
Epoch 52/300
 - 17s - loss: 0.0056 - val_loss: 0.0038
 - val_f1: 0.9903
Epoch 53/300
 - 18s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9898
Epoch 54/300
 - 18s - loss: 0.0054 - val_loss: 0.0036
 - val_f1: 0.9910
Epoch 55/300
 - 18s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 56/300
 - 18s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9908
Epoch 57/300
 - 18s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 58/300
 - 18s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 59/300
 - 18s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 60/300
 - 17s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9944
Epoch 61/300
 - 18s - loss: 0.0048 - val_loss: 0.0032
2019-12-24 15:23:10,680 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9928
Epoch 62/300
 - 18s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 63/300
 - 17s - loss: 0.0048 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 64/300
 - 18s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 65/300
 - 18s - loss: 0.0046 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 66/300
 - 18s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 67/300
 - 17s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 68/300
 - 17s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 69/300
 - 18s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 70/300
 - 17s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 71/300
 - 17s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9919
Epoch 72/300
 - 18s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 73/300
 - 18s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 74/300
 - 18s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 75/300
 - 18s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 76/300
 - 18s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 77/300
 - 18s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 78/300
 - 18s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 79/300
 - 18s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 80/300
 - 18s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 81/300
 - 17s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 82/300
 - 17s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 83/300
 - 17s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 84/300
 - 18s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 85/300
 - 17s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 86/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 87/300
 - 18s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 88/300
 - 17s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 89/300
 - 17s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 90/300
 - 17s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 91/300
 - 18s - loss: 0.0039 - val_loss: 0.0029
2019-12-24 15:38:27,258 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9935
Epoch 92/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 93/300
 - 17s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 94/300
 - 18s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 95/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 96/300
 - 17s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 97/300
 - 17s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 98/300
 - 18s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 99/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 100/300
 - 17s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 101/300
 - 17s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 102/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 103/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 104/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 105/300
 - 18s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 106/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 107/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 108/300
 - 18s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 109/300
 - 18s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 110/300
 - 18s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 111/300
 - 18s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 112/300
 - 17s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 113/300
 - 17s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 114/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 115/300
 - 18s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 116/300
 - 18s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 117/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 118/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 119/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 120/300
 - 17s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 121/300
 - 17s - loss: 0.0035 - val_loss: 0.0025
2019-12-24 15:53:43,328 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9946
Epoch 122/300
 - 17s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 123/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 124/300
 - 17s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 125/300
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 126/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 127/300
 - 17s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 128/300
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 129/300
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 130/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 131/300
 - 17s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 132/300
 - 17s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 133/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 134/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 135/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 136/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 137/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 138/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 139/300
 - 17s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 140/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 141/300
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 142/300
 - 17s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9913
Epoch 143/300
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 144/300
 - 18s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 145/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 146/300
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 147/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 148/300
 - 18s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 149/300
 - 18s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 150/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 151/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
2019-12-24 16:08:59,850 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9946
Epoch 152/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 153/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 154/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 155/300
 - 17s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 156/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 157/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 158/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 159/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 160/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 161/300
 - 17s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 162/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 163/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 164/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 165/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 166/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 167/300
 - 17s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 168/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 169/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 170/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 171/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 172/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 173/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 174/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 175/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 176/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 177/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 178/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 179/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9940
Epoch 180/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 181/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
2019-12-24 16:24:16,432 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9950
Epoch 182/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9939
Epoch 183/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 184/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9935
Epoch 185/300
 - 17s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 186/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 187/300
 - 18s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 188/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 189/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 190/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 191/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 192/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 193/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 194/300
 - 17s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 195/300
 - 17s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 196/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 197/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 198/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9940
Epoch 199/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 200/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 201/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 202/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 203/300
 - 18s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 204/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 205/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 206/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 207/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 208/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 209/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 210/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 211/300
 - 17s - loss: 0.0035 - val_loss: 0.0024
2019-12-24 16:39:33,799 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9944
Epoch 212/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 213/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9940
Epoch 214/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 215/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 216/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 217/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 218/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9939
Epoch 219/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 220/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9951
Epoch 221/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 222/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 223/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 224/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 225/300
 - 17s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 226/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 227/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 228/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 229/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 230/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 231/300
 - 17s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9941
Epoch 232/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 233/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 234/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9943
Epoch 235/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 236/300
 - 18s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9948
Epoch 237/300
 - 18s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 238/300
 - 17s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 239/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 240/300
 - 18s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 241/300
 - 18s - loss: 0.0030 - val_loss: 0.0022
2019-12-24 16:54:50,551 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9949
Epoch 242/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9940
Epoch 243/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 244/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 245/300
 - 18s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 246/300
 - 18s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9947
Epoch 247/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 248/300
 - 18s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 249/300
 - 18s - loss: 0.0030 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 250/300
 - 17s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 251/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9944
Epoch 252/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 253/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 254/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 255/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9939
Epoch 256/300
 - 17s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 257/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9939
Epoch 258/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 259/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 260/300
 - 17s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 261/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 262/300
 - 17s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 263/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 264/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9943
Epoch 265/300
 - 17s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 266/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 267/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 268/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 269/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 270/300
 - 18s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 271/300
 - 18s - loss: 0.0031 - val_loss: 0.0021
2019-12-24 17:10:07,093 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9955
Epoch 272/300
 - 18s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 273/300
 - 17s - loss: 0.0034 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 274/300
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 275/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 276/300
 - 18s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 277/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 278/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 279/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 280/300
 - 17s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9942
Epoch 281/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 282/300
 - 17s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 283/300
 - 18s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 284/300
 - 17s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 285/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 286/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9949
Epoch 287/300
 - 18s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 288/300
 - 18s - loss: 0.0031 - val_loss: 0.0022
 - val_f1: 0.9945
Epoch 289/300
 - 17s - loss: 0.0032 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 290/300
 - 17s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 291/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 292/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9943
Epoch 293/300
 - 17s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 294/300
 - 17s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9943
Epoch 295/300
 - 17s - loss: 0.0030 - val_loss: 0.0021
 - val_f1: 0.9950
Epoch 296/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 297/300
 - 18s - loss: 0.0033 - val_loss: 0.0022
 - val_f1: 0.9946
Epoch 298/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9939
Epoch 299/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9937
Epoch 300/300
 - 18s - loss: 0.0033 - val_loss: 0.0027
2019-12-24 17:25:05,337 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 17:25:39,356 [INFO] Last epoch loss evaluation: train_loss = 0.002065, val_loss = 0.002138
2019-12-24 17:25:39,394 [INFO] Training complete. time_to_train = 11057.96 sec, 184.30 min
2019-12-24 17:25:39,401 [INFO] Model saved to results_selected_models/selected_ids17_dbn_deep_rep2/best_model.pickle
2019-12-24 17:25:39,404 [INFO] Training history saved to: results_selected_models/selected_ids17_dbn_deep_rep2/training_error_history.csv
2019-12-24 17:25:39,539 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep2/training_error_history.png
2019-12-24 17:25:39,667 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep2/training_f1_history.png
2019-12-24 17:25:39,667 [INFO] Making predictions on training, validation, testing data
2019-12-24 17:26:42,751 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 17:26:53,169 [INFO] Dataset: Testing. Classification report below
2019-12-24 17:26:53,169 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2058
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.99      0.98      0.99      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.82      0.09      0.17       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 17:26:53,169 [INFO] Overall accuracy (micro avg): 0.9956450398011182
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-24 17:27:04,985 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8800                       0.7825                0.0009                   0.2175  0.7960
2  Weighted avg        0.9964         0.9954                       0.9956                0.0064                   0.0044  0.9953
2019-12-24 17:27:15,437 [INFO] Dataset: Validation. Classification report below
2019-12-24 17:27:15,437 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.96      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.98      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1180
Web Attack Brute Force       0.77      0.07      0.12       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.87      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 17:27:15,437 [INFO] Overall accuracy (micro avg): 0.9956291264264572
2019-12-24 17:27:27,352 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8745                       0.7763                0.0009                   0.2237  0.7887
2  Weighted avg        0.9964         0.9953                       0.9956                0.0064                   0.0044  0.9952
2019-12-24 17:28:01,756 [INFO] Dataset: Training. Classification report below
2019-12-24 17:28:01,756 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.83      0.08      0.15       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.79   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-24 17:28:01,756 [INFO] Overall accuracy (micro avg): 0.9958077049114626
2019-12-24 17:28:40,825 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.8829                       0.7807                0.0009                   0.2193  0.7947
2  Weighted avg        0.9965         0.9955                       0.9958                0.0063                   0.0042  0.9954
2019-12-24 17:28:40,849 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_deep_rep2/selected_ids17_dbn_deep_rep2_results.xlsx
2019-12-24 17:28:40,857 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 17:28:40,925 [INFO] Created directory: results_selected_models/selected_ids17_dbn_deep_rep3
2019-12-24 17:28:40,925 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_deep_rep3/run_log.log
2019-12-24 17:28:40,925 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 17:28:40,925 [INFO] Experiment parameters given below
2019-12-24 17:28:40,925 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_deep_rep3'}
2019-12-24 17:28:40,925 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_deep_rep3/tf_logs_run_2019_12_24-17_28_40
2019-12-24 17:28:40,925 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 17:28:40,926 [INFO] Reading X, y files
2019-12-24 17:28:40,926 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 17:28:46,309 [INFO] Reading complete. time_to_read=5.38 seconds
2019-12-24 17:28:46,309 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 17:28:47,739 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-24 17:28:47,739 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 17:28:49,169 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-24 17:28:49,169 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 17:28:49,395 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-24 17:28:49,395 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 17:28:49,469 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 17:28:49,469 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 17:28:49,543 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 17:28:53,001 [INFO] Initializing model
2019-12-24 17:28:53,001 [INFO] Training model
2019-12-24 17:28:53,001 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 17:29:12,570 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = a7d23749ad325e93e633726cf91d7fab53f80692
2019-12-24 17:29:12,570 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9941
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.74, time = 9.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.33, time = 19.76s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.47, time = 18.81s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.74, time = 18.63s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.47, time = 18.57s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.21, time = 18.51s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -60.12, time = 18.43s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -64.19, time = 18.38s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -68.34, time = 18.35s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -72.54, time = 18.32s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -76.79, time = 18.29s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -81.07, time = 18.26s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -85.37, time = 18.24s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -89.69, time = 18.23s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -94.04, time = 18.20s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -98.41, time = 18.18s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -102.80, time = 18.16s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -107.21, time = 18.14s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -111.65, time = 18.13s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -116.09, time = 18.14s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -120.54, time = 18.13s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -125.02, time = 18.11s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -129.52, time = 17.86s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -134.00, time = 17.71s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -138.51, time = 17.47s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -143.00, time = 17.22s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -147.52, time = 17.10s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -152.04, time = 16.97s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -156.56, time = 16.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -161.09, time = 16.87s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -165.60, time = 16.83s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -170.12, time = 16.80s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -174.64, time = 16.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -179.16, time = 16.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -183.69, time = 16.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -188.22, time = 16.72s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -192.74, time = 16.71s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -197.26, time = 16.70s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -201.78, time = 16.69s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -206.30, time = 16.76s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -210.83, time = 16.70s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -215.36, time = 16.69s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -219.88, time = 16.69s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -224.42, time = 16.69s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -228.94, time = 16.69s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -233.48, time = 16.71s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -238.01, time = 16.68s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -242.54, time = 16.66s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -247.07, time = 16.69s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -251.61, time = 16.65s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -58.08, time = 7.59s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.66, time = 12.36s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.34, time = 12.34s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -57.02, time = 12.33s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.69, time = 12.32s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.36, time = 12.32s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -56.02, time = 12.33s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.67, time = 12.33s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -55.31, time = 12.32s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.96, time = 12.32s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.60, time = 12.33s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.21, time = 12.32s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.84, time = 12.32s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -53.45, time = 12.33s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -53.05, time = 12.34s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.66, time = 12.34s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.26, time = 12.35s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -51.85, time = 12.34s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.43, time = 12.35s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -50.99, time = 12.36s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -50.57, time = 12.39s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -50.14, time = 12.39s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -49.70, time = 12.40s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -49.25, time = 12.38s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -48.80, time = 12.37s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -48.34, time = 12.35s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.88, time = 12.35s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -47.42, time = 12.36s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -46.95, time = 12.36s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -46.49, time = 12.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -46.01, time = 12.37s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -45.53, time = 12.36s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -45.05, time = 12.27s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -44.56, time = 12.19s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.08, time = 12.18s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.60, time = 12.18s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.12, time = 12.17s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.62, time = 12.17s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.13, time = 12.16s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.64, time = 12.16s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.16, time = 12.16s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -40.67, time = 12.16s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -40.18, time = 12.15s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -39.69, time = 12.18s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.22, time = 12.17s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -38.73, time = 12.16s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -38.27, time = 12.15s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -37.78, time = 12.17s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -37.30, time = 12.16s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -36.84, time = 12.17s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.37, time = 4.08s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.41, time = 6.66s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.31, time = 6.65s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.26, time = 6.66s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.22, time = 6.65s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.17, time = 6.65s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.12, time = 6.65s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.07, time = 6.64s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -29.02, time = 6.64s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.98, time = 6.64s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.93, time = 6.64s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -28.88, time = 6.64s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -28.83, time = 6.64s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -28.77, time = 6.64s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -28.72, time = 6.64s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -28.67, time = 6.64s2019-12-24 17:59:37,767 [INFO] Pretraining Complete
2019-12-24 17:59:37,791 [INFO] Getting pretrained weights
2019-12-24 17:59:37,792 [INFO] Creating and initializing feed forward neural network
2019-12-24 17:59:38,078 [INFO] _________________________________________________________________
2019-12-24 17:59:38,078 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 17:59:38,078 [INFO] =================================================================
2019-12-24 17:59:38,078 [INFO] dense_29 (Dense)             (None, 128)               10112     
2019-12-24 17:59:38,078 [INFO] _________________________________________________________________
2019-12-24 17:59:38,078 [INFO] batch_normalization_22 (Batc (None, 128)               512       
2019-12-24 17:59:38,078 [INFO] _________________________________________________________________
2019-12-24 17:59:38,078 [INFO] dropout_22 (Dropout)         (None, 128)               0         
2019-12-24 17:59:38,078 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] dense_30 (Dense)             (None, 64)                8256      
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] batch_normalization_23 (Batc (None, 64)                256       
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] dropout_23 (Dropout)         (None, 64)                0         
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] dense_31 (Dense)             (None, 34)                2210      
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] batch_normalization_24 (Batc (None, 34)                136       
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] dropout_24 (Dropout)         (None, 34)                0         
2019-12-24 17:59:38,079 [INFO] _________________________________________________________________
2019-12-24 17:59:38,079 [INFO] dense_32 (Dense)             (None, 12)                420       
2019-12-24 17:59:38,079 [INFO] =================================================================
2019-12-24 17:59:38,079 [INFO] Total params: 21,902
2019-12-24 17:59:38,080 [INFO] Trainable params: 21,450
2019-12-24 17:59:38,080 [INFO] Non-trainable params: 452
2019-12-24 17:59:38,080 [INFO] _________________________________________________________________
2019-12-24 17:59:40,409 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -28.62, time = 6.65s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -28.56, time = 6.64s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -28.51, time = 6.65s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -28.45, time = 6.65s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -28.39, time = 6.64s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.34, time = 6.65s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.27, time = 6.64s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.21, time = 6.64s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.15, time = 6.64s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -28.09, time = 6.64s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -28.03, time = 6.64s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -27.96, time = 6.64s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -27.90, time = 6.64s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -27.83, time = 6.65s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -27.76, time = 6.64s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -27.69, time = 6.64s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -27.63, time = 6.65s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -27.56, time = 6.64s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.49, time = 6.64s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -27.41, time = 6.65s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -27.34, time = 6.64s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -27.27, time = 6.65s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -27.19, time = 6.64s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.12, time = 6.65s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.04, time = 6.64s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.96, time = 6.64s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.88, time = 6.64s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.80, time = 6.65s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.72, time = 6.64s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.64, time = 6.64s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.55, time = 6.64s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.46, time = 6.64s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.37, time = 6.64s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.29, time = 6.64s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 18s - loss: 0.0984 - val_loss: 0.0631
 - val_f1: 0.7620
Epoch 2/300
 - 18s - loss: 0.0604 - val_loss: 0.0489
 - val_f1: 0.8404
Epoch 3/300
 - 18s - loss: 0.0524 - val_loss: 0.0460
 - val_f1: 0.8456
Epoch 4/300
 - 18s - loss: 0.0503 - val_loss: 0.0443
 - val_f1: 0.8464
Epoch 5/300
 - 18s - loss: 0.0485 - val_loss: 0.0421
 - val_f1: 0.8574
Epoch 6/300
 - 18s - loss: 0.0397 - val_loss: 0.0257
 - val_f1: 0.9401
Epoch 7/300
 - 18s - loss: 0.0317 - val_loss: 0.0228
 - val_f1: 0.9448
Epoch 8/300
 - 18s - loss: 0.0291 - val_loss: 0.0216
 - val_f1: 0.9466
Epoch 9/300
 - 18s - loss: 0.0272 - val_loss: 0.0193
 - val_f1: 0.9499
Epoch 10/300
 - 18s - loss: 0.0256 - val_loss: 0.0180
 - val_f1: 0.9513
Epoch 11/300
 - 18s - loss: 0.0242 - val_loss: 0.0170
 - val_f1: 0.9532
Epoch 12/300
 - 18s - loss: 0.0228 - val_loss: 0.0161
 - val_f1: 0.9559
Epoch 13/300
 - 18s - loss: 0.0218 - val_loss: 0.0154
 - val_f1: 0.9578
Epoch 14/300
 - 18s - loss: 0.0209 - val_loss: 0.0142
 - val_f1: 0.9620
Epoch 15/300
 - 18s - loss: 0.0196 - val_loss: 0.0130
 - val_f1: 0.9654
Epoch 16/300
 - 18s - loss: 0.0188 - val_loss: 0.0125
 - val_f1: 0.9660
Epoch 17/300
 - 18s - loss: 0.0183 - val_loss: 0.0120
 - val_f1: 0.9680
Epoch 18/300
 - 18s - loss: 0.0178 - val_loss: 0.0117
 - val_f1: 0.9673
Epoch 19/300
 - 18s - loss: 0.0172 - val_loss: 0.0110
 - val_f1: 0.9713
Epoch 20/300
 - 18s - loss: 0.0163 - val_loss: 0.0105
 - val_f1: 0.9712
Epoch 21/300
 - 18s - loss: 0.0149 - val_loss: 0.0096
 - val_f1: 0.9753
Epoch 22/300
 - 18s - loss: 0.0141 - val_loss: 0.0092
 - val_f1: 0.9763
Epoch 23/300
 - 18s - loss: 0.0135 - val_loss: 0.0086
 - val_f1: 0.9793
Epoch 24/300
 - 18s - loss: 0.0131 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 25/300
 - 18s - loss: 0.0125 - val_loss: 0.0075
 - val_f1: 0.9812
Epoch 26/300
 - 18s - loss: 0.0119 - val_loss: 0.0066
 - val_f1: 0.9846
Epoch 27/300
 - 18s - loss: 0.0114 - val_loss: 0.0065
 - val_f1: 0.9853
Epoch 28/300
 - 18s - loss: 0.0110 - val_loss: 0.0064
 - val_f1: 0.9886
Epoch 29/300
 - 18s - loss: 0.0104 - val_loss: 0.0058
 - val_f1: 0.9856
Epoch 30/300
 - 18s - loss: 0.0100 - val_loss: 0.0055
 - val_f1: 0.9877
Epoch 31/300
 - 18s - loss: 0.0095 - val_loss: 0.0057
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 18:15:54,025 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9885
Epoch 32/300
 - 18s - loss: 0.0090 - val_loss: 0.0055
 - val_f1: 0.9905
Epoch 33/300
 - 18s - loss: 0.0087 - val_loss: 0.0052
 - val_f1: 0.9888
Epoch 34/300
 - 18s - loss: 0.0085 - val_loss: 0.0051
 - val_f1: 0.9894
Epoch 35/300
 - 18s - loss: 0.0082 - val_loss: 0.0050
 - val_f1: 0.9890
Epoch 36/300
 - 18s - loss: 0.0080 - val_loss: 0.0049
 - val_f1: 0.9916
Epoch 37/300
 - 18s - loss: 0.0079 - val_loss: 0.0051
 - val_f1: 0.9903
Epoch 38/300
 - 18s - loss: 0.0076 - val_loss: 0.0051
 - val_f1: 0.9895
Epoch 39/300
 - 18s - loss: 0.0074 - val_loss: 0.0048
 - val_f1: 0.9873
Epoch 40/300
 - 18s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9916
Epoch 41/300
 - 18s - loss: 0.0071 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 42/300
 - 18s - loss: 0.0070 - val_loss: 0.0043
 - val_f1: 0.9919
Epoch 43/300
 - 18s - loss: 0.0068 - val_loss: 0.0042
 - val_f1: 0.9919
Epoch 44/300
 - 18s - loss: 0.0067 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 45/300
 - 18s - loss: 0.0065 - val_loss: 0.0043
 - val_f1: 0.9895
Epoch 46/300
 - 18s - loss: 0.0064 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 47/300
 - 18s - loss: 0.0063 - val_loss: 0.0039
 - val_f1: 0.9916
Epoch 48/300
 - 18s - loss: 0.0061 - val_loss: 0.0040
 - val_f1: 0.9903
Epoch 49/300
 - 18s - loss: 0.0060 - val_loss: 0.0037
 - val_f1: 0.9907
Epoch 50/300
 - 18s - loss: 0.0059 - val_loss: 0.0038
 - val_f1: 0.9908
Epoch 51/300
 - 18s - loss: 0.0058 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 52/300
 - 18s - loss: 0.0057 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 53/300
 - 18s - loss: 0.0056 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 54/300
 - 18s - loss: 0.0054 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 55/300
 - 18s - loss: 0.0054 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 56/300
 - 18s - loss: 0.0053 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 57/300
 - 18s - loss: 0.0051 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 58/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 59/300
 - 18s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 60/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 61/300
 - 18s - loss: 0.0048 - val_loss: 0.0031
2019-12-24 18:31:41,956 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9937
Epoch 62/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 63/300
 - 18s - loss: 0.0047 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 64/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 65/300
 - 18s - loss: 0.0047 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 66/300
 - 18s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 67/300
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 68/300
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 69/300
 - 18s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 70/300
 - 18s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 71/300
 - 18s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 72/300
 - 18s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 73/300
 - 18s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 74/300
 - 18s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 75/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 76/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 77/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 78/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 79/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 80/300
 - 18s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 81/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 82/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 83/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 84/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 85/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 86/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 87/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 88/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 89/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 90/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 91/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
2019-12-24 18:47:30,026 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9937
Epoch 92/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 93/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 94/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 95/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 96/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 97/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 98/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 99/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 100/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 101/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 102/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 103/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 104/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 105/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 106/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 107/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 108/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 109/300
 - 18s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 110/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 111/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 112/300
 - 18s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 113/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 114/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 115/300
 - 18s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 116/300
 - 18s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 117/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 118/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 119/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 120/300
 - 18s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 121/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
2019-12-24 19:03:18,541 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9944
Epoch 122/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 123/300
 - 18s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 124/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 125/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 126/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 127/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 128/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 129/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 130/300
 - 18s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 131/300
 - 18s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 132/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 133/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 134/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 135/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 136/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 137/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 138/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 139/300
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 140/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 141/300
 - 18s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 142/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 143/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 144/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 145/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 146/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 147/300
 - 18s - loss: 0.0034 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 148/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 149/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 150/300
 - 18s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 151/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
2019-12-24 19:19:06,674 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9947
Epoch 152/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 153/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 154/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 155/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 156/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 157/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 158/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 159/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 160/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 161/300
 - 18s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9919
Epoch 162/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 163/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 164/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 165/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 166/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 167/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 168/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 169/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 170/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 171/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 172/300
 - 18s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 173/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 174/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 175/300
 - 18s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 176/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 177/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 178/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 179/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 180/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 181/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
2019-12-24 19:34:53,508 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9949
Epoch 182/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 183/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 184/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 185/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 186/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 187/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 188/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 189/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 190/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 191/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 192/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 193/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 194/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 195/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 196/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 197/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 198/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 199/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 200/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 201/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 202/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 203/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 204/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 205/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 206/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 207/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 208/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 209/300
 - 18s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 210/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 211/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
2019-12-24 19:50:42,108 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9947
Epoch 212/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 213/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 214/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 215/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 216/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 217/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 218/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 219/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 220/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 221/300
 - 18s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 222/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9926
Epoch 223/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 224/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 225/300
 - 18s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 226/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 227/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 228/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 229/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 230/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 231/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 232/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 233/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 234/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 235/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 236/300
 - 18s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 237/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 238/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 239/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 240/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 241/300
 - 18s - loss: 0.0031 - val_loss: 0.0031
2019-12-24 20:06:30,677 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9930
Epoch 242/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 243/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 244/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 245/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 246/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 247/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 248/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 249/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 250/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 251/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 252/300
 - 18s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 253/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 254/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 255/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 256/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9929
Epoch 257/300
 - 18s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 258/300
 - 18s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 259/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 260/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 261/300
 - 18s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 262/300
 - 18s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 263/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 264/300
 - 18s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 265/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 266/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 267/300
 - 18s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 268/300
 - 18s - loss: 0.0030 - val_loss: 0.0023
2019-12-24 20:20:58,584 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 20:21:33,996 [INFO] Last epoch loss evaluation: train_loss = 0.002174, val_loss = 0.002284
2019-12-24 20:21:34,036 [INFO] Training complete. time_to_train = 10361.03 sec, 172.68 min
2019-12-24 20:21:34,043 [INFO] Model saved to results_selected_models/selected_ids17_dbn_deep_rep3/best_model.pickle
2019-12-24 20:21:34,046 [INFO] Training history saved to: results_selected_models/selected_ids17_dbn_deep_rep3/training_error_history.csv
2019-12-24 20:21:34,229 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep3/training_error_history.png
2019-12-24 20:21:34,355 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep3/training_f1_history.png
2019-12-24 20:21:34,355 [INFO] Making predictions on training, validation, testing data
2019-12-24 20:22:41,390 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 20:22:51,741 [INFO] Dataset: Testing. Classification report below
2019-12-24 20:22:51,741 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.97      0.98      0.98      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       1.00      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 20:22:51,741 [INFO] Overall accuracy (micro avg): 0.9955301098730113
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-24 20:23:03,488 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9993         0.8932                       0.7792                0.0010                   0.2208  0.7905
2  Weighted avg        0.9963         0.9953                       0.9955                0.0079                   0.0045  0.9951
2019-12-24 20:23:13,935 [INFO] Dataset: Validation. Classification report below
2019-12-24 20:23:13,935 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.96      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.97      0.97      0.97      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.97      0.95      1180
Web Attack Brute Force       0.86      0.04      0.08       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.77      0.78    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 20:23:13,935 [INFO] Overall accuracy (micro avg): 0.9955672410805535
2019-12-24 20:23:25,825 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8801                       0.7723                0.0010                   0.2277  0.7829
2  Weighted avg        0.9964         0.9953                       0.9956                0.0077                   0.0044  0.9951
2019-12-24 20:24:00,429 [INFO] Dataset: Training. Classification report below
2019-12-24 20:24:00,429 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.99      0.98      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.95      0.98      0.97      3538
Web Attack Brute Force       0.80      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.79   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-24 20:24:00,429 [INFO] Overall accuracy (micro avg): 0.9957216547100108
2019-12-24 20:24:39,715 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8799                       0.7769                0.0010                   0.2231  0.7888
2  Weighted avg        0.9965         0.9954                       0.9957                0.0077                   0.0043  0.9953
2019-12-24 20:24:39,743 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_deep_rep3/selected_ids17_dbn_deep_rep3_results.xlsx
2019-12-24 20:24:39,747 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 20:24:39,817 [INFO] Created directory: results_selected_models/selected_ids17_dbn_deep_rep4
2019-12-24 20:24:39,818 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_deep_rep4/run_log.log
2019-12-24 20:24:39,818 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 20:24:39,818 [INFO] Experiment parameters given below
2019-12-24 20:24:39,818 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_deep_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 35], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.5], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_deep_rep4'}
2019-12-24 20:24:39,818 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_deep_rep4/tf_logs_run_2019_12_24-20_24_39
2019-12-24 20:24:39,818 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 20:24:39,818 [INFO] Reading X, y files
2019-12-24 20:24:39,818 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 20:24:44,933 [INFO] Reading complete. time_to_read=5.11 seconds
2019-12-24 20:24:44,933 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 20:24:46,455 [INFO] Reading complete. time_to_read=1.52 seconds
2019-12-24 20:24:46,455 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 20:24:47,873 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-24 20:24:47,873 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 20:24:48,091 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-24 20:24:48,091 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 20:24:48,166 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 20:24:48,166 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 20:24:48,240 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 20:24:51,684 [INFO] Initializing model
2019-12-24 20:24:51,685 [INFO] Training model
2019-12-24 20:24:51,685 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 20:25:10,567 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 16998b3fd982593546899fc131652dd0ac712ce1
2019-12-24 20:25:10,567 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9948
Epoch 00268: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.45, time = 9.72s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.08, time = 19.75s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.27, time = 18.82s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -48.55, time = 18.63s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.27, time = 18.58s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -55.99, time = 18.51s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -59.88, time = 18.43s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -63.92, time = 18.39s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -68.03, time = 18.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -72.20, time = 18.33s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -76.41, time = 18.30s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -80.66, time = 18.27s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -84.93, time = 18.25s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -89.22, time = 18.22s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -93.54, time = 18.20s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -97.87, time = 18.18s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -102.22, time = 18.17s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -106.60, time = 18.16s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -110.99, time = 18.13s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -115.39, time = 18.14s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -119.78, time = 18.14s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -124.22, time = 18.12s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -128.66, time = 17.86s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -133.09, time = 17.72s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -137.54, time = 17.48s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -141.99, time = 17.24s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -146.44, time = 17.11s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -150.91, time = 16.98s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -155.38, time = 16.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -159.86, time = 16.87s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -164.32, time = 16.83s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -168.80, time = 16.80s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -173.27, time = 16.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -177.74, time = 16.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -182.23, time = 16.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -186.71, time = 16.72s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -191.20, time = 16.71s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -195.67, time = 16.70s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -200.16, time = 16.69s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -204.64, time = 16.75s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -209.14, time = 16.69s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -213.63, time = 16.70s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -218.11, time = 16.69s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -222.61, time = 16.69s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -227.09, time = 16.69s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -231.60, time = 16.72s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -236.10, time = 16.67s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -240.59, time = 16.66s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -245.09, time = 16.66s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -249.59, time = 16.67s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -58.01, time = 7.57s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.59, time = 12.34s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.27, time = 12.33s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.95, time = 12.31s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.62, time = 12.30s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.29, time = 12.64s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.95, time = 12.32s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.60, time = 12.31s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -55.24, time = 12.31s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.88, time = 12.30s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.52, time = 12.30s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.14, time = 12.31s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.77, time = 12.30s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -53.38, time = 12.31s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -52.98, time = 12.32s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.59, time = 12.34s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.19, time = 12.35s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -51.77, time = 12.37s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.36, time = 12.38s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -50.91, time = 12.38s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -50.50, time = 12.36s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -50.07, time = 12.35s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -49.63, time = 12.34s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -49.18, time = 12.33s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -48.72, time = 12.33s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -48.26, time = 12.35s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.81, time = 12.35s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -47.34, time = 12.35s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -46.88, time = 12.35s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -46.41, time = 12.35s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -45.93, time = 12.36s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -45.45, time = 12.33s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -44.97, time = 12.22s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -44.48, time = 12.15s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.00, time = 12.15s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.53, time = 12.14s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.04, time = 12.14s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.54, time = 12.14s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.06, time = 12.14s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.56, time = 12.14s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.08, time = 12.14s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -40.59, time = 12.14s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -40.10, time = 12.14s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -39.61, time = 12.15s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.14, time = 12.14s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -38.66, time = 12.14s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -38.19, time = 12.14s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -37.70, time = 12.15s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -37.23, time = 12.14s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -36.77, time = 12.14s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.26, time = 4.13s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.33, time = 6.77s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.24, time = 6.78s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.19, time = 6.79s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.15, time = 6.78s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.10, time = 6.78s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.05, time = 6.78s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -29.00, time = 6.77s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -28.95, time = 6.77s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.91, time = 6.77s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.86, time = 6.77s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -28.81, time = 6.77s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -28.76, time = 6.77s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -28.70, time = 6.77s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -28.65, time = 6.78s2019-12-24 20:55:41,663 [INFO] Pretraining Complete
2019-12-24 20:55:41,663 [INFO] Getting pretrained weights
2019-12-24 20:55:41,663 [INFO] Creating and initializing feed forward neural network
2019-12-24 20:55:41,940 [INFO] _________________________________________________________________
2019-12-24 20:55:41,940 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 20:55:41,940 [INFO] =================================================================
2019-12-24 20:55:41,940 [INFO] dense_33 (Dense)             (None, 128)               10112     
2019-12-24 20:55:41,940 [INFO] _________________________________________________________________
2019-12-24 20:55:41,940 [INFO] batch_normalization_25 (Batc (None, 128)               512       
2019-12-24 20:55:41,940 [INFO] _________________________________________________________________
2019-12-24 20:55:41,940 [INFO] dropout_25 (Dropout)         (None, 128)               0         
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] dense_34 (Dense)             (None, 64)                8256      
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] dense_35 (Dense)             (None, 35)                2275      
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] batch_normalization_27 (Batc (None, 35)                140       
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] dropout_27 (Dropout)         (None, 35)                0         
2019-12-24 20:55:41,941 [INFO] _________________________________________________________________
2019-12-24 20:55:41,941 [INFO] dense_36 (Dense)             (None, 12)                432       
2019-12-24 20:55:41,941 [INFO] =================================================================
2019-12-24 20:55:41,942 [INFO] Total params: 21,983
2019-12-24 20:55:41,942 [INFO] Trainable params: 21,529
2019-12-24 20:55:41,942 [INFO] Non-trainable params: 454
2019-12-24 20:55:41,942 [INFO] _________________________________________________________________
2019-12-24 20:55:44,606 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 16, pseudo-likelihood = -28.59, time = 6.77s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -28.54, time = 6.77s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -28.49, time = 6.77s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -28.43, time = 6.78s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -28.38, time = 6.77s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -28.32, time = 6.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.26, time = 6.78s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.20, time = 6.77s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.14, time = 6.77s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.08, time = 6.77s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -28.02, time = 6.77s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -27.96, time = 6.77s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -27.89, time = 6.77s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -27.82, time = 6.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -27.76, time = 6.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -27.69, time = 6.77s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -27.63, time = 6.77s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -27.56, time = 6.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -27.49, time = 6.77s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.42, time = 6.77s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -27.34, time = 6.77s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -27.27, time = 6.77s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -27.19, time = 6.77s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -27.12, time = 6.77s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.04, time = 6.77s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -26.97, time = 6.76s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.89, time = 6.76s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.81, time = 6.76s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.73, time = 6.77s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.65, time = 6.77s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.56, time = 6.77s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.48, time = 6.77s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.39, time = 6.77s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.31, time = 6.77s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.22, time = 6.78s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 19s - loss: 0.1172 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 2/300
 - 18s - loss: 0.1075 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 3/300
 - 18s - loss: 0.1069 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 4/300
 - 18s - loss: 0.1068 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 5/300
 - 18s - loss: 0.1067 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 6/300
 - 18s - loss: 0.1067 - val_loss: 0.1065
 - val_f1: 0.7155
Epoch 7/300
 - 18s - loss: 0.1067 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 8/300
 - 18s - loss: 0.1066 - val_loss: 0.1065
 - val_f1: 0.7155
Epoch 9/300
 - 18s - loss: 0.1066 - val_loss: 0.1065
 - val_f1: 0.7155
Epoch 10/300
 - 18s - loss: 0.1066 - val_loss: 0.1065
 - val_f1: 0.7155
Epoch 11/300
 - 18s - loss: 0.1066 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 12/300
 - 18s - loss: 0.0953 - val_loss: 0.0701
 - val_f1: 0.7467
Epoch 13/300
 - 18s - loss: 0.0690 - val_loss: 0.0538
 - val_f1: 0.8265
Epoch 14/300
 - 18s - loss: 0.0607 - val_loss: 0.0502
 - val_f1: 0.8358
Epoch 15/300
 - 18s - loss: 0.0576 - val_loss: 0.0484
 - val_f1: 0.8406
Epoch 16/300
 - 18s - loss: 0.0552 - val_loss: 0.0474
 - val_f1: 0.8413
Epoch 17/300
 - 18s - loss: 0.0537 - val_loss: 0.0459
 - val_f1: 0.8438
Epoch 18/300
 - 18s - loss: 0.0521 - val_loss: 0.0432
 - val_f1: 0.8449
Epoch 19/300
 - 18s - loss: 0.0427 - val_loss: 0.0266
 - val_f1: 0.9422
Epoch 20/300
 - 18s - loss: 0.0351 - val_loss: 0.0251
 - val_f1: 0.9430
Epoch 21/300
 - 18s - loss: 0.0326 - val_loss: 0.0227
 - val_f1: 0.9473
Epoch 22/300
 - 18s - loss: 0.0304 - val_loss: 0.0245
 - val_f1: 0.9407
Epoch 23/300
 - 18s - loss: 0.0284 - val_loss: 0.0202
 - val_f1: 0.9523
Epoch 24/300
 - 18s - loss: 0.0263 - val_loss: 0.0176
 - val_f1: 0.9574
Epoch 25/300
 - 18s - loss: 0.0233 - val_loss: 0.0146
 - val_f1: 0.9710
Epoch 26/300
 - 18s - loss: 0.0211 - val_loss: 0.0119
 - val_f1: 0.9687
Epoch 27/300
 - 18s - loss: 0.0195 - val_loss: 0.0110
 - val_f1: 0.9716
Epoch 28/300
 - 18s - loss: 0.0185 - val_loss: 0.0112
 - val_f1: 0.9714
Epoch 29/300
 - 18s - loss: 0.0173 - val_loss: 0.0100
 - val_f1: 0.9747
Epoch 30/300
 - 18s - loss: 0.0167 - val_loss: 0.0096
 - val_f1: 0.9772
Epoch 31/300
 - 18s - loss: 0.0158 - val_loss: 0.0086
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 21:12:34,023 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9777
Epoch 32/300
 - 18s - loss: 0.0148 - val_loss: 0.0085
 - val_f1: 0.9779
Epoch 33/300
 - 18s - loss: 0.0142 - val_loss: 0.0083
 - val_f1: 0.9797
Epoch 34/300
 - 18s - loss: 0.0136 - val_loss: 0.0082
 - val_f1: 0.9790
Epoch 35/300
 - 18s - loss: 0.0133 - val_loss: 0.0078
 - val_f1: 0.9820
Epoch 36/300
 - 18s - loss: 0.0127 - val_loss: 0.0073
 - val_f1: 0.9823
Epoch 37/300
 - 18s - loss: 0.0123 - val_loss: 0.0073
 - val_f1: 0.9826
Epoch 38/300
 - 18s - loss: 0.0120 - val_loss: 0.0069
 - val_f1: 0.9827
Epoch 39/300
 - 18s - loss: 0.0117 - val_loss: 0.0071
 - val_f1: 0.9831
Epoch 40/300
 - 18s - loss: 0.0114 - val_loss: 0.0068
 - val_f1: 0.9830
Epoch 41/300
 - 18s - loss: 0.0112 - val_loss: 0.0067
 - val_f1: 0.9834
Epoch 42/300
 - 18s - loss: 0.0109 - val_loss: 0.0064
 - val_f1: 0.9839
Epoch 43/300
 - 18s - loss: 0.0108 - val_loss: 0.0066
 - val_f1: 0.9838
Epoch 44/300
 - 18s - loss: 0.0106 - val_loss: 0.0062
 - val_f1: 0.9840
Epoch 45/300
 - 18s - loss: 0.0104 - val_loss: 0.0062
 - val_f1: 0.9839
Epoch 46/300
 - 18s - loss: 0.0102 - val_loss: 0.0061
 - val_f1: 0.9839
Epoch 47/300
 - 18s - loss: 0.0099 - val_loss: 0.0061
 - val_f1: 0.9839
Epoch 48/300
 - 18s - loss: 0.0099 - val_loss: 0.0059
 - val_f1: 0.9848
Epoch 49/300
 - 18s - loss: 0.0098 - val_loss: 0.0059
 - val_f1: 0.9871
Epoch 50/300
 - 18s - loss: 0.0095 - val_loss: 0.0063
 - val_f1: 0.9838
Epoch 51/300
 - 18s - loss: 0.0094 - val_loss: 0.0058
 - val_f1: 0.9855
Epoch 52/300
 - 18s - loss: 0.0094 - val_loss: 0.0057
 - val_f1: 0.9862
Epoch 53/300
 - 18s - loss: 0.0092 - val_loss: 0.0057
 - val_f1: 0.9878
Epoch 54/300
 - 18s - loss: 0.0090 - val_loss: 0.0057
 - val_f1: 0.9855
Epoch 55/300
 - 18s - loss: 0.0090 - val_loss: 0.0054
 - val_f1: 0.9876
Epoch 56/300
 - 18s - loss: 0.0088 - val_loss: 0.0067
 - val_f1: 0.9862
Epoch 57/300
 - 18s - loss: 0.0087 - val_loss: 0.0055
 - val_f1: 0.9854
Epoch 58/300
 - 18s - loss: 0.0087 - val_loss: 0.0054
 - val_f1: 0.9873
Epoch 59/300
 - 18s - loss: 0.0086 - val_loss: 0.0054
 - val_f1: 0.9855
Epoch 60/300
 - 18s - loss: 0.0084 - val_loss: 0.0054
 - val_f1: 0.9867
Epoch 61/300
 - 18s - loss: 0.0083 - val_loss: 0.0056
2019-12-24 21:29:01,829 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9853
Epoch 62/300
 - 18s - loss: 0.0081 - val_loss: 0.0054
 - val_f1: 0.9898
Epoch 63/300
 - 18s - loss: 0.0079 - val_loss: 0.0050
 - val_f1: 0.9890
Epoch 64/300
 - 18s - loss: 0.0078 - val_loss: 0.0049
 - val_f1: 0.9889
Epoch 65/300
 - 18s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9748
Epoch 66/300
 - 18s - loss: 0.0077 - val_loss: 0.0056
 - val_f1: 0.9882
Epoch 67/300
 - 18s - loss: 0.0076 - val_loss: 0.0047
 - val_f1: 0.9880
Epoch 68/300
 - 18s - loss: 0.0075 - val_loss: 0.0048
 - val_f1: 0.9880
Epoch 69/300
 - 18s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9881
Epoch 70/300
 - 18s - loss: 0.0071 - val_loss: 0.0046
 - val_f1: 0.9880
Epoch 71/300
 - 18s - loss: 0.0070 - val_loss: 0.0046
 - val_f1: 0.9916
Epoch 72/300
 - 18s - loss: 0.0069 - val_loss: 0.0046
 - val_f1: 0.9888
Epoch 73/300
 - 18s - loss: 0.0068 - val_loss: 0.0044
 - val_f1: 0.9885
Epoch 74/300
 - 18s - loss: 0.0068 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 75/300
 - 18s - loss: 0.0066 - val_loss: 0.0052
 - val_f1: 0.9881
Epoch 76/300
 - 18s - loss: 0.0067 - val_loss: 0.0107
 - val_f1: 0.9807
Epoch 77/300
 - 18s - loss: 0.0066 - val_loss: 0.0040
 - val_f1: 0.9906
Epoch 78/300
 - 18s - loss: 0.0065 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 79/300
 - 18s - loss: 0.0063 - val_loss: 0.0038
 - val_f1: 0.9928
Epoch 80/300
 - 18s - loss: 0.0063 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 81/300
 - 18s - loss: 0.0062 - val_loss: 0.0116
 - val_f1: 0.9805
Epoch 82/300
 - 18s - loss: 0.0065 - val_loss: 0.0037
 - val_f1: 0.9928
Epoch 83/300
 - 18s - loss: 0.0063 - val_loss: 0.0037
 - val_f1: 0.9926
Epoch 84/300
 - 18s - loss: 0.0061 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 85/300
 - 18s - loss: 0.0060 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 86/300
 - 18s - loss: 0.0058 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 87/300
 - 18s - loss: 0.0058 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 88/300
 - 18s - loss: 0.0057 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 89/300
 - 18s - loss: 0.0057 - val_loss: 0.0036
 - val_f1: 0.9908
Epoch 90/300
 - 18s - loss: 0.0055 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 91/300
 - 18s - loss: 0.0055 - val_loss: 0.0034
2019-12-24 21:45:30,920 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9926
Epoch 92/300
 - 18s - loss: 0.0054 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 93/300
 - 18s - loss: 0.0055 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 94/300
 - 18s - loss: 0.0056 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 95/300
 - 18s - loss: 0.0054 - val_loss: 0.0032
 - val_f1: 0.9929
Epoch 96/300
 - 18s - loss: 0.0053 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 97/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 98/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 99/300
 - 18s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 100/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 101/300
 - 18s - loss: 0.0049 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 102/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 103/300
 - 18s - loss: 0.0049 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 104/300
 - 18s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9931
Epoch 105/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 106/300
 - 18s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 107/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 108/300
 - 18s - loss: 0.0046 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 109/300
 - 18s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 110/300
 - 18s - loss: 0.0048 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 111/300
 - 18s - loss: 0.0049 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 112/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 113/300
 - 18s - loss: 0.0047 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 114/300
 - 18s - loss: 0.0047 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 115/300
 - 18s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 116/300
 - 18s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9917
Epoch 117/300
 - 18s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 118/300
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 119/300
 - 18s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 120/300
 - 18s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 121/300
 - 18s - loss: 0.0046 - val_loss: 0.0028
2019-12-24 22:02:00,093 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9939
Epoch 122/300
 - 18s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 123/300
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 124/300
 - 18s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 125/300
 - 18s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 126/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 127/300
 - 18s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 128/300
 - 18s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 129/300
 - 18s - loss: 0.0043 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 130/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 131/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 132/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 133/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 134/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 135/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 136/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 137/300
 - 18s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 138/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 139/300
 - 18s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 140/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 141/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 142/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 143/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 144/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 145/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9948
Epoch 146/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 147/300
 - 18s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 148/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 149/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9948
Epoch 150/300
 - 18s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 151/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
2019-12-24 22:18:29,308 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9945
Epoch 152/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 153/300
 - 18s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 154/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 155/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 156/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 157/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 158/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 159/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 160/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 161/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 162/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 163/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 164/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 165/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 166/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 167/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 168/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 169/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 170/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 171/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 172/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 173/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 174/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9947
Epoch 175/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 176/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 177/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 178/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 179/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 180/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 181/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
2019-12-24 22:34:58,134 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9949
Epoch 182/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 183/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 184/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 185/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 186/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 187/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 188/300
 - 18s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 189/300
 - 18s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 190/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 191/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 192/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 193/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 194/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 195/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 196/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 197/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 198/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 199/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 200/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 201/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 202/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 203/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 204/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 205/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 206/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 207/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 208/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 209/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 210/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 211/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
2019-12-24 22:51:27,069 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9945
Epoch 212/300
 - 18s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 213/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 214/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 215/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 216/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 217/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 218/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 219/300
 - 18s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 220/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 221/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 222/300
 - 18s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 223/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 224/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 225/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 226/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 227/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 228/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 229/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 230/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 231/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 232/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 233/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 234/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 235/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 236/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 237/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 238/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 239/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 240/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 241/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
2019-12-24 23:07:57,008 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9946
Epoch 242/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 243/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 244/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 245/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 246/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 247/300
 - 18s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 248/300
 - 18s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 249/300
 - 18s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 250/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 251/300
 - 18s - loss: 0.0035 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 252/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 253/300
 - 18s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 254/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 255/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 256/300
 - 18s - loss: 0.0035 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 257/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 258/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 259/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 260/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 261/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 262/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 263/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 264/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 265/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 266/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 267/300
 - 18s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 268/300
 - 18s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 269/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 270/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 271/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
2019-12-24 23:24:27,010 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9948
Epoch 272/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 273/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 274/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 275/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 276/300
 - 18s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 277/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 278/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 279/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 280/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 281/300
 - 18s - loss: 0.0034 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 282/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 283/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 284/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 285/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 286/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 287/300
 - 18s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 288/300
 - 18s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 289/300
 - 18s - loss: 0.0034 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 290/300
 - 18s - loss: 0.0033 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 291/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 292/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 293/300
 - 18s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9923
Epoch 294/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 295/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 296/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 297/300
 - 18s - loss: 0.0033 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 298/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 299/300
 - 18s - loss: 0.0032 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 300/300
 - 18s - loss: 0.0032 - val_loss: 0.0024
2019-12-24 23:40:37,569 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 23:41:14,036 [INFO] Last epoch loss evaluation: train_loss = 0.002220, val_loss = 0.002279
2019-12-24 23:41:14,077 [INFO] Training complete. time_to_train = 11782.39 sec, 196.37 min
2019-12-24 23:41:14,085 [INFO] Model saved to results_selected_models/selected_ids17_dbn_deep_rep4/best_model.pickle
2019-12-24 23:41:14,088 [INFO] Training history saved to: results_selected_models/selected_ids17_dbn_deep_rep4/training_error_history.csv
2019-12-24 23:41:14,226 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep4/training_error_history.png
2019-12-24 23:41:14,352 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep4/training_f1_history.png
2019-12-24 23:41:14,352 [INFO] Making predictions on training, validation, testing data
2019-12-24 23:42:26,283 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 23:42:36,563 [INFO] Dataset: Testing. Classification report below
2019-12-24 23:42:36,563 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.99      0.99      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       1.00      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 23:42:36,563 [INFO] Overall accuracy (micro avg): 0.9957281429799032
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-24 23:42:48,248 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8966                       0.7785                0.0011                   0.2215  0.7910
2  Weighted avg        0.9965         0.9955                       0.9957                0.0085                   0.0043  0.9953
2019-12-24 23:42:58,689 [INFO] Dataset: Validation. Classification report below
2019-12-24 23:42:58,689 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.33      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.79      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.77      0.78    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 23:42:58,689 [INFO] Overall accuracy (micro avg): 0.9958837404210326
2019-12-24 23:43:10,559 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0004                   0.0041  0.9959
1     Macro avg        0.9993         0.8796                       0.7722                0.0010                   0.2278  0.7837
2  Weighted avg        0.9966         0.9956                       0.9959                0.0083                   0.0041  0.9954
2019-12-24 23:43:45,238 [INFO] Dataset: Training. Classification report below
2019-12-24 23:43:45,238 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.99      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.77      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.79   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-24 23:43:45,238 [INFO] Overall accuracy (micro avg): 0.995987467318605
2019-12-24 23:44:24,621 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.8810                       0.7771                0.0010                   0.2229  0.7899
2  Weighted avg        0.9967         0.9957                       0.9960                0.0082                   0.0040  0.9955
2019-12-24 23:44:24,645 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_deep_rep4/selected_ids17_dbn_deep_rep4_results.xlsx
2019-12-24 23:44:24,649 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-24 23:44:24,719 [INFO] Created directory: results_selected_models/selected_ids17_dbn_deep_rep5
2019-12-24 23:44:24,719 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_deep_rep5/run_log.log
2019-12-24 23:44:24,719 [INFO] ================= Running experiment no. 1  ================= 

2019-12-24 23:44:24,719 [INFO] Experiment parameters given below
2019-12-24 23:44:24,719 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_deep_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 36], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.6], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_deep_rep5'}
2019-12-24 23:44:24,719 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_deep_rep5/tf_logs_run_2019_12_24-23_44_24
2019-12-24 23:44:24,719 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 23:44:24,720 [INFO] Reading X, y files
2019-12-24 23:44:24,720 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 23:44:29,349 [INFO] Reading complete. time_to_read=4.63 seconds
2019-12-24 23:44:29,349 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 23:44:30,783 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-24 23:44:30,783 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 23:44:32,216 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-24 23:44:32,216 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 23:44:32,437 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-24 23:44:32,438 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 23:44:32,511 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 23:44:32,511 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 23:44:32,585 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 23:44:36,016 [INFO] Initializing model
2019-12-24 23:44:36,017 [INFO] Training model
2019-12-24 23:44:36,017 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 23:44:55,652 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 9984a972c8fe7dec16bc7045a7465d0db5f4a93b
2019-12-24 23:44:55,652 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9949
[BernoulliRBM] Iteration 1, pseudo-likelihood = -33.84, time = 9.72s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -39.54, time = 19.76s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -44.78, time = 18.82s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -49.11, time = 18.63s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -52.89, time = 18.58s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.66, time = 18.51s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -60.62, time = 18.43s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -64.73, time = 18.39s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -68.93, time = 18.36s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -73.20, time = 18.33s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -77.51, time = 18.30s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -81.86, time = 18.27s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -86.24, time = 18.24s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -90.63, time = 18.22s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -95.07, time = 18.20s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -99.51, time = 18.18s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -103.97, time = 18.17s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -108.46, time = 18.16s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -112.97, time = 18.14s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -117.49, time = 18.15s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -122.00, time = 18.14s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -126.56, time = 18.12s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -131.12, time = 17.86s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -135.67, time = 17.71s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -140.24, time = 17.47s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -144.80, time = 17.22s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -149.39, time = 17.10s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -153.98, time = 16.98s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -158.57, time = 16.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -163.16, time = 16.87s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -167.74, time = 16.83s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -172.33, time = 16.80s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -176.91, time = 16.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -181.49, time = 16.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -186.09, time = 16.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -190.68, time = 16.73s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -195.27, time = 16.71s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -199.85, time = 16.70s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -204.44, time = 16.69s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -209.03, time = 16.75s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -213.62, time = 16.69s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -218.21, time = 16.70s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -222.80, time = 16.69s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -227.40, time = 16.70s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -231.99, time = 16.69s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -236.59, time = 16.71s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -241.19, time = 16.67s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -245.79, time = 16.66s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -250.39, time = 16.66s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -254.99, time = 16.66s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -57.97, time = 7.59s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -57.55, time = 12.35s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.23, time = 12.35s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -56.91, time = 12.35s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -56.58, time = 12.33s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -56.25, time = 12.33s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -55.91, time = 12.34s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.56, time = 12.33s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -55.21, time = 12.33s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.85, time = 12.33s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.49, time = 12.33s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.11, time = 12.34s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.73, time = 12.33s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -53.35, time = 12.34s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -52.95, time = 12.35s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.56, time = 12.37s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.16, time = 12.40s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -51.74, time = 12.40s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.33, time = 12.42s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -50.89, time = 12.41s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -50.47, time = 12.39s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -50.04, time = 12.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -49.60, time = 12.36s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -49.15, time = 12.35s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -48.69, time = 12.36s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -48.24, time = 12.38s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -47.78, time = 12.38s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -47.32, time = 12.37s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -46.85, time = 12.37s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -46.39, time = 12.37s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -45.91, time = 12.38s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -45.43, time = 12.35s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -44.95, time = 12.25s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -44.46, time = 12.18s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -43.98, time = 12.17s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.51, time = 12.17s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -43.02, time = 12.17s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -42.52, time = 12.17s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -42.04, time = 12.17s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -41.54, time = 12.17s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -41.06, time = 12.17s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -40.58, time = 12.17s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -40.09, time = 12.16s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -39.60, time = 12.16s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -39.13, time = 12.17s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -38.64, time = 12.17s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -38.18, time = 12.17s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -37.69, time = 12.17s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -37.22, time = 12.17s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -36.76, time = 12.16s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -30.18, time = 4.19s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -29.28, time = 6.89s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -29.20, time = 6.88s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.15, time = 6.87s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -29.10, time = 6.88s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -29.06, time = 6.87s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -29.01, time = 6.87s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -28.96, time = 6.87s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -28.91, time = 7.07s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -28.86, time = 6.87s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -28.81, time = 6.87s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -28.76, time = 6.86s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -28.71, time = 6.87s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -28.66, time = 6.86s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -28.61, time = 6.86s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -28.55, time = 6.86s2019-12-25 00:15:32,693 [INFO] Pretraining Complete
2019-12-25 00:15:32,702 [INFO] Getting pretrained weights
2019-12-25 00:15:32,702 [INFO] Creating and initializing feed forward neural network
2019-12-25 00:15:32,945 [WARNING] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2019-12-25 00:15:32,985 [INFO] _________________________________________________________________
2019-12-25 00:15:32,985 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 00:15:32,985 [INFO] =================================================================
2019-12-25 00:15:32,985 [INFO] dense_37 (Dense)             (None, 128)               10112     
2019-12-25 00:15:32,985 [INFO] _________________________________________________________________
2019-12-25 00:15:32,985 [INFO] batch_normalization_28 (Batc (None, 128)               512       
2019-12-25 00:15:32,985 [INFO] _________________________________________________________________
2019-12-25 00:15:32,985 [INFO] dropout_28 (Dropout)         (None, 128)               0         
2019-12-25 00:15:32,985 [INFO] _________________________________________________________________
2019-12-25 00:15:32,985 [INFO] dense_38 (Dense)             (None, 64)                8256      
2019-12-25 00:15:32,985 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] batch_normalization_29 (Batc (None, 64)                256       
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] dropout_29 (Dropout)         (None, 64)                0         
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] dense_39 (Dense)             (None, 36)                2340      
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] batch_normalization_30 (Batc (None, 36)                144       
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] dropout_30 (Dropout)         (None, 36)                0         
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:32,986 [INFO] dense_40 (Dense)             (None, 12)                444       
2019-12-25 00:15:32,986 [INFO] =================================================================
2019-12-25 00:15:32,986 [INFO] Total params: 22,064
2019-12-25 00:15:32,986 [INFO] Trainable params: 21,608
2019-12-25 00:15:32,986 [INFO] Non-trainable params: 456
2019-12-25 00:15:32,986 [INFO] _________________________________________________________________
2019-12-25 00:15:35,967 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -28.50, time = 6.88s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -28.44, time = 6.86s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -28.39, time = 6.88s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -28.33, time = 6.87s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -28.28, time = 6.87s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -28.22, time = 6.87s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -28.16, time = 6.87s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -28.10, time = 6.87s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -28.04, time = 6.86s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -27.98, time = 6.86s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -27.91, time = 6.86s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -27.84, time = 6.86s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -27.78, time = 6.86s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -27.72, time = 6.86s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -27.64, time = 6.87s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -27.58, time = 6.86s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -27.52, time = 6.86s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -27.44, time = 6.87s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -27.38, time = 6.86s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -27.30, time = 6.87s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -27.24, time = 6.87s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -27.15, time = 6.86s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -27.08, time = 6.87s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.01, time = 6.86s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -26.93, time = 6.86s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -26.85, time = 6.86s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.77, time = 6.86s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.69, time = 6.86s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.61, time = 6.86s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.52, time = 6.86s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -26.44, time = 6.86s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -26.35, time = 6.86s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -26.27, time = 6.86s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -26.18, time = 6.86s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 19s - loss: 0.1192 - val_loss: 0.1067
 - val_f1: 0.7155
Epoch 2/300
 - 18s - loss: 0.1075 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 3/300
 - 18s - loss: 0.1069 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 4/300
 - 18s - loss: 0.1068 - val_loss: 0.1066
 - val_f1: 0.7155
Epoch 5/300
 - 18s - loss: 0.0998 - val_loss: 0.0826
 - val_f1: 0.7720
Epoch 6/300
 - 18s - loss: 0.0812 - val_loss: 0.0619
 - val_f1: 0.7821
Epoch 7/300
 - 18s - loss: 0.0749 - val_loss: 0.0534
 - val_f1: 0.7942
Epoch 8/300
 - 18s - loss: 0.0654 - val_loss: 0.0435
 - val_f1: 0.8243
Epoch 9/300
 - 18s - loss: 0.0579 - val_loss: 0.0362
 - val_f1: 0.8859
Epoch 10/300
 - 18s - loss: 0.0493 - val_loss: 0.0352
 - val_f1: 0.8872
Epoch 11/300
 - 18s - loss: 0.0449 - val_loss: 0.0337
 - val_f1: 0.8936
Epoch 12/300
 - 18s - loss: 0.0414 - val_loss: 0.0314
 - val_f1: 0.8975
Epoch 13/300
 - 18s - loss: 0.0398 - val_loss: 0.0300
 - val_f1: 0.9140
Epoch 14/300
 - 18s - loss: 0.0386 - val_loss: 0.0284
 - val_f1: 0.9177
Epoch 15/300
 - 18s - loss: 0.0368 - val_loss: 0.0242
 - val_f1: 0.9447
Epoch 16/300
 - 18s - loss: 0.0335 - val_loss: 0.0196
 - val_f1: 0.9505
Epoch 17/300
 - 18s - loss: 0.0305 - val_loss: 0.0179
 - val_f1: 0.9536
Epoch 18/300
 - 18s - loss: 0.0285 - val_loss: 0.0173
 - val_f1: 0.9549
Epoch 19/300
 - 18s - loss: 0.0272 - val_loss: 0.0167
 - val_f1: 0.9552
Epoch 20/300
 - 18s - loss: 0.0258 - val_loss: 0.0157
 - val_f1: 0.9567
Epoch 21/300
 - 18s - loss: 0.0245 - val_loss: 0.0160
 - val_f1: 0.9557
Epoch 22/300
 - 18s - loss: 0.0233 - val_loss: 0.0152
 - val_f1: 0.9568
Epoch 23/300
 - 18s - loss: 0.0219 - val_loss: 0.0145
 - val_f1: 0.9593
Epoch 24/300
 - 18s - loss: 0.0209 - val_loss: 0.0138
 - val_f1: 0.9617
Epoch 25/300
 - 18s - loss: 0.0199 - val_loss: 0.0131
 - val_f1: 0.9637
Epoch 26/300
 - 18s - loss: 0.0191 - val_loss: 0.0128
 - val_f1: 0.9666
Epoch 27/300
 - 18s - loss: 0.0184 - val_loss: 0.0119
 - val_f1: 0.9681
Epoch 28/300
 - 18s - loss: 0.0177 - val_loss: 0.0115
 - val_f1: 0.9678
Epoch 29/300
 - 18s - loss: 0.0171 - val_loss: 0.0109
 - val_f1: 0.9705
Epoch 30/300
 - 18s - loss: 0.0164 - val_loss: 0.0103
 - val_f1: 0.9709
Epoch 31/300
 - 18s - loss: 0.0156 - val_loss: 0.0092
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 00:32:50,085 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9811
Epoch 32/300
 - 18s - loss: 0.0149 - val_loss: 0.0092
 - val_f1: 0.9793
Epoch 33/300
 - 18s - loss: 0.0140 - val_loss: 0.0083
 - val_f1: 0.9840
Epoch 34/300
 - 18s - loss: 0.0134 - val_loss: 0.0071
 - val_f1: 0.9840
Epoch 35/300
 - 18s - loss: 0.0127 - val_loss: 0.0071
 - val_f1: 0.9845
Epoch 36/300
 - 18s - loss: 0.0120 - val_loss: 0.0067
 - val_f1: 0.9852
Epoch 37/300
 - 18s - loss: 0.0115 - val_loss: 0.0063
 - val_f1: 0.9856
Epoch 38/300
 - 18s - loss: 0.0110 - val_loss: 0.0066
 - val_f1: 0.9877
Epoch 39/300
 - 18s - loss: 0.0105 - val_loss: 0.0062
 - val_f1: 0.9865
Epoch 40/300
 - 18s - loss: 0.0103 - val_loss: 0.0059
 - val_f1: 0.9860
Epoch 41/300
 - 18s - loss: 0.0099 - val_loss: 0.0057
 - val_f1: 0.9877
Epoch 42/300
 - 18s - loss: 0.0096 - val_loss: 0.0058
 - val_f1: 0.9862
Epoch 43/300
 - 18s - loss: 0.0093 - val_loss: 0.0054
 - val_f1: 0.9888
Epoch 44/300
 - 18s - loss: 0.0090 - val_loss: 0.0052
 - val_f1: 0.9901
Epoch 45/300
 - 18s - loss: 0.0088 - val_loss: 0.0054
 - val_f1: 0.9885
Epoch 46/300
 - 18s - loss: 0.0085 - val_loss: 0.0048
 - val_f1: 0.9899
Epoch 47/300
 - 18s - loss: 0.0083 - val_loss: 0.0047
 - val_f1: 0.9911
Epoch 48/300
 - 18s - loss: 0.0081 - val_loss: 0.0046
 - val_f1: 0.9911
Epoch 49/300
 - 18s - loss: 0.0080 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 50/300
 - 18s - loss: 0.0078 - val_loss: 0.0045
 - val_f1: 0.9916
Epoch 51/300
 - 18s - loss: 0.0076 - val_loss: 0.0043
 - val_f1: 0.9910
Epoch 52/300
 - 18s - loss: 0.0075 - val_loss: 0.0042
 - val_f1: 0.9894
Epoch 53/300
 - 18s - loss: 0.0073 - val_loss: 0.0041
 - val_f1: 0.9911
Epoch 54/300
 - 18s - loss: 0.0071 - val_loss: 0.0042
 - val_f1: 0.9914
Epoch 55/300
 - 18s - loss: 0.0071 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 56/300
 - 18s - loss: 0.0069 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 57/300
 - 18s - loss: 0.0068 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 58/300
 - 18s - loss: 0.0067 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 59/300
 - 18s - loss: 0.0066 - val_loss: 0.0046
 - val_f1: 0.9897
Epoch 60/300
 - 18s - loss: 0.0065 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 61/300
 - 18s - loss: 0.0064 - val_loss: 0.0036
2019-12-25 00:49:41,499 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9925
Epoch 62/300
 - 18s - loss: 0.0063 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 63/300
 - 18s - loss: 0.0062 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 64/300
 - 18s - loss: 0.0061 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 65/300
 - 18s - loss: 0.0061 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 66/300
 - 18s - loss: 0.0060 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 67/300
 - 18s - loss: 0.0059 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 68/300
 - 18s - loss: 0.0059 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 69/300
 - 18s - loss: 0.0058 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 70/300
 - 18s - loss: 0.0057 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 71/300
 - 18s - loss: 0.0057 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 72/300
 - 18s - loss: 0.0058 - val_loss: 0.0037
 - val_f1: 0.9910
Epoch 73/300
 - 18s - loss: 0.0060 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 74/300
 - 18s - loss: 0.0060 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 75/300
 - 18s - loss: 0.0056 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 76/300
 - 18s - loss: 0.0055 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 77/300
 - 18s - loss: 0.0055 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 78/300
 - 18s - loss: 0.0055 - val_loss: 0.0039
 - val_f1: 0.9908
Epoch 79/300
 - 18s - loss: 0.0058 - val_loss: 0.0037
 - val_f1: 0.9912
Epoch 80/300
 - 18s - loss: 0.0055 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 81/300
 - 18s - loss: 0.0054 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 82/300
 - 18s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 83/300
 - 18s - loss: 0.0053 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 84/300
 - 18s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 85/300
 - 18s - loss: 0.0052 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 86/300
 - 18s - loss: 0.0053 - val_loss: 0.0033
 - val_f1: 0.9913
Epoch 87/300
 - 18s - loss: 0.0052 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 88/300
 - 18s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 89/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 90/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 91/300
 - 18s - loss: 0.0053 - val_loss: 0.0033
2019-12-25 01:06:32,895 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9924
Epoch 92/300
 - 18s - loss: 0.0052 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 93/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 94/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9906
Epoch 95/300
 - 18s - loss: 0.0050 - val_loss: 0.0034
 - val_f1: 0.9915
Epoch 96/300
 - 18s - loss: 0.0049 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 97/300
 - 18s - loss: 0.0049 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 98/300
 - 18s - loss: 0.0051 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 99/300
 - 18s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9901
Epoch 100/300
 - 18s - loss: 0.0051 - val_loss: 0.0031
 - val_f1: 0.9909
Epoch 101/300
 - 18s - loss: 0.0051 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 102/300
 - 18s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9913
Epoch 103/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 104/300
 - 18s - loss: 0.0050 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 105/300
 - 18s - loss: 0.0050 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 106/300
 - 18s - loss: 0.0050 - val_loss: 0.0031
 - val_f1: 0.9918
Epoch 107/300
 - 18s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 108/300
 - 18s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9918
Epoch 109/300
 - 18s - loss: 0.0049 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 110/300
 - 18s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 111/300
 - 18s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 112/300
 - 18s - loss: 0.0049 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 113/300
 - 18s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9914
Epoch 114/300
 - 18s - loss: 0.0048 - val_loss: 0.0032
 - val_f1: 0.9916
Epoch 115/300
 - 18s - loss: 0.0049 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 116/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 117/300
 - 18s - loss: 0.0048 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 118/300
 - 18s - loss: 0.0047 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 119/300
 - 18s - loss: 0.0047 - val_loss: 0.0030
 - val_f1: 0.9921
Epoch 120/300
 - 18s - loss: 0.0047 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 121/300
 - 18s - loss: 0.0047 - val_loss: 0.0030
2019-12-25 01:23:25,007 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9931
Epoch 122/300
 - 18s - loss: 0.0047 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 123/300
 - 18s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 124/300
 - 18s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 125/300
 - 18s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 126/300
 - 18s - loss: 0.0047 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 127/300
 - 18s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 128/300
 - 18s - loss: 0.0046 - val_loss: 0.0029
 - val_f1: 0.9917
Epoch 129/300
 - 18s - loss: 0.0045 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 130/300
 - 18s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 131/300
 - 18s - loss: 0.0046 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 132/300
 - 18s - loss: 0.0044 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 133/300
 - 18s - loss: 0.0045 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 134/300
 - 18s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 135/300
 - 18s - loss: 0.0045 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 136/300
 - 18s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 137/300
 - 18s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 138/300
 - 18s - loss: 0.0045 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 139/300
 - 18s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 140/300
 - 18s - loss: 0.0044 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 141/300
 - 18s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9921
Epoch 142/300
 - 18s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 143/300
 - 18s - loss: 0.0044 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 144/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 145/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 146/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 147/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 148/300
 - 18s - loss: 0.0043 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 149/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 150/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 151/300
 - 18s - loss: 0.0043 - val_loss: 0.0039
2019-12-25 01:40:16,105 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9915
Epoch 152/300
 - 18s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 153/300
 - 18s - loss: 0.0043 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 154/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 155/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 156/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 157/300
 - 18s - loss: 0.0042 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 158/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9932
Epoch 159/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 160/300
 - 18s - loss: 0.0042 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 161/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 162/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9924
Epoch 163/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 164/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 165/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 166/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9920
Epoch 167/300
 - 18s - loss: 0.0042 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 168/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 169/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 170/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 171/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 172/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 173/300
 - 18s - loss: 0.0041 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 174/300
 - 18s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 175/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 176/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 177/300
 - 18s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 178/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 179/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 180/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 181/300
 - 18s - loss: 0.0040 - val_loss: 0.0025
2019-12-25 01:57:08,193 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9946
Epoch 182/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 183/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 184/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 185/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 186/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 187/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 188/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 189/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 190/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 191/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 192/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 193/300
 - 18s - loss: 0.0040 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 194/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 195/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 196/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 197/300
 - 18s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 198/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 199/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 200/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 201/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 202/300
 - 18s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 203/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 204/300
 - 18s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 205/300
 - 18s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 206/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 207/300
 - 18s - loss: 0.0039 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 208/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 209/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9924
Epoch 210/300
 - 18s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 211/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
2019-12-25 02:13:59,872 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9939
Epoch 212/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 213/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 214/300
 - 18s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9904
Epoch 215/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 216/300
 - 18s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 217/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 218/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 219/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 220/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 221/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 222/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 223/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 224/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 225/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 226/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 227/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 228/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 229/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 230/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 231/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 232/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 233/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 234/300
 - 18s - loss: 0.0039 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 235/300
 - 18s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 236/300
 - 18s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 237/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 238/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 239/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 240/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 241/300
 - 18s - loss: 0.0037 - val_loss: 0.0034
2019-12-25 02:30:51,428 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9923
Epoch 242/300
 - 18s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 243/300
 - 18s - loss: 0.0038 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 244/300
 - 18s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 245/300
 - 18s - loss: 0.0038 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 246/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 247/300
 - 18s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 248/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 249/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 250/300
 - 18s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 251/300
 - 18s - loss: 0.0038 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 252/300
 - 18s - loss: 0.0038 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 253/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 254/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 255/300
 - 18s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 256/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 257/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 258/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 259/300
 - 18s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 260/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 261/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 262/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9929
Epoch 263/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 264/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 265/300
 - 18s - loss: 0.0037 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 266/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 267/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 268/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 269/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 270/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 271/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
2019-12-25 02:47:44,094 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_deep_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9946
Epoch 272/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 273/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 274/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 275/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 276/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 277/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 278/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 279/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 280/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 281/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 282/300
 - 18s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 283/300
 - 18s - loss: 0.0037 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 284/300
 - 18s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 285/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 286/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 287/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 288/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 289/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 290/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 291/300
 - 18s - loss: 0.0037 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 292/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 293/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 294/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 295/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 296/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 297/300
 - 18s - loss: 0.0036 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 298/300
 - 18s - loss: 0.0036 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 299/300
 - 18s - loss: 0.0036 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 300/300
 - 18s - loss: 0.0036 - val_loss: 0.0027
2019-12-25 03:04:16,881 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-25 03:04:55,329 [INFO] Last epoch loss evaluation: train_loss = 0.002244, val_loss = 0.002299
2019-12-25 03:04:55,371 [INFO] Training complete. time_to_train = 12019.35 sec, 200.32 min
2019-12-25 03:04:55,378 [INFO] Model saved to results_selected_models/selected_ids17_dbn_deep_rep5/best_model.pickle
2019-12-25 03:04:55,413 [INFO] Training history saved to: results_selected_models/selected_ids17_dbn_deep_rep5/training_error_history.csv
2019-12-25 03:04:55,615 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep5/training_error_history.png
2019-12-25 03:04:55,745 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_deep_rep5/training_f1_history.png
2019-12-25 03:04:55,745 [INFO] Making predictions on training, validation, testing data
2019-12-25 03:06:11,669 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 03:06:21,968 [INFO] Dataset: Testing. Classification report below
2019-12-25 03:06:21,968 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.98      0.98      2058
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.80    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-25 03:06:21,968 [INFO] Overall accuracy (micro avg): 0.9954310933195654
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-25 03:06:33,710 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8943                       0.7823                0.0011                   0.2177  0.7969
2  Weighted avg        0.9962         0.9952                       0.9954                0.0092                   0.0046  0.9950
2019-12-25 03:06:44,149 [INFO] Dataset: Validation. Classification report below
2019-12-25 03:06:44,149 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       0.99      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.81      0.07      0.13       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.88      0.78      0.79    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-25 03:06:44,149 [INFO] Overall accuracy (micro avg): 0.9955937633716551
2019-12-25 03:06:56,013 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8803                       0.7757                0.0011                   0.2243  0.7892
2  Weighted avg        0.9964         0.9953                       0.9956                0.0089                   0.0044  0.9952
2019-12-25 03:07:30,549 [INFO] Dataset: Training. Classification report below
2019-12-25 03:07:30,549 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.98      0.94      3300
         DoS slowloris       0.99      0.98      0.98      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.85      0.09      0.16       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.88      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-25 03:07:30,549 [INFO] Overall accuracy (micro avg): 0.9956468028224466
2019-12-25 03:08:09,766 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8844                       0.7803                0.0011                   0.2197  0.7950
2  Weighted avg        0.9964         0.9954                       0.9956                0.0091                   0.0044  0.9952
2019-12-25 03:08:09,797 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_deep_rep5/selected_ids17_dbn_deep_rep5_results.xlsx
2019-12-25 03:08:09,801 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-25 03:08:09,868 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_deep_rep1
2019-12-25 03:08:09,869 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_deep_rep1/run_log.log
2019-12-25 03:08:09,869 [INFO] ================= Running experiment no. 1  ================= 

2019-12-25 03:08:09,869 [INFO] Experiment parameters given below
2019-12-25 03:08:09,869 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_deep_rep1'}
2019-12-25 03:08:09,869 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_deep_rep1/tf_logs_run_2019_12_25-03_08_09
2019-12-25 03:08:09,869 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-25 03:08:09,894 [INFO] Reading X, y files
2019-12-25 03:08:09,894 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-25 03:08:16,028 [INFO] Reading complete. time_to_read=6.13 seconds
2019-12-25 03:08:16,028 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-25 03:08:17,701 [INFO] Reading complete. time_to_read=1.67 seconds
2019-12-25 03:08:17,701 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-25 03:08:19,359 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-25 03:08:19,359 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-25 03:08:19,836 [INFO] Reading complete. time_to_read=0.48 seconds
2019-12-25 03:08:19,836 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-25 03:08:20,019 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-25 03:08:20,019 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-25 03:08:20,225 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-25 03:08:24,137 [INFO] Initializing model
2019-12-25 03:08:24,138 [INFO] Training model
2019-12-25 03:08:24,138 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-25 03:08:47,315 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = ba1b640cc5361b8d9338857b212ee107f98b4f08
2019-12-25 03:08:47,315 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9942
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.68, time = 11.08s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -52.07, time = 22.61s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -58.04, time = 21.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.34, time = 21.24s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -71.12, time = 21.17s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.38, time = 21.15s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.93, time = 21.13s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -93.55, time = 21.07s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.14, time = 21.02s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -108.69, time = 20.89s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -116.26, time = 20.78s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -123.84, time = 20.68s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -131.40, time = 20.62s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -138.99, time = 20.60s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -146.57, time = 20.57s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -154.13, time = 20.30s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -161.67, time = 20.10s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -169.22, time = 20.03s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -176.74, time = 19.89s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -184.25, time = 19.71s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -191.77, time = 19.58s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -199.28, time = 19.46s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -206.80, time = 19.37s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -214.33, time = 19.33s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -221.85, time = 19.30s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -229.39, time = 19.27s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -236.92, time = 19.30s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -244.47, time = 19.23s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -252.00, time = 19.21s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -259.54, time = 19.18s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -267.09, time = 19.18s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -274.63, time = 19.18s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -282.18, time = 19.16s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -289.73, time = 19.16s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -297.28, time = 19.14s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -304.84, time = 19.13s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -312.40, time = 19.13s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -319.96, time = 19.11s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -327.53, time = 19.12s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -335.10, time = 19.10s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -342.67, time = 19.08s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -350.25, time = 19.07s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -357.83, time = 19.08s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -365.42, time = 19.07s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -373.01, time = 19.06s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -380.61, time = 19.06s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -388.21, time = 19.05s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -395.81, time = 19.05s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -403.42, time = 19.05s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -411.03, time = 19.05s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.72, time = 8.72s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.13, time = 14.96s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.60, time = 14.39s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.04, time = 14.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.48, time = 14.24s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.89, time = 14.23s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.28, time = 14.22s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.66, time = 14.21s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.02, time = 14.21s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.37, time = 14.20s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -64.70, time = 14.20s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -64.01, time = 14.20s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -63.29, time = 14.20s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -62.58, time = 14.20s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.83, time = 14.22s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.08, time = 14.20s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.30, time = 14.20s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -59.51, time = 14.21s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.71, time = 14.20s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.88, time = 14.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.03, time = 14.21s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.20, time = 14.20s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.33, time = 14.20s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.44, time = 14.20s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.58, time = 14.22s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -52.68, time = 14.13s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -51.78, time = 13.93s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -50.88, time = 13.92s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -49.95, time = 13.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.05, time = 13.92s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -48.14, time = 13.91s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -47.22, time = 13.93s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -46.31, time = 13.92s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.41, time = 13.92s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.50, time = 13.92s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.61, time = 13.93s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.72, time = 13.94s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.85, time = 13.94s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -40.98, time = 13.94s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -40.13, time = 13.94s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -39.27, time = 13.95s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -38.45, time = 13.94s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -37.64, time = 13.94s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -36.84, time = 13.93s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -36.07, time = 13.93s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -35.30, time = 13.92s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -34.54, time = 13.92s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -33.80, time = 13.93s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -33.10, time = 13.92s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -32.39, time = 13.92s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -37.03, time = 4.59s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.19, time = 7.43s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.02, time = 7.43s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.87, time = 7.44s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.72, time = 7.42s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.58, time = 7.42s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -35.43, time = 7.42s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -35.27, time = 7.42s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -35.11, time = 7.42s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -34.95, time = 7.41s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -34.78, time = 7.42s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -34.61, time = 7.42s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -34.44, time = 7.42s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -34.26, time = 7.42s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -34.07, time = 7.41s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -33.88, time = 7.40s2019-12-25 03:43:14,983 [INFO] Pretraining Complete
2019-12-25 03:43:15,010 [INFO] Getting pretrained weights
2019-12-25 03:43:15,010 [INFO] Creating and initializing feed forward neural network
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 03:43:15,806 [INFO] =================================================================
2019-12-25 03:43:15,806 [INFO] dense_41 (Dense)             (None, 128)               9984      
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] batch_normalization_31 (Batc (None, 128)               512       
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] dropout_31 (Dropout)         (None, 128)               0         
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] dense_42 (Dense)             (None, 64)                8256      
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] batch_normalization_32 (Batc (None, 64)                256       
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,806 [INFO] dropout_32 (Dropout)         (None, 64)                0         
2019-12-25 03:43:15,806 [INFO] _________________________________________________________________
2019-12-25 03:43:15,807 [INFO] dense_43 (Dense)             (None, 32)                2080      
2019-12-25 03:43:15,807 [INFO] _________________________________________________________________
2019-12-25 03:43:15,807 [INFO] batch_normalization_33 (Batc (None, 32)                128       
2019-12-25 03:43:15,807 [INFO] _________________________________________________________________
2019-12-25 03:43:15,807 [INFO] dropout_33 (Dropout)         (None, 32)                0         
2019-12-25 03:43:15,807 [INFO] _________________________________________________________________
2019-12-25 03:43:15,807 [INFO] dense_44 (Dense)             (None, 15)                495       
2019-12-25 03:43:15,807 [INFO] =================================================================
2019-12-25 03:43:15,807 [INFO] Total params: 21,711
2019-12-25 03:43:15,807 [INFO] Trainable params: 21,263
2019-12-25 03:43:15,807 [INFO] Non-trainable params: 448
2019-12-25 03:43:15,807 [INFO] _________________________________________________________________
2019-12-25 03:43:19,537 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.70, time = 7.44s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -33.49, time = 7.40s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -33.29, time = 7.40s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.09, time = 7.40s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -32.87, time = 7.41s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -32.66, time = 7.41s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -32.44, time = 7.41s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.21, time = 7.42s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -31.98, time = 7.42s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -31.74, time = 7.41s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -31.50, time = 7.42s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -31.25, time = 7.42s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -31.00, time = 7.42s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -30.74, time = 7.43s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -30.48, time = 7.41s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -30.21, time = 7.41s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -29.94, time = 7.40s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -29.66, time = 7.41s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -29.37, time = 7.41s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -29.09, time = 7.41s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -28.80, time = 7.41s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -28.50, time = 7.41s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -28.20, time = 7.41s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.90, time = 7.41s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.59, time = 7.42s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -27.27, time = 7.42s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.95, time = 7.37s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.64, time = 7.34s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.31, time = 7.30s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -25.99, time = 7.28s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -25.67, time = 7.28s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -25.33, time = 7.28s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -25.00, time = 7.28s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -24.67, time = 7.27s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 23s - loss: 0.0722 - val_loss: 0.0445
 - val_f1: 0.8706
Epoch 2/300
 - 21s - loss: 0.0444 - val_loss: 0.0371
 - val_f1: 0.8986
Epoch 3/300
 - 21s - loss: 0.0390 - val_loss: 0.0344
 - val_f1: 0.9175
Epoch 4/300
 - 21s - loss: 0.0365 - val_loss: 0.0333
 - val_f1: 0.9184
Epoch 5/300
 - 21s - loss: 0.0352 - val_loss: 0.0326
 - val_f1: 0.9187
Epoch 6/300
 - 21s - loss: 0.0345 - val_loss: 0.0323
 - val_f1: 0.9195
Epoch 7/300
 - 22s - loss: 0.0338 - val_loss: 0.0320
 - val_f1: 0.9205
Epoch 8/300
 - 22s - loss: 0.0334 - val_loss: 0.0317
 - val_f1: 0.9234
Epoch 9/300
 - 21s - loss: 0.0329 - val_loss: 0.0312
 - val_f1: 0.9213
Epoch 10/300
 - 21s - loss: 0.0325 - val_loss: 0.0310
 - val_f1: 0.9245
Epoch 11/300
 - 21s - loss: 0.0322 - val_loss: 0.0334
 - val_f1: 0.9223
Epoch 12/300
 - 22s - loss: 0.0317 - val_loss: 0.0301
 - val_f1: 0.9249
Epoch 13/300
 - 21s - loss: 0.0300 - val_loss: 0.0269
 - val_f1: 0.9259
Epoch 14/300
 - 21s - loss: 0.0283 - val_loss: 0.0250
 - val_f1: 0.9318
Epoch 15/300
 - 21s - loss: 0.0267 - val_loss: 0.0463
 - val_f1: 0.8951
Epoch 16/300
 - 21s - loss: 0.0260 - val_loss: 0.0546
 - val_f1: 0.8945
Epoch 17/300
 - 21s - loss: 0.0257 - val_loss: 0.0242
 - val_f1: 0.9328
Epoch 18/300
 - 22s - loss: 0.0254 - val_loss: 0.0500
 - val_f1: 0.9024
Epoch 19/300
 - 22s - loss: 0.0252 - val_loss: 0.0237
 - val_f1: 0.9337
Epoch 20/300
 - 21s - loss: 0.0250 - val_loss: 0.0495
 - val_f1: 0.8975
Epoch 21/300
 - 21s - loss: 0.0247 - val_loss: 0.0233
 - val_f1: 0.9315
Epoch 22/300
 - 21s - loss: 0.0206 - val_loss: 0.0172
 - val_f1: 0.9533
Epoch 23/300
 - 21s - loss: 0.0187 - val_loss: 0.0170
 - val_f1: 0.9556
Epoch 24/300
 - 22s - loss: 0.0172 - val_loss: 0.0149
 - val_f1: 0.9549
Epoch 25/300
 - 21s - loss: 0.0164 - val_loss: 0.0120
 - val_f1: 0.9629
Epoch 26/300
 - 22s - loss: 0.0141 - val_loss: 0.0108
 - val_f1: 0.9647
Epoch 27/300
 - 21s - loss: 0.0129 - val_loss: 0.0389
 - val_f1: 0.9472
Epoch 28/300
 - 21s - loss: 0.0124 - val_loss: 0.0397
 - val_f1: 0.9380
Epoch 29/300
 - 21s - loss: 0.0119 - val_loss: 0.0093
 - val_f1: 0.9764
Epoch 30/300
 - 22s - loss: 0.0115 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 31/300
 - 21s - loss: 0.0111 - val_loss: 0.0187
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 04:03:53,648 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9461
Epoch 32/300
 - 22s - loss: 0.0109 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 33/300
 - 21s - loss: 0.0108 - val_loss: 0.0086
 - val_f1: 0.9764
Epoch 34/300
 - 22s - loss: 0.0107 - val_loss: 0.0086
 - val_f1: 0.9766
Epoch 35/300
 - 21s - loss: 0.0106 - val_loss: 0.0086
 - val_f1: 0.9766
Epoch 36/300
 - 21s - loss: 0.0105 - val_loss: 0.0086
 - val_f1: 0.9769
Epoch 37/300
 - 21s - loss: 0.0104 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 38/300
 - 21s - loss: 0.0103 - val_loss: 0.0085
 - val_f1: 0.9766
Epoch 39/300
 - 21s - loss: 0.0102 - val_loss: 0.0400
 - val_f1: 0.9430
Epoch 40/300
 - 21s - loss: 0.0102 - val_loss: 0.0260
 - val_f1: 0.9425
Epoch 41/300
 - 22s - loss: 0.0101 - val_loss: 0.0085
 - val_f1: 0.9767
Epoch 42/300
 - 21s - loss: 0.0101 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 43/300
 - 21s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9750
Epoch 44/300
 - 21s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 45/300
 - 22s - loss: 0.0099 - val_loss: 0.0084
 - val_f1: 0.9772
Epoch 46/300
 - 21s - loss: 0.0099 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 47/300
 - 21s - loss: 0.0099 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 48/300
 - 21s - loss: 0.0098 - val_loss: 0.0146
 - val_f1: 0.9463
Epoch 49/300
 - 22s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 50/300
 - 21s - loss: 0.0097 - val_loss: 0.0190
 - val_f1: 0.9468
Epoch 51/300
 - 21s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9752
Epoch 52/300
 - 21s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 53/300
 - 21s - loss: 0.0093 - val_loss: 0.0098
 - val_f1: 0.9767
Epoch 54/300
 - 21s - loss: 0.0092 - val_loss: 0.0082
 - val_f1: 0.9752
Epoch 55/300
 - 21s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 56/300
 - 21s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 57/300
 - 21s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 58/300
 - 22s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 59/300
 - 21s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 60/300
 - 21s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9754
Epoch 61/300
 - 21s - loss: 0.0087 - val_loss: 0.0168
2019-12-25 04:24:02,079 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9475
Epoch 62/300
 - 21s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 63/300
 - 21s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 64/300
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 65/300
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 66/300
 - 21s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 67/300
 - 21s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 68/300
 - 21s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 69/300
 - 21s - loss: 0.0086 - val_loss: 0.0135
 - val_f1: 0.9496
Epoch 70/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 71/300
 - 21s - loss: 0.0086 - val_loss: 0.0096
 - val_f1: 0.9746
Epoch 72/300
 - 21s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 73/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 74/300
 - 21s - loss: 0.0085 - val_loss: 0.0103
 - val_f1: 0.9751
Epoch 75/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 76/300
 - 21s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 77/300
 - 22s - loss: 0.0085 - val_loss: 0.0174
 - val_f1: 0.9474
Epoch 78/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 79/300
 - 21s - loss: 0.0084 - val_loss: 0.0127
 - val_f1: 0.9492
Epoch 80/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 81/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 82/300
 - 21s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 83/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 84/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 85/300
 - 22s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9776
Epoch 86/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 87/300
 - 21s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 88/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 89/300
 - 21s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 90/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 91/300
 - 21s - loss: 0.0083 - val_loss: 0.0093
2019-12-25 04:44:07,463 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9775
Epoch 92/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 93/300
 - 21s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 94/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 95/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 96/300
 - 21s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 97/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 98/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 99/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 100/300
 - 21s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 101/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9756
Epoch 102/300
 - 21s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 103/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 104/300
 - 21s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 105/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 106/300
 - 21s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 107/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 108/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 109/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 110/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 111/300
 - 21s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 112/300
 - 21s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9777
Epoch 113/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 114/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 115/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 116/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 117/300
 - 21s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 118/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 119/300
 - 21s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 120/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 121/300
 - 21s - loss: 0.0082 - val_loss: 0.0083
2019-12-25 05:04:14,914 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9777
Epoch 122/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 123/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 124/300
 - 21s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 125/300
 - 21s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 126/300
 - 21s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 127/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 128/300
 - 21s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 129/300
 - 21s - loss: 0.0082 - val_loss: 0.0085
 - val_f1: 0.9768
Epoch 130/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 131/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 132/300
 - 21s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 133/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 134/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 135/300
 - 21s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9763
Epoch 136/300
 - 21s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 137/300
 - 21s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9763
Epoch 138/300
 - 21s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9713
Epoch 139/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 140/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 141/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 142/300
 - 22s - loss: 0.0081 - val_loss: 0.0087
 - val_f1: 0.9769
Epoch 143/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 144/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 145/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 146/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 147/300
 - 21s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 148/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 149/300
 - 21s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9767
Epoch 150/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 151/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
2019-12-25 05:24:20,139 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9781
Epoch 152/300
 - 21s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 153/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 154/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 155/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 156/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 157/300
 - 21s - loss: 0.0081 - val_loss: 0.0085
 - val_f1: 0.9770
Epoch 158/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 159/300
 - 21s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 160/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 161/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 162/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 163/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 164/300
 - 21s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 165/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 166/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 167/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 168/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 169/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 170/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 171/300
 - 21s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 172/300
 - 22s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9764
Epoch 173/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 174/300
 - 21s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 175/300
 - 21s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 176/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 177/300
 - 21s - loss: 0.0080 - val_loss: 0.0087
 - val_f1: 0.9752
Epoch 178/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 179/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 180/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 181/300
 - 21s - loss: 0.0081 - val_loss: 0.0078
2019-12-25 05:44:29,247 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9780
Epoch 182/300
 - 21s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 183/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 184/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 185/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 186/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 187/300
 - 21s - loss: 0.0080 - val_loss: 0.0086
 - val_f1: 0.9771
Epoch 188/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 189/300
 - 22s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 190/300
 - 21s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 191/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 192/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 193/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 194/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 195/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 196/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 197/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 198/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 199/300
 - 21s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 200/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 201/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 202/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 203/300
 - 21s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 204/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 205/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 206/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 207/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 208/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 209/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 210/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 211/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
2019-12-25 06:04:34,572 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9788
Epoch 212/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 213/300
 - 21s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9770
Epoch 214/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 215/300
 - 21s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 216/300
 - 21s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 217/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 218/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 219/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 220/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9789
Epoch 221/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 222/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 223/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 224/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 225/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 226/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 227/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9790
Epoch 228/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 229/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 230/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 231/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 232/300
 - 21s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 233/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 234/300
 - 21s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 235/300
 - 21s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 236/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 237/300
 - 21s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 238/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 239/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 240/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 241/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
2019-12-25 06:24:42,876 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9779
Epoch 242/300
 - 21s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 243/300
 - 21s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 244/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 245/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 246/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 247/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 248/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 249/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 250/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 251/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 252/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 253/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 254/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 255/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 256/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 257/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 258/300
 - 21s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 259/300
 - 21s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 260/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 261/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 262/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 263/300
 - 21s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 264/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 265/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 266/300
 - 21s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 267/300
 - 21s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 268/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 269/300
 - 21s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 270/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 271/300
 - 21s - loss: 0.0079 - val_loss: 0.0078
2019-12-25 06:44:48,582 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9781
Epoch 272/300
 - 21s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 273/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 274/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 275/300
 - 21s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 276/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 277/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 278/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 279/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 280/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 281/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 282/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 283/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 284/300
 - 21s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 285/300
 - 21s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 286/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 287/300
 - 21s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 288/300
 - 22s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 289/300
 - 22s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 290/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 291/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 292/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 293/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 294/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 295/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 296/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 297/300
 - 22s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 298/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 299/300
 - 22s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 300/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
2019-12-25 07:04:32,999 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-25 07:05:19,655 [INFO] Last epoch loss evaluation: train_loss = 0.007650, val_loss = 0.007697
2019-12-25 07:05:19,699 [INFO] Training complete. time_to_train = 14215.56 sec, 236.93 min
2019-12-25 07:05:19,706 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep1/best_model.pickle
2019-12-25 07:05:19,785 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep1/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-25 07:05:20,184 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep1/training_error_history.png
2019-12-25 07:05:20,310 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep1/training_f1_history.png
2019-12-25 07:05:20,310 [INFO] Making predictions on training, validation, testing data
2019-12-25 07:06:50,193 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 07:07:02,390 [INFO] Dataset: Testing. Classification report below
2019-12-25 07:07:02,390 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.99      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.52      0.02      0.04      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.71      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-25 07:07:02,390 [INFO] Overall accuracy (micro avg): 0.9837223929801948
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-25 07:07:16,315 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7073                       0.6909                0.0043                   0.3091  0.6806
2  Weighted avg        0.9911         0.9792                       0.9837                0.0487                   0.0163  0.9789
2019-12-25 07:07:28,538 [INFO] Dataset: Validation. Classification report below
2019-12-25 07:07:28,538 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.50      0.02      0.04      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.71      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-25 07:07:28,538 [INFO] Overall accuracy (micro avg): 0.98374870446655
2019-12-25 07:07:42,424 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7097                       0.6915                0.0043                   0.3085  0.6829
2  Weighted avg        0.9911         0.9792                       0.9837                0.0486                   0.0163  0.9789
2019-12-25 07:08:22,074 [INFO] Dataset: Training. Classification report below
2019-12-25 07:08:22,074 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.97      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.51      0.61     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.51      0.02      0.04     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-25 07:08:22,075 [INFO] Overall accuracy (micro avg): 0.9837239253855743
2019-12-25 07:09:07,095 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7081                       0.6906                0.0043                   0.3094  0.6810
2  Weighted avg        0.9911         0.9792                       0.9837                0.0486                   0.0163  0.9789
2019-12-25 07:09:07,151 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep1/selected_ids18_subset_dbn_deep_rep1_results.xlsx
2019-12-25 07:09:07,156 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-25 07:09:07,260 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_deep_rep2
2019-12-25 07:09:07,261 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_deep_rep2/run_log.log
2019-12-25 07:09:07,261 [INFO] ================= Running experiment no. 1  ================= 

2019-12-25 07:09:07,261 [INFO] Experiment parameters given below
2019-12-25 07:09:07,261 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_deep_rep2'}
2019-12-25 07:09:07,261 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_deep_rep2/tf_logs_run_2019_12_25-07_09_07
2019-12-25 07:09:07,261 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-25 07:09:07,272 [INFO] Reading X, y files
2019-12-25 07:09:07,272 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-25 07:09:13,430 [INFO] Reading complete. time_to_read=6.16 seconds
2019-12-25 07:09:13,430 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-25 07:09:15,102 [INFO] Reading complete. time_to_read=1.67 seconds
2019-12-25 07:09:15,103 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-25 07:09:16,768 [INFO] Reading complete. time_to_read=1.67 seconds
2019-12-25 07:09:16,769 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-25 07:09:17,266 [INFO] Reading complete. time_to_read=0.50 seconds
2019-12-25 07:09:17,266 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-25 07:09:17,451 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-25 07:09:17,451 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-25 07:09:17,631 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-25 07:09:21,558 [INFO] Initializing model
2019-12-25 07:09:21,558 [INFO] Training model
2019-12-25 07:09:21,558 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-25 07:09:46,350 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 0b1a28f6220e7f538940472e48825f37ca641166
2019-12-25 07:09:46,351 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9787
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.26, time = 11.08s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.57, time = 23.26s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.57, time = 21.60s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.05, time = 21.28s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -71.07, time = 21.22s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.61, time = 21.20s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.46, time = 21.18s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -94.37, time = 21.10s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -102.27, time = 21.04s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -110.12, time = 20.91s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -117.99, time = 20.78s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -125.86, time = 20.69s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -133.70, time = 20.64s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -141.57, time = 20.62s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -149.42, time = 20.58s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -157.24, time = 20.33s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -165.04, time = 20.12s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -172.83, time = 20.05s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -180.61, time = 19.92s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -188.36, time = 19.73s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -196.11, time = 19.62s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -203.86, time = 19.49s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -211.61, time = 19.39s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -219.37, time = 19.35s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -227.12, time = 19.30s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -234.90, time = 19.28s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -242.66, time = 19.29s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -250.43, time = 19.24s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -258.20, time = 19.22s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -265.97, time = 19.19s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -273.75, time = 19.19s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -281.52, time = 19.19s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -289.30, time = 19.18s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -297.09, time = 19.18s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -304.87, time = 19.15s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -312.66, time = 19.15s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -320.46, time = 19.13s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -328.25, time = 19.13s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -336.05, time = 19.13s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -343.86, time = 19.11s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -351.66, time = 19.09s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -359.48, time = 19.09s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -367.29, time = 19.09s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -375.13, time = 19.08s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -382.94, time = 19.08s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -390.78, time = 19.08s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -398.61, time = 19.07s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -406.45, time = 19.07s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -414.30, time = 19.07s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -422.15, time = 19.06s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.76, time = 8.74s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.17, time = 15.71s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.63, time = 14.26s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.07, time = 14.25s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.51, time = 14.24s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.92, time = 14.24s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.31, time = 14.25s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.68, time = 14.23s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.05, time = 14.22s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.39, time = 14.22s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -64.72, time = 14.22s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -64.03, time = 14.22s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -63.31, time = 14.22s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -62.59, time = 14.22s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.85, time = 14.22s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.09, time = 14.24s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.31, time = 14.22s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -59.52, time = 14.22s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.72, time = 14.22s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.89, time = 14.23s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.04, time = 14.22s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.20, time = 14.22s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.33, time = 14.22s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.44, time = 14.22s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.57, time = 14.24s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -52.67, time = 14.16s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -51.77, time = 13.95s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -50.87, time = 13.94s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -49.94, time = 13.95s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.03, time = 13.96s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -48.12, time = 13.94s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -47.21, time = 13.94s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -46.30, time = 13.94s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.39, time = 13.94s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.48, time = 13.95s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.59, time = 13.95s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.70, time = 13.95s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.82, time = 14.95s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -40.95, time = 14.66s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -40.10, time = 15.04s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -39.24, time = 13.98s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -38.42, time = 13.97s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -37.61, time = 13.96s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -36.81, time = 13.95s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -36.04, time = 13.95s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -35.27, time = 13.95s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -34.51, time = 13.95s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -33.77, time = 13.95s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -33.07, time = 13.95s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -32.35, time = 13.94s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -37.03, time = 4.66s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.21, time = 7.56s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.04, time = 7.56s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.89, time = 7.57s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.74, time = 7.56s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.60, time = 7.56s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -35.44, time = 7.56s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -35.28, time = 7.56s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -35.13, time = 7.56s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -34.97, time = 7.56s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -34.80, time = 7.56s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -34.62, time = 7.56s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -34.45, time = 7.58s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -34.27, time = 7.57s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -34.09, time = 7.55s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -33.89, time = 7.55s2019-12-25 07:44:27,349 [INFO] Pretraining Complete
2019-12-25 07:44:27,382 [INFO] Getting pretrained weights
2019-12-25 07:44:27,382 [INFO] Creating and initializing feed forward neural network
2019-12-25 07:44:28,275 [INFO] _________________________________________________________________
2019-12-25 07:44:28,276 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 07:44:28,276 [INFO] =================================================================
2019-12-25 07:44:28,276 [INFO] dense_45 (Dense)             (None, 128)               9984      
2019-12-25 07:44:28,276 [INFO] _________________________________________________________________
2019-12-25 07:44:28,276 [INFO] batch_normalization_34 (Batc (None, 128)               512       
2019-12-25 07:44:28,276 [INFO] _________________________________________________________________
2019-12-25 07:44:28,276 [INFO] dropout_34 (Dropout)         (None, 128)               0         
2019-12-25 07:44:28,276 [INFO] _________________________________________________________________
2019-12-25 07:44:28,276 [INFO] dense_46 (Dense)             (None, 64)                8256      
2019-12-25 07:44:28,276 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] batch_normalization_35 (Batc (None, 64)                256       
2019-12-25 07:44:28,277 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] dropout_35 (Dropout)         (None, 64)                0         
2019-12-25 07:44:28,277 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] dense_47 (Dense)             (None, 33)                2145      
2019-12-25 07:44:28,277 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] batch_normalization_36 (Batc (None, 33)                132       
2019-12-25 07:44:28,277 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] dropout_36 (Dropout)         (None, 33)                0         
2019-12-25 07:44:28,277 [INFO] _________________________________________________________________
2019-12-25 07:44:28,277 [INFO] dense_48 (Dense)             (None, 15)                510       
2019-12-25 07:44:28,277 [INFO] =================================================================
2019-12-25 07:44:28,277 [INFO] Total params: 21,795
2019-12-25 07:44:28,277 [INFO] Trainable params: 21,345
2019-12-25 07:44:28,278 [INFO] Non-trainable params: 450
2019-12-25 07:44:28,278 [INFO] _________________________________________________________________
2019-12-25 07:44:32,395 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.70, time = 7.59s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -33.50, time = 7.55s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -33.30, time = 7.56s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.09, time = 7.55s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -32.88, time = 7.55s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -32.67, time = 7.55s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -32.44, time = 7.55s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.22, time = 7.56s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -31.98, time = 7.56s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -31.74, time = 7.55s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -31.50, time = 7.56s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -31.25, time = 7.56s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -31.00, time = 7.56s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -30.75, time = 7.56s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -30.48, time = 7.56s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -30.21, time = 7.56s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -29.94, time = 7.56s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -29.66, time = 7.55s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -29.37, time = 7.56s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -29.09, time = 7.55s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -28.79, time = 7.56s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -28.50, time = 7.55s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -28.20, time = 7.55s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.90, time = 7.55s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.58, time = 7.55s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -27.27, time = 7.55s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -26.96, time = 7.55s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.63, time = 7.51s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.30, time = 7.47s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -25.98, time = 7.43s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -25.66, time = 7.41s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -25.33, time = 7.42s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -24.99, time = 7.42s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -24.66, time = 7.42s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 23s - loss: 0.0744 - val_loss: 0.0429
 - val_f1: 0.8667
Epoch 2/300
 - 22s - loss: 0.0437 - val_loss: 0.0369
 - val_f1: 0.8980
Epoch 3/300
 - 22s - loss: 0.0390 - val_loss: 0.0342
 - val_f1: 0.9174
Epoch 4/300
 - 22s - loss: 0.0364 - val_loss: 0.0329
 - val_f1: 0.9182
Epoch 5/300
 - 22s - loss: 0.0351 - val_loss: 0.0327
 - val_f1: 0.9187
Epoch 6/300
 - 22s - loss: 0.0343 - val_loss: 0.0322
 - val_f1: 0.9202
Epoch 7/300
 - 22s - loss: 0.0338 - val_loss: 0.0321
 - val_f1: 0.9199
Epoch 8/300
 - 22s - loss: 0.0334 - val_loss: 0.0318
 - val_f1: 0.9214
Epoch 9/300
 - 22s - loss: 0.0331 - val_loss: 0.0316
 - val_f1: 0.9209
Epoch 10/300
 - 22s - loss: 0.0327 - val_loss: 0.0314
 - val_f1: 0.9216
Epoch 11/300
 - 22s - loss: 0.0325 - val_loss: 0.0312
 - val_f1: 0.9218
Epoch 12/300
 - 22s - loss: 0.0323 - val_loss: 0.0356
 - val_f1: 0.9058
Epoch 13/300
 - 22s - loss: 0.0320 - val_loss: 0.0308
 - val_f1: 0.9218
Epoch 14/300
 - 22s - loss: 0.0313 - val_loss: 0.0280
 - val_f1: 0.9223
Epoch 15/300
 - 22s - loss: 0.0280 - val_loss: 0.0217
 - val_f1: 0.9286
Epoch 16/300
 - 22s - loss: 0.0240 - val_loss: 0.0206
 - val_f1: 0.9319
Epoch 17/300
 - 22s - loss: 0.0231 - val_loss: 0.0230
 - val_f1: 0.9303
Epoch 18/300
 - 22s - loss: 0.0208 - val_loss: 0.0157
 - val_f1: 0.9538
Epoch 19/300
 - 22s - loss: 0.0185 - val_loss: 0.0188
 - val_f1: 0.9318
Epoch 20/300
 - 22s - loss: 0.0180 - val_loss: 0.0151
 - val_f1: 0.9525
Epoch 21/300
 - 22s - loss: 0.0175 - val_loss: 0.0147
 - val_f1: 0.9529
Epoch 22/300
 - 22s - loss: 0.0169 - val_loss: 0.0142
 - val_f1: 0.9554
Epoch 23/300
 - 22s - loss: 0.0165 - val_loss: 0.0161
 - val_f1: 0.9532
Epoch 24/300
 - 22s - loss: 0.0160 - val_loss: 0.0312
 - val_f1: 0.9009
Epoch 25/300
 - 22s - loss: 0.0147 - val_loss: 0.0116
 - val_f1: 0.9655
Epoch 26/300
 - 22s - loss: 0.0138 - val_loss: 0.0115
 - val_f1: 0.9657
Epoch 27/300
 - 22s - loss: 0.0133 - val_loss: 0.0315
 - val_f1: 0.9016
Epoch 28/300
 - 22s - loss: 0.0131 - val_loss: 0.0115
 - val_f1: 0.9658
Epoch 29/300
 - 22s - loss: 0.0129 - val_loss: 0.0114
 - val_f1: 0.9653
Epoch 30/300
 - 22s - loss: 0.0127 - val_loss: 0.0114
 - val_f1: 0.9635
Epoch 31/300
 - 22s - loss: 0.0126 - val_loss: 0.0114
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 08:06:03,643 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9659
Epoch 32/300
 - 22s - loss: 0.0126 - val_loss: 0.0113
 - val_f1: 0.9657
Epoch 33/300
 - 22s - loss: 0.0125 - val_loss: 0.0113
 - val_f1: 0.9658
Epoch 34/300
 - 22s - loss: 0.0124 - val_loss: 0.0136
 - val_f1: 0.9621
Epoch 35/300
 - 22s - loss: 0.0124 - val_loss: 0.0112
 - val_f1: 0.9659
Epoch 36/300
 - 22s - loss: 0.0123 - val_loss: 0.0138
 - val_f1: 0.9576
Epoch 37/300
 - 22s - loss: 0.0122 - val_loss: 0.0112
 - val_f1: 0.9659
Epoch 38/300
 - 22s - loss: 0.0122 - val_loss: 0.0112
 - val_f1: 0.9659
Epoch 39/300
 - 22s - loss: 0.0122 - val_loss: 0.0227
 - val_f1: 0.9337
Epoch 40/300
 - 22s - loss: 0.0121 - val_loss: 0.0124
 - val_f1: 0.9643
Epoch 41/300
 - 22s - loss: 0.0121 - val_loss: 0.0166
 - val_f1: 0.9525
Epoch 42/300
 - 22s - loss: 0.0120 - val_loss: 0.0111
 - val_f1: 0.9655
Epoch 43/300
 - 22s - loss: 0.0120 - val_loss: 0.0111
 - val_f1: 0.9661
Epoch 44/300
 - 22s - loss: 0.0120 - val_loss: 0.0214
 - val_f1: 0.9327
Epoch 45/300
 - 22s - loss: 0.0120 - val_loss: 0.0111
 - val_f1: 0.9660
Epoch 46/300
 - 22s - loss: 0.0114 - val_loss: 0.0085
 - val_f1: 0.9767
Epoch 47/300
 - 22s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9767
Epoch 48/300
 - 22s - loss: 0.0096 - val_loss: 0.0092
 - val_f1: 0.9754
Epoch 49/300
 - 22s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9769
Epoch 50/300
 - 22s - loss: 0.0095 - val_loss: 0.0105
 - val_f1: 0.9605
Epoch 51/300
 - 22s - loss: 0.0094 - val_loss: 0.0360
 - val_f1: 0.9147
Epoch 52/300
 - 22s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9771
Epoch 53/300
 - 22s - loss: 0.0094 - val_loss: 0.0091
 - val_f1: 0.9735
Epoch 54/300
 - 22s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 55/300
 - 22s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9768
Epoch 56/300
 - 22s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 57/300
 - 22s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 58/300
 - 22s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 59/300
 - 22s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 60/300
 - 22s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 61/300
 - 22s - loss: 0.0089 - val_loss: 0.0082
2019-12-25 08:27:06,102 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9775
Epoch 62/300
 - 22s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 63/300
 - 22s - loss: 0.0088 - val_loss: 0.0105
 - val_f1: 0.9643
Epoch 64/300
 - 22s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 65/300
 - 22s - loss: 0.0088 - val_loss: 0.0204
 - val_f1: 0.9592
Epoch 66/300
 - 22s - loss: 0.0087 - val_loss: 0.0148
 - val_f1: 0.9612
Epoch 67/300
 - 22s - loss: 0.0087 - val_loss: 0.0227
 - val_f1: 0.9366
Epoch 68/300
 - 22s - loss: 0.0087 - val_loss: 0.0236
 - val_f1: 0.9170
Epoch 69/300
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 70/300
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 71/300
 - 22s - loss: 0.0087 - val_loss: 0.0100
 - val_f1: 0.9748
Epoch 72/300
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 73/300
 - 22s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 74/300
 - 22s - loss: 0.0086 - val_loss: 0.0168
 - val_f1: 0.9475
Epoch 75/300
 - 22s - loss: 0.0086 - val_loss: 0.0126
 - val_f1: 0.9495
Epoch 76/300
 - 22s - loss: 0.0086 - val_loss: 0.0221
 - val_f1: 0.9466
Epoch 77/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 78/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 79/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 80/300
 - 22s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 81/300
 - 22s - loss: 0.0085 - val_loss: 0.0116
 - val_f1: 0.9633
Epoch 82/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 83/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 84/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 85/300
 - 22s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 86/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 87/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 88/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 89/300
 - 22s - loss: 0.0084 - val_loss: 0.0266
 - val_f1: 0.9199
Epoch 90/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 91/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
2019-12-25 08:48:08,575 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9776
Epoch 92/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 93/300
 - 22s - loss: 0.0084 - val_loss: 0.0159
 - val_f1: 0.9649
Epoch 94/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 95/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 96/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 97/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 98/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 99/300
 - 22s - loss: 0.0083 - val_loss: 0.0349
 - val_f1: 0.8859
Epoch 100/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 101/300
 - 22s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9752
Epoch 102/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 103/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 104/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 105/300
 - 22s - loss: 0.0083 - val_loss: 0.0177
 - val_f1: 0.9334
Epoch 106/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 107/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 108/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 109/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 110/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 111/300
 - 22s - loss: 0.0083 - val_loss: 0.0131
 - val_f1: 0.9458
Epoch 112/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 113/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 114/300
 - 22s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 115/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 116/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 117/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 118/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 119/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 120/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 121/300
 - 22s - loss: 0.0082 - val_loss: 0.0115
2019-12-25 09:09:09,295 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9642
Epoch 122/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 123/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 124/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 125/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 126/300
 - 22s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9749
Epoch 127/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 128/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 129/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 130/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 131/300
 - 22s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9747
Epoch 132/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 133/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 134/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 135/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 136/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 137/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 138/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 139/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 140/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 141/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 142/300
 - 22s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9751
Epoch 143/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 144/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 145/300
 - 22s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9762
Epoch 146/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 147/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 148/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 149/300
 - 22s - loss: 0.0082 - val_loss: 0.0089
 - val_f1: 0.9748
Epoch 150/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 151/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
2019-12-25 09:30:11,538 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9780
Epoch 152/300
 - 22s - loss: 0.0081 - val_loss: 0.0246
 - val_f1: 0.9309
Epoch 153/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 154/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 155/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 156/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 157/300
 - 22s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9770
Epoch 158/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 159/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 160/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 161/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 162/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 163/300
 - 22s - loss: 0.0081 - val_loss: 0.0087
 - val_f1: 0.9738
Epoch 164/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 165/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 166/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 167/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 168/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 169/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 170/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 171/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 172/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 173/300
 - 22s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9750
Epoch 174/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 175/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 176/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 177/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 178/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 179/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 180/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 181/300
 - 22s - loss: 0.0081 - val_loss: 0.0084
2019-12-25 09:51:14,119 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9752
Epoch 182/300
 - 22s - loss: 0.0081 - val_loss: 0.0279
 - val_f1: 0.9027
Epoch 183/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 184/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 185/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 186/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 187/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 188/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 189/300
 - 22s - loss: 0.0081 - val_loss: 0.0113
 - val_f1: 0.9656
Epoch 190/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 191/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 192/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 193/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 194/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 195/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9771
Epoch 196/300
 - 22s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9750
Epoch 197/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 198/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 199/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 200/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 201/300
 - 22s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 202/300
 - 22s - loss: 0.0081 - val_loss: 0.0099
 - val_f1: 0.9724
Epoch 203/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 204/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 205/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 206/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 207/300
 - 22s - loss: 0.0080 - val_loss: 0.0267
 - val_f1: 0.9316
Epoch 208/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 209/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 210/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 211/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
2019-12-25 10:12:15,852 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9783
Epoch 212/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 213/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 214/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 215/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 216/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 217/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 218/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 219/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 220/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 221/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 222/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 223/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 224/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 225/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9749
Epoch 226/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 227/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 228/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 229/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 230/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 231/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 232/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 233/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 234/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 235/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 236/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 237/300
 - 22s - loss: 0.0080 - val_loss: 0.0085
 - val_f1: 0.9768
Epoch 238/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 239/300
 - 22s - loss: 0.0080 - val_loss: 0.0091
 - val_f1: 0.9770
Epoch 240/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 241/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
2019-12-25 10:33:16,343 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9787
Epoch 242/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 243/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 244/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 245/300
 - 22s - loss: 0.0080 - val_loss: 0.0108
 - val_f1: 0.9639
Epoch 246/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 247/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 248/300
 - 22s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 249/300
 - 22s - loss: 0.0080 - val_loss: 0.0085
 - val_f1: 0.9771
Epoch 250/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 251/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 252/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 253/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 254/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 255/300
 - 22s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 256/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 257/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 258/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 259/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 260/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 261/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 262/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 263/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 264/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 265/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 266/300
 - 22s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 267/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 268/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 269/300
 - 22s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 270/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 271/300
 - 22s - loss: 0.0079 - val_loss: 0.0078
2019-12-25 10:54:18,632 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9786
Epoch 272/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 273/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 274/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 275/300
 - 22s - loss: 0.0080 - val_loss: 0.0086
 - val_f1: 0.9771
Epoch 276/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 277/300
 - 22s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 278/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 279/300
 - 22s - loss: 0.0079 - val_loss: 0.0214
 - val_f1: 0.9438
Epoch 280/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 281/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 282/300
 - 22s - loss: 0.0080 - val_loss: 0.0106
 - val_f1: 0.9751
Epoch 283/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 284/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 285/300
 - 22s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9758
Epoch 286/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 287/300
 - 22s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 288/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 289/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 290/300
 - 22s - loss: 0.0080 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 291/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 292/300
 - 22s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 293/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 294/300
 - 22s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 295/300
 - 22s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 296/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 297/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 298/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 299/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 300/300
 - 22s - loss: 0.0079 - val_loss: 0.0080
2019-12-25 11:14:56,946 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-25 11:15:44,972 [INFO] Last epoch loss evaluation: train_loss = 0.007644, val_loss = 0.007714
2019-12-25 11:15:45,018 [INFO] Training complete. time_to_train = 14783.46 sec, 246.39 min
2019-12-25 11:15:45,033 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep2/best_model.pickle
2019-12-25 11:15:45,132 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep2/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-25 11:15:45,553 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep2/training_error_history.png
2019-12-25 11:15:45,683 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep2/training_f1_history.png
2019-12-25 11:15:45,683 [INFO] Making predictions on training, validation, testing data
2019-12-25 11:17:21,646 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 11:17:33,818 [INFO] Dataset: Testing. Classification report below
2019-12-25 11:17:33,818 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.67      1.00      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.54      0.62      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       440
          FTP-BruteForce       0.72      0.85      0.78      7718
           Infilteration       0.45      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.77      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-25 11:17:33,818 [INFO] Overall accuracy (micro avg): 0.9837084500408992
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-25 11:17:47,704 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7657                       0.7124                0.0044                   0.2876  0.7099
2  Weighted avg        0.9911         0.9784                       0.9837                0.0490                   0.0163  0.9787
2019-12-25 11:17:59,927 [INFO] Dataset: Validation. Classification report below
2019-12-25 11:17:59,927 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.83        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.54      0.62      5596
   DoS attacks-Slowloris       0.94      0.97      0.95       439
          FTP-BruteForce       0.72      0.86      0.78      7718
           Infilteration       0.55      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.74      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-25 11:17:59,927 [INFO] Overall accuracy (micro avg): 0.9838168700531537
2019-12-25 11:18:13,745 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7749                       0.7353                0.0043                   0.2647  0.7323
2  Weighted avg        0.9912         0.9795                       0.9838                0.0489                   0.0162  0.9788
2019-12-25 11:18:53,407 [INFO] Dataset: Training. Classification report below
2019-12-25 11:18:53,408 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      1.00     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.72      0.53      0.61     16787
   DoS attacks-Slowloris       0.95      0.99      0.97      1318
          FTP-BruteForce       0.72      0.85      0.78     23153
           Infilteration       0.54      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.77      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-25 11:18:53,408 [INFO] Overall accuracy (micro avg): 0.9837724675206639
2019-12-25 11:19:38,454 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0012                   0.0162  0.9838
1     Macro avg        0.9978         0.7742                       0.7250                0.0043                   0.2750  0.7237
2  Weighted avg        0.9912         0.9794                       0.9838                0.0488                   0.0162  0.9788
2019-12-25 11:19:38,519 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep2/selected_ids18_subset_dbn_deep_rep2_results.xlsx
2019-12-25 11:19:38,524 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-25 11:19:38,623 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_deep_rep3
2019-12-25 11:19:38,630 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_deep_rep3/run_log.log
2019-12-25 11:19:38,630 [INFO] ================= Running experiment no. 1  ================= 

2019-12-25 11:19:38,630 [INFO] Experiment parameters given below
2019-12-25 11:19:38,630 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_deep_rep3'}
2019-12-25 11:19:38,630 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_deep_rep3/tf_logs_run_2019_12_25-11_19_38
2019-12-25 11:19:38,630 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-25 11:19:38,642 [INFO] Reading X, y files
2019-12-25 11:19:38,642 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-25 11:19:44,809 [INFO] Reading complete. time_to_read=6.17 seconds
2019-12-25 11:19:44,809 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-25 11:19:46,529 [INFO] Reading complete. time_to_read=1.72 seconds
2019-12-25 11:19:46,529 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-25 11:19:48,186 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-25 11:19:48,186 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-25 11:19:48,673 [INFO] Reading complete. time_to_read=0.49 seconds
2019-12-25 11:19:48,673 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-25 11:19:48,870 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-25 11:19:48,870 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-25 11:19:49,051 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-25 11:19:53,004 [INFO] Initializing model
2019-12-25 11:19:53,009 [INFO] Training model
2019-12-25 11:19:53,009 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-25 11:20:17,338 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 62adc44aea971d3bcb5834db12af9aefd0b8659f
2019-12-25 11:20:17,338 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9781
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.27, time = 11.07s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.50, time = 22.68s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.48, time = 21.55s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -63.91, time = 21.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -70.85, time = 21.17s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.26, time = 21.15s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -85.96, time = 21.12s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -93.72, time = 21.07s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.44, time = 21.02s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -109.10, time = 20.90s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -116.78, time = 20.76s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -124.47, time = 20.67s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -132.15, time = 20.62s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -139.86, time = 20.60s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -147.56, time = 20.56s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -155.27, time = 20.34s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -162.97, time = 20.10s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -170.69, time = 20.03s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -178.39, time = 19.88s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -186.08, time = 19.70s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -193.79, time = 19.58s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -201.49, time = 19.46s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -209.19, time = 19.36s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -216.91, time = 19.34s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -224.61, time = 19.28s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -232.34, time = 19.27s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -240.06, time = 19.29s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -247.79, time = 19.22s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -255.51, time = 19.20s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -263.24, time = 19.18s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -270.98, time = 19.21s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -278.71, time = 19.16s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -286.44, time = 19.15s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -294.19, time = 19.15s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -301.93, time = 19.13s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -309.68, time = 19.13s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -317.43, time = 19.11s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -325.18, time = 19.10s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -332.94, time = 19.10s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -340.70, time = 19.08s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -348.46, time = 19.07s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -356.24, time = 19.07s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -364.01, time = 19.07s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -371.80, time = 19.06s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -379.57, time = 19.06s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -387.37, time = 19.06s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -395.16, time = 19.06s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -402.95, time = 19.06s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -410.76, time = 19.05s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -418.56, time = 19.05s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.77, time = 8.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.19, time = 15.22s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.65, time = 14.23s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.09, time = 14.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.53, time = 14.22s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.94, time = 14.22s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.33, time = 14.22s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.71, time = 14.20s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.07, time = 14.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.42, time = 14.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -64.75, time = 14.19s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -64.06, time = 14.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -63.34, time = 14.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -62.63, time = 14.19s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.88, time = 14.20s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.13, time = 14.19s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.35, time = 14.19s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -59.56, time = 14.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.76, time = 14.21s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.93, time = 14.19s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.08, time = 14.59s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.24, time = 14.24s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.38, time = 14.24s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.49, time = 14.31s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.62, time = 14.23s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -52.72, time = 14.17s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -51.83, time = 13.97s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -50.92, time = 13.95s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -50.00, time = 13.96s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.09, time = 13.96s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -48.18, time = 13.97s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -47.27, time = 13.96s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -46.36, time = 14.01s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.45, time = 14.10s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.54, time = 13.96s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.66, time = 13.99s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.76, time = 13.99s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.89, time = 13.98s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -41.02, time = 13.99s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -40.17, time = 13.98s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -39.31, time = 14.01s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -38.49, time = 13.99s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -37.68, time = 14.00s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -36.88, time = 13.98s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -36.10, time = 13.97s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -35.33, time = 13.97s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -34.58, time = 13.97s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -33.84, time = 13.97s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -33.13, time = 13.96s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -32.42, time = 13.95s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -37.03, time = 4.69s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.23, time = 7.69s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.06, time = 7.68s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.92, time = 7.70s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.77, time = 7.69s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.62, time = 7.68s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -35.46, time = 7.68s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -35.31, time = 7.68s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -35.15, time = 7.68s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -34.99, time = 7.68s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -34.82, time = 7.68s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -34.65, time = 7.68s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -34.47, time = 7.68s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -34.29, time = 7.70s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -34.11, time = 7.67s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -33.92, time = 7.66s2019-12-25 11:54:59,726 [INFO] Pretraining Complete
2019-12-25 11:54:59,738 [INFO] Getting pretrained weights
2019-12-25 11:54:59,738 [INFO] Creating and initializing feed forward neural network
2019-12-25 11:55:00,535 [INFO] _________________________________________________________________
2019-12-25 11:55:00,535 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 11:55:00,535 [INFO] =================================================================
2019-12-25 11:55:00,535 [INFO] dense_49 (Dense)             (None, 128)               9984      
2019-12-25 11:55:00,535 [INFO] _________________________________________________________________
2019-12-25 11:55:00,535 [INFO] batch_normalization_37 (Batc (None, 128)               512       
2019-12-25 11:55:00,535 [INFO] _________________________________________________________________
2019-12-25 11:55:00,535 [INFO] dropout_37 (Dropout)         (None, 128)               0         
2019-12-25 11:55:00,535 [INFO] _________________________________________________________________
2019-12-25 11:55:00,535 [INFO] dense_50 (Dense)             (None, 64)                8256      
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] batch_normalization_38 (Batc (None, 64)                256       
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] dropout_38 (Dropout)         (None, 64)                0         
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] dense_51 (Dense)             (None, 34)                2210      
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] batch_normalization_39 (Batc (None, 34)                136       
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] dropout_39 (Dropout)         (None, 34)                0         
2019-12-25 11:55:00,536 [INFO] _________________________________________________________________
2019-12-25 11:55:00,536 [INFO] dense_52 (Dense)             (None, 15)                525       
2019-12-25 11:55:00,536 [INFO] =================================================================
2019-12-25 11:55:00,536 [INFO] Total params: 21,879
2019-12-25 11:55:00,536 [INFO] Trainable params: 21,427
2019-12-25 11:55:00,536 [INFO] Non-trainable params: 452
2019-12-25 11:55:00,537 [INFO] _________________________________________________________________
2019-12-25 11:55:04,884 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.73, time = 7.68s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -33.53, time = 7.66s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -33.33, time = 7.67s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.13, time = 7.66s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -32.91, time = 7.66s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -32.70, time = 7.68s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -32.48, time = 7.66s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.25, time = 7.67s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -32.02, time = 7.67s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -31.78, time = 7.66s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -31.54, time = 7.66s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -31.30, time = 7.66s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -31.05, time = 7.67s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -30.79, time = 7.68s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -30.53, time = 7.68s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -30.26, time = 7.68s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -29.99, time = 7.67s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -29.71, time = 7.68s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -29.43, time = 7.68s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -29.15, time = 7.68s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -28.85, time = 7.67s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -28.56, time = 7.66s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -28.26, time = 7.67s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.95, time = 7.66s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.64, time = 7.66s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -27.33, time = 7.66s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -27.02, time = 7.67s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.69, time = 7.63s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.38, time = 7.60s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.05, time = 7.55s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -25.71, time = 7.53s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -25.39, time = 7.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -25.06, time = 7.52s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -24.73, time = 7.53s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 23s - loss: 0.0763 - val_loss: 0.0432
 - val_f1: 0.8662
Epoch 2/300
 - 22s - loss: 0.0447 - val_loss: 0.0371
 - val_f1: 0.8986
Epoch 3/300
 - 22s - loss: 0.0399 - val_loss: 0.0349
 - val_f1: 0.9172
Epoch 4/300
 - 22s - loss: 0.0377 - val_loss: 0.0332
 - val_f1: 0.9180
Epoch 5/300
 - 22s - loss: 0.0361 - val_loss: 0.0329
 - val_f1: 0.9177
Epoch 6/300
 - 22s - loss: 0.0353 - val_loss: 0.0325
 - val_f1: 0.9187
Epoch 7/300
 - 22s - loss: 0.0346 - val_loss: 0.0322
 - val_f1: 0.9163
Epoch 8/300
 - 22s - loss: 0.0342 - val_loss: 0.0317
 - val_f1: 0.9209
Epoch 9/300
 - 22s - loss: 0.0336 - val_loss: 0.0315
 - val_f1: 0.9212
Epoch 10/300
 - 23s - loss: 0.0332 - val_loss: 0.0311
 - val_f1: 0.9217
Epoch 11/300
 - 22s - loss: 0.0329 - val_loss: 0.0310
 - val_f1: 0.9207
Epoch 12/300
 - 22s - loss: 0.0325 - val_loss: 0.0295
 - val_f1: 0.9226
Epoch 13/300
 - 22s - loss: 0.0306 - val_loss: 0.0246
 - val_f1: 0.9227
Epoch 14/300
 - 23s - loss: 0.0270 - val_loss: 0.0214
 - val_f1: 0.9283
Epoch 15/300
 - 23s - loss: 0.0250 - val_loss: 0.0207
 - val_f1: 0.9326
Epoch 16/300
 - 22s - loss: 0.0237 - val_loss: 0.0203
 - val_f1: 0.9330
Epoch 17/300
 - 22s - loss: 0.0208 - val_loss: 0.0230
 - val_f1: 0.9292
Epoch 18/300
 - 22s - loss: 0.0187 - val_loss: 0.0149
 - val_f1: 0.9540
Epoch 19/300
 - 23s - loss: 0.0169 - val_loss: 0.0130
 - val_f1: 0.9638
Epoch 20/300
 - 22s - loss: 0.0157 - val_loss: 0.0127
 - val_f1: 0.9642
Epoch 21/300
 - 22s - loss: 0.0151 - val_loss: 0.0126
 - val_f1: 0.9621
Epoch 22/300
 - 22s - loss: 0.0146 - val_loss: 0.0124
 - val_f1: 0.9650
Epoch 23/300
 - 23s - loss: 0.0142 - val_loss: 0.0720
 - val_f1: 0.8277
Epoch 24/300
 - 22s - loss: 0.0138 - val_loss: 0.0117
 - val_f1: 0.9647
Epoch 25/300
 - 22s - loss: 0.0136 - val_loss: 0.0650
 - val_f1: 0.8288
Epoch 26/300
 - 22s - loss: 0.0134 - val_loss: 0.0118
 - val_f1: 0.9633
Epoch 27/300
 - 22s - loss: 0.0133 - val_loss: 0.0117
 - val_f1: 0.9635
Epoch 28/300
 - 22s - loss: 0.0132 - val_loss: 0.0116
 - val_f1: 0.9658
Epoch 29/300
 - 22s - loss: 0.0131 - val_loss: 0.0115
 - val_f1: 0.9654
Epoch 30/300
 - 22s - loss: 0.0130 - val_loss: 0.0115
 - val_f1: 0.9633
Epoch 31/300
 - 23s - loss: 0.0129 - val_loss: 0.0115
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 12:17:11,449 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9658
Epoch 32/300
 - 22s - loss: 0.0129 - val_loss: 0.0927
 - val_f1: 0.8286
Epoch 33/300
 - 23s - loss: 0.0128 - val_loss: 0.0114
 - val_f1: 0.9659
Epoch 34/300
 - 22s - loss: 0.0127 - val_loss: 0.0114
 - val_f1: 0.9658
Epoch 35/300
 - 22s - loss: 0.0127 - val_loss: 0.0113
 - val_f1: 0.9660
Epoch 36/300
 - 23s - loss: 0.0126 - val_loss: 0.0114
 - val_f1: 0.9637
Epoch 37/300
 - 23s - loss: 0.0126 - val_loss: 0.0887
 - val_f1: 0.8293
Epoch 38/300
 - 22s - loss: 0.0125 - val_loss: 0.0113
 - val_f1: 0.9660
Epoch 39/300
 - 23s - loss: 0.0125 - val_loss: 0.0112
 - val_f1: 0.9657
Epoch 40/300
 - 22s - loss: 0.0124 - val_loss: 0.0113
 - val_f1: 0.9660
Epoch 41/300
 - 22s - loss: 0.0124 - val_loss: 0.0112
 - val_f1: 0.9637
Epoch 42/300
 - 22s - loss: 0.0124 - val_loss: 0.0895
 - val_f1: 0.8326
Epoch 43/300
 - 22s - loss: 0.0123 - val_loss: 0.0113
 - val_f1: 0.9659
Epoch 44/300
 - 22s - loss: 0.0123 - val_loss: 0.0112
 - val_f1: 0.9661
Epoch 45/300
 - 22s - loss: 0.0122 - val_loss: 0.0112
 - val_f1: 0.9661
Epoch 46/300
 - 22s - loss: 0.0122 - val_loss: 0.0112
 - val_f1: 0.9668
Epoch 47/300
 - 22s - loss: 0.0122 - val_loss: 0.0174
 - val_f1: 0.9542
Epoch 48/300
 - 22s - loss: 0.0122 - val_loss: 0.0111
 - val_f1: 0.9662
Epoch 49/300
 - 22s - loss: 0.0121 - val_loss: 0.0112
 - val_f1: 0.9660
Epoch 50/300
 - 22s - loss: 0.0121 - val_loss: 0.0111
 - val_f1: 0.9637
Epoch 51/300
 - 23s - loss: 0.0121 - val_loss: 0.0645
 - val_f1: 0.8523
Epoch 52/300
 - 22s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9661
Epoch 53/300
 - 23s - loss: 0.0120 - val_loss: 0.0111
 - val_f1: 0.9661
Epoch 54/300
 - 22s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9660
Epoch 55/300
 - 22s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9668
Epoch 56/300
 - 22s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9669
Epoch 57/300
 - 22s - loss: 0.0119 - val_loss: 0.0863
 - val_f1: 0.8353
Epoch 58/300
 - 22s - loss: 0.0104 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 59/300
 - 22s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 60/300
 - 23s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 61/300
 - 22s - loss: 0.0092 - val_loss: 0.0082
2019-12-25 12:38:47,960 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9777
Epoch 62/300
 - 22s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 63/300
 - 22s - loss: 0.0091 - val_loss: 0.0860
 - val_f1: 0.8360
Epoch 64/300
 - 22s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 65/300
 - 22s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 66/300
 - 22s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 67/300
 - 22s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 68/300
 - 22s - loss: 0.0089 - val_loss: 0.0807
 - val_f1: 0.8368
Epoch 69/300
 - 22s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 70/300
 - 22s - loss: 0.0089 - val_loss: 0.0746
 - val_f1: 0.8519
Epoch 71/300
 - 22s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 72/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 73/300
 - 22s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 74/300
 - 22s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 75/300
 - 22s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 76/300
 - 22s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 77/300
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 78/300
 - 22s - loss: 0.0087 - val_loss: 0.0235
 - val_f1: 0.9177
Epoch 79/300
 - 22s - loss: 0.0087 - val_loss: 0.0730
 - val_f1: 0.8362
Epoch 80/300
 - 22s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 81/300
 - 22s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 82/300
 - 22s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 83/300
 - 22s - loss: 0.0086 - val_loss: 0.0689
 - val_f1: 0.8310
Epoch 84/300
 - 23s - loss: 0.0086 - val_loss: 0.0757
 - val_f1: 0.8311
Epoch 85/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 86/300
 - 22s - loss: 0.0086 - val_loss: 0.0181
 - val_f1: 0.9655
Epoch 87/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 88/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 89/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 90/300
 - 22s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 91/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
2019-12-25 13:00:25,570 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9779
Epoch 92/300
 - 22s - loss: 0.0085 - val_loss: 0.0359
 - val_f1: 0.8751
Epoch 93/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 94/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 95/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 96/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 97/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 98/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 99/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 100/300
 - 22s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 101/300
 - 22s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 102/300
 - 22s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9770
Epoch 103/300
 - 22s - loss: 0.0085 - val_loss: 0.0503
 - val_f1: 0.8519
Epoch 104/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 105/300
 - 22s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 106/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 107/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9756
Epoch 108/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 109/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 110/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 111/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 112/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 113/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 114/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 115/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 116/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 117/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 118/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 119/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 120/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 121/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
2019-12-25 13:22:02,947 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9777
Epoch 122/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 123/300
 - 22s - loss: 0.0084 - val_loss: 0.0521
 - val_f1: 0.8363
Epoch 124/300
 - 22s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 125/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 126/300
 - 22s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 127/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 128/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 129/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 130/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 131/300
 - 22s - loss: 0.0083 - val_loss: 0.0423
 - val_f1: 0.8733
Epoch 132/300
 - 22s - loss: 0.0083 - val_loss: 0.0506
 - val_f1: 0.8363
Epoch 133/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 134/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 135/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 136/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 137/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 138/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 139/300
 - 23s - loss: 0.0083 - val_loss: 0.0461
 - val_f1: 0.8520
Epoch 140/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 141/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 142/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 143/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 144/300
 - 22s - loss: 0.0083 - val_loss: 0.0432
 - val_f1: 0.8519
Epoch 145/300
 - 22s - loss: 0.0083 - val_loss: 0.0394
 - val_f1: 0.9032
Epoch 146/300
 - 22s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 147/300
 - 22s - loss: 0.0083 - val_loss: 0.0458
 - val_f1: 0.8516
Epoch 148/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 149/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 150/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 151/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
2019-12-25 13:43:40,838 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9781
Epoch 152/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 153/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 154/300
 - 22s - loss: 0.0083 - val_loss: 0.0437
 - val_f1: 0.8366
Epoch 155/300
 - 23s - loss: 0.0082 - val_loss: 0.0420
 - val_f1: 0.8735
Epoch 156/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 157/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 158/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 159/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 160/300
 - 23s - loss: 0.0083 - val_loss: 0.0487
 - val_f1: 0.8523
Epoch 161/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 162/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 163/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 164/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 165/300
 - 22s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 166/300
 - 22s - loss: 0.0082 - val_loss: 0.0085
 - val_f1: 0.9761
Epoch 167/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 168/300
 - 22s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 169/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9792
Epoch 170/300
 - 22s - loss: 0.0082 - val_loss: 0.0538
 - val_f1: 0.8372
Epoch 171/300
 - 23s - loss: 0.0082 - val_loss: 0.0313
 - val_f1: 0.9147
Epoch 172/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 173/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 174/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 175/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 176/300
 - 22s - loss: 0.0082 - val_loss: 0.0369
 - val_f1: 0.8372
Epoch 177/300
 - 23s - loss: 0.0082 - val_loss: 0.0268
 - val_f1: 0.9260
Epoch 178/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 179/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 180/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 181/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
2019-12-25 14:05:17,084 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9782
Epoch 182/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 183/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 184/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 185/300
 - 22s - loss: 0.0082 - val_loss: 0.0387
 - val_f1: 0.8518
Epoch 186/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 187/300
 - 22s - loss: 0.0082 - val_loss: 0.0508
 - val_f1: 0.8363
Epoch 188/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 189/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 190/300
 - 22s - loss: 0.0082 - val_loss: 0.0362
 - val_f1: 0.8728
Epoch 191/300
 - 22s - loss: 0.0082 - val_loss: 0.0454
 - val_f1: 0.8524
Epoch 192/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 193/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 194/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 195/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 196/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 197/300
 - 23s - loss: 0.0082 - val_loss: 0.0348
 - val_f1: 0.8739
Epoch 198/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 199/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 200/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 201/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 202/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 203/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 204/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 205/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 206/300
 - 22s - loss: 0.0082 - val_loss: 0.0309
 - val_f1: 0.9146
Epoch 207/300
 - 22s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 208/300
 - 23s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 209/300
 - 22s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 210/300
 - 23s - loss: 0.0082 - val_loss: 0.0255
 - val_f1: 0.9305
Epoch 211/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
2019-12-25 14:26:53,752 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9781
Epoch 212/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 213/300
 - 22s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9738
Epoch 214/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 215/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 216/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 217/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 218/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 219/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 220/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 221/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 222/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 223/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 224/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 225/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 226/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 227/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 228/300
 - 23s - loss: 0.0081 - val_loss: 0.0331
 - val_f1: 0.8739
Epoch 229/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 230/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 231/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 232/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 233/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 234/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 235/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 236/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 237/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 238/300
 - 22s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 239/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 240/300
 - 22s - loss: 0.0081 - val_loss: 0.0246
 - val_f1: 0.9136
Epoch 241/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
2019-12-25 14:48:30,348 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9782
Epoch 242/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 243/300
 - 22s - loss: 0.0081 - val_loss: 0.0202
 - val_f1: 0.9331
Epoch 244/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 245/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 246/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 247/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 248/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 249/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 250/300
 - 22s - loss: 0.0081 - val_loss: 0.0351
 - val_f1: 0.9038
Epoch 251/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 252/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 253/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 254/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 255/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 256/300
 - 22s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 257/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 258/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 259/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 260/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 261/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 262/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 263/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 264/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 265/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 266/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 267/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 268/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 269/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 270/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 271/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
2019-12-25 15:10:06,770 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9783
Epoch 272/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 273/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 274/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 275/300
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 276/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 277/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 278/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 279/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 280/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9789
Epoch 281/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 282/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 283/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 284/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 285/300
 - 23s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 286/300
 - 22s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 287/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 288/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 289/300
 - 23s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 290/300
 - 23s - loss: 0.0080 - val_loss: 0.0305
 - val_f1: 0.9044
Epoch 291/300
 - 22s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 292/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 293/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 294/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 295/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 296/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 297/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 298/300
 - 22s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 299/300
 - 22s - loss: 0.0080 - val_loss: 0.0313
 - val_f1: 0.8750
Epoch 300/300
 - 23s - loss: 0.0080 - val_loss: 0.0078
2019-12-25 15:31:21,866 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-25 15:32:11,370 [INFO] Last epoch loss evaluation: train_loss = 0.007707, val_loss = 0.007752
2019-12-25 15:32:11,417 [INFO] Training complete. time_to_train = 15138.41 sec, 252.31 min
2019-12-25 15:32:11,425 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep3/best_model.pickle
2019-12-25 15:32:11,428 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep3/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-25 15:32:11,722 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep3/training_error_history.png
2019-12-25 15:32:11,876 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep3/training_f1_history.png
2019-12-25 15:32:11,876 [INFO] Making predictions on training, validation, testing data
2019-12-25 15:33:52,663 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 15:34:04,821 [INFO] Dataset: Testing. Classification report below
2019-12-25 15:34:04,822 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.46      0.57      5596
   DoS attacks-Slowloris       0.96      0.97      0.97       440
          FTP-BruteForce       0.69      0.88      0.78      7718
           Infilteration       0.45      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.70      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-25 15:34:04,822 [INFO] Overall accuracy (micro avg): 0.983404803807352
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-25 15:34:18,637 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7014                       0.6876                0.0044                   0.3124  0.6756
2  Weighted avg        0.9911         0.9783                       0.9834                0.0492                   0.0166  0.9783
2019-12-25 15:34:30,795 [INFO] Dataset: Validation. Classification report below
2019-12-25 15:34:30,795 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.46      0.57      5596
   DoS attacks-Slowloris       0.95      0.97      0.96       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.46      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.71      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-25 15:34:30,795 [INFO] Overall accuracy (micro avg): 0.9834636483771169
2019-12-25 15:34:44,597 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7061                       0.6871                0.0044                   0.3129  0.6777
2  Weighted avg        0.9911         0.9785                       0.9835                0.0491                   0.0165  0.9783
2019-12-25 15:35:24,419 [INFO] Dataset: Training. Classification report below
2019-12-25 15:35:24,419 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.46      0.57     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.69      0.88      0.78     23153
           Infilteration       0.53      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-25 15:35:24,419 [INFO] Overall accuracy (micro avg): 0.9834512631799642
2019-12-25 15:36:09,646 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7091                       0.6876                0.0044                   0.3124  0.6773
2  Weighted avg        0.9911         0.9791                       0.9835                0.0490                   0.0165  0.9783
2019-12-25 15:36:09,676 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep3/selected_ids18_subset_dbn_deep_rep3_results.xlsx
2019-12-25 15:36:09,681 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-25 15:36:09,781 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_deep_rep4
2019-12-25 15:36:09,782 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_deep_rep4/run_log.log
2019-12-25 15:36:09,782 [INFO] ================= Running experiment no. 1  ================= 

2019-12-25 15:36:09,782 [INFO] Experiment parameters given below
2019-12-25 15:36:09,782 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_deep_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 35], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.5], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_deep_rep4'}
2019-12-25 15:36:09,782 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_deep_rep4/tf_logs_run_2019_12_25-15_36_09
2019-12-25 15:36:09,782 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-25 15:36:09,795 [INFO] Reading X, y files
2019-12-25 15:36:09,795 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-25 15:36:15,869 [INFO] Reading complete. time_to_read=6.07 seconds
2019-12-25 15:36:15,869 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-25 15:36:17,530 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-25 15:36:17,530 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-25 15:36:19,188 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-25 15:36:19,188 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-25 15:36:19,673 [INFO] Reading complete. time_to_read=0.49 seconds
2019-12-25 15:36:19,673 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-25 15:36:19,868 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-25 15:36:19,868 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-25 15:36:20,044 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-25 15:36:23,971 [INFO] Initializing model
2019-12-25 15:36:23,971 [INFO] Training model
2019-12-25 15:36:23,971 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-25 15:36:48,318 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 2b9e3002e614a8027a60bbf392ada8cdd5a42e14
2019-12-25 15:36:48,318 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9781
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.13, time = 11.03s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.47, time = 22.56s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.47, time = 21.51s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -63.86, time = 21.21s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -70.78, time = 21.13s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.22, time = 21.12s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.00, time = 21.09s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -93.87, time = 21.04s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.75, time = 21.00s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -109.57, time = 20.86s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -117.42, time = 20.73s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -125.27, time = 20.65s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -133.11, time = 20.59s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -140.98, time = 20.58s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -148.83, time = 20.54s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -156.65, time = 20.29s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -164.47, time = 20.09s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -172.28, time = 20.00s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -180.07, time = 19.87s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -187.85, time = 19.68s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -195.63, time = 19.55s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -203.40, time = 19.43s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -211.17, time = 19.34s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -218.96, time = 19.31s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -226.73, time = 19.26s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -234.53, time = 19.24s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -242.31, time = 19.26s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -250.10, time = 19.19s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -257.89, time = 19.17s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -265.68, time = 19.15s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -273.48, time = 19.15s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -281.27, time = 19.16s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -289.07, time = 19.13s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -296.87, time = 19.13s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -304.67, time = 19.10s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -312.48, time = 19.11s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -320.29, time = 19.09s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -328.10, time = 19.08s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -335.92, time = 19.09s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -343.75, time = 19.06s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -351.57, time = 19.05s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -359.40, time = 19.04s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -367.23, time = 19.04s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -375.08, time = 19.03s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -382.92, time = 19.04s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -390.78, time = 19.03s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -398.63, time = 19.03s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -406.48, time = 19.02s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -414.35, time = 19.02s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -422.22, time = 19.01s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.71, time = 8.69s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.13, time = 15.71s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.59, time = 14.22s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.03, time = 14.21s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.47, time = 14.22s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.88, time = 14.21s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.27, time = 14.21s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.65, time = 14.19s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.01, time = 14.19s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.36, time = 14.19s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -64.69, time = 14.19s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -64.01, time = 14.19s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -63.29, time = 14.19s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -62.57, time = 14.18s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.83, time = 14.18s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.07, time = 14.18s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.29, time = 14.18s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -59.51, time = 14.19s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.70, time = 14.19s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.88, time = 14.18s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.03, time = 14.18s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.19, time = 14.19s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.33, time = 14.18s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.44, time = 14.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.57, time = 14.20s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -52.67, time = 14.13s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -51.78, time = 13.91s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -50.88, time = 13.90s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -49.95, time = 13.91s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.05, time = 13.90s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -48.14, time = 13.89s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -47.22, time = 13.90s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -46.32, time = 13.91s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.41, time = 13.91s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.50, time = 13.91s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.62, time = 13.91s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.73, time = 13.93s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.85, time = 13.92s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -40.99, time = 13.94s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -40.13, time = 13.93s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -39.28, time = 13.94s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -38.46, time = 13.93s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -37.65, time = 13.93s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -36.85, time = 13.93s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -36.08, time = 13.91s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -35.31, time = 13.90s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -34.55, time = 13.90s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -33.82, time = 13.91s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -33.12, time = 13.90s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -32.40, time = 13.91s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -36.99, time = 4.72s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.21, time = 7.81s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.05, time = 7.80s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.90, time = 7.79s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.76, time = 7.79s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.61, time = 7.79s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -35.45, time = 7.79s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -35.30, time = 7.79s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -35.14, time = 7.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -34.97, time = 7.79s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -34.81, time = 7.78s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -34.64, time = 7.79s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -34.46, time = 7.79s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -34.28, time = 7.80s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -34.10, time = 7.78s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -33.91, time = 7.77s2019-12-25 16:11:32,914 [INFO] Pretraining Complete
2019-12-25 16:11:32,914 [INFO] Getting pretrained weights
2019-12-25 16:11:32,914 [INFO] Creating and initializing feed forward neural network
2019-12-25 16:11:33,751 [INFO] _________________________________________________________________
2019-12-25 16:11:33,751 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 16:11:33,751 [INFO] =================================================================
2019-12-25 16:11:33,751 [INFO] dense_53 (Dense)             (None, 128)               9984      
2019-12-25 16:11:33,751 [INFO] _________________________________________________________________
2019-12-25 16:11:33,751 [INFO] batch_normalization_40 (Batc (None, 128)               512       
2019-12-25 16:11:33,751 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dropout_40 (Dropout)         (None, 128)               0         
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dense_54 (Dense)             (None, 64)                8256      
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] batch_normalization_41 (Batc (None, 64)                256       
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dropout_41 (Dropout)         (None, 64)                0         
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dense_55 (Dense)             (None, 35)                2275      
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] batch_normalization_42 (Batc (None, 35)                140       
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dropout_42 (Dropout)         (None, 35)                0         
2019-12-25 16:11:33,752 [INFO] _________________________________________________________________
2019-12-25 16:11:33,752 [INFO] dense_56 (Dense)             (None, 15)                540       
2019-12-25 16:11:33,752 [INFO] =================================================================
2019-12-25 16:11:33,753 [INFO] Total params: 21,963
2019-12-25 16:11:33,753 [INFO] Trainable params: 21,509
2019-12-25 16:11:33,753 [INFO] Non-trainable params: 454
2019-12-25 16:11:33,753 [INFO] _________________________________________________________________
2019-12-25 16:11:38,600 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.72, time = 7.78s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -33.52, time = 7.78s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -33.32, time = 7.77s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.12, time = 7.77s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -32.91, time = 7.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -32.69, time = 7.77s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -32.47, time = 7.78s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.25, time = 7.78s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -32.01, time = 7.79s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -31.78, time = 7.78s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -31.54, time = 7.77s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -31.30, time = 7.77s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -31.05, time = 7.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -30.79, time = 7.78s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -30.53, time = 7.78s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -30.27, time = 7.79s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -29.99, time = 7.78s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -29.71, time = 7.79s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -29.44, time = 7.79s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -29.15, time = 7.78s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -28.87, time = 7.78s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -28.57, time = 7.78s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -28.27, time = 7.78s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -27.96, time = 7.79s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.65, time = 7.79s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -27.34, time = 7.77s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -27.03, time = 7.78s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.71, time = 7.77s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.39, time = 7.74s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.06, time = 7.69s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -25.74, time = 7.65s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -25.40, time = 7.63s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -25.07, time = 7.63s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -24.74, time = 7.65s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 25s - loss: 0.0802 - val_loss: 0.0448
 - val_f1: 0.8651
Epoch 2/300
 - 23s - loss: 0.0486 - val_loss: 0.0383
 - val_f1: 0.8975
Epoch 3/300
 - 23s - loss: 0.0419 - val_loss: 0.0362
 - val_f1: 0.8991
Epoch 4/300
 - 23s - loss: 0.0392 - val_loss: 0.0347
 - val_f1: 0.9050
Epoch 5/300
 - 23s - loss: 0.0377 - val_loss: 0.0333
 - val_f1: 0.9180
Epoch 6/300
 - 23s - loss: 0.0369 - val_loss: 0.0334
 - val_f1: 0.9181
Epoch 7/300
 - 23s - loss: 0.0363 - val_loss: 0.0330
 - val_f1: 0.9154
Epoch 8/300
 - 23s - loss: 0.0359 - val_loss: 0.0327
 - val_f1: 0.9156
Epoch 9/300
 - 23s - loss: 0.0354 - val_loss: 0.0322
 - val_f1: 0.9192
Epoch 10/300
 - 23s - loss: 0.0348 - val_loss: 0.0317
 - val_f1: 0.9182
Epoch 11/300
 - 23s - loss: 0.0340 - val_loss: 0.0309
 - val_f1: 0.9208
Epoch 12/300
 - 23s - loss: 0.0327 - val_loss: 0.0290
 - val_f1: 0.9180
Epoch 13/300
 - 23s - loss: 0.0316 - val_loss: 0.0283
 - val_f1: 0.9211
Epoch 14/300
 - 23s - loss: 0.0286 - val_loss: 0.0229
 - val_f1: 0.9201
Epoch 15/300
 - 23s - loss: 0.0263 - val_loss: 0.0219
 - val_f1: 0.9285
Epoch 16/300
 - 23s - loss: 0.0236 - val_loss: 0.0175
 - val_f1: 0.9408
Epoch 17/300
 - 23s - loss: 0.0207 - val_loss: 0.0139
 - val_f1: 0.9576
Epoch 18/300
 - 23s - loss: 0.0189 - val_loss: 0.0128
 - val_f1: 0.9618
Epoch 19/300
 - 23s - loss: 0.0178 - val_loss: 0.0125
 - val_f1: 0.9641
Epoch 20/300
 - 23s - loss: 0.0171 - val_loss: 0.0121
 - val_f1: 0.9608
Epoch 21/300
 - 23s - loss: 0.0163 - val_loss: 0.0119
 - val_f1: 0.9635
Epoch 22/300
 - 23s - loss: 0.0159 - val_loss: 0.0118
 - val_f1: 0.9632
Epoch 23/300
 - 23s - loss: 0.0155 - val_loss: 0.0117
 - val_f1: 0.9666
Epoch 24/300
 - 23s - loss: 0.0153 - val_loss: 0.0115
 - val_f1: 0.9688
Epoch 25/300
 - 23s - loss: 0.0149 - val_loss: 0.0114
 - val_f1: 0.9653
Epoch 26/300
 - 23s - loss: 0.0147 - val_loss: 0.0111
 - val_f1: 0.9653
Epoch 27/300
 - 23s - loss: 0.0146 - val_loss: 0.0112
 - val_f1: 0.9655
Epoch 28/300
 - 23s - loss: 0.0142 - val_loss: 0.0110
 - val_f1: 0.9655
Epoch 29/300
 - 23s - loss: 0.0139 - val_loss: 0.0102
 - val_f1: 0.9727
Epoch 30/300
 - 23s - loss: 0.0134 - val_loss: 0.0100
 - val_f1: 0.9713
Epoch 31/300
 - 23s - loss: 0.0130 - val_loss: 0.0098
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 16:34:22,315 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9715
Epoch 32/300
 - 23s - loss: 0.0127 - val_loss: 0.0097
 - val_f1: 0.9720
Epoch 33/300
 - 23s - loss: 0.0124 - val_loss: 0.0096
 - val_f1: 0.9731
Epoch 34/300
 - 23s - loss: 0.0119 - val_loss: 0.0094
 - val_f1: 0.9751
Epoch 35/300
 - 23s - loss: 0.0117 - val_loss: 0.0092
 - val_f1: 0.9748
Epoch 36/300
 - 23s - loss: 0.0115 - val_loss: 0.0092
 - val_f1: 0.9737
Epoch 37/300
 - 23s - loss: 0.0113 - val_loss: 0.0092
 - val_f1: 0.9759
Epoch 38/300
 - 23s - loss: 0.0111 - val_loss: 0.0091
 - val_f1: 0.9737
Epoch 39/300
 - 23s - loss: 0.0109 - val_loss: 0.0091
 - val_f1: 0.9753
Epoch 40/300
 - 23s - loss: 0.0108 - val_loss: 0.0090
 - val_f1: 0.9755
Epoch 41/300
 - 23s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9766
Epoch 42/300
 - 23s - loss: 0.0105 - val_loss: 0.0089
 - val_f1: 0.9742
Epoch 43/300
 - 23s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 44/300
 - 23s - loss: 0.0103 - val_loss: 0.0089
 - val_f1: 0.9764
Epoch 45/300
 - 23s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9742
Epoch 46/300
 - 23s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9762
Epoch 47/300
 - 23s - loss: 0.0101 - val_loss: 0.0089
 - val_f1: 0.9766
Epoch 48/300
 - 23s - loss: 0.0101 - val_loss: 0.0089
 - val_f1: 0.9766
Epoch 49/300
 - 23s - loss: 0.0101 - val_loss: 0.0089
 - val_f1: 0.9738
Epoch 50/300
 - 23s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9767
Epoch 51/300
 - 23s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9767
Epoch 52/300
 - 23s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9767
Epoch 53/300
 - 23s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9769
Epoch 54/300
 - 23s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9759
Epoch 55/300
 - 23s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 56/300
 - 23s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 57/300
 - 23s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 58/300
 - 23s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9748
Epoch 59/300
 - 23s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 60/300
 - 23s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 61/300
 - 23s - loss: 0.0095 - val_loss: 0.0085
2019-12-25 16:56:29,750 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9746
Epoch 62/300
 - 23s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 63/300
 - 23s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 64/300
 - 23s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9770
Epoch 65/300
 - 23s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 66/300
 - 23s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 67/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 68/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 69/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 70/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 71/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9751
Epoch 72/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 73/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 74/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 75/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 76/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 77/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 78/300
 - 23s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9752
Epoch 79/300
 - 23s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 80/300
 - 23s - loss: 0.0091 - val_loss: 0.0093
 - val_f1: 0.9774
Epoch 81/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 82/300
 - 23s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 83/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 84/300
 - 23s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 85/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 86/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 87/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 88/300
 - 23s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 89/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 90/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 91/300
 - 23s - loss: 0.0089 - val_loss: 0.0083
2019-12-25 17:18:41,494 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9777
Epoch 92/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 93/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 94/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 95/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 96/300
 - 23s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 97/300
 - 23s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 98/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 99/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 100/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 101/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 102/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 103/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 104/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 105/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 106/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 107/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 108/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 109/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 110/300
 - 23s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 111/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 112/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 113/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 114/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 115/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 116/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 117/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 118/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 119/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 120/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 121/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
2019-12-25 17:40:49,343 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9777
Epoch 122/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 123/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 124/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 125/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 126/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 127/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 128/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 129/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 130/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 131/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 132/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 133/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 134/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 135/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 136/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 137/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 138/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 139/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 140/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 141/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 142/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 143/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 144/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 145/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 146/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 147/300
 - 23s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 148/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 149/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 150/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 151/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
2019-12-25 18:03:01,260 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9778
Epoch 152/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 153/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 154/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 155/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 156/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 157/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 158/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 159/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 160/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 161/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 162/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 163/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 164/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 165/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 166/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 167/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 168/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 169/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 170/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 171/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 172/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 173/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 174/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 175/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 176/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 177/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 178/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 179/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 180/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 181/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
2019-12-25 18:25:09,437 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 183/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 184/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 185/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 186/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 187/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 188/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 189/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 190/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 191/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 192/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 193/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 194/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 195/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 196/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 197/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 198/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 199/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 200/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 201/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 202/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 203/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 204/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 205/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 206/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 207/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 208/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 209/300
 - 23s - loss: 0.0084 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 210/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 211/300
 - 23s - loss: 0.0084 - val_loss: 0.0080
2019-12-25 18:47:22,973 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9779
Epoch 212/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 213/300
 - 23s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 214/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 215/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 216/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 217/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 218/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 219/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 220/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 221/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 222/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 223/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 224/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 225/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 226/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 227/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 228/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 229/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 230/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 231/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 232/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 233/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 234/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 235/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 236/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 237/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 238/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 239/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 240/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 241/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
2019-12-25 19:09:31,436 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9783
Epoch 242/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 243/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 244/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 245/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 246/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 247/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 248/300
 - 23s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 249/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 250/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 251/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 252/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 253/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 254/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 255/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 256/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 257/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 258/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 259/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 260/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 261/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 262/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 263/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 264/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 265/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 266/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 267/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 268/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 269/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 270/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 271/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
2019-12-25 19:31:44,533 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9786
Epoch 272/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 273/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 274/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 275/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 276/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 277/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 278/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 279/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 280/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 281/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 282/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 283/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 284/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 285/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 286/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 287/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 288/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 289/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 290/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 291/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 292/300
 - 23s - loss: 0.0083 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 293/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 294/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 295/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 296/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 297/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 298/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 299/300
 - 23s - loss: 0.0082 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 300/300
 - 23s - loss: 0.0082 - val_loss: 0.0079
2019-12-25 19:53:29,956 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-25 19:54:23,409 [INFO] Last epoch loss evaluation: train_loss = 0.007712, val_loss = 0.007767
2019-12-25 19:54:23,455 [INFO] Training complete. time_to_train = 15479.48 sec, 257.99 min
2019-12-25 19:54:23,463 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep4/best_model.pickle
2019-12-25 19:54:23,529 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep4/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-25 19:54:23,909 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep4/training_error_history.png
2019-12-25 19:54:24,038 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep4/training_f1_history.png
2019-12-25 19:54:24,038 [INFO] Making predictions on training, validation, testing data
2019-12-25 19:56:08,297 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 19:56:20,481 [INFO] Dataset: Testing. Classification report below
2019-12-25 19:56:20,481 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       440
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.43      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.70      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-25 19:56:20,481 [INFO] Overall accuracy (micro avg): 0.9836542274991944
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-25 19:56:34,391 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.6998                       0.6898                0.0044                   0.3102  0.6772
2  Weighted avg        0.9910         0.9783                       0.9837                0.0498                   0.0163  0.9786
2019-12-25 19:56:46,552 [INFO] Dataset: Validation. Classification report below
2019-12-25 19:56:46,553 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.51      0.61      5596
   DoS attacks-Slowloris       0.95      0.97      0.96       439
          FTP-BruteForce       0.71      0.87      0.78      7718
           Infilteration       0.40      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.70      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-25 19:56:46,553 [INFO] Overall accuracy (micro avg): 0.9836727927905596
2019-12-25 19:57:00,349 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7004                       0.6902                0.0044                   0.3098  0.6790
2  Weighted avg        0.9910         0.9780                       0.9837                0.0498                   0.0163  0.9786
2019-12-25 19:57:40,078 [INFO] Dataset: Training. Classification report below
2019-12-25 19:57:40,078 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.70      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       1.00      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.51      0.61     16787
   DoS attacks-Slowloris       0.96      0.99      0.98      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.49      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-25 19:57:40,078 [INFO] Overall accuracy (micro avg): 0.9837012035351068
2019-12-25 19:58:25,151 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7054                       0.6903                0.0044                   0.3097  0.6788
2  Weighted avg        0.9911         0.9788                       0.9837                0.0497                   0.0163  0.9786
2019-12-25 19:58:25,202 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep4/selected_ids18_subset_dbn_deep_rep4_results.xlsx
2019-12-25 19:58:25,209 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-25 19:58:25,304 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_deep_rep5
2019-12-25 19:58:25,304 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_deep_rep5/run_log.log
2019-12-25 19:58:25,304 [INFO] ================= Running experiment no. 1  ================= 

2019-12-25 19:58:25,304 [INFO] Experiment parameters given below
2019-12-25 19:58:25,304 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_deep_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 36], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.6], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_deep_rep5'}
2019-12-25 19:58:25,304 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_deep_rep5/tf_logs_run_2019_12_25-19_58_25
2019-12-25 19:58:25,304 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-25 19:58:25,314 [INFO] Reading X, y files
2019-12-25 19:58:25,314 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-25 19:58:31,448 [INFO] Reading complete. time_to_read=6.13 seconds
2019-12-25 19:58:31,448 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-25 19:58:33,134 [INFO] Reading complete. time_to_read=1.69 seconds
2019-12-25 19:58:33,134 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-25 19:58:34,794 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-25 19:58:34,794 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-25 19:58:35,274 [INFO] Reading complete. time_to_read=0.48 seconds
2019-12-25 19:58:35,274 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-25 19:58:35,471 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-25 19:58:35,471 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-25 19:58:35,646 [INFO] Reading complete. time_to_read=0.17 seconds
2019-12-25 19:58:39,561 [INFO] Initializing model
2019-12-25 19:58:39,561 [INFO] Training model
2019-12-25 19:58:39,562 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-25 19:59:04,610 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 09aa443b89658bee283164e2922384e89352846b
2019-12-25 19:59:04,610 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9779
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.37, time = 11.08s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -51.74, time = 23.18s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -57.85, time = 21.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.35, time = 21.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -71.30, time = 21.17s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -78.70, time = 21.15s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -86.40, time = 21.11s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -94.16, time = 21.07s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -101.93, time = 21.02s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -109.65, time = 20.89s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -117.39, time = 20.77s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -125.14, time = 20.67s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -132.87, time = 20.62s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -140.63, time = 20.60s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -148.37, time = 20.56s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -156.10, time = 20.30s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -163.83, time = 20.10s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -171.55, time = 20.03s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -179.25, time = 19.89s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -186.95, time = 19.71s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -194.65, time = 19.58s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -202.35, time = 19.47s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -210.05, time = 19.38s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -217.76, time = 19.33s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -225.46, time = 19.29s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -233.18, time = 19.27s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -240.90, time = 19.28s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -248.62, time = 19.22s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -256.34, time = 19.20s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -264.07, time = 19.18s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -271.80, time = 19.17s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -279.52, time = 19.17s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -287.26, time = 19.16s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -295.00, time = 19.17s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -302.73, time = 19.13s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -310.48, time = 19.13s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -318.23, time = 19.11s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -325.98, time = 19.11s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -333.74, time = 19.11s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -341.49, time = 19.09s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -349.25, time = 19.07s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -357.02, time = 19.07s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -364.79, time = 19.07s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -372.58, time = 19.07s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -380.35, time = 19.06s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -388.14, time = 19.06s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -395.93, time = 19.05s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -403.72, time = 19.05s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -411.52, time = 19.06s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -419.32, time = 19.04s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -70.75, time = 8.74s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.16, time = 15.61s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -69.63, time = 14.27s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -69.07, time = 14.27s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -68.51, time = 14.27s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.92, time = 14.26s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -67.31, time = 14.28s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.69, time = 14.25s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -66.05, time = 14.25s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -65.40, time = 14.24s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -64.73, time = 14.25s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -64.05, time = 14.24s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -63.33, time = 14.24s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -62.61, time = 14.24s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.87, time = 14.24s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -61.11, time = 14.24s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.33, time = 14.24s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -59.55, time = 14.25s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.74, time = 14.24s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.92, time = 14.24s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.07, time = 14.24s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.23, time = 14.25s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.37, time = 14.24s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.48, time = 14.25s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.61, time = 14.25s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -52.71, time = 14.17s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -51.82, time = 13.98s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -50.92, time = 13.96s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -49.99, time = 13.96s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -49.08, time = 13.97s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -48.18, time = 13.96s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -47.26, time = 13.97s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -46.35, time = 13.96s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -45.44, time = 13.96s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -44.54, time = 13.96s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -43.65, time = 13.96s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -42.76, time = 13.97s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -41.88, time = 13.97s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -41.02, time = 13.98s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -40.17, time = 13.98s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -39.31, time = 13.99s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -38.49, time = 13.97s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -37.68, time = 13.98s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -36.88, time = 14.34s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -36.10, time = 13.96s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -35.33, time = 13.96s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -34.58, time = 13.96s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -33.84, time = 13.97s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -33.14, time = 13.96s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -32.42, time = 13.96s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -36.99, time = 4.79s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -36.24, time = 7.96s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.07, time = 7.96s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -35.93, time = 7.96s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.78, time = 7.94s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.64, time = 7.94s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -35.48, time = 7.94s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -35.33, time = 7.94s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -35.17, time = 7.93s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -35.00, time = 7.93s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -34.84, time = 7.94s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -34.67, time = 7.94s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -34.50, time = 7.94s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -34.31, time = 7.95s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -34.13, time = 7.93s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -33.94, time = 7.92s2019-12-25 20:34:01,560 [INFO] Pretraining Complete
2019-12-25 20:34:01,583 [INFO] Getting pretrained weights
2019-12-25 20:34:01,583 [INFO] Creating and initializing feed forward neural network
2019-12-25 20:34:02,370 [WARNING] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
2019-12-25 20:34:02,411 [INFO] _________________________________________________________________
2019-12-25 20:34:02,411 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-25 20:34:02,411 [INFO] =================================================================
2019-12-25 20:34:02,411 [INFO] dense_57 (Dense)             (None, 128)               9984      
2019-12-25 20:34:02,411 [INFO] _________________________________________________________________
2019-12-25 20:34:02,411 [INFO] batch_normalization_43 (Batc (None, 128)               512       
2019-12-25 20:34:02,411 [INFO] _________________________________________________________________
2019-12-25 20:34:02,411 [INFO] dropout_43 (Dropout)         (None, 128)               0         
2019-12-25 20:34:02,411 [INFO] _________________________________________________________________
2019-12-25 20:34:02,411 [INFO] dense_58 (Dense)             (None, 64)                8256      
2019-12-25 20:34:02,411 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] batch_normalization_44 (Batc (None, 64)                256       
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] dropout_44 (Dropout)         (None, 64)                0         
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] dense_59 (Dense)             (None, 36)                2340      
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] batch_normalization_45 (Batc (None, 36)                144       
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] dropout_45 (Dropout)         (None, 36)                0         
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:02,412 [INFO] dense_60 (Dense)             (None, 15)                555       
2019-12-25 20:34:02,412 [INFO] =================================================================
2019-12-25 20:34:02,412 [INFO] Total params: 22,047
2019-12-25 20:34:02,412 [INFO] Trainable params: 21,591
2019-12-25 20:34:02,412 [INFO] Non-trainable params: 456
2019-12-25 20:34:02,412 [INFO] _________________________________________________________________
2019-12-25 20:34:07,507 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -33.75, time = 7.96s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -33.56, time = 7.92s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -33.36, time = 7.92s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -33.15, time = 7.92s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -32.94, time = 7.92s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -32.72, time = 7.92s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -32.51, time = 7.92s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -32.28, time = 7.93s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -32.05, time = 7.93s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -31.82, time = 7.92s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -31.58, time = 7.92s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -31.34, time = 7.92s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -31.09, time = 7.92s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -30.83, time = 7.92s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -30.58, time = 7.92s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -30.31, time = 7.93s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -30.04, time = 7.93s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -29.76, time = 7.92s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -29.49, time = 7.92s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -29.20, time = 7.92s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -28.92, time = 7.92s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -28.62, time = 7.93s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -28.33, time = 7.93s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -28.02, time = 7.93s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -27.71, time = 7.93s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -27.40, time = 7.93s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -27.09, time = 7.93s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -26.77, time = 7.93s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -26.45, time = 7.92s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -26.11, time = 7.87s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -25.79, time = 7.82s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -25.47, time = 7.79s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -25.14, time = 7.77s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -24.80, time = 7.77s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 24s - loss: 0.0862 - val_loss: 0.0588
 - val_f1: 0.7826
Epoch 2/300
 - 23s - loss: 0.0573 - val_loss: 0.0430
 - val_f1: 0.8839
Epoch 3/300
 - 23s - loss: 0.0496 - val_loss: 0.0394
 - val_f1: 0.8866
Epoch 4/300
 - 23s - loss: 0.0463 - val_loss: 0.0377
 - val_f1: 0.8909
Epoch 5/300
 - 23s - loss: 0.0446 - val_loss: 0.0375
 - val_f1: 0.8970
Epoch 6/300
 - 23s - loss: 0.0436 - val_loss: 0.0369
 - val_f1: 0.8994
Epoch 7/300
 - 23s - loss: 0.0428 - val_loss: 0.0358
 - val_f1: 0.8992
Epoch 8/300
 - 23s - loss: 0.0420 - val_loss: 0.0348
 - val_f1: 0.9152
Epoch 9/300
 - 23s - loss: 0.0412 - val_loss: 0.0342
 - val_f1: 0.9155
Epoch 10/300
 - 23s - loss: 0.0404 - val_loss: 0.0336
 - val_f1: 0.9159
Epoch 11/300
 - 23s - loss: 0.0394 - val_loss: 0.0331
 - val_f1: 0.9154
Epoch 12/300
 - 23s - loss: 0.0386 - val_loss: 0.0326
 - val_f1: 0.9169
Epoch 13/300
 - 23s - loss: 0.0375 - val_loss: 0.0307
 - val_f1: 0.9174
Epoch 14/300
 - 23s - loss: 0.0365 - val_loss: 0.0422
 - val_f1: 0.8948
Epoch 15/300
 - 23s - loss: 0.0360 - val_loss: 0.0294
 - val_f1: 0.9176
Epoch 16/300
 - 23s - loss: 0.0329 - val_loss: 0.0248
 - val_f1: 0.9179
Epoch 17/300
 - 23s - loss: 0.0314 - val_loss: 0.0236
 - val_f1: 0.9188
Epoch 18/300
 - 23s - loss: 0.0306 - val_loss: 0.0275
 - val_f1: 0.9130
Epoch 19/300
 - 23s - loss: 0.0302 - val_loss: 0.0232
 - val_f1: 0.9179
Epoch 20/300
 - 23s - loss: 0.0296 - val_loss: 0.0230
 - val_f1: 0.9179
Epoch 21/300
 - 23s - loss: 0.0288 - val_loss: 0.0231
 - val_f1: 0.9184
Epoch 22/300
 - 23s - loss: 0.0282 - val_loss: 0.0231
 - val_f1: 0.9179
Epoch 23/300
 - 23s - loss: 0.0277 - val_loss: 0.0224
 - val_f1: 0.9207
Epoch 24/300
 - 23s - loss: 0.0274 - val_loss: 0.0221
 - val_f1: 0.9291
Epoch 25/300
 - 23s - loss: 0.0265 - val_loss: 0.0195
 - val_f1: 0.9434
Epoch 26/300
 - 23s - loss: 0.0247 - val_loss: 0.0193
 - val_f1: 0.9419
Epoch 27/300
 - 23s - loss: 0.0230 - val_loss: 0.0168
 - val_f1: 0.9490
Epoch 28/300
 - 23s - loss: 0.0202 - val_loss: 0.0131
 - val_f1: 0.9588
Epoch 29/300
 - 23s - loss: 0.0193 - val_loss: 0.0225
 - val_f1: 0.9124
Epoch 30/300
 - 23s - loss: 0.0190 - val_loss: 0.0130
 - val_f1: 0.9595
Epoch 31/300
 - 23s - loss: 0.0186 - val_loss: 0.0129
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-25 20:57:11,828 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9597
Epoch 32/300
 - 23s - loss: 0.0181 - val_loss: 0.0128
 - val_f1: 0.9596
Epoch 33/300
 - 23s - loss: 0.0180 - val_loss: 0.0127
 - val_f1: 0.9626
Epoch 34/300
 - 23s - loss: 0.0174 - val_loss: 0.0126
 - val_f1: 0.9614
Epoch 35/300
 - 23s - loss: 0.0170 - val_loss: 0.0285
 - val_f1: 0.8685
Epoch 36/300
 - 23s - loss: 0.0165 - val_loss: 0.0126
 - val_f1: 0.9615
Epoch 37/300
 - 23s - loss: 0.0163 - val_loss: 0.0156
 - val_f1: 0.9544
Epoch 38/300
 - 23s - loss: 0.0160 - val_loss: 0.0124
 - val_f1: 0.9645
Epoch 39/300
 - 23s - loss: 0.0159 - val_loss: 0.0121
 - val_f1: 0.9671
Epoch 40/300
 - 23s - loss: 0.0156 - val_loss: 0.0121
 - val_f1: 0.9651
Epoch 41/300
 - 23s - loss: 0.0154 - val_loss: 0.0120
 - val_f1: 0.9622
Epoch 42/300
 - 23s - loss: 0.0152 - val_loss: 0.0119
 - val_f1: 0.9634
Epoch 43/300
 - 23s - loss: 0.0151 - val_loss: 0.0119
 - val_f1: 0.9619
Epoch 44/300
 - 23s - loss: 0.0150 - val_loss: 0.0423
 - val_f1: 0.8482
Epoch 45/300
 - 23s - loss: 0.0148 - val_loss: 0.0118
 - val_f1: 0.9625
Epoch 46/300
 - 23s - loss: 0.0146 - val_loss: 0.0327
 - val_f1: 0.8712
Epoch 47/300
 - 23s - loss: 0.0144 - val_loss: 0.0112
 - val_f1: 0.9676
Epoch 48/300
 - 23s - loss: 0.0142 - val_loss: 0.0109
 - val_f1: 0.9655
Epoch 49/300
 - 23s - loss: 0.0141 - val_loss: 0.0108
 - val_f1: 0.9708
Epoch 50/300
 - 23s - loss: 0.0139 - val_loss: 0.0260
 - val_f1: 0.9162
Epoch 51/300
 - 23s - loss: 0.0138 - val_loss: 0.0104
 - val_f1: 0.9694
Epoch 52/300
 - 23s - loss: 0.0135 - val_loss: 0.0572
 - val_f1: 0.8478
Epoch 53/300
 - 23s - loss: 0.0132 - val_loss: 0.0101
 - val_f1: 0.9722
Epoch 54/300
 - 23s - loss: 0.0130 - val_loss: 0.0101
 - val_f1: 0.9724
Epoch 55/300
 - 23s - loss: 0.0129 - val_loss: 0.0099
 - val_f1: 0.9724
Epoch 56/300
 - 23s - loss: 0.0127 - val_loss: 0.0099
 - val_f1: 0.9745
Epoch 57/300
 - 23s - loss: 0.0127 - val_loss: 0.0505
 - val_f1: 0.8786
Epoch 58/300
 - 23s - loss: 0.0124 - val_loss: 0.0097
 - val_f1: 0.9709
Epoch 59/300
 - 23s - loss: 0.0123 - val_loss: 0.0098
 - val_f1: 0.9724
Epoch 60/300
 - 23s - loss: 0.0122 - val_loss: 0.0096
 - val_f1: 0.9724
Epoch 61/300
 - 23s - loss: 0.0118 - val_loss: 0.0095
2019-12-25 21:19:47,528 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9732
Epoch 62/300
 - 23s - loss: 0.0116 - val_loss: 0.0095
 - val_f1: 0.9724
Epoch 63/300
 - 23s - loss: 0.0115 - val_loss: 0.0094
 - val_f1: 0.9750
Epoch 64/300
 - 23s - loss: 0.0113 - val_loss: 0.0101
 - val_f1: 0.9723
Epoch 65/300
 - 23s - loss: 0.0112 - val_loss: 0.0092
 - val_f1: 0.9759
Epoch 66/300
 - 23s - loss: 0.0109 - val_loss: 0.0091
 - val_f1: 0.9759
Epoch 67/300
 - 23s - loss: 0.0108 - val_loss: 0.0090
 - val_f1: 0.9727
Epoch 68/300
 - 23s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9762
Epoch 69/300
 - 23s - loss: 0.0106 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 70/300
 - 23s - loss: 0.0106 - val_loss: 0.0089
 - val_f1: 0.9769
Epoch 71/300
 - 23s - loss: 0.0105 - val_loss: 0.0089
 - val_f1: 0.9770
Epoch 72/300
 - 23s - loss: 0.0105 - val_loss: 0.0088
 - val_f1: 0.9771
Epoch 73/300
 - 23s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9769
Epoch 74/300
 - 23s - loss: 0.0103 - val_loss: 0.0087
 - val_f1: 0.9752
Epoch 75/300
 - 23s - loss: 0.0102 - val_loss: 0.0087
 - val_f1: 0.9775
Epoch 76/300
 - 23s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9746
Epoch 77/300
 - 23s - loss: 0.0102 - val_loss: 0.0086
 - val_f1: 0.9773
Epoch 78/300
 - 23s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9774
Epoch 79/300
 - 23s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9775
Epoch 80/300
 - 23s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9751
Epoch 81/300
 - 23s - loss: 0.0100 - val_loss: 0.0235
 - val_f1: 0.9302
Epoch 82/300
 - 23s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9775
Epoch 83/300
 - 23s - loss: 0.0099 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 84/300
 - 23s - loss: 0.0099 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 85/300
 - 23s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 86/300
 - 23s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 87/300
 - 23s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9766
Epoch 88/300
 - 23s - loss: 0.0097 - val_loss: 0.0084
 - val_f1: 0.9753
Epoch 89/300
 - 23s - loss: 0.0097 - val_loss: 0.0084
 - val_f1: 0.9754
Epoch 90/300
 - 23s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9752
Epoch 91/300
 - 23s - loss: 0.0096 - val_loss: 0.0173
2019-12-25 21:42:22,582 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9392
Epoch 92/300
 - 23s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 93/300
 - 23s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 94/300
 - 23s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 95/300
 - 23s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 96/300
 - 23s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 97/300
 - 23s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9754
Epoch 98/300
 - 23s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9754
Epoch 99/300
 - 23s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 100/300
 - 23s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9774
Epoch 101/300
 - 23s - loss: 0.0095 - val_loss: 0.0183
 - val_f1: 0.9598
Epoch 102/300
 - 23s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 103/300
 - 23s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 104/300
 - 23s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9753
Epoch 105/300
 - 23s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 106/300
 - 23s - loss: 0.0094 - val_loss: 0.0249
 - val_f1: 0.9295
Epoch 107/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9754
Epoch 108/300
 - 23s - loss: 0.0093 - val_loss: 0.0230
 - val_f1: 0.9154
Epoch 109/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 110/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 111/300
 - 23s - loss: 0.0092 - val_loss: 0.0213
 - val_f1: 0.9348
Epoch 112/300
 - 23s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 113/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 114/300
 - 23s - loss: 0.0092 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 115/300
 - 23s - loss: 0.0092 - val_loss: 0.0143
 - val_f1: 0.9670
Epoch 116/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 117/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9755
Epoch 118/300
 - 23s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 119/300
 - 23s - loss: 0.0092 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 120/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 121/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
2019-12-25 22:04:58,440 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9776
Epoch 122/300
 - 23s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 123/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 124/300
 - 23s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 125/300
 - 23s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 126/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 127/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9754
Epoch 128/300
 - 23s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 129/300
 - 23s - loss: 0.0091 - val_loss: 0.0391
 - val_f1: 0.8973
Epoch 130/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 131/300
 - 23s - loss: 0.0091 - val_loss: 0.0188
 - val_f1: 0.9409
Epoch 132/300
 - 23s - loss: 0.0090 - val_loss: 0.0143
 - val_f1: 0.9673
Epoch 133/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 134/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 135/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 136/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 137/300
 - 23s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9753
Epoch 138/300
 - 23s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 139/300
 - 23s - loss: 0.0090 - val_loss: 0.0118
 - val_f1: 0.9672
Epoch 140/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 141/300
 - 23s - loss: 0.0090 - val_loss: 0.0329
 - val_f1: 0.8960
Epoch 142/300
 - 23s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9762
Epoch 143/300
 - 23s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 144/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 145/300
 - 23s - loss: 0.0089 - val_loss: 0.0184
 - val_f1: 0.9540
Epoch 146/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 147/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 148/300
 - 23s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 149/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 150/300
 - 23s - loss: 0.0089 - val_loss: 0.0148
 - val_f1: 0.9502
Epoch 151/300
 - 23s - loss: 0.0089 - val_loss: 0.0083
2019-12-25 22:27:34,219 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9777
Epoch 152/300
 - 23s - loss: 0.0089 - val_loss: 0.0168
 - val_f1: 0.9514
Epoch 153/300
 - 23s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 154/300
 - 23s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 155/300
 - 23s - loss: 0.0089 - val_loss: 0.0259
 - val_f1: 0.9137
Epoch 156/300
 - 23s - loss: 0.0089 - val_loss: 0.0165
 - val_f1: 0.9662
Epoch 157/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 158/300
 - 23s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 159/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 160/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 161/300
 - 23s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 162/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 163/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 164/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 165/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 166/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9754
Epoch 167/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 168/300
 - 23s - loss: 0.0088 - val_loss: 0.0242
 - val_f1: 0.9141
Epoch 169/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 170/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 171/300
 - 23s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 172/300
 - 23s - loss: 0.0088 - val_loss: 0.0274
 - val_f1: 0.9180
Epoch 173/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 174/300
 - 23s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 175/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 176/300
 - 23s - loss: 0.0088 - val_loss: 0.0258
 - val_f1: 0.9127
Epoch 177/300
 - 23s - loss: 0.0088 - val_loss: 0.0124
 - val_f1: 0.9674
Epoch 178/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 179/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 180/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 181/300
 - 23s - loss: 0.0088 - val_loss: 0.0080
2019-12-25 22:50:10,506 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/300
 - 23s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 183/300
 - 23s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 184/300
 - 23s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 185/300
 - 23s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 186/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 187/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 188/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 189/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 190/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 191/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 192/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 193/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 194/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 195/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 196/300
 - 23s - loss: 0.0087 - val_loss: 0.0125
 - val_f1: 0.9682
Epoch 197/300
 - 23s - loss: 0.0087 - val_loss: 0.0188
 - val_f1: 0.9552
Epoch 198/300
 - 23s - loss: 0.0087 - val_loss: 0.0129
 - val_f1: 0.9672
Epoch 199/300
 - 23s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9702
Epoch 200/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 201/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 202/300
 - 23s - loss: 0.0087 - val_loss: 0.0120
 - val_f1: 0.9671
Epoch 203/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 204/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 205/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 206/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 207/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 208/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 209/300
 - 23s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 210/300
 - 23s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9754
Epoch 211/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
2019-12-25 23:12:48,283 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9777
Epoch 212/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 213/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 214/300
 - 23s - loss: 0.0086 - val_loss: 0.0181
 - val_f1: 0.9584
Epoch 215/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 216/300
 - 23s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 217/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 218/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 219/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 220/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 221/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 222/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 223/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 224/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 225/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 226/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 227/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 228/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 229/300
 - 23s - loss: 0.0086 - val_loss: 0.0232
 - val_f1: 0.9346
Epoch 230/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 231/300
 - 23s - loss: 0.0086 - val_loss: 0.0218
 - val_f1: 0.9321
Epoch 232/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 233/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 234/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9757
Epoch 235/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 236/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 237/300
 - 23s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 238/300
 - 23s - loss: 0.0086 - val_loss: 0.0088
 - val_f1: 0.9742
Epoch 239/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9755
Epoch 240/300
 - 23s - loss: 0.0086 - val_loss: 0.0189
 - val_f1: 0.9385
Epoch 241/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
2019-12-25 23:35:24,893 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9780
Epoch 242/300
 - 23s - loss: 0.0086 - val_loss: 0.0134
 - val_f1: 0.9670
Epoch 243/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 244/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 245/300
 - 23s - loss: 0.0085 - val_loss: 0.0317
 - val_f1: 0.9126
Epoch 246/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 247/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 248/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 249/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 250/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 251/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 252/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 253/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 254/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 255/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 256/300
 - 23s - loss: 0.0085 - val_loss: 0.0186
 - val_f1: 0.9281
Epoch 257/300
 - 23s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 258/300
 - 23s - loss: 0.0085 - val_loss: 0.0255
 - val_f1: 0.9174
Epoch 259/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 260/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 261/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 262/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 263/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 264/300
 - 23s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9770
Epoch 265/300
 - 23s - loss: 0.0085 - val_loss: 0.0245
 - val_f1: 0.9204
Epoch 266/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 267/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 268/300
 - 23s - loss: 0.0085 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 269/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 270/300
 - 23s - loss: 0.0085 - val_loss: 0.0122
 - val_f1: 0.9652
Epoch 271/300
 - 23s - loss: 0.0086 - val_loss: 0.0080
2019-12-25 23:58:02,271 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9779
Epoch 272/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 273/300
 - 23s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 274/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 275/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 276/300
 - 23s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 277/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 278/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 279/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 280/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 281/300
 - 23s - loss: 0.0085 - val_loss: 0.0194
 - val_f1: 0.9341
Epoch 282/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 283/300
 - 23s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 284/300
 - 23s - loss: 0.0085 - val_loss: 0.0171
 - val_f1: 0.9418
Epoch 285/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 286/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 287/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 288/300
 - 23s - loss: 0.0085 - val_loss: 0.0132
 - val_f1: 0.9671
Epoch 289/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 290/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 291/300
 - 23s - loss: 0.0085 - val_loss: 0.0294
 - val_f1: 0.9160
Epoch 292/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 293/300
 - 23s - loss: 0.0085 - val_loss: 0.0144
 - val_f1: 0.9465
Epoch 294/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 295/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 296/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 297/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 298/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 299/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 300/300
 - 23s - loss: 0.0085 - val_loss: 0.0080
2019-12-26 00:20:15,919 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 00:21:10,448 [INFO] Last epoch loss evaluation: train_loss = 0.007917, val_loss = 0.007942
2019-12-26 00:21:10,496 [INFO] Training complete. time_to_train = 15750.93 sec, 262.52 min
2019-12-26 00:21:10,505 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_deep_rep5/best_model.pickle
2019-12-26 00:21:10,574 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep5/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 00:21:10,994 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep5/training_error_history.png
2019-12-26 00:21:11,141 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep5/training_f1_history.png
2019-12-26 00:21:11,141 [INFO] Making predictions on training, validation, testing data
2019-12-26 00:22:58,931 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 00:23:11,147 [INFO] Dataset: Testing. Classification report below
2019-12-26 00:23:11,147 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      0.99      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.65      0.56      0.60      5596
   DoS attacks-Slowloris       0.93      0.97      0.95       440
          FTP-BruteForce       0.71      0.78      0.74      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.67      0.69      0.67    645488
            weighted avg       0.97      0.98      0.98    645488

2019-12-26 00:23:11,147 [INFO] Overall accuracy (micro avg): 0.9829415883796445
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 00:23:25,079 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.6650                       0.6852                0.0045                   0.3148  0.6733
2  Weighted avg        0.9910         0.9730                       0.9829                0.0497                   0.0171  0.9779
2019-12-26 00:23:37,256 [INFO] Dataset: Validation. Classification report below
2019-12-26 00:23:37,256 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.77      0.97      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.65      0.55      0.60      5596
   DoS attacks-Slowloris       0.93      0.97      0.95       439
          FTP-BruteForce       0.71      0.79      0.74      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.69      0.68    645487
            weighted avg       0.97      0.98      0.98    645487

2019-12-26 00:23:37,256 [INFO] Overall accuracy (micro avg): 0.9830066291032972
2019-12-26 00:23:51,094 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9830         0.9830                       0.9830                0.0012                   0.0170  0.9830
1     Macro avg        0.9977         0.6685                       0.6850                0.0044                   0.3150  0.6755
2  Weighted avg        0.9910         0.9731                       0.9830                0.0496                   0.0170  0.9780
2019-12-26 00:24:30,832 [INFO] Dataset: Training. Classification report below
2019-12-26 00:24:30,832 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.97      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.65      0.55      0.59     16787
   DoS attacks-Slowloris       0.94      0.99      0.97      1318
          FTP-BruteForce       0.71      0.78      0.74     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.67      0.69      0.67   1936462
            weighted avg       0.97      0.98      0.98   1936462

2019-12-26 00:24:30,832 [INFO] Overall accuracy (micro avg): 0.9829281442135193
2019-12-26 00:25:16,017 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9829         0.9829                       0.9829                0.0012                   0.0171  0.9829
1     Macro avg        0.9977         0.6658                       0.6852                0.0044                   0.3148  0.6739
2  Weighted avg        0.9910         0.9730                       0.9829                0.0496                   0.0171  0.9779
2019-12-26 00:25:16,065 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_deep_rep5/selected_ids18_subset_dbn_deep_rep5_results.xlsx
2019-12-26 00:25:16,073 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-26 00:25:16,150 [INFO] ================= Finished running 15 experiments ================= 

 - val_f1: 0.9779
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2019-12-30 15:16:58,156 [INFO] Read 5 experiments from file: experiment_specs/selected_model_tests/selected_dbn.csv
2019-12-30 15:16:58,156 [INFO] ================= Started running experiments ================= 

2019-12-30 15:16:58,156 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_deep_rep1
2019-12-30 15:16:58,156 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_deep_rep1/run_log.log
2019-12-30 15:16:58,157 [INFO] ================= Running experiment no. 1  ================= 

2019-12-30 15:16:58,157 [INFO] Experiment parameters given below
2019-12-30 15:16:58,157 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_dbn_deep_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 32], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.2], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_deep_rep1'}
2019-12-30 15:16:58,157 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_deep_rep1/tf_logs_run_2019_12_30-15_16_58
2019-12-30 15:16:58,157 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-30 15:16:58,158 [INFO] Reading X, y files
2019-12-30 15:16:58,158 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-30 15:16:58,182 [INFO] NumExpr defaulting to 8 threads.
2019-12-30 15:17:04,704 [INFO] Reading complete. time_to_read=6.55 seconds
2019-12-30 15:17:04,704 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-30 15:17:06,329 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-30 15:17:06,329 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-30 15:17:06,786 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-30 15:17:06,786 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-30 15:17:07,009 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-30 15:17:07,009 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-30 15:17:07,066 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-30 15:17:07,067 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-30 15:17:07,086 [INFO] Reading complete. time_to_read=0.02 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6001 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6017 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6018 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6019 thread 3 bound to OS proc set 3
2019-12-30 15:17:14,408 [INFO] Initializing model
2019-12-30 15:17:14,409 [INFO] Training model
2019-12-30 15:17:14,409 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-30 15:17:53,755 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 9157802ed12986447b8e6e653ad2293b908ba599
2019-12-30 15:17:53,755 [INFO] Pretraining Deep Belief Network
[BernoulliRBM] Iteration 1, pseudo-likelihood = -66.32, time = 15.24s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -98.12, time = 26.09s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -127.31, time = 25.42s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -157.48, time = 25.00s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -188.33, time = 24.52s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -219.51, time = 24.39s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -250.54, time = 24.31s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -281.45, time = 24.43s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -312.72, time = 24.42s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -343.89, time = 24.40s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -375.01, time = 24.40s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -406.13, time = 24.38s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -437.37, time = 24.37s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -468.51, time = 24.36s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -499.69, time = 24.36s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -530.97, time = 24.35s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -562.44, time = 24.35s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -593.47, time = 24.35s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -625.14, time = 24.35s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -656.89, time = 24.36s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -688.71, time = 24.43s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -720.65, time = 25.70s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -752.54, time = 25.51s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -784.52, time = 24.30s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -816.51, time = 24.33s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -848.49, time = 24.31s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -880.49, time = 24.28s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -912.61, time = 24.30s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -944.81, time = 24.28s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -976.99, time = 24.27s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -1009.13, time = 24.28s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -1041.14, time = 24.28s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -1073.09, time = 24.56s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -1105.05, time = 24.37s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -1137.03, time = 24.83s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -1169.12, time = 25.50s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -1201.21, time = 25.79s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1233.33, time = 25.54s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1265.41, time = 24.98s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1297.52, time = 26.21s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1329.61, time = 26.96s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1361.72, time = 25.99s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1393.83, time = 26.00s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1425.93, time = 24.76s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1458.00, time = 24.57s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1490.02, time = 24.87s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1522.05, time = 24.76s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1554.09, time = 24.60s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1586.12, time = 24.29s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1618.20, time = 24.28s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.96, time = 9.92s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.61, time = 15.22s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.26, time = 15.05s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.21, time = 14.97s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.53, time = 14.99s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.76, time = 14.93s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.24, time = 14.95s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -3.79, time = 14.94s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.57, time = 14.94s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.43, time = 14.94s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -3.32, time = 14.94s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -3.23, time = 14.92s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.08, time = 14.95s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.00, time = 14.99s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -2.95, time = 15.01s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -2.90, time = 15.04s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.87, time = 15.05s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -2.76, time = 15.06s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.70, time = 15.07s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.55, time = 15.06s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -2.47, time = 14.99s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -2.41, time = 14.98s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -2.36, time = 15.00s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -2.32, time = 15.01s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -2.29, time = 14.99s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -2.26, time = 15.01s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -2.24, time = 15.01s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -2.22, time = 15.00s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -2.20, time = 14.99s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -2.19, time = 15.01s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -2.17, time = 15.01s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -2.16, time = 15.01s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -2.09, time = 15.00s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -2.06, time = 14.88s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -2.04, time = 14.87s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -2.02, time = 14.86s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -2.00, time = 14.86s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1.98, time = 14.85s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1.97, time = 14.86s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1.95, time = 14.85s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1.94, time = 14.84s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1.93, time = 14.84s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1.92, time = 14.86s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1.91, time = 14.85s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1.90, time = 14.85s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1.89, time = 14.87s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1.89, time = 14.88s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1.88, time = 14.87s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1.87, time = 14.87s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1.87, time = 14.88s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -11.54, time = 5.31s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.57, time = 7.99s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -8.77, time = 7.97s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -8.04, time = 7.95s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -7.32, time = 7.91s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -6.80, time = 7.90s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -6.25, time = 7.90s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -5.68, time = 7.89s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -5.41, time = 7.89s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -5.30, time = 7.89s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -5.21, time = 7.90s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -5.14, time = 7.88s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -5.10, time = 7.89s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -5.06, time = 7.88s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -5.02, time = 7.90s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -4.99, time = 7.88s2019-12-30 15:57:38,346 [INFO] Pretraining Complete
2019-12-30 15:57:38,346 [INFO] Getting pretrained weights
2019-12-30 15:57:38,346 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-30 15:57:38,361 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-30 15:57:38,433 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-30 15:57:38,641 [INFO] _________________________________________________________________
2019-12-30 15:57:38,641 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 15:57:38,642 [INFO] =================================================================
2019-12-30 15:57:38,642 [INFO] dense_1 (Dense)              (None, 128)               15872     
2019-12-30 15:57:38,642 [INFO] _________________________________________________________________
2019-12-30 15:57:38,642 [INFO] batch_normalization_1 (Batch (None, 128)               512       
2019-12-30 15:57:38,642 [INFO] _________________________________________________________________
2019-12-30 15:57:38,642 [INFO] dropout_1 (Dropout)          (None, 128)               0         
2019-12-30 15:57:38,642 [INFO] _________________________________________________________________
2019-12-30 15:57:38,642 [INFO] dense_2 (Dense)              (None, 64)                8256      
2019-12-30 15:57:38,642 [INFO] _________________________________________________________________
2019-12-30 15:57:38,642 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2019-12-30 15:57:38,642 [INFO] _________________________________________________________________
2019-12-30 15:57:38,642 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2019-12-30 15:57:38,643 [INFO] _________________________________________________________________
2019-12-30 15:57:38,643 [INFO] dense_3 (Dense)              (None, 32)                2080      
2019-12-30 15:57:38,643 [INFO] _________________________________________________________________
2019-12-30 15:57:38,643 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-30 15:57:38,643 [INFO] _________________________________________________________________
2019-12-30 15:57:38,643 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-30 15:57:38,643 [INFO] _________________________________________________________________
2019-12-30 15:57:38,643 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-30 15:57:38,643 [INFO] =================================================================
2019-12-30 15:57:38,644 [INFO] Total params: 27,269
2019-12-30 15:57:38,644 [INFO] Trainable params: 26,821
2019-12-30 15:57:38,644 [INFO] Non-trainable params: 448
2019-12-30 15:57:38,644 [INFO] _________________________________________________________________
2019-12-30 15:57:38.644307: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2019-12-30 15:57:38.663561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2019-12-30 15:57:38.663699: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56382f1b5bd0 executing computations on platform Host. Devices:
2019-12-30 15:57:38.663718: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-30 15:57:38.663802: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-12-30 15:57:38,867 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-30 15:57:39,628 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6309 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6363 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6364 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6365 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6366 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6310 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6368 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6367 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6369 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6371 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6370 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6373 thread 16 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6372 thread 15 bound to OS proc set 7

[BernoulliRBM] Iteration 17, pseudo-likelihood = -4.95, time = 7.89s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -4.93, time = 7.89s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -4.91, time = 7.90s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -4.89, time = 7.89s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -4.69, time = 7.88s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -4.64, time = 7.89s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -4.62, time = 7.89s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -4.61, time = 7.89s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -4.48, time = 7.87s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -4.46, time = 7.87s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -4.45, time = 7.87s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -4.44, time = 7.88s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -4.45, time = 7.88s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -4.44, time = 7.88s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -4.42, time = 7.88s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -4.42, time = 7.87s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -4.41, time = 7.89s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -4.40, time = 7.87s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -4.39, time = 7.88s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -4.39, time = 7.87s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -4.39, time = 7.87s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -4.39, time = 7.88s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -4.38, time = 7.86s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -4.39, time = 7.87s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -4.38, time = 7.87s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -4.37, time = 7.88s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -4.37, time = 7.86s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -4.37, time = 7.86s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -4.37, time = 7.87s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -4.36, time = 7.88s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -4.36, time = 7.86s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -4.35, time = 7.87s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -4.34, time = 7.88s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -4.36, time = 7.86s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/300
 - 61s - loss: 0.0182 - val_loss: 0.0066
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6392 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6393 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 6001 tid 6394 thread 19 bound to OS proc set 3
 - val_f1: 0.9958
Epoch 2/300
 - 59s - loss: 0.0072 - val_loss: 0.0052
 - val_f1: 0.9973
Epoch 3/300
 - 59s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9975
Epoch 4/300
 - 59s - loss: 0.0049 - val_loss: 0.0034
 - val_f1: 0.9981
Epoch 5/300
 - 59s - loss: 0.0038 - val_loss: 0.0028
 - val_f1: 0.9984
Epoch 6/300
 - 59s - loss: 0.0031 - val_loss: 0.0023
 - val_f1: 0.9985
Epoch 7/300
 - 59s - loss: 0.0028 - val_loss: 0.0019
 - val_f1: 0.9986
Epoch 8/300
 - 59s - loss: 0.0025 - val_loss: 0.0017
 - val_f1: 0.9988
Epoch 9/300
 - 59s - loss: 0.0023 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 10/300
 - 59s - loss: 0.0021 - val_loss: 0.0015
 - val_f1: 0.9990
Epoch 11/300
 - 59s - loss: 0.0020 - val_loss: 0.0014
 - val_f1: 0.9991
Epoch 12/300
 - 59s - loss: 0.0019 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 13/300
 - 59s - loss: 0.0018 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 14/300
 - 59s - loss: 0.0018 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 15/300
 - 59s - loss: 0.0017 - val_loss: 0.0013
 - val_f1: 0.9993
Epoch 16/300
 - 59s - loss: 0.0017 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 17/300
 - 59s - loss: 0.0016 - val_loss: 0.0012
 - val_f1: 0.9992
Epoch 18/300
 - 59s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 19/300
 - 59s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 20/300
 - 59s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 21/300
 - 59s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 22/300
 - 59s - loss: 0.0014 - val_loss: 0.0010
 - val_f1: 0.9993
Epoch 23/300
 - 59s - loss: 0.0014 - val_loss: 9.9307e-04
 - val_f1: 0.9994
Epoch 24/300
 - 59s - loss: 0.0014 - val_loss: 9.3953e-04
 - val_f1: 0.9994
Epoch 25/300
 - 59s - loss: 0.0013 - val_loss: 9.1110e-04
 - val_f1: 0.9994
Epoch 26/300
 - 59s - loss: 0.0013 - val_loss: 9.0838e-04
 - val_f1: 0.9994
Epoch 27/300
 - 59s - loss: 0.0013 - val_loss: 9.1023e-04
 - val_f1: 0.9994
Epoch 28/300
 - 59s - loss: 0.0012 - val_loss: 8.7682e-04
 - val_f1: 0.9994
Epoch 29/300
 - 59s - loss: 0.0012 - val_loss: 8.9213e-04
 - val_f1: 0.9995
Epoch 30/300
 - 59s - loss: 0.0012 - val_loss: 8.6843e-04
 - val_f1: 0.9995
Epoch 31/300
 - 59s - loss: 0.0011 - val_loss: 7.7020e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 16:38:42,903 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9995
Epoch 32/300
 - 59s - loss: 0.0011 - val_loss: 7.8516e-04
 - val_f1: 0.9995
Epoch 33/300
 - 59s - loss: 0.0011 - val_loss: 7.6204e-04
 - val_f1: 0.9995
Epoch 34/300
 - 59s - loss: 0.0011 - val_loss: 7.7322e-04
 - val_f1: 0.9995
Epoch 35/300
 - 59s - loss: 0.0010 - val_loss: 7.3959e-04
 - val_f1: 0.9995
Epoch 36/300
 - 59s - loss: 0.0010 - val_loss: 7.3522e-04
 - val_f1: 0.9995
Epoch 37/300
 - 59s - loss: 0.0010 - val_loss: 6.6463e-04
 - val_f1: 0.9995
Epoch 38/300
 - 59s - loss: 9.6606e-04 - val_loss: 6.5081e-04
 - val_f1: 0.9995
Epoch 39/300
 - 59s - loss: 9.6741e-04 - val_loss: 6.2548e-04
 - val_f1: 0.9996
Epoch 40/300
 - 59s - loss: 9.2432e-04 - val_loss: 6.3665e-04
 - val_f1: 0.9996
Epoch 41/300
 - 59s - loss: 9.3807e-04 - val_loss: 6.3374e-04
 - val_f1: 0.9996
Epoch 42/300
 - 59s - loss: 9.1185e-04 - val_loss: 5.9791e-04
 - val_f1: 0.9996
Epoch 43/300
 - 59s - loss: 9.1502e-04 - val_loss: 6.0912e-04
 - val_f1: 0.9996
Epoch 44/300
 - 59s - loss: 8.8240e-04 - val_loss: 6.1078e-04
 - val_f1: 0.9996
Epoch 45/300
 - 59s - loss: 8.6440e-04 - val_loss: 5.7092e-04
 - val_f1: 0.9996
Epoch 46/300
 - 59s - loss: 8.3533e-04 - val_loss: 5.7485e-04
 - val_f1: 0.9996
Epoch 47/300
 - 59s - loss: 8.3930e-04 - val_loss: 5.6304e-04
 - val_f1: 0.9996
Epoch 48/300
 - 59s - loss: 8.3496e-04 - val_loss: 5.6024e-04
 - val_f1: 0.9996
Epoch 49/300
 - 59s - loss: 8.0411e-04 - val_loss: 5.6387e-04
 - val_f1: 0.9996
Epoch 50/300
 - 59s - loss: 8.0547e-04 - val_loss: 5.8337e-04
 - val_f1: 0.9996
Epoch 51/300
 - 59s - loss: 7.9943e-04 - val_loss: 5.5370e-04
 - val_f1: 0.9996
Epoch 52/300
 - 59s - loss: 8.2155e-04 - val_loss: 5.4015e-04
 - val_f1: 0.9996
Epoch 53/300
 - 59s - loss: 7.9962e-04 - val_loss: 5.4508e-04
 - val_f1: 0.9996
Epoch 54/300
 - 59s - loss: 7.9606e-04 - val_loss: 5.4888e-04
 - val_f1: 0.9996
Epoch 55/300
 - 59s - loss: 7.5640e-04 - val_loss: 5.4192e-04
 - val_f1: 0.9996
Epoch 56/300
 - 59s - loss: 7.5978e-04 - val_loss: 5.3237e-04
 - val_f1: 0.9997
Epoch 57/300
 - 59s - loss: 7.5390e-04 - val_loss: 5.4384e-04
 - val_f1: 0.9996
Epoch 58/300
 - 60s - loss: 7.6765e-04 - val_loss: 5.5259e-04
 - val_f1: 0.9996
Epoch 59/300
 - 59s - loss: 7.5124e-04 - val_loss: 5.1199e-04
 - val_f1: 0.9996
Epoch 60/300
 - 60s - loss: 7.2951e-04 - val_loss: 5.0703e-04
 - val_f1: 0.9996
Epoch 61/300
 - 59s - loss: 7.3916e-04 - val_loss: 5.0601e-04
2019-12-30 17:18:51,381 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/300
 - 59s - loss: 7.1841e-04 - val_loss: 5.2168e-04
 - val_f1: 0.9996
Epoch 63/300
 - 59s - loss: 7.3545e-04 - val_loss: 5.0532e-04
 - val_f1: 0.9997
Epoch 64/300
 - 59s - loss: 7.2879e-04 - val_loss: 5.0596e-04
 - val_f1: 0.9997
Epoch 65/300
 - 59s - loss: 7.2306e-04 - val_loss: 4.8708e-04
 - val_f1: 0.9997
Epoch 66/300
 - 59s - loss: 6.9452e-04 - val_loss: 5.3428e-04
 - val_f1: 0.9996
Epoch 67/300
 - 59s - loss: 7.1375e-04 - val_loss: 4.9308e-04
 - val_f1: 0.9997
Epoch 68/300
 - 59s - loss: 6.9327e-04 - val_loss: 5.1431e-04
 - val_f1: 0.9996
Epoch 69/300
 - 59s - loss: 6.9373e-04 - val_loss: 4.9536e-04
 - val_f1: 0.9997
Epoch 70/300
 - 59s - loss: 6.8191e-04 - val_loss: 5.0142e-04
 - val_f1: 0.9997
Epoch 71/300
 - 59s - loss: 6.8593e-04 - val_loss: 4.7942e-04
 - val_f1: 0.9997
Epoch 72/300
 - 59s - loss: 6.6739e-04 - val_loss: 4.6324e-04
 - val_f1: 0.9997
Epoch 73/300
 - 59s - loss: 6.6457e-04 - val_loss: 4.5870e-04
 - val_f1: 0.9997
Epoch 74/300
 - 59s - loss: 6.6830e-04 - val_loss: 4.7869e-04
 - val_f1: 0.9997
Epoch 75/300
 - 59s - loss: 6.5196e-04 - val_loss: 4.7722e-04
 - val_f1: 0.9997
Epoch 76/300
 - 59s - loss: 6.5705e-04 - val_loss: 4.6161e-04
 - val_f1: 0.9997
Epoch 77/300
 - 59s - loss: 6.6366e-04 - val_loss: 4.9001e-04
 - val_f1: 0.9997
Epoch 78/300
 - 59s - loss: 6.5894e-04 - val_loss: 4.5077e-04
 - val_f1: 0.9997
Epoch 79/300
 - 59s - loss: 6.5623e-04 - val_loss: 4.8727e-04
 - val_f1: 0.9997
Epoch 80/300
 - 59s - loss: 6.3680e-04 - val_loss: 4.7084e-04
 - val_f1: 0.9997
Epoch 81/300
 - 59s - loss: 6.4882e-04 - val_loss: 4.4597e-04
 - val_f1: 0.9997
Epoch 82/300
 - 59s - loss: 6.2886e-04 - val_loss: 4.7395e-04
 - val_f1: 0.9997
Epoch 83/300
 - 59s - loss: 6.2950e-04 - val_loss: 4.7551e-04
 - val_f1: 0.9997
Epoch 84/300
 - 59s - loss: 6.2311e-04 - val_loss: 4.5402e-04
 - val_f1: 0.9997
Epoch 85/300
 - 59s - loss: 6.3452e-04 - val_loss: 4.4759e-04
 - val_f1: 0.9997
Epoch 86/300
 - 59s - loss: 6.0916e-04 - val_loss: 4.6110e-04
 - val_f1: 0.9997
Epoch 87/300
 - 59s - loss: 6.0843e-04 - val_loss: 4.6157e-04
 - val_f1: 0.9997
Epoch 88/300
 - 59s - loss: 6.1234e-04 - val_loss: 4.4148e-04
 - val_f1: 0.9997
Epoch 89/300
 - 59s - loss: 6.1624e-04 - val_loss: 4.5093e-04
 - val_f1: 0.9997
Epoch 90/300
 - 59s - loss: 6.1426e-04 - val_loss: 4.4138e-04
 - val_f1: 0.9997
Epoch 91/300
 - 59s - loss: 6.0623e-04 - val_loss: 4.5006e-04
2019-12-30 17:58:54,288 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9997
Epoch 92/300
 - 59s - loss: 6.0998e-04 - val_loss: 4.4548e-04
 - val_f1: 0.9997
Epoch 93/300
 - 59s - loss: 5.9127e-04 - val_loss: 4.3467e-04
 - val_f1: 0.9997
Epoch 94/300
 - 59s - loss: 5.8788e-04 - val_loss: 4.2469e-04
 - val_f1: 0.9997
Epoch 95/300
 - 59s - loss: 5.8922e-04 - val_loss: 4.6818e-04
 - val_f1: 0.9997
Epoch 96/300
 - 59s - loss: 6.0543e-04 - val_loss: 4.4776e-04
 - val_f1: 0.9997
Epoch 97/300
 - 59s - loss: 6.0229e-04 - val_loss: 4.4474e-04
 - val_f1: 0.9997
Epoch 98/300
 - 59s - loss: 5.7476e-04 - val_loss: 4.2062e-04
 - val_f1: 0.9997
Epoch 99/300
 - 59s - loss: 5.9116e-04 - val_loss: 4.2871e-04
 - val_f1: 0.9997
Epoch 100/300
 - 59s - loss: 5.7016e-04 - val_loss: 4.6646e-04
 - val_f1: 0.9997
Epoch 101/300
 - 59s - loss: 5.9849e-04 - val_loss: 4.4983e-04
 - val_f1: 0.9997
Epoch 102/300
 - 59s - loss: 5.7280e-04 - val_loss: 4.4564e-04
 - val_f1: 0.9997
Epoch 103/300
 - 59s - loss: 5.7461e-04 - val_loss: 4.6215e-04
 - val_f1: 0.9997
Epoch 104/300
 - 59s - loss: 5.8096e-04 - val_loss: 4.3057e-04
 - val_f1: 0.9997
Epoch 105/300
 - 59s - loss: 5.6063e-04 - val_loss: 4.3209e-04
 - val_f1: 0.9997
Epoch 106/300
 - 59s - loss: 5.7021e-04 - val_loss: 4.2211e-04
 - val_f1: 0.9997
Epoch 107/300
 - 59s - loss: 5.6525e-04 - val_loss: 4.3383e-04
 - val_f1: 0.9997
Epoch 108/300
 - 59s - loss: 5.5189e-04 - val_loss: 4.0874e-04
 - val_f1: 0.9997
Epoch 109/300
 - 59s - loss: 5.4988e-04 - val_loss: 4.2632e-04
 - val_f1: 0.9997
Epoch 110/300
 - 59s - loss: 5.5722e-04 - val_loss: 4.0531e-04
 - val_f1: 0.9997
Epoch 111/300
 - 59s - loss: 5.5827e-04 - val_loss: 4.1919e-04
 - val_f1: 0.9997
Epoch 112/300
 - 59s - loss: 5.5918e-04 - val_loss: 4.0662e-04
 - val_f1: 0.9997
Epoch 113/300
 - 59s - loss: 5.5445e-04 - val_loss: 4.0819e-04
 - val_f1: 0.9997
Epoch 114/300
 - 59s - loss: 5.5645e-04 - val_loss: 4.2185e-04
 - val_f1: 0.9997
Epoch 115/300
 - 59s - loss: 5.4098e-04 - val_loss: 4.1402e-04
 - val_f1: 0.9997
Epoch 116/300
 - 59s - loss: 5.5543e-04 - val_loss: 4.1485e-04
 - val_f1: 0.9997
Epoch 117/300
 - 59s - loss: 5.4567e-04 - val_loss: 4.3344e-04
 - val_f1: 0.9997
Epoch 118/300
 - 59s - loss: 5.3871e-04 - val_loss: 4.1409e-04
 - val_f1: 0.9997
Epoch 119/300
 - 59s - loss: 5.4786e-04 - val_loss: 4.2026e-04
 - val_f1: 0.9997
Epoch 120/300
 - 59s - loss: 5.3925e-04 - val_loss: 4.2469e-04
 - val_f1: 0.9997
Epoch 121/300
 - 59s - loss: 5.3837e-04 - val_loss: 4.1613e-04
2019-12-30 18:38:55,117 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/300
 - 59s - loss: 5.4414e-04 - val_loss: 4.0342e-04
 - val_f1: 0.9997
Epoch 123/300
 - 59s - loss: 5.2889e-04 - val_loss: 4.2971e-04
 - val_f1: 0.9997
Epoch 124/300
 - 59s - loss: 5.4509e-04 - val_loss: 4.0968e-04
 - val_f1: 0.9998
Epoch 125/300
 - 59s - loss: 5.2486e-04 - val_loss: 4.0046e-04
 - val_f1: 0.9997
Epoch 126/300
 - 59s - loss: 5.3051e-04 - val_loss: 4.0223e-04
 - val_f1: 0.9997
Epoch 127/300
 - 59s - loss: 5.2834e-04 - val_loss: 4.1650e-04
 - val_f1: 0.9997
Epoch 128/300
 - 59s - loss: 5.3151e-04 - val_loss: 4.0142e-04
 - val_f1: 0.9998
Epoch 129/300
 - 59s - loss: 5.2094e-04 - val_loss: 3.9301e-04
 - val_f1: 0.9997
Epoch 130/300
 - 59s - loss: 5.1005e-04 - val_loss: 4.1153e-04
 - val_f1: 0.9998
Epoch 131/300
 - 59s - loss: 5.1846e-04 - val_loss: 3.9550e-04
 - val_f1: 0.9998
Epoch 132/300
 - 59s - loss: 5.1975e-04 - val_loss: 3.9146e-04
 - val_f1: 0.9997
Epoch 133/300
 - 59s - loss: 5.1823e-04 - val_loss: 4.1736e-04
 - val_f1: 0.9997
Epoch 134/300
 - 59s - loss: 5.2482e-04 - val_loss: 3.8972e-04
 - val_f1: 0.9997
Epoch 135/300
 - 59s - loss: 5.1360e-04 - val_loss: 4.2145e-04
 - val_f1: 0.9997
Epoch 136/300
 - 59s - loss: 5.1643e-04 - val_loss: 3.9119e-04
 - val_f1: 0.9997
Epoch 137/300
 - 59s - loss: 4.9758e-04 - val_loss: 4.0068e-04
 - val_f1: 0.9997
Epoch 138/300
 - 59s - loss: 5.0718e-04 - val_loss: 4.0976e-04
 - val_f1: 0.9997
Epoch 139/300
 - 59s - loss: 4.9742e-04 - val_loss: 4.0114e-04
 - val_f1: 0.9998
Epoch 140/300
 - 59s - loss: 5.1753e-04 - val_loss: 4.0366e-04
 - val_f1: 0.9997
Epoch 141/300
 - 59s - loss: 5.0384e-04 - val_loss: 3.9868e-04
 - val_f1: 0.9997
Epoch 142/300
 - 59s - loss: 5.0690e-04 - val_loss: 4.0032e-04
 - val_f1: 0.9998
Epoch 143/300
 - 59s - loss: 4.8858e-04 - val_loss: 3.8693e-04
 - val_f1: 0.9998
Epoch 144/300
 - 59s - loss: 4.9197e-04 - val_loss: 3.9064e-04
 - val_f1: 0.9997
Epoch 145/300
 - 59s - loss: 4.9438e-04 - val_loss: 3.8386e-04
 - val_f1: 0.9998
Epoch 146/300
 - 59s - loss: 5.0179e-04 - val_loss: 3.8256e-04
 - val_f1: 0.9997
Epoch 147/300
 - 59s - loss: 4.9314e-04 - val_loss: 3.9386e-04
 - val_f1: 0.9997
Epoch 148/300
 - 59s - loss: 4.9292e-04 - val_loss: 3.8649e-04
 - val_f1: 0.9998
Epoch 149/300
 - 59s - loss: 4.8260e-04 - val_loss: 3.8221e-04
 - val_f1: 0.9998
Epoch 150/300
 - 59s - loss: 4.8570e-04 - val_loss: 3.8255e-04
 - val_f1: 0.9998
Epoch 151/300
 - 59s - loss: 4.9143e-04 - val_loss: 3.5540e-04
2019-12-30 19:18:55,226 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 59s - loss: 5.0036e-04 - val_loss: 3.6359e-04
 - val_f1: 0.9998
Epoch 153/300
 - 59s - loss: 4.8722e-04 - val_loss: 3.6749e-04
 - val_f1: 0.9998
Epoch 154/300
 - 59s - loss: 4.8459e-04 - val_loss: 3.6947e-04
 - val_f1: 0.9998
Epoch 155/300
 - 59s - loss: 4.7844e-04 - val_loss: 3.8026e-04
 - val_f1: 0.9998
Epoch 156/300
 - 59s - loss: 4.8769e-04 - val_loss: 3.9270e-04
 - val_f1: 0.9997
Epoch 157/300
 - 59s - loss: 4.8394e-04 - val_loss: 3.6894e-04
 - val_f1: 0.9998
Epoch 158/300
 - 59s - loss: 4.7609e-04 - val_loss: 3.8646e-04
 - val_f1: 0.9998
Epoch 159/300
 - 59s - loss: 4.7292e-04 - val_loss: 3.6513e-04
 - val_f1: 0.9998
Epoch 160/300
 - 59s - loss: 4.7195e-04 - val_loss: 3.6513e-04
 - val_f1: 0.9998
Epoch 161/300
 - 59s - loss: 4.7477e-04 - val_loss: 3.6634e-04
 - val_f1: 0.9998
Epoch 162/300
 - 59s - loss: 4.6821e-04 - val_loss: 3.6618e-04
 - val_f1: 0.9998
Epoch 163/300
 - 59s - loss: 4.7484e-04 - val_loss: 3.5347e-04
 - val_f1: 0.9998
Epoch 164/300
 - 59s - loss: 4.6416e-04 - val_loss: 3.6059e-04
 - val_f1: 0.9998
Epoch 165/300
 - 59s - loss: 4.6016e-04 - val_loss: 3.9665e-04
 - val_f1: 0.9998
Epoch 166/300
 - 59s - loss: 4.4804e-04 - val_loss: 3.5876e-04
 - val_f1: 0.9998
Epoch 167/300
 - 59s - loss: 4.5441e-04 - val_loss: 3.8697e-04
 - val_f1: 0.9998
Epoch 168/300
 - 59s - loss: 4.6910e-04 - val_loss: 3.4615e-04
 - val_f1: 0.9998
Epoch 169/300
 - 59s - loss: 4.7116e-04 - val_loss: 3.5856e-04
 - val_f1: 0.9998
Epoch 170/300
 - 59s - loss: 4.7875e-04 - val_loss: 3.5720e-04
 - val_f1: 0.9998
Epoch 171/300
 - 59s - loss: 4.5641e-04 - val_loss: 3.5727e-04
 - val_f1: 0.9998
Epoch 172/300
 - 59s - loss: 4.5469e-04 - val_loss: 3.5209e-04
 - val_f1: 0.9998
Epoch 173/300
 - 59s - loss: 4.4767e-04 - val_loss: 3.5195e-04
 - val_f1: 0.9998
Epoch 174/300
 - 59s - loss: 4.4645e-04 - val_loss: 3.5288e-04
 - val_f1: 0.9998
Epoch 175/300
 - 59s - loss: 4.5326e-04 - val_loss: 3.6609e-04
 - val_f1: 0.9998
Epoch 176/300
 - 59s - loss: 4.5390e-04 - val_loss: 3.5570e-04
 - val_f1: 0.9998
Epoch 177/300
 - 59s - loss: 4.4510e-04 - val_loss: 3.6704e-04
 - val_f1: 0.9998
Epoch 178/300
 - 59s - loss: 4.5557e-04 - val_loss: 3.3911e-04
 - val_f1: 0.9998
Epoch 179/300
 - 59s - loss: 4.6809e-04 - val_loss: 3.4029e-04
 - val_f1: 0.9998
Epoch 180/300
 - 60s - loss: 4.5945e-04 - val_loss: 3.3256e-04
 - val_f1: 0.9998
Epoch 181/300
 - 59s - loss: 4.4439e-04 - val_loss: 3.4428e-04
2019-12-30 19:58:49,937 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 59s - loss: 4.4817e-04 - val_loss: 3.4570e-04
 - val_f1: 0.9998
Epoch 183/300
 - 59s - loss: 4.3885e-04 - val_loss: 3.6623e-04
 - val_f1: 0.9997
Epoch 184/300
 - 59s - loss: 4.3234e-04 - val_loss: 3.3691e-04
 - val_f1: 0.9998
Epoch 185/300
 - 59s - loss: 4.5256e-04 - val_loss: 3.2855e-04
 - val_f1: 0.9998
Epoch 186/300
 - 59s - loss: 4.3225e-04 - val_loss: 3.5935e-04
 - val_f1: 0.9998
Epoch 187/300
 - 59s - loss: 4.5428e-04 - val_loss: 3.2722e-04
 - val_f1: 0.9998
Epoch 188/300
 - 59s - loss: 4.4928e-04 - val_loss: 3.4478e-04
 - val_f1: 0.9998
Epoch 189/300
 - 59s - loss: 4.3888e-04 - val_loss: 3.7128e-04
 - val_f1: 0.9998
Epoch 190/300
 - 59s - loss: 4.3594e-04 - val_loss: 3.4524e-04
 - val_f1: 0.9998
Epoch 191/300
 - 59s - loss: 4.3425e-04 - val_loss: 3.4687e-04
 - val_f1: 0.9998
Epoch 192/300
 - 59s - loss: 4.3979e-04 - val_loss: 3.4790e-04
 - val_f1: 0.9998
Epoch 193/300
 - 59s - loss: 4.1644e-04 - val_loss: 3.4005e-04
 - val_f1: 0.9998
Epoch 194/300
 - 59s - loss: 4.1579e-04 - val_loss: 3.2971e-04
 - val_f1: 0.9998
Epoch 195/300
 - 59s - loss: 4.3698e-04 - val_loss: 3.2351e-04
 - val_f1: 0.9998
Epoch 196/300
 - 59s - loss: 4.1855e-04 - val_loss: 3.3978e-04
 - val_f1: 0.9998
Epoch 197/300
 - 59s - loss: 4.3566e-04 - val_loss: 3.2288e-04
 - val_f1: 0.9998
Epoch 198/300
 - 59s - loss: 4.2788e-04 - val_loss: 3.5658e-04
 - val_f1: 0.9998
Epoch 199/300
 - 59s - loss: 4.2473e-04 - val_loss: 3.3877e-04
 - val_f1: 0.9998
Epoch 200/300
 - 59s - loss: 4.3530e-04 - val_loss: 3.3021e-04
 - val_f1: 0.9998
Epoch 201/300
 - 59s - loss: 4.2593e-04 - val_loss: 3.2792e-04
 - val_f1: 0.9998
Epoch 202/300
 - 59s - loss: 4.2319e-04 - val_loss: 3.3580e-04
 - val_f1: 0.9998
Epoch 203/300
 - 59s - loss: 4.2296e-04 - val_loss: 3.1796e-04
 - val_f1: 0.9998
Epoch 204/300
 - 59s - loss: 4.1045e-04 - val_loss: 3.2262e-04
 - val_f1: 0.9998
Epoch 205/300
 - 59s - loss: 4.2538e-04 - val_loss: 3.4442e-04
 - val_f1: 0.9998
Epoch 206/300
 - 59s - loss: 4.2208e-04 - val_loss: 3.2920e-04
 - val_f1: 0.9998
Epoch 207/300
 - 59s - loss: 4.2695e-04 - val_loss: 3.5100e-04
 - val_f1: 0.9998
Epoch 208/300
 - 59s - loss: 4.2087e-04 - val_loss: 3.3636e-04
 - val_f1: 0.9998
Epoch 209/300
 - 59s - loss: 4.2520e-04 - val_loss: 3.3519e-04
 - val_f1: 0.9998
Epoch 210/300
 - 59s - loss: 4.1904e-04 - val_loss: 3.1576e-04
 - val_f1: 0.9998
Epoch 211/300
 - 59s - loss: 4.1765e-04 - val_loss: 3.4614e-04
2019-12-30 20:38:55,097 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 59s - loss: 4.1640e-04 - val_loss: 3.2295e-04
 - val_f1: 0.9998
Epoch 213/300
 - 59s - loss: 4.3411e-04 - val_loss: 3.3441e-04
 - val_f1: 0.9998
Epoch 214/300
 - 59s - loss: 4.0152e-04 - val_loss: 3.3075e-04
 - val_f1: 0.9998
Epoch 215/300
 - 59s - loss: 4.1105e-04 - val_loss: 3.2517e-04
 - val_f1: 0.9998
Epoch 216/300
 - 59s - loss: 4.1020e-04 - val_loss: 3.3568e-04
 - val_f1: 0.9998
Epoch 217/300
 - 59s - loss: 4.2143e-04 - val_loss: 3.3972e-04
 - val_f1: 0.9998
Epoch 218/300
 - 59s - loss: 4.1182e-04 - val_loss: 3.1897e-04
 - val_f1: 0.9998
Epoch 219/300
 - 59s - loss: 3.9674e-04 - val_loss: 3.2641e-04
 - val_f1: 0.9998
Epoch 220/300
 - 59s - loss: 4.1388e-04 - val_loss: 3.1946e-04
 - val_f1: 0.9998
Epoch 221/300
 - 59s - loss: 4.1335e-04 - val_loss: 3.3206e-04
 - val_f1: 0.9998
Epoch 222/300
 - 59s - loss: 4.0981e-04 - val_loss: 3.4531e-04
 - val_f1: 0.9998
Epoch 223/300
 - 59s - loss: 4.0989e-04 - val_loss: 3.1819e-04
 - val_f1: 0.9998
Epoch 224/300
 - 59s - loss: 4.0474e-04 - val_loss: 3.2401e-04
 - val_f1: 0.9998
Epoch 225/300
 - 59s - loss: 4.1231e-04 - val_loss: 3.1968e-04
 - val_f1: 0.9998
Epoch 226/300
 - 59s - loss: 3.9042e-04 - val_loss: 3.2693e-04
 - val_f1: 0.9998
Epoch 227/300
 - 59s - loss: 4.0435e-04 - val_loss: 3.3924e-04
 - val_f1: 0.9998
Epoch 228/300
 - 59s - loss: 4.0539e-04 - val_loss: 3.4221e-04
 - val_f1: 0.9998
Epoch 229/300
 - 59s - loss: 3.8071e-04 - val_loss: 3.1385e-04
 - val_f1: 0.9998
Epoch 230/300
 - 59s - loss: 3.9424e-04 - val_loss: 3.2338e-04
 - val_f1: 0.9998
Epoch 231/300
 - 59s - loss: 4.1058e-04 - val_loss: 3.1441e-04
 - val_f1: 0.9998
Epoch 232/300
 - 59s - loss: 4.0242e-04 - val_loss: 3.1519e-04
 - val_f1: 0.9998
Epoch 233/300
 - 59s - loss: 4.0538e-04 - val_loss: 3.3016e-04
 - val_f1: 0.9998
Epoch 234/300
 - 59s - loss: 3.9501e-04 - val_loss: 3.0818e-04
 - val_f1: 0.9998
Epoch 235/300
 - 59s - loss: 3.9660e-04 - val_loss: 3.2873e-04
 - val_f1: 0.9998
Epoch 236/300
 - 59s - loss: 3.8005e-04 - val_loss: 3.1503e-04
 - val_f1: 0.9998
Epoch 237/300
 - 59s - loss: 3.8316e-04 - val_loss: 3.1204e-04
 - val_f1: 0.9998
Epoch 238/300
 - 59s - loss: 3.9139e-04 - val_loss: 3.2186e-04
 - val_f1: 0.9998
Epoch 239/300
 - 59s - loss: 3.8925e-04 - val_loss: 3.1695e-04
 - val_f1: 0.9998
Epoch 240/300
 - 60s - loss: 3.7849e-04 - val_loss: 3.2193e-04
 - val_f1: 0.9998
Epoch 241/300
 - 59s - loss: 3.9698e-04 - val_loss: 3.1444e-04
2019-12-30 21:18:52,289 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 59s - loss: 3.9134e-04 - val_loss: 3.1587e-04
 - val_f1: 0.9998
Epoch 243/300
 - 59s - loss: 3.9898e-04 - val_loss: 3.1578e-04
 - val_f1: 0.9998
Epoch 244/300
 - 59s - loss: 3.7119e-04 - val_loss: 3.2994e-04
 - val_f1: 0.9998
Epoch 245/300
 - 59s - loss: 3.9963e-04 - val_loss: 3.2306e-04
 - val_f1: 0.9998
Epoch 246/300
 - 59s - loss: 4.0299e-04 - val_loss: 3.1538e-04
 - val_f1: 0.9998
Epoch 247/300
 - 59s - loss: 3.9514e-04 - val_loss: 3.2930e-04
 - val_f1: 0.9998
Epoch 248/300
 - 59s - loss: 3.9736e-04 - val_loss: 3.3734e-04
 - val_f1: 0.9998
Epoch 249/300
 - 59s - loss: 3.9126e-04 - val_loss: 3.1797e-04
 - val_f1: 0.9998
Epoch 250/300
 - 59s - loss: 3.8057e-04 - val_loss: 3.0828e-04
 - val_f1: 0.9998
Epoch 251/300
 - 59s - loss: 3.8380e-04 - val_loss: 3.0527e-04
 - val_f1: 0.9998
Epoch 252/300
 - 59s - loss: 3.8035e-04 - val_loss: 3.2420e-04
 - val_f1: 0.9998
Epoch 253/300
 - 59s - loss: 3.7788e-04 - val_loss: 3.2304e-04
 - val_f1: 0.9998
Epoch 254/300
 - 59s - loss: 3.8156e-04 - val_loss: 2.9655e-04
 - val_f1: 0.9998
Epoch 255/300
 - 59s - loss: 3.8928e-04 - val_loss: 3.1965e-04
 - val_f1: 0.9998
Epoch 256/300
 - 59s - loss: 3.8288e-04 - val_loss: 3.0871e-04
 - val_f1: 0.9998
Epoch 257/300
 - 59s - loss: 3.8325e-04 - val_loss: 3.2601e-04
 - val_f1: 0.9998
Epoch 258/300
 - 59s - loss: 3.6578e-04 - val_loss: 3.0985e-04
 - val_f1: 0.9998
Epoch 259/300
 - 59s - loss: 3.7754e-04 - val_loss: 3.1337e-04
 - val_f1: 0.9998
Epoch 260/300
 - 59s - loss: 3.8770e-04 - val_loss: 3.4055e-04
 - val_f1: 0.9998
Epoch 261/300
 - 59s - loss: 3.8041e-04 - val_loss: 3.0797e-04
 - val_f1: 0.9998
Epoch 262/300
 - 59s - loss: 3.6758e-04 - val_loss: 3.1338e-04
 - val_f1: 0.9998
Epoch 263/300
 - 59s - loss: 3.8896e-04 - val_loss: 3.2050e-04
 - val_f1: 0.9998
Epoch 264/300
 - 59s - loss: 3.5403e-04 - val_loss: 3.1610e-04
 - val_f1: 0.9998
Epoch 265/300
 - 59s - loss: 3.6661e-04 - val_loss: 3.0821e-04
 - val_f1: 0.9998
Epoch 266/300
 - 59s - loss: 3.7619e-04 - val_loss: 3.0592e-04
 - val_f1: 0.9998
Epoch 267/300
 - 59s - loss: 3.9248e-04 - val_loss: 3.2215e-04
 - val_f1: 0.9998
Epoch 268/300
 - 59s - loss: 3.7708e-04 - val_loss: 3.2187e-04
 - val_f1: 0.9998
Epoch 269/300
 - 59s - loss: 3.6627e-04 - val_loss: 3.4436e-04
 - val_f1: 0.9998
Epoch 270/300
 - 59s - loss: 3.7888e-04 - val_loss: 3.1262e-04
 - val_f1: 0.9998
Epoch 271/300
 - 59s - loss: 3.8696e-04 - val_loss: 3.0408e-04
2019-12-30 21:58:55,642 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 59s - loss: 3.7147e-04 - val_loss: 3.0619e-04
 - val_f1: 0.9998
Epoch 273/300
 - 59s - loss: 3.6525e-04 - val_loss: 3.2281e-04
 - val_f1: 0.9998
Epoch 274/300
 - 59s - loss: 3.6886e-04 - val_loss: 3.1109e-04
 - val_f1: 0.9998
Epoch 275/300
 - 59s - loss: 3.6529e-04 - val_loss: 3.1838e-04
 - val_f1: 0.9998
Epoch 276/300
 - 59s - loss: 3.7662e-04 - val_loss: 2.9977e-04
 - val_f1: 0.9998
Epoch 277/300
 - 59s - loss: 3.6159e-04 - val_loss: 3.0054e-04
 - val_f1: 0.9998
Epoch 278/300
 - 59s - loss: 3.5208e-04 - val_loss: 3.0796e-04
 - val_f1: 0.9998
Epoch 279/300
 - 59s - loss: 3.7068e-04 - val_loss: 3.0548e-04
 - val_f1: 0.9998
Epoch 280/300
 - 59s - loss: 3.7654e-04 - val_loss: 2.8818e-04
 - val_f1: 0.9998
Epoch 281/300
 - 59s - loss: 3.7187e-04 - val_loss: 3.0726e-04
 - val_f1: 0.9998
Epoch 282/300
 - 59s - loss: 3.6370e-04 - val_loss: 3.0779e-04
 - val_f1: 0.9998
Epoch 283/300
 - 59s - loss: 3.6600e-04 - val_loss: 2.9841e-04
 - val_f1: 0.9998
Epoch 284/300
 - 60s - loss: 3.7239e-04 - val_loss: 3.1741e-04
 - val_f1: 0.9998
Epoch 285/300
 - 59s - loss: 3.6211e-04 - val_loss: 5.3151e-04
 - val_f1: 0.9996
Epoch 286/300
 - 59s - loss: 3.4797e-04 - val_loss: 3.0298e-04
 - val_f1: 0.9998
Epoch 287/300
 - 59s - loss: 3.3912e-04 - val_loss: 3.0349e-04
 - val_f1: 0.9998
Epoch 288/300
 - 59s - loss: 3.7358e-04 - val_loss: 2.9196e-04
 - val_f1: 0.9998
Epoch 289/300
 - 59s - loss: 3.6161e-04 - val_loss: 2.8421e-04
 - val_f1: 0.9998
Epoch 290/300
 - 59s - loss: 3.5629e-04 - val_loss: 3.0675e-04
 - val_f1: 0.9998
Epoch 291/300
 - 59s - loss: 3.6825e-04 - val_loss: 3.0893e-04
 - val_f1: 0.9998
Epoch 292/300
 - 59s - loss: 3.5603e-04 - val_loss: 3.0468e-04
 - val_f1: 0.9998
Epoch 293/300
 - 59s - loss: 3.4711e-04 - val_loss: 2.9433e-04
 - val_f1: 0.9998
Epoch 294/300
 - 59s - loss: 3.5088e-04 - val_loss: 3.1449e-04
 - val_f1: 0.9998
Epoch 295/300
 - 59s - loss: 3.5949e-04 - val_loss: 3.0607e-04
 - val_f1: 0.9998
Epoch 296/300
 - 59s - loss: 3.5316e-04 - val_loss: 2.9252e-04
 - val_f1: 0.9998
Epoch 297/300
 - 59s - loss: 3.5056e-04 - val_loss: 3.0178e-04
 - val_f1: 0.9998
Epoch 298/300
 - 59s - loss: 3.5124e-04 - val_loss: 2.9544e-04
 - val_f1: 0.9998
Epoch 299/300
 - 59s - loss: 3.5733e-04 - val_loss: 2.7811e-04
 - val_f1: 0.9998
Epoch 300/300
 - 59s - loss: 3.5341e-04 - val_loss: 2.8404e-04
2019-12-30 22:37:52,608 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 22:39:26,233 [INFO] Last epoch loss evaluation: train_loss = 0.000217, val_loss = 0.000278
2019-12-30 22:39:26,247 [INFO] Training complete. time_to_train = 26531.84 sec, 442.20 min
2019-12-30 22:39:26,255 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_deep_rep1/best_model.pickle
2019-12-30 22:39:26,263 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_deep_rep1/training_error_history.csv
2019-12-30 22:39:26,459 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep1/training_error_history.png
2019-12-30 22:39:26,640 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep1/training_f1_history.png
2019-12-30 22:39:26,640 [INFO] Making predictions on training, validation, testing data
2019-12-30 22:41:13,858 [INFO] Evaluating predictions (results)
2019-12-30 22:41:22,669 [INFO] Dataset: Testing. Classification report below
2019-12-30 22:41:22,669 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.91      0.77      0.83      4166
         r2l       0.97      0.03      0.06     13781
         u2r       0.90      0.00      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.90      0.55      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-30 22:41:22,669 [INFO] Overall accuracy (micro avg): 0.9228142713380424
2019-12-30 22:41:31,960 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9228         0.9228                       0.9228                0.0193                   0.0772  0.9228
1     Macro avg        0.9691         0.8982                       0.5529                0.0206                   0.4471  0.5437
2  Weighted avg        0.9665         0.9396                       0.9228                0.0258                   0.0772  0.9040
2019-12-30 22:42:02,193 [INFO] Dataset: Validation. Classification report below
2019-12-30 22:42:02,193 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.91      0.77      0.83       225
         u2r       0.50      0.20      0.29        10

    accuracy                           1.00    979687
   macro avg       0.88      0.79      0.82    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-30 22:42:02,193 [INFO] Overall accuracy (micro avg): 0.9998111641779466
2019-12-30 22:42:34,807 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8807                       0.7923                0.0001                   0.2077  0.8225
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-30 22:44:47,554 [INFO] Dataset: Training. Classification report below
2019-12-30 22:44:47,554 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.92      0.81      0.87       901
         u2r       0.95      0.45      0.61        42

    accuracy                           1.00   3918744
   macro avg       0.97      0.85      0.89   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-30 22:44:47,554 [INFO] Overall accuracy (micro avg): 0.9998489311881562
2019-12-30 22:47:10,837 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9744                       0.8521                0.0001                   0.1479  0.8949
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-30 22:47:10,887 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_deep_rep1/selected_kdd99_dbn_deep_rep1_results.xlsx
2019-12-30 22:47:10,895 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-30 22:47:10,920 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_deep_rep2
2019-12-30 22:47:10,921 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_deep_rep2/run_log.log
2019-12-30 22:47:10,921 [INFO] ================= Running experiment no. 2  ================= 

2019-12-30 22:47:10,921 [INFO] Experiment parameters given below
2019-12-30 22:47:10,921 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_kdd99_dbn_deep_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 33], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.3], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_deep_rep2'}
2019-12-30 22:47:10,921 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_deep_rep2/tf_logs_run_2019_12_30-22_47_10
2019-12-30 22:47:10,921 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-30 22:47:10,921 [INFO] Reading X, y files
2019-12-30 22:47:10,921 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-30 22:47:17,331 [INFO] Reading complete. time_to_read=6.41 seconds
2019-12-30 22:47:17,331 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-30 22:47:18,955 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-30 22:47:18,955 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-30 22:47:19,412 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-30 22:47:19,412 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-30 22:47:19,649 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-30 22:47:19,649 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-30 22:47:19,703 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-30 22:47:19,703 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-30 22:47:19,723 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-30 22:47:26,981 [INFO] Initializing model
2019-12-30 22:47:26,981 [INFO] Training model
2019-12-30 22:47:26,981 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-30 22:48:06,298 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = dd2a2e49f2d8d7b24e5a2d491cd5836a4fc3e085
2019-12-30 22:48:06,298 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9998
[BernoulliRBM] Iteration 1, pseudo-likelihood = -64.99, time = 17.70s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -95.39, time = 30.44s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -123.43, time = 29.76s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -152.76, time = 29.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -183.12, time = 28.89s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -213.34, time = 28.76s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -243.68, time = 28.67s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -273.95, time = 28.78s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -304.62, time = 28.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -335.20, time = 28.75s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -365.77, time = 28.75s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -396.44, time = 28.73s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -427.13, time = 28.74s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -457.87, time = 28.72s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -488.61, time = 28.72s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -519.43, time = 28.72s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -550.06, time = 28.71s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -580.52, time = 28.69s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -611.14, time = 28.70s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -641.78, time = 28.68s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -672.46, time = 28.67s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -703.15, time = 28.68s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -733.90, time = 28.69s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -764.64, time = 28.76s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -795.40, time = 28.75s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -826.17, time = 28.71s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -856.92, time = 28.71s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -887.68, time = 28.72s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -918.44, time = 28.70s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -949.22, time = 28.69s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -979.99, time = 28.70s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -1010.78, time = 28.71s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -1041.57, time = 28.75s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -1072.37, time = 29.13s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -1103.16, time = 29.83s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -1133.94, time = 30.23s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -1164.75, time = 29.98s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1195.55, time = 29.38s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1226.35, time = 29.50s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1257.16, time = 36.05s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1287.96, time = 30.86s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1318.76, time = 30.58s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1349.59, time = 31.94s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1380.40, time = 30.15s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1411.20, time = 30.53s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1442.00, time = 29.59s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1472.83, time = 29.49s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1503.61, time = 29.34s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1534.43, time = 28.73s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1565.27, time = 28.93s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.45, time = 10.78s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.52, time = 17.19s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.33, time = 17.03s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.30, time = 16.93s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.28, time = 16.92s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.72, time = 16.91s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.36, time = 16.93s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.06, time = 16.91s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.89, time = 16.92s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.66, time = 16.93s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -3.51, time = 16.94s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -3.31, time = 16.96s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.19, time = 16.93s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.11, time = 16.91s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -3.05, time = 16.92s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -3.00, time = 16.95s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.96, time = 16.94s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -2.93, time = 16.98s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.90, time = 17.00s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.88, time = 17.00s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -2.86, time = 17.03s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -2.76, time = 17.02s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -2.62, time = 16.96s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -2.55, time = 16.94s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -2.49, time = 16.95s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -2.44, time = 16.94s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -2.41, time = 16.95s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -2.37, time = 16.98s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -2.30, time = 16.98s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -2.25, time = 16.88s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -2.21, time = 16.87s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -2.18, time = 16.86s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -2.15, time = 16.86s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -2.13, time = 16.86s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -2.11, time = 16.87s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -2.09, time = 16.85s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -2.07, time = 16.86s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -2.06, time = 16.86s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -2.05, time = 16.85s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -2.04, time = 16.86s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -2.03, time = 16.86s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -2.02, time = 16.86s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -2.01, time = 16.86s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -2.00, time = 16.87s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1.99, time = 16.86s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1.99, time = 16.87s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1.98, time = 16.86s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1.98, time = 16.87s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1.97, time = 16.87s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1.97, time = 17.07s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -12.71, time = 5.15s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -11.04, time = 8.20s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -10.23, time = 8.20s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -9.51, time = 8.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -9.00, time = 8.18s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -8.46, time = 8.13s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -8.04, time = 8.11s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -7.86, time = 8.10s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -7.60, time = 8.10s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -7.50, time = 8.10s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -7.32, time = 8.10s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -7.26, time = 8.09s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -7.20, time = 8.09s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -7.17, time = 8.09s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -7.13, time = 8.08s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -7.10, time = 8.09s2019-12-30 23:33:28,800 [INFO] Pretraining Complete
2019-12-30 23:33:28,801 [INFO] Getting pretrained weights
2019-12-30 23:33:28,801 [INFO] Creating and initializing feed forward neural network
2019-12-30 23:33:29,180 [INFO] _________________________________________________________________
2019-12-30 23:33:29,180 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 23:33:29,180 [INFO] =================================================================
2019-12-30 23:33:29,180 [INFO] dense_5 (Dense)              (None, 128)               15872     
2019-12-30 23:33:29,180 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] batch_normalization_4 (Batch (None, 128)               512       
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] dropout_4 (Dropout)          (None, 128)               0         
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] dense_6 (Dense)              (None, 64)                8256      
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,181 [INFO] dense_7 (Dense)              (None, 33)                2145      
2019-12-30 23:33:29,181 [INFO] _________________________________________________________________
2019-12-30 23:33:29,182 [INFO] batch_normalization_6 (Batch (None, 33)                132       
2019-12-30 23:33:29,182 [INFO] _________________________________________________________________
2019-12-30 23:33:29,182 [INFO] dropout_6 (Dropout)          (None, 33)                0         
2019-12-30 23:33:29,182 [INFO] _________________________________________________________________
2019-12-30 23:33:29,182 [INFO] dense_8 (Dense)              (None, 5)                 170       
2019-12-30 23:33:29,182 [INFO] =================================================================
2019-12-30 23:33:29,182 [INFO] Total params: 27,343
2019-12-30 23:33:29,182 [INFO] Trainable params: 26,893
2019-12-30 23:33:29,182 [INFO] Non-trainable params: 450
2019-12-30 23:33:29,182 [INFO] _________________________________________________________________
2019-12-30 23:33:29,599 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -7.08, time = 8.09s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -7.03, time = 8.09s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -6.93, time = 8.09s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -6.92, time = 8.09s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -6.90, time = 8.09s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -6.79, time = 8.09s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -6.78, time = 8.09s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -6.76, time = 8.08s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -6.74, time = 8.08s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -6.75, time = 8.09s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -6.73, time = 8.08s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -6.72, time = 8.08s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -6.72, time = 8.08s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -6.70, time = 8.08s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -6.71, time = 8.08s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -6.70, time = 8.09s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -6.70, time = 8.09s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -6.68, time = 8.08s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -6.68, time = 8.08s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -6.67, time = 8.09s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -6.68, time = 8.08s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -6.67, time = 8.08s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -6.66, time = 8.08s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -6.67, time = 8.08s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -6.66, time = 8.08s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -6.65, time = 8.08s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -6.66, time = 8.07s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -6.65, time = 8.08s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -6.65, time = 8.07s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -6.64, time = 8.08s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -6.64, time = 8.07s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -6.64, time = 8.06s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -6.64, time = 8.08s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -6.63, time = 8.05s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/300
 - 62s - loss: 0.0177 - val_loss: 0.0065
 - val_f1: 0.9962
Epoch 2/300
 - 60s - loss: 0.0074 - val_loss: 0.0051
 - val_f1: 0.9971
Epoch 3/300
 - 60s - loss: 0.0060 - val_loss: 0.0045
 - val_f1: 0.9974
Epoch 4/300
 - 60s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9977
Epoch 5/300
 - 60s - loss: 0.0043 - val_loss: 0.0025
 - val_f1: 0.9982
Epoch 6/300
 - 61s - loss: 0.0031 - val_loss: 0.0019
 - val_f1: 0.9988
Epoch 7/300
 - 60s - loss: 0.0026 - val_loss: 0.0018
 - val_f1: 0.9989
Epoch 8/300
 - 61s - loss: 0.0023 - val_loss: 0.0016
 - val_f1: 0.9990
Epoch 9/300
 - 60s - loss: 0.0021 - val_loss: 0.0015
 - val_f1: 0.9992
Epoch 10/300
 - 60s - loss: 0.0020 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 11/300
 - 60s - loss: 0.0019 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 12/300
 - 60s - loss: 0.0019 - val_loss: 0.0014
 - val_f1: 0.9992
Epoch 13/300
 - 60s - loss: 0.0017 - val_loss: 0.0012
 - val_f1: 0.9992
Epoch 14/300
 - 60s - loss: 0.0017 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 15/300
 - 60s - loss: 0.0016 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 16/300
 - 60s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 17/300
 - 60s - loss: 0.0015 - val_loss: 0.0010
 - val_f1: 0.9993
Epoch 18/300
 - 60s - loss: 0.0015 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 19/300
 - 60s - loss: 0.0014 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 20/300
 - 60s - loss: 0.0014 - val_loss: 9.9329e-04
 - val_f1: 0.9994
Epoch 21/300
 - 60s - loss: 0.0014 - val_loss: 9.8184e-04
 - val_f1: 0.9994
Epoch 22/300
 - 60s - loss: 0.0014 - val_loss: 9.9873e-04
 - val_f1: 0.9994
Epoch 23/300
 - 60s - loss: 0.0013 - val_loss: 9.7972e-04
 - val_f1: 0.9995
Epoch 24/300
 - 60s - loss: 0.0013 - val_loss: 9.5360e-04
 - val_f1: 0.9995
Epoch 25/300
 - 60s - loss: 0.0013 - val_loss: 9.2273e-04
 - val_f1: 0.9995
Epoch 26/300
 - 60s - loss: 0.0012 - val_loss: 9.1986e-04
 - val_f1: 0.9995
Epoch 27/300
 - 61s - loss: 0.0013 - val_loss: 9.6192e-04
 - val_f1: 0.9995
Epoch 28/300
 - 60s - loss: 0.0012 - val_loss: 9.1761e-04
 - val_f1: 0.9995
Epoch 29/300
 - 60s - loss: 0.0012 - val_loss: 8.4349e-04
 - val_f1: 0.9995
Epoch 30/300
 - 60s - loss: 0.0012 - val_loss: 8.6107e-04
 - val_f1: 0.9994
Epoch 31/300
 - 60s - loss: 0.0012 - val_loss: 8.2142e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 00:16:22,173 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9995
Epoch 32/300
 - 60s - loss: 0.0011 - val_loss: 8.2504e-04
 - val_f1: 0.9994
Epoch 33/300
 - 60s - loss: 0.0011 - val_loss: 8.1184e-04
 - val_f1: 0.9995
Epoch 34/300
 - 60s - loss: 0.0011 - val_loss: 7.7568e-04
 - val_f1: 0.9995
Epoch 35/300
 - 60s - loss: 0.0011 - val_loss: 7.5410e-04
 - val_f1: 0.9995
Epoch 36/300
 - 60s - loss: 0.0010 - val_loss: 7.1794e-04
 - val_f1: 0.9995
Epoch 37/300
 - 60s - loss: 0.0010 - val_loss: 6.8506e-04
 - val_f1: 0.9996
Epoch 38/300
 - 60s - loss: 0.0010 - val_loss: 6.7403e-04
 - val_f1: 0.9995
Epoch 39/300
 - 60s - loss: 9.8774e-04 - val_loss: 6.4453e-04
 - val_f1: 0.9996
Epoch 40/300
 - 60s - loss: 9.6484e-04 - val_loss: 7.0301e-04
 - val_f1: 0.9996
Epoch 41/300
 - 60s - loss: 9.4996e-04 - val_loss: 6.6413e-04
 - val_f1: 0.9996
Epoch 42/300
 - 60s - loss: 9.4642e-04 - val_loss: 6.4564e-04
 - val_f1: 0.9996
Epoch 43/300
 - 60s - loss: 9.2395e-04 - val_loss: 6.2508e-04
 - val_f1: 0.9996
Epoch 44/300
 - 60s - loss: 9.3081e-04 - val_loss: 6.3554e-04
 - val_f1: 0.9996
Epoch 45/300
 - 60s - loss: 9.1019e-04 - val_loss: 6.0350e-04
 - val_f1: 0.9996
Epoch 46/300
 - 60s - loss: 8.8798e-04 - val_loss: 6.4805e-04
 - val_f1: 0.9996
Epoch 47/300
 - 60s - loss: 8.8158e-04 - val_loss: 6.2462e-04
 - val_f1: 0.9996
Epoch 48/300
 - 60s - loss: 8.5027e-04 - val_loss: 5.8753e-04
 - val_f1: 0.9996
Epoch 49/300
 - 60s - loss: 8.4149e-04 - val_loss: 5.9274e-04
 - val_f1: 0.9996
Epoch 50/300
 - 60s - loss: 8.4208e-04 - val_loss: 5.7299e-04
 - val_f1: 0.9997
Epoch 51/300
 - 60s - loss: 8.3356e-04 - val_loss: 5.7822e-04
 - val_f1: 0.9996
Epoch 52/300
 - 60s - loss: 7.9571e-04 - val_loss: 6.0290e-04
 - val_f1: 0.9996
Epoch 53/300
 - 60s - loss: 8.0848e-04 - val_loss: 5.9037e-04
 - val_f1: 0.9996
Epoch 54/300
 - 60s - loss: 8.1264e-04 - val_loss: 5.8416e-04
 - val_f1: 0.9996
Epoch 55/300
 - 60s - loss: 8.0906e-04 - val_loss: 5.8834e-04
 - val_f1: 0.9996
Epoch 56/300
 - 60s - loss: 7.8984e-04 - val_loss: 5.4973e-04
 - val_f1: 0.9996
Epoch 57/300
 - 60s - loss: 7.7864e-04 - val_loss: 5.5607e-04
 - val_f1: 0.9996
Epoch 58/300
 - 60s - loss: 7.6545e-04 - val_loss: 5.4009e-04
 - val_f1: 0.9996
Epoch 59/300
 - 60s - loss: 7.6025e-04 - val_loss: 5.3446e-04
 - val_f1: 0.9997
Epoch 60/300
 - 60s - loss: 7.4877e-04 - val_loss: 5.4568e-04
 - val_f1: 0.9996
Epoch 61/300
 - 60s - loss: 7.3338e-04 - val_loss: 5.1722e-04
2019-12-31 00:58:11,870 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/300
 - 60s - loss: 7.4311e-04 - val_loss: 5.3771e-04
 - val_f1: 0.9997
Epoch 63/300
 - 60s - loss: 7.2159e-04 - val_loss: 5.1876e-04
 - val_f1: 0.9997
Epoch 64/300
 - 60s - loss: 7.3486e-04 - val_loss: 5.1572e-04
 - val_f1: 0.9997
Epoch 65/300
 - 60s - loss: 7.1550e-04 - val_loss: 4.9216e-04
 - val_f1: 0.9996
Epoch 66/300
 - 60s - loss: 7.1294e-04 - val_loss: 5.2885e-04
 - val_f1: 0.9997
Epoch 67/300
 - 60s - loss: 6.9183e-04 - val_loss: 4.6403e-04
 - val_f1: 0.9997
Epoch 68/300
 - 60s - loss: 7.0984e-04 - val_loss: 4.8526e-04
 - val_f1: 0.9997
Epoch 69/300
 - 60s - loss: 7.1403e-04 - val_loss: 5.0067e-04
 - val_f1: 0.9997
Epoch 70/300
 - 60s - loss: 7.0662e-04 - val_loss: 4.8132e-04
 - val_f1: 0.9997
Epoch 71/300
 - 61s - loss: 6.9219e-04 - val_loss: 4.7784e-04
 - val_f1: 0.9997
Epoch 72/300
 - 60s - loss: 6.8523e-04 - val_loss: 4.6689e-04
 - val_f1: 0.9997
Epoch 73/300
 - 61s - loss: 6.7143e-04 - val_loss: 4.4891e-04
 - val_f1: 0.9997
Epoch 74/300
 - 60s - loss: 6.7261e-04 - val_loss: 4.9403e-04
 - val_f1: 0.9997
Epoch 75/300
 - 60s - loss: 6.7655e-04 - val_loss: 4.5552e-04
 - val_f1: 0.9997
Epoch 76/300
 - 60s - loss: 6.6688e-04 - val_loss: 4.7265e-04
 - val_f1: 0.9997
Epoch 77/300
 - 60s - loss: 6.6493e-04 - val_loss: 4.7064e-04
 - val_f1: 0.9997
Epoch 78/300
 - 60s - loss: 6.5670e-04 - val_loss: 4.6824e-04
 - val_f1: 0.9997
Epoch 79/300
 - 60s - loss: 6.6986e-04 - val_loss: 4.5906e-04
 - val_f1: 0.9997
Epoch 80/300
 - 60s - loss: 6.5027e-04 - val_loss: 4.6686e-04
 - val_f1: 0.9997
Epoch 81/300
 - 60s - loss: 6.4405e-04 - val_loss: 4.6805e-04
 - val_f1: 0.9997
Epoch 82/300
 - 61s - loss: 6.4600e-04 - val_loss: 4.5449e-04
 - val_f1: 0.9997
Epoch 83/300
 - 60s - loss: 6.5163e-04 - val_loss: 4.4229e-04
 - val_f1: 0.9997
Epoch 84/300
 - 60s - loss: 6.3750e-04 - val_loss: 4.4842e-04
 - val_f1: 0.9997
Epoch 85/300
 - 60s - loss: 6.4071e-04 - val_loss: 4.9127e-04
 - val_f1: 0.9997
Epoch 86/300
 - 61s - loss: 6.4927e-04 - val_loss: 4.2056e-04
 - val_f1: 0.9997
Epoch 87/300
 - 60s - loss: 6.1789e-04 - val_loss: 4.4183e-04
 - val_f1: 0.9997
Epoch 88/300
 - 60s - loss: 6.1830e-04 - val_loss: 4.4632e-04
 - val_f1: 0.9997
Epoch 89/300
 - 61s - loss: 6.2065e-04 - val_loss: 4.3356e-04
 - val_f1: 0.9997
Epoch 90/300
 - 60s - loss: 6.2031e-04 - val_loss: 4.3011e-04
 - val_f1: 0.9997
Epoch 91/300
 - 60s - loss: 6.2913e-04 - val_loss: 4.2882e-04
2019-12-31 01:40:01,370 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9997
Epoch 92/300
 - 60s - loss: 6.1369e-04 - val_loss: 4.2119e-04
 - val_f1: 0.9997
Epoch 93/300
 - 60s - loss: 6.1222e-04 - val_loss: 4.4416e-04
 - val_f1: 0.9997
Epoch 94/300
 - 60s - loss: 5.9413e-04 - val_loss: 4.3000e-04
 - val_f1: 0.9997
Epoch 95/300
 - 60s - loss: 5.9861e-04 - val_loss: 4.3115e-04
 - val_f1: 0.9997
Epoch 96/300
 - 60s - loss: 6.0709e-04 - val_loss: 4.1005e-04
 - val_f1: 0.9997
Epoch 97/300
 - 60s - loss: 5.7619e-04 - val_loss: 4.2070e-04
 - val_f1: 0.9997
Epoch 98/300
 - 60s - loss: 5.9910e-04 - val_loss: 4.3511e-04
 - val_f1: 0.9997
Epoch 99/300
 - 60s - loss: 5.8318e-04 - val_loss: 4.1171e-04
 - val_f1: 0.9998
Epoch 100/300
 - 60s - loss: 5.8808e-04 - val_loss: 4.3371e-04
 - val_f1: 0.9997
Epoch 101/300
 - 60s - loss: 5.7824e-04 - val_loss: 4.1273e-04
 - val_f1: 0.9997
Epoch 102/300
 - 60s - loss: 5.8046e-04 - val_loss: 4.0794e-04
 - val_f1: 0.9997
Epoch 103/300
 - 60s - loss: 5.6910e-04 - val_loss: 4.1346e-04
 - val_f1: 0.9998
Epoch 104/300
 - 60s - loss: 5.7741e-04 - val_loss: 4.0303e-04
 - val_f1: 0.9997
Epoch 105/300
 - 60s - loss: 5.8042e-04 - val_loss: 4.3839e-04
 - val_f1: 0.9997
Epoch 106/300
 - 60s - loss: 5.5820e-04 - val_loss: 4.0984e-04
 - val_f1: 0.9997
Epoch 107/300
 - 60s - loss: 5.5837e-04 - val_loss: 4.1573e-04
 - val_f1: 0.9998
Epoch 108/300
 - 60s - loss: 5.6134e-04 - val_loss: 4.0397e-04
 - val_f1: 0.9997
Epoch 109/300
 - 60s - loss: 5.5562e-04 - val_loss: 4.1663e-04
 - val_f1: 0.9997
Epoch 110/300
 - 60s - loss: 5.4483e-04 - val_loss: 4.3032e-04
 - val_f1: 0.9997
Epoch 111/300
 - 61s - loss: 5.5274e-04 - val_loss: 4.0578e-04
 - val_f1: 0.9997
Epoch 112/300
 - 60s - loss: 5.6042e-04 - val_loss: 4.0570e-04
 - val_f1: 0.9998
Epoch 113/300
 - 60s - loss: 5.4988e-04 - val_loss: 3.9619e-04
 - val_f1: 0.9998
Epoch 114/300
 - 60s - loss: 5.5144e-04 - val_loss: 4.0786e-04
 - val_f1: 0.9998
Epoch 115/300
 - 60s - loss: 5.3238e-04 - val_loss: 4.4974e-04
 - val_f1: 0.9997
Epoch 116/300
 - 60s - loss: 5.5035e-04 - val_loss: 4.1314e-04
 - val_f1: 0.9998
Epoch 117/300
 - 60s - loss: 5.4794e-04 - val_loss: 4.0807e-04
 - val_f1: 0.9997
Epoch 118/300
 - 60s - loss: 5.4737e-04 - val_loss: 4.1303e-04
 - val_f1: 0.9997
Epoch 119/300
 - 60s - loss: 5.4383e-04 - val_loss: 4.1295e-04
 - val_f1: 0.9998
Epoch 120/300
 - 60s - loss: 5.5166e-04 - val_loss: 4.0219e-04
 - val_f1: 0.9997
Epoch 121/300
 - 60s - loss: 5.3987e-04 - val_loss: 3.8378e-04
2019-12-31 02:21:47,570 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 60s - loss: 5.4139e-04 - val_loss: 3.9492e-04
 - val_f1: 0.9998
Epoch 123/300
 - 61s - loss: 5.3456e-04 - val_loss: 3.9547e-04
 - val_f1: 0.9998
Epoch 124/300
 - 60s - loss: 5.2499e-04 - val_loss: 3.7696e-04
 - val_f1: 0.9998
Epoch 125/300
 - 60s - loss: 5.2321e-04 - val_loss: 3.8979e-04
 - val_f1: 0.9998
Epoch 126/300
 - 60s - loss: 5.3637e-04 - val_loss: 3.9384e-04
 - val_f1: 0.9998
Epoch 127/300
 - 60s - loss: 5.1129e-04 - val_loss: 3.9298e-04
 - val_f1: 0.9998
Epoch 128/300
 - 60s - loss: 5.2241e-04 - val_loss: 3.9423e-04
 - val_f1: 0.9998
Epoch 129/300
 - 60s - loss: 5.3052e-04 - val_loss: 3.9261e-04
 - val_f1: 0.9998
Epoch 130/300
 - 60s - loss: 5.2184e-04 - val_loss: 4.0093e-04
 - val_f1: 0.9997
Epoch 131/300
 - 60s - loss: 4.9678e-04 - val_loss: 4.2383e-04
 - val_f1: 0.9998
Epoch 132/300
 - 60s - loss: 5.3219e-04 - val_loss: 3.9401e-04
 - val_f1: 0.9998
Epoch 133/300
 - 60s - loss: 5.1168e-04 - val_loss: 3.7746e-04
 - val_f1: 0.9998
Epoch 134/300
 - 60s - loss: 5.0272e-04 - val_loss: 3.9491e-04
 - val_f1: 0.9998
Epoch 135/300
 - 60s - loss: 5.1062e-04 - val_loss: 3.8359e-04
 - val_f1: 0.9997
Epoch 136/300
 - 60s - loss: 5.0483e-04 - val_loss: 3.8635e-04
 - val_f1: 0.9998
Epoch 137/300
 - 60s - loss: 5.1455e-04 - val_loss: 3.7731e-04
 - val_f1: 0.9998
Epoch 138/300
 - 60s - loss: 4.8474e-04 - val_loss: 3.7741e-04
 - val_f1: 0.9998
Epoch 139/300
 - 61s - loss: 5.0371e-04 - val_loss: 3.6366e-04
 - val_f1: 0.9998
Epoch 140/300
 - 60s - loss: 4.9377e-04 - val_loss: 3.7340e-04
 - val_f1: 0.9998
Epoch 141/300
 - 60s - loss: 4.8890e-04 - val_loss: 3.8592e-04
 - val_f1: 0.9998
Epoch 142/300
 - 61s - loss: 4.9233e-04 - val_loss: 3.8100e-04
 - val_f1: 0.9998
Epoch 143/300
 - 60s - loss: 5.0106e-04 - val_loss: 3.7538e-04
 - val_f1: 0.9998
Epoch 144/300
 - 60s - loss: 5.0276e-04 - val_loss: 3.8611e-04
 - val_f1: 0.9998
Epoch 145/300
 - 60s - loss: 4.9617e-04 - val_loss: 3.9365e-04
 - val_f1: 0.9997
Epoch 146/300
 - 60s - loss: 4.8756e-04 - val_loss: 3.5975e-04
 - val_f1: 0.9998
Epoch 147/300
 - 60s - loss: 4.9523e-04 - val_loss: 3.8006e-04
 - val_f1: 0.9998
Epoch 148/300
 - 60s - loss: 4.8094e-04 - val_loss: 3.6233e-04
 - val_f1: 0.9998
Epoch 149/300
 - 60s - loss: 4.7997e-04 - val_loss: 4.1594e-04
 - val_f1: 0.9998
Epoch 150/300
 - 60s - loss: 4.7872e-04 - val_loss: 3.7902e-04
 - val_f1: 0.9998
Epoch 151/300
 - 60s - loss: 4.9023e-04 - val_loss: 3.7305e-04
2019-12-31 03:03:36,894 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 60s - loss: 4.7288e-04 - val_loss: 3.8913e-04
 - val_f1: 0.9997
Epoch 153/300
 - 60s - loss: 4.7701e-04 - val_loss: 3.8658e-04
 - val_f1: 0.9998
Epoch 154/300
 - 60s - loss: 4.9186e-04 - val_loss: 3.7157e-04
 - val_f1: 0.9998
Epoch 155/300
 - 60s - loss: 4.8146e-04 - val_loss: 3.9270e-04
 - val_f1: 0.9998
Epoch 156/300
 - 60s - loss: 4.8407e-04 - val_loss: 3.9419e-04
 - val_f1: 0.9998
Epoch 157/300
 - 60s - loss: 4.9281e-04 - val_loss: 3.7560e-04
 - val_f1: 0.9998
Epoch 158/300
 - 60s - loss: 4.7078e-04 - val_loss: 3.7938e-04
 - val_f1: 0.9998
Epoch 159/300
 - 60s - loss: 4.7459e-04 - val_loss: 3.6073e-04
 - val_f1: 0.9998
Epoch 160/300
 - 60s - loss: 4.7446e-04 - val_loss: 3.6126e-04
 - val_f1: 0.9998
Epoch 161/300
 - 60s - loss: 4.6261e-04 - val_loss: 3.6114e-04
 - val_f1: 0.9998
Epoch 162/300
 - 60s - loss: 4.9111e-04 - val_loss: 3.5877e-04
 - val_f1: 0.9998
Epoch 163/300
 - 60s - loss: 4.6719e-04 - val_loss: 3.8558e-04
 - val_f1: 0.9998
Epoch 164/300
 - 60s - loss: 4.6944e-04 - val_loss: 3.5770e-04
 - val_f1: 0.9997
Epoch 165/300
 - 60s - loss: 4.7137e-04 - val_loss: 3.6746e-04
 - val_f1: 0.9998
Epoch 166/300
 - 60s - loss: 4.6864e-04 - val_loss: 3.6853e-04
 - val_f1: 0.9998
Epoch 167/300
 - 60s - loss: 4.5872e-04 - val_loss: 3.6059e-04
 - val_f1: 0.9998
Epoch 168/300
 - 60s - loss: 4.6558e-04 - val_loss: 3.7167e-04
 - val_f1: 0.9998
Epoch 169/300
 - 60s - loss: 4.6133e-04 - val_loss: 3.7714e-04
 - val_f1: 0.9998
Epoch 170/300
 - 60s - loss: 4.6614e-04 - val_loss: 3.5208e-04
 - val_f1: 0.9998
Epoch 171/300
 - 60s - loss: 4.5965e-04 - val_loss: 3.4991e-04
 - val_f1: 0.9998
Epoch 172/300
 - 60s - loss: 4.5790e-04 - val_loss: 3.4065e-04
 - val_f1: 0.9998
Epoch 173/300
 - 60s - loss: 4.6068e-04 - val_loss: 3.5269e-04
 - val_f1: 0.9998
Epoch 174/300
 - 60s - loss: 4.6376e-04 - val_loss: 3.4823e-04
 - val_f1: 0.9998
Epoch 175/300
 - 60s - loss: 4.5512e-04 - val_loss: 3.5401e-04
 - val_f1: 0.9998
Epoch 176/300
 - 60s - loss: 4.5549e-04 - val_loss: 3.5398e-04
 - val_f1: 0.9998
Epoch 177/300
 - 60s - loss: 4.6234e-04 - val_loss: 3.3992e-04
 - val_f1: 0.9998
Epoch 178/300
 - 60s - loss: 4.4457e-04 - val_loss: 3.5223e-04
 - val_f1: 0.9998
Epoch 179/300
 - 60s - loss: 4.5139e-04 - val_loss: 3.3917e-04
 - val_f1: 0.9998
Epoch 180/300
 - 60s - loss: 4.4906e-04 - val_loss: 3.3879e-04
 - val_f1: 0.9998
Epoch 181/300
 - 60s - loss: 4.5201e-04 - val_loss: 3.4720e-04
2019-12-31 03:45:21,451 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 60s - loss: 4.3731e-04 - val_loss: 3.5517e-04
 - val_f1: 0.9998
Epoch 183/300
 - 60s - loss: 4.3229e-04 - val_loss: 3.2966e-04
 - val_f1: 0.9998
Epoch 184/300
 - 60s - loss: 4.4833e-04 - val_loss: 3.5004e-04
 - val_f1: 0.9998
Epoch 185/300
 - 60s - loss: 4.5815e-04 - val_loss: 3.3509e-04
 - val_f1: 0.9998
Epoch 186/300
 - 60s - loss: 4.3880e-04 - val_loss: 3.4140e-04
 - val_f1: 0.9998
Epoch 187/300
 - 60s - loss: 4.5049e-04 - val_loss: 3.6070e-04
 - val_f1: 0.9998
Epoch 188/300
 - 60s - loss: 4.3087e-04 - val_loss: 3.3955e-04
 - val_f1: 0.9998
Epoch 189/300
 - 60s - loss: 4.4272e-04 - val_loss: 3.7689e-04
 - val_f1: 0.9998
Epoch 190/300
 - 60s - loss: 4.3767e-04 - val_loss: 3.4563e-04
 - val_f1: 0.9998
Epoch 191/300
 - 60s - loss: 4.3238e-04 - val_loss: 3.3068e-04
 - val_f1: 0.9998
Epoch 192/300
 - 60s - loss: 4.2727e-04 - val_loss: 3.1851e-04
 - val_f1: 0.9998
Epoch 193/300
 - 60s - loss: 4.2742e-04 - val_loss: 3.2191e-04
 - val_f1: 0.9998
Epoch 194/300
 - 60s - loss: 4.3905e-04 - val_loss: 3.2697e-04
 - val_f1: 0.9998
Epoch 195/300
 - 60s - loss: 4.4148e-04 - val_loss: 3.5141e-04
 - val_f1: 0.9998
Epoch 196/300
 - 60s - loss: 4.2669e-04 - val_loss: 3.2080e-04
 - val_f1: 0.9998
Epoch 197/300
 - 60s - loss: 4.3580e-04 - val_loss: 3.4489e-04
 - val_f1: 0.9998
Epoch 198/300
 - 60s - loss: 4.3887e-04 - val_loss: 3.3363e-04
 - val_f1: 0.9998
Epoch 199/300
 - 60s - loss: 4.1895e-04 - val_loss: 3.3141e-04
 - val_f1: 0.9998
Epoch 200/300
 - 60s - loss: 4.2086e-04 - val_loss: 3.4846e-04
 - val_f1: 0.9998
Epoch 201/300
 - 60s - loss: 4.2547e-04 - val_loss: 3.3039e-04
 - val_f1: 0.9998
Epoch 202/300
 - 60s - loss: 4.2663e-04 - val_loss: 3.2757e-04
 - val_f1: 0.9998
Epoch 203/300
 - 59s - loss: 4.1421e-04 - val_loss: 3.2970e-04
 - val_f1: 0.9998
Epoch 204/300
 - 59s - loss: 4.3135e-04 - val_loss: 3.0659e-04
 - val_f1: 0.9998
Epoch 205/300
 - 59s - loss: 4.0818e-04 - val_loss: 3.4200e-04
 - val_f1: 0.9998
Epoch 206/300
 - 59s - loss: 4.2324e-04 - val_loss: 3.2127e-04
 - val_f1: 0.9998
Epoch 207/300
 - 59s - loss: 4.2306e-04 - val_loss: 3.4283e-04
 - val_f1: 0.9998
Epoch 208/300
 - 59s - loss: 4.0937e-04 - val_loss: 3.3839e-04
 - val_f1: 0.9998
Epoch 209/300
 - 59s - loss: 4.2098e-04 - val_loss: 3.2653e-04
 - val_f1: 0.9998
Epoch 210/300
 - 60s - loss: 4.2457e-04 - val_loss: 3.1992e-04
 - val_f1: 0.9998
Epoch 211/300
 - 59s - loss: 4.0559e-04 - val_loss: 3.3947e-04
2019-12-31 04:26:49,211 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 60s - loss: 4.0774e-04 - val_loss: 3.1102e-04
 - val_f1: 0.9998
Epoch 213/300
 - 60s - loss: 4.1175e-04 - val_loss: 3.2573e-04
 - val_f1: 0.9998
Epoch 214/300
 - 60s - loss: 4.0176e-04 - val_loss: 3.3168e-04
 - val_f1: 0.9998
Epoch 215/300
 - 60s - loss: 4.1869e-04 - val_loss: 3.2086e-04
 - val_f1: 0.9998
Epoch 216/300
 - 60s - loss: 4.0596e-04 - val_loss: 3.0756e-04
 - val_f1: 0.9998
Epoch 217/300
 - 59s - loss: 4.0589e-04 - val_loss: 3.0435e-04
 - val_f1: 0.9998
Epoch 218/300
 - 60s - loss: 4.0402e-04 - val_loss: 3.0382e-04
 - val_f1: 0.9998
Epoch 219/300
 - 60s - loss: 4.1184e-04 - val_loss: 3.3698e-04
 - val_f1: 0.9998
Epoch 220/300
 - 60s - loss: 4.0556e-04 - val_loss: 3.3398e-04
 - val_f1: 0.9998
Epoch 221/300
 - 60s - loss: 3.9096e-04 - val_loss: 3.1741e-04
 - val_f1: 0.9998
Epoch 222/300
 - 60s - loss: 4.0717e-04 - val_loss: 3.0193e-04
 - val_f1: 0.9998
Epoch 223/300
 - 60s - loss: 4.0688e-04 - val_loss: 3.4514e-04
 - val_f1: 0.9998
Epoch 224/300
 - 60s - loss: 4.0181e-04 - val_loss: 3.4116e-04
 - val_f1: 0.9998
Epoch 225/300
 - 60s - loss: 3.9808e-04 - val_loss: 3.1127e-04
 - val_f1: 0.9998
Epoch 226/300
 - 60s - loss: 3.9625e-04 - val_loss: 3.1858e-04
 - val_f1: 0.9998
Epoch 227/300
 - 60s - loss: 3.9351e-04 - val_loss: 3.1901e-04
 - val_f1: 0.9998
Epoch 228/300
 - 60s - loss: 3.9464e-04 - val_loss: 3.1868e-04
 - val_f1: 0.9998
Epoch 229/300
 - 60s - loss: 3.8797e-04 - val_loss: 3.2305e-04
 - val_f1: 0.9998
Epoch 230/300
 - 60s - loss: 3.9166e-04 - val_loss: 3.1545e-04
 - val_f1: 0.9998
Epoch 231/300
 - 60s - loss: 3.8976e-04 - val_loss: 3.3340e-04
 - val_f1: 0.9998
Epoch 232/300
 - 60s - loss: 3.9393e-04 - val_loss: 3.2389e-04
 - val_f1: 0.9998
Epoch 233/300
 - 60s - loss: 4.0389e-04 - val_loss: 3.5706e-04
 - val_f1: 0.9998
Epoch 234/300
 - 60s - loss: 3.9853e-04 - val_loss: 3.8457e-04
 - val_f1: 0.9998
Epoch 235/300
 - 60s - loss: 3.9633e-04 - val_loss: 3.2497e-04
 - val_f1: 0.9998
Epoch 236/300
 - 60s - loss: 3.8562e-04 - val_loss: 3.3053e-04
 - val_f1: 0.9998
Epoch 237/300
 - 60s - loss: 3.8523e-04 - val_loss: 3.5506e-04
 - val_f1: 0.9998
Epoch 238/300
 - 60s - loss: 3.9014e-04 - val_loss: 3.3336e-04
 - val_f1: 0.9998
Epoch 239/300
 - 60s - loss: 3.8508e-04 - val_loss: 3.2801e-04
 - val_f1: 0.9998
Epoch 240/300
 - 60s - loss: 3.9293e-04 - val_loss: 3.1665e-04
 - val_f1: 0.9998
Epoch 241/300
 - 60s - loss: 3.8646e-04 - val_loss: 3.2242e-04
2019-12-31 05:08:15,544 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 60s - loss: 3.9785e-04 - val_loss: 3.1432e-04
 - val_f1: 0.9998
Epoch 243/300
 - 60s - loss: 3.7710e-04 - val_loss: 3.4222e-04
 - val_f1: 0.9998
Epoch 244/300
 - 60s - loss: 3.8223e-04 - val_loss: 3.1207e-04
 - val_f1: 0.9998
Epoch 245/300
 - 60s - loss: 3.7472e-04 - val_loss: 2.9633e-04
 - val_f1: 0.9998
Epoch 246/300
 - 60s - loss: 3.8671e-04 - val_loss: 3.0331e-04
 - val_f1: 0.9998
Epoch 247/300
 - 60s - loss: 3.7649e-04 - val_loss: 3.0565e-04
 - val_f1: 0.9998
Epoch 248/300
 - 60s - loss: 3.8144e-04 - val_loss: 2.9798e-04
 - val_f1: 0.9998
Epoch 249/300
 - 60s - loss: 3.9254e-04 - val_loss: 3.0088e-04
 - val_f1: 0.9998
Epoch 250/300
 - 60s - loss: 3.9023e-04 - val_loss: 3.1396e-04
 - val_f1: 0.9998
Epoch 251/300
 - 60s - loss: 3.7669e-04 - val_loss: 3.0331e-04
 - val_f1: 0.9998
Epoch 252/300
 - 60s - loss: 3.8625e-04 - val_loss: 3.1918e-04
 - val_f1: 0.9998
Epoch 253/300
 - 60s - loss: 3.6613e-04 - val_loss: 3.3689e-04
 - val_f1: 0.9998
Epoch 254/300
 - 60s - loss: 3.7822e-04 - val_loss: 3.3882e-04
 - val_f1: 0.9998
Epoch 255/300
 - 60s - loss: 3.7030e-04 - val_loss: 3.0697e-04
 - val_f1: 0.9998
Epoch 256/300
 - 60s - loss: 3.8079e-04 - val_loss: 3.1348e-04
 - val_f1: 0.9998
Epoch 257/300
 - 60s - loss: 3.7182e-04 - val_loss: 2.9266e-04
 - val_f1: 0.9998
Epoch 258/300
 - 60s - loss: 3.7760e-04 - val_loss: 3.0674e-04
 - val_f1: 0.9998
Epoch 259/300
 - 60s - loss: 3.6765e-04 - val_loss: 3.2743e-04
 - val_f1: 0.9998
Epoch 260/300
 - 60s - loss: 3.6490e-04 - val_loss: 2.9342e-04
 - val_f1: 0.9998
Epoch 261/300
 - 60s - loss: 3.7297e-04 - val_loss: 3.2179e-04
 - val_f1: 0.9998
Epoch 262/300
 - 60s - loss: 3.5563e-04 - val_loss: 3.1277e-04
 - val_f1: 0.9998
Epoch 263/300
 - 60s - loss: 3.6954e-04 - val_loss: 3.2979e-04
 - val_f1: 0.9998
Epoch 264/300
 - 60s - loss: 3.7130e-04 - val_loss: 3.0336e-04
 - val_f1: 0.9998
Epoch 265/300
 - 60s - loss: 3.6174e-04 - val_loss: 3.2273e-04
 - val_f1: 0.9998
Epoch 266/300
 - 60s - loss: 3.7916e-04 - val_loss: 2.9698e-04
 - val_f1: 0.9998
Epoch 267/300
 - 60s - loss: 3.6599e-04 - val_loss: 3.0566e-04
 - val_f1: 0.9998
Epoch 268/300
 - 60s - loss: 3.6765e-04 - val_loss: 3.3445e-04
 - val_f1: 0.9998
Epoch 269/300
 - 60s - loss: 3.6181e-04 - val_loss: 3.0165e-04
 - val_f1: 0.9998
Epoch 270/300
 - 60s - loss: 3.5982e-04 - val_loss: 3.0943e-04
 - val_f1: 0.9998
Epoch 271/300
 - 60s - loss: 3.5893e-04 - val_loss: 3.1953e-04
2019-12-31 05:49:45,712 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 60s - loss: 3.6280e-04 - val_loss: 3.1711e-04
 - val_f1: 0.9998
Epoch 273/300
 - 60s - loss: 3.8141e-04 - val_loss: 2.9042e-04
 - val_f1: 0.9998
Epoch 274/300
 - 60s - loss: 3.5915e-04 - val_loss: 3.0904e-04
 - val_f1: 0.9998
Epoch 275/300
 - 60s - loss: 3.6876e-04 - val_loss: 3.0879e-04
 - val_f1: 0.9998
Epoch 276/300
 - 60s - loss: 3.7931e-04 - val_loss: 3.3719e-04
 - val_f1: 0.9998
Epoch 277/300
 - 60s - loss: 3.7351e-04 - val_loss: 3.0432e-04
 - val_f1: 0.9998
Epoch 278/300
 - 60s - loss: 3.6350e-04 - val_loss: 2.9639e-04
 - val_f1: 0.9998
Epoch 279/300
 - 60s - loss: 3.6236e-04 - val_loss: 2.8986e-04
 - val_f1: 0.9998
Epoch 280/300
 - 60s - loss: 3.5546e-04 - val_loss: 3.1945e-04
 - val_f1: 0.9998
Epoch 281/300
 - 60s - loss: 3.5473e-04 - val_loss: 3.0566e-04
 - val_f1: 0.9998
Epoch 282/300
 - 60s - loss: 3.6566e-04 - val_loss: 3.2712e-04
 - val_f1: 0.9998
Epoch 283/300
 - 60s - loss: 3.5542e-04 - val_loss: 2.9958e-04
 - val_f1: 0.9998
Epoch 284/300
 - 60s - loss: 3.6776e-04 - val_loss: 3.3188e-04
 - val_f1: 0.9998
Epoch 285/300
 - 60s - loss: 3.5791e-04 - val_loss: 3.1486e-04
 - val_f1: 0.9998
Epoch 286/300
 - 60s - loss: 3.4139e-04 - val_loss: 3.0539e-04
 - val_f1: 0.9998
Epoch 287/300
 - 60s - loss: 3.6238e-04 - val_loss: 3.1733e-04
 - val_f1: 0.9998
Epoch 288/300
 - 60s - loss: 3.6924e-04 - val_loss: 2.9029e-04
 - val_f1: 0.9998
Epoch 289/300
 - 60s - loss: 3.6172e-04 - val_loss: 3.0226e-04
 - val_f1: 0.9998
Epoch 290/300
 - 60s - loss: 3.6114e-04 - val_loss: 2.9780e-04
 - val_f1: 0.9998
Epoch 291/300
 - 60s - loss: 3.4920e-04 - val_loss: 2.8644e-04
 - val_f1: 0.9998
Epoch 292/300
 - 60s - loss: 3.4353e-04 - val_loss: 2.8512e-04
 - val_f1: 0.9998
Epoch 293/300
 - 60s - loss: 3.5393e-04 - val_loss: 2.9594e-04
 - val_f1: 0.9998
Epoch 294/300
 - 60s - loss: 3.5441e-04 - val_loss: 3.0956e-04
 - val_f1: 0.9998
Epoch 295/300
 - 60s - loss: 3.5778e-04 - val_loss: 3.2470e-04
 - val_f1: 0.9998
Epoch 296/300
 - 60s - loss: 3.4874e-04 - val_loss: 3.1614e-04
 - val_f1: 0.9998
Epoch 297/300
 - 60s - loss: 3.5207e-04 - val_loss: 3.0018e-04
 - val_f1: 0.9998
Epoch 298/300
 - 60s - loss: 3.4802e-04 - val_loss: 3.0067e-04
 - val_f1: 0.9998
Epoch 299/300
 - 60s - loss: 3.4691e-04 - val_loss: 2.8549e-04
 - val_f1: 0.9998
Epoch 300/300
 - 60s - loss: 3.4526e-04 - val_loss: 3.0504e-04
2019-12-31 06:30:12,779 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 06:31:57,048 [INFO] Last epoch loss evaluation: train_loss = 0.000221, val_loss = 0.000285
2019-12-31 06:31:57,062 [INFO] Training complete. time_to_train = 27870.08 sec, 464.50 min
2019-12-31 06:31:57,070 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_deep_rep2/best_model.pickle
2019-12-31 06:31:57,073 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_deep_rep2/training_error_history.csv
2019-12-31 06:31:57,260 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep2/training_error_history.png
2019-12-31 06:31:57,442 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep2/training_f1_history.png
2019-12-31 06:31:57,442 [INFO] Making predictions on training, validation, testing data
2019-12-31 06:33:56,955 [INFO] Evaluating predictions (results)
2019-12-31 06:34:05,629 [INFO] Dataset: Testing. Classification report below
2019-12-31 06:34:05,629 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.90      0.74      0.81      4166
         r2l       0.94      0.02      0.05     13781
         u2r       0.83      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.88      0.54      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-31 06:34:05,630 [INFO] Overall accuracy (micro avg): 0.9217982889055362
2019-12-31 06:34:14,921 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9218         0.9218                       0.9218                0.0196                   0.0782  0.9218
1     Macro avg        0.9687         0.8779                       0.5439                0.0212                   0.4561  0.5354
2  Weighted avg        0.9658         0.9370                       0.9218                0.0276                   0.0782  0.9025
2019-12-31 06:34:45,023 [INFO] Dataset: Validation. Classification report below
2019-12-31 06:34:45,023 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.97      0.84      0.90       225
         u2r       0.40      0.20      0.27        10

    accuracy                           1.00    979687
   macro avg       0.87      0.81      0.83    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-31 06:34:45,023 [INFO] Overall accuracy (micro avg): 0.9998448484056642
2019-12-31 06:35:17,504 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8733                       0.8076                0.0001                   0.1924  0.8329
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-31 06:37:30,368 [INFO] Dataset: Training. Classification report below
2019-12-31 06:37:30,368 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.94      0.87      0.91       901
         u2r       1.00      0.48      0.65        42

    accuracy                           1.00   3918744
   macro avg       0.99      0.87      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-31 06:37:30,368 [INFO] Overall accuracy (micro avg): 0.999858883356504
2019-12-31 06:39:53,793 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.9880                       0.8685                0.0001                   0.1315  0.9094
2  Weighted avg        0.9999         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-31 06:39:53,839 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_deep_rep2/selected_kdd99_dbn_deep_rep2_results.xlsx
2019-12-31 06:39:53,846 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-31 06:39:53,872 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_deep_rep3
2019-12-31 06:39:53,872 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_deep_rep3/run_log.log
2019-12-31 06:39:53,872 [INFO] ================= Running experiment no. 3  ================= 

2019-12-31 06:39:53,872 [INFO] Experiment parameters given below
2019-12-31 06:39:53,872 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_kdd99_dbn_deep_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 34], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.4], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_deep_rep3'}
2019-12-31 06:39:53,872 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_deep_rep3/tf_logs_run_2019_12_31-06_39_53
2019-12-31 06:39:53,873 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-31 06:39:53,873 [INFO] Reading X, y files
2019-12-31 06:39:53,873 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-31 06:40:00,298 [INFO] Reading complete. time_to_read=6.43 seconds
2019-12-31 06:40:00,299 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-31 06:40:01,917 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-31 06:40:01,917 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-31 06:40:02,382 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-31 06:40:02,382 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-31 06:40:02,579 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-31 06:40:02,579 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-31 06:40:02,632 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-31 06:40:02,632 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-31 06:40:02,651 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-31 06:40:09,882 [INFO] Initializing model
2019-12-31 06:40:09,882 [INFO] Training model
2019-12-31 06:40:09,882 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-31 06:40:50,537 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = b2557011c71e7a11d79e153811369ddb98e921b0
2019-12-31 06:40:50,537 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9998
[BernoulliRBM] Iteration 1, pseudo-likelihood = -65.51, time = 17.67s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -95.04, time = 30.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -121.17, time = 29.74s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -148.86, time = 29.34s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -177.79, time = 28.86s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -206.43, time = 28.72s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -235.28, time = 28.66s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -264.19, time = 28.77s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -292.90, time = 28.76s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -321.84, time = 28.74s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -350.95, time = 28.73s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -380.07, time = 28.73s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -408.87, time = 28.71s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -437.63, time = 28.70s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -466.50, time = 28.71s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -495.44, time = 28.70s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -524.50, time = 28.68s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -553.80, time = 28.70s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -583.06, time = 28.71s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -612.30, time = 29.09s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -641.60, time = 28.68s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -670.74, time = 28.69s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -700.08, time = 28.68s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -729.29, time = 28.76s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -758.45, time = 28.73s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -787.59, time = 28.70s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -816.76, time = 28.71s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -846.02, time = 28.74s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -875.25, time = 28.69s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -904.47, time = 28.69s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -933.69, time = 28.71s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -962.84, time = 28.72s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -991.95, time = 28.72s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -1021.06, time = 28.98s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -1050.19, time = 29.60s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -1079.32, time = 30.21s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -1108.47, time = 30.18s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1137.62, time = 29.65s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1166.74, time = 29.85s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1195.89, time = 35.82s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1225.03, time = 30.68s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1254.20, time = 31.07s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1283.35, time = 32.01s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1312.51, time = 29.91s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1341.64, time = 30.54s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1370.80, time = 29.56s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1399.96, time = 29.60s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1429.10, time = 29.29s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1458.26, time = 28.70s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1487.42, time = 28.92s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.83, time = 10.79s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.92, time = 17.16s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.46, time = 17.03s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.14, time = 16.96s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.43, time = 16.91s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.01, time = 16.92s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.68, time = 16.92s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.26, time = 16.91s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.04, time = 16.91s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.84, time = 16.91s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -3.64, time = 16.93s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -3.53, time = 16.96s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.36, time = 16.98s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.25, time = 16.95s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -3.18, time = 16.93s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -3.12, time = 16.94s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -3.07, time = 16.94s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -3.04, time = 16.94s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -3.01, time = 16.96s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.98, time = 17.20s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -2.96, time = 17.01s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -2.88, time = 17.02s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -2.72, time = 16.93s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -2.58, time = 16.94s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -2.48, time = 16.86s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -2.42, time = 16.86s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -2.36, time = 16.83s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -2.32, time = 16.84s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -2.29, time = 16.85s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -2.26, time = 16.84s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -2.23, time = 16.84s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -2.21, time = 16.83s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -2.19, time = 16.84s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -2.18, time = 16.83s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -2.16, time = 16.83s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -2.15, time = 16.84s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -2.14, time = 16.83s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -2.12, time = 16.83s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -2.11, time = 16.85s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -2.11, time = 16.85s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -2.10, time = 16.86s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -2.09, time = 16.85s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -2.08, time = 16.84s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -2.08, time = 16.84s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -2.07, time = 16.85s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -2.03, time = 16.85s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -2.01, time = 16.87s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1.99, time = 16.85s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1.98, time = 16.86s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1.97, time = 16.87s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -12.41, time = 5.21s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -10.83, time = 8.31s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -10.07, time = 8.32s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -9.31, time = 8.31s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -8.60, time = 8.30s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -8.13, time = 8.26s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -7.77, time = 8.23s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -7.36, time = 8.22s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -7.21, time = 8.22s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -7.12, time = 8.22s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -7.06, time = 8.22s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -7.00, time = 8.22s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -6.87, time = 8.22s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -6.82, time = 8.22s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -6.80, time = 8.21s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -6.75, time = 8.22s2019-12-31 07:26:19,365 [INFO] Pretraining Complete
2019-12-31 07:26:19,365 [INFO] Getting pretrained weights
2019-12-31 07:26:19,365 [INFO] Creating and initializing feed forward neural network
2019-12-31 07:26:19,653 [INFO] _________________________________________________________________
2019-12-31 07:26:19,654 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 07:26:19,654 [INFO] =================================================================
2019-12-31 07:26:19,654 [INFO] dense_9 (Dense)              (None, 128)               15872     
2019-12-31 07:26:19,654 [INFO] _________________________________________________________________
2019-12-31 07:26:19,654 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2019-12-31 07:26:19,654 [INFO] _________________________________________________________________
2019-12-31 07:26:19,654 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2019-12-31 07:26:19,654 [INFO] _________________________________________________________________
2019-12-31 07:26:19,654 [INFO] dense_10 (Dense)             (None, 64)                8256      
2019-12-31 07:26:19,654 [INFO] _________________________________________________________________
2019-12-31 07:26:19,654 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2019-12-31 07:26:19,655 [INFO] _________________________________________________________________
2019-12-31 07:26:19,655 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2019-12-31 07:26:19,655 [INFO] _________________________________________________________________
2019-12-31 07:26:19,655 [INFO] dense_11 (Dense)             (None, 34)                2210      
2019-12-31 07:26:19,655 [INFO] _________________________________________________________________
2019-12-31 07:26:19,655 [INFO] batch_normalization_9 (Batch (None, 34)                136       
2019-12-31 07:26:19,655 [INFO] _________________________________________________________________
2019-12-31 07:26:19,655 [INFO] dropout_9 (Dropout)          (None, 34)                0         
2019-12-31 07:26:19,655 [INFO] _________________________________________________________________
2019-12-31 07:26:19,655 [INFO] dense_12 (Dense)             (None, 5)                 175       
2019-12-31 07:26:19,655 [INFO] =================================================================
2019-12-31 07:26:19,656 [INFO] Total params: 27,417
2019-12-31 07:26:19,656 [INFO] Trainable params: 26,965
2019-12-31 07:26:19,656 [INFO] Non-trainable params: 452
2019-12-31 07:26:19,656 [INFO] _________________________________________________________________
2019-12-31 07:26:20,325 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -6.73, time = 8.21s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -6.72, time = 8.21s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -6.71, time = 8.22s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -6.69, time = 8.21s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -6.67, time = 8.21s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -6.67, time = 8.21s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -6.64, time = 8.21s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -6.65, time = 8.20s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -6.63, time = 8.20s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -6.62, time = 8.21s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -6.61, time = 8.21s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -6.60, time = 8.21s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -6.59, time = 8.21s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -6.59, time = 8.21s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -6.49, time = 8.21s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -6.47, time = 8.21s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -6.47, time = 8.21s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -6.46, time = 8.21s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -6.46, time = 8.21s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -6.45, time = 8.21s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -6.46, time = 8.21s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -6.45, time = 8.21s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -6.45, time = 8.21s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -6.44, time = 8.21s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -6.45, time = 8.21s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -6.43, time = 8.90s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -6.43, time = 8.21s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -6.43, time = 8.20s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -6.43, time = 8.20s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -6.43, time = 8.20s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -6.42, time = 8.20s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -6.42, time = 8.20s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -6.42, time = 8.20s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -6.42, time = 8.20s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/300
 - 63s - loss: 0.0213 - val_loss: 0.0072
 - val_f1: 0.9956
Epoch 2/300
 - 61s - loss: 0.0081 - val_loss: 0.0055
 - val_f1: 0.9972
Epoch 3/300
 - 61s - loss: 0.0066 - val_loss: 0.0046
 - val_f1: 0.9975
Epoch 4/300
 - 61s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9979
Epoch 5/300
 - 61s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9983
Epoch 6/300
 - 61s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9985
Epoch 7/300
 - 61s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9985
Epoch 8/300
 - 61s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9986
Epoch 9/300
 - 61s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9986
Epoch 10/300
 - 61s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9987
Epoch 11/300
 - 61s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9986
Epoch 12/300
 - 61s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9987
Epoch 13/300
 - 61s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9987
Epoch 14/300
 - 61s - loss: 0.0027 - val_loss: 0.0021
 - val_f1: 0.9987
Epoch 15/300
 - 61s - loss: 0.0026 - val_loss: 0.0021
 - val_f1: 0.9987
Epoch 16/300
 - 61s - loss: 0.0025 - val_loss: 0.0019
 - val_f1: 0.9987
Epoch 17/300
 - 61s - loss: 0.0023 - val_loss: 0.0017
 - val_f1: 0.9988
Epoch 18/300
 - 61s - loss: 0.0021 - val_loss: 0.0014
 - val_f1: 0.9988
Epoch 19/300
 - 61s - loss: 0.0020 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 20/300
 - 61s - loss: 0.0019 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 21/300
 - 61s - loss: 0.0019 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 22/300
 - 62s - loss: 0.0018 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 23/300
 - 61s - loss: 0.0017 - val_loss: 0.0012
 - val_f1: 0.9994
Epoch 24/300
 - 61s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 25/300
 - 61s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 26/300
 - 61s - loss: 0.0015 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 27/300
 - 61s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 28/300
 - 61s - loss: 0.0015 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 29/300
 - 61s - loss: 0.0014 - val_loss: 9.6877e-04
 - val_f1: 0.9994
Epoch 30/300
 - 61s - loss: 0.0014 - val_loss: 9.5079e-04
 - val_f1: 0.9994
Epoch 31/300
 - 61s - loss: 0.0014 - val_loss: 9.0496e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 08:10:43,949 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9995
Epoch 32/300
 - 61s - loss: 0.0013 - val_loss: 8.9248e-04
 - val_f1: 0.9995
Epoch 33/300
 - 61s - loss: 0.0013 - val_loss: 9.0382e-04
 - val_f1: 0.9995
Epoch 34/300
 - 61s - loss: 0.0013 - val_loss: 9.2463e-04
 - val_f1: 0.9995
Epoch 35/300
 - 61s - loss: 0.0013 - val_loss: 9.1015e-04
 - val_f1: 0.9994
Epoch 36/300
 - 61s - loss: 0.0012 - val_loss: 8.5344e-04
 - val_f1: 0.9995
Epoch 37/300
 - 61s - loss: 0.0012 - val_loss: 8.5190e-04
 - val_f1: 0.9995
Epoch 38/300
 - 61s - loss: 0.0012 - val_loss: 8.0236e-04
 - val_f1: 0.9995
Epoch 39/300
 - 61s - loss: 0.0012 - val_loss: 7.5899e-04
 - val_f1: 0.9995
Epoch 40/300
 - 61s - loss: 0.0012 - val_loss: 7.7080e-04
 - val_f1: 0.9995
Epoch 41/300
 - 61s - loss: 0.0011 - val_loss: 7.7475e-04
 - val_f1: 0.9995
Epoch 42/300
 - 61s - loss: 0.0011 - val_loss: 7.5388e-04
 - val_f1: 0.9995
Epoch 43/300
 - 61s - loss: 0.0011 - val_loss: 7.1514e-04
 - val_f1: 0.9996
Epoch 44/300
 - 61s - loss: 0.0011 - val_loss: 7.4686e-04
 - val_f1: 0.9995
Epoch 45/300
 - 61s - loss: 0.0010 - val_loss: 7.5687e-04
 - val_f1: 0.9995
Epoch 46/300
 - 61s - loss: 9.9567e-04 - val_loss: 6.3959e-04
 - val_f1: 0.9996
Epoch 47/300
 - 61s - loss: 0.0010 - val_loss: 6.6176e-04
 - val_f1: 0.9996
Epoch 48/300
 - 61s - loss: 0.0010 - val_loss: 6.7471e-04
 - val_f1: 0.9996
Epoch 49/300
 - 61s - loss: 9.8145e-04 - val_loss: 6.4890e-04
 - val_f1: 0.9996
Epoch 50/300
 - 61s - loss: 9.6228e-04 - val_loss: 6.5552e-04
 - val_f1: 0.9996
Epoch 51/300
 - 61s - loss: 9.8121e-04 - val_loss: 6.8121e-04
 - val_f1: 0.9996
Epoch 52/300
 - 61s - loss: 9.3145e-04 - val_loss: 6.5589e-04
 - val_f1: 0.9996
Epoch 53/300
 - 61s - loss: 9.3521e-04 - val_loss: 6.8559e-04
 - val_f1: 0.9996
Epoch 54/300
 - 61s - loss: 9.2072e-04 - val_loss: 6.7339e-04
 - val_f1: 0.9996
Epoch 55/300
 - 61s - loss: 9.1192e-04 - val_loss: 6.1114e-04
 - val_f1: 0.9996
Epoch 56/300
 - 61s - loss: 9.2102e-04 - val_loss: 6.4185e-04
 - val_f1: 0.9996
Epoch 57/300
 - 61s - loss: 8.9816e-04 - val_loss: 6.4059e-04
 - val_f1: 0.9996
Epoch 58/300
 - 61s - loss: 9.0725e-04 - val_loss: 6.7170e-04
 - val_f1: 0.9996
Epoch 59/300
 - 61s - loss: 8.6509e-04 - val_loss: 5.9010e-04
 - val_f1: 0.9996
Epoch 60/300
 - 61s - loss: 8.5610e-04 - val_loss: 6.0476e-04
 - val_f1: 0.9996
Epoch 61/300
 - 67s - loss: 8.6049e-04 - val_loss: 5.9444e-04
2019-12-31 08:54:09,386 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9996
Epoch 62/300
 - 61s - loss: 8.5121e-04 - val_loss: 5.8996e-04
 - val_f1: 0.9996
Epoch 63/300
 - 61s - loss: 8.5725e-04 - val_loss: 5.7765e-04
 - val_f1: 0.9996
Epoch 64/300
 - 61s - loss: 8.3018e-04 - val_loss: 5.9700e-04
 - val_f1: 0.9996
Epoch 65/300
 - 61s - loss: 8.4522e-04 - val_loss: 6.0636e-04
 - val_f1: 0.9996
Epoch 66/300
 - 61s - loss: 8.2326e-04 - val_loss: 5.5646e-04
 - val_f1: 0.9996
Epoch 67/300
 - 61s - loss: 8.1934e-04 - val_loss: 5.5049e-04
 - val_f1: 0.9996
Epoch 68/300
 - 61s - loss: 8.1800e-04 - val_loss: 5.5421e-04
 - val_f1: 0.9996
Epoch 69/300
 - 61s - loss: 7.8559e-04 - val_loss: 5.8648e-04
 - val_f1: 0.9996
Epoch 70/300
 - 62s - loss: 7.9896e-04 - val_loss: 5.8720e-04
 - val_f1: 0.9996
Epoch 71/300
 - 61s - loss: 7.8710e-04 - val_loss: 5.4519e-04
 - val_f1: 0.9997
Epoch 72/300
 - 61s - loss: 8.1191e-04 - val_loss: 5.5339e-04
 - val_f1: 0.9996
Epoch 73/300
 - 61s - loss: 7.7198e-04 - val_loss: 5.4168e-04
 - val_f1: 0.9997
Epoch 74/300
 - 61s - loss: 7.8504e-04 - val_loss: 5.3030e-04
 - val_f1: 0.9996
Epoch 75/300
 - 61s - loss: 7.7788e-04 - val_loss: 5.6235e-04
 - val_f1: 0.9996
Epoch 76/300
 - 61s - loss: 7.7154e-04 - val_loss: 5.4304e-04
 - val_f1: 0.9996
Epoch 77/300
 - 61s - loss: 7.4545e-04 - val_loss: 5.4309e-04
 - val_f1: 0.9996
Epoch 78/300
 - 61s - loss: 7.3264e-04 - val_loss: 5.3222e-04
 - val_f1: 0.9996
Epoch 79/300
 - 61s - loss: 7.4725e-04 - val_loss: 5.1699e-04
 - val_f1: 0.9997
Epoch 80/300
 - 61s - loss: 7.5717e-04 - val_loss: 5.4740e-04
 - val_f1: 0.9997
Epoch 81/300
 - 61s - loss: 7.1439e-04 - val_loss: 5.2525e-04
 - val_f1: 0.9996
Epoch 82/300
 - 61s - loss: 7.5009e-04 - val_loss: 5.0764e-04
 - val_f1: 0.9996
Epoch 83/300
 - 61s - loss: 7.2823e-04 - val_loss: 5.1738e-04
 - val_f1: 0.9997
Epoch 84/300
 - 62s - loss: 7.2191e-04 - val_loss: 5.0468e-04
 - val_f1: 0.9996
Epoch 85/300
 - 61s - loss: 7.0885e-04 - val_loss: 5.4401e-04
 - val_f1: 0.9997
Epoch 86/300
 - 61s - loss: 7.1790e-04 - val_loss: 5.3529e-04
 - val_f1: 0.9996
Epoch 87/300
 - 61s - loss: 7.0347e-04 - val_loss: 5.3427e-04
 - val_f1: 0.9996
Epoch 88/300
 - 62s - loss: 6.9740e-04 - val_loss: 5.1808e-04
 - val_f1: 0.9997
Epoch 89/300
 - 61s - loss: 7.3555e-04 - val_loss: 4.9175e-04
 - val_f1: 0.9997
Epoch 90/300
 - 62s - loss: 6.8968e-04 - val_loss: 5.4685e-04
 - val_f1: 0.9997
Epoch 91/300
 - 61s - loss: 7.0459e-04 - val_loss: 4.8349e-04
2019-12-31 09:37:35,524 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9997
Epoch 92/300
 - 61s - loss: 6.7689e-04 - val_loss: 4.9530e-04
 - val_f1: 0.9997
Epoch 93/300
 - 61s - loss: 7.0363e-04 - val_loss: 4.9875e-04
 - val_f1: 0.9997
Epoch 94/300
 - 61s - loss: 6.9659e-04 - val_loss: 4.8294e-04
 - val_f1: 0.9997
Epoch 95/300
 - 61s - loss: 6.8100e-04 - val_loss: 5.0671e-04
 - val_f1: 0.9997
Epoch 96/300
 - 61s - loss: 6.8345e-04 - val_loss: 4.9556e-04
 - val_f1: 0.9997
Epoch 97/300
 - 61s - loss: 6.7325e-04 - val_loss: 5.1190e-04
 - val_f1: 0.9997
Epoch 98/300
 - 61s - loss: 6.6107e-04 - val_loss: 4.7813e-04
 - val_f1: 0.9997
Epoch 99/300
 - 61s - loss: 6.6797e-04 - val_loss: 4.9922e-04
 - val_f1: 0.9997
Epoch 100/300
 - 61s - loss: 6.7374e-04 - val_loss: 5.0083e-04
 - val_f1: 0.9997
Epoch 101/300
 - 61s - loss: 6.5898e-04 - val_loss: 4.7102e-04
 - val_f1: 0.9997
Epoch 102/300
 - 61s - loss: 6.5790e-04 - val_loss: 4.8642e-04
 - val_f1: 0.9997
Epoch 103/300
 - 61s - loss: 6.5033e-04 - val_loss: 4.8608e-04
 - val_f1: 0.9997
Epoch 104/300
 - 61s - loss: 6.6068e-04 - val_loss: 4.7403e-04
 - val_f1: 0.9997
Epoch 105/300
 - 61s - loss: 6.4169e-04 - val_loss: 5.0636e-04
 - val_f1: 0.9997
Epoch 106/300
 - 61s - loss: 6.5340e-04 - val_loss: 5.0820e-04
 - val_f1: 0.9997
Epoch 107/300
 - 61s - loss: 6.4295e-04 - val_loss: 5.0988e-04
 - val_f1: 0.9997
Epoch 108/300
 - 61s - loss: 6.3727e-04 - val_loss: 4.6879e-04
 - val_f1: 0.9997
Epoch 109/300
 - 61s - loss: 6.3936e-04 - val_loss: 5.0163e-04
 - val_f1: 0.9997
Epoch 110/300
 - 61s - loss: 6.3691e-04 - val_loss: 4.9227e-04
 - val_f1: 0.9997
Epoch 111/300
 - 61s - loss: 6.3572e-04 - val_loss: 4.5906e-04
 - val_f1: 0.9997
Epoch 112/300
 - 61s - loss: 6.1700e-04 - val_loss: 4.6791e-04
 - val_f1: 0.9997
Epoch 113/300
 - 61s - loss: 6.1983e-04 - val_loss: 5.0378e-04
 - val_f1: 0.9997
Epoch 114/300
 - 61s - loss: 6.0965e-04 - val_loss: 4.6328e-04
 - val_f1: 0.9997
Epoch 115/300
 - 61s - loss: 6.2436e-04 - val_loss: 4.7106e-04
 - val_f1: 0.9997
Epoch 116/300
 - 61s - loss: 6.1685e-04 - val_loss: 4.6930e-04
 - val_f1: 0.9997
Epoch 117/300
 - 61s - loss: 6.2023e-04 - val_loss: 4.5746e-04
 - val_f1: 0.9997
Epoch 118/300
 - 61s - loss: 6.0223e-04 - val_loss: 4.9076e-04
 - val_f1: 0.9997
Epoch 119/300
 - 61s - loss: 6.0083e-04 - val_loss: 4.7327e-04
 - val_f1: 0.9997
Epoch 120/300
 - 61s - loss: 6.1220e-04 - val_loss: 4.6003e-04
 - val_f1: 0.9997
Epoch 121/300
 - 61s - loss: 5.9097e-04 - val_loss: 4.9218e-04
2019-12-31 10:20:59,489 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/300
 - 61s - loss: 6.0646e-04 - val_loss: 4.5784e-04
 - val_f1: 0.9997
Epoch 123/300
 - 61s - loss: 5.9891e-04 - val_loss: 4.8135e-04
 - val_f1: 0.9997
Epoch 124/300
 - 61s - loss: 6.0322e-04 - val_loss: 4.8077e-04
 - val_f1: 0.9997
Epoch 125/300
 - 61s - loss: 5.9087e-04 - val_loss: 4.5304e-04
 - val_f1: 0.9997
Epoch 126/300
 - 61s - loss: 5.9858e-04 - val_loss: 4.7056e-04
 - val_f1: 0.9997
Epoch 127/300
 - 61s - loss: 5.9318e-04 - val_loss: 4.6068e-04
 - val_f1: 0.9997
Epoch 128/300
 - 61s - loss: 6.0198e-04 - val_loss: 4.4539e-04
 - val_f1: 0.9997
Epoch 129/300
 - 61s - loss: 5.8052e-04 - val_loss: 4.5188e-04
 - val_f1: 0.9997
Epoch 130/300
 - 61s - loss: 6.0812e-04 - val_loss: 4.6210e-04
 - val_f1: 0.9998
Epoch 131/300
 - 61s - loss: 5.7371e-04 - val_loss: 4.7135e-04
 - val_f1: 0.9997
Epoch 132/300
 - 61s - loss: 5.7661e-04 - val_loss: 4.5868e-04
 - val_f1: 0.9997
Epoch 133/300
 - 61s - loss: 5.8571e-04 - val_loss: 4.6872e-04
 - val_f1: 0.9997
Epoch 134/300
 - 61s - loss: 5.7406e-04 - val_loss: 4.8725e-04
 - val_f1: 0.9997
Epoch 135/300
 - 61s - loss: 5.7262e-04 - val_loss: 4.7647e-04
 - val_f1: 0.9997
Epoch 136/300
 - 61s - loss: 5.6551e-04 - val_loss: 4.6393e-04
 - val_f1: 0.9997
Epoch 137/300
 - 61s - loss: 5.7541e-04 - val_loss: 4.5081e-04
 - val_f1: 0.9997
Epoch 138/300
 - 61s - loss: 5.4318e-04 - val_loss: 4.7360e-04
 - val_f1: 0.9997
Epoch 139/300
 - 61s - loss: 5.7478e-04 - val_loss: 4.5642e-04
 - val_f1: 0.9997
Epoch 140/300
 - 61s - loss: 5.7369e-04 - val_loss: 4.4425e-04
 - val_f1: 0.9998
Epoch 141/300
 - 61s - loss: 5.6679e-04 - val_loss: 4.4941e-04
 - val_f1: 0.9997
Epoch 142/300
 - 61s - loss: 5.3880e-04 - val_loss: 4.3466e-04
 - val_f1: 0.9997
Epoch 143/300
 - 61s - loss: 5.6255e-04 - val_loss: 4.7449e-04
 - val_f1: 0.9997
Epoch 144/300
 - 61s - loss: 5.6333e-04 - val_loss: 4.7142e-04
 - val_f1: 0.9997
Epoch 145/300
 - 61s - loss: 5.5742e-04 - val_loss: 4.5968e-04
 - val_f1: 0.9997
Epoch 146/300
 - 61s - loss: 5.5394e-04 - val_loss: 4.6481e-04
 - val_f1: 0.9997
Epoch 147/300
 - 61s - loss: 5.6018e-04 - val_loss: 4.4129e-04
 - val_f1: 0.9997
Epoch 148/300
 - 61s - loss: 5.3389e-04 - val_loss: 4.3987e-04
 - val_f1: 0.9998
Epoch 149/300
 - 61s - loss: 5.4055e-04 - val_loss: 4.2790e-04
 - val_f1: 0.9998
Epoch 150/300
 - 61s - loss: 5.4943e-04 - val_loss: 4.7632e-04
 - val_f1: 0.9997
Epoch 151/300
 - 61s - loss: 5.5161e-04 - val_loss: 4.7820e-04
2019-12-31 11:04:20,580 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9997
Epoch 152/300
 - 61s - loss: 5.3230e-04 - val_loss: 4.4826e-04
 - val_f1: 0.9998
Epoch 153/300
 - 62s - loss: 5.5268e-04 - val_loss: 4.5415e-04
 - val_f1: 0.9998
Epoch 154/300
 - 61s - loss: 5.5331e-04 - val_loss: 4.3983e-04
 - val_f1: 0.9998
Epoch 155/300
 - 61s - loss: 5.4711e-04 - val_loss: 4.2180e-04
 - val_f1: 0.9998
Epoch 156/300
 - 61s - loss: 5.5094e-04 - val_loss: 4.4218e-04
 - val_f1: 0.9997
Epoch 157/300
 - 61s - loss: 5.5950e-04 - val_loss: 4.3770e-04
 - val_f1: 0.9998
Epoch 158/300
 - 61s - loss: 5.3805e-04 - val_loss: 4.4341e-04
 - val_f1: 0.9997
Epoch 159/300
 - 61s - loss: 5.2591e-04 - val_loss: 4.4536e-04
 - val_f1: 0.9998
Epoch 160/300
 - 61s - loss: 5.4026e-04 - val_loss: 4.3703e-04
 - val_f1: 0.9997
Epoch 161/300
 - 61s - loss: 5.4849e-04 - val_loss: 4.3244e-04
 - val_f1: 0.9998
Epoch 162/300
 - 61s - loss: 5.3419e-04 - val_loss: 4.5095e-04
 - val_f1: 0.9997
Epoch 163/300
 - 61s - loss: 5.2148e-04 - val_loss: 4.3703e-04
 - val_f1: 0.9998
Epoch 164/300
 - 61s - loss: 5.2758e-04 - val_loss: 4.4041e-04
 - val_f1: 0.9998
Epoch 165/300
 - 61s - loss: 5.2641e-04 - val_loss: 4.6233e-04
 - val_f1: 0.9997
Epoch 166/300
 - 61s - loss: 5.2472e-04 - val_loss: 4.5518e-04
 - val_f1: 0.9998
Epoch 167/300
 - 62s - loss: 5.3034e-04 - val_loss: 3.9748e-04
 - val_f1: 0.9998
Epoch 168/300
 - 61s - loss: 5.3341e-04 - val_loss: 4.4112e-04
 - val_f1: 0.9997
Epoch 169/300
 - 61s - loss: 5.3869e-04 - val_loss: 4.3696e-04
 - val_f1: 0.9998
Epoch 170/300
 - 61s - loss: 5.2356e-04 - val_loss: 4.2427e-04
 - val_f1: 0.9998
Epoch 171/300
 - 61s - loss: 5.1853e-04 - val_loss: 4.3998e-04
 - val_f1: 0.9998
Epoch 172/300
 - 61s - loss: 5.1895e-04 - val_loss: 4.0911e-04
 - val_f1: 0.9997
Epoch 173/300
 - 61s - loss: 5.1313e-04 - val_loss: 4.3388e-04
 - val_f1: 0.9998
Epoch 174/300
 - 61s - loss: 5.2052e-04 - val_loss: 4.0985e-04
 - val_f1: 0.9998
Epoch 175/300
 - 61s - loss: 5.0803e-04 - val_loss: 4.0885e-04
 - val_f1: 0.9998
Epoch 176/300
 - 61s - loss: 4.9266e-04 - val_loss: 4.2030e-04
 - val_f1: 0.9998
Epoch 177/300
 - 61s - loss: 5.0441e-04 - val_loss: 3.9353e-04
 - val_f1: 0.9998
Epoch 178/300
 - 61s - loss: 4.9692e-04 - val_loss: 4.2156e-04
 - val_f1: 0.9998
Epoch 179/300
 - 61s - loss: 5.0522e-04 - val_loss: 4.3193e-04
 - val_f1: 0.9997
Epoch 180/300
 - 61s - loss: 5.0234e-04 - val_loss: 4.0194e-04
 - val_f1: 0.9998
Epoch 181/300
 - 61s - loss: 4.9680e-04 - val_loss: 4.1460e-04
2019-12-31 11:47:42,022 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9997
Epoch 182/300
 - 61s - loss: 5.0323e-04 - val_loss: 4.2492e-04
 - val_f1: 0.9998
Epoch 183/300
 - 61s - loss: 4.9078e-04 - val_loss: 4.0048e-04
 - val_f1: 0.9998
Epoch 184/300
 - 61s - loss: 5.1314e-04 - val_loss: 4.1349e-04
 - val_f1: 0.9998
Epoch 185/300
 - 61s - loss: 4.9651e-04 - val_loss: 4.2874e-04
 - val_f1: 0.9998
Epoch 186/300
 - 61s - loss: 5.0150e-04 - val_loss: 4.1969e-04
 - val_f1: 0.9997
Epoch 187/300
 - 61s - loss: 4.9322e-04 - val_loss: 4.2836e-04
 - val_f1: 0.9998
Epoch 188/300
 - 61s - loss: 4.9338e-04 - val_loss: 4.0541e-04
 - val_f1: 0.9998
Epoch 189/300
 - 61s - loss: 4.9629e-04 - val_loss: 4.3727e-04
 - val_f1: 0.9997
Epoch 190/300
 - 61s - loss: 5.0526e-04 - val_loss: 3.9478e-04
 - val_f1: 0.9997
Epoch 191/300
 - 61s - loss: 4.9997e-04 - val_loss: 4.0534e-04
 - val_f1: 0.9998
Epoch 192/300
 - 61s - loss: 4.9570e-04 - val_loss: 4.0115e-04
 - val_f1: 0.9998
Epoch 193/300
 - 61s - loss: 5.0728e-04 - val_loss: 4.2056e-04
 - val_f1: 0.9998
Epoch 194/300
 - 61s - loss: 5.0658e-04 - val_loss: 4.0702e-04
 - val_f1: 0.9998
Epoch 195/300
 - 61s - loss: 4.8721e-04 - val_loss: 4.2219e-04
 - val_f1: 0.9998
Epoch 196/300
 - 61s - loss: 4.7255e-04 - val_loss: 4.0975e-04
 - val_f1: 0.9998
Epoch 197/300
 - 61s - loss: 4.9513e-04 - val_loss: 4.3445e-04
 - val_f1: 0.9998
Epoch 198/300
 - 61s - loss: 4.8838e-04 - val_loss: 3.9990e-04
 - val_f1: 0.9998
Epoch 199/300
 - 61s - loss: 4.7885e-04 - val_loss: 4.2523e-04
 - val_f1: 0.9997
Epoch 200/300
 - 61s - loss: 4.8461e-04 - val_loss: 4.0481e-04
 - val_f1: 0.9998
Epoch 201/300
 - 61s - loss: 4.7957e-04 - val_loss: 3.8599e-04
 - val_f1: 0.9998
Epoch 202/300
 - 61s - loss: 4.8225e-04 - val_loss: 3.9332e-04
 - val_f1: 0.9998
Epoch 203/300
 - 61s - loss: 4.8767e-04 - val_loss: 4.0948e-04
 - val_f1: 0.9998
Epoch 204/300
 - 63s - loss: 4.7467e-04 - val_loss: 4.0514e-04
 - val_f1: 0.9998
Epoch 205/300
 - 62s - loss: 4.7118e-04 - val_loss: 3.9611e-04
 - val_f1: 0.9998
Epoch 206/300
 - 62s - loss: 4.8412e-04 - val_loss: 3.8605e-04
 - val_f1: 0.9998
Epoch 207/300
 - 62s - loss: 4.7621e-04 - val_loss: 4.0112e-04
 - val_f1: 0.9998
Epoch 208/300
 - 62s - loss: 4.6726e-04 - val_loss: 3.9706e-04
 - val_f1: 0.9998
Epoch 209/300
 - 62s - loss: 4.7240e-04 - val_loss: 4.1921e-04
 - val_f1: 0.9998
Epoch 210/300
 - 62s - loss: 4.7740e-04 - val_loss: 3.9667e-04
 - val_f1: 0.9998
Epoch 211/300
 - 62s - loss: 4.8030e-04 - val_loss: 4.0299e-04
2019-12-31 12:31:10,349 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 62s - loss: 4.7123e-04 - val_loss: 4.0663e-04
 - val_f1: 0.9998
Epoch 213/300
 - 62s - loss: 4.7739e-04 - val_loss: 3.7813e-04
 - val_f1: 0.9998
Epoch 214/300
 - 62s - loss: 4.6195e-04 - val_loss: 3.7214e-04
 - val_f1: 0.9997
Epoch 215/300
 - 62s - loss: 4.7961e-04 - val_loss: 3.8366e-04
 - val_f1: 0.9998
Epoch 216/300
 - 62s - loss: 4.8153e-04 - val_loss: 3.8399e-04
 - val_f1: 0.9998
Epoch 217/300
 - 62s - loss: 4.5312e-04 - val_loss: 3.9090e-04
 - val_f1: 0.9998
Epoch 218/300
 - 62s - loss: 4.8079e-04 - val_loss: 4.0349e-04
 - val_f1: 0.9998
Epoch 219/300
 - 62s - loss: 4.5670e-04 - val_loss: 3.8868e-04
 - val_f1: 0.9998
Epoch 220/300
 - 62s - loss: 4.6171e-04 - val_loss: 3.6721e-04
 - val_f1: 0.9998
Epoch 221/300
 - 62s - loss: 4.6245e-04 - val_loss: 3.7931e-04
 - val_f1: 0.9998
Epoch 222/300
 - 62s - loss: 4.6546e-04 - val_loss: 3.8886e-04
 - val_f1: 0.9998
Epoch 223/300
 - 62s - loss: 4.5195e-04 - val_loss: 3.6418e-04
 - val_f1: 0.9998
Epoch 224/300
 - 62s - loss: 4.6758e-04 - val_loss: 3.8510e-04
 - val_f1: 0.9998
Epoch 225/300
 - 62s - loss: 4.5210e-04 - val_loss: 3.7525e-04
 - val_f1: 0.9998
Epoch 226/300
 - 62s - loss: 4.5365e-04 - val_loss: 3.9197e-04
 - val_f1: 0.9998
Epoch 227/300
 - 62s - loss: 4.5981e-04 - val_loss: 3.7710e-04
 - val_f1: 0.9998
Epoch 228/300
 - 62s - loss: 4.7490e-04 - val_loss: 3.5585e-04
 - val_f1: 0.9998
Epoch 229/300
 - 62s - loss: 4.4488e-04 - val_loss: 3.7964e-04
 - val_f1: 0.9998
Epoch 230/300
 - 62s - loss: 4.5061e-04 - val_loss: 3.7646e-04
 - val_f1: 0.9998
Epoch 231/300
 - 62s - loss: 4.3757e-04 - val_loss: 4.0313e-04
 - val_f1: 0.9998
Epoch 232/300
 - 62s - loss: 4.4467e-04 - val_loss: 3.7325e-04
 - val_f1: 0.9998
Epoch 233/300
 - 62s - loss: 4.5248e-04 - val_loss: 3.7993e-04
 - val_f1: 0.9998
Epoch 234/300
 - 62s - loss: 4.6140e-04 - val_loss: 3.6838e-04
 - val_f1: 0.9998
Epoch 235/300
 - 62s - loss: 4.3884e-04 - val_loss: 3.5645e-04
 - val_f1: 0.9998
Epoch 236/300
 - 62s - loss: 4.5239e-04 - val_loss: 3.6876e-04
 - val_f1: 0.9998
Epoch 237/300
 - 62s - loss: 4.5558e-04 - val_loss: 3.7946e-04
 - val_f1: 0.9998
Epoch 238/300
 - 62s - loss: 4.3495e-04 - val_loss: 3.6031e-04
 - val_f1: 0.9998
Epoch 239/300
 - 62s - loss: 4.5097e-04 - val_loss: 3.8323e-04
 - val_f1: 0.9998
Epoch 240/300
 - 62s - loss: 4.5071e-04 - val_loss: 3.7827e-04
 - val_f1: 0.9998
Epoch 241/300
 - 62s - loss: 4.3982e-04 - val_loss: 3.5545e-04
2019-12-31 13:15:00,633 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 62s - loss: 4.4953e-04 - val_loss: 3.7391e-04
 - val_f1: 0.9998
Epoch 243/300
 - 62s - loss: 4.3948e-04 - val_loss: 3.5045e-04
 - val_f1: 0.9998
Epoch 244/300
 - 62s - loss: 4.4632e-04 - val_loss: 3.6366e-04
 - val_f1: 0.9998
Epoch 245/300
 - 62s - loss: 4.5527e-04 - val_loss: 3.6668e-04
 - val_f1: 0.9998
Epoch 246/300
 - 62s - loss: 4.3826e-04 - val_loss: 3.5317e-04
 - val_f1: 0.9998
Epoch 247/300
 - 62s - loss: 4.4687e-04 - val_loss: 3.3824e-04
 - val_f1: 0.9998
Epoch 248/300
 - 62s - loss: 4.3168e-04 - val_loss: 3.4972e-04
 - val_f1: 0.9998
Epoch 249/300
 - 62s - loss: 4.3118e-04 - val_loss: 3.7502e-04
 - val_f1: 0.9998
Epoch 250/300
 - 62s - loss: 4.4002e-04 - val_loss: 3.4058e-04
 - val_f1: 0.9998
Epoch 251/300
 - 62s - loss: 4.3247e-04 - val_loss: 3.4149e-04
 - val_f1: 0.9998
Epoch 252/300
 - 62s - loss: 4.3389e-04 - val_loss: 3.6615e-04
 - val_f1: 0.9998
Epoch 253/300
 - 62s - loss: 4.3447e-04 - val_loss: 3.5192e-04
 - val_f1: 0.9998
Epoch 254/300
 - 62s - loss: 4.3423e-04 - val_loss: 3.4160e-04
 - val_f1: 0.9998
Epoch 255/300
 - 62s - loss: 4.4023e-04 - val_loss: 3.5588e-04
 - val_f1: 0.9998
Epoch 256/300
 - 62s - loss: 4.3052e-04 - val_loss: 3.6780e-04
 - val_f1: 0.9998
Epoch 257/300
 - 62s - loss: 4.1560e-04 - val_loss: 3.3823e-04
 - val_f1: 0.9998
Epoch 258/300
 - 62s - loss: 4.3415e-04 - val_loss: 3.4129e-04
 - val_f1: 0.9998
Epoch 259/300
 - 62s - loss: 4.2298e-04 - val_loss: 3.3935e-04
 - val_f1: 0.9998
Epoch 260/300
 - 62s - loss: 4.2457e-04 - val_loss: 3.3490e-04
 - val_f1: 0.9998
Epoch 261/300
 - 62s - loss: 4.2826e-04 - val_loss: 3.4340e-04
 - val_f1: 0.9998
Epoch 262/300
 - 62s - loss: 4.0898e-04 - val_loss: 3.5375e-04
 - val_f1: 0.9998
Epoch 263/300
 - 62s - loss: 4.2911e-04 - val_loss: 3.5938e-04
 - val_f1: 0.9998
Epoch 264/300
 - 62s - loss: 4.2726e-04 - val_loss: 3.5403e-04
 - val_f1: 0.9998
Epoch 265/300
 - 62s - loss: 4.4007e-04 - val_loss: 3.3972e-04
 - val_f1: 0.9998
Epoch 266/300
 - 62s - loss: 4.1782e-04 - val_loss: 3.5157e-04
 - val_f1: 0.9998
Epoch 267/300
 - 62s - loss: 4.2516e-04 - val_loss: 3.4925e-04
 - val_f1: 0.9998
Epoch 268/300
 - 62s - loss: 4.0633e-04 - val_loss: 3.6618e-04
 - val_f1: 0.9998
Epoch 269/300
 - 62s - loss: 4.1582e-04 - val_loss: 3.4679e-04
 - val_f1: 0.9998
Epoch 270/300
 - 62s - loss: 4.1943e-04 - val_loss: 3.4175e-04
 - val_f1: 0.9998
Epoch 271/300
 - 62s - loss: 4.2701e-04 - val_loss: 3.4621e-04
2019-12-31 13:58:49,106 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 62s - loss: 4.1988e-04 - val_loss: 3.4656e-04
 - val_f1: 0.9998
Epoch 273/300
 - 62s - loss: 4.0817e-04 - val_loss: 3.6299e-04
 - val_f1: 0.9998
Epoch 274/300
 - 62s - loss: 4.0573e-04 - val_loss: 3.3972e-04
 - val_f1: 0.9998
Epoch 275/300
 - 62s - loss: 4.1241e-04 - val_loss: 3.3442e-04
 - val_f1: 0.9998
Epoch 276/300
 - 62s - loss: 4.1271e-04 - val_loss: 3.5273e-04
 - val_f1: 0.9998
Epoch 277/300
 - 62s - loss: 4.0294e-04 - val_loss: 3.3931e-04
 - val_f1: 0.9998
Epoch 278/300
 - 62s - loss: 4.1277e-04 - val_loss: 3.3323e-04
 - val_f1: 0.9998
Epoch 279/300
 - 62s - loss: 4.0786e-04 - val_loss: 3.5963e-04
 - val_f1: 0.9998
Epoch 280/300
 - 62s - loss: 4.0759e-04 - val_loss: 3.4969e-04
 - val_f1: 0.9998
Epoch 281/300
 - 62s - loss: 4.1391e-04 - val_loss: 3.4667e-04
 - val_f1: 0.9998
Epoch 282/300
 - 62s - loss: 4.0373e-04 - val_loss: 3.4555e-04
 - val_f1: 0.9998
Epoch 283/300
 - 62s - loss: 4.1562e-04 - val_loss: 3.7298e-04
 - val_f1: 0.9998
Epoch 284/300
 - 62s - loss: 4.0100e-04 - val_loss: 3.3338e-04
 - val_f1: 0.9998
Epoch 285/300
 - 62s - loss: 4.0937e-04 - val_loss: 3.3318e-04
 - val_f1: 0.9998
Epoch 286/300
 - 62s - loss: 3.9427e-04 - val_loss: 3.3716e-04
 - val_f1: 0.9998
Epoch 287/300
 - 62s - loss: 4.2046e-04 - val_loss: 3.3869e-04
 - val_f1: 0.9998
Epoch 288/300
 - 62s - loss: 4.0453e-04 - val_loss: 3.3878e-04
 - val_f1: 0.9998
Epoch 289/300
 - 62s - loss: 4.0185e-04 - val_loss: 3.2865e-04
 - val_f1: 0.9998
Epoch 290/300
 - 62s - loss: 4.1276e-04 - val_loss: 3.2991e-04
 - val_f1: 0.9998
Epoch 291/300
 - 62s - loss: 3.9867e-04 - val_loss: 3.3404e-04
 - val_f1: 0.9998
Epoch 292/300
 - 62s - loss: 4.0650e-04 - val_loss: 3.3098e-04
 - val_f1: 0.9998
Epoch 293/300
 - 62s - loss: 4.0863e-04 - val_loss: 3.2616e-04
 - val_f1: 0.9998
Epoch 294/300
 - 62s - loss: 3.9810e-04 - val_loss: 3.3959e-04
 - val_f1: 0.9998
Epoch 295/300
 - 62s - loss: 4.0867e-04 - val_loss: 3.3823e-04
 - val_f1: 0.9998
Epoch 296/300
 - 62s - loss: 3.9586e-04 - val_loss: 3.3466e-04
 - val_f1: 0.9998
Epoch 297/300
 - 62s - loss: 4.0818e-04 - val_loss: 3.3106e-04
 - val_f1: 0.9998
Epoch 298/300
 - 62s - loss: 4.0133e-04 - val_loss: 3.4570e-04
 - val_f1: 0.9998
Epoch 299/300
 - 62s - loss: 3.9844e-04 - val_loss: 3.5013e-04
 - val_f1: 0.9998
Epoch 300/300
 - 62s - loss: 3.8526e-04 - val_loss: 3.2507e-04
2019-12-31 14:41:35,085 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 14:43:28,992 [INFO] Last epoch loss evaluation: train_loss = 0.000237, val_loss = 0.000325
2019-12-31 14:43:29,006 [INFO] Training complete. time_to_train = 28999.12 sec, 483.32 min
2019-12-31 14:43:29,014 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_deep_rep3/best_model.pickle
2019-12-31 14:43:29,017 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_deep_rep3/training_error_history.csv
2019-12-31 14:43:29,191 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep3/training_error_history.png
2019-12-31 14:43:29,355 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep3/training_f1_history.png
2019-12-31 14:43:29,355 [INFO] Making predictions on training, validation, testing data
2019-12-31 14:45:41,374 [INFO] Evaluating predictions (results)
2019-12-31 14:45:50,052 [INFO] Dataset: Testing. Classification report below
2019-12-31 14:45:50,052 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.77      0.78      0.78      4166
         r2l       0.89      0.01      0.02     13781
         u2r       1.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.88      0.55      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-31 14:45:50,052 [INFO] Overall accuracy (micro avg): 0.9222033958248266
2019-12-31 14:45:59,347 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9222         0.9222                       0.9222                0.0194                   0.0778  0.9222
1     Macro avg        0.9689         0.8758                       0.5514                0.0197                   0.4486  0.5252
2  Weighted avg        0.9678         0.9369                       0.9222                0.0205                   0.0778  0.9025
2019-12-31 14:46:29,521 [INFO] Dataset: Validation. Classification report below
2019-12-31 14:46:29,521 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.91      0.70      0.79       225
         u2r       0.67      0.20      0.31        10

    accuracy                           1.00    979687
   macro avg       0.92      0.78      0.82    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-31 14:46:29,521 [INFO] Overall accuracy (micro avg): 0.9998060605070803
2019-12-31 14:47:02,087 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9153                       0.7783                0.0001                   0.2217  0.8188
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-31 14:49:15,218 [INFO] Dataset: Training. Classification report below
2019-12-31 14:49:15,219 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.93      0.72      0.81       901
         u2r       0.90      0.43      0.58        42

    accuracy                           1.00   3918744
   macro avg       0.97      0.83      0.88   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-31 14:49:15,219 [INFO] Overall accuracy (micro avg): 0.9998292820352643
2019-12-31 14:51:38,926 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9659                       0.8288                0.0001                   0.1712  0.8779
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-31 14:51:38,972 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_deep_rep3/selected_kdd99_dbn_deep_rep3_results.xlsx
2019-12-31 14:51:38,979 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-31 14:51:39,003 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_deep_rep4
2019-12-31 14:51:39,004 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_deep_rep4/run_log.log
2019-12-31 14:51:39,004 [INFO] ================= Running experiment no. 4  ================= 

2019-12-31 14:51:39,004 [INFO] Experiment parameters given below
2019-12-31 14:51:39,004 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_kdd99_dbn_deep_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 35], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.5], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_deep_rep4'}
2019-12-31 14:51:39,004 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_deep_rep4/tf_logs_run_2019_12_31-14_51_39
2019-12-31 14:51:39,004 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-31 14:51:39,004 [INFO] Reading X, y files
2019-12-31 14:51:39,005 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-31 14:51:45,423 [INFO] Reading complete. time_to_read=6.42 seconds
2019-12-31 14:51:45,424 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-31 14:51:47,062 [INFO] Reading complete. time_to_read=1.64 seconds
2019-12-31 14:51:47,062 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-31 14:51:47,530 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-31 14:51:47,530 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-31 14:51:47,731 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-31 14:51:47,731 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-31 14:51:47,784 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-31 14:51:47,784 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-31 14:51:47,803 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-31 14:51:55,039 [INFO] Initializing model
2019-12-31 14:51:55,039 [INFO] Training model
2019-12-31 14:51:55,039 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-31 14:52:36,719 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 55a87c80280deda6b61e076422a475add4503943
2019-12-31 14:52:36,719 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9998
[BernoulliRBM] Iteration 1, pseudo-likelihood = -64.20, time = 17.68s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -94.52, time = 30.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -122.35, time = 29.74s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -152.20, time = 29.35s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -183.17, time = 28.87s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -213.75, time = 28.74s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -244.17, time = 28.68s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -274.70, time = 28.78s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -305.52, time = 28.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -335.88, time = 28.76s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -366.54, time = 28.74s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -397.24, time = 28.73s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -427.94, time = 28.71s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -458.68, time = 28.71s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -489.41, time = 28.70s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -520.13, time = 28.71s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -550.89, time = 28.71s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -581.73, time = 28.70s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -612.45, time = 28.71s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -643.32, time = 28.69s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -674.20, time = 28.70s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -704.70, time = 28.70s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -735.45, time = 28.78s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -766.40, time = 28.83s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -797.03, time = 28.85s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -827.79, time = 28.78s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -858.46, time = 28.78s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -889.11, time = 28.81s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -919.71, time = 28.78s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -950.35, time = 28.78s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -981.05, time = 28.82s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -1011.86, time = 28.80s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -1042.68, time = 29.05s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -1073.51, time = 29.71s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -1104.33, time = 30.22s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -1135.17, time = 30.18s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -1166.02, time = 29.66s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1196.86, time = 29.09s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1227.65, time = 29.62s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1258.43, time = 36.20s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1289.12, time = 30.89s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1319.81, time = 30.57s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1350.58, time = 31.83s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1381.34, time = 30.32s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1412.08, time = 30.79s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1442.84, time = 29.60s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1473.63, time = 29.53s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1504.44, time = 29.40s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1535.26, time = 28.83s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1566.11, time = 29.11s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.58, time = 10.80s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.18, time = 17.21s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -6.92, time = 17.06s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -5.63, time = 16.97s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.15, time = 16.97s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.79, time = 16.94s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.45, time = 16.94s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.11, time = 16.94s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.82, time = 16.94s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.63, time = 16.95s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -3.39, time = 16.95s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -3.25, time = 16.95s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.15, time = 16.94s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.08, time = 16.95s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -3.03, time = 16.98s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -2.96, time = 16.99s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -2.88, time = 17.03s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -2.78, time = 17.04s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.70, time = 16.96s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.65, time = 16.95s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -2.60, time = 16.96s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -2.57, time = 16.97s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -2.54, time = 16.96s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -2.52, time = 17.00s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -2.50, time = 17.04s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -2.48, time = 17.02s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -2.41, time = 17.02s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -2.38, time = 17.04s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -2.35, time = 17.04s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -2.33, time = 17.03s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -2.31, time = 17.03s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -2.30, time = 17.02s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -2.26, time = 17.04s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -2.22, time = 17.01s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -2.19, time = 16.93s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -2.16, time = 16.92s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -2.14, time = 16.91s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -2.12, time = 16.90s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -2.10, time = 16.91s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -2.09, time = 16.90s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -2.08, time = 16.90s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -2.06, time = 16.90s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -2.05, time = 16.92s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -2.04, time = 16.90s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -2.04, time = 16.89s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -2.03, time = 16.91s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -2.01, time = 16.91s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1.97, time = 16.92s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1.94, time = 16.92s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1.93, time = 16.92s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -14.88, time = 5.32s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -13.12, time = 8.53s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -12.03, time = 8.53s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -11.40, time = 8.52s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -11.07, time = 8.52s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -10.88, time = 8.52s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -10.75, time = 8.52s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -10.59, time = 8.52s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -10.34, time = 8.53s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -10.27, time = 8.50s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -10.21, time = 8.50s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -10.18, time = 8.50s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -10.13, time = 8.50s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -10.10, time = 8.50s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -10.08, time = 8.52s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -10.05, time = 8.53s2019-12-31 15:38:23,938 [INFO] Pretraining Complete
2019-12-31 15:38:23,938 [INFO] Getting pretrained weights
2019-12-31 15:38:23,938 [INFO] Creating and initializing feed forward neural network
2019-12-31 15:38:24,229 [INFO] _________________________________________________________________
2019-12-31 15:38:24,229 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-31 15:38:24,229 [INFO] =================================================================
2019-12-31 15:38:24,230 [INFO] dense_13 (Dense)             (None, 128)               15872     
2019-12-31 15:38:24,230 [INFO] _________________________________________________________________
2019-12-31 15:38:24,230 [INFO] batch_normalization_10 (Batc (None, 128)               512       
2019-12-31 15:38:24,230 [INFO] _________________________________________________________________
2019-12-31 15:38:24,230 [INFO] dropout_10 (Dropout)         (None, 128)               0         
2019-12-31 15:38:24,230 [INFO] _________________________________________________________________
2019-12-31 15:38:24,230 [INFO] dense_14 (Dense)             (None, 64)                8256      
2019-12-31 15:38:24,230 [INFO] _________________________________________________________________
2019-12-31 15:38:24,230 [INFO] batch_normalization_11 (Batc (None, 64)                256       
2019-12-31 15:38:24,230 [INFO] _________________________________________________________________
2019-12-31 15:38:24,230 [INFO] dropout_11 (Dropout)         (None, 64)                0         
2019-12-31 15:38:24,231 [INFO] _________________________________________________________________
2019-12-31 15:38:24,231 [INFO] dense_15 (Dense)             (None, 35)                2275      
2019-12-31 15:38:24,231 [INFO] _________________________________________________________________
2019-12-31 15:38:24,231 [INFO] batch_normalization_12 (Batc (None, 35)                140       
2019-12-31 15:38:24,231 [INFO] _________________________________________________________________
2019-12-31 15:38:24,231 [INFO] dropout_12 (Dropout)         (None, 35)                0         
2019-12-31 15:38:24,231 [INFO] _________________________________________________________________
2019-12-31 15:38:24,231 [INFO] dense_16 (Dense)             (None, 5)                 180       
2019-12-31 15:38:24,231 [INFO] =================================================================
2019-12-31 15:38:24,232 [INFO] Total params: 27,491
2019-12-31 15:38:24,232 [INFO] Trainable params: 27,037
2019-12-31 15:38:24,232 [INFO] Non-trainable params: 454
2019-12-31 15:38:24,232 [INFO] _________________________________________________________________
2019-12-31 15:38:25,196 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -10.03, time = 8.51s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -10.02, time = 8.52s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -10.01, time = 8.52s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -9.99, time = 8.51s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -9.98, time = 8.52s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -9.97, time = 8.51s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -9.97, time = 8.51s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -9.96, time = 8.51s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -9.94, time = 8.51s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -9.93, time = 8.50s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -9.94, time = 8.50s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -9.94, time = 8.49s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -9.93, time = 8.50s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -9.92, time = 8.49s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -9.92, time = 8.49s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -9.91, time = 8.49s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -9.91, time = 8.48s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -9.90, time = 8.48s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -9.90, time = 8.47s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -9.90, time = 8.47s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -9.90, time = 8.48s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -9.90, time = 8.47s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -9.89, time = 8.48s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -9.89, time = 8.48s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -9.89, time = 8.47s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -9.88, time = 8.47s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -9.88, time = 8.46s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -9.88, time = 8.47s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -9.88, time = 8.48s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -9.87, time = 8.46s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -9.87, time = 8.47s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -9.87, time = 8.46s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -9.88, time = 8.46s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -9.87, time = 8.46s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/300
 - 65s - loss: 0.0230 - val_loss: 0.0073
 - val_f1: 0.9956
Epoch 2/300
 - 63s - loss: 0.0086 - val_loss: 0.0056
 - val_f1: 0.9972
Epoch 3/300
 - 63s - loss: 0.0069 - val_loss: 0.0048
 - val_f1: 0.9975
Epoch 4/300
 - 63s - loss: 0.0060 - val_loss: 0.0042
 - val_f1: 0.9979
Epoch 5/300
 - 63s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9983
Epoch 6/300
 - 63s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9985
Epoch 7/300
 - 63s - loss: 0.0035 - val_loss: 0.0022
 - val_f1: 0.9985
Epoch 8/300
 - 63s - loss: 0.0030 - val_loss: 0.0019
 - val_f1: 0.9986
Epoch 9/300
 - 63s - loss: 0.0028 - val_loss: 0.0017
 - val_f1: 0.9990
Epoch 10/300
 - 63s - loss: 0.0027 - val_loss: 0.0018
 - val_f1: 0.9990
Epoch 11/300
 - 63s - loss: 0.0025 - val_loss: 0.0017
 - val_f1: 0.9990
Epoch 12/300
 - 63s - loss: 0.0024 - val_loss: 0.0016
 - val_f1: 0.9991
Epoch 13/300
 - 63s - loss: 0.0023 - val_loss: 0.0017
 - val_f1: 0.9991
Epoch 14/300
 - 63s - loss: 0.0023 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 15/300
 - 63s - loss: 0.0022 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 16/300
 - 63s - loss: 0.0021 - val_loss: 0.0014
 - val_f1: 0.9992
Epoch 17/300
 - 63s - loss: 0.0020 - val_loss: 0.0014
 - val_f1: 0.9992
Epoch 18/300
 - 63s - loss: 0.0020 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 19/300
 - 63s - loss: 0.0019 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 20/300
 - 63s - loss: 0.0018 - val_loss: 0.0012
 - val_f1: 0.9994
Epoch 21/300
 - 63s - loss: 0.0017 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 22/300
 - 63s - loss: 0.0017 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 23/300
 - 63s - loss: 0.0017 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 24/300
 - 63s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 25/300
 - 63s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 26/300
 - 63s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 27/300
 - 63s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 28/300
 - 63s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9991
Epoch 29/300
 - 63s - loss: 0.0014 - val_loss: 9.4037e-04
 - val_f1: 0.9995
Epoch 30/300
 - 63s - loss: 0.0013 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 31/300
 - 63s - loss: 0.0013 - val_loss: 0.0011
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-31 16:25:17,527 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9991
Epoch 32/300
 - 63s - loss: 0.0013 - val_loss: 9.4605e-04
 - val_f1: 0.9995
Epoch 33/300
 - 63s - loss: 0.0013 - val_loss: 9.6456e-04
 - val_f1: 0.9992
Epoch 34/300
 - 63s - loss: 0.0012 - val_loss: 8.8232e-04
 - val_f1: 0.9995
Epoch 35/300
 - 63s - loss: 0.0012 - val_loss: 9.0444e-04
 - val_f1: 0.9993
Epoch 36/300
 - 63s - loss: 0.0012 - val_loss: 8.4798e-04
 - val_f1: 0.9995
Epoch 37/300
 - 63s - loss: 0.0012 - val_loss: 8.1526e-04
 - val_f1: 0.9995
Epoch 38/300
 - 63s - loss: 0.0012 - val_loss: 0.0010
 - val_f1: 0.9991
Epoch 39/300
 - 63s - loss: 0.0011 - val_loss: 8.3580e-04
 - val_f1: 0.9995
Epoch 40/300
 - 63s - loss: 0.0011 - val_loss: 7.9414e-04
 - val_f1: 0.9995
Epoch 41/300
 - 63s - loss: 0.0011 - val_loss: 8.0441e-04
 - val_f1: 0.9995
Epoch 42/300
 - 63s - loss: 0.0011 - val_loss: 9.1094e-04
 - val_f1: 0.9992
Epoch 43/300
 - 63s - loss: 0.0011 - val_loss: 7.5071e-04
 - val_f1: 0.9995
Epoch 44/300
 - 63s - loss: 0.0010 - val_loss: 7.3873e-04
 - val_f1: 0.9995
Epoch 45/300
 - 63s - loss: 0.0010 - val_loss: 7.8333e-04
 - val_f1: 0.9995
Epoch 46/300
 - 63s - loss: 0.0010 - val_loss: 7.3467e-04
 - val_f1: 0.9995
Epoch 47/300
 - 63s - loss: 0.0010 - val_loss: 6.3309e-04
 - val_f1: 0.9996
Epoch 48/300
 - 63s - loss: 9.8808e-04 - val_loss: 7.3988e-04
 - val_f1: 0.9996
Epoch 49/300
 - 63s - loss: 9.9706e-04 - val_loss: 7.3828e-04
 - val_f1: 0.9996
Epoch 50/300
 - 63s - loss: 9.6644e-04 - val_loss: 6.8468e-04
 - val_f1: 0.9996
Epoch 51/300
 - 63s - loss: 9.6357e-04 - val_loss: 7.1066e-04
 - val_f1: 0.9996
Epoch 52/300
 - 63s - loss: 9.5415e-04 - val_loss: 6.7904e-04
 - val_f1: 0.9996
Epoch 53/300
 - 63s - loss: 9.3866e-04 - val_loss: 6.5455e-04
 - val_f1: 0.9996
Epoch 54/300
 - 63s - loss: 9.4618e-04 - val_loss: 6.6690e-04
 - val_f1: 0.9996
Epoch 55/300
 - 63s - loss: 9.4683e-04 - val_loss: 6.7852e-04
 - val_f1: 0.9996
Epoch 56/300
 - 63s - loss: 9.2001e-04 - val_loss: 7.0727e-04
 - val_f1: 0.9996
Epoch 57/300
 - 63s - loss: 9.2504e-04 - val_loss: 6.9201e-04
 - val_f1: 0.9996
Epoch 58/300
 - 63s - loss: 9.0502e-04 - val_loss: 6.6732e-04
 - val_f1: 0.9996
Epoch 59/300
 - 63s - loss: 8.9545e-04 - val_loss: 6.9492e-04
 - val_f1: 0.9996
Epoch 60/300
 - 63s - loss: 8.8713e-04 - val_loss: 6.5263e-04
 - val_f1: 0.9996
Epoch 61/300
 - 63s - loss: 8.6400e-04 - val_loss: 6.1778e-04
2019-12-31 17:10:55,217 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9996
Epoch 62/300
 - 63s - loss: 8.3839e-04 - val_loss: 6.3955e-04
 - val_f1: 0.9996
Epoch 63/300
 - 63s - loss: 8.4051e-04 - val_loss: 6.7620e-04
 - val_f1: 0.9996
Epoch 64/300
 - 63s - loss: 8.4686e-04 - val_loss: 6.2875e-04
 - val_f1: 0.9996
Epoch 65/300
 - 63s - loss: 8.5719e-04 - val_loss: 6.1592e-04
 - val_f1: 0.9997
Epoch 66/300
 - 63s - loss: 8.5641e-04 - val_loss: 6.0047e-04
 - val_f1: 0.9996
Epoch 67/300
 - 63s - loss: 8.4535e-04 - val_loss: 5.7110e-04
 - val_f1: 0.9996
Epoch 68/300
 - 63s - loss: 8.2381e-04 - val_loss: 6.3176e-04
 - val_f1: 0.9996
Epoch 69/300
 - 63s - loss: 8.3051e-04 - val_loss: 6.1639e-04
 - val_f1: 0.9996
Epoch 70/300
 - 63s - loss: 8.2149e-04 - val_loss: 6.1551e-04
 - val_f1: 0.9996
Epoch 71/300
 - 63s - loss: 8.0910e-04 - val_loss: 6.4125e-04
 - val_f1: 0.9996
Epoch 72/300
 - 63s - loss: 8.0716e-04 - val_loss: 5.9995e-04
 - val_f1: 0.9996
Epoch 73/300
 - 63s - loss: 7.8130e-04 - val_loss: 6.0267e-04
 - val_f1: 0.9996
Epoch 74/300
 - 63s - loss: 7.8448e-04 - val_loss: 5.8100e-04
 - val_f1: 0.9996
Epoch 75/300
 - 63s - loss: 7.7196e-04 - val_loss: 5.7332e-04
 - val_f1: 0.9997
Epoch 76/300
 - 63s - loss: 7.7145e-04 - val_loss: 5.8890e-04
 - val_f1: 0.9997
Epoch 77/300
 - 63s - loss: 7.8673e-04 - val_loss: 6.5558e-04
 - val_f1: 0.9996
Epoch 78/300
 - 63s - loss: 7.6289e-04 - val_loss: 5.7163e-04
 - val_f1: 0.9996
Epoch 79/300
 - 63s - loss: 7.6691e-04 - val_loss: 5.9686e-04
 - val_f1: 0.9996
Epoch 80/300
 - 63s - loss: 7.6403e-04 - val_loss: 5.9377e-04
 - val_f1: 0.9997
Epoch 81/300
 - 63s - loss: 7.5458e-04 - val_loss: 5.5691e-04
 - val_f1: 0.9997
Epoch 82/300
 - 63s - loss: 7.4580e-04 - val_loss: 5.9952e-04
 - val_f1: 0.9997
Epoch 83/300
 - 63s - loss: 7.4716e-04 - val_loss: 5.0291e-04
 - val_f1: 0.9997
Epoch 84/300
 - 63s - loss: 7.2282e-04 - val_loss: 5.5651e-04
 - val_f1: 0.9997
Epoch 85/300
 - 63s - loss: 7.4303e-04 - val_loss: 6.1650e-04
 - val_f1: 0.9996
Epoch 86/300
 - 63s - loss: 7.3291e-04 - val_loss: 5.4508e-04
 - val_f1: 0.9997
Epoch 87/300
 - 63s - loss: 7.4256e-04 - val_loss: 5.6723e-04
 - val_f1: 0.9997
Epoch 88/300
 - 63s - loss: 7.1735e-04 - val_loss: 5.3698e-04
 - val_f1: 0.9997
Epoch 89/300
 - 63s - loss: 7.3218e-04 - val_loss: 5.5187e-04
 - val_f1: 0.9997
Epoch 90/300
 - 63s - loss: 7.2323e-04 - val_loss: 5.3504e-04
 - val_f1: 0.9997
Epoch 91/300
 - 63s - loss: 7.2051e-04 - val_loss: 6.5377e-04
2019-12-31 17:56:35,745 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9993
Epoch 92/300
 - 63s - loss: 7.0871e-04 - val_loss: 5.1428e-04
 - val_f1: 0.9997
Epoch 93/300
 - 63s - loss: 7.1904e-04 - val_loss: 5.6276e-04
 - val_f1: 0.9997
Epoch 94/300
 - 63s - loss: 6.9222e-04 - val_loss: 5.5017e-04
 - val_f1: 0.9996
Epoch 95/300
 - 63s - loss: 7.0503e-04 - val_loss: 5.3851e-04
 - val_f1: 0.9997
Epoch 96/300
 - 63s - loss: 7.2487e-04 - val_loss: 5.5792e-04
 - val_f1: 0.9997
Epoch 97/300
 - 63s - loss: 7.0697e-04 - val_loss: 5.2632e-04
 - val_f1: 0.9997
Epoch 98/300
 - 63s - loss: 6.7958e-04 - val_loss: 5.6072e-04
 - val_f1: 0.9997
Epoch 99/300
 - 63s - loss: 7.0808e-04 - val_loss: 5.5102e-04
 - val_f1: 0.9997
Epoch 100/300
 - 63s - loss: 6.7718e-04 - val_loss: 5.1982e-04
 - val_f1: 0.9997
Epoch 101/300
 - 63s - loss: 6.8568e-04 - val_loss: 5.1644e-04
 - val_f1: 0.9997
Epoch 102/300
 - 63s - loss: 6.8353e-04 - val_loss: 4.9490e-04
 - val_f1: 0.9997
Epoch 103/300
 - 63s - loss: 6.8208e-04 - val_loss: 5.2373e-04
 - val_f1: 0.9997
Epoch 104/300
 - 63s - loss: 6.8674e-04 - val_loss: 5.3136e-04
 - val_f1: 0.9997
Epoch 105/300
 - 63s - loss: 6.7830e-04 - val_loss: 5.1475e-04
 - val_f1: 0.9997
Epoch 106/300
 - 63s - loss: 6.7271e-04 - val_loss: 5.3446e-04
 - val_f1: 0.9997
Epoch 107/300
 - 63s - loss: 6.7835e-04 - val_loss: 5.7202e-04
 - val_f1: 0.9997
Epoch 108/300
 - 63s - loss: 6.7537e-04 - val_loss: 6.1524e-04
 - val_f1: 0.9997
Epoch 109/300
 - 63s - loss: 6.7354e-04 - val_loss: 4.9913e-04
 - val_f1: 0.9997
Epoch 110/300
 - 63s - loss: 6.6086e-04 - val_loss: 5.1571e-04
 - val_f1: 0.9997
Epoch 111/300
 - 63s - loss: 6.5141e-04 - val_loss: 5.2649e-04
 - val_f1: 0.9997
Epoch 112/300
 - 63s - loss: 6.4018e-04 - val_loss: 5.0567e-04
 - val_f1: 0.9997
Epoch 113/300
 - 63s - loss: 6.5381e-04 - val_loss: 5.0463e-04
 - val_f1: 0.9997
Epoch 114/300
 - 63s - loss: 6.4679e-04 - val_loss: 5.1764e-04
 - val_f1: 0.9997
Epoch 115/300
 - 63s - loss: 6.5530e-04 - val_loss: 5.1390e-04
 - val_f1: 0.9997
Epoch 116/300
 - 63s - loss: 6.4403e-04 - val_loss: 5.4379e-04
 - val_f1: 0.9997
Epoch 117/300
 - 63s - loss: 6.6383e-04 - val_loss: 4.9349e-04
 - val_f1: 0.9997
Epoch 118/300
 - 63s - loss: 6.6772e-04 - val_loss: 4.9145e-04
 - val_f1: 0.9997
Epoch 119/300
 - 63s - loss: 6.3984e-04 - val_loss: 4.7660e-04
 - val_f1: 0.9997
Epoch 120/300
 - 63s - loss: 6.3543e-04 - val_loss: 4.8636e-04
 - val_f1: 0.9997
Epoch 121/300
 - 63s - loss: 6.4505e-04 - val_loss: 4.9339e-04
2019-12-31 18:42:16,065 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/300
 - 63s - loss: 6.3488e-04 - val_loss: 4.9957e-04
 - val_f1: 0.9997
Epoch 123/300
 - 63s - loss: 6.5847e-04 - val_loss: 4.8996e-04
 - val_f1: 0.9997
Epoch 124/300
 - 63s - loss: 6.4631e-04 - val_loss: 4.7675e-04
 - val_f1: 0.9997
Epoch 125/300
 - 63s - loss: 6.3390e-04 - val_loss: 5.1823e-04
 - val_f1: 0.9997
Epoch 126/300
 - 63s - loss: 6.4782e-04 - val_loss: 4.7480e-04
 - val_f1: 0.9997
Epoch 127/300
 - 63s - loss: 6.3261e-04 - val_loss: 5.3122e-04
 - val_f1: 0.9997
Epoch 128/300
 - 63s - loss: 6.2429e-04 - val_loss: 5.1508e-04
 - val_f1: 0.9997
Epoch 129/300
 - 63s - loss: 6.0865e-04 - val_loss: 4.9195e-04
 - val_f1: 0.9997
Epoch 130/300
 - 63s - loss: 6.5500e-04 - val_loss: 4.6718e-04
 - val_f1: 0.9997
Epoch 131/300
 - 63s - loss: 6.2540e-04 - val_loss: 5.2143e-04
 - val_f1: 0.9997
Epoch 132/300
 - 63s - loss: 6.1957e-04 - val_loss: 4.8828e-04
 - val_f1: 0.9997
Epoch 133/300
 - 63s - loss: 5.9855e-04 - val_loss: 4.6311e-04
 - val_f1: 0.9997
Epoch 134/300
 - 63s - loss: 6.0698e-04 - val_loss: 5.2108e-04
 - val_f1: 0.9997
Epoch 135/300
 - 63s - loss: 6.0142e-04 - val_loss: 6.3219e-04
 - val_f1: 0.9994
Epoch 136/300
 - 63s - loss: 6.1229e-04 - val_loss: 4.5843e-04
 - val_f1: 0.9997
Epoch 137/300
 - 63s - loss: 6.1038e-04 - val_loss: 5.3821e-04
 - val_f1: 0.9997
Epoch 138/300
 - 63s - loss: 6.1858e-04 - val_loss: 4.9776e-04
 - val_f1: 0.9997
Epoch 139/300
 - 63s - loss: 6.1071e-04 - val_loss: 4.8965e-04
 - val_f1: 0.9997
Epoch 140/300
 - 63s - loss: 6.0072e-04 - val_loss: 4.8367e-04
 - val_f1: 0.9997
Epoch 141/300
 - 63s - loss: 6.1152e-04 - val_loss: 4.7679e-04
 - val_f1: 0.9997
Epoch 142/300
 - 63s - loss: 6.0023e-04 - val_loss: 4.8904e-04
 - val_f1: 0.9997
Epoch 143/300
 - 63s - loss: 6.1441e-04 - val_loss: 5.0328e-04
 - val_f1: 0.9997
Epoch 144/300
 - 63s - loss: 6.0475e-04 - val_loss: 4.7635e-04
 - val_f1: 0.9997
Epoch 145/300
 - 63s - loss: 5.9458e-04 - val_loss: 5.1414e-04
 - val_f1: 0.9997
Epoch 146/300
 - 63s - loss: 5.9553e-04 - val_loss: 4.8587e-04
 - val_f1: 0.9997
Epoch 147/300
 - 63s - loss: 6.0370e-04 - val_loss: 4.7278e-04
 - val_f1: 0.9997
Epoch 148/300
 - 63s - loss: 6.0688e-04 - val_loss: 4.2546e-04
 - val_f1: 0.9997
Epoch 149/300
 - 63s - loss: 5.6825e-04 - val_loss: 4.6895e-04
 - val_f1: 0.9997
Epoch 150/300
 - 63s - loss: 5.8724e-04 - val_loss: 5.3632e-04
 - val_f1: 0.9997
Epoch 151/300
 - 63s - loss: 5.8139e-04 - val_loss: 4.9185e-04
2019-12-31 19:27:47,879 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9997
Epoch 152/300
 - 63s - loss: 6.0826e-04 - val_loss: 4.7192e-04
 - val_f1: 0.9997
Epoch 153/300
 - 63s - loss: 5.7141e-04 - val_loss: 5.5028e-04
 - val_f1: 0.9997
Epoch 154/300
 - 63s - loss: 5.6384e-04 - val_loss: 4.7862e-04
 - val_f1: 0.9997
Epoch 155/300
 - 63s - loss: 5.8202e-04 - val_loss: 4.8513e-04
 - val_f1: 0.9997
Epoch 156/300
 - 63s - loss: 5.7990e-04 - val_loss: 4.7294e-04
 - val_f1: 0.9997
Epoch 157/300
 - 63s - loss: 5.8297e-04 - val_loss: 4.7064e-04
 - val_f1: 0.9997
Epoch 158/300
 - 63s - loss: 5.7744e-04 - val_loss: 4.8725e-04
 - val_f1: 0.9997
Epoch 159/300
 - 63s - loss: 5.5389e-04 - val_loss: 4.9792e-04
 - val_f1: 0.9997
Epoch 160/300
 - 63s - loss: 5.8535e-04 - val_loss: 4.9776e-04
 - val_f1: 0.9997
Epoch 161/300
 - 63s - loss: 5.8126e-04 - val_loss: 4.7942e-04
 - val_f1: 0.9997
Epoch 162/300
 - 63s - loss: 5.8324e-04 - val_loss: 4.5507e-04
 - val_f1: 0.9997
Epoch 163/300
 - 63s - loss: 5.6607e-04 - val_loss: 4.6891e-04
 - val_f1: 0.9997
Epoch 164/300
 - 63s - loss: 5.8419e-04 - val_loss: 4.8066e-04
 - val_f1: 0.9997
Epoch 165/300
 - 63s - loss: 5.6902e-04 - val_loss: 4.9990e-04
 - val_f1: 0.9997
Epoch 166/300
 - 63s - loss: 5.6136e-04 - val_loss: 4.6476e-04
 - val_f1: 0.9998
Epoch 167/300
 - 63s - loss: 5.6954e-04 - val_loss: 5.5944e-04
 - val_f1: 0.9997
Epoch 168/300
 - 63s - loss: 5.9114e-04 - val_loss: 4.7903e-04
 - val_f1: 0.9997
Epoch 169/300
 - 63s - loss: 5.5699e-04 - val_loss: 4.6179e-04
 - val_f1: 0.9997
Epoch 170/300
 - 63s - loss: 5.7677e-04 - val_loss: 9.3901e-04
 - val_f1: 0.9996
Epoch 171/300
 - 63s - loss: 5.6616e-04 - val_loss: 4.7795e-04
 - val_f1: 0.9997
Epoch 172/300
 - 63s - loss: 5.7179e-04 - val_loss: 5.0838e-04
 - val_f1: 0.9997
Epoch 173/300
 - 63s - loss: 5.5297e-04 - val_loss: 5.0477e-04
 - val_f1: 0.9997
Epoch 174/300
 - 63s - loss: 5.5365e-04 - val_loss: 4.3477e-04
 - val_f1: 0.9997
Epoch 175/300
 - 63s - loss: 5.5349e-04 - val_loss: 4.6323e-04
 - val_f1: 0.9997
Epoch 176/300
 - 63s - loss: 5.4866e-04 - val_loss: 4.9847e-04
 - val_f1: 0.9997
Epoch 177/300
 - 63s - loss: 5.5722e-04 - val_loss: 4.6961e-04
 - val_f1: 0.9997
Epoch 178/300
 - 63s - loss: 5.5359e-04 - val_loss: 5.0152e-04
 - val_f1: 0.9997
Epoch 179/300
 - 63s - loss: 5.5525e-04 - val_loss: 4.7631e-04
 - val_f1: 0.9997
Epoch 180/300
 - 63s - loss: 5.5631e-04 - val_loss: 4.6658e-04
 - val_f1: 0.9997
Epoch 181/300
 - 63s - loss: 5.3926e-04 - val_loss: 4.9756e-04
2019-12-31 20:13:06,833 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9997
Epoch 182/300
 - 63s - loss: 5.6116e-04 - val_loss: 4.4426e-04
 - val_f1: 0.9997
Epoch 183/300
 - 63s - loss: 5.5063e-04 - val_loss: 4.7471e-04
 - val_f1: 0.9997
Epoch 184/300
 - 63s - loss: 5.4779e-04 - val_loss: 4.8091e-04
 - val_f1: 0.9997
Epoch 185/300
 - 63s - loss: 5.3465e-04 - val_loss: 5.0065e-04
 - val_f1: 0.9997
Epoch 186/300
 - 63s - loss: 5.3930e-04 - val_loss: 4.9082e-04
 - val_f1: 0.9997
Epoch 187/300
 - 63s - loss: 5.5255e-04 - val_loss: 4.7750e-04
 - val_f1: 0.9997
Epoch 188/300
 - 63s - loss: 5.5149e-04 - val_loss: 4.2205e-04
 - val_f1: 0.9997
Epoch 189/300
 - 63s - loss: 5.4952e-04 - val_loss: 4.6219e-04
 - val_f1: 0.9997
Epoch 190/300
 - 63s - loss: 5.4623e-04 - val_loss: 4.6530e-04
 - val_f1: 0.9997
Epoch 191/300
 - 63s - loss: 5.4230e-04 - val_loss: 4.5137e-04
 - val_f1: 0.9997
Epoch 192/300
 - 63s - loss: 5.3538e-04 - val_loss: 4.5998e-04
 - val_f1: 0.9997
Epoch 193/300
 - 63s - loss: 5.3514e-04 - val_loss: 4.6567e-04
 - val_f1: 0.9997
Epoch 194/300
 - 63s - loss: 5.4636e-04 - val_loss: 4.7322e-04
 - val_f1: 0.9997
Epoch 195/300
 - 63s - loss: 5.4968e-04 - val_loss: 4.6657e-04
 - val_f1: 0.9997
Epoch 196/300
 - 63s - loss: 5.3885e-04 - val_loss: 4.4653e-04
 - val_f1: 0.9997
Epoch 197/300
 - 63s - loss: 5.1254e-04 - val_loss: 4.2685e-04
 - val_f1: 0.9997
Epoch 198/300
 - 63s - loss: 5.3106e-04 - val_loss: 4.4729e-04
 - val_f1: 0.9997
Epoch 199/300
 - 63s - loss: 5.4069e-04 - val_loss: 4.2523e-04
 - val_f1: 0.9997
Epoch 200/300
 - 63s - loss: 5.4840e-04 - val_loss: 4.5851e-04
 - val_f1: 0.9997
Epoch 201/300
 - 63s - loss: 5.4282e-04 - val_loss: 4.6494e-04
 - val_f1: 0.9997
Epoch 202/300
 - 63s - loss: 5.3413e-04 - val_loss: 5.0799e-04
 - val_f1: 0.9997
Epoch 203/300
 - 63s - loss: 5.2622e-04 - val_loss: 4.1833e-04
 - val_f1: 0.9997
Epoch 204/300
 - 63s - loss: 5.2429e-04 - val_loss: 5.3235e-04
 - val_f1: 0.9997
Epoch 205/300
 - 63s - loss: 5.2355e-04 - val_loss: 4.8753e-04
 - val_f1: 0.9997
Epoch 206/300
 - 63s - loss: 5.3235e-04 - val_loss: 4.4960e-04
 - val_f1: 0.9997
Epoch 207/300
 - 63s - loss: 5.1918e-04 - val_loss: 4.5584e-04
 - val_f1: 0.9997
Epoch 208/300
 - 63s - loss: 5.0742e-04 - val_loss: 4.7635e-04
 - val_f1: 0.9997
Epoch 209/300
 - 63s - loss: 5.2169e-04 - val_loss: 4.6437e-04
 - val_f1: 0.9997
Epoch 210/300
 - 63s - loss: 5.1951e-04 - val_loss: 4.5086e-04
 - val_f1: 0.9997
Epoch 211/300
 - 63s - loss: 5.2640e-04 - val_loss: 4.4981e-04
2019-12-31 20:58:25,846 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9997
Epoch 212/300
 - 63s - loss: 5.0441e-04 - val_loss: 4.4807e-04
 - val_f1: 0.9997
Epoch 213/300
 - 63s - loss: 5.3204e-04 - val_loss: 5.1717e-04
 - val_f1: 0.9997
Epoch 214/300
 - 63s - loss: 5.3547e-04 - val_loss: 4.9572e-04
 - val_f1: 0.9997
Epoch 215/300
 - 63s - loss: 5.2418e-04 - val_loss: 4.7909e-04
 - val_f1: 0.9997
Epoch 216/300
 - 63s - loss: 5.0824e-04 - val_loss: 4.8221e-04
 - val_f1: 0.9997
Epoch 217/300
 - 63s - loss: 5.0253e-04 - val_loss: 4.8125e-04
 - val_f1: 0.9997
Epoch 218/300
 - 63s - loss: 5.0384e-04 - val_loss: 4.7378e-04
 - val_f1: 0.9997
Epoch 219/300
 - 63s - loss: 5.1983e-04 - val_loss: 4.5502e-04
 - val_f1: 0.9997
Epoch 220/300
 - 63s - loss: 5.1710e-04 - val_loss: 4.8087e-04
 - val_f1: 0.9997
Epoch 221/300
 - 63s - loss: 5.1340e-04 - val_loss: 4.8972e-04
 - val_f1: 0.9997
Epoch 222/300
 - 63s - loss: 5.3038e-04 - val_loss: 5.1412e-04
 - val_f1: 0.9997
Epoch 223/300
 - 63s - loss: 5.1438e-04 - val_loss: 4.8686e-04
 - val_f1: 0.9997
Epoch 224/300
 - 63s - loss: 5.1153e-04 - val_loss: 4.8603e-04
 - val_f1: 0.9997
Epoch 225/300
 - 63s - loss: 5.3048e-04 - val_loss: 4.8709e-04
 - val_f1: 0.9997
Epoch 226/300
 - 63s - loss: 5.1195e-04 - val_loss: 4.8903e-04
 - val_f1: 0.9997
Epoch 227/300
 - 63s - loss: 5.2683e-04 - val_loss: 4.6593e-04
 - val_f1: 0.9997
Epoch 228/300
 - 63s - loss: 4.9589e-04 - val_loss: 4.8326e-04
 - val_f1: 0.9997
Epoch 229/300
 - 63s - loss: 5.0948e-04 - val_loss: 4.6014e-04
 - val_f1: 0.9997
Epoch 230/300
 - 63s - loss: 5.0417e-04 - val_loss: 4.9357e-04
 - val_f1: 0.9997
Epoch 231/300
 - 63s - loss: 5.0281e-04 - val_loss: 4.7804e-04
 - val_f1: 0.9997
Epoch 232/300
 - 63s - loss: 5.1099e-04 - val_loss: 4.7335e-04
 - val_f1: 0.9997
Epoch 233/300
 - 63s - loss: 4.8300e-04 - val_loss: 4.7895e-04
 - val_f1: 0.9998
Epoch 234/300
 - 63s - loss: 4.9891e-04 - val_loss: 4.3517e-04
 - val_f1: 0.9997
Epoch 235/300
 - 63s - loss: 4.9725e-04 - val_loss: 4.9317e-04
 - val_f1: 0.9998
Epoch 236/300
 - 63s - loss: 5.1185e-04 - val_loss: 4.5061e-04
 - val_f1: 0.9997
Epoch 237/300
 - 63s - loss: 5.0514e-04 - val_loss: 5.1391e-04
 - val_f1: 0.9996
Epoch 238/300
 - 63s - loss: 4.9685e-04 - val_loss: 4.7280e-04
 - val_f1: 0.9997
Epoch 239/300
 - 63s - loss: 4.9135e-04 - val_loss: 4.7160e-04
 - val_f1: 0.9998
Epoch 240/300
 - 63s - loss: 4.9526e-04 - val_loss: 4.9498e-04
 - val_f1: 0.9997
Epoch 241/300
 - 63s - loss: 4.9517e-04 - val_loss: 4.8009e-04
2019-12-31 21:43:44,500 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9997
Epoch 242/300
 - 63s - loss: 4.9886e-04 - val_loss: 4.4905e-04
 - val_f1: 0.9997
Epoch 243/300
 - 63s - loss: 4.8515e-04 - val_loss: 4.7460e-04
 - val_f1: 0.9998
Epoch 244/300
 - 63s - loss: 4.9227e-04 - val_loss: 4.7760e-04
 - val_f1: 0.9997
Epoch 245/300
 - 63s - loss: 4.9218e-04 - val_loss: 4.7700e-04
 - val_f1: 0.9997
Epoch 246/300
 - 63s - loss: 4.9425e-04 - val_loss: 4.9338e-04
 - val_f1: 0.9997
Epoch 247/300
 - 63s - loss: 4.7745e-04 - val_loss: 5.0294e-04
 - val_f1: 0.9997
Epoch 248/300
 - 63s - loss: 4.9079e-04 - val_loss: 4.2542e-04
 - val_f1: 0.9997
Epoch 249/300
 - 63s - loss: 4.8195e-04 - val_loss: 4.7129e-04
 - val_f1: 0.9997
Epoch 250/300
 - 63s - loss: 4.9936e-04 - val_loss: 4.4172e-04
 - val_f1: 0.9997
Epoch 251/300
 - 63s - loss: 4.8285e-04 - val_loss: 4.0485e-04
 - val_f1: 0.9998
Epoch 252/300
 - 63s - loss: 5.0216e-04 - val_loss: 4.6330e-04
 - val_f1: 0.9997
Epoch 253/300
 - 63s - loss: 4.8353e-04 - val_loss: 4.0303e-04
 - val_f1: 0.9998
Epoch 254/300
 - 63s - loss: 4.9148e-04 - val_loss: 4.6613e-04
 - val_f1: 0.9997
Epoch 255/300
 - 63s - loss: 4.6864e-04 - val_loss: 4.7334e-04
 - val_f1: 0.9997
Epoch 256/300
 - 63s - loss: 4.7738e-04 - val_loss: 4.7728e-04
 - val_f1: 0.9997
Epoch 257/300
 - 63s - loss: 4.8517e-04 - val_loss: 4.5151e-04
 - val_f1: 0.9997
Epoch 258/300
 - 63s - loss: 4.7631e-04 - val_loss: 4.4761e-04
 - val_f1: 0.9998
Epoch 259/300
 - 63s - loss: 4.9039e-04 - val_loss: 5.0366e-04
 - val_f1: 0.9997
Epoch 260/300
 - 63s - loss: 4.8119e-04 - val_loss: 4.1797e-04
 - val_f1: 0.9998
Epoch 261/300
 - 63s - loss: 4.7714e-04 - val_loss: 4.4567e-04
 - val_f1: 0.9998
Epoch 262/300
 - 63s - loss: 4.8160e-04 - val_loss: 4.5167e-04
 - val_f1: 0.9998
Epoch 263/300
 - 63s - loss: 4.8468e-04 - val_loss: 4.2807e-04
 - val_f1: 0.9997
Epoch 264/300
 - 63s - loss: 4.6520e-04 - val_loss: 4.6390e-04
 - val_f1: 0.9997
Epoch 265/300
 - 63s - loss: 4.8379e-04 - val_loss: 4.6892e-04
 - val_f1: 0.9997
Epoch 266/300
 - 63s - loss: 4.7903e-04 - val_loss: 4.4404e-04
 - val_f1: 0.9997
Epoch 267/300
 - 63s - loss: 4.7634e-04 - val_loss: 4.4423e-04
 - val_f1: 0.9997
Epoch 268/300
 - 63s - loss: 4.8085e-04 - val_loss: 4.4950e-04
 - val_f1: 0.9997
Epoch 269/300
 - 63s - loss: 4.8778e-04 - val_loss: 4.4059e-04
 - val_f1: 0.9998
Epoch 270/300
 - 63s - loss: 4.7265e-04 - val_loss: 4.2709e-04
 - val_f1: 0.9997
Epoch 271/300
 - 63s - loss: 4.7475e-04 - val_loss: 4.2260e-04
2019-12-31 22:29:01,040 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 63s - loss: 4.6673e-04 - val_loss: 3.9949e-04
 - val_f1: 0.9998
Epoch 273/300
 - 63s - loss: 4.6803e-04 - val_loss: 4.2851e-04
 - val_f1: 0.9998
Epoch 274/300
 - 63s - loss: 4.5757e-04 - val_loss: 4.2498e-04
 - val_f1: 0.9998
Epoch 275/300
 - 63s - loss: 4.6239e-04 - val_loss: 4.2420e-04
 - val_f1: 0.9997
Epoch 276/300
 - 63s - loss: 4.7358e-04 - val_loss: 4.2517e-04
 - val_f1: 0.9998
Epoch 277/300
 - 63s - loss: 4.8296e-04 - val_loss: 4.3427e-04
 - val_f1: 0.9998
Epoch 278/300
 - 63s - loss: 4.6865e-04 - val_loss: 3.9659e-04
 - val_f1: 0.9998
Epoch 279/300
 - 63s - loss: 4.7293e-04 - val_loss: 4.2895e-04
 - val_f1: 0.9997
Epoch 280/300
 - 63s - loss: 4.6887e-04 - val_loss: 4.3434e-04
 - val_f1: 0.9997
Epoch 281/300
 - 63s - loss: 4.8925e-04 - val_loss: 3.8863e-04
 - val_f1: 0.9998
Epoch 282/300
 - 63s - loss: 4.6535e-04 - val_loss: 4.4359e-04
 - val_f1: 0.9998
Epoch 283/300
 - 63s - loss: 4.6678e-04 - val_loss: 4.2657e-04
 - val_f1: 0.9998
Epoch 284/300
 - 63s - loss: 4.6671e-04 - val_loss: 3.9240e-04
 - val_f1: 0.9998
Epoch 285/300
 - 63s - loss: 4.6027e-04 - val_loss: 4.3119e-04
 - val_f1: 0.9997
Epoch 286/300
 - 63s - loss: 4.6300e-04 - val_loss: 4.0415e-04
 - val_f1: 0.9998
Epoch 287/300
 - 63s - loss: 4.6188e-04 - val_loss: 4.0816e-04
 - val_f1: 0.9998
Epoch 288/300
 - 63s - loss: 4.5846e-04 - val_loss: 4.0975e-04
 - val_f1: 0.9998
Epoch 289/300
 - 63s - loss: 4.7162e-04 - val_loss: 4.1406e-04
 - val_f1: 0.9998
Epoch 290/300
 - 63s - loss: 4.7241e-04 - val_loss: 4.3236e-04
 - val_f1: 0.9998
Epoch 291/300
 - 63s - loss: 4.6170e-04 - val_loss: 3.7782e-04
 - val_f1: 0.9998
Epoch 292/300
 - 63s - loss: 4.7558e-04 - val_loss: 4.0117e-04
 - val_f1: 0.9997
Epoch 293/300
 - 63s - loss: 4.5653e-04 - val_loss: 4.0040e-04
 - val_f1: 0.9998
Epoch 294/300
 - 63s - loss: 4.6718e-04 - val_loss: 4.0728e-04
 - val_f1: 0.9998
Epoch 295/300
 - 63s - loss: 4.5303e-04 - val_loss: 4.1712e-04
 - val_f1: 0.9997
Epoch 296/300
 - 63s - loss: 4.5589e-04 - val_loss: 3.9145e-04
 - val_f1: 0.9997
Epoch 297/300
 - 63s - loss: 4.5168e-04 - val_loss: 3.6913e-04
 - val_f1: 0.9998
Epoch 298/300
 - 63s - loss: 4.4274e-04 - val_loss: 3.9951e-04
 - val_f1: 0.9998
Epoch 299/300
 - 63s - loss: 4.5650e-04 - val_loss: 3.9103e-04
 - val_f1: 0.9998
Epoch 300/300
 - 63s - loss: 4.6110e-04 - val_loss: 4.0174e-04
2019-12-31 23:13:14,125 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-31 23:15:19,376 [INFO] Last epoch loss evaluation: train_loss = 0.000278, val_loss = 0.000369
2019-12-31 23:15:19,390 [INFO] Training complete. time_to_train = 30204.35 sec, 503.41 min
2019-12-31 23:15:19,398 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_deep_rep4/best_model.pickle
2019-12-31 23:15:19,402 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_deep_rep4/training_error_history.csv
2019-12-31 23:15:19,576 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep4/training_error_history.png
2019-12-31 23:15:19,741 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep4/training_f1_history.png
2019-12-31 23:15:19,741 [INFO] Making predictions on training, validation, testing data
2019-12-31 23:17:43,613 [INFO] Evaluating predictions (results)
2019-12-31 23:17:52,296 [INFO] Dataset: Testing. Classification report below
2019-12-31 23:17:52,297 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.90      0.80      0.85      4166
         r2l       0.97      0.02      0.04     13781
         u2r       1.00      0.00      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.92      0.56      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-31 23:17:52,297 [INFO] Overall accuracy (micro avg): 0.921714695414254
2019-12-31 23:18:01,594 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9217         0.9217                       0.9217                0.0196                   0.0783  0.9217
1     Macro avg        0.9687         0.9175                       0.5564                0.0209                   0.4436  0.5428
2  Weighted avg        0.9655         0.9400                       0.9217                0.0261                   0.0783  0.9024
2019-12-31 23:18:31,741 [INFO] Dataset: Validation. Classification report below
2019-12-31 23:18:31,741 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.88      0.82      0.85       225
         u2r       0.50      0.10      0.17        10

    accuracy                           1.00    979687
   macro avg       0.88      0.78      0.80    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-31 23:18:31,741 [INFO] Overall accuracy (micro avg): 0.9998081019754268
2019-12-31 23:19:04,272 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8755                       0.7821                0.0001                   0.2179  0.8019
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-31 23:21:17,283 [INFO] Dataset: Training. Classification report below
2019-12-31 23:21:17,283 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.84      0.81      0.82       901
         u2r       0.94      0.40      0.57        42

    accuracy                           1.00   3918744
   macro avg       0.96      0.84      0.88   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-31 23:21:17,284 [INFO] Overall accuracy (micro avg): 0.9998190746831127
2019-12-31 23:23:40,843 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9572                       0.8407                0.0001                   0.1593  0.8773
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-31 23:23:40,889 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_deep_rep4/selected_kdd99_dbn_deep_rep4_results.xlsx
2019-12-31 23:23:40,896 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-31 23:23:40,920 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_deep_rep5
2019-12-31 23:23:40,920 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_deep_rep5/run_log.log
2019-12-31 23:23:40,920 [INFO] ================= Running experiment no. 5  ================= 

2019-12-31 23:23:40,920 [INFO] Experiment parameters given below
2019-12-31 23:23:40,920 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_kdd99_dbn_deep_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [128, 64, 36], 'ann_layer_activations': ['relu', 'relu', 'relu'], 'ann_layer_dropout_rates': [0.2, 0.2, 0.6], 'unsupervised_ratio': 0.25, 'dbn_learning_rate': 0.001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_deep_rep5'}
2019-12-31 23:23:40,920 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_deep_rep5/tf_logs_run_2019_12_31-23_23_40
2019-12-31 23:23:40,920 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-31 23:23:40,921 [INFO] Reading X, y files
2019-12-31 23:23:40,921 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-31 23:23:47,335 [INFO] Reading complete. time_to_read=6.41 seconds
2019-12-31 23:23:47,335 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-31 23:23:49,009 [INFO] Reading complete. time_to_read=1.67 seconds
2019-12-31 23:23:49,010 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-31 23:23:49,485 [INFO] Reading complete. time_to_read=0.48 seconds
2019-12-31 23:23:49,485 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-31 23:23:49,702 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-31 23:23:49,702 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-31 23:23:49,757 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-31 23:23:49,757 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-31 23:23:49,776 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-31 23:23:57,005 [INFO] Initializing model
2019-12-31 23:23:57,006 [INFO] Training model
2019-12-31 23:23:57,006 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-31 23:24:39,390 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = af8569a79bb2b1e054fef32defd2f1d54241d09a
2019-12-31 23:24:39,391 [INFO] Pretraining Deep Belief Network
 - val_f1: 0.9998
[BernoulliRBM] Iteration 1, pseudo-likelihood = -65.25, time = 17.66s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -95.42, time = 30.37s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -122.31, time = 29.71s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -150.65, time = 29.29s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -180.26, time = 28.82s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -209.77, time = 28.69s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -239.28, time = 28.62s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -268.96, time = 28.73s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -298.57, time = 28.73s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -328.18, time = 28.70s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -358.29, time = 28.70s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -388.37, time = 28.69s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -418.29, time = 28.68s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -448.02, time = 28.67s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -477.79, time = 28.67s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -507.62, time = 28.68s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -537.49, time = 28.66s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -567.51, time = 28.67s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -597.51, time = 28.68s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -627.47, time = 28.68s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -657.56, time = 28.66s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -687.57, time = 28.65s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -717.69, time = 28.65s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -747.68, time = 28.72s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -777.68, time = 28.72s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -807.93, time = 28.68s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -838.09, time = 28.67s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -868.22, time = 28.70s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -898.29, time = 28.67s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -928.35, time = 28.67s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -958.39, time = 28.68s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -988.41, time = 28.70s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -1018.38, time = 28.68s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -1048.39, time = 28.81s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -1078.48, time = 29.32s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -1108.58, time = 30.02s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -1138.73, time = 30.21s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -1168.88, time = 29.83s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -1199.00, time = 29.59s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1229.14, time = 35.74s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1259.27, time = 31.22s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1289.40, time = 30.26s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1319.54, time = 31.99s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1349.67, time = 30.58s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1379.76, time = 30.36s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1409.89, time = 29.88s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1440.00, time = 29.35s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1470.09, time = 29.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1500.21, time = 28.85s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1530.34, time = 28.93s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -15.64, time = 10.78s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -9.88, time = 17.15s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -7.29, time = 17.01s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -6.18, time = 16.95s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -5.50, time = 16.91s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -5.02, time = 16.92s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.67, time = 16.92s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.23, time = 16.90s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -3.95, time = 16.89s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -3.79, time = 16.90s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -3.68, time = 16.92s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -3.59, time = 16.93s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.47, time = 16.95s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -3.30, time = 16.88s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -3.21, time = 16.89s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -3.11, time = 16.92s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -3.02, time = 16.94s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -2.96, time = 16.94s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -2.91, time = 16.95s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -2.79, time = 16.96s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -2.69, time = 16.87s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -2.62, time = 16.84s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -2.56, time = 16.83s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -2.51, time = 16.82s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -2.40, time = 16.82s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -2.34, time = 16.83s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -2.29, time = 16.83s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -2.23, time = 16.83s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -2.19, time = 16.83s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -2.16, time = 16.83s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -2.14, time = 16.83s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -2.11, time = 16.83s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -2.09, time = 16.82s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -2.07, time = 16.82s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -2.06, time = 16.83s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -2.04, time = 16.84s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -2.03, time = 16.81s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -2.02, time = 16.80s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -2.00, time = 16.80s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -1.99, time = 16.80s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -1.98, time = 16.81s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -1.98, time = 16.80s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -1.97, time = 16.79s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -1.96, time = 16.80s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -1.95, time = 16.80s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -1.95, time = 16.80s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -1.94, time = 16.80s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -1.93, time = 16.80s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -1.93, time = 16.81s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -1.92, time = 16.80s
[BernoulliRBM] Iteration 1, pseudo-likelihood = -11.52, time = 5.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -10.07, time = 8.60s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -8.87, time = 8.60s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -8.12, time = 8.61s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -7.51, time = 8.59s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -6.94, time = 8.56s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -6.75, time = 8.52s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -6.51, time = 8.50s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -6.32, time = 8.50s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -6.14, time = 8.50s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -6.08, time = 8.49s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -6.04, time = 8.50s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -6.01, time = 8.49s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -5.98, time = 8.49s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -5.95, time = 8.49s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -5.94, time = 8.48s2020-01-01 00:10:18,034 [INFO] Pretraining Complete
2020-01-01 00:10:18,034 [INFO] Getting pretrained weights
2020-01-01 00:10:18,034 [INFO] Creating and initializing feed forward neural network
2020-01-01 00:10:18,330 [INFO] _________________________________________________________________
2020-01-01 00:10:18,330 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-01 00:10:18,330 [INFO] =================================================================
2020-01-01 00:10:18,330 [INFO] dense_17 (Dense)             (None, 128)               15872     
2020-01-01 00:10:18,330 [INFO] _________________________________________________________________
2020-01-01 00:10:18,330 [INFO] batch_normalization_13 (Batc (None, 128)               512       
2020-01-01 00:10:18,330 [INFO] _________________________________________________________________
2020-01-01 00:10:18,330 [INFO] dropout_13 (Dropout)         (None, 128)               0         
2020-01-01 00:10:18,330 [INFO] _________________________________________________________________
2020-01-01 00:10:18,330 [INFO] dense_18 (Dense)             (None, 64)                8256      
2020-01-01 00:10:18,330 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-01 00:10:18,331 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-01 00:10:18,331 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] dense_19 (Dense)             (None, 36)                2340      
2020-01-01 00:10:18,331 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] batch_normalization_15 (Batc (None, 36)                144       
2020-01-01 00:10:18,331 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] dropout_15 (Dropout)         (None, 36)                0         
2020-01-01 00:10:18,331 [INFO] _________________________________________________________________
2020-01-01 00:10:18,331 [INFO] dense_20 (Dense)             (None, 5)                 185       
2020-01-01 00:10:18,331 [INFO] =================================================================
2020-01-01 00:10:18,332 [INFO] Total params: 27,565
2020-01-01 00:10:18,332 [INFO] Trainable params: 27,109
2020-01-01 00:10:18,332 [INFO] Non-trainable params: 456
2020-01-01 00:10:18,332 [INFO] _________________________________________________________________
2020-01-01 00:10:19,602 [INFO] Fine-tuning final neural network

[BernoulliRBM] Iteration 17, pseudo-likelihood = -5.92, time = 8.49s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -5.91, time = 8.49s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -5.89, time = 8.48s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -5.77, time = 8.48s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -5.75, time = 8.48s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -5.73, time = 8.48s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -5.64, time = 8.48s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -5.62, time = 8.48s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -5.61, time = 8.48s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -5.61, time = 8.48s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -5.59, time = 8.49s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -5.60, time = 8.49s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -5.59, time = 8.48s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -5.58, time = 8.48s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -5.58, time = 8.48s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -5.58, time = 8.48s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -5.57, time = 8.48s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -5.56, time = 8.48s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -5.57, time = 8.48s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -5.57, time = 8.48s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -5.56, time = 8.48s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -5.56, time = 8.48s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -5.55, time = 8.48s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -5.56, time = 8.48s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -5.55, time = 8.48s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -5.55, time = 8.48s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -5.54, time = 8.48s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -5.53, time = 8.49s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -5.54, time = 8.49s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -5.53, time = 8.48s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -5.54, time = 8.49s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -5.54, time = 8.48s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -5.53, time = 8.48s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -5.54, time = 8.59s
Train on 2939058 samples, validate on 979687 samples
Epoch 1/300
 - 66s - loss: 0.0256 - val_loss: 0.0078
 - val_f1: 0.9950
Epoch 2/300
 - 64s - loss: 0.0099 - val_loss: 0.0058
 - val_f1: 0.9972
Epoch 3/300
 - 64s - loss: 0.0085 - val_loss: 0.0055
 - val_f1: 0.9975
Epoch 4/300
 - 64s - loss: 0.0076 - val_loss: 0.0046
 - val_f1: 0.9978
Epoch 5/300
 - 64s - loss: 0.0066 - val_loss: 0.0040
 - val_f1: 0.9981
Epoch 6/300
 - 64s - loss: 0.0056 - val_loss: 0.0036
 - val_f1: 0.9983
Epoch 7/300
 - 64s - loss: 0.0051 - val_loss: 0.0034
 - val_f1: 0.9985
Epoch 8/300
 - 64s - loss: 0.0048 - val_loss: 0.0033
 - val_f1: 0.9986
Epoch 9/300
 - 64s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9986
Epoch 10/300
 - 64s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9986
Epoch 11/300
 - 64s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9986
Epoch 12/300
 - 64s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9986
Epoch 13/300
 - 64s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9986
Epoch 14/300
 - 64s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9987
Epoch 15/300
 - 64s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9987
Epoch 16/300
 - 64s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9987
Epoch 17/300
 - 64s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9987
Epoch 18/300
 - 64s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9987
Epoch 19/300
 - 64s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9988
Epoch 20/300
 - 64s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9988
Epoch 21/300
 - 64s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9988
Epoch 22/300
 - 64s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9988
Epoch 23/300
 - 64s - loss: 0.0031 - val_loss: 0.0024
 - val_f1: 0.9988
Epoch 24/300
 - 64s - loss: 0.0030 - val_loss: 0.0023
 - val_f1: 0.9988
Epoch 25/300
 - 64s - loss: 0.0029 - val_loss: 0.0021
 - val_f1: 0.9988
Epoch 26/300
 - 64s - loss: 0.0028 - val_loss: 0.0020
 - val_f1: 0.9988
Epoch 27/300
 - 64s - loss: 0.0027 - val_loss: 0.0018
 - val_f1: 0.9988
Epoch 28/300
 - 64s - loss: 0.0026 - val_loss: 0.0016
 - val_f1: 0.9988
Epoch 29/300
 - 64s - loss: 0.0026 - val_loss: 0.0016
 - val_f1: 0.9988
Epoch 30/300
 - 64s - loss: 0.0024 - val_loss: 0.0014
 - val_f1: 0.9988
Epoch 31/300
 - 64s - loss: 0.0024 - val_loss: 0.0016
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 00:58:35,919 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9988
Epoch 32/300
 - 64s - loss: 0.0024 - val_loss: 0.0015
 - val_f1: 0.9988
Epoch 33/300
 - 64s - loss: 0.0023 - val_loss: 0.0015
 - val_f1: 0.9988
Epoch 34/300
 - 64s - loss: 0.0023 - val_loss: 0.0014
 - val_f1: 0.9988
Epoch 35/300
 - 64s - loss: 0.0022 - val_loss: 0.0014
 - val_f1: 0.9988
Epoch 36/300
 - 64s - loss: 0.0022 - val_loss: 0.0014
 - val_f1: 0.9988
Epoch 37/300
 - 64s - loss: 0.0022 - val_loss: 0.0013
 - val_f1: 0.9989
Epoch 38/300
 - 64s - loss: 0.0022 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 39/300
 - 64s - loss: 0.0021 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 40/300
 - 65s - loss: 0.0021 - val_loss: 0.0012
 - val_f1: 0.9990
Epoch 41/300
 - 64s - loss: 0.0020 - val_loss: 0.0012
 - val_f1: 0.9991
Epoch 42/300
 - 64s - loss: 0.0020 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 43/300
 - 64s - loss: 0.0019 - val_loss: 0.0010
 - val_f1: 0.9993
Epoch 44/300
 - 64s - loss: 0.0018 - val_loss: 9.6312e-04
 - val_f1: 0.9993
Epoch 45/300
 - 64s - loss: 0.0018 - val_loss: 9.9349e-04
 - val_f1: 0.9993
Epoch 46/300
 - 65s - loss: 0.0017 - val_loss: 0.0010
 - val_f1: 0.9993
Epoch 47/300
 - 64s - loss: 0.0017 - val_loss: 0.0010
 - val_f1: 0.9993
Epoch 48/300
 - 64s - loss: 0.0017 - val_loss: 9.4776e-04
 - val_f1: 0.9993
Epoch 49/300
 - 64s - loss: 0.0016 - val_loss: 9.6377e-04
 - val_f1: 0.9993
Epoch 50/300
 - 64s - loss: 0.0016 - val_loss: 8.8645e-04
 - val_f1: 0.9993
Epoch 51/300
 - 64s - loss: 0.0016 - val_loss: 8.8688e-04
 - val_f1: 0.9993
Epoch 52/300
 - 64s - loss: 0.0016 - val_loss: 9.4773e-04
 - val_f1: 0.9993
Epoch 53/300
 - 64s - loss: 0.0016 - val_loss: 8.8672e-04
 - val_f1: 0.9993
Epoch 54/300
 - 64s - loss: 0.0015 - val_loss: 9.2400e-04
 - val_f1: 0.9993
Epoch 55/300
 - 64s - loss: 0.0015 - val_loss: 8.8129e-04
 - val_f1: 0.9993
Epoch 56/300
 - 64s - loss: 0.0015 - val_loss: 8.8348e-04
 - val_f1: 0.9993
Epoch 57/300
 - 64s - loss: 0.0015 - val_loss: 8.6585e-04
 - val_f1: 0.9994
Epoch 58/300
 - 64s - loss: 0.0015 - val_loss: 8.7051e-04
 - val_f1: 0.9994
Epoch 59/300
 - 64s - loss: 0.0014 - val_loss: 8.5681e-04
 - val_f1: 0.9994
Epoch 60/300
 - 64s - loss: 0.0014 - val_loss: 8.3631e-04
 - val_f1: 0.9994
Epoch 61/300
 - 64s - loss: 0.0014 - val_loss: 7.8935e-04
2020-01-01 01:45:58,820 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9994
Epoch 62/300
 - 65s - loss: 0.0014 - val_loss: 7.8189e-04
 - val_f1: 0.9994
Epoch 63/300
 - 64s - loss: 0.0014 - val_loss: 7.7365e-04
 - val_f1: 0.9994
Epoch 64/300
 - 64s - loss: 0.0013 - val_loss: 8.2091e-04
 - val_f1: 0.9994
Epoch 65/300
 - 65s - loss: 0.0013 - val_loss: 7.3875e-04
 - val_f1: 0.9994
Epoch 66/300
 - 65s - loss: 0.0013 - val_loss: 7.5936e-04
 - val_f1: 0.9994
Epoch 67/300
 - 64s - loss: 0.0012 - val_loss: 7.4565e-04
 - val_f1: 0.9994
Epoch 68/300
 - 64s - loss: 0.0012 - val_loss: 7.2158e-04
 - val_f1: 0.9995
Epoch 69/300
 - 65s - loss: 0.0012 - val_loss: 7.1776e-04
 - val_f1: 0.9995
Epoch 70/300
 - 64s - loss: 0.0011 - val_loss: 7.3862e-04
 - val_f1: 0.9996
Epoch 71/300
 - 64s - loss: 0.0012 - val_loss: 6.8130e-04
 - val_f1: 0.9996
Epoch 72/300
 - 65s - loss: 0.0011 - val_loss: 6.6883e-04
 - val_f1: 0.9996
Epoch 73/300
 - 64s - loss: 0.0011 - val_loss: 6.9621e-04
 - val_f1: 0.9996
Epoch 74/300
 - 64s - loss: 0.0011 - val_loss: 6.3677e-04
 - val_f1: 0.9996
Epoch 75/300
 - 64s - loss: 0.0011 - val_loss: 6.6379e-04
 - val_f1: 0.9995
Epoch 76/300
 - 65s - loss: 0.0011 - val_loss: 6.7452e-04
 - val_f1: 0.9996
Epoch 77/300
 - 64s - loss: 0.0010 - val_loss: 5.9885e-04
 - val_f1: 0.9996
Epoch 78/300
 - 65s - loss: 0.0010 - val_loss: 6.0994e-04
 - val_f1: 0.9996
Epoch 79/300
 - 64s - loss: 9.9296e-04 - val_loss: 6.5579e-04
 - val_f1: 0.9996
Epoch 80/300
 - 65s - loss: 9.6748e-04 - val_loss: 6.5640e-04
 - val_f1: 0.9996
Epoch 81/300
 - 65s - loss: 9.7680e-04 - val_loss: 6.5164e-04
 - val_f1: 0.9996
Epoch 82/300
 - 64s - loss: 9.6245e-04 - val_loss: 6.2302e-04
 - val_f1: 0.9996
Epoch 83/300
 - 64s - loss: 9.5154e-04 - val_loss: 5.8946e-04
 - val_f1: 0.9996
Epoch 84/300
 - 64s - loss: 9.3065e-04 - val_loss: 5.8006e-04
 - val_f1: 0.9996
Epoch 85/300
 - 64s - loss: 9.3314e-04 - val_loss: 5.6001e-04
 - val_f1: 0.9997
Epoch 86/300
 - 64s - loss: 9.0330e-04 - val_loss: 5.2286e-04
 - val_f1: 0.9997
Epoch 87/300
 - 65s - loss: 9.0252e-04 - val_loss: 5.6854e-04
 - val_f1: 0.9996
Epoch 88/300
 - 64s - loss: 8.7775e-04 - val_loss: 5.5671e-04
 - val_f1: 0.9997
Epoch 89/300
 - 64s - loss: 8.9444e-04 - val_loss: 5.6724e-04
 - val_f1: 0.9997
Epoch 90/300
 - 64s - loss: 8.6706e-04 - val_loss: 5.3789e-04
 - val_f1: 0.9997
Epoch 91/300
 - 64s - loss: 8.8354e-04 - val_loss: 5.2860e-04
2020-01-01 02:33:22,659 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9997
Epoch 92/300
 - 64s - loss: 8.7605e-04 - val_loss: 5.3713e-04
 - val_f1: 0.9997
Epoch 93/300
 - 64s - loss: 8.4498e-04 - val_loss: 5.5461e-04
 - val_f1: 0.9997
Epoch 94/300
 - 64s - loss: 8.2932e-04 - val_loss: 5.3694e-04
 - val_f1: 0.9997
Epoch 95/300
 - 64s - loss: 8.5448e-04 - val_loss: 5.1668e-04
 - val_f1: 0.9997
Epoch 96/300
 - 64s - loss: 8.5568e-04 - val_loss: 5.1783e-04
 - val_f1: 0.9997
Epoch 97/300
 - 64s - loss: 8.6089e-04 - val_loss: 5.2886e-04
 - val_f1: 0.9997
Epoch 98/300
 - 64s - loss: 8.4803e-04 - val_loss: 5.4365e-04
 - val_f1: 0.9997
Epoch 99/300
 - 64s - loss: 8.3256e-04 - val_loss: 4.9605e-04
 - val_f1: 0.9997
Epoch 100/300
 - 64s - loss: 8.3530e-04 - val_loss: 5.4297e-04
 - val_f1: 0.9997
Epoch 101/300
 - 64s - loss: 8.2094e-04 - val_loss: 5.0816e-04
 - val_f1: 0.9997
Epoch 102/300
 - 64s - loss: 7.9429e-04 - val_loss: 5.1913e-04
 - val_f1: 0.9997
Epoch 103/300
 - 64s - loss: 8.2019e-04 - val_loss: 4.8557e-04
 - val_f1: 0.9997
Epoch 104/300
 - 64s - loss: 8.1323e-04 - val_loss: 4.9932e-04
 - val_f1: 0.9997
Epoch 105/300
 - 64s - loss: 8.0949e-04 - val_loss: 5.1587e-04
 - val_f1: 0.9997
Epoch 106/300
 - 64s - loss: 7.9140e-04 - val_loss: 4.9932e-04
 - val_f1: 0.9997
Epoch 107/300
 - 64s - loss: 7.7628e-04 - val_loss: 4.5853e-04
 - val_f1: 0.9997
Epoch 108/300
 - 65s - loss: 7.8027e-04 - val_loss: 4.8570e-04
 - val_f1: 0.9997
Epoch 109/300
 - 64s - loss: 7.7041e-04 - val_loss: 4.6930e-04
 - val_f1: 0.9997
Epoch 110/300
 - 64s - loss: 7.5415e-04 - val_loss: 5.2821e-04
 - val_f1: 0.9997
Epoch 111/300
 - 64s - loss: 7.5822e-04 - val_loss: 5.1659e-04
 - val_f1: 0.9997
Epoch 112/300
 - 64s - loss: 7.5703e-04 - val_loss: 5.0489e-04
 - val_f1: 0.9997
Epoch 113/300
 - 64s - loss: 7.6351e-04 - val_loss: 5.2585e-04
 - val_f1: 0.9997
Epoch 114/300
 - 64s - loss: 7.7419e-04 - val_loss: 4.9983e-04
 - val_f1: 0.9997
Epoch 115/300
 - 64s - loss: 7.7716e-04 - val_loss: 5.0281e-04
 - val_f1: 0.9997
Epoch 116/300
 - 64s - loss: 7.4976e-04 - val_loss: 5.4068e-04
 - val_f1: 0.9997
Epoch 117/300
 - 64s - loss: 7.4384e-04 - val_loss: 4.5550e-04
 - val_f1: 0.9997
Epoch 118/300
 - 64s - loss: 7.4012e-04 - val_loss: 5.5768e-04
 - val_f1: 0.9997
Epoch 119/300
 - 64s - loss: 7.3172e-04 - val_loss: 4.7239e-04
 - val_f1: 0.9997
Epoch 120/300
 - 64s - loss: 7.2800e-04 - val_loss: 5.2355e-04
 - val_f1: 0.9997
Epoch 121/300
 - 64s - loss: 7.1783e-04 - val_loss: 4.7294e-04
2020-01-01 03:20:39,558 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/300
 - 64s - loss: 7.1953e-04 - val_loss: 4.8452e-04
 - val_f1: 0.9998
Epoch 123/300
 - 64s - loss: 7.0986e-04 - val_loss: 4.8712e-04
 - val_f1: 0.9997
Epoch 124/300
 - 64s - loss: 7.3978e-04 - val_loss: 4.8357e-04
 - val_f1: 0.9998
Epoch 125/300
 - 65s - loss: 7.2245e-04 - val_loss: 4.8568e-04
 - val_f1: 0.9998
Epoch 126/300
 - 64s - loss: 7.2338e-04 - val_loss: 4.6828e-04
 - val_f1: 0.9998
Epoch 127/300
 - 64s - loss: 7.2666e-04 - val_loss: 4.6531e-04
 - val_f1: 0.9997
Epoch 128/300
 - 64s - loss: 7.2472e-04 - val_loss: 4.8886e-04
 - val_f1: 0.9997
Epoch 129/300
 - 64s - loss: 7.2042e-04 - val_loss: 4.8153e-04
 - val_f1: 0.9997
Epoch 130/300
 - 64s - loss: 6.9053e-04 - val_loss: 4.7842e-04
 - val_f1: 0.9998
Epoch 131/300
 - 64s - loss: 7.0158e-04 - val_loss: 4.6102e-04
 - val_f1: 0.9997
Epoch 132/300
 - 64s - loss: 6.9931e-04 - val_loss: 4.8676e-04
 - val_f1: 0.9997
Epoch 133/300
 - 65s - loss: 6.8216e-04 - val_loss: 4.5529e-04
 - val_f1: 0.9997
Epoch 134/300
 - 64s - loss: 6.9499e-04 - val_loss: 4.5219e-04
 - val_f1: 0.9998
Epoch 135/300
 - 64s - loss: 7.1480e-04 - val_loss: 4.6559e-04
 - val_f1: 0.9998
Epoch 136/300
 - 64s - loss: 6.9969e-04 - val_loss: 4.8846e-04
 - val_f1: 0.9997
Epoch 137/300
 - 64s - loss: 7.0250e-04 - val_loss: 4.4299e-04
 - val_f1: 0.9998
Epoch 138/300
 - 65s - loss: 6.8745e-04 - val_loss: 4.4439e-04
 - val_f1: 0.9998
Epoch 139/300
 - 64s - loss: 6.9231e-04 - val_loss: 4.8161e-04
 - val_f1: 0.9997
Epoch 140/300
 - 64s - loss: 6.9918e-04 - val_loss: 4.5861e-04
 - val_f1: 0.9997
Epoch 141/300
 - 64s - loss: 6.8662e-04 - val_loss: 4.4612e-04
 - val_f1: 0.9998
Epoch 142/300
 - 64s - loss: 6.5237e-04 - val_loss: 4.7333e-04
 - val_f1: 0.9998
Epoch 143/300
 - 64s - loss: 6.7562e-04 - val_loss: 4.3458e-04
 - val_f1: 0.9998
Epoch 144/300
 - 64s - loss: 6.7850e-04 - val_loss: 4.7161e-04
 - val_f1: 0.9998
Epoch 145/300
 - 64s - loss: 6.7007e-04 - val_loss: 4.5119e-04
 - val_f1: 0.9998
Epoch 146/300
 - 64s - loss: 6.8013e-04 - val_loss: 4.6936e-04
 - val_f1: 0.9998
Epoch 147/300
 - 64s - loss: 6.7033e-04 - val_loss: 4.3447e-04
 - val_f1: 0.9998
Epoch 148/300
 - 64s - loss: 6.4827e-04 - val_loss: 4.5121e-04
 - val_f1: 0.9998
Epoch 149/300
 - 64s - loss: 6.6260e-04 - val_loss: 4.5394e-04
 - val_f1: 0.9998
Epoch 150/300
 - 64s - loss: 6.5167e-04 - val_loss: 4.7696e-04
 - val_f1: 0.9998
Epoch 151/300
 - 64s - loss: 6.5174e-04 - val_loss: 4.4155e-04
2020-01-01 04:08:01,141 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 64s - loss: 6.5258e-04 - val_loss: 4.6864e-04
 - val_f1: 0.9998
Epoch 153/300
 - 64s - loss: 6.4889e-04 - val_loss: 4.6014e-04
 - val_f1: 0.9998
Epoch 154/300
 - 64s - loss: 6.4856e-04 - val_loss: 4.3328e-04
 - val_f1: 0.9998
Epoch 155/300
 - 65s - loss: 6.5577e-04 - val_loss: 4.5369e-04
 - val_f1: 0.9998
Epoch 156/300
 - 65s - loss: 6.4159e-04 - val_loss: 4.5692e-04
 - val_f1: 0.9998
Epoch 157/300
 - 65s - loss: 6.3637e-04 - val_loss: 4.1715e-04
 - val_f1: 0.9998
Epoch 158/300
 - 64s - loss: 6.2383e-04 - val_loss: 4.1052e-04
 - val_f1: 0.9998
Epoch 159/300
 - 64s - loss: 6.2944e-04 - val_loss: 4.0788e-04
 - val_f1: 0.9998
Epoch 160/300
 - 65s - loss: 6.3947e-04 - val_loss: 4.1281e-04
 - val_f1: 0.9998
Epoch 161/300
 - 65s - loss: 6.2793e-04 - val_loss: 4.2998e-04
 - val_f1: 0.9998
Epoch 162/300
 - 64s - loss: 6.4671e-04 - val_loss: 4.3787e-04
 - val_f1: 0.9998
Epoch 163/300
 - 65s - loss: 6.1811e-04 - val_loss: 4.2618e-04
 - val_f1: 0.9998
Epoch 164/300
 - 64s - loss: 6.3619e-04 - val_loss: 4.2894e-04
 - val_f1: 0.9998
Epoch 165/300
 - 64s - loss: 6.0794e-04 - val_loss: 4.1365e-04
 - val_f1: 0.9998
Epoch 166/300
 - 64s - loss: 6.4232e-04 - val_loss: 3.9388e-04
 - val_f1: 0.9998
Epoch 167/300
 - 65s - loss: 6.2586e-04 - val_loss: 4.2836e-04
 - val_f1: 0.9998
Epoch 168/300
 - 64s - loss: 6.1534e-04 - val_loss: 4.0508e-04
 - val_f1: 0.9998
Epoch 169/300
 - 64s - loss: 6.1805e-04 - val_loss: 4.6875e-04
 - val_f1: 0.9997
Epoch 170/300
 - 64s - loss: 5.9362e-04 - val_loss: 4.1380e-04
 - val_f1: 0.9998
Epoch 171/300
 - 64s - loss: 6.1517e-04 - val_loss: 4.1094e-04
 - val_f1: 0.9998
Epoch 172/300
 - 64s - loss: 6.3622e-04 - val_loss: 4.1554e-04
 - val_f1: 0.9998
Epoch 173/300
 - 64s - loss: 5.9349e-04 - val_loss: 4.2081e-04
 - val_f1: 0.9998
Epoch 174/300
 - 64s - loss: 6.0148e-04 - val_loss: 4.1628e-04
 - val_f1: 0.9998
Epoch 175/300
 - 64s - loss: 5.8528e-04 - val_loss: 4.1946e-04
 - val_f1: 0.9998
Epoch 176/300
 - 65s - loss: 6.0082e-04 - val_loss: 5.7210e-04
 - val_f1: 0.9997
Epoch 177/300
 - 64s - loss: 5.9694e-04 - val_loss: 4.1659e-04
 - val_f1: 0.9998
Epoch 178/300
 - 64s - loss: 6.0557e-04 - val_loss: 4.1746e-04
 - val_f1: 0.9998
Epoch 179/300
 - 64s - loss: 5.8757e-04 - val_loss: 4.5513e-04
 - val_f1: 0.9998
Epoch 180/300
 - 64s - loss: 5.8562e-04 - val_loss: 4.5434e-04
 - val_f1: 0.9998
Epoch 181/300
 - 64s - loss: 5.9376e-04 - val_loss: 4.0063e-04
2020-01-01 04:55:19,201 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 64s - loss: 5.8141e-04 - val_loss: 4.1834e-04
 - val_f1: 0.9998
Epoch 183/300
 - 64s - loss: 5.9191e-04 - val_loss: 4.1696e-04
 - val_f1: 0.9998
Epoch 184/300
 - 64s - loss: 5.8312e-04 - val_loss: 4.0154e-04
 - val_f1: 0.9998
Epoch 185/300
 - 64s - loss: 6.0049e-04 - val_loss: 3.9301e-04
 - val_f1: 0.9998
Epoch 186/300
 - 64s - loss: 5.8574e-04 - val_loss: 4.0726e-04
 - val_f1: 0.9998
Epoch 187/300
 - 64s - loss: 5.7241e-04 - val_loss: 3.7984e-04
 - val_f1: 0.9998
Epoch 188/300
 - 64s - loss: 5.9251e-04 - val_loss: 4.1238e-04
 - val_f1: 0.9998
Epoch 189/300
 - 64s - loss: 5.7440e-04 - val_loss: 4.0686e-04
 - val_f1: 0.9998
Epoch 190/300
 - 64s - loss: 5.7665e-04 - val_loss: 5.0415e-04
 - val_f1: 0.9997
Epoch 191/300
 - 64s - loss: 5.7217e-04 - val_loss: 3.9066e-04
 - val_f1: 0.9998
Epoch 192/300
 - 64s - loss: 5.7530e-04 - val_loss: 3.9801e-04
 - val_f1: 0.9998
Epoch 193/300
 - 64s - loss: 5.6270e-04 - val_loss: 3.9096e-04
 - val_f1: 0.9998
Epoch 194/300
 - 64s - loss: 5.7657e-04 - val_loss: 3.9446e-04
 - val_f1: 0.9998
Epoch 195/300
 - 64s - loss: 5.5185e-04 - val_loss: 4.2653e-04
 - val_f1: 0.9998
Epoch 196/300
 - 64s - loss: 5.7164e-04 - val_loss: 3.9368e-04
 - val_f1: 0.9998
Epoch 197/300
 - 64s - loss: 5.6716e-04 - val_loss: 5.5311e-04
 - val_f1: 0.9997
Epoch 198/300
 - 64s - loss: 5.4706e-04 - val_loss: 3.9196e-04
 - val_f1: 0.9998
Epoch 199/300
 - 64s - loss: 5.5212e-04 - val_loss: 5.9709e-04
 - val_f1: 0.9997
Epoch 200/300
 - 64s - loss: 5.6130e-04 - val_loss: 4.2001e-04
 - val_f1: 0.9998
Epoch 201/300
 - 64s - loss: 5.7124e-04 - val_loss: 4.0593e-04
 - val_f1: 0.9998
Epoch 202/300
 - 64s - loss: 5.5917e-04 - val_loss: 4.5596e-04
 - val_f1: 0.9998
Epoch 203/300
 - 65s - loss: 5.3427e-04 - val_loss: 3.9576e-04
 - val_f1: 0.9998
Epoch 204/300
 - 65s - loss: 5.4734e-04 - val_loss: 3.9047e-04
 - val_f1: 0.9998
Epoch 205/300
 - 64s - loss: 5.5236e-04 - val_loss: 4.1673e-04
 - val_f1: 0.9998
Epoch 206/300
 - 64s - loss: 5.3149e-04 - val_loss: 4.0964e-04
 - val_f1: 0.9998
Epoch 207/300
 - 64s - loss: 5.3731e-04 - val_loss: 3.8339e-04
 - val_f1: 0.9998
Epoch 208/300
 - 64s - loss: 5.3769e-04 - val_loss: 4.1095e-04
 - val_f1: 0.9998
Epoch 209/300
 - 64s - loss: 5.3610e-04 - val_loss: 4.1568e-04
 - val_f1: 0.9998
Epoch 210/300
 - 64s - loss: 5.3068e-04 - val_loss: 4.5355e-04
 - val_f1: 0.9997
Epoch 211/300
 - 64s - loss: 5.2976e-04 - val_loss: 3.9425e-04
2020-01-01 05:42:37,641 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 64s - loss: 5.2723e-04 - val_loss: 3.9561e-04
 - val_f1: 0.9998
Epoch 213/300
 - 64s - loss: 5.3589e-04 - val_loss: 4.0625e-04
 - val_f1: 0.9998
Epoch 214/300
 - 70s - loss: 5.2120e-04 - val_loss: 4.6390e-04
 - val_f1: 0.9998
Epoch 215/300
 - 64s - loss: 5.2907e-04 - val_loss: 5.7306e-04
 - val_f1: 0.9997
Epoch 216/300
 - 64s - loss: 5.1458e-04 - val_loss: 3.7957e-04
 - val_f1: 0.9998
Epoch 217/300
 - 64s - loss: 5.0112e-04 - val_loss: 3.7567e-04
 - val_f1: 0.9998
Epoch 218/300
 - 64s - loss: 5.4158e-04 - val_loss: 3.8077e-04
 - val_f1: 0.9998
Epoch 219/300
 - 64s - loss: 5.2890e-04 - val_loss: 4.1471e-04
 - val_f1: 0.9998
Epoch 220/300
 - 64s - loss: 5.4281e-04 - val_loss: 3.7178e-04
 - val_f1: 0.9998
Epoch 221/300
 - 64s - loss: 5.2649e-04 - val_loss: 4.0187e-04
 - val_f1: 0.9998
Epoch 222/300
 - 64s - loss: 5.2121e-04 - val_loss: 3.8657e-04
 - val_f1: 0.9998
Epoch 223/300
 - 64s - loss: 5.1298e-04 - val_loss: 3.8221e-04
 - val_f1: 0.9998
Epoch 224/300
 - 65s - loss: 5.2558e-04 - val_loss: 3.9020e-04
 - val_f1: 0.9998
Epoch 225/300
 - 65s - loss: 5.2244e-04 - val_loss: 4.5820e-04
 - val_f1: 0.9998
Epoch 226/300
 - 64s - loss: 4.9782e-04 - val_loss: 4.0586e-04
 - val_f1: 0.9998
Epoch 227/300
 - 65s - loss: 5.3384e-04 - val_loss: 3.7092e-04
 - val_f1: 0.9998
Epoch 228/300
 - 64s - loss: 5.3137e-04 - val_loss: 3.9326e-04
 - val_f1: 0.9998
Epoch 229/300
 - 64s - loss: 5.1650e-04 - val_loss: 3.7850e-04
 - val_f1: 0.9998
Epoch 230/300
 - 64s - loss: 5.0582e-04 - val_loss: 4.0341e-04
 - val_f1: 0.9998
Epoch 231/300
 - 64s - loss: 5.1355e-04 - val_loss: 3.7530e-04
 - val_f1: 0.9998
Epoch 232/300
 - 64s - loss: 5.0946e-04 - val_loss: 4.1862e-04
 - val_f1: 0.9998
Epoch 233/300
 - 64s - loss: 5.0579e-04 - val_loss: 3.8540e-04
 - val_f1: 0.9998
Epoch 234/300
 - 64s - loss: 5.1481e-04 - val_loss: 4.3006e-04
 - val_f1: 0.9998
Epoch 235/300
 - 64s - loss: 4.8536e-04 - val_loss: 3.9284e-04
 - val_f1: 0.9998
Epoch 236/300
 - 64s - loss: 5.1090e-04 - val_loss: 3.6621e-04
 - val_f1: 0.9998
Epoch 237/300
 - 64s - loss: 5.0239e-04 - val_loss: 3.7200e-04
 - val_f1: 0.9998
Epoch 238/300
 - 64s - loss: 5.0910e-04 - val_loss: 3.8262e-04
 - val_f1: 0.9998
Epoch 239/300
 - 64s - loss: 4.8914e-04 - val_loss: 3.9508e-04
 - val_f1: 0.9998
Epoch 240/300
 - 64s - loss: 5.0006e-04 - val_loss: 3.8068e-04
 - val_f1: 0.9998
Epoch 241/300
 - 64s - loss: 4.9347e-04 - val_loss: 3.9385e-04
2020-01-01 06:30:01,950 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 64s - loss: 4.9803e-04 - val_loss: 3.7351e-04
 - val_f1: 0.9998
Epoch 243/300
 - 64s - loss: 4.8607e-04 - val_loss: 4.0835e-04
 - val_f1: 0.9997
Epoch 244/300
 - 64s - loss: 5.0926e-04 - val_loss: 3.7411e-04
 - val_f1: 0.9998
Epoch 245/300
 - 64s - loss: 4.9694e-04 - val_loss: 3.6859e-04
 - val_f1: 0.9998
Epoch 246/300
 - 64s - loss: 4.9341e-04 - val_loss: 3.9333e-04
 - val_f1: 0.9998
Epoch 247/300
 - 64s - loss: 4.8650e-04 - val_loss: 3.7186e-04
 - val_f1: 0.9998
Epoch 248/300
 - 64s - loss: 4.9502e-04 - val_loss: 3.6056e-04
 - val_f1: 0.9998
Epoch 249/300
 - 64s - loss: 4.8135e-04 - val_loss: 3.7391e-04
 - val_f1: 0.9998
Epoch 250/300
 - 65s - loss: 5.0022e-04 - val_loss: 3.6167e-04
 - val_f1: 0.9998
Epoch 251/300
 - 64s - loss: 5.0034e-04 - val_loss: 3.6625e-04
 - val_f1: 0.9998
Epoch 252/300
 - 64s - loss: 4.9322e-04 - val_loss: 3.7335e-04
 - val_f1: 0.9998
Epoch 253/300
 - 64s - loss: 4.9434e-04 - val_loss: 3.8244e-04
 - val_f1: 0.9998
Epoch 254/300
 - 64s - loss: 4.6427e-04 - val_loss: 3.9775e-04
 - val_f1: 0.9998
Epoch 255/300
 - 64s - loss: 4.9816e-04 - val_loss: 3.5125e-04
 - val_f1: 0.9998
Epoch 256/300
 - 64s - loss: 5.0158e-04 - val_loss: 3.5953e-04
 - val_f1: 0.9998
Epoch 257/300
 - 64s - loss: 4.8689e-04 - val_loss: 3.6662e-04
 - val_f1: 0.9998
Epoch 258/300
 - 64s - loss: 4.8924e-04 - val_loss: 3.7400e-04
 - val_f1: 0.9998
Epoch 259/300
 - 64s - loss: 4.8641e-04 - val_loss: 4.8734e-04
 - val_f1: 0.9998
Epoch 260/300
 - 64s - loss: 4.8675e-04 - val_loss: 3.7739e-04
 - val_f1: 0.9998
Epoch 261/300
 - 64s - loss: 4.7896e-04 - val_loss: 4.2499e-04
 - val_f1: 0.9998
Epoch 262/300
 - 64s - loss: 4.6739e-04 - val_loss: 3.6850e-04
 - val_f1: 0.9998
Epoch 263/300
 - 64s - loss: 4.8422e-04 - val_loss: 3.7526e-04
 - val_f1: 0.9998
Epoch 264/300
 - 64s - loss: 4.6800e-04 - val_loss: 3.8330e-04
 - val_f1: 0.9998
Epoch 265/300
 - 65s - loss: 4.6216e-04 - val_loss: 3.5679e-04
 - val_f1: 0.9998
Epoch 266/300
 - 64s - loss: 4.7006e-04 - val_loss: 3.6467e-04
 - val_f1: 0.9998
Epoch 267/300
 - 64s - loss: 4.7460e-04 - val_loss: 3.4475e-04
 - val_f1: 0.9998
Epoch 268/300
 - 64s - loss: 4.7720e-04 - val_loss: 3.6887e-04
 - val_f1: 0.9998
Epoch 269/300
 - 64s - loss: 4.6583e-04 - val_loss: 3.6962e-04
 - val_f1: 0.9998
Epoch 270/300
 - 64s - loss: 4.5157e-04 - val_loss: 3.9618e-04
 - val_f1: 0.9998
Epoch 271/300
 - 64s - loss: 4.7967e-04 - val_loss: 3.9087e-04
2020-01-01 07:17:18,785 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 64s - loss: 4.6346e-04 - val_loss: 4.3816e-04
 - val_f1: 0.9998
Epoch 273/300
 - 64s - loss: 4.7151e-04 - val_loss: 3.7635e-04
 - val_f1: 0.9998
Epoch 274/300
 - 64s - loss: 4.6421e-04 - val_loss: 3.7568e-04
 - val_f1: 0.9998
Epoch 275/300
 - 64s - loss: 4.8550e-04 - val_loss: 3.7236e-04
 - val_f1: 0.9998
Epoch 276/300
 - 64s - loss: 4.8707e-04 - val_loss: 3.9880e-04
 - val_f1: 0.9998
Epoch 277/300
 - 64s - loss: 4.5493e-04 - val_loss: 3.8215e-04
 - val_f1: 0.9998
Epoch 278/300
 - 64s - loss: 4.6760e-04 - val_loss: 3.6748e-04
 - val_f1: 0.9998
Epoch 279/300
 - 64s - loss: 4.7570e-04 - val_loss: 3.6963e-04
 - val_f1: 0.9998
Epoch 280/300
 - 64s - loss: 4.5166e-04 - val_loss: 3.7391e-04
 - val_f1: 0.9998
Epoch 281/300
 - 64s - loss: 4.7937e-04 - val_loss: 3.8208e-04
 - val_f1: 0.9998
Epoch 282/300
 - 64s - loss: 4.5960e-04 - val_loss: 3.6261e-04
 - val_f1: 0.9998
Epoch 283/300
 - 64s - loss: 4.6733e-04 - val_loss: 3.7065e-04
 - val_f1: 0.9998
Epoch 284/300
 - 64s - loss: 4.8131e-04 - val_loss: 4.5695e-04
 - val_f1: 0.9998
Epoch 285/300
 - 64s - loss: 4.7356e-04 - val_loss: 3.4483e-04
 - val_f1: 0.9998
Epoch 286/300
 - 64s - loss: 4.5455e-04 - val_loss: 3.7908e-04
 - val_f1: 0.9998
Epoch 287/300
 - 64s - loss: 4.6366e-04 - val_loss: 3.6622e-04
 - val_f1: 0.9998
Epoch 288/300
 - 64s - loss: 4.6003e-04 - val_loss: 3.7634e-04
 - val_f1: 0.9998
Epoch 289/300
 - 64s - loss: 4.6466e-04 - val_loss: 5.2772e-04
 - val_f1: 0.9998
Epoch 290/300
 - 64s - loss: 4.6853e-04 - val_loss: 3.5230e-04
 - val_f1: 0.9998
Epoch 291/300
 - 64s - loss: 4.5409e-04 - val_loss: 3.6425e-04
 - val_f1: 0.9998
Epoch 292/300
 - 64s - loss: 4.5591e-04 - val_loss: 3.7270e-04
 - val_f1: 0.9998
Epoch 293/300
 - 64s - loss: 4.4458e-04 - val_loss: 3.4883e-04
 - val_f1: 0.9998
Epoch 294/300
 - 64s - loss: 4.5322e-04 - val_loss: 3.5627e-04
 - val_f1: 0.9998
Epoch 295/300
 - 64s - loss: 4.5139e-04 - val_loss: 3.7303e-04
 - val_f1: 0.9998
Epoch 296/300
 - 64s - loss: 4.6080e-04 - val_loss: 3.7431e-04
 - val_f1: 0.9998
Epoch 297/300
 - 64s - loss: 4.4509e-04 - val_loss: 3.9130e-04
 - val_f1: 0.9998
Epoch 298/300
 - 64s - loss: 4.6987e-04 - val_loss: 3.7067e-04
 - val_f1: 0.9998
Epoch 299/300
 - 64s - loss: 4.5137e-04 - val_loss: 3.9848e-04
 - val_f1: 0.9998
Epoch 300/300
 - 64s - loss: 4.5533e-04 - val_loss: 5.5501e-04
2020-01-01 08:03:29,982 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-01 08:05:45,833 [INFO] Last epoch loss evaluation: train_loss = 0.000259, val_loss = 0.000345
2020-01-01 08:05:45,847 [INFO] Training complete. time_to_train = 31308.84 sec, 521.81 min
2020-01-01 08:05:45,856 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_deep_rep5/best_model.pickle
2020-01-01 08:05:45,859 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_deep_rep5/training_error_history.csv
2020-01-01 08:05:46,037 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep5/training_error_history.png
2020-01-01 08:05:46,206 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_deep_rep5/training_f1_history.png
2020-01-01 08:05:46,206 [INFO] Making predictions on training, validation, testing data
2020-01-01 08:08:22,377 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-01 08:08:31,050 [INFO] Dataset: Testing. Classification report below
2020-01-01 08:08:31,050 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.99      0.84     60593
       probe       0.86      0.78      0.82      4166
         r2l       0.89      0.03      0.06     13781
         u2r       0.00      0.00      0.00      2636

    accuracy                           0.92    311029
   macro avg       0.70      0.55      0.54    311029
weighted avg       0.93      0.92      0.91    311029

2020-01-01 08:08:31,050 [INFO] Overall accuracy (micro avg): 0.9242964482411608
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-01 08:08:40,345 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9243         0.9243                       0.9243                0.0189                   0.0757  0.9243
1     Macro avg        0.9697         0.6963                       0.5544                0.0192                   0.4456  0.5403
2  Weighted avg        0.9683         0.9306                       0.9243                0.0203                   0.0757  0.9055
2020-01-01 08:09:10,556 [INFO] Dataset: Validation. Classification report below
2020-01-01 08:09:10,556 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      1.00      8221
         r2l       0.95      0.77      0.85       225
         u2r       0.00      0.00      0.00        10

    accuracy                           1.00    979687
   macro avg       0.79      0.75      0.77    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-01 08:09:10,556 [INFO] Overall accuracy (micro avg): 0.9998142263804665
2020-01-01 08:09:43,146 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.7894                       0.7524                0.0001                   0.2476  0.7690
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2020-01-01 08:11:56,185 [INFO] Dataset: Training. Classification report below
2020-01-01 08:11:56,185 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.94      0.82      0.87       901
         u2r       0.00      0.00      0.00        42

    accuracy                           1.00   3918744
   macro avg       0.79      0.76      0.77   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-01 08:11:56,185 [INFO] Overall accuracy (micro avg): 0.9998343857113402
2020-01-01 08:14:19,767 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.7871                       0.7623                0.0001                   0.2377  0.7739
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2020-01-01 08:14:19,814 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_deep_rep5/selected_kdd99_dbn_deep_rep5_results.xlsx
2020-01-01 08:14:19,821 [INFO] ================= Finished running experiment no. 5 ================= 

2020-01-01 08:14:19,844 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9998
