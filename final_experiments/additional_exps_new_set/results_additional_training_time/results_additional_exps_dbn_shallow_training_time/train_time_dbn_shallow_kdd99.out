Using TensorFlow backend.
2020-01-15 00:10:37,811 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_shallow_rep1/run_log.log
2020-01-15 00:10:37,811 [INFO] ================= Running experiment no. 1  ================= 

2020-01-15 00:10:37,812 [INFO] Experiment parameters given below
2020-01-15 00:10:37,812 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_shallow_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.921590082, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_shallow_rep1'}
2020-01-15 00:10:37,812 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_shallow_rep1/tf_logs_run_2020_01_15-00_10_37
2020-01-15 00:10:37,812 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-15 00:10:37,820 [INFO] Reading X, y files
2020-01-15 00:10:37,820 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-15 00:10:46,679 [INFO] Reading complete. time_to_read=8.86 seconds
2020-01-15 00:10:46,679 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-15 00:10:48,781 [INFO] Reading complete. time_to_read=2.10 seconds
2020-01-15 00:10:48,781 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-15 00:10:49,420 [INFO] Reading complete. time_to_read=0.64 seconds
2020-01-15 00:10:49,420 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-15 00:10:49,834 [INFO] Reading complete. time_to_read=0.41 seconds
2020-01-15 00:10:49,834 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-15 00:10:49,953 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-15 00:10:49,954 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-15 00:10:49,996 [INFO] Reading complete. time_to_read=0.04 seconds
2020-01-15 00:11:33,234 [INFO] Initializing model
2020-01-15 00:11:33,302 [INFO] Training model
2020-01-15 00:11:33,304 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-15 00:14:12,653 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 7113593fe95397e7410d0a04e6e918d66551e5e1
2020-01-15 00:14:12,683 [INFO] Pretraining Deep Belief Network
2020-01-15 00:17:38,462 [INFO] Pretraining Complete
2020-01-15 00:17:38,495 [INFO] Getting pretrained weights
2020-01-15 00:17:38,495 [INFO] Creating and initializing feed forward neural network
2020-01-15 00:17:38,520 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2020-01-15 00:17:39,047 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2020-01-15 00:17:39,196 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2020-01-15 00:17:39,667 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2020-01-15 00:17:39,731 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-15 00:17:39,770 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-01-15 00:17:39,794 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2020-01-15 00:17:39,799 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-01-15 00:17:39,817 [INFO] _________________________________________________________________
2020-01-15 00:17:39,817 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-15 00:17:39,817 [INFO] =================================================================
2020-01-15 00:17:39,818 [INFO] dense_1 (Dense)              (None, 32)                3968      
2020-01-15 00:17:39,818 [INFO] _________________________________________________________________
2020-01-15 00:17:39,818 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2020-01-15 00:17:39,818 [INFO] _________________________________________________________________
2020-01-15 00:17:39,818 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2020-01-15 00:17:39,818 [INFO] _________________________________________________________________
2020-01-15 00:17:39,818 [INFO] dense_2 (Dense)              (None, 5)                 165       
2020-01-15 00:17:39,818 [INFO] =================================================================
2020-01-15 00:17:39,818 [INFO] Total params: 4,261
2020-01-15 00:17:39,819 [INFO] Trainable params: 4,197
2020-01-15 00:17:39,819 [INFO] Non-trainable params: 64
2020-01-15 00:17:39,819 [INFO] _________________________________________________________________
2020-01-15 00:17:39.831528: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-15 00:17:40.205122: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2020-01-15 00:17:40.224951: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c0bd664ae0 executing computations on platform Host. Devices:
2020-01-15 00:17:40.225017: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-15 00:17:40.651630: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-01-15 00:17:40,721 [INFO] Fine-tuning final neural network
2020-01-15 00:17:47,320 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2020-01-15 00:17:47,320 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.30, time = 13.71s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -33.89, time = 21.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.03, time = 20.35s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.45, time = 20.19s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.68, time = 20.21s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.38, time = 20.11s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -40.73, time = 20.07s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -42.91, time = 19.89s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.07, time = 19.86s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -47.23, time = 19.84s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 51s - loss: 0.0172 - val_loss: 0.0012
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9200
Epoch 2/100
 - 25s - loss: 0.0016 - val_loss: 8.5424e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9213
Epoch 3/100
 - 25s - loss: 0.0012 - val_loss: 7.1168e-04
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-15 00:20:25,503 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9216, current_metric = 0.9230, num_epochs = 3
2020-01-15 00:20:25,504 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-15 00:21:06,279 [INFO] Last epoch loss evaluation: train_loss = 0.000710, val_loss = 0.000712
2020-01-15 00:21:06,416 [INFO] Training complete. time_to_train = 573.11 sec, 9.55 min
2020-01-15 00:21:06,472 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_shallow_rep1/best_model.pickle
2020-01-15 00:21:06,512 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep1/training_error_history.csv
2020-01-15 00:21:06,980 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep1/training_error_history.png
2020-01-15 00:21:07,106 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep1/training_f1_history.png
2020-01-15 00:21:07,106 [INFO] Making predictions on training, validation, testing data
2020-01-15 00:22:22,805 [INFO] Making predictions complete. time_to_predict = 75.70 sec, 1.26 min
2020-01-15 00:22:22,920 [INFO] Evaluating predictions (results)
2020-01-15 00:22:27,642 [INFO] Dataset: Testing. Classification report below
2020-01-15 00:22:27,642 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.91      0.75      0.82      4166
         r2l       0.85      0.03      0.06     13781
         u2r       0.64      0.00      0.01      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.82      0.55      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-15 00:22:27,642 [INFO] Overall accuracy (micro avg): 0.9232000874516524
2020-01-15 00:22:32,994 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9232         0.9232                       0.9232                0.0192                   0.0768  0.9232
1     Macro avg        0.9693         0.8250                       0.5479                0.0206                   0.4521  0.5418
2  Weighted avg        0.9669         0.9325                       0.9232                0.0262                   0.0768  0.9044
2020-01-15 00:22:49,374 [INFO] Dataset: Validation. Classification report below
2020-01-15 00:22:49,374 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.98      0.99      8221
         r2l       0.89      0.51      0.65       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.78      0.70      0.73    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-15 00:22:49,374 [INFO] Overall accuracy (micro avg): 0.9995968100015618
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-15 00:23:07,987 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9998         0.7765                       0.6990                0.0002                   0.3010  0.7275
2  Weighted avg        0.9998         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-15 00:24:20,113 [INFO] Dataset: Training. Classification report below
2020-01-15 00:24:20,113 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.98      0.99     32881
         r2l       0.87      0.53      0.66       901
         u2r       0.23      0.12      0.16        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.82      0.73      0.76   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-15 00:24:20,113 [INFO] Overall accuracy (micro avg): 0.9995891540758978
2020-01-15 00:25:41,866 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9998         0.8174                       0.7257                0.0002                   0.2743  0.7598
2  Weighted avg        0.9998         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-15 00:25:41,917 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep1/train_time_kdd99_dbn_shallow_rep1_results.xlsx
2020-01-15 00:25:41,924 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-15 00:25:42,275 [INFO] Created directory: results_additional_exps/train_time_kdd99_dbn_shallow_rep2
2020-01-15 00:25:42,276 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_shallow_rep2/run_log.log
2020-01-15 00:25:42,276 [INFO] ================= Running experiment no. 2  ================= 

2020-01-15 00:25:42,276 [INFO] Experiment parameters given below
2020-01-15 00:25:42,276 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_shallow_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.921590082, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_shallow_rep2'}
2020-01-15 00:25:42,276 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_shallow_rep2/tf_logs_run_2020_01_15-00_25_42
2020-01-15 00:25:42,276 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-15 00:25:42,289 [INFO] Reading X, y files
2020-01-15 00:25:42,289 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-15 00:25:51,140 [INFO] Reading complete. time_to_read=8.85 seconds
2020-01-15 00:25:51,140 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-15 00:25:53,296 [INFO] Reading complete. time_to_read=2.16 seconds
2020-01-15 00:25:53,296 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-15 00:25:53,932 [INFO] Reading complete. time_to_read=0.64 seconds
2020-01-15 00:25:53,932 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-15 00:25:54,467 [INFO] Reading complete. time_to_read=0.54 seconds
2020-01-15 00:25:54,467 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-15 00:25:54,586 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-15 00:25:54,586 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-15 00:25:54,632 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-15 00:26:44,500 [INFO] Initializing model
2020-01-15 00:26:44,548 [INFO] Training model
2020-01-15 00:26:44,549 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-15 00:29:24,002 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 7aefe5eb5a79e33c25cad91f3058616ba6e57c65
2020-01-15 00:29:24,028 [INFO] Pretraining Deep Belief Network
2020-01-15 00:32:52,799 [INFO] Pretraining Complete
2020-01-15 00:32:52,814 [INFO] Getting pretrained weights
2020-01-15 00:32:52,814 [INFO] Creating and initializing feed forward neural network
2020-01-15 00:32:53,522 [INFO] _________________________________________________________________
2020-01-15 00:32:53,522 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-15 00:32:53,522 [INFO] =================================================================
2020-01-15 00:32:53,522 [INFO] dense_3 (Dense)              (None, 32)                3968      
2020-01-15 00:32:53,522 [INFO] _________________________________________________________________
2020-01-15 00:32:53,522 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2020-01-15 00:32:53,522 [INFO] _________________________________________________________________
2020-01-15 00:32:53,522 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2020-01-15 00:32:53,522 [INFO] _________________________________________________________________
2020-01-15 00:32:53,522 [INFO] dense_4 (Dense)              (None, 5)                 165       
2020-01-15 00:32:53,522 [INFO] =================================================================
2020-01-15 00:32:53,533 [INFO] Total params: 4,261
2020-01-15 00:32:53,533 [INFO] Trainable params: 4,197
2020-01-15 00:32:53,533 [INFO] Non-trainable params: 64
2020-01-15 00:32:53,533 [INFO] _________________________________________________________________
2020-01-15 00:32:54,183 [INFO] Fine-tuning final neural network
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9230
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.77, time = 13.55s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -34.29, time = 22.05s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.51, time = 20.37s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -34.13, time = 20.23s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -36.63, time = 20.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -39.08, time = 20.14s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -41.34, time = 20.14s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.59, time = 19.95s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.86, time = 19.91s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -48.11, time = 19.89s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 59s - loss: 0.0187 - val_loss: 0.0013
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9203
Epoch 2/100
 - 27s - loss: 0.0016 - val_loss: 8.5027e-04
 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9214
Epoch 3/100
 - 27s - loss: 0.0011 - val_loss: 7.0301e-04
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-15 00:35:41,647 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9216, current_metric = 0.9233, num_epochs = 3
2020-01-15 00:35:41,653 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-15 00:36:25,247 [INFO] Last epoch loss evaluation: train_loss = 0.000622, val_loss = 0.000703
2020-01-15 00:36:25,405 [INFO] Training complete. time_to_train = 580.86 sec, 9.68 min
2020-01-15 00:36:25,529 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_shallow_rep2/best_model.pickle
2020-01-15 00:36:25,616 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep2/training_error_history.csv
2020-01-15 00:36:25,969 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep2/training_error_history.png
2020-01-15 00:36:26,099 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep2/training_f1_history.png
2020-01-15 00:36:26,099 [INFO] Making predictions on training, validation, testing data
2020-01-15 00:37:40,379 [INFO] Making predictions complete. time_to_predict = 74.28 sec, 1.24 min
2020-01-15 00:37:40,599 [INFO] Evaluating predictions (results)
2020-01-15 00:37:45,255 [INFO] Dataset: Testing. Classification report below
2020-01-15 00:37:45,255 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.90      0.77      0.83      4166
         r2l       0.98      0.03      0.06     13781
         u2r       0.74      0.01      0.01      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.87      0.55      0.54    311029
weighted avg       0.94      0.92      0.90    311029

2020-01-15 00:37:45,256 [INFO] Overall accuracy (micro avg): 0.9234765889997396
2020-01-15 00:37:50,617 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9235         0.9235                       0.9235                0.0191                   0.0765  0.9235
1     Macro avg        0.9694         0.8666                       0.5528                0.0204                   0.4472  0.5442
2  Weighted avg        0.9671         0.9390                       0.9235                0.0257                   0.0765  0.9046
2020-01-15 00:38:06,946 [INFO] Dataset: Validation. Classification report below
2020-01-15 00:38:06,946 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.98      0.99      8221
         r2l       0.89      0.72      0.80       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.78      0.74      0.76    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-15 00:38:06,946 [INFO] Overall accuracy (micro avg): 0.9996386601026654
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-15 00:38:25,448 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9999         0.7772                       0.7399                0.0002                   0.2601  0.7566
2  Weighted avg        0.9998         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-15 00:39:37,601 [INFO] Dataset: Training. Classification report below
2020-01-15 00:39:37,601 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.87      0.72      0.79       901
         u2r       0.25      0.10      0.14        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.82      0.76      0.78   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-15 00:39:37,601 [INFO] Overall accuracy (micro avg): 0.9996414667556748
2020-01-15 00:41:02,315 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9996         0.9996                       0.9996                0.0001                   0.0004  0.9996
1     Macro avg        0.9999         0.8232                       0.7592                0.0002                   0.2408  0.7826
2  Weighted avg        0.9998         0.9996                       0.9996                0.0004                   0.0004  0.9996
2020-01-15 00:41:02,369 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep2/train_time_kdd99_dbn_shallow_rep2_results.xlsx
2020-01-15 00:41:02,377 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-15 00:41:02,728 [INFO] Created directory: results_additional_exps/train_time_kdd99_dbn_shallow_rep3
2020-01-15 00:41:02,728 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_dbn_shallow_rep3/run_log.log
2020-01-15 00:41:02,728 [INFO] ================= Running experiment no. 3  ================= 

2020-01-15 00:41:02,728 [INFO] Experiment parameters given below
2020-01-15 00:41:02,728 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_kdd99_dbn_shallow_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 10, 'fine_tune_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.921590082, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_dbn_shallow_rep3'}
2020-01-15 00:41:02,729 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_dbn_shallow_rep3/tf_logs_run_2020_01_15-00_41_02
2020-01-15 00:41:02,729 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-15 00:41:02,767 [INFO] Reading X, y files
2020-01-15 00:41:02,767 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-15 00:41:12,817 [INFO] Reading complete. time_to_read=10.05 seconds
2020-01-15 00:41:12,818 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-15 00:41:15,140 [INFO] Reading complete. time_to_read=2.32 seconds
2020-01-15 00:41:15,140 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-15 00:41:15,869 [INFO] Reading complete. time_to_read=0.73 seconds
2020-01-15 00:41:15,869 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-15 00:41:16,583 [INFO] Reading complete. time_to_read=0.71 seconds
2020-01-15 00:41:16,583 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-15 00:41:16,706 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-15 00:41:16,706 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-15 00:41:16,751 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-15 00:42:05,162 [INFO] Initializing model
2020-01-15 00:42:05,210 [INFO] Training model
2020-01-15 00:42:05,212 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-15 00:44:44,688 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 21374f1d6305f5b2dfc66a2aa158b17d55d74916
2020-01-15 00:44:44,714 [INFO] Pretraining Deep Belief Network
2020-01-15 00:48:10,894 [INFO] Pretraining Complete
2020-01-15 00:48:10,913 [INFO] Getting pretrained weights
2020-01-15 00:48:10,913 [INFO] Creating and initializing feed forward neural network
2020-01-15 00:48:12,188 [INFO] _________________________________________________________________
2020-01-15 00:48:12,189 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-15 00:48:12,189 [INFO] =================================================================
2020-01-15 00:48:12,190 [INFO] dense_5 (Dense)              (None, 32)                3968      
2020-01-15 00:48:12,190 [INFO] _________________________________________________________________
2020-01-15 00:48:12,190 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2020-01-15 00:48:12,190 [INFO] _________________________________________________________________
2020-01-15 00:48:12,191 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2020-01-15 00:48:12,191 [INFO] _________________________________________________________________
2020-01-15 00:48:12,191 [INFO] dense_6 (Dense)              (None, 5)                 165       
2020-01-15 00:48:12,191 [INFO] =================================================================
2020-01-15 00:48:12,191 [INFO] Total params: 4,261
2020-01-15 00:48:12,191 [INFO] Trainable params: 4,197
2020-01-15 00:48:12,191 [INFO] Non-trainable params: 64
2020-01-15 00:48:12,191 [INFO] _________________________________________________________________
2020-01-15 00:48:13,191 [INFO] Fine-tuning final neural network
 - val_f1: 0.9996
 - out_of_sample_accuracy: 0.9233
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.60, time = 13.55s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -34.34, time = 21.91s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.57, time = 20.35s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.90, time = 20.27s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.92, time = 20.26s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.69, time = 20.16s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -41.23, time = 20.14s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.41, time = 20.00s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.50, time = 19.87s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -47.55, time = 19.88s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/100
 - 49s - loss: 0.0162 - val_loss: 0.0012
 - val_f1: 0.9993
 - out_of_sample_accuracy: 0.9210
Epoch 2/100
 - 26s - loss: 0.0016 - val_loss: 8.3396e-04
2020-01-15 00:50:09,405 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9216, current_metric = 0.9217, num_epochs = 2
2020-01-15 00:50:09,406 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-15 00:50:53,979 [INFO] Last epoch loss evaluation: train_loss = 0.000841, val_loss = 0.000834
2020-01-15 00:50:54,125 [INFO] Training complete. time_to_train = 528.91 sec, 8.82 min
2020-01-15 00:50:54,278 [INFO] Model saved to results_additional_exps/train_time_kdd99_dbn_shallow_rep3/best_model.pickle
2020-01-15 00:50:54,307 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep3/training_error_history.csv
2020-01-15 00:50:54,661 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep3/training_error_history.png
2020-01-15 00:50:54,782 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep3/training_f1_history.png
2020-01-15 00:50:54,782 [INFO] Making predictions on training, validation, testing data
2020-01-15 00:52:14,889 [INFO] Making predictions complete. time_to_predict = 80.11 sec, 1.34 min
2020-01-15 00:52:15,089 [INFO] Evaluating predictions (results)
2020-01-15 00:52:19,769 [INFO] Dataset: Testing. Classification report below
2020-01-15 00:52:19,769 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.72      0.99      0.83     60593
       probe       0.88      0.77      0.82      4166
         r2l       0.96      0.03      0.06     13781
         u2r       0.00      0.00      0.00      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.71      0.55      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-15 00:52:19,769 [INFO] Overall accuracy (micro avg): 0.9217307710856544
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-15 00:52:25,136 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9217         0.9217                       0.9217                0.0196                   0.0783  0.9217
1     Macro avg        0.9687         0.7113                       0.5512                0.0209                   0.4488  0.5396
2  Weighted avg        0.9654         0.9310                       0.9217                0.0262                   0.0783  0.9030
2020-01-15 00:52:41,525 [INFO] Dataset: Validation. Classification report below
2020-01-15 00:52:41,525 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.98      0.98      8221
         r2l       0.77      0.56      0.65       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.75      0.71      0.73    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-15 00:52:41,525 [INFO] Overall accuracy (micro avg): 0.9995141305335276
2020-01-15 00:53:00,101 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9995         0.9995                       0.9995                0.0001                   0.0005  0.9995
1     Macro avg        0.9998         0.7532                       0.7082                0.0002                   0.2918  0.7274
2  Weighted avg        0.9998         0.9995                       0.9995                0.0006                   0.0005  0.9995
2020-01-15 00:54:12,120 [INFO] Dataset: Training. Classification report below
2020-01-15 00:54:12,121 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.98      0.98     32881
         r2l       0.73      0.56      0.64       901
         u2r       0.00      0.00      0.00        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.74      0.71      0.72   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-15 00:54:12,121 [INFO] Overall accuracy (micro avg): 0.99948427353254
2020-01-15 00:55:33,821 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9995         0.9995                       0.9995                0.0001                   0.0005  0.9995
1     Macro avg        0.9998         0.7437                       0.7079                0.0002                   0.2921  0.7237
2  Weighted avg        0.9998         0.9995                       0.9995                0.0006                   0.0005  0.9995
2020-01-15 00:55:33,873 [INFO] Results saved to: results_additional_exps/train_time_kdd99_dbn_shallow_rep3/train_time_kdd99_dbn_shallow_rep3_results.xlsx
2020-01-15 00:55:33,881 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-15 00:55:34,190 [INFO] ================= Finished running 3 experiments ================= 

 - val_f1: 0.9995
 - out_of_sample_accuracy: 0.9217
