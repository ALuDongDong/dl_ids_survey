Using TensorFlow backend.
2019-12-23 21:06:09,384 [INFO] Read 6 experiments from file: experiment_specs/additional_exps/semi_sup_perf_dbn.csv
2019-12-23 21:06:09,384 [INFO] ================= Started running experiments ================= 

2019-12-23 21:06:09,384 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep1
2019-12-23 21:06:09,385 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep1/run_log.log
2019-12-23 21:06:09,385 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 21:06:09,385 [INFO] Experiment parameters given below
2019-12-23 21:06:09,385 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep1'}
2019-12-23 21:06:09,385 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/tf_logs_run_2019_12_23-21_06_09
2019-12-23 21:06:09,385 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 21:06:09,385 [INFO] Reading X, y files
2019-12-23 21:06:09,386 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 21:06:09,650 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-23 21:06:09,650 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 21:06:09,715 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 21:06:09,716 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 21:06:09,774 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 21:06:09,774 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 21:06:09,782 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 21:06:09,782 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 21:06:09,785 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:06:09,785 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 21:06:09,789 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:06:09,980 [INFO] Initializing model
2019-12-23 21:06:09,980 [INFO] Training model
2019-12-23 21:06:09,980 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 21:06:10,648 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 1141908572ca0715ff327e6e507527e312df82d8
2019-12-23 21:06:10,648 [INFO] Pretraining Deep Belief Network
2019-12-23 21:06:49,961 [INFO] Pretraining Complete
2019-12-23 21:06:49,961 [INFO] Getting pretrained weights
2019-12-23 21:06:49,961 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-23 21:06:49,974 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 21:06:50,037 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 21:06:50,074 [INFO] _________________________________________________________________
2019-12-23 21:06:50,074 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 21:06:50,074 [INFO] =================================================================
2019-12-23 21:06:50,074 [INFO] dense_1 (Dense)              (None, 64)                7872      
2019-12-23 21:06:50,074 [INFO] _________________________________________________________________
2019-12-23 21:06:50,075 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2019-12-23 21:06:50,075 [INFO] _________________________________________________________________
2019-12-23 21:06:50,075 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2019-12-23 21:06:50,075 [INFO] _________________________________________________________________
2019-12-23 21:06:50,075 [INFO] dense_2 (Dense)              (None, 5)                 325       
2019-12-23 21:06:50,075 [INFO] =================================================================
2019-12-23 21:06:50,075 [INFO] Total params: 8,453
2019-12-23 21:06:50,075 [INFO] Trainable params: 8,325
2019-12-23 21:06:50,075 [INFO] Non-trainable params: 128
2019-12-23 21:06:50,075 [INFO] _________________________________________________________________
2019-12-23 21:06:50.075668: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-23 21:06:50.096756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2019-12-23 21:06:50.096948: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3394fd0 executing computations on platform Host. Devices:
2019-12-23 21:06:50.096970: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-23 21:06:50,148 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-23 21:06:50,539 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
[BernoulliRBM] Iteration 1, pseudo-likelihood = -76.21, time = 0.48s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.53, time = 0.80s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -66.33, time = 0.81s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -63.13, time = 0.81s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -60.64, time = 0.80s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -58.66, time = 0.80s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -57.09, time = 0.80s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -55.83, time = 0.80s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -54.83, time = 0.80s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -54.03, time = 0.80s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -53.41, time = 0.79s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -52.92, time = 0.80s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -52.57, time = 0.79s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -52.31, time = 0.80s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -52.15, time = 0.79s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -52.06, time = 0.80s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -52.04, time = 0.79s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -52.07, time = 0.79s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -52.16, time = 0.79s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -52.29, time = 0.79s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -52.45, time = 0.79s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -52.65, time = 0.79s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -52.88, time = 0.79s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -53.14, time = 0.79s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -53.42, time = 0.79s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -53.71, time = 0.79s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -54.03, time = 0.79s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -54.35, time = 0.79s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -54.69, time = 0.79s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -55.04, time = 0.79s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -55.39, time = 0.79s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -55.76, time = 0.79s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -56.13, time = 0.79s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -56.50, time = 0.78s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -56.88, time = 0.78s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -57.27, time = 0.78s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -57.66, time = 0.78s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -58.06, time = 0.77s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -58.47, time = 0.78s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -58.89, time = 0.77s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -59.32, time = 0.77s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -59.76, time = 0.77s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -60.23, time = 0.77s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -60.71, time = 0.77s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -61.21, time = 0.77s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -61.72, time = 0.76s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -62.24, time = 0.77s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -62.77, time = 0.76s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -63.30, time = 0.76s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -63.81, time = 0.76s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1550 - val_loss: 0.0582
 - val_f1: 0.9631
Epoch 2/300
 - 0s - loss: 0.0478 - val_loss: 0.0298
 - val_f1: 0.9795
Epoch 3/300
 - 0s - loss: 0.0250 - val_loss: 0.0169
 - val_f1: 0.9874
Epoch 4/300
 - 0s - loss: 0.0189 - val_loss: 0.0138
 - val_f1: 0.9889
Epoch 5/300
 - 0s - loss: 0.0160 - val_loss: 0.0124
 - val_f1: 0.9907
Epoch 6/300
 - 0s - loss: 0.0145 - val_loss: 0.0117
 - val_f1: 0.9902
Epoch 7/300
 - 0s - loss: 0.0138 - val_loss: 0.0114
 - val_f1: 0.9906
Epoch 8/300
 - 0s - loss: 0.0128 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 9/300
 - 0s - loss: 0.0120 - val_loss: 0.0102
 - val_f1: 0.9919
Epoch 10/300
 - 0s - loss: 0.0118 - val_loss: 0.0100
 - val_f1: 0.9925
Epoch 11/300
 - 0s - loss: 0.0114 - val_loss: 0.0103
 - val_f1: 0.9913
Epoch 12/300
 - 0s - loss: 0.0111 - val_loss: 0.0107
 - val_f1: 0.9908
Epoch 13/300
 - 0s - loss: 0.0101 - val_loss: 0.0094
 - val_f1: 0.9920
Epoch 14/300
 - 0s - loss: 0.0099 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 15/300
 - 0s - loss: 0.0092 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 16/300
 - 0s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9941
Epoch 17/300
 - 0s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9932
Epoch 18/300
 - 0s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9937
Epoch 19/300
 - 0s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9934
Epoch 20/300
 - 0s - loss: 0.0084 - val_loss: 0.0078
 - val_f1: 0.9944
Epoch 21/300
 - 0s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9935
Epoch 22/300
 - 0s - loss: 0.0086 - val_loss: 0.0086
 - val_f1: 0.9924
Epoch 23/300
 - 0s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9945
Epoch 24/300
 - 0s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 25/300
 - 0s - loss: 0.0077 - val_loss: 0.0079
 - val_f1: 0.9930
Epoch 26/300
 - 0s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 27/300
 - 0s - loss: 0.0077 - val_loss: 0.0083
 - val_f1: 0.9943
Epoch 28/300
 - 0s - loss: 0.0076 - val_loss: 0.0084
 - val_f1: 0.9930
Epoch 29/300
 - 0s - loss: 0.0075 - val_loss: 0.0077
 - val_f1: 0.9939
Epoch 30/300
 - 0s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9940
Epoch 31/300
 - 0s - loss: 0.0075 - val_loss: 0.0078
2019-12-23 21:07:11,266 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9941
Epoch 32/300
 - 0s - loss: 0.0071 - val_loss: 0.0075
 - val_f1: 0.9941
Epoch 33/300
 - 0s - loss: 0.0072 - val_loss: 0.0076
 - val_f1: 0.9939
Epoch 34/300
 - 0s - loss: 0.0069 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 35/300
 - 0s - loss: 0.0070 - val_loss: 0.0074
 - val_f1: 0.9947
Epoch 36/300
 - 0s - loss: 0.0067 - val_loss: 0.0075
 - val_f1: 0.9946
Epoch 37/300
 - 0s - loss: 0.0072 - val_loss: 0.0075
 - val_f1: 0.9944
Epoch 38/300
 - 0s - loss: 0.0067 - val_loss: 0.0075
 - val_f1: 0.9948
Epoch 39/300
 - 0s - loss: 0.0068 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 40/300
 - 0s - loss: 0.0069 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 41/300
 - 0s - loss: 0.0066 - val_loss: 0.0075
 - val_f1: 0.9943
Epoch 42/300
 - 0s - loss: 0.0065 - val_loss: 0.0073
 - val_f1: 0.9948
Epoch 43/300
 - 0s - loss: 0.0063 - val_loss: 0.0074
 - val_f1: 0.9947
Epoch 44/300
 - 0s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 45/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 46/300
 - 0s - loss: 0.0064 - val_loss: 0.0075
 - val_f1: 0.9945
Epoch 47/300
 - 0s - loss: 0.0062 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 48/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 49/300
 - 0s - loss: 0.0059 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 50/300
 - 0s - loss: 0.0059 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 51/300
 - 0s - loss: 0.0059 - val_loss: 0.0068
 - val_f1: 0.9949
Epoch 52/300
 - 0s - loss: 0.0056 - val_loss: 0.0076
 - val_f1: 0.9944
Epoch 53/300
 - 0s - loss: 0.0060 - val_loss: 0.0075
 - val_f1: 0.9943
Epoch 54/300
 - 0s - loss: 0.0056 - val_loss: 0.0071
 - val_f1: 0.9950
Epoch 55/300
 - 0s - loss: 0.0056 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 56/300
 - 0s - loss: 0.0055 - val_loss: 0.0066
 - val_f1: 0.9949
Epoch 57/300
 - 0s - loss: 0.0054 - val_loss: 0.0067
 - val_f1: 0.9949
Epoch 58/300
 - 0s - loss: 0.0055 - val_loss: 0.0074
 - val_f1: 0.9949
Epoch 59/300
 - 0s - loss: 0.0052 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 60/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9957
Epoch 61/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
2019-12-23 21:07:30,838 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9954
Epoch 62/300
 - 0s - loss: 0.0053 - val_loss: 0.0075
 - val_f1: 0.9942
Epoch 63/300
 - 0s - loss: 0.0054 - val_loss: 0.0075
 - val_f1: 0.9949
Epoch 64/300
 - 0s - loss: 0.0054 - val_loss: 0.0071
 - val_f1: 0.9957
Epoch 65/300
 - 0s - loss: 0.0052 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 66/300
 - 0s - loss: 0.0050 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 67/300
 - 0s - loss: 0.0051 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 68/300
 - 0s - loss: 0.0052 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 69/300
 - 0s - loss: 0.0052 - val_loss: 0.0065
 - val_f1: 0.9951
Epoch 70/300
 - 0s - loss: 0.0049 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 71/300
 - 0s - loss: 0.0049 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 72/300
 - 0s - loss: 0.0050 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 73/300
 - 0s - loss: 0.0048 - val_loss: 0.0076
 - val_f1: 0.9946
Epoch 74/300
 - 0s - loss: 0.0049 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 75/300
 - 0s - loss: 0.0049 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 76/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 77/300
 - 0s - loss: 0.0047 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 78/300
 - 0s - loss: 0.0050 - val_loss: 0.0073
 - val_f1: 0.9956
Epoch 79/300
 - 0s - loss: 0.0054 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 80/300
 - 0s - loss: 0.0052 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 81/300
 - 0s - loss: 0.0050 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 82/300
 - 0s - loss: 0.0050 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 83/300
 - 0s - loss: 0.0051 - val_loss: 0.0081
 - val_f1: 0.9951
Epoch 84/300
 - 0s - loss: 0.0054 - val_loss: 0.0072
 - val_f1: 0.9956
Epoch 85/300
 - 0s - loss: 0.0048 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 86/300
 - 0s - loss: 0.0051 - val_loss: 0.0079
 - val_f1: 0.9948
Epoch 87/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9957
Epoch 88/300
 - 0s - loss: 0.0047 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 89/300
 - 0s - loss: 0.0050 - val_loss: 0.0074
 - val_f1: 0.9955
Epoch 90/300
 - 0s - loss: 0.0048 - val_loss: 0.0073
 - val_f1: 0.9953
Epoch 91/300
 - 0s - loss: 0.0045 - val_loss: 0.0072
2019-12-23 21:07:50,316 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9955
Epoch 92/300
 - 0s - loss: 0.0048 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 93/300
 - 0s - loss: 0.0047 - val_loss: 0.0071
 - val_f1: 0.9954
Epoch 94/300
 - 0s - loss: 0.0046 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 95/300
 - 0s - loss: 0.0046 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 96/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 97/300
 - 0s - loss: 0.0047 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 98/300
 - 0s - loss: 0.0048 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 99/300
 - 0s - loss: 0.0046 - val_loss: 0.0070
 - val_f1: 0.9957
Epoch 100/300
 - 0s - loss: 0.0048 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 101/300
 - 0s - loss: 0.0043 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 102/300
 - 0s - loss: 0.0044 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 103/300
 - 0s - loss: 0.0046 - val_loss: 0.0075
 - val_f1: 0.9956
Epoch 104/300
 - 0s - loss: 0.0047 - val_loss: 0.0078
 - val_f1: 0.9954
Epoch 105/300
 - 0s - loss: 0.0043 - val_loss: 0.0075
 - val_f1: 0.9958
Epoch 106/300
 - 0s - loss: 0.0042 - val_loss: 0.0075
 - val_f1: 0.9961
Epoch 107/300
 - 0s - loss: 0.0043 - val_loss: 0.0075
 - val_f1: 0.9954
Epoch 108/300
 - 0s - loss: 0.0040 - val_loss: 0.0073
 - val_f1: 0.9956
Epoch 109/300
 - 0s - loss: 0.0040 - val_loss: 0.0074
 - val_f1: 0.9955
Epoch 110/300
 - 0s - loss: 0.0047 - val_loss: 0.0074
 - val_f1: 0.9956
Epoch 111/300
 - 0s - loss: 0.0045 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 112/300
 - 0s - loss: 0.0040 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 113/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 114/300
 - 0s - loss: 0.0041 - val_loss: 0.0079
 - val_f1: 0.9938
Epoch 115/300
 - 0s - loss: 0.0041 - val_loss: 0.0076
 - val_f1: 0.9957
Epoch 116/300
 - 0s - loss: 0.0046 - val_loss: 0.0078
 - val_f1: 0.9949
Epoch 117/300
 - 0s - loss: 0.0041 - val_loss: 0.0082
 - val_f1: 0.9952
Epoch 118/300
 - 0s - loss: 0.0040 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 119/300
 - 0s - loss: 0.0041 - val_loss: 0.0081
2019-12-23 21:08:08,796 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 21:08:09,630 [INFO] Last epoch loss evaluation: train_loss = 0.003264, val_loss = 0.006511
2019-12-23 21:08:09,635 [INFO] Training complete. time_to_train = 119.65 sec, 1.99 min
2019-12-23 21:08:09,639 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep1/best_model.pickle
2019-12-23 21:08:09,828 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/training_error_history.png
2019-12-23 21:08:09,997 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/training_f1_history.png
2019-12-23 21:08:09,997 [INFO] Making predictions on training, validation, testing data
2019-12-23 21:08:11,207 [INFO] Evaluating predictions (results)
2019-12-23 21:08:11,554 [INFO] Dataset: Testing. Classification report below
2019-12-23 21:08:11,555 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.69      0.96      0.80      9711
       probe       0.82      0.71      0.76      2421
         r2l       0.97      0.11      0.20      2421
         u2r       0.67      0.03      0.05       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.82      0.53      0.54     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-23 21:08:11,555 [INFO] Overall accuracy (micro avg): 0.7822480482611781
2019-12-23 21:08:11,849 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7822         0.7822                       0.7822                0.0544                   0.2178  0.7822
1     Macro avg        0.9129         0.8229                       0.5305                0.0738                   0.4695  0.5427
2  Weighted avg        0.8745         0.8233                       0.7822                0.1512                   0.2178  0.7470
2019-12-23 21:08:12,182 [INFO] Dataset: Validation. Classification report below
2019-12-23 21:08:12,182 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.94      0.88      0.91       199
         u2r       0.75      0.30      0.43        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.93      0.83      0.86     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 21:08:12,182 [INFO] Overall accuracy (micro avg): 0.9951180789839253
2019-12-23 21:08:12,537 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0012                   0.0049  0.9951
1     Macro avg        0.9980         0.9327                       0.8328                0.0016                   0.1672  0.8633
2  Weighted avg        0.9970         0.9950                       0.9951                0.0030                   0.0049  0.9950
2019-12-23 21:08:13,972 [INFO] Dataset: Training. Classification report below
2019-12-23 21:08:13,972 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.96      0.90      0.93       796
         u2r       0.92      0.55      0.69        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.89      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 21:08:13,972 [INFO] Overall accuracy (micro avg): 0.9962392585683383
2019-12-23 21:08:15,584 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0009                   0.0038  0.9962
1     Macro avg        0.9985         0.9734                       0.8865                0.0013                   0.1135  0.9202
2  Weighted avg        0.9976         0.9962                       0.9962                0.0026                   0.0038  0.9962
2019-12-23 21:08:15,623 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep1/semi_sup_perf_nsl_dbn_rep1_results.xlsx
2019-12-23 21:08:15,623 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 21:08:15,627 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep2
2019-12-23 21:08:15,627 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep2/run_log.log
2019-12-23 21:08:15,627 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 21:08:15,627 [INFO] Experiment parameters given below
2019-12-23 21:08:15,627 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep2'}
2019-12-23 21:08:15,627 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/tf_logs_run_2019_12_23-21_08_15
2019-12-23 21:08:15,627 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 21:08:15,627 [INFO] Reading X, y files
2019-12-23 21:08:15,628 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 21:08:15,871 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-23 21:08:15,871 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 21:08:15,936 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 21:08:15,936 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 21:08:15,994 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 21:08:15,995 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 21:08:16,002 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 21:08:16,002 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 21:08:16,006 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:08:16,006 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 21:08:16,009 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:08:16,197 [INFO] Initializing model
2019-12-23 21:08:16,198 [INFO] Training model
2019-12-23 21:08:16,198 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 21:08:16,824 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 65012b5fb60faa81106d4fe32edd455945f95f46
2019-12-23 21:08:16,825 [INFO] Pretraining Deep Belief Network
2019-12-23 21:08:55,276 [INFO] Pretraining Complete
2019-12-23 21:08:55,276 [INFO] Getting pretrained weights
2019-12-23 21:08:55,276 [INFO] Creating and initializing feed forward neural network
2019-12-23 21:08:55,442 [INFO] _________________________________________________________________
2019-12-23 21:08:55,442 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 21:08:55,442 [INFO] =================================================================
2019-12-23 21:08:55,442 [INFO] dense_3 (Dense)              (None, 64)                7872      
2019-12-23 21:08:55,442 [INFO] _________________________________________________________________
2019-12-23 21:08:55,442 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2019-12-23 21:08:55,442 [INFO] _________________________________________________________________
2019-12-23 21:08:55,442 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2019-12-23 21:08:55,442 [INFO] _________________________________________________________________
2019-12-23 21:08:55,442 [INFO] dense_4 (Dense)              (None, 5)                 325       
2019-12-23 21:08:55,442 [INFO] =================================================================
2019-12-23 21:08:55,443 [INFO] Total params: 8,453
2019-12-23 21:08:55,443 [INFO] Trainable params: 8,325
2019-12-23 21:08:55,443 [INFO] Non-trainable params: 128
2019-12-23 21:08:55,443 [INFO] _________________________________________________________________
2019-12-23 21:08:55,540 [INFO] Fine-tuning final neural network
 - val_f1: 0.9956
Epoch 00119: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -76.40, time = 0.47s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -70.90, time = 0.81s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -66.87, time = 0.80s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -63.82, time = 0.79s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -61.46, time = 0.79s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -59.61, time = 0.78s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -58.16, time = 0.79s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -57.02, time = 0.78s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -56.12, time = 0.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -55.43, time = 0.78s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.91, time = 0.78s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -54.52, time = 0.78s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -54.26, time = 0.78s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -54.09, time = 0.77s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -54.01, time = 0.78s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -54.01, time = 0.77s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -54.07, time = 0.78s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -54.18, time = 0.77s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -54.34, time = 0.77s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -54.55, time = 0.77s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -54.79, time = 0.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -55.06, time = 0.77s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.36, time = 0.77s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -55.68, time = 0.77s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -56.03, time = 0.77s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -56.39, time = 0.77s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -56.77, time = 0.77s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -57.15, time = 0.77s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -57.55, time = 0.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -57.96, time = 0.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -58.37, time = 0.77s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -58.79, time = 0.77s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -59.21, time = 0.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -59.64, time = 0.77s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -60.07, time = 0.76s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -60.50, time = 0.77s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -60.94, time = 0.76s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -61.38, time = 0.76s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -61.83, time = 0.76s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -62.28, time = 0.76s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -62.75, time = 0.75s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -63.23, time = 0.76s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -63.72, time = 0.75s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -64.22, time = 0.75s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -64.75, time = 0.75s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -65.29, time = 0.75s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -65.84, time = 0.75s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -66.40, time = 0.75s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -66.97, time = 0.74s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -67.52, time = 0.75s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1965 - val_loss: 0.0533
 - val_f1: 0.9636
Epoch 2/300
 - 0s - loss: 0.0443 - val_loss: 0.0294
 - val_f1: 0.9824
Epoch 3/300
 - 0s - loss: 0.0255 - val_loss: 0.0176
 - val_f1: 0.9863
Epoch 4/300
 - 0s - loss: 0.0194 - val_loss: 0.0144
 - val_f1: 0.9886
Epoch 5/300
 - 0s - loss: 0.0163 - val_loss: 0.0122
 - val_f1: 0.9899
Epoch 6/300
 - 0s - loss: 0.0148 - val_loss: 0.0116
 - val_f1: 0.9907
Epoch 7/300
 - 0s - loss: 0.0133 - val_loss: 0.0108
 - val_f1: 0.9911
Epoch 8/300
 - 0s - loss: 0.0125 - val_loss: 0.0105
 - val_f1: 0.9914
Epoch 9/300
 - 0s - loss: 0.0125 - val_loss: 0.0100
 - val_f1: 0.9910
Epoch 10/300
 - 0s - loss: 0.0113 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 11/300
 - 0s - loss: 0.0113 - val_loss: 0.0097
 - val_f1: 0.9911
Epoch 12/300
 - 0s - loss: 0.0102 - val_loss: 0.0091
 - val_f1: 0.9922
Epoch 13/300
 - 0s - loss: 0.0100 - val_loss: 0.0090
 - val_f1: 0.9936
Epoch 14/300
 - 0s - loss: 0.0100 - val_loss: 0.0086
 - val_f1: 0.9933
Epoch 15/300
 - 0s - loss: 0.0097 - val_loss: 0.0085
 - val_f1: 0.9924
Epoch 16/300
 - 0s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9941
Epoch 17/300
 - 0s - loss: 0.0089 - val_loss: 0.0080
 - val_f1: 0.9941
Epoch 18/300
 - 0s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9942
Epoch 19/300
 - 0s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9921
Epoch 20/300
 - 0s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9931
Epoch 21/300
 - 0s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9938
Epoch 22/300
 - 0s - loss: 0.0083 - val_loss: 0.0087
 - val_f1: 0.9930
Epoch 23/300
 - 0s - loss: 0.0084 - val_loss: 0.0076
 - val_f1: 0.9934
Epoch 24/300
 - 0s - loss: 0.0082 - val_loss: 0.0075
 - val_f1: 0.9939
Epoch 25/300
 - 0s - loss: 0.0078 - val_loss: 0.0075
 - val_f1: 0.9938
Epoch 26/300
 - 0s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9938
Epoch 27/300
 - 0s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9940
Epoch 28/300
 - 0s - loss: 0.0074 - val_loss: 0.0076
 - val_f1: 0.9943
Epoch 29/300
 - 0s - loss: 0.0075 - val_loss: 0.0081
 - val_f1: 0.9937
Epoch 30/300
 - 0s - loss: 0.0074 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 31/300
 - 0s - loss: 0.0075 - val_loss: 0.0072
2019-12-23 21:09:16,891 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9948
Epoch 32/300
 - 0s - loss: 0.0074 - val_loss: 0.0077
 - val_f1: 0.9930
Epoch 33/300
 - 0s - loss: 0.0070 - val_loss: 0.0078
 - val_f1: 0.9942
Epoch 34/300
 - 0s - loss: 0.0071 - val_loss: 0.0072
 - val_f1: 0.9945
Epoch 35/300
 - 0s - loss: 0.0074 - val_loss: 0.0081
 - val_f1: 0.9927
Epoch 36/300
 - 0s - loss: 0.0068 - val_loss: 0.0077
 - val_f1: 0.9931
Epoch 37/300
 - 0s - loss: 0.0067 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 38/300
 - 0s - loss: 0.0067 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 39/300
 - 0s - loss: 0.0067 - val_loss: 0.0076
 - val_f1: 0.9932
Epoch 40/300
 - 0s - loss: 0.0064 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 41/300
 - 0s - loss: 0.0065 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 42/300
 - 0s - loss: 0.0060 - val_loss: 0.0077
 - val_f1: 0.9938
Epoch 43/300
 - 0s - loss: 0.0062 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 44/300
 - 0s - loss: 0.0062 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 45/300
 - 0s - loss: 0.0065 - val_loss: 0.0081
 - val_f1: 0.9941
Epoch 46/300
 - 0s - loss: 0.0065 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 47/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 48/300
 - 0s - loss: 0.0060 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 49/300
 - 0s - loss: 0.0061 - val_loss: 0.0073
 - val_f1: 0.9944
Epoch 50/300
 - 0s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 51/300
 - 0s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 52/300
 - 0s - loss: 0.0057 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 53/300
 - 0s - loss: 0.0059 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 54/300
 - 0s - loss: 0.0056 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 55/300
 - 0s - loss: 0.0058 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 56/300
 - 0s - loss: 0.0060 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 57/300
 - 0s - loss: 0.0058 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 58/300
 - 0s - loss: 0.0056 - val_loss: 0.0074
 - val_f1: 0.9954
Epoch 59/300
 - 0s - loss: 0.0056 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 60/300
 - 0s - loss: 0.0056 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 61/300
 - 0s - loss: 0.0053 - val_loss: 0.0067
2019-12-23 21:09:36,872 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9955
Epoch 62/300
 - 0s - loss: 0.0053 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 63/300
 - 0s - loss: 0.0054 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 64/300
 - 0s - loss: 0.0053 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 65/300
 - 0s - loss: 0.0054 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 66/300
 - 0s - loss: 0.0052 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 67/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9952
Epoch 68/300
 - 0s - loss: 0.0055 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 69/300
 - 0s - loss: 0.0052 - val_loss: 0.0064
 - val_f1: 0.9963
Epoch 70/300
 - 0s - loss: 0.0051 - val_loss: 0.0063
 - val_f1: 0.9961
Epoch 71/300
 - 0s - loss: 0.0051 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 72/300
 - 0s - loss: 0.0051 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 73/300
 - 0s - loss: 0.0050 - val_loss: 0.0060
 - val_f1: 0.9963
Epoch 74/300
 - 0s - loss: 0.0048 - val_loss: 0.0061
 - val_f1: 0.9957
Epoch 75/300
 - 0s - loss: 0.0050 - val_loss: 0.0065
 - val_f1: 0.9959
Epoch 76/300
 - 0s - loss: 0.0047 - val_loss: 0.0063
 - val_f1: 0.9960
Epoch 77/300
 - 0s - loss: 0.0050 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 78/300
 - 0s - loss: 0.0051 - val_loss: 0.0066
 - val_f1: 0.9952
Epoch 79/300
 - 0s - loss: 0.0047 - val_loss: 0.0063
 - val_f1: 0.9960
Epoch 80/300
 - 0s - loss: 0.0050 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 81/300
 - 0s - loss: 0.0048 - val_loss: 0.0063
 - val_f1: 0.9959
Epoch 82/300
 - 0s - loss: 0.0047 - val_loss: 0.0065
 - val_f1: 0.9963
Epoch 83/300
 - 0s - loss: 0.0050 - val_loss: 0.0062
 - val_f1: 0.9961
Epoch 84/300
 - 0s - loss: 0.0048 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 85/300
 - 0s - loss: 0.0045 - val_loss: 0.0065
 - val_f1: 0.9962
Epoch 86/300
 - 0s - loss: 0.0048 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 87/300
 - 0s - loss: 0.0046 - val_loss: 0.0064
 - val_f1: 0.9960
Epoch 88/300
 - 0s - loss: 0.0043 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 89/300
 - 0s - loss: 0.0045 - val_loss: 0.0060
 - val_f1: 0.9961
Epoch 90/300
 - 0s - loss: 0.0050 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 91/300
 - 0s - loss: 0.0046 - val_loss: 0.0061
2019-12-23 21:09:56,935 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9964
Epoch 92/300
 - 0s - loss: 0.0047 - val_loss: 0.0062
 - val_f1: 0.9961
Epoch 93/300
 - 0s - loss: 0.0047 - val_loss: 0.0062
 - val_f1: 0.9962
Epoch 94/300
 - 0s - loss: 0.0046 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 95/300
 - 0s - loss: 0.0045 - val_loss: 0.0065
 - val_f1: 0.9958
Epoch 96/300
 - 0s - loss: 0.0046 - val_loss: 0.0065
 - val_f1: 0.9959
Epoch 97/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9950
Epoch 98/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 99/300
 - 0s - loss: 0.0048 - val_loss: 0.0064
 - val_f1: 0.9961
Epoch 100/300
 - 0s - loss: 0.0044 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 101/300
 - 0s - loss: 0.0048 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 102/300
 - 0s - loss: 0.0044 - val_loss: 0.0061
 - val_f1: 0.9960
Epoch 103/300
 - 0s - loss: 0.0043 - val_loss: 0.0065
 - val_f1: 0.9956
Epoch 104/300
 - 0s - loss: 0.0044 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 105/300
 - 0s - loss: 0.0046 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 106/300
 - 0s - loss: 0.0044 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 107/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 108/300
 - 0s - loss: 0.0045 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 109/300
 - 0s - loss: 0.0044 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 110/300
 - 0s - loss: 0.0043 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 111/300
 - 0s - loss: 0.0043 - val_loss: 0.0063
 - val_f1: 0.9961
Epoch 112/300
 - 0s - loss: 0.0041 - val_loss: 0.0062
 - val_f1: 0.9960
Epoch 113/300
 - 0s - loss: 0.0040 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 114/300
 - 0s - loss: 0.0043 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 115/300
 - 0s - loss: 0.0042 - val_loss: 0.0065
 - val_f1: 0.9958
Epoch 116/300
 - 0s - loss: 0.0043 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 117/300
 - 0s - loss: 0.0043 - val_loss: 0.0064
 - val_f1: 0.9960
Epoch 118/300
 - 0s - loss: 0.0044 - val_loss: 0.0072
 - val_f1: 0.9951
Epoch 119/300
 - 0s - loss: 0.0042 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 120/300
 - 0s - loss: 0.0043 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 121/300
 - 0s - loss: 0.0041 - val_loss: 0.0070
2019-12-23 21:10:16,975 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9949
Epoch 122/300
 - 0s - loss: 0.0040 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 123/300
 - 0s - loss: 0.0041 - val_loss: 0.0065
2019-12-23 21:10:18,566 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 21:10:19,464 [INFO] Last epoch loss evaluation: train_loss = 0.003576, val_loss = 0.005956
2019-12-23 21:10:19,469 [INFO] Training complete. time_to_train = 123.27 sec, 2.05 min
2019-12-23 21:10:19,472 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep2/best_model.pickle
2019-12-23 21:10:19,654 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/training_error_history.png
2019-12-23 21:10:19,823 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/training_f1_history.png
2019-12-23 21:10:19,823 [INFO] Making predictions on training, validation, testing data
2019-12-23 21:10:21,154 [INFO] Evaluating predictions (results)
2019-12-23 21:10:21,414 [INFO] Dataset: Testing. Classification report below
2019-12-23 21:10:21,414 [INFO] 
              precision    recall  f1-score   support

         dos       0.91      0.84      0.88      7458
      normal       0.67      0.93      0.78      9711
       probe       0.87      0.65      0.74      2421
         r2l       0.92      0.10      0.18      2421
         u2r       0.59      0.06      0.11       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.79      0.52      0.54     22544
weighted avg       0.80      0.76      0.73     22544

2019-12-23 21:10:21,414 [INFO] Overall accuracy (micro avg): 0.7622427253371186
2019-12-23 21:10:21,710 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7622         0.7622                       0.7622                0.0594                   0.2378  0.7622
1     Macro avg        0.9049         0.7931                       0.5172                0.0805                   0.4828  0.5383
2  Weighted avg        0.8596         0.7965                       0.7622                0.1649                   0.2378  0.7275
2019-12-23 21:10:22,042 [INFO] Dataset: Validation. Classification report below
2019-12-23 21:10:22,042 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.95      0.87      0.91       199
         u2r       0.60      0.30      0.40        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.91      0.83      0.86     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 21:10:22,042 [INFO] Overall accuracy (micro avg): 0.9962294105973407
2019-12-23 21:10:22,397 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0009                   0.0038  0.9962
1     Macro avg        0.9985         0.9065                       0.8322                0.0013                   0.1678  0.8591
2  Weighted avg        0.9977         0.9961                       0.9962                0.0028                   0.0038  0.9961
2019-12-23 21:10:23,838 [INFO] Dataset: Training. Classification report below
2019-12-23 21:10:23,838 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.97      0.89      0.93       796
         u2r       0.69      0.60      0.64        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.93      0.90      0.91    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 21:10:23,838 [INFO] Overall accuracy (micro avg): 0.9968941634086804
2019-12-23 21:10:25,459 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9969         0.9969                       0.9969                0.0008                   0.0031  0.9969
1     Macro avg        0.9988         0.9304                       0.8957                0.0011                   0.1043  0.9120
2  Weighted avg        0.9981         0.9969                       0.9969                0.0025                   0.0031  0.9969
2019-12-23 21:10:25,498 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep2/semi_sup_perf_nsl_dbn_rep2_results.xlsx
2019-12-23 21:10:25,498 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 21:10:25,502 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep3
2019-12-23 21:10:25,502 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_dbn_rep3/run_log.log
2019-12-23 21:10:25,502 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 21:10:25,502 [INFO] Experiment parameters given below
2019-12-23 21:10:25,502 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_dbn_rep3'}
2019-12-23 21:10:25,502 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/tf_logs_run_2019_12_23-21_10_25
2019-12-23 21:10:25,503 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 21:10:25,503 [INFO] Reading X, y files
2019-12-23 21:10:25,503 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 21:10:25,749 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-23 21:10:25,750 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 21:10:25,812 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 21:10:25,812 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 21:10:25,868 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 21:10:25,868 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 21:10:25,875 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 21:10:25,875 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 21:10:25,879 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:10:25,879 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 21:10:25,882 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 21:10:26,074 [INFO] Initializing model
2019-12-23 21:10:26,074 [INFO] Training model
2019-12-23 21:10:26,074 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 21:10:26,750 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = bafd1dbd539517ba822e6219b6ca0fe5dbecae6a
2019-12-23 21:10:26,750 [INFO] Pretraining Deep Belief Network
2019-12-23 21:11:05,149 [INFO] Pretraining Complete
2019-12-23 21:11:05,149 [INFO] Getting pretrained weights
2019-12-23 21:11:05,149 [INFO] Creating and initializing feed forward neural network
2019-12-23 21:11:05,254 [INFO] _________________________________________________________________
2019-12-23 21:11:05,254 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 21:11:05,254 [INFO] =================================================================
2019-12-23 21:11:05,254 [INFO] dense_5 (Dense)              (None, 64)                7872      
2019-12-23 21:11:05,254 [INFO] _________________________________________________________________
2019-12-23 21:11:05,254 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2019-12-23 21:11:05,254 [INFO] _________________________________________________________________
2019-12-23 21:11:05,254 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2019-12-23 21:11:05,254 [INFO] _________________________________________________________________
2019-12-23 21:11:05,254 [INFO] dense_6 (Dense)              (None, 5)                 325       
2019-12-23 21:11:05,255 [INFO] =================================================================
2019-12-23 21:11:05,255 [INFO] Total params: 8,453
2019-12-23 21:11:05,255 [INFO] Trainable params: 8,325
2019-12-23 21:11:05,255 [INFO] Non-trainable params: 128
2019-12-23 21:11:05,255 [INFO] _________________________________________________________________
2019-12-23 21:11:05,418 [INFO] Fine-tuning final neural network
 - val_f1: 0.9961
Epoch 00123: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -76.47, time = 0.48s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -71.03, time = 0.80s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -67.05, time = 0.79s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -64.06, time = 0.79s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -61.75, time = 0.78s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -59.95, time = 0.78s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -58.55, time = 0.78s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -57.45, time = 0.78s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -56.59, time = 0.78s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -55.94, time = 0.78s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -55.45, time = 0.78s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -55.10, time = 0.77s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -54.87, time = 0.77s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -54.73, time = 0.77s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -54.68, time = 0.77s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -54.71, time = 0.78s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -54.79, time = 0.77s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -54.93, time = 0.78s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -55.12, time = 0.77s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -55.35, time = 0.77s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -55.61, time = 0.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -55.90, time = 0.77s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -56.22, time = 0.77s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.56, time = 0.77s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -56.91, time = 0.77s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -57.29, time = 0.77s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -57.68, time = 0.77s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -58.08, time = 0.77s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -58.48, time = 0.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -58.89, time = 0.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -59.31, time = 0.77s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -59.73, time = 0.77s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -60.15, time = 0.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -60.58, time = 0.77s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -61.00, time = 0.76s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -61.42, time = 0.76s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -61.84, time = 0.76s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -62.26, time = 0.76s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -62.69, time = 0.75s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -63.11, time = 0.76s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -63.54, time = 0.75s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -63.98, time = 0.75s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -64.42, time = 0.75s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -64.88, time = 0.75s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -65.35, time = 0.75s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -65.83, time = 0.75s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -66.32, time = 0.74s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -66.83, time = 0.75s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -67.34, time = 0.74s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -67.85, time = 0.74s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1757 - val_loss: 0.0528
 - val_f1: 0.9627
Epoch 2/300
 - 0s - loss: 0.0435 - val_loss: 0.0270
 - val_f1: 0.9790
Epoch 3/300
 - 0s - loss: 0.0239 - val_loss: 0.0161
 - val_f1: 0.9895
Epoch 4/300
 - 0s - loss: 0.0189 - val_loss: 0.0136
 - val_f1: 0.9889
Epoch 5/300
 - 0s - loss: 0.0159 - val_loss: 0.0119
 - val_f1: 0.9912
Epoch 6/300
 - 0s - loss: 0.0146 - val_loss: 0.0113
 - val_f1: 0.9912
Epoch 7/300
 - 0s - loss: 0.0137 - val_loss: 0.0109
 - val_f1: 0.9922
Epoch 8/300
 - 0s - loss: 0.0131 - val_loss: 0.0102
 - val_f1: 0.9908
Epoch 9/300
 - 0s - loss: 0.0122 - val_loss: 0.0094
 - val_f1: 0.9929
Epoch 10/300
 - 0s - loss: 0.0118 - val_loss: 0.0096
 - val_f1: 0.9912
Epoch 11/300
 - 0s - loss: 0.0115 - val_loss: 0.0090
 - val_f1: 0.9931
Epoch 12/300
 - 0s - loss: 0.0111 - val_loss: 0.0092
 - val_f1: 0.9931
Epoch 13/300
 - 0s - loss: 0.0105 - val_loss: 0.0091
 - val_f1: 0.9926
Epoch 14/300
 - 0s - loss: 0.0105 - val_loss: 0.0086
 - val_f1: 0.9932
Epoch 15/300
 - 0s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9936
Epoch 16/300
 - 0s - loss: 0.0095 - val_loss: 0.0079
 - val_f1: 0.9941
Epoch 17/300
 - 0s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9926
Epoch 18/300
 - 0s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9939
Epoch 19/300
 - 0s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9937
Epoch 20/300
 - 0s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9938
Epoch 21/300
 - 0s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9938
Epoch 22/300
 - 0s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9944
Epoch 23/300
 - 0s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9945
Epoch 24/300
 - 0s - loss: 0.0084 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 25/300
 - 0s - loss: 0.0082 - val_loss: 0.0076
 - val_f1: 0.9936
Epoch 26/300
 - 0s - loss: 0.0079 - val_loss: 0.0075
 - val_f1: 0.9946
Epoch 27/300
 - 0s - loss: 0.0077 - val_loss: 0.0082
 - val_f1: 0.9939
Epoch 28/300
 - 0s - loss: 0.0078 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 29/300
 - 0s - loss: 0.0077 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 30/300
 - 0s - loss: 0.0075 - val_loss: 0.0074
 - val_f1: 0.9942
Epoch 31/300
 - 0s - loss: 0.0073 - val_loss: 0.0079
2019-12-23 21:11:27,730 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9944
Epoch 32/300
 - 0s - loss: 0.0073 - val_loss: 0.0074
 - val_f1: 0.9950
Epoch 33/300
 - 0s - loss: 0.0073 - val_loss: 0.0071
 - val_f1: 0.9945
Epoch 34/300
 - 0s - loss: 0.0071 - val_loss: 0.0082
 - val_f1: 0.9929
Epoch 35/300
 - 0s - loss: 0.0074 - val_loss: 0.0077
 - val_f1: 0.9945
Epoch 36/300
 - 0s - loss: 0.0074 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 37/300
 - 0s - loss: 0.0072 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 38/300
 - 0s - loss: 0.0072 - val_loss: 0.0074
 - val_f1: 0.9942
Epoch 39/300
 - 0s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 40/300
 - 0s - loss: 0.0070 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 41/300
 - 0s - loss: 0.0068 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 42/300
 - 0s - loss: 0.0069 - val_loss: 0.0073
 - val_f1: 0.9941
Epoch 43/300
 - 0s - loss: 0.0066 - val_loss: 0.0077
 - val_f1: 0.9949
Epoch 44/300
 - 0s - loss: 0.0065 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 45/300
 - 0s - loss: 0.0066 - val_loss: 0.0075
 - val_f1: 0.9943
Epoch 46/300
 - 0s - loss: 0.0065 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 47/300
 - 0s - loss: 0.0062 - val_loss: 0.0069
 - val_f1: 0.9948
Epoch 48/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9948
Epoch 49/300
 - 0s - loss: 0.0060 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 50/300
 - 0s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 51/300
 - 0s - loss: 0.0060 - val_loss: 0.0076
 - val_f1: 0.9952
Epoch 52/300
 - 0s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9950
Epoch 53/300
 - 0s - loss: 0.0062 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 54/300
 - 0s - loss: 0.0063 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 55/300
 - 0s - loss: 0.0064 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 56/300
 - 0s - loss: 0.0062 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 57/300
 - 0s - loss: 0.0058 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 58/300
 - 0s - loss: 0.0058 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 59/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9948
Epoch 60/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 61/300
 - 0s - loss: 0.0056 - val_loss: 0.0078
2019-12-23 21:11:48,403 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9950
Epoch 62/300
 - 0s - loss: 0.0060 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 63/300
 - 0s - loss: 0.0058 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 64/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 65/300
 - 0s - loss: 0.0054 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 66/300
 - 0s - loss: 0.0055 - val_loss: 0.0061
 - val_f1: 0.9953
Epoch 67/300
 - 0s - loss: 0.0054 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 68/300
 - 0s - loss: 0.0055 - val_loss: 0.0074
 - val_f1: 0.9949
Epoch 69/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 70/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 71/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 72/300
 - 0s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9959
Epoch 73/300
 - 0s - loss: 0.0051 - val_loss: 0.0065
 - val_f1: 0.9956
Epoch 74/300
 - 0s - loss: 0.0059 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 75/300
 - 0s - loss: 0.0058 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 76/300
 - 0s - loss: 0.0058 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 77/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 78/300
 - 0s - loss: 0.0052 - val_loss: 0.0065
 - val_f1: 0.9956
Epoch 79/300
 - 0s - loss: 0.0057 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 80/300
 - 0s - loss: 0.0054 - val_loss: 0.0075
 - val_f1: 0.9956
Epoch 81/300
 - 0s - loss: 0.0054 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 82/300
 - 0s - loss: 0.0052 - val_loss: 0.0067
 - val_f1: 0.9960
Epoch 83/300
 - 0s - loss: 0.0050 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 84/300
 - 0s - loss: 0.0056 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 85/300
 - 0s - loss: 0.0057 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 86/300
 - 0s - loss: 0.0055 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 87/300
 - 0s - loss: 0.0056 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 88/300
 - 0s - loss: 0.0052 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 89/300
 - 0s - loss: 0.0056 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 90/300
 - 0s - loss: 0.0055 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 91/300
 - 0s - loss: 0.0051 - val_loss: 0.0067
2019-12-23 21:12:09,073 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9954
Epoch 92/300
 - 0s - loss: 0.0053 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 93/300
 - 0s - loss: 0.0053 - val_loss: 0.0071
 - val_f1: 0.9949
Epoch 94/300
 - 0s - loss: 0.0057 - val_loss: 0.0074
 - val_f1: 0.9954
Epoch 95/300
 - 0s - loss: 0.0054 - val_loss: 0.0077
 - val_f1: 0.9948
Epoch 96/300
 - 0s - loss: 0.0056 - val_loss: 0.0075
 - val_f1: 0.9950
Epoch 97/300
 - 0s - loss: 0.0050 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 98/300
 - 0s - loss: 0.0053 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 99/300
 - 0s - loss: 0.0052 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 100/300
 - 0s - loss: 0.0051 - val_loss: 0.0078
 - val_f1: 0.9950
Epoch 101/300
 - 0s - loss: 0.0053 - val_loss: 0.0079
 - val_f1: 0.9950
Epoch 102/300
 - 0s - loss: 0.0056 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 103/300
 - 0s - loss: 0.0055 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 104/300
 - 0s - loss: 0.0053 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 105/300
 - 0s - loss: 0.0050 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 106/300
 - 0s - loss: 0.0053 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 107/300
 - 0s - loss: 0.0049 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 108/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9961
Epoch 109/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 110/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 111/300
 - 0s - loss: 0.0046 - val_loss: 0.0071
 - val_f1: 0.9959
Epoch 112/300
 - 0s - loss: 0.0044 - val_loss: 0.0072
 - val_f1: 0.9956
Epoch 113/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 114/300
 - 0s - loss: 0.0048 - val_loss: 0.0072
 - val_f1: 0.9960
Epoch 115/300
 - 0s - loss: 0.0046 - val_loss: 0.0064
 - val_f1: 0.9964
Epoch 116/300
 - 0s - loss: 0.0045 - val_loss: 0.0062
2019-12-23 21:12:26,595 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 21:12:27,534 [INFO] Last epoch loss evaluation: train_loss = 0.003704, val_loss = 0.006136
2019-12-23 21:12:27,539 [INFO] Training complete. time_to_train = 121.46 sec, 2.02 min
2019-12-23 21:12:27,543 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_dbn_rep3/best_model.pickle
2019-12-23 21:12:27,722 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/training_error_history.png
2019-12-23 21:12:27,891 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/training_f1_history.png
2019-12-23 21:12:27,891 [INFO] Making predictions on training, validation, testing data
2019-12-23 21:12:29,301 [INFO] Evaluating predictions (results)
2019-12-23 21:12:29,559 [INFO] Dataset: Testing. Classification report below
2019-12-23 21:12:29,559 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.89      7458
      normal       0.69      0.97      0.80      9711
       probe       0.85      0.76      0.80      2421
         r2l       0.94      0.10      0.18      2421
         u2r       0.50      0.03      0.06       533

   micro avg       0.79      0.79      0.79     22544
   macro avg       0.79      0.54      0.55     22544
weighted avg       0.82      0.79      0.75     22544

2019-12-23 21:12:29,559 [INFO] Overall accuracy (micro avg): 0.785929737402413
2019-12-23 21:12:29,853 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7859         0.7859                       0.7859                0.0535                   0.2141  0.7859
1     Macro avg        0.9144         0.7895                       0.5390                0.0727                   0.4610  0.5493
2  Weighted avg        0.8760         0.8206                       0.7859                0.1497                   0.2141  0.7498
2019-12-23 21:12:30,185 [INFO] Dataset: Validation. Classification report below
2019-12-23 21:12:30,185 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.92      0.86      0.89       199
         u2r       0.57      0.40      0.47        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.90      0.85      0.87     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 21:12:30,185 [INFO] Overall accuracy (micro avg): 0.9953165310577495
2019-12-23 21:12:30,540 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0012                   0.0047  0.9953
1     Macro avg        0.9981         0.8951                       0.8493                0.0015                   0.1507  0.8690
2  Weighted avg        0.9971         0.9952                       0.9953                0.0028                   0.0047  0.9953
2019-12-23 21:12:31,976 [INFO] Dataset: Training. Classification report below
2019-12-23 21:12:31,978 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.94      0.87      0.91       796
         u2r       0.79      0.55      0.65        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.94      0.88      0.91    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 21:12:31,978 [INFO] Overall accuracy (micro avg): 0.9960904165591696
2019-12-23 21:12:33,591 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9961         0.9961                       0.9961                0.0010                   0.0039  0.9961
1     Macro avg        0.9984         0.9443                       0.8811                0.0013                   0.1189  0.9079
2  Weighted avg        0.9976         0.9960                       0.9961                0.0027                   0.0039  0.9960
2019-12-23 21:12:33,629 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_dbn_rep3/semi_sup_perf_nsl_dbn_rep3_results.xlsx
2019-12-23 21:12:33,630 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 21:12:33,633 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep1
2019-12-23 21:12:33,633 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep1/run_log.log
2019-12-23 21:12:33,633 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 21:12:33,633 [INFO] Experiment parameters given below
2019-12-23 21:12:33,633 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep1'}
2019-12-23 21:12:33,633 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/tf_logs_run_2019_12_23-21_12_33
2019-12-23 21:12:33,633 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 21:12:33,634 [INFO] Reading X, y files
2019-12-23 21:12:33,634 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 21:12:37,656 [INFO] Reading complete. time_to_read=4.02 seconds
2019-12-23 21:12:37,656 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 21:12:39,037 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 21:12:39,038 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 21:12:40,419 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 21:12:40,419 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 21:12:40,623 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-23 21:12:40,623 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 21:12:40,689 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 21:12:40,690 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 21:12:40,756 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 21:12:43,916 [INFO] Initializing model
2019-12-23 21:12:43,917 [INFO] Training model
2019-12-23 21:12:43,917 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 21:12:59,675 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 7d9adfbbbdb00008549f135bbd1a412b4b9e077c
2019-12-23 21:12:59,675 [INFO] Pretraining Deep Belief Network
2019-12-23 21:21:28,069 [INFO] Pretraining Complete
2019-12-23 21:21:28,069 [INFO] Getting pretrained weights
2019-12-23 21:21:28,070 [INFO] Creating and initializing feed forward neural network
2019-12-23 21:21:28,175 [INFO] _________________________________________________________________
2019-12-23 21:21:28,175 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 21:21:28,175 [INFO] =================================================================
2019-12-23 21:21:28,175 [INFO] dense_7 (Dense)              (None, 64)                5056      
2019-12-23 21:21:28,175 [INFO] _________________________________________________________________
2019-12-23 21:21:28,175 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2019-12-23 21:21:28,175 [INFO] _________________________________________________________________
2019-12-23 21:21:28,175 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2019-12-23 21:21:28,176 [INFO] _________________________________________________________________
2019-12-23 21:21:28,176 [INFO] dense_8 (Dense)              (None, 12)                780       
2019-12-23 21:21:28,176 [INFO] =================================================================
2019-12-23 21:21:28,176 [INFO] Total params: 6,092
2019-12-23 21:21:28,176 [INFO] Trainable params: 5,964
2019-12-23 21:21:28,176 [INFO] Non-trainable params: 128
2019-12-23 21:21:28,176 [INFO] _________________________________________________________________
2019-12-23 21:21:28,424 [INFO] Fine-tuning final neural network
 - val_f1: 0.9962
Epoch 00116: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -27.90, time = 6.26s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -31.89, time = 11.35s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.73, time = 10.86s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -40.26, time = 10.78s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -42.83, time = 10.75s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -44.96, time = 10.70s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -46.97, time = 10.66s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -48.98, time = 10.63s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -51.03, time = 10.61s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -53.12, time = 10.60s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -55.24, time = 10.59s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -57.38, time = 10.57s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -59.54, time = 10.56s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -61.72, time = 10.54s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -63.92, time = 10.53s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -66.12, time = 10.53s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -68.33, time = 10.52s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -70.55, time = 10.51s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -72.78, time = 10.50s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -75.01, time = 10.50s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -77.25, time = 10.48s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -79.49, time = 10.42s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -81.73, time = 10.34s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -83.99, time = 10.22s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -86.25, time = 10.05s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -88.52, time = 9.99s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -90.79, time = 9.92s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -93.07, time = 9.86s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -95.35, time = 9.86s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -97.64, time = 9.82s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -99.92, time = 9.79s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -102.22, time = 9.78s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -104.52, time = 9.78s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -106.82, time = 9.76s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -109.13, time = 9.76s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -111.44, time = 9.74s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -113.75, time = 9.75s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -116.06, time = 9.75s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -118.37, time = 9.73s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -120.69, time = 9.75s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -123.01, time = 9.75s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -125.33, time = 9.74s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -127.66, time = 9.75s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -129.98, time = 9.75s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -132.30, time = 9.75s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -134.63, time = 9.74s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -136.95, time = 9.74s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -139.28, time = 9.72s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -141.61, time = 9.74s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -143.94, time = 9.73s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0802 - val_loss: 0.0552
 - val_f1: 0.8557
Epoch 2/300
 - 8s - loss: 0.0557 - val_loss: 0.0495
 - val_f1: 0.8586
Epoch 3/300
 - 8s - loss: 0.0442 - val_loss: 0.0321
 - val_f1: 0.9240
Epoch 4/300
 - 8s - loss: 0.0346 - val_loss: 0.0248
 - val_f1: 0.9479
Epoch 5/300
 - 9s - loss: 0.0280 - val_loss: 0.0194
 - val_f1: 0.9572
Epoch 6/300
 - 8s - loss: 0.0233 - val_loss: 0.0170
 - val_f1: 0.9619
Epoch 7/300
 - 8s - loss: 0.0207 - val_loss: 0.0156
 - val_f1: 0.9660
Epoch 8/300
 - 8s - loss: 0.0187 - val_loss: 0.0137
 - val_f1: 0.9687
Epoch 9/300
 - 8s - loss: 0.0171 - val_loss: 0.0128
 - val_f1: 0.9695
Epoch 10/300
 - 9s - loss: 0.0162 - val_loss: 0.0122
 - val_f1: 0.9705
Epoch 11/300
 - 8s - loss: 0.0153 - val_loss: 0.0115
 - val_f1: 0.9712
Epoch 12/300
 - 9s - loss: 0.0146 - val_loss: 0.0113
 - val_f1: 0.9715
Epoch 13/300
 - 9s - loss: 0.0139 - val_loss: 0.0109
 - val_f1: 0.9724
Epoch 14/300
 - 8s - loss: 0.0133 - val_loss: 0.0106
 - val_f1: 0.9716
Epoch 15/300
 - 8s - loss: 0.0129 - val_loss: 0.0099
 - val_f1: 0.9837
Epoch 16/300
 - 8s - loss: 0.0123 - val_loss: 0.0097
 - val_f1: 0.9831
Epoch 17/300
 - 9s - loss: 0.0117 - val_loss: 0.0088
 - val_f1: 0.9841
Epoch 18/300
 - 8s - loss: 0.0109 - val_loss: 0.0081
 - val_f1: 0.9844
Epoch 19/300
 - 9s - loss: 0.0100 - val_loss: 0.0089
 - val_f1: 0.9843
Epoch 20/300
 - 8s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9852
Epoch 21/300
 - 8s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9842
Epoch 22/300
 - 8s - loss: 0.0085 - val_loss: 0.0062
 - val_f1: 0.9867
Epoch 23/300
 - 8s - loss: 0.0083 - val_loss: 0.0069
 - val_f1: 0.9855
Epoch 24/300
 - 8s - loss: 0.0080 - val_loss: 0.0064
 - val_f1: 0.9859
Epoch 25/300
 - 8s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9841
Epoch 26/300
 - 8s - loss: 0.0077 - val_loss: 0.0057
 - val_f1: 0.9914
Epoch 27/300
 - 8s - loss: 0.0076 - val_loss: 0.0059
 - val_f1: 0.9879
Epoch 28/300
 - 8s - loss: 0.0074 - val_loss: 0.0073
 - val_f1: 0.9849
Epoch 29/300
 - 9s - loss: 0.0072 - val_loss: 0.0058
 - val_f1: 0.9889
Epoch 30/300
 - 9s - loss: 0.0070 - val_loss: 0.0056
 - val_f1: 0.9920
Epoch 31/300
 - 8s - loss: 0.0070 - val_loss: 0.0064
2019-12-23 21:28:50,703 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9865
Epoch 32/300
 - 9s - loss: 0.0068 - val_loss: 0.0063
 - val_f1: 0.9922
Epoch 33/300
 - 9s - loss: 0.0067 - val_loss: 0.0055
 - val_f1: 0.9901
Epoch 34/300
 - 8s - loss: 0.0066 - val_loss: 0.0055
 - val_f1: 0.9905
Epoch 35/300
 - 9s - loss: 0.0065 - val_loss: 0.0056
 - val_f1: 0.9874
Epoch 36/300
 - 8s - loss: 0.0064 - val_loss: 0.0053
 - val_f1: 0.9928
Epoch 37/300
 - 9s - loss: 0.0063 - val_loss: 0.0054
 - val_f1: 0.9896
Epoch 38/300
 - 8s - loss: 0.0061 - val_loss: 0.0051
 - val_f1: 0.9912
Epoch 39/300
 - 9s - loss: 0.0061 - val_loss: 0.0050
 - val_f1: 0.9933
Epoch 40/300
 - 9s - loss: 0.0059 - val_loss: 0.0053
 - val_f1: 0.9900
Epoch 41/300
 - 9s - loss: 0.0058 - val_loss: 0.0052
 - val_f1: 0.9889
Epoch 42/300
 - 9s - loss: 0.0057 - val_loss: 0.0057
 - val_f1: 0.9871
Epoch 43/300
 - 9s - loss: 0.0057 - val_loss: 0.0055
 - val_f1: 0.9885
Epoch 44/300
 - 9s - loss: 0.0056 - val_loss: 0.0053
 - val_f1: 0.9929
Epoch 45/300
 - 8s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9912
Epoch 46/300
 - 9s - loss: 0.0056 - val_loss: 0.0047
 - val_f1: 0.9910
Epoch 47/300
 - 9s - loss: 0.0055 - val_loss: 0.0056
 - val_f1: 0.9883
Epoch 48/300
 - 9s - loss: 0.0054 - val_loss: 0.0047
 - val_f1: 0.9911
Epoch 49/300
 - 9s - loss: 0.0053 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 50/300
 - 9s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9932
Epoch 51/300
 - 9s - loss: 0.0052 - val_loss: 0.0045
 - val_f1: 0.9932
Epoch 52/300
 - 9s - loss: 0.0051 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 53/300
 - 9s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9931
Epoch 54/300
 - 9s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9936
Epoch 55/300
 - 9s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9893
Epoch 56/300
 - 9s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9895
Epoch 57/300
 - 9s - loss: 0.0050 - val_loss: 0.0051
 - val_f1: 0.9897
Epoch 58/300
 - 9s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 59/300
 - 9s - loss: 0.0049 - val_loss: 0.0049
 - val_f1: 0.9904
Epoch 60/300
 - 8s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9929
Epoch 61/300
 - 9s - loss: 0.0048 - val_loss: 0.0042
2019-12-23 21:36:02,646 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9937
Epoch 62/300
 - 9s - loss: 0.0048 - val_loss: 0.0049
 - val_f1: 0.9901
Epoch 63/300
 - 8s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9940
Epoch 64/300
 - 9s - loss: 0.0048 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 65/300
 - 9s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9916
Epoch 66/300
 - 8s - loss: 0.0047 - val_loss: 0.0046
 - val_f1: 0.9905
Epoch 67/300
 - 9s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9933
Epoch 68/300
 - 8s - loss: 0.0046 - val_loss: 0.0043
 - val_f1: 0.9942
Epoch 69/300
 - 9s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 70/300
 - 8s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9940
Epoch 71/300
 - 8s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9931
Epoch 72/300
 - 8s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9942
Epoch 73/300
 - 8s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9936
Epoch 74/300
 - 8s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9940
Epoch 75/300
 - 9s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9944
Epoch 76/300
 - 8s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9921
Epoch 77/300
 - 8s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9938
Epoch 78/300
 - 8s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9941
Epoch 79/300
 - 8s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9945
Epoch 80/300
 - 8s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9944
Epoch 81/300
 - 8s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9944
Epoch 82/300
 - 8s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 83/300
 - 8s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9944
Epoch 84/300
 - 8s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9941
Epoch 85/300
 - 8s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9941
Epoch 86/300
 - 8s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9944
Epoch 87/300
 - 9s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9943
Epoch 88/300
 - 8s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9941
Epoch 89/300
 - 8s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9940
Epoch 90/300
 - 8s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 91/300
 - 9s - loss: 0.0042 - val_loss: 0.0037
2019-12-23 21:43:11,818 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9948
Epoch 92/300
 - 9s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9940
Epoch 93/300
 - 9s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 94/300
 - 8s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9946
Epoch 95/300
 - 9s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9946
Epoch 96/300
 - 9s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9941
Epoch 97/300
 - 9s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 98/300
 - 9s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9911
Epoch 99/300
 - 9s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9936
Epoch 100/300
 - 8s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9948
Epoch 101/300
 - 8s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9942
Epoch 102/300
 - 8s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9947
Epoch 103/300
 - 8s - loss: 0.0041 - val_loss: 0.0037
 - val_f1: 0.9943
Epoch 104/300
 - 8s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 105/300
 - 8s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 106/300
 - 8s - loss: 0.0040 - val_loss: 0.0043
 - val_f1: 0.9914
Epoch 107/300
 - 9s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9944
Epoch 108/300
 - 8s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9944
Epoch 109/300
 - 8s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9947
Epoch 110/300
 - 8s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9919
Epoch 111/300
 - 9s - loss: 0.0040 - val_loss: 0.0036
 - val_f1: 0.9942
Epoch 112/300
 - 9s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 113/300
 - 8s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 114/300
 - 9s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9948
Epoch 115/300
 - 8s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 116/300
 - 8s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9941
Epoch 117/300
 - 9s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9939
Epoch 118/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9944
Epoch 119/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9947
Epoch 120/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9944
Epoch 121/300
 - 8s - loss: 0.0039 - val_loss: 0.0037
2019-12-23 21:50:21,993 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9921
Epoch 122/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9946
Epoch 123/300
 - 8s - loss: 0.0039 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 124/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 125/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9945
Epoch 126/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 127/300
 - 8s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 128/300
 - 8s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 129/300
 - 9s - loss: 0.0039 - val_loss: 0.0043
 - val_f1: 0.9923
Epoch 130/300
 - 8s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9945
Epoch 131/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 132/300
 - 9s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9948
Epoch 133/300
 - 9s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9950
Epoch 134/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9944
Epoch 135/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9948
Epoch 136/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9946
Epoch 137/300
 - 8s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 138/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 139/300
 - 9s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9945
Epoch 140/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 141/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 142/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 143/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9946
Epoch 144/300
 - 9s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9948
Epoch 145/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9946
Epoch 146/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9948
Epoch 147/300
 - 9s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 148/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9949
Epoch 149/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 150/300
 - 8s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 151/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
2019-12-23 21:57:31,696 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9947
Epoch 152/300
 - 8s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 153/300
 - 8s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 154/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 155/300
 - 8s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9938
Epoch 156/300
 - 9s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 157/300
 - 8s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 158/300
 - 9s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9946
Epoch 159/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 160/300
 - 9s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 161/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 162/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 163/300
 - 9s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9948
Epoch 164/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 165/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 166/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 167/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 168/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 169/300
 - 9s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 170/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 171/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9951
Epoch 172/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9951
Epoch 173/300
 - 8s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 174/300
 - 8s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 175/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 176/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 177/300
 - 9s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 178/300
 - 9s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 179/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 180/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 181/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
2019-12-23 22:04:41,613 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9949
Epoch 182/300
 - 9s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9943
Epoch 183/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 184/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 185/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 186/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 187/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 188/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 189/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 190/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 191/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 192/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 193/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 194/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 195/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 196/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 197/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9953
Epoch 198/300
 - 8s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9912
Epoch 199/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 200/300
 - 8s - loss: 0.0035 - val_loss: 0.0044
 - val_f1: 0.9915
Epoch 201/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 202/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 203/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 204/300
 - 8s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 205/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 206/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 207/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 208/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 209/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 210/300
 - 9s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 211/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
2019-12-23 22:11:52,388 [INFO] epoch = 210. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9948
Epoch 212/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 213/300
 - 9s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 214/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 215/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 216/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 217/300
 - 8s - loss: 0.0034 - val_loss: 0.0036
 - val_f1: 0.9937
Epoch 218/300
 - 9s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 219/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 220/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 221/300
 - 8s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9948
Epoch 222/300
 - 9s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 223/300
 - 8s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 224/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9953
Epoch 225/300
 - 9s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 226/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 227/300
 - 9s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 228/300
 - 8s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 229/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 230/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 231/300
 - 9s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 232/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 233/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9954
Epoch 234/300
 - 8s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 235/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9952
Epoch 236/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 237/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 238/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 239/300
 - 8s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9951
Epoch 240/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 241/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
2019-12-23 22:19:02,027 [INFO] epoch = 240. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9947
Epoch 242/300
 - 8s - loss: 0.0033 - val_loss: 0.0036
 - val_f1: 0.9927
Epoch 243/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9953
Epoch 244/300
 - 8s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 245/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 246/300
 - 8s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 247/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 248/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 249/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 250/300
 - 9s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 251/300
 - 8s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 252/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 253/300
 - 9s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9953
Epoch 254/300
 - 8s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9924
Epoch 255/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 256/300
 - 8s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 257/300
 - 8s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 258/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 259/300
 - 8s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 260/300
 - 8s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 261/300
 - 9s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9936
Epoch 262/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 263/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 264/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9952
Epoch 265/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 266/300
 - 8s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9950
Epoch 267/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 268/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 269/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9955
Epoch 270/300
 - 8s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 271/300
 - 8s - loss: 0.0032 - val_loss: 0.0026
2019-12-23 22:26:12,044 [INFO] epoch = 270. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9957
Epoch 272/300
 - 9s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 273/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 274/300
 - 9s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9930
Epoch 275/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 276/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9950
Epoch 277/300
 - 8s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 278/300
 - 8s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 279/300
 - 8s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 280/300
 - 9s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9929
Epoch 281/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 282/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9953
Epoch 283/300
 - 8s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9927
Epoch 284/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 285/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9945
Epoch 286/300
 - 9s - loss: 0.0032 - val_loss: 0.0037
 - val_f1: 0.9927
Epoch 287/300
 - 8s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 288/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 289/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 290/300
 - 8s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 291/300
 - 9s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9950
Epoch 292/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 293/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 294/300
 - 9s - loss: 0.0031 - val_loss: 0.0032
 - val_f1: 0.9920
Epoch 295/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 296/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9952
Epoch 297/300
 - 9s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 298/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 299/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 300/300
 - 9s - loss: 0.0031 - val_loss: 0.0032
2019-12-23 22:33:14,851 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 22:33:32,089 [INFO] Last epoch loss evaluation: train_loss = 0.002532, val_loss = 0.002643
2019-12-23 22:33:32,122 [INFO] Training complete. time_to_train = 4848.20 sec, 80.80 min
2019-12-23 22:33:32,125 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep1/best_model.pickle
2019-12-23 22:33:32,307 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/training_error_history.png
2019-12-23 22:33:32,478 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/training_f1_history.png
2019-12-23 22:33:32,478 [INFO] Making predictions on training, validation, testing data
2019-12-23 22:33:59,948 [INFO] Evaluating predictions (results)
2019-12-23 22:34:10,078 [INFO] Dataset: Testing. Classification report below
2019-12-23 22:34:10,078 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.87      0.99      0.93      1100
         DoS slowloris       0.99      0.96      0.97      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.97      1179
Web Attack Brute Force       0.93      0.09      0.16       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-23 22:34:10,078 [INFO] Overall accuracy (micro avg): 0.9951782474777301
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 22:34:21,613 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.8902                       0.7785                0.0012                   0.2215  0.7939
2  Weighted avg        0.9960         0.9950                       0.9952                0.0094                   0.0048  0.9948
2019-12-23 22:34:31,919 [INFO] Dataset: Validation. Classification report below
2019-12-23 22:34:31,919 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.99      0.96      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.79      0.05      0.09       301
        Web Attack XSS       0.19      0.02      0.04       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.77      0.79    565562
          weighted avg       1.00      1.00      0.99    565562

2019-12-23 22:34:31,920 [INFO] Overall accuracy (micro avg): 0.9953550627517408
2019-12-23 22:34:43,611 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8963                       0.7742                0.0011                   0.2258  0.7897
2  Weighted avg        0.9961         0.9951                       0.9954                0.0091                   0.0046  0.9949
2019-12-23 22:35:17,674 [INFO] Dataset: Training. Classification report below
2019-12-23 22:35:17,674 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.89      0.99      0.94      3300
         DoS slowloris       0.99      0.97      0.98      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.86      0.07      0.13       904
        Web Attack XSS       0.27      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.91      0.78      0.80   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-23 22:35:17,675 [INFO] Overall accuracy (micro avg): 0.9954010293018617
2019-12-23 22:35:56,368 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.9094                       0.7793                0.0012                   0.2207  0.7970
2  Weighted avg        0.9962         0.9952                       0.9954                0.0093                   0.0046  0.9950
2019-12-23 22:35:56,419 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep1/semi_sup_perf_ids17_dbn_rep1_results.xlsx
2019-12-23 22:35:56,426 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 22:35:56,491 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep2
2019-12-23 22:35:56,492 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep2/run_log.log
2019-12-23 22:35:56,492 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 22:35:56,492 [INFO] Experiment parameters given below
2019-12-23 22:35:56,492 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep2'}
2019-12-23 22:35:56,492 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/tf_logs_run_2019_12_23-22_35_56
2019-12-23 22:35:56,492 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 22:35:56,492 [INFO] Reading X, y files
2019-12-23 22:35:56,492 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 22:36:00,501 [INFO] Reading complete. time_to_read=4.01 seconds
2019-12-23 22:36:00,501 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 22:36:01,881 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 22:36:01,881 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 22:36:03,257 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 22:36:03,257 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 22:36:03,467 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-23 22:36:03,467 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 22:36:03,533 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 22:36:03,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 22:36:03,599 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 22:36:06,786 [INFO] Initializing model
2019-12-23 22:36:06,786 [INFO] Training model
2019-12-23 22:36:06,787 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 22:36:22,636 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 3a0fd8d952e53975bcf801cae628681073e6ead1
2019-12-23 22:36:22,636 [INFO] Pretraining Deep Belief Network
2019-12-23 22:44:49,235 [INFO] Pretraining Complete
2019-12-23 22:44:49,236 [INFO] Getting pretrained weights
2019-12-23 22:44:49,236 [INFO] Creating and initializing feed forward neural network
2019-12-23 22:44:49,435 [INFO] _________________________________________________________________
2019-12-23 22:44:49,435 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 22:44:49,435 [INFO] =================================================================
2019-12-23 22:44:49,435 [INFO] dense_9 (Dense)              (None, 64)                5056      
2019-12-23 22:44:49,435 [INFO] _________________________________________________________________
2019-12-23 22:44:49,435 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2019-12-23 22:44:49,435 [INFO] _________________________________________________________________
2019-12-23 22:44:49,435 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2019-12-23 22:44:49,435 [INFO] _________________________________________________________________
2019-12-23 22:44:49,436 [INFO] dense_10 (Dense)             (None, 12)                780       
2019-12-23 22:44:49,436 [INFO] =================================================================
2019-12-23 22:44:49,436 [INFO] Total params: 6,092
2019-12-23 22:44:49,436 [INFO] Trainable params: 5,964
2019-12-23 22:44:49,436 [INFO] Non-trainable params: 128
2019-12-23 22:44:49,436 [INFO] _________________________________________________________________
2019-12-23 22:44:49,776 [INFO] Fine-tuning final neural network
 - val_f1: 0.9944
[BernoulliRBM] Iteration 1, pseudo-likelihood = -27.96, time = 6.22s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -31.96, time = 11.31s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.80, time = 10.83s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -40.32, time = 10.75s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -42.87, time = 10.72s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -44.96, time = 10.67s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -46.93, time = 10.64s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -48.89, time = 10.62s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -50.88, time = 10.60s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -52.92, time = 10.58s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.98, time = 10.56s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -57.08, time = 10.52s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -59.19, time = 10.51s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -61.31, time = 10.51s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -63.46, time = 10.50s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -65.61, time = 10.49s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -67.78, time = 10.48s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -69.95, time = 10.48s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -72.14, time = 10.47s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -74.32, time = 10.45s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -76.52, time = 10.46s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -78.72, time = 10.37s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -80.93, time = 10.31s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -83.14, time = 10.17s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -85.36, time = 10.02s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -87.59, time = 9.95s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -89.82, time = 9.88s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -92.06, time = 9.83s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -94.30, time = 9.80s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -96.55, time = 9.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -98.79, time = 9.77s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -101.06, time = 9.76s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -103.31, time = 9.73s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -105.58, time = 9.73s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -107.85, time = 9.73s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -110.13, time = 9.70s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -112.40, time = 9.70s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -114.67, time = 9.70s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -116.95, time = 9.70s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -119.23, time = 9.72s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -121.52, time = 9.71s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -123.81, time = 9.71s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -126.10, time = 9.72s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -128.38, time = 9.71s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -130.67, time = 9.70s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -132.97, time = 9.70s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -135.27, time = 9.69s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -137.56, time = 9.71s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -139.86, time = 9.71s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -142.15, time = 9.70s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0808 - val_loss: 0.0553
 - val_f1: 0.8557
Epoch 2/300
 - 8s - loss: 0.0551 - val_loss: 0.0482
 - val_f1: 0.8630
Epoch 3/300
 - 8s - loss: 0.0456 - val_loss: 0.0348
 - val_f1: 0.9211
Epoch 4/300
 - 8s - loss: 0.0347 - val_loss: 0.0284
 - val_f1: 0.9295
Epoch 5/300
 - 8s - loss: 0.0312 - val_loss: 0.0261
 - val_f1: 0.9355
Epoch 6/300
 - 8s - loss: 0.0287 - val_loss: 0.0197
 - val_f1: 0.9584
Epoch 7/300
 - 8s - loss: 0.0217 - val_loss: 0.0154
 - val_f1: 0.9640
Epoch 8/300
 - 8s - loss: 0.0189 - val_loss: 0.0143
 - val_f1: 0.9669
Epoch 9/300
 - 8s - loss: 0.0172 - val_loss: 0.0131
 - val_f1: 0.9690
Epoch 10/300
 - 8s - loss: 0.0161 - val_loss: 0.0125
 - val_f1: 0.9697
Epoch 11/300
 - 8s - loss: 0.0154 - val_loss: 0.0133
 - val_f1: 0.9679
Epoch 12/300
 - 8s - loss: 0.0149 - val_loss: 0.0122
 - val_f1: 0.9689
Epoch 13/300
 - 8s - loss: 0.0145 - val_loss: 0.0111
 - val_f1: 0.9718
Epoch 14/300
 - 8s - loss: 0.0140 - val_loss: 0.0110
 - val_f1: 0.9712
Epoch 15/300
 - 8s - loss: 0.0135 - val_loss: 0.0106
 - val_f1: 0.9751
Epoch 16/300
 - 8s - loss: 0.0131 - val_loss: 0.0102
 - val_f1: 0.9789
Epoch 17/300
 - 8s - loss: 0.0125 - val_loss: 0.0096
 - val_f1: 0.9822
Epoch 18/300
 - 8s - loss: 0.0119 - val_loss: 0.0089
 - val_f1: 0.9845
Epoch 19/300
 - 8s - loss: 0.0114 - val_loss: 0.0085
 - val_f1: 0.9844
Epoch 20/300
 - 8s - loss: 0.0108 - val_loss: 0.0081
 - val_f1: 0.9841
Epoch 21/300
 - 8s - loss: 0.0102 - val_loss: 0.0073
 - val_f1: 0.9848
Epoch 22/300
 - 8s - loss: 0.0098 - val_loss: 0.0067
 - val_f1: 0.9850
Epoch 23/300
 - 8s - loss: 0.0092 - val_loss: 0.0065
 - val_f1: 0.9853
Epoch 24/300
 - 8s - loss: 0.0090 - val_loss: 0.0064
 - val_f1: 0.9858
Epoch 25/300
 - 8s - loss: 0.0087 - val_loss: 0.0061
 - val_f1: 0.9864
Epoch 26/300
 - 8s - loss: 0.0084 - val_loss: 0.0060
 - val_f1: 0.9857
Epoch 27/300
 - 8s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9858
Epoch 28/300
 - 8s - loss: 0.0081 - val_loss: 0.0067
 - val_f1: 0.9835
Epoch 29/300
 - 8s - loss: 0.0079 - val_loss: 0.0062
 - val_f1: 0.9860
Epoch 30/300
 - 8s - loss: 0.0077 - val_loss: 0.0058
 - val_f1: 0.9863
Epoch 31/300
 - 8s - loss: 0.0076 - val_loss: 0.0058
2019-12-23 22:52:19,934 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9863
Epoch 32/300
 - 8s - loss: 0.0073 - val_loss: 0.0055
 - val_f1: 0.9870
Epoch 33/300
 - 8s - loss: 0.0072 - val_loss: 0.0054
 - val_f1: 0.9874
Epoch 34/300
 - 8s - loss: 0.0072 - val_loss: 0.0052
 - val_f1: 0.9899
Epoch 35/300
 - 8s - loss: 0.0070 - val_loss: 0.0052
 - val_f1: 0.9881
Epoch 36/300
 - 8s - loss: 0.0069 - val_loss: 0.0052
 - val_f1: 0.9901
Epoch 37/300
 - 8s - loss: 0.0067 - val_loss: 0.0050
 - val_f1: 0.9893
Epoch 38/300
 - 8s - loss: 0.0067 - val_loss: 0.0049
 - val_f1: 0.9888
Epoch 39/300
 - 8s - loss: 0.0066 - val_loss: 0.0047
 - val_f1: 0.9896
Epoch 40/300
 - 8s - loss: 0.0064 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 41/300
 - 8s - loss: 0.0063 - val_loss: 0.0059
 - val_f1: 0.9866
Epoch 42/300
 - 8s - loss: 0.0062 - val_loss: 0.0046
 - val_f1: 0.9904
Epoch 43/300
 - 8s - loss: 0.0061 - val_loss: 0.0045
 - val_f1: 0.9902
Epoch 44/300
 - 8s - loss: 0.0060 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 45/300
 - 8s - loss: 0.0058 - val_loss: 0.0046
 - val_f1: 0.9902
Epoch 46/300
 - 8s - loss: 0.0057 - val_loss: 0.0041
 - val_f1: 0.9911
Epoch 47/300
 - 8s - loss: 0.0056 - val_loss: 0.0042
 - val_f1: 0.9902
Epoch 48/300
 - 8s - loss: 0.0055 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 49/300
 - 8s - loss: 0.0055 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 50/300
 - 8s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9911
Epoch 51/300
 - 8s - loss: 0.0054 - val_loss: 0.0039
 - val_f1: 0.9925
Epoch 52/300
 - 8s - loss: 0.0054 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 53/300
 - 8s - loss: 0.0053 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 54/300
 - 8s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9890
Epoch 55/300
 - 8s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9923
Epoch 56/300
 - 8s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 57/300
 - 8s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 58/300
 - 8s - loss: 0.0051 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 59/300
 - 8s - loss: 0.0051 - val_loss: 0.0043
 - val_f1: 0.9915
Epoch 60/300
 - 8s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9906
Epoch 61/300
 - 8s - loss: 0.0050 - val_loss: 0.0038
2019-12-23 22:59:39,916 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9904
Epoch 62/300
 - 8s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 63/300
 - 8s - loss: 0.0050 - val_loss: 0.0040
 - val_f1: 0.9894
Epoch 64/300
 - 8s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9908
Epoch 65/300
 - 8s - loss: 0.0049 - val_loss: 0.0047
 - val_f1: 0.9920
Epoch 66/300
 - 8s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 67/300
 - 8s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9908
Epoch 68/300
 - 8s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9931
Epoch 69/300
 - 8s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9927
Epoch 70/300
 - 8s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 71/300
 - 8s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 72/300
 - 8s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 73/300
 - 8s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 74/300
 - 8s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 75/300
 - 8s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 76/300
 - 8s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9912
Epoch 77/300
 - 8s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 78/300
 - 8s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 79/300
 - 8s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 80/300
 - 8s - loss: 0.0046 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 81/300
 - 8s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 82/300
 - 8s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 83/300
 - 8s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 84/300
 - 8s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 85/300
 - 8s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 86/300
 - 8s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 87/300
 - 8s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 88/300
 - 8s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 89/300
 - 8s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 90/300
 - 8s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9916
Epoch 91/300
 - 8s - loss: 0.0045 - val_loss: 0.0035
2019-12-23 23:06:59,533 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9932
Epoch 92/300
 - 8s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 93/300
 - 8s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 94/300
 - 8s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 95/300
 - 8s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 96/300
 - 8s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 97/300
 - 8s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9934
Epoch 98/300
 - 8s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 99/300
 - 8s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 100/300
 - 8s - loss: 0.0044 - val_loss: 0.0054
 - val_f1: 0.9895
Epoch 101/300
 - 8s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 102/300
 - 8s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 103/300
 - 8s - loss: 0.0043 - val_loss: 0.0046
 - val_f1: 0.9909
Epoch 104/300
 - 8s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 105/300
 - 8s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 106/300
 - 8s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 107/300
 - 8s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9918
Epoch 108/300
 - 8s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 109/300
 - 8s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9912
Epoch 110/300
 - 8s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9947
Epoch 111/300
 - 8s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9914
Epoch 112/300
 - 8s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 113/300
 - 8s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 114/300
 - 8s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 115/300
 - 8s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 116/300
 - 8s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 117/300
 - 8s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9923
Epoch 118/300
 - 8s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 119/300
 - 8s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 120/300
 - 8s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9934
Epoch 121/300
 - 8s - loss: 0.0041 - val_loss: 0.0036
2019-12-23 23:14:19,860 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9928
Epoch 122/300
 - 8s - loss: 0.0041 - val_loss: 0.0039
 - val_f1: 0.9940
Epoch 123/300
 - 8s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 124/300
 - 8s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9949
Epoch 125/300
 - 8s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 126/300
 - 8s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 127/300
 - 8s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 128/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 129/300
 - 8s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9915
Epoch 130/300
 - 8s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9952
Epoch 131/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9941
Epoch 132/300
 - 8s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9943
Epoch 133/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 134/300
 - 8s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9946
Epoch 135/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 136/300
 - 8s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 137/300
 - 8s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 138/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 139/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 140/300
 - 8s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 141/300
 - 8s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 142/300
 - 8s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9948
Epoch 143/300
 - 8s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 144/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 145/300
 - 8s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 146/300
 - 8s - loss: 0.0039 - val_loss: 0.0044
 - val_f1: 0.9926
Epoch 147/300
 - 8s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 148/300
 - 8s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 149/300
 - 8s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 150/300
 - 8s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9928
Epoch 151/300
 - 8s - loss: 0.0039 - val_loss: 0.0032
2019-12-23 23:21:39,155 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9924
Epoch 152/300
 - 8s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 153/300
 - 8s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 154/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 155/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 156/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 157/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 158/300
 - 8s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 159/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 160/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9947
Epoch 161/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 162/300
 - 8s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9941
Epoch 163/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9949
Epoch 164/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 165/300
 - 8s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 166/300
 - 8s - loss: 0.0038 - val_loss: 0.0043
 - val_f1: 0.9896
Epoch 167/300
 - 8s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 168/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 169/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 170/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 171/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 172/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 173/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9946
Epoch 174/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 175/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 176/300
 - 8s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 177/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 178/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 179/300
 - 8s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 180/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 181/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
2019-12-23 23:28:57,837 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9936
Epoch 182/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 183/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 184/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 185/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 186/300
 - 8s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 187/300
 - 8s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 188/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 189/300
 - 8s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 190/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 191/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 192/300
 - 8s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 193/300
 - 8s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 194/300
 - 8s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 195/300
 - 8s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 196/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9949
Epoch 197/300
 - 8s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 198/300
 - 8s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 199/300
 - 8s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 200/300
 - 8s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 201/300
 - 8s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 202/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 203/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 204/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 205/300
 - 8s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 206/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 207/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 208/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 209/300
 - 8s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 210/300
 - 8s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 211/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
2019-12-23 23:36:17,281 [INFO] epoch = 210. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9936
Epoch 212/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 213/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9949
Epoch 214/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 215/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 216/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 217/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9950
Epoch 218/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9927
Epoch 219/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 220/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 221/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 222/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 223/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 224/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 225/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 226/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9949
Epoch 227/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 228/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9953
Epoch 229/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 230/300
 - 8s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 231/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 232/300
 - 8s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 233/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 234/300
 - 8s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9955
Epoch 235/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 236/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 237/300
 - 8s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 238/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9952
Epoch 239/300
 - 8s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 240/300
 - 8s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 241/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
2019-12-23 23:43:36,585 [INFO] epoch = 240. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9925
Epoch 242/300
 - 8s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 243/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9950
Epoch 244/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 245/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 246/300
 - 8s - loss: 0.0036 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 247/300
 - 8s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 248/300
 - 8s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9921
Epoch 249/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9954
Epoch 250/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 251/300
 - 8s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 252/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 253/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 254/300
 - 8s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 255/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 256/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 257/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 258/300
 - 8s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 259/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 260/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 261/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 262/300
 - 8s - loss: 0.0035 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 263/300
 - 8s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 264/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 265/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9955
Epoch 266/300
 - 8s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9926
Epoch 267/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 268/300
 - 8s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 269/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 270/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9950
Epoch 271/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
2019-12-23 23:50:57,404 [INFO] epoch = 270. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9950
Epoch 272/300
 - 8s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 273/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 274/300
 - 8s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9950
Epoch 275/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 276/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9954
Epoch 277/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 278/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9953
Epoch 279/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 280/300
 - 8s - loss: 0.0034 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 281/300
 - 8s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 282/300
 - 8s - loss: 0.0035 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 283/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9952
Epoch 284/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 285/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 286/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 287/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 288/300
 - 8s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 289/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 290/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 291/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9955
Epoch 292/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9948
Epoch 293/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 294/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 295/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 296/300
 - 8s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 297/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 298/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 299/300
 - 8s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 300/300
 - 8s - loss: 0.0034 - val_loss: 0.0035
2019-12-23 23:58:08,555 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 23:58:26,752 [INFO] Last epoch loss evaluation: train_loss = 0.002681, val_loss = 0.002810
2019-12-23 23:58:26,784 [INFO] Training complete. time_to_train = 4940.00 sec, 82.33 min
2019-12-23 23:58:26,788 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep2/best_model.pickle
2019-12-23 23:58:26,969 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/training_error_history.png
2019-12-23 23:58:27,140 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/training_f1_history.png
2019-12-23 23:58:27,140 [INFO] Making predictions on training, validation, testing data
2019-12-23 23:58:56,762 [INFO] Evaluating predictions (results)
2019-12-23 23:59:06,898 [INFO] Dataset: Testing. Classification report below
2019-12-23 23:59:06,898 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.95      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.85      0.99      0.92      1100
         DoS slowloris       0.99      0.91      0.95      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.67      0.87      0.76       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.86      0.84      0.84    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-23 23:59:06,898 [INFO] Overall accuracy (micro avg): 0.9950014322037195
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 23:59:18,429 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.8637                       0.8399                0.0008                   0.1601  0.8397
2  Weighted avg        0.9961         0.9949                       0.9950                0.0050                   0.0050  0.9948
2019-12-23 23:59:28,765 [INFO] Dataset: Validation. Classification report below
2019-12-23 23:59:28,765 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.34      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.98      2059
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.86      0.98      0.92      1099
         DoS slowloris       0.99      0.91      0.95      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1180
Web Attack Brute Force       0.67      0.86      0.75       301
        Web Attack XSS       0.38      0.02      0.04       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.90      0.84      0.84    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 23:59:28,768 [INFO] Overall accuracy (micro avg): 0.9949430831632959
2019-12-23 23:59:40,500 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9992         0.8965                       0.8366                0.0009                   0.1634  0.8395
2  Weighted avg        0.9960         0.9950                       0.9949                0.0053                   0.0051  0.9948
2019-12-24 00:00:14,623 [INFO] Dataset: Training. Classification report below
2019-12-24 00:00:14,623 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.97      1.00      0.98    138074
      DoS Slowhttptest       0.87      0.98      0.92      3300
         DoS slowloris       0.99      0.92      0.95      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.69      0.90      0.78       904
        Web Attack XSS       0.46      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.91      0.84      0.85   1696684
          weighted avg       1.00      1.00      0.99   1696684

2019-12-24 00:00:14,623 [INFO] Overall accuracy (micro avg): 0.995130501613736
2019-12-24 00:00:53,361 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0004                   0.0049  0.9951
1     Macro avg        0.9992         0.9083                       0.8445                0.0008                   0.1555  0.8477
2  Weighted avg        0.9961         0.9952                       0.9951                0.0051                   0.0049  0.9950
2019-12-24 00:00:53,413 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep2/semi_sup_perf_ids17_dbn_rep2_results.xlsx
2019-12-24 00:00:53,417 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-24 00:00:53,481 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep3
2019-12-24 00:00:53,482 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_dbn_rep3/run_log.log
2019-12-24 00:00:53,482 [INFO] ================= Running experiment no. 3  ================= 

2019-12-24 00:00:53,482 [INFO] Experiment parameters given below
2019-12-24 00:00:53,482 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_dbn_rep3'}
2019-12-24 00:00:53,482 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/tf_logs_run_2019_12_24-00_00_53
2019-12-24 00:00:53,482 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-24 00:00:53,482 [INFO] Reading X, y files
2019-12-24 00:00:53,482 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-24 00:00:57,494 [INFO] Reading complete. time_to_read=4.01 seconds
2019-12-24 00:00:57,494 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-24 00:00:58,874 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-24 00:00:58,874 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-24 00:01:00,252 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-24 00:01:00,252 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-24 00:01:00,442 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-24 00:01:00,442 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-24 00:01:00,509 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 00:01:00,510 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-24 00:01:00,577 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-24 00:01:03,773 [INFO] Initializing model
2019-12-24 00:01:03,773 [INFO] Training model
2019-12-24 00:01:03,775 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 00:01:19,759 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 034e8d42db8c49785b8377965f1a69328941adb0
2019-12-24 00:01:19,759 [INFO] Pretraining Deep Belief Network
2019-12-24 00:09:46,604 [INFO] Pretraining Complete
2019-12-24 00:09:46,604 [INFO] Getting pretrained weights
2019-12-24 00:09:46,604 [INFO] Creating and initializing feed forward neural network
2019-12-24 00:09:46,710 [INFO] _________________________________________________________________
2019-12-24 00:09:46,710 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 00:09:46,710 [INFO] =================================================================
2019-12-24 00:09:46,711 [INFO] dense_11 (Dense)             (None, 64)                5056      
2019-12-24 00:09:46,711 [INFO] _________________________________________________________________
2019-12-24 00:09:46,711 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2019-12-24 00:09:46,711 [INFO] _________________________________________________________________
2019-12-24 00:09:46,711 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2019-12-24 00:09:46,711 [INFO] _________________________________________________________________
2019-12-24 00:09:46,711 [INFO] dense_12 (Dense)             (None, 12)                780       
2019-12-24 00:09:46,711 [INFO] =================================================================
2019-12-24 00:09:46,711 [INFO] Total params: 6,092
2019-12-24 00:09:46,711 [INFO] Trainable params: 5,964
2019-12-24 00:09:46,711 [INFO] Non-trainable params: 128
2019-12-24 00:09:46,711 [INFO] _________________________________________________________________
2019-12-24 00:09:47,136 [INFO] Fine-tuning final neural network
 - val_f1: 0.9927
[BernoulliRBM] Iteration 1, pseudo-likelihood = -27.85, time = 6.24s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -31.67, time = 11.27s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -36.35, time = 10.82s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -39.72, time = 10.73s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -42.15, time = 10.69s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -44.16, time = 10.65s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -46.07, time = 10.61s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.98, time = 10.58s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -49.93, time = 10.57s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -51.93, time = 10.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -53.95, time = 10.54s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.01, time = 10.52s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -58.08, time = 10.51s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.16, time = 10.50s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -62.27, time = 10.49s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -64.38, time = 10.48s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -66.50, time = 10.47s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -68.63, time = 10.46s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -70.78, time = 10.44s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -72.92, time = 10.43s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -75.07, time = 10.43s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -77.23, time = 10.35s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -79.39, time = 10.28s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -81.56, time = 10.17s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -83.74, time = 10.00s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -85.93, time = 9.94s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -88.12, time = 9.86s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -90.31, time = 9.82s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -92.50, time = 9.79s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -94.70, time = 9.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -96.90, time = 9.75s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -99.12, time = 9.73s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -101.32, time = 9.71s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -103.54, time = 9.72s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -105.76, time = 9.71s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -107.98, time = 9.69s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -110.20, time = 9.70s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -112.43, time = 9.70s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -114.65, time = 9.70s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -116.88, time = 9.71s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -119.11, time = 9.71s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -121.34, time = 9.71s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -123.58, time = 9.71s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -125.81, time = 9.70s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -128.04, time = 9.70s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -130.28, time = 9.69s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -132.52, time = 9.70s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -134.76, time = 10.59s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -137.00, time = 9.70s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -139.24, time = 9.70s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0806 - val_loss: 0.0554
 - val_f1: 0.8548
Epoch 2/300
 - 9s - loss: 0.0556 - val_loss: 0.0489
 - val_f1: 0.8604
Epoch 3/300
 - 9s - loss: 0.0453 - val_loss: 0.0345
 - val_f1: 0.9181
Epoch 4/300
 - 9s - loss: 0.0346 - val_loss: 0.0252
 - val_f1: 0.9464
Epoch 5/300
 - 9s - loss: 0.0256 - val_loss: 0.0182
 - val_f1: 0.9589
Epoch 6/300
 - 9s - loss: 0.0218 - val_loss: 0.0166
 - val_f1: 0.9636
Epoch 7/300
 - 9s - loss: 0.0197 - val_loss: 0.0145
 - val_f1: 0.9672
Epoch 8/300
 - 9s - loss: 0.0179 - val_loss: 0.0133
 - val_f1: 0.9686
Epoch 9/300
 - 9s - loss: 0.0169 - val_loss: 0.0128
 - val_f1: 0.9696
Epoch 10/300
 - 9s - loss: 0.0161 - val_loss: 0.0120
 - val_f1: 0.9707
Epoch 11/300
 - 9s - loss: 0.0153 - val_loss: 0.0115
 - val_f1: 0.9717
Epoch 12/300
 - 9s - loss: 0.0144 - val_loss: 0.0113
 - val_f1: 0.9720
Epoch 13/300
 - 9s - loss: 0.0137 - val_loss: 0.0106
 - val_f1: 0.9727
Epoch 14/300
 - 9s - loss: 0.0131 - val_loss: 0.0106
 - val_f1: 0.9727
Epoch 15/300
 - 9s - loss: 0.0126 - val_loss: 0.0103
 - val_f1: 0.9732
Epoch 16/300
 - 9s - loss: 0.0120 - val_loss: 0.0102
 - val_f1: 0.9807
Epoch 17/300
 - 9s - loss: 0.0116 - val_loss: 0.0092
 - val_f1: 0.9806
Epoch 18/300
 - 9s - loss: 0.0110 - val_loss: 0.0096
 - val_f1: 0.9830
Epoch 19/300
 - 9s - loss: 0.0105 - val_loss: 0.0084
 - val_f1: 0.9849
Epoch 20/300
 - 9s - loss: 0.0100 - val_loss: 0.0076
 - val_f1: 0.9896
Epoch 21/300
 - 9s - loss: 0.0095 - val_loss: 0.0072
 - val_f1: 0.9855
Epoch 22/300
 - 9s - loss: 0.0090 - val_loss: 0.0067
 - val_f1: 0.9860
Epoch 23/300
 - 9s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9857
Epoch 24/300
 - 9s - loss: 0.0083 - val_loss: 0.0065
 - val_f1: 0.9860
Epoch 25/300
 - 9s - loss: 0.0081 - val_loss: 0.0067
 - val_f1: 0.9864
Epoch 26/300
 - 9s - loss: 0.0078 - val_loss: 0.0063
 - val_f1: 0.9858
Epoch 27/300
 - 9s - loss: 0.0075 - val_loss: 0.0063
 - val_f1: 0.9859
Epoch 28/300
 - 9s - loss: 0.0074 - val_loss: 0.0063
 - val_f1: 0.9862
Epoch 29/300
 - 9s - loss: 0.0072 - val_loss: 0.0060
 - val_f1: 0.9862
Epoch 30/300
 - 9s - loss: 0.0070 - val_loss: 0.0059
 - val_f1: 0.9866
Epoch 31/300
 - 9s - loss: 0.0069 - val_loss: 0.0056
2019-12-24 00:17:35,030 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9875
Epoch 32/300
 - 9s - loss: 0.0068 - val_loss: 0.0062
 - val_f1: 0.9867
Epoch 33/300
 - 9s - loss: 0.0066 - val_loss: 0.0066
 - val_f1: 0.9862
Epoch 34/300
 - 9s - loss: 0.0065 - val_loss: 0.0054
 - val_f1: 0.9891
Epoch 35/300
 - 9s - loss: 0.0064 - val_loss: 0.0053
 - val_f1: 0.9897
Epoch 36/300
 - 9s - loss: 0.0064 - val_loss: 0.0052
 - val_f1: 0.9907
Epoch 37/300
 - 9s - loss: 0.0063 - val_loss: 0.0052
 - val_f1: 0.9891
Epoch 38/300
 - 9s - loss: 0.0062 - val_loss: 0.0053
 - val_f1: 0.9921
Epoch 39/300
 - 9s - loss: 0.0061 - val_loss: 0.0051
 - val_f1: 0.9907
Epoch 40/300
 - 9s - loss: 0.0060 - val_loss: 0.0070
 - val_f1: 0.9850
Epoch 41/300
 - 9s - loss: 0.0059 - val_loss: 0.0049
 - val_f1: 0.9918
Epoch 42/300
 - 9s - loss: 0.0059 - val_loss: 0.0052
 - val_f1: 0.9902
Epoch 43/300
 - 9s - loss: 0.0058 - val_loss: 0.0050
 - val_f1: 0.9903
Epoch 44/300
 - 9s - loss: 0.0058 - val_loss: 0.0048
 - val_f1: 0.9911
Epoch 45/300
 - 9s - loss: 0.0057 - val_loss: 0.0047
 - val_f1: 0.9915
Epoch 46/300
 - 9s - loss: 0.0056 - val_loss: 0.0046
 - val_f1: 0.9931
Epoch 47/300
 - 9s - loss: 0.0056 - val_loss: 0.0048
 - val_f1: 0.9914
Epoch 48/300
 - 9s - loss: 0.0056 - val_loss: 0.0049
 - val_f1: 0.9903
Epoch 49/300
 - 9s - loss: 0.0056 - val_loss: 0.0051
 - val_f1: 0.9888
Epoch 50/300
 - 9s - loss: 0.0055 - val_loss: 0.0051
 - val_f1: 0.9912
Epoch 51/300
 - 9s - loss: 0.0055 - val_loss: 0.0054
 - val_f1: 0.9890
Epoch 52/300
 - 9s - loss: 0.0054 - val_loss: 0.0044
 - val_f1: 0.9936
Epoch 53/300
 - 9s - loss: 0.0054 - val_loss: 0.0046
 - val_f1: 0.9913
Epoch 54/300
 - 9s - loss: 0.0053 - val_loss: 0.0049
 - val_f1: 0.9905
Epoch 55/300
 - 9s - loss: 0.0053 - val_loss: 0.0047
 - val_f1: 0.9909
Epoch 56/300
 - 9s - loss: 0.0053 - val_loss: 0.0049
 - val_f1: 0.9905
Epoch 57/300
 - 9s - loss: 0.0052 - val_loss: 0.0049
 - val_f1: 0.9895
Epoch 58/300
 - 9s - loss: 0.0052 - val_loss: 0.0049
 - val_f1: 0.9932
Epoch 59/300
 - 9s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9940
Epoch 60/300
 - 9s - loss: 0.0051 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 61/300
 - 9s - loss: 0.0051 - val_loss: 0.0042
2019-12-24 00:25:10,573 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9917
Epoch 62/300
 - 9s - loss: 0.0050 - val_loss: 0.0048
 - val_f1: 0.9903
Epoch 63/300
 - 9s - loss: 0.0049 - val_loss: 0.0044
 - val_f1: 0.9916
Epoch 64/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9935
Epoch 65/300
 - 9s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9936
Epoch 66/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 67/300
 - 9s - loss: 0.0048 - val_loss: 0.0062
 - val_f1: 0.9909
Epoch 68/300
 - 9s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9919
Epoch 69/300
 - 9s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 70/300
 - 9s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9913
Epoch 71/300
 - 9s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9915
Epoch 72/300
 - 9s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 73/300
 - 9s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9915
Epoch 74/300
 - 9s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9926
Epoch 75/300
 - 9s - loss: 0.0046 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 76/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9939
Epoch 77/300
 - 9s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9939
Epoch 78/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 79/300
 - 9s - loss: 0.0045 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 80/300
 - 9s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9938
Epoch 81/300
 - 9s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9929
Epoch 82/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9940
Epoch 83/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9946
Epoch 84/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9942
Epoch 85/300
 - 9s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9922
Epoch 86/300
 - 9s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9944
Epoch 87/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9937
Epoch 88/300
 - 9s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9940
Epoch 89/300
 - 9s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 90/300
 - 9s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 91/300
 - 9s - loss: 0.0043 - val_loss: 0.0039
2019-12-24 00:32:44,715 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9921
Epoch 92/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 93/300
 - 9s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9944
Epoch 94/300
 - 9s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9941
Epoch 95/300
 - 9s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 96/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 97/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 98/300
 - 9s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 99/300
 - 9s - loss: 0.0041 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 100/300
 - 9s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 101/300
 - 9s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9948
Epoch 102/300
 - 9s - loss: 0.0041 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 103/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 104/300
 - 9s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 105/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 106/300
 - 9s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 107/300
 - 9s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 108/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 109/300
 - 9s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 110/300
 - 9s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 111/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 112/300
 - 9s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 113/300
 - 9s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 114/300
 - 9s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 115/300
 - 9s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 116/300
 - 9s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9946
Epoch 117/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9943
Epoch 118/300
 - 9s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 119/300
 - 9s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 120/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9942
Epoch 121/300
 - 9s - loss: 0.0039 - val_loss: 0.0042
2019-12-24 00:40:19,164 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9910
Epoch 122/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 123/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 124/300
 - 9s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 125/300
 - 9s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 126/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 127/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 128/300
 - 9s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 129/300
 - 9s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 130/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 131/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 132/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 133/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 134/300
 - 9s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9943
Epoch 135/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 136/300
 - 9s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9945
Epoch 137/300
 - 9s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 138/300
 - 9s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9948
Epoch 139/300
 - 9s - loss: 0.0037 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 140/300
 - 9s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9944
Epoch 141/300
 - 9s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 142/300
 - 9s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 143/300
 - 9s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9949
Epoch 144/300
 - 9s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 145/300
 - 9s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 146/300
 - 9s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 147/300
 - 9s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 148/300
 - 9s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 149/300
 - 9s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 150/300
 - 9s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9950
Epoch 151/300
 - 9s - loss: 0.0037 - val_loss: 0.0041
2019-12-24 00:47:53,921 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9931
Epoch 152/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9954
Epoch 153/300
 - 9s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 154/300
 - 9s - loss: 0.0037 - val_loss: 0.0034
 - val_f1: 0.9943
Epoch 155/300
 - 9s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 156/300
 - 9s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9947
Epoch 157/300
 - 9s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9944
Epoch 158/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 159/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 160/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9950
Epoch 161/300
 - 9s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 162/300
 - 9s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 163/300
 - 9s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 164/300
 - 9s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 165/300
 - 9s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 166/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 167/300
 - 9s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 168/300
 - 9s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9947
Epoch 169/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 170/300
 - 9s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 171/300
 - 9s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 172/300
 - 9s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 173/300
 - 9s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 174/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 175/300
 - 9s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 176/300
 - 9s - loss: 0.0036 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 177/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 178/300
 - 9s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 179/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 180/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 181/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
2019-12-24 00:55:29,659 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9948
Epoch 182/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 183/300
 - 9s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9950
Epoch 184/300
 - 9s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 185/300
 - 9s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 186/300
 - 9s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 187/300
 - 9s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 188/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 189/300
 - 9s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9954
Epoch 190/300
 - 9s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 191/300
 - 9s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 192/300
 - 9s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 193/300
 - 9s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 194/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 195/300
 - 9s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 196/300
 - 9s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 197/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 198/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 199/300
 - 9s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 200/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 201/300
 - 9s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9954
Epoch 202/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 203/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 204/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 205/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 206/300
 - 9s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 207/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 208/300
 - 9s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9956
Epoch 209/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 210/300
 - 9s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9950
Epoch 211/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
2019-12-24 01:03:05,362 [INFO] epoch = 210. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9937
Epoch 212/300
 - 9s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9953
Epoch 213/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9955
Epoch 214/300
 - 9s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 215/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 216/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 217/300
 - 9s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 218/300
 - 9s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 219/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 220/300
 - 9s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9955
Epoch 221/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 222/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 223/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 224/300
 - 9s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 225/300
 - 9s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 226/300
 - 9s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9929
Epoch 227/300
 - 9s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9952
Epoch 228/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 229/300
 - 9s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 230/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 231/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 232/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 233/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 234/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 235/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9953
Epoch 236/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9956
Epoch 237/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 238/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 239/300
 - 9s - loss: 0.0031 - val_loss: 0.0045
 - val_f1: 0.9914
Epoch 240/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9953
Epoch 241/300
 - 9s - loss: 0.0031 - val_loss: 0.0032
2019-12-24 01:10:40,753 [INFO] epoch = 240. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9925
Epoch 242/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9956
Epoch 243/300
 - 9s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 244/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 245/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 246/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 247/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 248/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 249/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 250/300
 - 9s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 251/300
 - 9s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 252/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 253/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 254/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 255/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9954
Epoch 256/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 257/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 258/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 259/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 260/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 261/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 262/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 263/300
 - 9s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9955
Epoch 264/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9955
Epoch 265/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 266/300
 - 9s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 267/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 268/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 269/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 270/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 271/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
2019-12-24 01:18:16,724 [INFO] epoch = 270. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9952
Epoch 272/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9950
Epoch 273/300
 - 9s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9933
Epoch 274/300
 - 9s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 275/300
 - 9s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 276/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 277/300
 - 9s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 278/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 279/300
 - 9s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 280/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9955
Epoch 281/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 282/300
 - 9s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 283/300
 - 9s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 284/300
 - 9s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 285/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 286/300
 - 9s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9960
Epoch 287/300
 - 9s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9954
Epoch 288/300
 - 9s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 289/300
 - 9s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 290/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9959
Epoch 291/300
 - 9s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 292/300
 - 9s - loss: 0.0030 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 293/300
 - 9s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 294/300
 - 9s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9954
Epoch 295/300
 - 9s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9954
Epoch 296/300
 - 9s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 297/300
 - 9s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 298/300
 - 9s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9957
Epoch 299/300
 - 9s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9957
Epoch 300/300
 - 9s - loss: 0.0030 - val_loss: 0.0025
2019-12-24 01:25:44,114 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 01:26:03,062 [INFO] Last epoch loss evaluation: train_loss = 0.002306, val_loss = 0.002449
2019-12-24 01:26:03,098 [INFO] Training complete. time_to_train = 5099.32 sec, 84.99 min
2019-12-24 01:26:03,101 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_dbn_rep3/best_model.pickle
2019-12-24 01:26:03,283 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/training_error_history.png
2019-12-24 01:26:03,454 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/training_f1_history.png
2019-12-24 01:26:03,454 [INFO] Making predictions on training, validation, testing data
2019-12-24 01:26:34,542 [INFO] Evaluating predictions (results)
2019-12-24 01:26:44,713 [INFO] Dataset: Testing. Classification report below
2019-12-24 01:26:44,713 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2058
              DoS Hulk       0.97      1.00      0.99     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.64      0.76      0.69       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.86      0.84      0.84    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 01:26:44,713 [INFO] Overall accuracy (micro avg): 0.9956149812045364
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-24 01:26:56,287 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.8649                       0.8370                0.0007                   0.1630  0.8390
2  Weighted avg        0.9965         0.9955                       0.9956                0.0043                   0.0044  0.9954
2019-12-24 01:27:06,614 [INFO] Dataset: Validation. Classification report below
2019-12-24 01:27:06,614 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.34      0.50       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.98      2059
              DoS Hulk       0.97      1.00      0.99     46025
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.99      0.97      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1180
Web Attack Brute Force       0.63      0.77      0.70       301
        Web Attack XSS       0.33      0.02      0.03       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.89      0.83      0.84    565562
          weighted avg       1.00      1.00      1.00    565562

2019-12-24 01:27:06,614 [INFO] Overall accuracy (micro avg): 0.9956945480778412
2019-12-24 01:27:18,330 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8943                       0.8347                0.0007                   0.1653  0.8384
2  Weighted avg        0.9966         0.9957                       0.9957                0.0041                   0.0043  0.9955
2019-12-24 01:27:52,548 [INFO] Dataset: Training. Classification report below
2019-12-24 01:27:52,548 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.97      1.00      0.99    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.99      0.98      0.98      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.66      0.80      0.73       904
        Web Attack XSS       0.71      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.93      0.84      0.85   1696684
          weighted avg       1.00      1.00      1.00   1696684

2019-12-24 01:27:52,548 [INFO] Overall accuracy (micro avg): 0.9957599647312051
2019-12-24 01:28:31,401 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.9292                       0.8417                0.0007                   0.1583  0.8468
2  Weighted avg        0.9966         0.9958                       0.9958                0.0042                   0.0042  0.9956
2019-12-24 01:28:31,451 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_dbn_rep3/semi_sup_perf_ids17_dbn_rep3_results.xlsx
2019-12-24 01:28:31,455 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-24 01:28:31,524 [INFO] ================= Finished running 6 experiments ================= 

 - val_f1: 0.9954
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2020-01-11 12:30:38,689 [INFO] Read 3 experiments from file: experiment_specs/additional_exps/semi_sup_perf_dbn.csv
2020-01-11 12:30:38,689 [INFO] ================= Started running experiments ================= 

2020-01-11 12:30:38,689 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1
2020-01-11 12:30:38,689 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/run_log.log
2020-01-11 12:30:38,689 [INFO] ================= Running experiment no. 1  ================= 

2020-01-11 12:30:38,689 [INFO] Experiment parameters given below
2020-01-11 12:30:38,689 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep1'}
2020-01-11 12:30:38,690 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/tf_logs_run_2020_01_11-12_30_38
2020-01-11 12:30:38,690 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 12:30:38,690 [INFO] Reading X, y files
2020-01-11 12:30:38,691 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 12:30:38,699 [INFO] NumExpr defaulting to 8 threads.
2020-01-11 12:30:42,735 [INFO] Reading complete. time_to_read=4.04 seconds
2020-01-11 12:30:42,735 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 12:30:44,107 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-11 12:30:44,107 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 12:30:45,480 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-11 12:30:45,480 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 12:30:45,821 [INFO] Reading complete. time_to_read=0.34 seconds
2020-01-11 12:30:45,821 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 12:30:45,923 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-11 12:30:45,924 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 12:30:46,024 [INFO] Reading complete. time_to_read=0.10 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25632 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25643 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25644 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25645 thread 3 bound to OS proc set 3
2020-01-11 12:30:49,413 [INFO] Initializing model
2020-01-11 12:30:49,413 [INFO] Training model
2020-01-11 12:30:49,413 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-11 12:31:18,795 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 854f718c13dae3902ca67179789ea47e7cb03aef
2020-01-11 12:31:18,795 [INFO] Pretraining Deep Belief Network
2020-01-11 12:42:26,066 [INFO] Pretraining Complete
2020-01-11 12:42:26,066 [INFO] Getting pretrained weights
2020-01-11 12:42:26,067 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-11 12:42:26,084 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-11 12:42:26,157 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-11 12:42:26,200 [INFO] _________________________________________________________________
2020-01-11 12:42:26,200 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 12:42:26,201 [INFO] =================================================================
2020-01-11 12:42:26,201 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-11 12:42:26,201 [INFO] _________________________________________________________________
2020-01-11 12:42:26,201 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-11 12:42:26,201 [INFO] _________________________________________________________________
2020-01-11 12:42:26,201 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-11 12:42:26,201 [INFO] _________________________________________________________________
2020-01-11 12:42:26,201 [INFO] dense_2 (Dense)              (None, 15)                975       
2020-01-11 12:42:26,201 [INFO] =================================================================
2020-01-11 12:42:26,201 [INFO] Total params: 6,223
2020-01-11 12:42:26,201 [INFO] Trainable params: 6,095
2020-01-11 12:42:26,202 [INFO] Non-trainable params: 128
2020-01-11 12:42:26,202 [INFO] _________________________________________________________________
2020-01-11 12:42:26.202209: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-01-11 12:42:26.223563: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2020-01-11 12:42:26.223700: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559f35d91520 executing computations on platform Host. Devices:
2020-01-11 12:42:26.223722: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-11 12:42:26.223815: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2020-01-11 12:42:26,308 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-11 12:42:26,715 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25815 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25855 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25853 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25854 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25856 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25816 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25857 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25860 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25858 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25859 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25862 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25861 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25863 thread 16 bound to OS proc set 0
[BernoulliRBM] Iteration 1, pseudo-likelihood = -34.16, time = 8.47s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -40.53, time = 14.15s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -46.20, time = 13.96s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -50.81, time = 13.93s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -54.85, time = 13.92s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -58.73, time = 13.90s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -62.61, time = 13.89s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.52, time = 13.87s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -70.48, time = 13.84s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.42, time = 13.79s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -78.37, time = 13.75s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -82.28, time = 13.73s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -86.16, time = 13.71s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -90.02, time = 13.68s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -93.87, time = 13.65s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -97.74, time = 13.53s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -101.60, time = 13.49s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -105.47, time = 13.45s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -109.35, time = 13.36s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -113.23, time = 13.31s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -117.12, time = 13.28s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -121.02, time = 13.24s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -124.92, time = 13.21s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -128.82, time = 13.19s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -132.73, time = 13.19s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -136.63, time = 13.15s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -140.52, time = 13.14s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -144.43, time = 13.13s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -148.33, time = 13.11s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -152.22, time = 13.10s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -156.12, time = 13.10s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -160.01, time = 13.09s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -163.91, time = 13.10s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -167.81, time = 13.08s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -171.72, time = 13.08s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -175.62, time = 13.07s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -179.54, time = 13.07s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -183.46, time = 13.08s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -187.37, time = 13.07s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -191.29, time = 13.06s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -195.23, time = 13.06s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -199.16, time = 13.05s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -203.09, time = 13.06s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -207.03, time = 13.07s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -210.98, time = 13.09s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -214.92, time = 13.10s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -218.87, time = 13.07s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -222.82, time = 13.07s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -226.78, time = 13.08s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -230.75, time = 13.08s
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 13s - loss: 0.0689 - val_loss: 0.0474
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25876 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25877 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 25632 tid 25878 thread 19 bound to OS proc set 3
 - val_f1: 0.8706
Epoch 2/200
 - 12s - loss: 0.0478 - val_loss: 0.0417
 - val_f1: 0.8906
Epoch 3/200
 - 12s - loss: 0.0417 - val_loss: 0.0373
 - val_f1: 0.8992
Epoch 4/200
 - 12s - loss: 0.0367 - val_loss: 0.0316
 - val_f1: 0.9036
Epoch 5/200
 - 12s - loss: 0.0245 - val_loss: 0.0165
 - val_f1: 0.9510
Epoch 6/200
 - 12s - loss: 0.0192 - val_loss: 0.0124
 - val_f1: 0.9680
Epoch 7/200
 - 12s - loss: 0.0157 - val_loss: 0.0106
 - val_f1: 0.9729
Epoch 8/200
 - 12s - loss: 0.0134 - val_loss: 0.0098
 - val_f1: 0.9734
Epoch 9/200
 - 12s - loss: 0.0121 - val_loss: 0.0095
 - val_f1: 0.9719
Epoch 10/200
 - 12s - loss: 0.0115 - val_loss: 0.0093
 - val_f1: 0.9739
Epoch 11/200
 - 12s - loss: 0.0111 - val_loss: 0.0092
 - val_f1: 0.9756
Epoch 12/200
 - 12s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9761
Epoch 13/200
 - 12s - loss: 0.0105 - val_loss: 0.0090
 - val_f1: 0.9763
Epoch 14/200
 - 12s - loss: 0.0102 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 15/200
 - 12s - loss: 0.0101 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 16/200
 - 12s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9765
Epoch 17/200
 - 12s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9765
Epoch 18/200
 - 12s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 19/200
 - 12s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9766
Epoch 20/200
 - 12s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9765
Epoch 21/200
 - 12s - loss: 0.0094 - val_loss: 0.0086
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 12:50:13,150 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9767
Epoch 22/200
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9766
Epoch 23/200
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 24/200
 - 12s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 25/200
 - 12s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9767
Epoch 26/200
 - 12s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 27/200
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 28/200
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 29/200
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 30/200
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9782
Epoch 31/200
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 32/200
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9777
Epoch 33/200
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 34/200
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 35/200
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 36/200
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9754
Epoch 37/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 38/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 39/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 40/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 41/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
2020-01-11 12:57:47,531 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9779
Epoch 42/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 43/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 44/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 45/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 46/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 47/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 48/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 49/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 50/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 51/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 52/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 53/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 54/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 55/200
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 56/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 57/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 58/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 59/200
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 60/200
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 61/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
2020-01-11 13:05:22,663 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9783
Epoch 62/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 63/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 64/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 65/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 66/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 67/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 68/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 69/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 70/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 71/200
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 72/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 73/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 74/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 75/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 76/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 77/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 78/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 79/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 80/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 81/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
2020-01-11 13:12:57,040 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9786
Epoch 82/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 83/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 84/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 85/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 86/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 87/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 88/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 89/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 90/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 91/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 92/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 93/200
 - 12s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 94/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 95/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9764
Epoch 96/200
 - 12s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 97/200
 - 12s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 98/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 99/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 100/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 101/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
2020-01-11 13:20:31,985 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9786
Epoch 102/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 103/200
 - 12s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 104/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 105/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 106/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 107/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 108/200
 - 12s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 109/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 110/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 111/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 112/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 113/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 114/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 115/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9787
Epoch 116/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 117/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 118/200
 - 12s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 119/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 120/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 121/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
2020-01-11 13:28:06,642 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9780
Epoch 122/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 123/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 124/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 125/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 126/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 127/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 128/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 129/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 130/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 131/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 132/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 133/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 134/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 135/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 136/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 137/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 138/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 139/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 140/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 141/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 13:35:41,604 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 143/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 144/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 145/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 146/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9758
Epoch 147/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 148/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 149/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 150/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 151/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 152/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 153/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 154/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 155/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 156/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 157/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 158/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 159/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 160/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 161/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 13:43:15,817 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9787
Epoch 162/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 163/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 164/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 165/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 166/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 167/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 168/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 169/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 170/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 171/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9788
Epoch 172/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 173/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 174/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9788
Epoch 175/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 176/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 177/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 178/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 179/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 180/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 181/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 13:50:47,993 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9786
Epoch 182/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 183/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 184/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 185/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 186/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 187/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 188/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 189/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 190/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 191/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 192/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 193/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 194/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 195/200
 - 12s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 196/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 197/200
 - 12s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 198/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 199/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 200/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
2020-01-11 13:58:07,017 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 13:58:33,899 [INFO] Last epoch loss evaluation: train_loss = 0.007843, val_loss = 0.007893
2020-01-11 13:58:33,904 [INFO] Training complete. time_to_train = 5264.49 sec, 87.74 min
2020-01-11 13:58:33,908 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/best_model.pickle
2020-01-11 13:58:33,911 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_error_history.csv
2020-01-11 13:58:34,107 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_error_history.png
2020-01-11 13:58:34,282 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/training_f1_history.png
2020-01-11 13:58:34,282 [INFO] Making predictions on training, validation, testing data
2020-01-11 13:59:19,209 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 13:59:42,357 [INFO] Dataset: Testing. Classification report below
2020-01-11 13:59:42,357 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.54      0.62      5596
   DoS attacks-Slowloris       1.00      0.74      0.85       440
          FTP-BruteForce       0.72      0.85      0.78      7718
           Infilteration       0.51      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.71      0.68      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 13:59:42,357 [INFO] Overall accuracy (micro avg): 0.9834590263490568
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-11 14:00:07,147 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7074                       0.6751                0.0045                   0.3249  0.6705
2  Weighted avg        0.9909         0.9788                       0.9835                0.0503                   0.0165  0.9784
2020-01-11 14:00:30,123 [INFO] Dataset: Validation. Classification report below
2020-01-11 14:00:30,123 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.54      0.62      5596
   DoS attacks-Slowloris       0.99      0.80      0.89       439
          FTP-BruteForce       0.72      0.86      0.78      7718
           Infilteration       0.43      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.71      0.68      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 14:00:30,123 [INFO] Overall accuracy (micro avg): 0.9835581506676354
2020-01-11 14:00:54,866 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.7067                       0.6781                0.0044                   0.3219  0.6757
2  Weighted avg        0.9909         0.9781                       0.9836                0.0501                   0.0164  0.9785
2020-01-11 14:02:09,658 [INFO] Dataset: Training. Classification report below
2020-01-11 14:02:09,658 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.99      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.72      0.54      0.61     16787
   DoS attacks-Slowloris       1.00      0.78      0.88      1318
          FTP-BruteForce       0.72      0.85      0.78     23153
           Infilteration       0.53      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.71      0.68      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 14:02:09,658 [INFO] Overall accuracy (micro avg): 0.9835018709378237
2020-01-11 14:03:30,414 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7115                       0.6769                0.0044                   0.3231  0.6735
2  Weighted avg        0.9909         0.9790                       0.9835                0.0502                   0.0165  0.9785
2020-01-11 14:03:30,489 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep1/semi_sup_perf_ids18_subset_dbn_rep1_results.xlsx
2020-01-11 14:03:30,494 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-11 14:03:30,550 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2
2020-01-11 14:03:30,550 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/run_log.log
2020-01-11 14:03:30,550 [INFO] ================= Running experiment no. 2  ================= 

2020-01-11 14:03:30,550 [INFO] Experiment parameters given below
2020-01-11 14:03:30,550 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep2'}
2020-01-11 14:03:30,551 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/tf_logs_run_2020_01_11-14_03_30
2020-01-11 14:03:30,551 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 14:03:30,551 [INFO] Reading X, y files
2020-01-11 14:03:30,551 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 14:03:34,547 [INFO] Reading complete. time_to_read=4.00 seconds
2020-01-11 14:03:34,547 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 14:03:35,920 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-11 14:03:35,920 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 14:03:37,296 [INFO] Reading complete. time_to_read=1.38 seconds
2020-01-11 14:03:37,296 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 14:03:37,602 [INFO] Reading complete. time_to_read=0.31 seconds
2020-01-11 14:03:37,602 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 14:03:37,702 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-11 14:03:37,702 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 14:03:37,799 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-11 14:03:41,183 [INFO] Initializing model
2020-01-11 14:03:41,183 [INFO] Training model
2020-01-11 14:03:41,185 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-11 14:04:11,246 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = f266e75effb0cf54ce7e5656d9ba3e2ac9988837
2020-01-11 14:04:11,246 [INFO] Pretraining Deep Belief Network
2020-01-11 14:15:51,639 [INFO] Pretraining Complete
2020-01-11 14:15:51,639 [INFO] Getting pretrained weights
2020-01-11 14:15:51,639 [INFO] Creating and initializing feed forward neural network
2020-01-11 14:15:51,759 [INFO] _________________________________________________________________
2020-01-11 14:15:51,759 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 14:15:51,759 [INFO] =================================================================
2020-01-11 14:15:51,759 [INFO] dense_3 (Dense)              (None, 64)                4992      
2020-01-11 14:15:51,760 [INFO] _________________________________________________________________
2020-01-11 14:15:51,760 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-11 14:15:51,760 [INFO] _________________________________________________________________
2020-01-11 14:15:51,760 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-11 14:15:51,760 [INFO] _________________________________________________________________
2020-01-11 14:15:51,760 [INFO] dense_4 (Dense)              (None, 15)                975       
2020-01-11 14:15:51,760 [INFO] =================================================================
2020-01-11 14:15:51,760 [INFO] Total params: 6,223
2020-01-11 14:15:51,760 [INFO] Trainable params: 6,095
2020-01-11 14:15:51,760 [INFO] Non-trainable params: 128
2020-01-11 14:15:51,760 [INFO] _________________________________________________________________
2020-01-11 14:15:51,889 [INFO] Fine-tuning final neural network
 - val_f1: 0.9785
[BernoulliRBM] Iteration 1, pseudo-likelihood = -34.08, time = 8.71s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -40.27, time = 14.80s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -45.74, time = 14.62s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -50.19, time = 14.56s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -54.10, time = 14.55s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -57.86, time = 14.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -61.63, time = 14.53s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -65.41, time = 14.51s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -69.24, time = 14.49s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -73.05, time = 14.43s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -76.85, time = 14.40s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -80.61, time = 14.38s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -84.34, time = 14.34s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -88.06, time = 14.34s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -91.75, time = 14.29s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -95.47, time = 14.17s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -99.19, time = 14.14s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -102.91, time = 14.10s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -106.64, time = 14.03s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -110.38, time = 13.97s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -114.11, time = 13.92s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -117.86, time = 13.88s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -121.61, time = 13.85s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -125.37, time = 13.84s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -129.13, time = 13.82s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -132.88, time = 13.81s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -136.62, time = 13.82s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -140.37, time = 13.81s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -144.11, time = 13.79s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -147.83, time = 13.78s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -151.55, time = 13.78s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -155.27, time = 13.78s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -159.00, time = 13.77s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -162.72, time = 13.76s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -166.45, time = 13.76s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -170.18, time = 13.76s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -173.92, time = 13.75s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -177.66, time = 13.75s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -181.40, time = 13.74s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -185.15, time = 13.73s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -188.91, time = 13.74s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -192.66, time = 13.73s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -196.43, time = 13.74s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -200.19, time = 13.73s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -203.96, time = 13.73s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -207.73, time = 13.73s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -211.51, time = 13.72s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -215.29, time = 13.73s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -219.07, time = 13.73s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -222.87, time = 13.72s
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 13s - loss: 0.0692 - val_loss: 0.0479
 - val_f1: 0.8708
Epoch 2/200
 - 12s - loss: 0.0473 - val_loss: 0.0416
 - val_f1: 0.8851
Epoch 3/200
 - 12s - loss: 0.0410 - val_loss: 0.0397
 - val_f1: 0.8965
Epoch 4/200
 - 12s - loss: 0.0355 - val_loss: 0.0251
 - val_f1: 0.9190
Epoch 5/200
 - 12s - loss: 0.0269 - val_loss: 0.0239
 - val_f1: 0.9053
Epoch 6/200
 - 12s - loss: 0.0214 - val_loss: 0.0146
 - val_f1: 0.9599
Epoch 7/200
 - 12s - loss: 0.0183 - val_loss: 0.0126
 - val_f1: 0.9712
Epoch 8/200
 - 12s - loss: 0.0169 - val_loss: 0.0156
 - val_f1: 0.9610
Epoch 9/200
 - 12s - loss: 0.0161 - val_loss: 0.0198
 - val_f1: 0.9294
Epoch 10/200
 - 12s - loss: 0.0154 - val_loss: 0.0105
 - val_f1: 0.9711
Epoch 11/200
 - 12s - loss: 0.0144 - val_loss: 0.0101
 - val_f1: 0.9713
Epoch 12/200
 - 12s - loss: 0.0139 - val_loss: 0.0136
 - val_f1: 0.9615
Epoch 13/200
 - 12s - loss: 0.0129 - val_loss: 0.0582
 - val_f1: 0.8254
Epoch 14/200
 - 12s - loss: 0.0123 - val_loss: 0.0092
 - val_f1: 0.9731
Epoch 15/200
 - 12s - loss: 0.0118 - val_loss: 0.0090
 - val_f1: 0.9758
Epoch 16/200
 - 12s - loss: 0.0114 - val_loss: 0.0091
 - val_f1: 0.9762
Epoch 17/200
 - 12s - loss: 0.0110 - val_loss: 0.0090
 - val_f1: 0.9763
Epoch 18/200
 - 12s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 19/200
 - 12s - loss: 0.0106 - val_loss: 0.0093
 - val_f1: 0.9761
Epoch 20/200
 - 12s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9769
Epoch 21/200
 - 12s - loss: 0.0101 - val_loss: 0.0086
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 14:23:47,752 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9772
Epoch 22/200
 - 12s - loss: 0.0099 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 23/200
 - 12s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 24/200
 - 12s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 25/200
 - 12s - loss: 0.0097 - val_loss: 0.0107
 - val_f1: 0.9731
Epoch 26/200
 - 12s - loss: 0.0096 - val_loss: 0.0156
 - val_f1: 0.9611
Epoch 27/200
 - 12s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 28/200
 - 12s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 29/200
 - 12s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 30/200
 - 12s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 31/200
 - 12s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 32/200
 - 13s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 33/200
 - 13s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 34/200
 - 12s - loss: 0.0091 - val_loss: 0.0243
 - val_f1: 0.9033
Epoch 35/200
 - 12s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9772
Epoch 36/200
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 37/200
 - 12s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 38/200
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 39/200
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 40/200
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9762
Epoch 41/200
 - 12s - loss: 0.0089 - val_loss: 0.0084
2020-01-11 14:31:35,143 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9777
Epoch 42/200
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 43/200
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 44/200
 - 13s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9759
Epoch 45/200
 - 12s - loss: 0.0089 - val_loss: 0.0555
 - val_f1: 0.8313
Epoch 46/200
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 47/200
 - 12s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 48/200
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 49/200
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 50/200
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 51/200
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 52/200
 - 12s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9752
Epoch 53/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 54/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9763
Epoch 55/200
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 56/200
 - 12s - loss: 0.0087 - val_loss: 0.0227
 - val_f1: 0.9231
Epoch 57/200
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 58/200
 - 13s - loss: 0.0087 - val_loss: 0.0151
 - val_f1: 0.9654
Epoch 59/200
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 60/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 61/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
2020-01-11 14:39:22,871 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9780
Epoch 62/200
 - 13s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 63/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 64/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 65/200
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 66/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 67/200
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 68/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 69/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 70/200
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 71/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 72/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 73/200
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 74/200
 - 13s - loss: 0.0085 - val_loss: 0.0830
 - val_f1: 0.8071
Epoch 75/200
 - 12s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 76/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 77/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 78/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 79/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 80/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 81/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
2020-01-11 14:47:10,670 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9779
Epoch 82/200
 - 12s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9767
Epoch 83/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 84/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 85/200
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 86/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 87/200
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 88/200
 - 12s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9669
Epoch 89/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 90/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 91/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 92/200
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 93/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 94/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 95/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 96/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 97/200
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 98/200
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 99/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 100/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 101/200
 - 12s - loss: 0.0084 - val_loss: 0.0082
2020-01-11 14:54:58,141 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9776
Epoch 102/200
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9774
Epoch 103/200
 - 13s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 104/200
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 105/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 106/200
 - 12s - loss: 0.0083 - val_loss: 0.0725
 - val_f1: 0.8178
Epoch 107/200
 - 12s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9772
Epoch 108/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 109/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 110/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 111/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 112/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 113/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 114/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 115/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 116/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 117/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 118/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9760
Epoch 119/200
 - 12s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 120/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 121/200
 - 12s - loss: 0.0083 - val_loss: 0.0142
2020-01-11 15:02:45,937 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9664
Epoch 122/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 123/200
 - 12s - loss: 0.0083 - val_loss: 0.0127
 - val_f1: 0.9667
Epoch 124/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 125/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 126/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 127/200
 - 12s - loss: 0.0083 - val_loss: 0.0125
 - val_f1: 0.9667
Epoch 128/200
 - 12s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9670
Epoch 129/200
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 130/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 131/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 132/200
 - 13s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 133/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 134/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 135/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 136/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 137/200
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 138/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 139/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 140/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 141/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
2020-01-11 15:10:33,786 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 143/200
 - 12s - loss: 0.0082 - val_loss: 0.0210
 - val_f1: 0.9617
Epoch 144/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 145/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 146/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 147/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 148/200
 - 12s - loss: 0.0082 - val_loss: 0.0188
 - val_f1: 0.9647
Epoch 149/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 150/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 151/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 152/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9787
Epoch 153/200
 - 12s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 154/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 155/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 156/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 157/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 158/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 159/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 160/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 161/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
2020-01-11 15:18:22,033 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9779
Epoch 162/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 163/200
 - 12s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 164/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 165/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 166/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 167/200
 - 12s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 168/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 169/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 170/200
 - 12s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 171/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 172/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 173/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 174/200
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 175/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 176/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 177/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 178/200
 - 12s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 179/200
 - 12s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 180/200
 - 12s - loss: 0.0081 - val_loss: 0.0099
 - val_f1: 0.9671
Epoch 181/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 15:26:09,739 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9785
Epoch 182/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 183/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 184/200
 - 12s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 185/200
 - 12s - loss: 0.0081 - val_loss: 0.0093
 - val_f1: 0.9765
Epoch 186/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 187/200
 - 12s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 188/200
 - 12s - loss: 0.0081 - val_loss: 0.0131
 - val_f1: 0.9667
Epoch 189/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 190/200
 - 12s - loss: 0.0081 - val_loss: 0.0117
 - val_f1: 0.9667
Epoch 191/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 192/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 193/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 194/200
 - 12s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 195/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 196/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 197/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 198/200
 - 12s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 199/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 200/200
 - 12s - loss: 0.0081 - val_loss: 0.0079
2020-01-11 15:33:45,640 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 15:34:14,202 [INFO] Last epoch loss evaluation: train_loss = 0.007890, val_loss = 0.007932
2020-01-11 15:34:14,206 [INFO] Training complete. time_to_train = 5433.02 sec, 90.55 min
2020-01-11 15:34:14,210 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/best_model.pickle
2020-01-11 15:34:14,213 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_error_history.csv
2020-01-11 15:34:14,410 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_error_history.png
2020-01-11 15:34:14,595 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/training_f1_history.png
2020-01-11 15:34:14,596 [INFO] Making predictions on training, validation, testing data
2020-01-11 15:35:02,614 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 15:35:25,676 [INFO] Dataset: Testing. Classification report below
2020-01-11 15:35:25,676 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.50      0.59      5596
   DoS attacks-Slowloris       0.94      0.97      0.95       440
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.62      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.78      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 15:35:25,677 [INFO] Overall accuracy (micro avg): 0.9834233943930794
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-11 15:35:50,466 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7781                       0.7103                0.0044                   0.2897  0.7086
2  Weighted avg        0.9910         0.9799                       0.9834                0.0500                   0.0166  0.9782
2020-01-11 15:36:13,460 [INFO] Dataset: Validation. Classification report below
2020-01-11 15:36:13,460 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.49      0.59      5596
   DoS attacks-Slowloris       0.93      0.96      0.95       439
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.57      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.78      0.73      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 15:36:13,460 [INFO] Overall accuracy (micro avg): 0.9834822389916451
2020-01-11 15:36:38,244 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7786                       0.7314                0.0044                   0.2686  0.7307
2  Weighted avg        0.9910         0.9794                       0.9835                0.0499                   0.0165  0.9783
2020-01-11 15:37:53,334 [INFO] Dataset: Training. Classification report below
2020-01-11 15:37:53,334 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.93      0.50      0.65        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.49      0.59     16787
   DoS attacks-Slowloris       0.95      0.99      0.97      1318
          FTP-BruteForce       0.70      0.87      0.78     23153
           Infilteration       0.64      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.78      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 15:37:53,335 [INFO] Overall accuracy (micro avg): 0.9834424842831927
2020-01-11 15:39:14,176 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7772                       0.7213                0.0044                   0.2787  0.7202
2  Weighted avg        0.9910         0.9801                       0.9834                0.0498                   0.0166  0.9783
2020-01-11 15:39:14,250 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep2/semi_sup_perf_ids18_subset_dbn_rep2_results.xlsx
2020-01-11 15:39:14,255 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-11 15:39:14,310 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3
2020-01-11 15:39:14,311 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/run_log.log
2020-01-11 15:39:14,311 [INFO] ================= Running experiment no. 3  ================= 

2020-01-11 15:39:14,311 [INFO] Experiment parameters given below
2020-01-11 15:39:14,311 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'dbn_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'random_seed': 42, 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_dbn_rep3'}
2020-01-11 15:39:14,311 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/tf_logs_run_2020_01_11-15_39_14
2020-01-11 15:39:14,311 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 15:39:14,311 [INFO] Reading X, y files
2020-01-11 15:39:14,311 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 15:39:18,313 [INFO] Reading complete. time_to_read=4.00 seconds
2020-01-11 15:39:18,314 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 15:39:19,678 [INFO] Reading complete. time_to_read=1.36 seconds
2020-01-11 15:39:19,678 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 15:39:21,048 [INFO] Reading complete. time_to_read=1.37 seconds
2020-01-11 15:39:21,048 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 15:39:21,334 [INFO] Reading complete. time_to_read=0.29 seconds
2020-01-11 15:39:21,334 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 15:39:21,434 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-11 15:39:21,434 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 15:39:21,535 [INFO] Reading complete. time_to_read=0.10 seconds
2020-01-11 15:39:24,896 [INFO] Initializing model
2020-01-11 15:39:24,898 [INFO] Training model
2020-01-11 15:39:24,898 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-11 15:39:54,913 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 98b9d1dc07d9315ef59683d8a8e6272c47d07f17
2020-01-11 15:39:54,913 [INFO] Pretraining Deep Belief Network
2020-01-11 15:51:36,454 [INFO] Pretraining Complete
2020-01-11 15:51:36,454 [INFO] Getting pretrained weights
2020-01-11 15:51:36,454 [INFO] Creating and initializing feed forward neural network
2020-01-11 15:51:36,575 [INFO] _________________________________________________________________
2020-01-11 15:51:36,575 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 15:51:36,575 [INFO] =================================================================
2020-01-11 15:51:36,575 [INFO] dense_5 (Dense)              (None, 64)                4992      
2020-01-11 15:51:36,575 [INFO] _________________________________________________________________
2020-01-11 15:51:36,575 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-11 15:51:36,575 [INFO] _________________________________________________________________
2020-01-11 15:51:36,576 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-11 15:51:36,576 [INFO] _________________________________________________________________
2020-01-11 15:51:36,576 [INFO] dense_6 (Dense)              (None, 15)                975       
2020-01-11 15:51:36,576 [INFO] =================================================================
2020-01-11 15:51:36,576 [INFO] Total params: 6,223
2020-01-11 15:51:36,576 [INFO] Trainable params: 6,095
2020-01-11 15:51:36,576 [INFO] Non-trainable params: 128
2020-01-11 15:51:36,576 [INFO] _________________________________________________________________
2020-01-11 15:51:36,760 [INFO] Fine-tuning final neural network
 - val_f1: 0.9782
[BernoulliRBM] Iteration 1, pseudo-likelihood = -34.20, time = 8.49s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -40.54, time = 14.83s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -46.17, time = 14.63s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -50.80, time = 14.60s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -54.87, time = 14.59s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -58.75, time = 14.58s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -62.59, time = 14.57s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -66.42, time = 14.55s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -70.28, time = 14.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -74.12, time = 14.47s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -77.96, time = 14.43s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -81.77, time = 14.39s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -85.54, time = 14.38s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -89.31, time = 14.37s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -93.05, time = 14.33s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -96.82, time = 14.20s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -100.59, time = 14.16s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -104.35, time = 14.13s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -108.14, time = 14.04s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -111.92, time = 13.99s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -115.71, time = 13.96s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -119.51, time = 13.91s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -123.31, time = 13.88s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -127.11, time = 13.86s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -130.91, time = 13.85s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -134.71, time = 13.83s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -138.51, time = 13.84s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -142.31, time = 13.85s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -146.10, time = 13.81s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -149.88, time = 13.81s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -153.66, time = 13.80s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -157.44, time = 13.80s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -161.23, time = 13.80s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -165.01, time = 13.79s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -168.80, time = 13.79s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -172.60, time = 13.78s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -176.39, time = 13.77s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -180.20, time = 13.78s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -184.00, time = 13.78s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -187.80, time = 13.77s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -191.62, time = 13.76s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -195.44, time = 13.76s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -199.26, time = 13.75s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -203.09, time = 13.76s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -206.92, time = 13.75s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -210.75, time = 13.75s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -214.59, time = 13.75s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -218.43, time = 13.75s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -222.27, time = 13.75s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -226.13, time = 13.74s
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 13s - loss: 0.0691 - val_loss: 0.0477
 - val_f1: 0.8709
Epoch 2/200
 - 12s - loss: 0.0466 - val_loss: 0.0402
 - val_f1: 0.8923
Epoch 3/200
 - 12s - loss: 0.0409 - val_loss: 0.0421
 - val_f1: 0.8445
Epoch 4/200
 - 12s - loss: 0.0362 - val_loss: 0.0294
 - val_f1: 0.9018
Epoch 5/200
 - 12s - loss: 0.0257 - val_loss: 0.0170
 - val_f1: 0.9583
Epoch 6/200
 - 12s - loss: 0.0210 - val_loss: 0.0137
 - val_f1: 0.9650
Epoch 7/200
 - 12s - loss: 0.0184 - val_loss: 0.0121
 - val_f1: 0.9722
Epoch 8/200
 - 12s - loss: 0.0164 - val_loss: 0.0111
 - val_f1: 0.9726
Epoch 9/200
 - 12s - loss: 0.0144 - val_loss: 0.0100
 - val_f1: 0.9731
Epoch 10/200
 - 12s - loss: 0.0129 - val_loss: 0.0531
 - val_f1: 0.8649
Epoch 11/200
 - 12s - loss: 0.0119 - val_loss: 0.0093
 - val_f1: 0.9757
Epoch 12/200
 - 12s - loss: 0.0113 - val_loss: 0.0091
 - val_f1: 0.9764
Epoch 13/200
 - 12s - loss: 0.0109 - val_loss: 0.0090
 - val_f1: 0.9759
Epoch 14/200
 - 13s - loss: 0.0107 - val_loss: 0.0523
 - val_f1: 0.8663
Epoch 15/200
 - 12s - loss: 0.0105 - val_loss: 0.0090
 - val_f1: 0.9738
Epoch 16/200
 - 12s - loss: 0.0104 - val_loss: 0.0619
 - val_f1: 0.8649
Epoch 17/200
 - 12s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9764
Epoch 18/200
 - 13s - loss: 0.0101 - val_loss: 0.0088
 - val_f1: 0.9760
Epoch 19/200
 - 12s - loss: 0.0100 - val_loss: 0.0107
 - val_f1: 0.9723
Epoch 20/200
 - 12s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9764
Epoch 21/200
 - 12s - loss: 0.0099 - val_loss: 0.0503
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 15:59:53,988 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.8749
Epoch 22/200
 - 13s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 23/200
 - 13s - loss: 0.0097 - val_loss: 0.0378
 - val_f1: 0.8774
Epoch 24/200
 - 13s - loss: 0.0096 - val_loss: 0.0113
 - val_f1: 0.9682
Epoch 25/200
 - 13s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9751
Epoch 26/200
 - 13s - loss: 0.0094 - val_loss: 0.0087
 - val_f1: 0.9767
Epoch 27/200
 - 13s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 28/200
 - 13s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 29/200
 - 13s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9779
Epoch 30/200
 - 13s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 31/200
 - 13s - loss: 0.0092 - val_loss: 0.0088
 - val_f1: 0.9758
Epoch 32/200
 - 13s - loss: 0.0091 - val_loss: 0.0369
 - val_f1: 0.8783
Epoch 33/200
 - 13s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 34/200
 - 13s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9781
Epoch 35/200
 - 13s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9780
Epoch 36/200
 - 13s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 37/200
 - 13s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 38/200
 - 13s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 39/200
 - 13s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 40/200
 - 13s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 41/200
 - 13s - loss: 0.0089 - val_loss: 0.0083
2020-01-11 16:07:59,610 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9774
Epoch 42/200
 - 13s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 43/200
 - 13s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 44/200
 - 13s - loss: 0.0089 - val_loss: 0.0221
 - val_f1: 0.9049
Epoch 45/200
 - 13s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 46/200
 - 13s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 47/200
 - 13s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 48/200
 - 13s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 49/200
 - 13s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9780
Epoch 50/200
 - 13s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 51/200
 - 13s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 52/200
 - 13s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 53/200
 - 13s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 54/200
 - 13s - loss: 0.0087 - val_loss: 0.0122
 - val_f1: 0.9673
Epoch 55/200
 - 13s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 56/200
 - 13s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 57/200
 - 13s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 58/200
 - 13s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 59/200
 - 13s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 60/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 61/200
 - 13s - loss: 0.0087 - val_loss: 0.0083
2020-01-11 16:16:05,057 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9782
Epoch 62/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 63/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 64/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 65/200
 - 13s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 66/200
 - 13s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 67/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 68/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 69/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 70/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 71/200
 - 13s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 72/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 73/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 74/200
 - 13s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 75/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 76/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 77/200
 - 13s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 78/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 79/200
 - 13s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 80/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 81/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
2020-01-11 16:24:11,274 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9779
Epoch 82/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 83/200
 - 13s - loss: 0.0085 - val_loss: 0.0142
 - val_f1: 0.9460
Epoch 84/200
 - 13s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 85/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 86/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 87/200
 - 13s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 88/200
 - 13s - loss: 0.0084 - val_loss: 0.0126
 - val_f1: 0.9643
Epoch 89/200
 - 13s - loss: 0.0084 - val_loss: 0.0169
 - val_f1: 0.9453
Epoch 90/200
 - 13s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9716
Epoch 91/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 92/200
 - 13s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 93/200
 - 13s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 94/200
 - 13s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 95/200
 - 13s - loss: 0.0084 - val_loss: 0.0137
 - val_f1: 0.9611
Epoch 96/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 97/200
 - 13s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9770
Epoch 98/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 99/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9786
Epoch 100/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 101/200
 - 13s - loss: 0.0084 - val_loss: 0.0082
2020-01-11 16:32:17,540 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9779
Epoch 102/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 103/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 104/200
 - 13s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 105/200
 - 13s - loss: 0.0084 - val_loss: 0.0135
 - val_f1: 0.9604
Epoch 106/200
 - 13s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 107/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 108/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 109/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 110/200
 - 13s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 111/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 112/200
 - 13s - loss: 0.0083 - val_loss: 0.0127
 - val_f1: 0.9625
Epoch 113/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 114/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 115/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 116/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9762
Epoch 117/200
 - 13s - loss: 0.0083 - val_loss: 0.0106
 - val_f1: 0.9722
Epoch 118/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 119/200
 - 13s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 120/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 121/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
2020-01-11 16:40:23,246 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9779
Epoch 122/200
 - 13s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 123/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 124/200
 - 13s - loss: 0.0083 - val_loss: 0.0114
 - val_f1: 0.9632
Epoch 125/200
 - 13s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9750
Epoch 126/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 127/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 128/200
 - 13s - loss: 0.0082 - val_loss: 0.0090
 - val_f1: 0.9732
Epoch 129/200
 - 13s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 130/200
 - 13s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 131/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 132/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9786
Epoch 133/200
 - 13s - loss: 0.0082 - val_loss: 0.0116
 - val_f1: 0.9622
Epoch 134/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 135/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 136/200
 - 13s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 137/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 138/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 139/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 140/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 141/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
2020-01-11 16:48:29,561 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9780
Epoch 142/200
 - 13s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 143/200
 - 13s - loss: 0.0082 - val_loss: 0.0102
 - val_f1: 0.9710
Epoch 144/200
 - 13s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9777
Epoch 145/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 146/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 147/200
 - 13s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9753
Epoch 148/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 149/200
 - 13s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9761
Epoch 150/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 151/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 152/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 153/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 154/200
 - 13s - loss: 0.0082 - val_loss: 0.0095
 - val_f1: 0.9720
Epoch 155/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 156/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 157/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 158/200
 - 13s - loss: 0.0082 - val_loss: 0.0100
 - val_f1: 0.9711
Epoch 159/200
 - 13s - loss: 0.0082 - val_loss: 0.0101
 - val_f1: 0.9711
Epoch 160/200
 - 13s - loss: 0.0082 - val_loss: 0.0096
 - val_f1: 0.9718
Epoch 161/200
 - 13s - loss: 0.0082 - val_loss: 0.0100
2020-01-11 16:56:36,259 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9712
Epoch 162/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 163/200
 - 13s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9766
Epoch 164/200
 - 13s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9714
Epoch 165/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 166/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 167/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 168/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 169/200
 - 13s - loss: 0.0082 - val_loss: 0.0100
 - val_f1: 0.9718
Epoch 170/200
 - 13s - loss: 0.0082 - val_loss: 0.0106
 - val_f1: 0.9645
Epoch 171/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 172/200
 - 13s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 173/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 174/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 175/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 176/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 177/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 178/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 179/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 180/200
 - 13s - loss: 0.0082 - val_loss: 0.0106
 - val_f1: 0.9707
Epoch 181/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
2020-01-11 17:04:43,064 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 183/200
 - 13s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 184/200
 - 13s - loss: 0.0082 - val_loss: 0.0092
 - val_f1: 0.9726
Epoch 185/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 186/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9769
Epoch 187/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 188/200
 - 13s - loss: 0.0082 - val_loss: 0.0086
 - val_f1: 0.9770
Epoch 189/200
 - 13s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 190/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 191/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 192/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 193/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 194/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 195/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 196/200
 - 13s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 197/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 198/200
 - 13s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 199/200
 - 13s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 200/200
 - 13s - loss: 0.0081 - val_loss: 0.0085
2020-01-11 17:12:37,634 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 17:13:07,811 [INFO] Last epoch loss evaluation: train_loss = 0.007906, val_loss = 0.007953
2020-01-11 17:13:07,816 [INFO] Training complete. time_to_train = 5622.92 sec, 93.72 min
2020-01-11 17:13:07,820 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/best_model.pickle
2020-01-11 17:13:07,823 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_error_history.csv
2020-01-11 17:13:08,016 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_error_history.png
2020-01-11 17:13:08,203 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/training_f1_history.png
2020-01-11 17:13:08,203 [INFO] Making predictions on training, validation, testing data
2020-01-11 17:13:59,972 [INFO] Evaluating predictions (results)
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 17:14:23,058 [INFO] Dataset: Testing. Classification report below
2020-01-11 17:14:23,058 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.49      0.59      5596
   DoS attacks-Slowloris       0.94      0.96      0.95       440
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.40      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645488
               macro avg       0.70      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 17:14:23,058 [INFO] Overall accuracy (micro avg): 0.9833877624371018
/home/sunanda/research/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/research/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/research/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-11 17:14:47,909 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.6971                       0.6879                0.0044                   0.3121  0.6760
2  Weighted avg        0.9910         0.9777                       0.9834                0.0497                   0.0166  0.9783
2020-01-11 17:15:10,926 [INFO] Dataset: Validation. Classification report below
2020-01-11 17:15:10,926 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.48      0.58      5596
   DoS attacks-Slowloris       0.93      0.96      0.95       439
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.43      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

                accuracy                           0.98    645487
               macro avg       0.70      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 17:15:10,926 [INFO] Overall accuracy (micro avg): 0.9834590007234848
2020-01-11 17:15:35,722 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7027                       0.6871                0.0044                   0.3129  0.6778
2  Weighted avg        0.9910         0.9781                       0.9835                0.0494                   0.0165  0.9784
2020-01-11 17:16:50,868 [INFO] Dataset: Training. Classification report below
2020-01-11 17:16:50,868 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.48      0.58     16787
   DoS attacks-Slowloris       0.95      0.98      0.97      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.49      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

                accuracy                           0.98   1936462
               macro avg       0.71      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 17:16:50,868 [INFO] Overall accuracy (micro avg): 0.9834460991230398
2020-01-11 17:18:11,888 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7057                       0.6879                0.0044                   0.3121  0.6775
2  Weighted avg        0.9910         0.9787                       0.9834                0.0494                   0.0166  0.9784
2020-01-11 17:18:11,962 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_dbn_rep3/semi_sup_perf_ids18_subset_dbn_rep3_results.xlsx
2020-01-11 17:18:11,966 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-11 17:18:12,022 [INFO] ================= Finished running 3 experiments ================= 

 - val_f1: 0.9773
