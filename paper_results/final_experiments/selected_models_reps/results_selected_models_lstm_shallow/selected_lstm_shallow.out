Using TensorFlow backend.
2019-12-26 12:37:46,976 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_lstm_shallow_rep1/run_log.log
2019-12-26 12:37:46,977 [INFO] ================= Running experiment no. 1  ================= 

2019-12-26 12:37:46,977 [INFO] Experiment parameters given below
2019-12-26 12:37:46,977 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_lstm_shallow_rep1', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_lstm_shallow_rep1'}
2019-12-26 12:37:46,977 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_lstm_shallow_rep1/tf_logs_run_2019_12_26-12_37_46
2019-12-26 12:37:46,977 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 12:37:46,984 [INFO] Reading X, y files
2019-12-26 12:37:46,984 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 12:37:47,543 [INFO] Reading complete. time_to_read=0.56 seconds
2019-12-26 12:37:47,543 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 12:37:47,679 [INFO] Reading complete. time_to_read=0.14 seconds
2019-12-26 12:37:47,680 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 12:37:47,805 [INFO] Reading complete. time_to_read=0.13 seconds
2019-12-26 12:37:47,805 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 12:37:47,830 [INFO] Reading complete. time_to_read=0.03 seconds
2019-12-26 12:37:47,830 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 12:37:47,849 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-26 12:37:47,849 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 12:37:47,866 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-26 12:37:48,023 [INFO] Preparing flow sequences
2019-12-26 12:37:49,178 [INFO] Extracting flows complete. time_taken = 1.15 sec
2019-12-26 12:37:49,228 [INFO] Initializing model
2019-12-26 12:37:49,228 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-26 12:37:49,237 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-26 12:37:49,238 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-26 12:37:49,607 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-26 12:37:49,621 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-26 12:37:49,640 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-26 12:37:49,652 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-26 12:37:49,655 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-26 12:37:49,664 [INFO] _________________________________________________________________
2019-12-26 12:37:49,664 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:37:49,664 [INFO] =================================================================
2019-12-26 12:37:49,664 [INFO] lstm_1 (LSTM)                (None, 32, 32)            19840     
2019-12-26 12:37:49,664 [INFO] _________________________________________________________________
2019-12-26 12:37:49,664 [INFO] batch_normalization_1 (Batch (None, 32, 32)            128       
2019-12-26 12:37:49,664 [INFO] _________________________________________________________________
2019-12-26 12:37:49,665 [INFO] dropout_1 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:37:49,665 [INFO] _________________________________________________________________
2019-12-26 12:37:49,665 [INFO] time_distributed_1 (TimeDist (None, 32, 5)             165       
2019-12-26 12:37:49,665 [INFO] =================================================================
2019-12-26 12:37:49,665 [INFO] Total params: 20,133
2019-12-26 12:37:49,665 [INFO] Trainable params: 20,069
2019-12-26 12:37:49,665 [INFO] Non-trainable params: 64
2019-12-26 12:37:49,665 [INFO] _________________________________________________________________
2019-12-26 12:37:49,665 [INFO] Training model
2019-12-26 12:37:52.591974: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-26 12:37:52.752965: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2019-12-26 12:37:52.753289: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56436ab70810 executing computations on platform Host. Devices:
2019-12-26 12:37:52.753333: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-26 12:37:52.937554: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-26 12:37:52,942 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-26 12:37:52,942 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Train on 3149 samples, validate on 787 samples
Epoch 1/300
 - 1s - loss: 0.5110 - val_loss: 0.3716
 - val_f1: 0.4580
Epoch 2/300
 - 0s - loss: 0.3298 - val_loss: 0.2367
 - val_f1: 0.7745
Epoch 3/300
 - 0s - loss: 0.2180 - val_loss: 0.1452
 - val_f1: 0.9004
Epoch 4/300
 - 0s - loss: 0.1481 - val_loss: 0.0996
 - val_f1: 0.9342
Epoch 5/300
 - 0s - loss: 0.1092 - val_loss: 0.0809
 - val_f1: 0.9504
Epoch 6/300
 - 0s - loss: 0.0881 - val_loss: 0.0703
 - val_f1: 0.9586
Epoch 7/300
 - 0s - loss: 0.0745 - val_loss: 0.0632
 - val_f1: 0.9635
Epoch 8/300
 - 0s - loss: 0.0660 - val_loss: 0.0575
 - val_f1: 0.9658
Epoch 9/300
 - 0s - loss: 0.0597 - val_loss: 0.0527
 - val_f1: 0.9677
Epoch 10/300
 - 0s - loss: 0.0554 - val_loss: 0.0488
 - val_f1: 0.9690
Epoch 11/300
 - 0s - loss: 0.0512 - val_loss: 0.0456
 - val_f1: 0.9695
Epoch 12/300
 - 0s - loss: 0.0482 - val_loss: 0.0428
 - val_f1: 0.9701
Epoch 13/300
 - 0s - loss: 0.0457 - val_loss: 0.0406
 - val_f1: 0.9717
Epoch 14/300
 - 0s - loss: 0.0433 - val_loss: 0.0388
 - val_f1: 0.9725
Epoch 15/300
 - 0s - loss: 0.0412 - val_loss: 0.0370
 - val_f1: 0.9729
Epoch 16/300
 - 0s - loss: 0.0397 - val_loss: 0.0355
 - val_f1: 0.9744
Epoch 17/300
 - 0s - loss: 0.0379 - val_loss: 0.0340
 - val_f1: 0.9740
Epoch 18/300
 - 0s - loss: 0.0364 - val_loss: 0.0326
 - val_f1: 0.9755
Epoch 19/300
 - 0s - loss: 0.0348 - val_loss: 0.0314
 - val_f1: 0.9757
Epoch 20/300
 - 0s - loss: 0.0332 - val_loss: 0.0301
 - val_f1: 0.9756
Epoch 21/300
 - 0s - loss: 0.0322 - val_loss: 0.0289
 - val_f1: 0.9770
Epoch 22/300
 - 0s - loss: 0.0307 - val_loss: 0.0278
 - val_f1: 0.9778
Epoch 23/300
 - 0s - loss: 0.0294 - val_loss: 0.0264
 - val_f1: 0.9778
Epoch 24/300
 - 0s - loss: 0.0277 - val_loss: 0.0251
 - val_f1: 0.9780
Epoch 25/300
 - 0s - loss: 0.0266 - val_loss: 0.0239
 - val_f1: 0.9786
Epoch 26/300
 - 0s - loss: 0.0249 - val_loss: 0.0227
 - val_f1: 0.9790
Epoch 27/300
 - 0s - loss: 0.0236 - val_loss: 0.0216
 - val_f1: 0.9801
Epoch 28/300
 - 0s - loss: 0.0220 - val_loss: 0.0206
 - val_f1: 0.9801
Epoch 29/300
 - 0s - loss: 0.0211 - val_loss: 0.0196
 - val_f1: 0.9814
Epoch 30/300
 - 0s - loss: 0.0202 - val_loss: 0.0188
 - val_f1: 0.9819
Epoch 31/300
 - 0s - loss: 0.0191 - val_loss: 0.0182
2019-12-26 12:38:06,300 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/_model_epoch_30.pickle
 - val_f1: 0.9829
Epoch 32/300
 - 0s - loss: 0.0184 - val_loss: 0.0176
 - val_f1: 0.9839
Epoch 33/300
 - 0s - loss: 0.0177 - val_loss: 0.0168
 - val_f1: 0.9855
Epoch 34/300
 - 0s - loss: 0.0167 - val_loss: 0.0162
 - val_f1: 0.9857
Epoch 35/300
 - 0s - loss: 0.0163 - val_loss: 0.0157
 - val_f1: 0.9861
Epoch 36/300
 - 0s - loss: 0.0158 - val_loss: 0.0151
 - val_f1: 0.9876
Epoch 37/300
 - 0s - loss: 0.0156 - val_loss: 0.0147
 - val_f1: 0.9878
Epoch 38/300
 - 0s - loss: 0.0151 - val_loss: 0.0143
 - val_f1: 0.9884
Epoch 39/300
 - 0s - loss: 0.0145 - val_loss: 0.0141
 - val_f1: 0.9887
Epoch 40/300
 - 0s - loss: 0.0142 - val_loss: 0.0135
 - val_f1: 0.9895
Epoch 41/300
 - 0s - loss: 0.0135 - val_loss: 0.0133
 - val_f1: 0.9901
Epoch 42/300
 - 0s - loss: 0.0133 - val_loss: 0.0128
 - val_f1: 0.9904
Epoch 43/300
 - 0s - loss: 0.0131 - val_loss: 0.0125
 - val_f1: 0.9904
Epoch 44/300
 - 0s - loss: 0.0129 - val_loss: 0.0122
 - val_f1: 0.9913
Epoch 45/300
 - 0s - loss: 0.0126 - val_loss: 0.0122
 - val_f1: 0.9909
Epoch 46/300
 - 0s - loss: 0.0122 - val_loss: 0.0118
 - val_f1: 0.9911
Epoch 47/300
 - 0s - loss: 0.0121 - val_loss: 0.0116
 - val_f1: 0.9917
Epoch 48/300
 - 0s - loss: 0.0118 - val_loss: 0.0116
 - val_f1: 0.9913
Epoch 49/300
 - 0s - loss: 0.0117 - val_loss: 0.0114
 - val_f1: 0.9915
Epoch 50/300
 - 0s - loss: 0.0114 - val_loss: 0.0111
 - val_f1: 0.9919
Epoch 51/300
 - 0s - loss: 0.0113 - val_loss: 0.0109
 - val_f1: 0.9919
Epoch 52/300
 - 0s - loss: 0.0109 - val_loss: 0.0110
 - val_f1: 0.9920
Epoch 53/300
 - 0s - loss: 0.0109 - val_loss: 0.0109
 - val_f1: 0.9920
Epoch 54/300
 - 0s - loss: 0.0108 - val_loss: 0.0108
 - val_f1: 0.9913
Epoch 55/300
 - 0s - loss: 0.0106 - val_loss: 0.0107
 - val_f1: 0.9921
Epoch 56/300
 - 0s - loss: 0.0104 - val_loss: 0.0106
 - val_f1: 0.9923
Epoch 57/300
 - 0s - loss: 0.0101 - val_loss: 0.0106
 - val_f1: 0.9918
Epoch 58/300
 - 0s - loss: 0.0101 - val_loss: 0.0105
 - val_f1: 0.9924
Epoch 59/300
 - 0s - loss: 0.0099 - val_loss: 0.0104
 - val_f1: 0.9923
Epoch 60/300
 - 0s - loss: 0.0098 - val_loss: 0.0102
 - val_f1: 0.9926
Epoch 61/300
 - 0s - loss: 0.0098 - val_loss: 0.0102
2019-12-26 12:38:18,092 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/_model_epoch_60.pickle
 - val_f1: 0.9927
Epoch 62/300
 - 0s - loss: 0.0095 - val_loss: 0.0103
 - val_f1: 0.9923
Epoch 63/300
 - 0s - loss: 0.0094 - val_loss: 0.0102
 - val_f1: 0.9926
Epoch 64/300
 - 0s - loss: 0.0093 - val_loss: 0.0102
 - val_f1: 0.9927
Epoch 65/300
 - 0s - loss: 0.0092 - val_loss: 0.0101
 - val_f1: 0.9924
Epoch 66/300
 - 0s - loss: 0.0094 - val_loss: 0.0100
 - val_f1: 0.9927
Epoch 67/300
 - 0s - loss: 0.0090 - val_loss: 0.0102
 - val_f1: 0.9925
Epoch 68/300
 - 0s - loss: 0.0091 - val_loss: 0.0100
 - val_f1: 0.9928
Epoch 69/300
 - 0s - loss: 0.0088 - val_loss: 0.0102
 - val_f1: 0.9922
Epoch 70/300
 - 0s - loss: 0.0088 - val_loss: 0.0101
 - val_f1: 0.9925
Epoch 71/300
 - 0s - loss: 0.0087 - val_loss: 0.0100
 - val_f1: 0.9926
Epoch 72/300
 - 0s - loss: 0.0084 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 73/300
 - 0s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 74/300
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9929
Epoch 75/300
 - 0s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 76/300
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 77/300
 - 0s - loss: 0.0080 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 78/300
 - 0s - loss: 0.0079 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 79/300
 - 0s - loss: 0.0077 - val_loss: 0.0097
 - val_f1: 0.9930
Epoch 80/300
 - 0s - loss: 0.0078 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 81/300
 - 0s - loss: 0.0077 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 82/300
 - 0s - loss: 0.0078 - val_loss: 0.0098
 - val_f1: 0.9926
Epoch 83/300
 - 0s - loss: 0.0077 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 84/300
 - 0s - loss: 0.0075 - val_loss: 0.0095
 - val_f1: 0.9930
Epoch 85/300
 - 0s - loss: 0.0074 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 86/300
 - 0s - loss: 0.0075 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 87/300
 - 0s - loss: 0.0072 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 88/300
 - 0s - loss: 0.0073 - val_loss: 0.0094
 - val_f1: 0.9930
Epoch 89/300
 - 0s - loss: 0.0074 - val_loss: 0.0096
 - val_f1: 0.9928
Epoch 90/300
 - 0s - loss: 0.0072 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 91/300
 - 0s - loss: 0.0072 - val_loss: 0.0094
2019-12-26 12:38:29,859 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/_model_epoch_90.pickle
 - val_f1: 0.9929
Epoch 92/300
 - 0s - loss: 0.0071 - val_loss: 0.0095
 - val_f1: 0.9927
Epoch 93/300
 - 0s - loss: 0.0068 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 94/300
 - 0s - loss: 0.0067 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 95/300
 - 0s - loss: 0.0067 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 96/300
 - 0s - loss: 0.0067 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 97/300
 - 0s - loss: 0.0066 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 98/300
 - 0s - loss: 0.0069 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 99/300
 - 0s - loss: 0.0067 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 100/300
 - 0s - loss: 0.0065 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 101/300
 - 0s - loss: 0.0065 - val_loss: 0.0092
 - val_f1: 0.9933
Epoch 102/300
 - 0s - loss: 0.0063 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 103/300
 - 0s - loss: 0.0064 - val_loss: 0.0092
 - val_f1: 0.9928
Epoch 104/300
 - 0s - loss: 0.0062 - val_loss: 0.0092
 - val_f1: 0.9929
Epoch 105/300
 - 0s - loss: 0.0062 - val_loss: 0.0093
 - val_f1: 0.9933
Epoch 106/300
 - 0s - loss: 0.0061 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 107/300
 - 0s - loss: 0.0062 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 108/300
 - 0s - loss: 0.0060 - val_loss: 0.0092
 - val_f1: 0.9933
Epoch 109/300
 - 0s - loss: 0.0060 - val_loss: 0.0094
 - val_f1: 0.9930
Epoch 110/300
 - 0s - loss: 0.0060 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 111/300
 - 0s - loss: 0.0061 - val_loss: 0.0092
 - val_f1: 0.9928
Epoch 112/300
 - 0s - loss: 0.0058 - val_loss: 0.0094
 - val_f1: 0.9927
Epoch 113/300
 - 0s - loss: 0.0059 - val_loss: 0.0092
 - val_f1: 0.9933
Epoch 114/300
 - 0s - loss: 0.0057 - val_loss: 0.0092
 - val_f1: 0.9927
Epoch 115/300
 - 0s - loss: 0.0057 - val_loss: 0.0092
 - val_f1: 0.9931
Epoch 116/300
 - 0s - loss: 0.0056 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 117/300
 - 0s - loss: 0.0056 - val_loss: 0.0092
 - val_f1: 0.9932
Epoch 118/300
 - 0s - loss: 0.0057 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 119/300
 - 0s - loss: 0.0056 - val_loss: 0.0091
 - val_f1: 0.9931
Epoch 120/300
 - 0s - loss: 0.0054 - val_loss: 0.0094
 - val_f1: 0.9929
Epoch 121/300
 - 0s - loss: 0.0058 - val_loss: 0.0097
2019-12-26 12:38:41,611 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/_model_epoch_120.pickle
 - val_f1: 0.9933
Epoch 122/300
 - 0s - loss: 0.0054 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 123/300
 - 0s - loss: 0.0052 - val_loss: 0.0093
 - val_f1: 0.9929
Epoch 124/300
 - 0s - loss: 0.0052 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 125/300
 - 0s - loss: 0.0052 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 126/300
 - 0s - loss: 0.0052 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 127/300
 - 0s - loss: 0.0052 - val_loss: 0.0094
 - val_f1: 0.9926
Epoch 128/300
 - 0s - loss: 0.0050 - val_loss: 0.0092
 - val_f1: 0.9932
Epoch 129/300
 - 0s - loss: 0.0051 - val_loss: 0.0090
 - val_f1: 0.9934
Epoch 130/300
 - 0s - loss: 0.0049 - val_loss: 0.0092
 - val_f1: 0.9932
Epoch 131/300
 - 0s - loss: 0.0049 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 132/300
 - 0s - loss: 0.0051 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 133/300
 - 0s - loss: 0.0048 - val_loss: 0.0095
 - val_f1: 0.9928
Epoch 134/300
 - 0s - loss: 0.0049 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 135/300
 - 0s - loss: 0.0049 - val_loss: 0.0094
 - val_f1: 0.9926
Epoch 136/300
 - 0s - loss: 0.0048 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 137/300
 - 0s - loss: 0.0046 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 138/300
 - 0s - loss: 0.0049 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 139/300
 - 0s - loss: 0.0046 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 140/300
 - 0s - loss: 0.0046 - val_loss: 0.0096
 - val_f1: 0.9928
Epoch 141/300
 - 0s - loss: 0.0045 - val_loss: 0.0096
 - val_f1: 0.9930
Epoch 142/300
 - 0s - loss: 0.0045 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 143/300
 - 0s - loss: 0.0046 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 144/300
 - 0s - loss: 0.0046 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 145/300
 - 0s - loss: 0.0044 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 146/300
 - 0s - loss: 0.0043 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 147/300
 - 0s - loss: 0.0044 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 148/300
 - 0s - loss: 0.0044 - val_loss: 0.0099
 - val_f1: 0.9927
Epoch 149/300
 - 0s - loss: 0.0043 - val_loss: 0.0095
 - val_f1: 0.9932
Epoch 150/300
 - 0s - loss: 0.0043 - val_loss: 0.0096
 - val_f1: 0.9930
Epoch 151/300
 - 0s - loss: 0.0043 - val_loss: 0.0095
2019-12-26 12:38:53,393 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/_model_epoch_150.pickle
 - val_f1: 0.9932
Epoch 152/300
 - 0s - loss: 0.0041 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 153/300
 - 0s - loss: 0.0042 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 154/300
 - 0s - loss: 0.0042 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 155/300
 - 0s - loss: 0.0043 - val_loss: 0.0098
 - val_f1: 0.9932
Epoch 156/300
 - 0s - loss: 0.0043 - val_loss: 0.0099
 - val_f1: 0.9932
Epoch 157/300
 - 0s - loss: 0.0039 - val_loss: 0.0099
 - val_f1: 0.9929
Epoch 158/300
 - 0s - loss: 0.0040 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 159/300
 - 0s - loss: 0.0040 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 160/300
 - 0s - loss: 0.0040 - val_loss: 0.0100
 - val_f1: 0.9931
Epoch 161/300
 - 0s - loss: 0.0038 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 162/300
 - 0s - loss: 0.0040 - val_loss: 0.0101
 - val_f1: 0.9928
Epoch 163/300
 - 0s - loss: 0.0039 - val_loss: 0.0099
 - val_f1: 0.9932
Epoch 164/300
 - 0s - loss: 0.0040 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 165/300
 - 0s - loss: 0.0039 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 166/300
 - 0s - loss: 0.0037 - val_loss: 0.0101
 - val_f1: 0.9931
Epoch 167/300
 - 0s - loss: 0.0038 - val_loss: 0.0102
 - val_f1: 0.9929
Epoch 168/300
 - 0s - loss: 0.0037 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 169/300
 - 0s - loss: 0.0038 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 170/300
 - 0s - loss: 0.0037 - val_loss: 0.0100
 - val_f1: 0.9932
Epoch 171/300
 - 0s - loss: 0.0036 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 172/300
 - 0s - loss: 0.0037 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 173/300
 - 0s - loss: 0.0036 - val_loss: 0.0101
 - val_f1: 0.9935
Epoch 174/300
 - 0s - loss: 0.0035 - val_loss: 0.0101
 - val_f1: 0.9931
Epoch 175/300
 - 0s - loss: 0.0036 - val_loss: 0.0100
 - val_f1: 0.9934
Epoch 176/300
 - 0s - loss: 0.0034 - val_loss: 0.0100
 - val_f1: 0.9935
Epoch 177/300
 - 0s - loss: 0.0036 - val_loss: 0.0104
 - val_f1: 0.9935
Epoch 178/300
 - 0s - loss: 0.0035 - val_loss: 0.0103
 - val_f1: 0.9929
Epoch 179/300
 - 0s - loss: 0.0034 - val_loss: 0.0103
2019-12-26 12:39:04,420 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 12:39:04,775 [INFO] Last epoch loss evaluation: train_loss = 0.003416, val_loss = 0.009014
2019-12-26 12:39:04,775 [INFO] Training complete. time_to_train = 75.11 sec, 1.25 min
2019-12-26 12:39:04,779 [INFO] Model saved to results_selected_models/selected_nsl_lstm_shallow_rep1/best_model.pickle
2019-12-26 12:39:04,796 [INFO] Training history saved to: results_selected_models/selected_nsl_lstm_shallow_rep1/training_error_history.csv
2019-12-26 12:39:04,960 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep1/training_error_history.png
2019-12-26 12:39:05,081 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep1/training_f1_history.png
2019-12-26 12:39:05,081 [INFO] Making predictions on training, validation, testing data
2019-12-26 12:39:05,421 [INFO] Evaluating predictions (results)
2019-12-26 12:39:05,751 [INFO] Dataset: Testing. Classification report below
2019-12-26 12:39:05,751 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.89      7450
      normal       0.68      0.93      0.79      9704
       probe       0.73      0.73      0.73      2420
         r2l       0.94      0.12      0.21      2421
         u2r       0.84      0.03      0.06       533

   micro avg       0.77      0.77      0.77     22528
   macro avg       0.83      0.53      0.53     22528
weighted avg       0.81      0.77      0.74     22528

2019-12-26 12:39:05,752 [INFO] Overall accuracy (micro avg): 0.7696644176136364
2019-12-26 12:39:06,085 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7697         0.7697                       0.7697                0.0576                   0.2303  0.7697
1     Macro avg        0.9079         0.8297                       0.5293                0.0764                   0.4707  0.5350
2  Weighted avg        0.8673         0.8094                       0.7697                0.1518                   0.2303  0.7364
2019-12-26 12:39:06,439 [INFO] Dataset: Validation. Classification report below
2019-12-26 12:39:06,439 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9183
      normal       0.99      0.99      0.99     13462
       probe       0.98      0.99      0.98      2330
         r2l       0.90      0.83      0.86       199
         u2r       0.60      0.30      0.40        10

   micro avg       0.99      0.99      0.99     25184
   macro avg       0.90      0.82      0.85     25184
weighted avg       0.99      0.99      0.99     25184

2019-12-26 12:39:06,439 [INFO] Overall accuracy (micro avg): 0.9935276365946633
2019-12-26 12:39:06,828 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9935         0.9935                       0.9935                0.0016                   0.0065  0.9935
1     Macro avg        0.9974         0.8954                       0.8215                0.0022                   0.1785  0.8482
2  Weighted avg        0.9959         0.9934                       0.9935                0.0045                   0.0065  0.9934
2019-12-26 12:39:08,337 [INFO] Dataset: Training. Classification report below
2019-12-26 12:39:08,337 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36738
      normal       1.00      1.00      1.00     53871
       probe       1.00      0.99      0.99      9321
         r2l       0.96      0.90      0.93       796
         u2r       1.00      0.64      0.78        42

   micro avg       1.00      1.00      1.00    100768
   macro avg       0.99      0.91      0.94    100768
weighted avg       1.00      1.00      1.00    100768

2019-12-26 12:39:08,337 [INFO] Overall accuracy (micro avg): 0.9975289774531597
2019-12-26 12:39:10,041 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9911                       0.9068                0.0009                   0.0932  0.9410
2  Weighted avg        0.9985         0.9975                       0.9975                0.0021                   0.0025  0.9975
2019-12-26 12:39:10,061 [INFO] Results saved to: results_selected_models/selected_nsl_lstm_shallow_rep1/selected_nsl_lstm_shallow_rep1_results.xlsx
2019-12-26 12:39:10,061 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-26 12:39:10,064 [INFO] Created directory: results_selected_models/selected_nsl_lstm_shallow_rep2
2019-12-26 12:39:10,064 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_lstm_shallow_rep2/run_log.log
2019-12-26 12:39:10,064 [INFO] ================= Running experiment no. 2  ================= 

2019-12-26 12:39:10,064 [INFO] Experiment parameters given below
2019-12-26 12:39:10,064 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_nsl_lstm_shallow_rep2', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_lstm_shallow_rep2'}
2019-12-26 12:39:10,065 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_lstm_shallow_rep2/tf_logs_run_2019_12_26-12_39_10
2019-12-26 12:39:10,065 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 12:39:10,065 [INFO] Reading X, y files
2019-12-26 12:39:10,065 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 12:39:10,319 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-26 12:39:10,319 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 12:39:10,381 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:39:10,381 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 12:39:10,442 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:39:10,442 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 12:39:10,449 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 12:39:10,449 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 12:39:10,453 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:39:10,453 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 12:39:10,457 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:39:10,612 [INFO] Preparing flow sequences
2019-12-26 12:39:11,770 [INFO] Extracting flows complete. time_taken = 1.16 sec
2019-12-26 12:39:11,820 [INFO] Initializing model
2019-12-26 12:39:12,055 [INFO] _________________________________________________________________
2019-12-26 12:39:12,055 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:39:12,055 [INFO] =================================================================
2019-12-26 12:39:12,055 [INFO] lstm_2 (LSTM)                (None, 32, 32)            19840     
2019-12-26 12:39:12,055 [INFO] _________________________________________________________________
2019-12-26 12:39:12,055 [INFO] batch_normalization_2 (Batch (None, 32, 32)            128       
2019-12-26 12:39:12,055 [INFO] _________________________________________________________________
2019-12-26 12:39:12,055 [INFO] dropout_2 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:39:12,055 [INFO] _________________________________________________________________
2019-12-26 12:39:12,055 [INFO] time_distributed_2 (TimeDist (None, 32, 5)             165       
2019-12-26 12:39:12,055 [INFO] =================================================================
2019-12-26 12:39:12,055 [INFO] Total params: 20,133
2019-12-26 12:39:12,055 [INFO] Trainable params: 20,069
2019-12-26 12:39:12,056 [INFO] Non-trainable params: 64
2019-12-26 12:39:12,056 [INFO] _________________________________________________________________
2019-12-26 12:39:12,056 [INFO] Training model
 - val_f1: 0.9931
Epoch 00179: early stopping
Train on 3149 samples, validate on 787 samples
Epoch 1/300
 - 1s - loss: 0.5927 - val_loss: 0.4138
 - val_f1: 0.3440
Epoch 2/300
 - 0s - loss: 0.3826 - val_loss: 0.2842
 - val_f1: 0.6602
Epoch 3/300
 - 0s - loss: 0.2507 - val_loss: 0.1885
 - val_f1: 0.8450
Epoch 4/300
 - 0s - loss: 0.1635 - val_loss: 0.1253
 - val_f1: 0.9228
Epoch 5/300
 - 0s - loss: 0.1138 - val_loss: 0.0924
 - val_f1: 0.9493
Epoch 6/300
 - 0s - loss: 0.0892 - val_loss: 0.0769
 - val_f1: 0.9578
Epoch 7/300
 - 0s - loss: 0.0758 - val_loss: 0.0676
 - val_f1: 0.9619
Epoch 8/300
 - 0s - loss: 0.0665 - val_loss: 0.0604
 - val_f1: 0.9650
Epoch 9/300
 - 0s - loss: 0.0608 - val_loss: 0.0553
 - val_f1: 0.9672
Epoch 10/300
 - 0s - loss: 0.0561 - val_loss: 0.0512
 - val_f1: 0.9682
Epoch 11/300
 - 0s - loss: 0.0526 - val_loss: 0.0479
 - val_f1: 0.9701
Epoch 12/300
 - 0s - loss: 0.0499 - val_loss: 0.0451
 - val_f1: 0.9707
Epoch 13/300
 - 0s - loss: 0.0470 - val_loss: 0.0428
 - val_f1: 0.9713
Epoch 14/300
 - 0s - loss: 0.0450 - val_loss: 0.0409
 - val_f1: 0.9727
Epoch 15/300
 - 0s - loss: 0.0434 - val_loss: 0.0392
 - val_f1: 0.9732
Epoch 16/300
 - 0s - loss: 0.0413 - val_loss: 0.0377
 - val_f1: 0.9743
Epoch 17/300
 - 0s - loss: 0.0399 - val_loss: 0.0362
 - val_f1: 0.9747
Epoch 18/300
 - 0s - loss: 0.0387 - val_loss: 0.0350
 - val_f1: 0.9751
Epoch 19/300
 - 0s - loss: 0.0373 - val_loss: 0.0339
 - val_f1: 0.9761
Epoch 20/300
 - 0s - loss: 0.0362 - val_loss: 0.0327
 - val_f1: 0.9756
Epoch 21/300
 - 0s - loss: 0.0347 - val_loss: 0.0316
 - val_f1: 0.9758
Epoch 22/300
 - 0s - loss: 0.0335 - val_loss: 0.0304
 - val_f1: 0.9762
Epoch 23/300
 - 0s - loss: 0.0323 - val_loss: 0.0295
 - val_f1: 0.9770
Epoch 24/300
 - 0s - loss: 0.0315 - val_loss: 0.0284
 - val_f1: 0.9771
Epoch 25/300
 - 0s - loss: 0.0302 - val_loss: 0.0275
 - val_f1: 0.9774
Epoch 26/300
 - 0s - loss: 0.0289 - val_loss: 0.0265
 - val_f1: 0.9776
Epoch 27/300
 - 0s - loss: 0.0281 - val_loss: 0.0255
 - val_f1: 0.9781
Epoch 28/300
 - 0s - loss: 0.0267 - val_loss: 0.0244
 - val_f1: 0.9785
Epoch 29/300
 - 0s - loss: 0.0258 - val_loss: 0.0233
 - val_f1: 0.9794
Epoch 30/300
 - 0s - loss: 0.0244 - val_loss: 0.0223
 - val_f1: 0.9794
Epoch 31/300
 - 0s - loss: 0.0235 - val_loss: 0.0216
2019-12-26 12:39:26,702 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/_model_epoch_30.pickle
 - val_f1: 0.9794
Epoch 32/300
 - 0s - loss: 0.0226 - val_loss: 0.0207
 - val_f1: 0.9803
Epoch 33/300
 - 0s - loss: 0.0216 - val_loss: 0.0197
 - val_f1: 0.9811
Epoch 34/300
 - 0s - loss: 0.0206 - val_loss: 0.0189
 - val_f1: 0.9820
Epoch 35/300
 - 0s - loss: 0.0198 - val_loss: 0.0183
 - val_f1: 0.9827
Epoch 36/300
 - 0s - loss: 0.0190 - val_loss: 0.0177
 - val_f1: 0.9836
Epoch 37/300
 - 0s - loss: 0.0182 - val_loss: 0.0171
 - val_f1: 0.9841
Epoch 38/300
 - 0s - loss: 0.0177 - val_loss: 0.0164
 - val_f1: 0.9853
Epoch 39/300
 - 0s - loss: 0.0172 - val_loss: 0.0158
 - val_f1: 0.9866
Epoch 40/300
 - 0s - loss: 0.0164 - val_loss: 0.0155
 - val_f1: 0.9862
Epoch 41/300
 - 0s - loss: 0.0161 - val_loss: 0.0152
 - val_f1: 0.9871
Epoch 42/300
 - 0s - loss: 0.0156 - val_loss: 0.0148
 - val_f1: 0.9883
Epoch 43/300
 - 0s - loss: 0.0153 - val_loss: 0.0145
 - val_f1: 0.9881
Epoch 44/300
 - 0s - loss: 0.0151 - val_loss: 0.0142
 - val_f1: 0.9885
Epoch 45/300
 - 0s - loss: 0.0146 - val_loss: 0.0138
 - val_f1: 0.9891
Epoch 46/300
 - 0s - loss: 0.0143 - val_loss: 0.0136
 - val_f1: 0.9892
Epoch 47/300
 - 0s - loss: 0.0140 - val_loss: 0.0132
 - val_f1: 0.9896
Epoch 48/300
 - 0s - loss: 0.0135 - val_loss: 0.0130
 - val_f1: 0.9899
Epoch 49/300
 - 0s - loss: 0.0132 - val_loss: 0.0126
 - val_f1: 0.9907
Epoch 50/300
 - 0s - loss: 0.0130 - val_loss: 0.0125
 - val_f1: 0.9907
Epoch 51/300
 - 0s - loss: 0.0129 - val_loss: 0.0123
 - val_f1: 0.9908
Epoch 52/300
 - 0s - loss: 0.0125 - val_loss: 0.0119
 - val_f1: 0.9916
Epoch 53/300
 - 0s - loss: 0.0124 - val_loss: 0.0119
 - val_f1: 0.9913
Epoch 54/300
 - 0s - loss: 0.0123 - val_loss: 0.0116
 - val_f1: 0.9919
Epoch 55/300
 - 0s - loss: 0.0120 - val_loss: 0.0117
 - val_f1: 0.9916
Epoch 56/300
 - 0s - loss: 0.0120 - val_loss: 0.0114
 - val_f1: 0.9919
Epoch 57/300
 - 0s - loss: 0.0117 - val_loss: 0.0112
 - val_f1: 0.9920
Epoch 58/300
 - 0s - loss: 0.0116 - val_loss: 0.0113
 - val_f1: 0.9916
Epoch 59/300
 - 0s - loss: 0.0113 - val_loss: 0.0110
 - val_f1: 0.9922
Epoch 60/300
 - 0s - loss: 0.0112 - val_loss: 0.0107
 - val_f1: 0.9925
Epoch 61/300
 - 0s - loss: 0.0110 - val_loss: 0.0107
2019-12-26 12:39:38,558 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/_model_epoch_60.pickle
 - val_f1: 0.9928
Epoch 62/300
 - 0s - loss: 0.0108 - val_loss: 0.0106
 - val_f1: 0.9924
Epoch 63/300
 - 0s - loss: 0.0107 - val_loss: 0.0105
 - val_f1: 0.9927
Epoch 64/300
 - 0s - loss: 0.0105 - val_loss: 0.0106
 - val_f1: 0.9923
Epoch 65/300
 - 0s - loss: 0.0104 - val_loss: 0.0105
 - val_f1: 0.9923
Epoch 66/300
 - 0s - loss: 0.0104 - val_loss: 0.0105
 - val_f1: 0.9925
Epoch 67/300
 - 0s - loss: 0.0100 - val_loss: 0.0101
 - val_f1: 0.9928
Epoch 68/300
 - 0s - loss: 0.0098 - val_loss: 0.0100
 - val_f1: 0.9926
Epoch 69/300
 - 0s - loss: 0.0098 - val_loss: 0.0102
 - val_f1: 0.9925
Epoch 70/300
 - 0s - loss: 0.0097 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 71/300
 - 0s - loss: 0.0097 - val_loss: 0.0098
 - val_f1: 0.9930
Epoch 72/300
 - 0s - loss: 0.0094 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 73/300
 - 0s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 74/300
 - 0s - loss: 0.0092 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 75/300
 - 0s - loss: 0.0092 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 76/300
 - 0s - loss: 0.0091 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 77/300
 - 0s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 78/300
 - 0s - loss: 0.0088 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 79/300
 - 0s - loss: 0.0088 - val_loss: 0.0095
 - val_f1: 0.9930
Epoch 80/300
 - 0s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 81/300
 - 0s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 82/300
 - 0s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 83/300
 - 0s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 84/300
 - 0s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9936
Epoch 85/300
 - 0s - loss: 0.0083 - val_loss: 0.0091
 - val_f1: 0.9937
Epoch 86/300
 - 0s - loss: 0.0081 - val_loss: 0.0092
 - val_f1: 0.9933
Epoch 87/300
 - 0s - loss: 0.0079 - val_loss: 0.0091
 - val_f1: 0.9936
Epoch 88/300
 - 0s - loss: 0.0081 - val_loss: 0.0090
 - val_f1: 0.9933
Epoch 89/300
 - 0s - loss: 0.0078 - val_loss: 0.0090
 - val_f1: 0.9936
Epoch 90/300
 - 0s - loss: 0.0079 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 91/300
 - 0s - loss: 0.0079 - val_loss: 0.0089
2019-12-26 12:39:50,430 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/_model_epoch_90.pickle
 - val_f1: 0.9935
Epoch 92/300
 - 0s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 93/300
 - 0s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 94/300
 - 0s - loss: 0.0077 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 95/300
 - 0s - loss: 0.0075 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 96/300
 - 0s - loss: 0.0074 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 97/300
 - 0s - loss: 0.0072 - val_loss: 0.0088
 - val_f1: 0.9937
Epoch 98/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 99/300
 - 0s - loss: 0.0074 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 100/300
 - 0s - loss: 0.0072 - val_loss: 0.0088
 - val_f1: 0.9938
Epoch 101/300
 - 0s - loss: 0.0070 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 102/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9938
Epoch 103/300
 - 0s - loss: 0.0070 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 104/300
 - 0s - loss: 0.0068 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 105/300
 - 0s - loss: 0.0069 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 106/300
 - 0s - loss: 0.0070 - val_loss: 0.0087
 - val_f1: 0.9938
Epoch 107/300
 - 0s - loss: 0.0070 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 108/300
 - 0s - loss: 0.0067 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 109/300
 - 0s - loss: 0.0066 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 110/300
 - 0s - loss: 0.0066 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 111/300
 - 0s - loss: 0.0065 - val_loss: 0.0086
 - val_f1: 0.9940
Epoch 112/300
 - 0s - loss: 0.0064 - val_loss: 0.0085
 - val_f1: 0.9938
Epoch 113/300
 - 0s - loss: 0.0064 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 114/300
 - 0s - loss: 0.0065 - val_loss: 0.0086
 - val_f1: 0.9940
Epoch 115/300
 - 0s - loss: 0.0063 - val_loss: 0.0085
 - val_f1: 0.9939
Epoch 116/300
 - 0s - loss: 0.0064 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 117/300
 - 0s - loss: 0.0062 - val_loss: 0.0085
 - val_f1: 0.9938
Epoch 118/300
 - 0s - loss: 0.0064 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 119/300
 - 0s - loss: 0.0061 - val_loss: 0.0083
 - val_f1: 0.9940
Epoch 120/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 121/300
 - 0s - loss: 0.0061 - val_loss: 0.0084
2019-12-26 12:40:02,275 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/_model_epoch_120.pickle
 - val_f1: 0.9941
Epoch 122/300
 - 0s - loss: 0.0060 - val_loss: 0.0083
 - val_f1: 0.9940
Epoch 123/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 124/300
 - 0s - loss: 0.0059 - val_loss: 0.0083
 - val_f1: 0.9939
Epoch 125/300
 - 0s - loss: 0.0061 - val_loss: 0.0083
 - val_f1: 0.9939
Epoch 126/300
 - 0s - loss: 0.0058 - val_loss: 0.0082
 - val_f1: 0.9943
Epoch 127/300
 - 0s - loss: 0.0058 - val_loss: 0.0083
 - val_f1: 0.9937
Epoch 128/300
 - 0s - loss: 0.0055 - val_loss: 0.0084
 - val_f1: 0.9939
Epoch 129/300
 - 0s - loss: 0.0057 - val_loss: 0.0084
 - val_f1: 0.9943
Epoch 130/300
 - 0s - loss: 0.0058 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 131/300
 - 0s - loss: 0.0054 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 132/300
 - 0s - loss: 0.0056 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 133/300
 - 0s - loss: 0.0055 - val_loss: 0.0084
 - val_f1: 0.9939
Epoch 134/300
 - 0s - loss: 0.0056 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 135/300
 - 0s - loss: 0.0054 - val_loss: 0.0084
 - val_f1: 0.9941
Epoch 136/300
 - 0s - loss: 0.0054 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 137/300
 - 0s - loss: 0.0052 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 138/300
 - 0s - loss: 0.0053 - val_loss: 0.0085
 - val_f1: 0.9941
Epoch 139/300
 - 0s - loss: 0.0053 - val_loss: 0.0085
 - val_f1: 0.9937
Epoch 140/300
 - 0s - loss: 0.0052 - val_loss: 0.0082
 - val_f1: 0.9943
Epoch 141/300
 - 0s - loss: 0.0053 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 142/300
 - 0s - loss: 0.0052 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 143/300
 - 0s - loss: 0.0052 - val_loss: 0.0084
 - val_f1: 0.9943
Epoch 144/300
 - 0s - loss: 0.0051 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 145/300
 - 0s - loss: 0.0051 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 146/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9939
Epoch 147/300
 - 0s - loss: 0.0051 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 148/300
 - 0s - loss: 0.0052 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 149/300
 - 0s - loss: 0.0050 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 150/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9942
Epoch 151/300
 - 0s - loss: 0.0048 - val_loss: 0.0085
2019-12-26 12:40:14,131 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/_model_epoch_150.pickle
 - val_f1: 0.9939
Epoch 152/300
 - 0s - loss: 0.0049 - val_loss: 0.0084
 - val_f1: 0.9939
Epoch 153/300
 - 0s - loss: 0.0050 - val_loss: 0.0084
 - val_f1: 0.9939
Epoch 154/300
 - 0s - loss: 0.0050 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 155/300
 - 0s - loss: 0.0047 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 156/300
 - 0s - loss: 0.0049 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 157/300
 - 0s - loss: 0.0049 - val_loss: 0.0084
 - val_f1: 0.9944
Epoch 158/300
 - 0s - loss: 0.0046 - val_loss: 0.0088
 - val_f1: 0.9939
Epoch 159/300
 - 0s - loss: 0.0047 - val_loss: 0.0083
 - val_f1: 0.9943
Epoch 160/300
 - 0s - loss: 0.0046 - val_loss: 0.0085
 - val_f1: 0.9941
Epoch 161/300
 - 0s - loss: 0.0047 - val_loss: 0.0084
 - val_f1: 0.9942
Epoch 162/300
 - 0s - loss: 0.0046 - val_loss: 0.0084
 - val_f1: 0.9942
Epoch 163/300
 - 0s - loss: 0.0046 - val_loss: 0.0087
 - val_f1: 0.9942
Epoch 164/300
 - 0s - loss: 0.0045 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 165/300
 - 0s - loss: 0.0044 - val_loss: 0.0088
 - val_f1: 0.9938
Epoch 166/300
 - 0s - loss: 0.0045 - val_loss: 0.0087
 - val_f1: 0.9941
Epoch 167/300
 - 0s - loss: 0.0044 - val_loss: 0.0086
 - val_f1: 0.9944
Epoch 168/300
 - 0s - loss: 0.0044 - val_loss: 0.0087
 - val_f1: 0.9941
Epoch 169/300
 - 0s - loss: 0.0043 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 170/300
 - 0s - loss: 0.0042 - val_loss: 0.0086
 - val_f1: 0.9942
Epoch 171/300
 - 0s - loss: 0.0045 - val_loss: 0.0088
 - val_f1: 0.9943
Epoch 172/300
 - 0s - loss: 0.0043 - val_loss: 0.0089
 - val_f1: 0.9938
Epoch 173/300
 - 0s - loss: 0.0040 - val_loss: 0.0088
 - val_f1: 0.9940
Epoch 174/300
 - 0s - loss: 0.0041 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 175/300
 - 0s - loss: 0.0040 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 176/300
 - 0s - loss: 0.0040 - val_loss: 0.0086
2019-12-26 12:40:24,056 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 12:40:24,460 [INFO] Last epoch loss evaluation: train_loss = 0.003967, val_loss = 0.008216
2019-12-26 12:40:24,460 [INFO] Training complete. time_to_train = 72.40 sec, 1.21 min
2019-12-26 12:40:24,463 [INFO] Model saved to results_selected_models/selected_nsl_lstm_shallow_rep2/best_model.pickle
2019-12-26 12:40:24,466 [INFO] Training history saved to: results_selected_models/selected_nsl_lstm_shallow_rep2/training_error_history.csv
2019-12-26 12:40:24,611 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep2/training_error_history.png
2019-12-26 12:40:24,740 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep2/training_f1_history.png
2019-12-26 12:40:24,740 [INFO] Making predictions on training, validation, testing data
2019-12-26 12:40:25,092 [INFO] Evaluating predictions (results)
2019-12-26 12:40:25,402 [INFO] Dataset: Testing. Classification report below
2019-12-26 12:40:25,402 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.86      0.90      7450
      normal       0.69      0.93      0.79      9704
       probe       0.73      0.74      0.73      2420
         r2l       0.92      0.10      0.19      2421
         u2r       0.57      0.04      0.07       533

   micro avg       0.77      0.77      0.77     22528
   macro avg       0.77      0.53      0.54     22528
weighted avg       0.80      0.77      0.74     22528

2019-12-26 12:40:25,402 [INFO] Overall accuracy (micro avg): 0.7744140625
2019-12-26 12:40:25,756 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7744         0.7744                       0.7744                0.0564                   0.2256  0.7744
1     Macro avg        0.9098         0.7726                       0.5328                0.0746                   0.4672  0.5371
2  Weighted avg        0.8714         0.8039                       0.7744                0.1474                   0.2256  0.7398
2019-12-26 12:40:26,102 [INFO] Dataset: Validation. Classification report below
2019-12-26 12:40:26,102 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9183
      normal       1.00      1.00      1.00     13462
       probe       0.99      0.99      0.99      2330
         r2l       0.90      0.80      0.85       199
         u2r       0.83      0.50      0.62        10

   micro avg       0.99      0.99      0.99     25184
   macro avg       0.94      0.86      0.89     25184
weighted avg       0.99      0.99      0.99     25184

2019-12-26 12:40:26,102 [INFO] Overall accuracy (micro avg): 0.9944409148665819
2019-12-26 12:40:26,480 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9944         0.9944                       0.9944                0.0014                   0.0056  0.9944
1     Macro avg        0.9978         0.9433                       0.8576                0.0018                   0.1424  0.8916
2  Weighted avg        0.9966         0.9943                       0.9944                0.0036                   0.0056  0.9943
2019-12-26 12:40:27,986 [INFO] Dataset: Training. Classification report below
2019-12-26 12:40:27,986 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36738
      normal       1.00      1.00      1.00     53871
       probe       1.00      0.99      1.00      9321
         r2l       0.95      0.89      0.92       796
         u2r       1.00      0.60      0.75        42

   micro avg       1.00      1.00      1.00    100768
   macro avg       0.99      0.89      0.93    100768
weighted avg       1.00      1.00      1.00    100768

2019-12-26 12:40:27,986 [INFO] Overall accuracy (micro avg): 0.9972709590346142
2019-12-26 12:40:29,689 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9973         0.9973                       0.9973                0.0007                   0.0027  0.9973
1     Macro avg        0.9989         0.9883                       0.8949                0.0010                   0.1051  0.9311
2  Weighted avg        0.9983         0.9972                       0.9973                0.0021                   0.0027  0.9972
2019-12-26 12:40:29,708 [INFO] Results saved to: results_selected_models/selected_nsl_lstm_shallow_rep2/selected_nsl_lstm_shallow_rep2_results.xlsx
2019-12-26 12:40:29,709 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-26 12:40:29,712 [INFO] Created directory: results_selected_models/selected_nsl_lstm_shallow_rep3
2019-12-26 12:40:29,712 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_lstm_shallow_rep3/run_log.log
2019-12-26 12:40:29,712 [INFO] ================= Running experiment no. 3  ================= 

2019-12-26 12:40:29,712 [INFO] Experiment parameters given below
2019-12-26 12:40:29,712 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_nsl_lstm_shallow_rep3', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_lstm_shallow_rep3'}
2019-12-26 12:40:29,712 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_lstm_shallow_rep3/tf_logs_run_2019_12_26-12_40_29
2019-12-26 12:40:29,712 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 12:40:29,713 [INFO] Reading X, y files
2019-12-26 12:40:29,713 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 12:40:29,969 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 12:40:29,969 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 12:40:30,032 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:40:30,032 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 12:40:30,089 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:40:30,089 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 12:40:30,096 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 12:40:30,097 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 12:40:30,101 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:40:30,101 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 12:40:30,104 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:40:30,259 [INFO] Preparing flow sequences
2019-12-26 12:40:31,420 [INFO] Extracting flows complete. time_taken = 1.16 sec
2019-12-26 12:40:31,469 [INFO] Initializing model
2019-12-26 12:40:31,717 [INFO] _________________________________________________________________
2019-12-26 12:40:31,717 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:40:31,717 [INFO] =================================================================
2019-12-26 12:40:31,718 [INFO] lstm_3 (LSTM)                (None, 32, 32)            19840     
2019-12-26 12:40:31,718 [INFO] _________________________________________________________________
2019-12-26 12:40:31,718 [INFO] batch_normalization_3 (Batch (None, 32, 32)            128       
2019-12-26 12:40:31,718 [INFO] _________________________________________________________________
2019-12-26 12:40:31,718 [INFO] dropout_3 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:40:31,718 [INFO] _________________________________________________________________
2019-12-26 12:40:31,718 [INFO] time_distributed_3 (TimeDist (None, 32, 5)             165       
2019-12-26 12:40:31,718 [INFO] =================================================================
2019-12-26 12:40:31,718 [INFO] Total params: 20,133
2019-12-26 12:40:31,718 [INFO] Trainable params: 20,069
2019-12-26 12:40:31,718 [INFO] Non-trainable params: 64
2019-12-26 12:40:31,718 [INFO] _________________________________________________________________
2019-12-26 12:40:31,718 [INFO] Training model
 - val_f1: 0.9941
Epoch 00176: early stopping
Train on 3149 samples, validate on 787 samples
Epoch 1/300
 - 1s - loss: 0.5817 - val_loss: 0.4161
 - val_f1: 0.3475
Epoch 2/300
 - 0s - loss: 0.3934 - val_loss: 0.2830
 - val_f1: 0.6739
Epoch 3/300
 - 0s - loss: 0.2718 - val_loss: 0.1925
 - val_f1: 0.8382
Epoch 4/300
 - 0s - loss: 0.1834 - val_loss: 0.1273
 - val_f1: 0.9129
Epoch 5/300
 - 0s - loss: 0.1258 - val_loss: 0.0941
 - val_f1: 0.9422
Epoch 6/300
 - 0s - loss: 0.0948 - val_loss: 0.0776
 - val_f1: 0.9539
Epoch 7/300
 - 0s - loss: 0.0777 - val_loss: 0.0669
 - val_f1: 0.9601
Epoch 8/300
 - 0s - loss: 0.0674 - val_loss: 0.0595
 - val_f1: 0.9636
Epoch 9/300
 - 0s - loss: 0.0604 - val_loss: 0.0539
 - val_f1: 0.9658
Epoch 10/300
 - 0s - loss: 0.0549 - val_loss: 0.0491
 - val_f1: 0.9671
Epoch 11/300
 - 0s - loss: 0.0512 - val_loss: 0.0455
 - val_f1: 0.9686
Epoch 12/300
 - 0s - loss: 0.0478 - val_loss: 0.0427
 - val_f1: 0.9700
Epoch 13/300
 - 0s - loss: 0.0453 - val_loss: 0.0407
 - val_f1: 0.9712
Epoch 14/300
 - 0s - loss: 0.0429 - val_loss: 0.0388
 - val_f1: 0.9725
Epoch 15/300
 - 0s - loss: 0.0409 - val_loss: 0.0371
 - val_f1: 0.9730
Epoch 16/300
 - 0s - loss: 0.0393 - val_loss: 0.0357
 - val_f1: 0.9740
Epoch 17/300
 - 0s - loss: 0.0373 - val_loss: 0.0342
 - val_f1: 0.9750
Epoch 18/300
 - 0s - loss: 0.0359 - val_loss: 0.0329
 - val_f1: 0.9754
Epoch 19/300
 - 0s - loss: 0.0343 - val_loss: 0.0316
 - val_f1: 0.9767
Epoch 20/300
 - 0s - loss: 0.0329 - val_loss: 0.0304
 - val_f1: 0.9753
Epoch 21/300
 - 0s - loss: 0.0317 - val_loss: 0.0291
 - val_f1: 0.9784
Epoch 22/300
 - 0s - loss: 0.0300 - val_loss: 0.0277
 - val_f1: 0.9773
Epoch 23/300
 - 0s - loss: 0.0287 - val_loss: 0.0262
 - val_f1: 0.9787
Epoch 24/300
 - 0s - loss: 0.0274 - val_loss: 0.0251
 - val_f1: 0.9784
Epoch 25/300
 - 0s - loss: 0.0261 - val_loss: 0.0241
 - val_f1: 0.9792
Epoch 26/300
 - 0s - loss: 0.0247 - val_loss: 0.0231
 - val_f1: 0.9801
Epoch 27/300
 - 0s - loss: 0.0237 - val_loss: 0.0223
 - val_f1: 0.9804
Epoch 28/300
 - 0s - loss: 0.0224 - val_loss: 0.0213
 - val_f1: 0.9822
Epoch 29/300
 - 0s - loss: 0.0217 - val_loss: 0.0207
 - val_f1: 0.9816
Epoch 30/300
 - 0s - loss: 0.0205 - val_loss: 0.0199
 - val_f1: 0.9832
Epoch 31/300
 - 0s - loss: 0.0200 - val_loss: 0.0194
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 12:40:46,946 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/_model_epoch_30.pickle
 - val_f1: 0.9838
Epoch 32/300
 - 0s - loss: 0.0191 - val_loss: 0.0187
 - val_f1: 0.9839
Epoch 33/300
 - 0s - loss: 0.0186 - val_loss: 0.0181
 - val_f1: 0.9850
Epoch 34/300
 - 0s - loss: 0.0179 - val_loss: 0.0175
 - val_f1: 0.9858
Epoch 35/300
 - 0s - loss: 0.0175 - val_loss: 0.0171
 - val_f1: 0.9855
Epoch 36/300
 - 0s - loss: 0.0169 - val_loss: 0.0166
 - val_f1: 0.9869
Epoch 37/300
 - 0s - loss: 0.0164 - val_loss: 0.0161
 - val_f1: 0.9874
Epoch 38/300
 - 0s - loss: 0.0158 - val_loss: 0.0159
 - val_f1: 0.9876
Epoch 39/300
 - 0s - loss: 0.0155 - val_loss: 0.0154
 - val_f1: 0.9889
Epoch 40/300
 - 0s - loss: 0.0154 - val_loss: 0.0151
 - val_f1: 0.9891
Epoch 41/300
 - 0s - loss: 0.0147 - val_loss: 0.0148
 - val_f1: 0.9895
Epoch 42/300
 - 0s - loss: 0.0147 - val_loss: 0.0144
 - val_f1: 0.9900
Epoch 43/300
 - 0s - loss: 0.0142 - val_loss: 0.0140
 - val_f1: 0.9899
Epoch 44/300
 - 0s - loss: 0.0138 - val_loss: 0.0136
 - val_f1: 0.9908
Epoch 45/300
 - 0s - loss: 0.0135 - val_loss: 0.0130
 - val_f1: 0.9909
Epoch 46/300
 - 0s - loss: 0.0134 - val_loss: 0.0128
 - val_f1: 0.9909
Epoch 47/300
 - 0s - loss: 0.0130 - val_loss: 0.0127
 - val_f1: 0.9909
Epoch 48/300
 - 0s - loss: 0.0130 - val_loss: 0.0125
 - val_f1: 0.9911
Epoch 49/300
 - 0s - loss: 0.0126 - val_loss: 0.0122
 - val_f1: 0.9915
Epoch 50/300
 - 0s - loss: 0.0125 - val_loss: 0.0120
 - val_f1: 0.9917
Epoch 51/300
 - 0s - loss: 0.0124 - val_loss: 0.0119
 - val_f1: 0.9913
Epoch 52/300
 - 0s - loss: 0.0118 - val_loss: 0.0117
 - val_f1: 0.9916
Epoch 53/300
 - 0s - loss: 0.0116 - val_loss: 0.0115
 - val_f1: 0.9917
Epoch 54/300
 - 0s - loss: 0.0115 - val_loss: 0.0114
 - val_f1: 0.9918
Epoch 55/300
 - 0s - loss: 0.0112 - val_loss: 0.0114
 - val_f1: 0.9918
Epoch 56/300
 - 0s - loss: 0.0113 - val_loss: 0.0112
 - val_f1: 0.9919
Epoch 57/300
 - 0s - loss: 0.0111 - val_loss: 0.0113
 - val_f1: 0.9914
Epoch 58/300
 - 0s - loss: 0.0110 - val_loss: 0.0110
 - val_f1: 0.9918
Epoch 59/300
 - 0s - loss: 0.0108 - val_loss: 0.0109
 - val_f1: 0.9920
Epoch 60/300
 - 0s - loss: 0.0107 - val_loss: 0.0109
 - val_f1: 0.9919
Epoch 61/300
 - 0s - loss: 0.0106 - val_loss: 0.0108
2019-12-26 12:40:58,820 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/_model_epoch_60.pickle
 - val_f1: 0.9920
Epoch 62/300
 - 0s - loss: 0.0103 - val_loss: 0.0107
 - val_f1: 0.9921
Epoch 63/300
 - 0s - loss: 0.0100 - val_loss: 0.0107
 - val_f1: 0.9921
Epoch 64/300
 - 0s - loss: 0.0102 - val_loss: 0.0107
 - val_f1: 0.9923
Epoch 65/300
 - 0s - loss: 0.0097 - val_loss: 0.0104
 - val_f1: 0.9924
Epoch 66/300
 - 0s - loss: 0.0098 - val_loss: 0.0103
 - val_f1: 0.9925
Epoch 67/300
 - 0s - loss: 0.0096 - val_loss: 0.0101
 - val_f1: 0.9924
Epoch 68/300
 - 0s - loss: 0.0096 - val_loss: 0.0101
 - val_f1: 0.9924
Epoch 69/300
 - 0s - loss: 0.0097 - val_loss: 0.0101
 - val_f1: 0.9925
Epoch 70/300
 - 0s - loss: 0.0094 - val_loss: 0.0104
 - val_f1: 0.9922
Epoch 71/300
 - 0s - loss: 0.0094 - val_loss: 0.0102
 - val_f1: 0.9926
Epoch 72/300
 - 0s - loss: 0.0092 - val_loss: 0.0100
 - val_f1: 0.9925
Epoch 73/300
 - 0s - loss: 0.0089 - val_loss: 0.0100
 - val_f1: 0.9925
Epoch 74/300
 - 0s - loss: 0.0089 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 75/300
 - 0s - loss: 0.0092 - val_loss: 0.0100
 - val_f1: 0.9926
Epoch 76/300
 - 0s - loss: 0.0087 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 77/300
 - 0s - loss: 0.0088 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 78/300
 - 0s - loss: 0.0085 - val_loss: 0.0097
 - val_f1: 0.9926
Epoch 79/300
 - 0s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9928
Epoch 80/300
 - 0s - loss: 0.0086 - val_loss: 0.0098
 - val_f1: 0.9928
Epoch 81/300
 - 0s - loss: 0.0083 - val_loss: 0.0098
 - val_f1: 0.9927
Epoch 82/300
 - 0s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 83/300
 - 0s - loss: 0.0081 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 84/300
 - 0s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 85/300
 - 0s - loss: 0.0081 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 86/300
 - 0s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9930
Epoch 87/300
 - 0s - loss: 0.0079 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 88/300
 - 0s - loss: 0.0077 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 89/300
 - 0s - loss: 0.0076 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 90/300
 - 0s - loss: 0.0076 - val_loss: 0.0093
 - val_f1: 0.9929
Epoch 91/300
 - 0s - loss: 0.0073 - val_loss: 0.0095
2019-12-26 12:41:10,715 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/_model_epoch_90.pickle
 - val_f1: 0.9932
Epoch 92/300
 - 0s - loss: 0.0075 - val_loss: 0.0095
 - val_f1: 0.9932
Epoch 93/300
 - 0s - loss: 0.0074 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 94/300
 - 0s - loss: 0.0072 - val_loss: 0.0094
 - val_f1: 0.9934
Epoch 95/300
 - 0s - loss: 0.0071 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 96/300
 - 0s - loss: 0.0070 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 97/300
 - 0s - loss: 0.0072 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 98/300
 - 0s - loss: 0.0069 - val_loss: 0.0093
 - val_f1: 0.9932
Epoch 99/300
 - 0s - loss: 0.0070 - val_loss: 0.0094
 - val_f1: 0.9934
Epoch 100/300
 - 0s - loss: 0.0070 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 101/300
 - 0s - loss: 0.0069 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 102/300
 - 0s - loss: 0.0067 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 103/300
 - 0s - loss: 0.0067 - val_loss: 0.0095
 - val_f1: 0.9934
Epoch 104/300
 - 0s - loss: 0.0067 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 105/300
 - 0s - loss: 0.0068 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 106/300
 - 0s - loss: 0.0066 - val_loss: 0.0094
 - val_f1: 0.9934
Epoch 107/300
 - 0s - loss: 0.0065 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 108/300
 - 0s - loss: 0.0065 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 109/300
 - 0s - loss: 0.0066 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 110/300
 - 0s - loss: 0.0063 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 111/300
 - 0s - loss: 0.0064 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 112/300
 - 0s - loss: 0.0063 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 113/300
 - 0s - loss: 0.0063 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 114/300
 - 0s - loss: 0.0063 - val_loss: 0.0093
 - val_f1: 0.9937
Epoch 115/300
 - 0s - loss: 0.0062 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 116/300
 - 0s - loss: 0.0062 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 117/300
 - 0s - loss: 0.0061 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 118/300
 - 0s - loss: 0.0060 - val_loss: 0.0092
 - val_f1: 0.9938
Epoch 119/300
 - 0s - loss: 0.0059 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 120/300
 - 0s - loss: 0.0058 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 121/300
 - 0s - loss: 0.0058 - val_loss: 0.0094
2019-12-26 12:41:22,601 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/_model_epoch_120.pickle
 - val_f1: 0.9936
Epoch 122/300
 - 0s - loss: 0.0058 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 123/300
 - 0s - loss: 0.0057 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 124/300
 - 0s - loss: 0.0058 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 125/300
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 126/300
 - 0s - loss: 0.0057 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 127/300
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 128/300
 - 0s - loss: 0.0057 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 129/300
 - 0s - loss: 0.0055 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 130/300
 - 0s - loss: 0.0056 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 131/300
 - 0s - loss: 0.0056 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 132/300
 - 0s - loss: 0.0054 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 133/300
 - 0s - loss: 0.0053 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 134/300
 - 0s - loss: 0.0052 - val_loss: 0.0095
 - val_f1: 0.9938
Epoch 135/300
 - 0s - loss: 0.0053 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 136/300
 - 0s - loss: 0.0053 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 137/300
 - 0s - loss: 0.0050 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 138/300
 - 0s - loss: 0.0051 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 139/300
 - 0s - loss: 0.0051 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 140/300
 - 0s - loss: 0.0049 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 141/300
 - 0s - loss: 0.0050 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 142/300
 - 0s - loss: 0.0050 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 143/300
 - 0s - loss: 0.0050 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 144/300
 - 0s - loss: 0.0049 - val_loss: 0.0099
 - val_f1: 0.9934
Epoch 145/300
 - 0s - loss: 0.0049 - val_loss: 0.0100
 - val_f1: 0.9936
Epoch 146/300
 - 0s - loss: 0.0048 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 147/300
 - 0s - loss: 0.0046 - val_loss: 0.0097
 - val_f1: 0.9937
Epoch 148/300
 - 0s - loss: 0.0049 - val_loss: 0.0097
 - val_f1: 0.9939
Epoch 149/300
 - 0s - loss: 0.0048 - val_loss: 0.0097
 - val_f1: 0.9937
Epoch 150/300
 - 0s - loss: 0.0048 - val_loss: 0.0098
 - val_f1: 0.9937
Epoch 151/300
 - 0s - loss: 0.0046 - val_loss: 0.0097
2019-12-26 12:41:34,453 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/_model_epoch_150.pickle
 - val_f1: 0.9937
Epoch 152/300
 - 0s - loss: 0.0046 - val_loss: 0.0098
 - val_f1: 0.9939
Epoch 153/300
 - 0s - loss: 0.0047 - val_loss: 0.0100
 - val_f1: 0.9934
Epoch 154/300
 - 0s - loss: 0.0046 - val_loss: 0.0099
 - val_f1: 0.9935
Epoch 155/300
 - 0s - loss: 0.0044 - val_loss: 0.0098
 - val_f1: 0.9937
Epoch 156/300
 - 0s - loss: 0.0047 - val_loss: 0.0099
 - val_f1: 0.9937
Epoch 157/300
 - 0s - loss: 0.0047 - val_loss: 0.0101
 - val_f1: 0.9933
Epoch 158/300
 - 0s - loss: 0.0046 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 159/300
 - 0s - loss: 0.0046 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 160/300
 - 0s - loss: 0.0043 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 161/300
 - 0s - loss: 0.0045 - val_loss: 0.0100
 - val_f1: 0.9935
Epoch 162/300
 - 0s - loss: 0.0042 - val_loss: 0.0100
 - val_f1: 0.9936
Epoch 163/300
 - 0s - loss: 0.0041 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 164/300
 - 0s - loss: 0.0045 - val_loss: 0.0102
 - val_f1: 0.9936
Epoch 165/300
 - 0s - loss: 0.0042 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 166/300
 - 0s - loss: 0.0042 - val_loss: 0.0101
 - val_f1: 0.9935
Epoch 167/300
 - 0s - loss: 0.0041 - val_loss: 0.0103
 - val_f1: 0.9935
Epoch 168/300
 - 0s - loss: 0.0042 - val_loss: 0.0100
2019-12-26 12:41:41,240 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 12:41:41,702 [INFO] Last epoch loss evaluation: train_loss = 0.004187, val_loss = 0.009247
2019-12-26 12:41:41,702 [INFO] Training complete. time_to_train = 69.98 sec, 1.17 min
2019-12-26 12:41:41,706 [INFO] Model saved to results_selected_models/selected_nsl_lstm_shallow_rep3/best_model.pickle
2019-12-26 12:41:41,708 [INFO] Training history saved to: results_selected_models/selected_nsl_lstm_shallow_rep3/training_error_history.csv
2019-12-26 12:41:41,842 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep3/training_error_history.png
2019-12-26 12:41:41,967 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep3/training_f1_history.png
2019-12-26 12:41:41,968 [INFO] Making predictions on training, validation, testing data
2019-12-26 12:41:42,315 [INFO] Evaluating predictions (results)
2019-12-26 12:41:42,608 [INFO] Dataset: Testing. Classification report below
2019-12-26 12:41:42,608 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.85      0.90      7450
      normal       0.69      0.95      0.80      9704
       probe       0.76      0.72      0.74      2420
         r2l       0.95      0.09      0.17      2421
         u2r       0.62      0.03      0.06       533

   micro avg       0.78      0.78      0.78     22528
   macro avg       0.79      0.53      0.53     22528
weighted avg       0.81      0.78      0.74     22528

2019-12-26 12:41:42,608 [INFO] Overall accuracy (micro avg): 0.77587890625
2019-12-26 12:41:42,937 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7759         0.7759                       0.7759                0.0560                   0.2241  0.7759
1     Macro avg        0.9104         0.7933                       0.5264                0.0747                   0.4736  0.5307
2  Weighted avg        0.8725         0.8098                       0.7759                0.1496                   0.2241  0.7384
2019-12-26 12:41:43,279 [INFO] Dataset: Validation. Classification report below
2019-12-26 12:41:43,279 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9183
      normal       0.99      0.99      0.99     13462
       probe       0.99      0.98      0.99      2330
         r2l       0.87      0.84      0.85       199
         u2r       0.75      0.30      0.43        10

   micro avg       0.99      0.99      0.99     25184
   macro avg       0.92      0.82      0.85     25184
weighted avg       0.99      0.99      0.99     25184

2019-12-26 12:41:43,279 [INFO] Overall accuracy (micro avg): 0.9939247141041931
2019-12-26 12:41:43,660 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9939         0.9939                       0.9939                0.0015                   0.0061  0.9939
1     Macro avg        0.9976         0.9190                       0.8245                0.0020                   0.1755  0.8524
2  Weighted avg        0.9962         0.9938                       0.9939                0.0040                   0.0061  0.9938
2019-12-26 12:41:45,165 [INFO] Dataset: Training. Classification report below
2019-12-26 12:41:45,165 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36738
      normal       1.00      1.00      1.00     53871
       probe       1.00      0.99      0.99      9321
         r2l       0.94      0.91      0.92       796
         u2r       0.86      0.57      0.69        42

   micro avg       1.00      1.00      1.00    100768
   macro avg       0.96      0.89      0.92    100768
weighted avg       1.00      1.00      1.00    100768

2019-12-26 12:41:45,166 [INFO] Overall accuracy (micro avg): 0.9972511114639568
2019-12-26 12:41:46,869 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9973         0.9973                       0.9973                0.0007                   0.0027  0.9973
1     Macro avg        0.9989         0.9585                       0.8934                0.0010                   0.1066  0.9202
2  Weighted avg        0.9983         0.9972                       0.9973                0.0021                   0.0027  0.9972
2019-12-26 12:41:46,890 [INFO] Results saved to: results_selected_models/selected_nsl_lstm_shallow_rep3/selected_nsl_lstm_shallow_rep3_results.xlsx
2019-12-26 12:41:46,890 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-26 12:41:46,893 [INFO] Created directory: results_selected_models/selected_nsl_lstm_shallow_rep4
2019-12-26 12:41:46,893 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_lstm_shallow_rep4/run_log.log
2019-12-26 12:41:46,893 [INFO] ================= Running experiment no. 4  ================= 

2019-12-26 12:41:46,894 [INFO] Experiment parameters given below
2019-12-26 12:41:46,894 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_nsl_lstm_shallow_rep4', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_lstm_shallow_rep4'}
2019-12-26 12:41:46,894 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_lstm_shallow_rep4/tf_logs_run_2019_12_26-12_41_46
2019-12-26 12:41:46,894 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 12:41:46,894 [INFO] Reading X, y files
2019-12-26 12:41:46,894 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 12:41:47,152 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 12:41:47,152 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 12:41:47,216 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:41:47,216 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 12:41:47,278 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:41:47,278 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 12:41:47,286 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 12:41:47,286 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 12:41:47,290 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:41:47,290 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 12:41:47,294 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:41:47,454 [INFO] Preparing flow sequences
2019-12-26 12:41:48,623 [INFO] Extracting flows complete. time_taken = 1.17 sec
2019-12-26 12:41:48,673 [INFO] Initializing model
2019-12-26 12:41:48,916 [INFO] _________________________________________________________________
2019-12-26 12:41:48,916 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:41:48,916 [INFO] =================================================================
2019-12-26 12:41:48,916 [INFO] lstm_4 (LSTM)                (None, 32, 32)            19840     
2019-12-26 12:41:48,916 [INFO] _________________________________________________________________
2019-12-26 12:41:48,916 [INFO] batch_normalization_4 (Batch (None, 32, 32)            128       
2019-12-26 12:41:48,916 [INFO] _________________________________________________________________
2019-12-26 12:41:48,917 [INFO] dropout_4 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:41:48,917 [INFO] _________________________________________________________________
2019-12-26 12:41:48,917 [INFO] time_distributed_4 (TimeDist (None, 32, 5)             165       
2019-12-26 12:41:48,917 [INFO] =================================================================
2019-12-26 12:41:48,917 [INFO] Total params: 20,133
2019-12-26 12:41:48,917 [INFO] Trainable params: 20,069
2019-12-26 12:41:48,917 [INFO] Non-trainable params: 64
2019-12-26 12:41:48,917 [INFO] _________________________________________________________________
2019-12-26 12:41:48,917 [INFO] Training model
 - val_f1: 0.9938
Epoch 00168: early stopping
Train on 3149 samples, validate on 787 samples
Epoch 1/300
 - 1s - loss: 0.5769 - val_loss: 0.4032
 - val_f1: 0.3403
Epoch 2/300
 - 0s - loss: 0.3798 - val_loss: 0.2861
 - val_f1: 0.6314
Epoch 3/300
 - 0s - loss: 0.2702 - val_loss: 0.2279
 - val_f1: 0.7533
Epoch 4/300
 - 0s - loss: 0.1940 - val_loss: 0.1743
 - val_f1: 0.8563
Epoch 5/300
 - 0s - loss: 0.1445 - val_loss: 0.1342
 - val_f1: 0.9058
Epoch 6/300
 - 0s - loss: 0.1136 - val_loss: 0.1084
 - val_f1: 0.9289
Epoch 7/300
 - 0s - loss: 0.0962 - val_loss: 0.0913
 - val_f1: 0.9434
Epoch 8/300
 - 0s - loss: 0.0834 - val_loss: 0.0814
 - val_f1: 0.9506
Epoch 9/300
 - 0s - loss: 0.0755 - val_loss: 0.0732
 - val_f1: 0.9566
Epoch 10/300
 - 0s - loss: 0.0690 - val_loss: 0.0673
 - val_f1: 0.9602
Epoch 11/300
 - 0s - loss: 0.0640 - val_loss: 0.0627
 - val_f1: 0.9619
Epoch 12/300
 - 0s - loss: 0.0603 - val_loss: 0.0587
 - val_f1: 0.9637
Epoch 13/300
 - 0s - loss: 0.0567 - val_loss: 0.0552
 - val_f1: 0.9650
Epoch 14/300
 - 0s - loss: 0.0539 - val_loss: 0.0522
 - val_f1: 0.9657
Epoch 15/300
 - 0s - loss: 0.0510 - val_loss: 0.0494
 - val_f1: 0.9667
Epoch 16/300
 - 0s - loss: 0.0484 - val_loss: 0.0468
 - val_f1: 0.9677
Epoch 17/300
 - 0s - loss: 0.0469 - val_loss: 0.0451
 - val_f1: 0.9683
Epoch 18/300
 - 0s - loss: 0.0449 - val_loss: 0.0435
 - val_f1: 0.9688
Epoch 19/300
 - 0s - loss: 0.0429 - val_loss: 0.0417
 - val_f1: 0.9693
Epoch 20/300
 - 0s - loss: 0.0409 - val_loss: 0.0403
 - val_f1: 0.9693
Epoch 21/300
 - 0s - loss: 0.0395 - val_loss: 0.0391
 - val_f1: 0.9698
Epoch 22/300
 - 0s - loss: 0.0380 - val_loss: 0.0389
 - val_f1: 0.9695
Epoch 23/300
 - 0s - loss: 0.0371 - val_loss: 0.0383
 - val_f1: 0.9698
Epoch 24/300
 - 0s - loss: 0.0356 - val_loss: 0.0370
 - val_f1: 0.9701
Epoch 25/300
 - 0s - loss: 0.0343 - val_loss: 0.0359
 - val_f1: 0.9703
Epoch 26/300
 - 0s - loss: 0.0326 - val_loss: 0.0346
 - val_f1: 0.9706
Epoch 27/300
 - 0s - loss: 0.0314 - val_loss: 0.0335
 - val_f1: 0.9712
Epoch 28/300
 - 0s - loss: 0.0304 - val_loss: 0.0325
 - val_f1: 0.9712
Epoch 29/300
 - 0s - loss: 0.0290 - val_loss: 0.0314
 - val_f1: 0.9715
Epoch 30/300
 - 0s - loss: 0.0279 - val_loss: 0.0303
 - val_f1: 0.9726
Epoch 31/300
 - 0s - loss: 0.0270 - val_loss: 0.0293
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 12:42:04,521 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_30.pickle
 - val_f1: 0.9734
Epoch 32/300
 - 0s - loss: 0.0265 - val_loss: 0.0281
 - val_f1: 0.9742
Epoch 33/300
 - 0s - loss: 0.0252 - val_loss: 0.0270
 - val_f1: 0.9754
Epoch 34/300
 - 0s - loss: 0.0240 - val_loss: 0.0259
 - val_f1: 0.9769
Epoch 35/300
 - 0s - loss: 0.0227 - val_loss: 0.0248
 - val_f1: 0.9777
Epoch 36/300
 - 0s - loss: 0.0222 - val_loss: 0.0239
 - val_f1: 0.9786
Epoch 37/300
 - 0s - loss: 0.0215 - val_loss: 0.0229
 - val_f1: 0.9796
Epoch 38/300
 - 0s - loss: 0.0209 - val_loss: 0.0220
 - val_f1: 0.9802
Epoch 39/300
 - 0s - loss: 0.0201 - val_loss: 0.0213
 - val_f1: 0.9806
Epoch 40/300
 - 0s - loss: 0.0201 - val_loss: 0.0205
 - val_f1: 0.9818
Epoch 41/300
 - 0s - loss: 0.0192 - val_loss: 0.0199
 - val_f1: 0.9822
Epoch 42/300
 - 0s - loss: 0.0188 - val_loss: 0.0193
 - val_f1: 0.9828
Epoch 43/300
 - 0s - loss: 0.0183 - val_loss: 0.0187
 - val_f1: 0.9836
Epoch 44/300
 - 0s - loss: 0.0176 - val_loss: 0.0183
 - val_f1: 0.9841
Epoch 45/300
 - 0s - loss: 0.0176 - val_loss: 0.0178
 - val_f1: 0.9842
Epoch 46/300
 - 0s - loss: 0.0171 - val_loss: 0.0174
 - val_f1: 0.9848
Epoch 47/300
 - 0s - loss: 0.0169 - val_loss: 0.0169
 - val_f1: 0.9855
Epoch 48/300
 - 0s - loss: 0.0163 - val_loss: 0.0165
 - val_f1: 0.9863
Epoch 49/300
 - 0s - loss: 0.0161 - val_loss: 0.0162
 - val_f1: 0.9864
Epoch 50/300
 - 0s - loss: 0.0157 - val_loss: 0.0159
 - val_f1: 0.9864
Epoch 51/300
 - 0s - loss: 0.0153 - val_loss: 0.0156
 - val_f1: 0.9870
Epoch 52/300
 - 0s - loss: 0.0156 - val_loss: 0.0154
 - val_f1: 0.9872
Epoch 53/300
 - 0s - loss: 0.0148 - val_loss: 0.0151
 - val_f1: 0.9873
Epoch 54/300
 - 0s - loss: 0.0148 - val_loss: 0.0149
 - val_f1: 0.9875
Epoch 55/300
 - 0s - loss: 0.0143 - val_loss: 0.0146
 - val_f1: 0.9882
Epoch 56/300
 - 0s - loss: 0.0143 - val_loss: 0.0143
 - val_f1: 0.9884
Epoch 57/300
 - 0s - loss: 0.0141 - val_loss: 0.0140
 - val_f1: 0.9887
Epoch 58/300
 - 0s - loss: 0.0139 - val_loss: 0.0138
 - val_f1: 0.9890
Epoch 59/300
 - 0s - loss: 0.0137 - val_loss: 0.0135
 - val_f1: 0.9894
Epoch 60/300
 - 0s - loss: 0.0131 - val_loss: 0.0134
 - val_f1: 0.9898
Epoch 61/300
 - 0s - loss: 0.0129 - val_loss: 0.0134
2019-12-26 12:42:16,435 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_60.pickle
 - val_f1: 0.9896
Epoch 62/300
 - 0s - loss: 0.0126 - val_loss: 0.0132
 - val_f1: 0.9897
Epoch 63/300
 - 0s - loss: 0.0124 - val_loss: 0.0129
 - val_f1: 0.9900
Epoch 64/300
 - 0s - loss: 0.0122 - val_loss: 0.0130
 - val_f1: 0.9895
Epoch 65/300
 - 0s - loss: 0.0121 - val_loss: 0.0126
 - val_f1: 0.9907
Epoch 66/300
 - 0s - loss: 0.0118 - val_loss: 0.0128
 - val_f1: 0.9896
Epoch 67/300
 - 0s - loss: 0.0119 - val_loss: 0.0123
 - val_f1: 0.9910
Epoch 68/300
 - 0s - loss: 0.0117 - val_loss: 0.0124
 - val_f1: 0.9905
Epoch 69/300
 - 0s - loss: 0.0114 - val_loss: 0.0123
 - val_f1: 0.9909
Epoch 70/300
 - 0s - loss: 0.0111 - val_loss: 0.0121
 - val_f1: 0.9910
Epoch 71/300
 - 0s - loss: 0.0109 - val_loss: 0.0120
 - val_f1: 0.9908
Epoch 72/300
 - 0s - loss: 0.0111 - val_loss: 0.0119
 - val_f1: 0.9912
Epoch 73/300
 - 0s - loss: 0.0109 - val_loss: 0.0117
 - val_f1: 0.9916
Epoch 74/300
 - 0s - loss: 0.0109 - val_loss: 0.0117
 - val_f1: 0.9914
Epoch 75/300
 - 0s - loss: 0.0107 - val_loss: 0.0116
 - val_f1: 0.9915
Epoch 76/300
 - 0s - loss: 0.0107 - val_loss: 0.0115
 - val_f1: 0.9917
Epoch 77/300
 - 0s - loss: 0.0105 - val_loss: 0.0115
 - val_f1: 0.9910
Epoch 78/300
 - 0s - loss: 0.0103 - val_loss: 0.0112
 - val_f1: 0.9919
Epoch 79/300
 - 0s - loss: 0.0103 - val_loss: 0.0112
 - val_f1: 0.9914
Epoch 80/300
 - 0s - loss: 0.0103 - val_loss: 0.0109
 - val_f1: 0.9921
Epoch 81/300
 - 0s - loss: 0.0100 - val_loss: 0.0110
 - val_f1: 0.9920
Epoch 82/300
 - 0s - loss: 0.0101 - val_loss: 0.0107
 - val_f1: 0.9924
Epoch 83/300
 - 0s - loss: 0.0099 - val_loss: 0.0107
 - val_f1: 0.9920
Epoch 84/300
 - 0s - loss: 0.0095 - val_loss: 0.0106
 - val_f1: 0.9922
Epoch 85/300
 - 0s - loss: 0.0097 - val_loss: 0.0105
 - val_f1: 0.9925
Epoch 86/300
 - 0s - loss: 0.0095 - val_loss: 0.0104
 - val_f1: 0.9925
Epoch 87/300
 - 0s - loss: 0.0094 - val_loss: 0.0103
 - val_f1: 0.9922
Epoch 88/300
 - 0s - loss: 0.0096 - val_loss: 0.0102
 - val_f1: 0.9926
Epoch 89/300
 - 0s - loss: 0.0094 - val_loss: 0.0101
 - val_f1: 0.9928
Epoch 90/300
 - 0s - loss: 0.0092 - val_loss: 0.0100
 - val_f1: 0.9925
Epoch 91/300
 - 0s - loss: 0.0091 - val_loss: 0.0100
2019-12-26 12:42:28,316 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_90.pickle
 - val_f1: 0.9929
Epoch 92/300
 - 0s - loss: 0.0090 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 93/300
 - 0s - loss: 0.0088 - val_loss: 0.0100
 - val_f1: 0.9924
Epoch 94/300
 - 0s - loss: 0.0088 - val_loss: 0.0098
 - val_f1: 0.9927
Epoch 95/300
 - 0s - loss: 0.0087 - val_loss: 0.0097
 - val_f1: 0.9928
Epoch 96/300
 - 0s - loss: 0.0088 - val_loss: 0.0097
 - val_f1: 0.9928
Epoch 97/300
 - 0s - loss: 0.0088 - val_loss: 0.0096
 - val_f1: 0.9925
Epoch 98/300
 - 0s - loss: 0.0086 - val_loss: 0.0095
 - val_f1: 0.9928
Epoch 99/300
 - 0s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 100/300
 - 0s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 101/300
 - 0s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 102/300
 - 0s - loss: 0.0082 - val_loss: 0.0093
 - val_f1: 0.9928
Epoch 103/300
 - 0s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9930
Epoch 104/300
 - 0s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9931
Epoch 105/300
 - 0s - loss: 0.0081 - val_loss: 0.0092
 - val_f1: 0.9930
Epoch 106/300
 - 0s - loss: 0.0080 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 107/300
 - 0s - loss: 0.0079 - val_loss: 0.0092
 - val_f1: 0.9930
Epoch 108/300
 - 0s - loss: 0.0081 - val_loss: 0.0093
 - val_f1: 0.9933
Epoch 109/300
 - 0s - loss: 0.0079 - val_loss: 0.0091
 - val_f1: 0.9931
Epoch 110/300
 - 0s - loss: 0.0077 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 111/300
 - 0s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9928
Epoch 112/300
 - 0s - loss: 0.0080 - val_loss: 0.0090
 - val_f1: 0.9931
Epoch 113/300
 - 0s - loss: 0.0075 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 114/300
 - 0s - loss: 0.0074 - val_loss: 0.0089
 - val_f1: 0.9931
Epoch 115/300
 - 0s - loss: 0.0076 - val_loss: 0.0089
 - val_f1: 0.9932
Epoch 116/300
 - 0s - loss: 0.0076 - val_loss: 0.0088
 - val_f1: 0.9933
Epoch 117/300
 - 0s - loss: 0.0074 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 118/300
 - 0s - loss: 0.0075 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 119/300
 - 0s - loss: 0.0076 - val_loss: 0.0091
 - val_f1: 0.9928
Epoch 120/300
 - 0s - loss: 0.0074 - val_loss: 0.0087
 - val_f1: 0.9935
Epoch 121/300
 - 0s - loss: 0.0073 - val_loss: 0.0086
2019-12-26 12:42:40,219 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_120.pickle
 - val_f1: 0.9934
Epoch 122/300
 - 0s - loss: 0.0071 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 123/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9932
Epoch 124/300
 - 0s - loss: 0.0073 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 125/300
 - 0s - loss: 0.0070 - val_loss: 0.0086
 - val_f1: 0.9932
Epoch 126/300
 - 0s - loss: 0.0070 - val_loss: 0.0087
 - val_f1: 0.9930
Epoch 127/300
 - 0s - loss: 0.0068 - val_loss: 0.0086
 - val_f1: 0.9933
Epoch 128/300
 - 0s - loss: 0.0070 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 129/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9933
Epoch 130/300
 - 0s - loss: 0.0068 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 131/300
 - 0s - loss: 0.0067 - val_loss: 0.0086
 - val_f1: 0.9935
Epoch 132/300
 - 0s - loss: 0.0067 - val_loss: 0.0085
 - val_f1: 0.9934
Epoch 133/300
 - 0s - loss: 0.0065 - val_loss: 0.0085
 - val_f1: 0.9931
Epoch 134/300
 - 0s - loss: 0.0066 - val_loss: 0.0086
 - val_f1: 0.9931
Epoch 135/300
 - 0s - loss: 0.0065 - val_loss: 0.0087
 - val_f1: 0.9928
Epoch 136/300
 - 0s - loss: 0.0068 - val_loss: 0.0086
 - val_f1: 0.9932
Epoch 137/300
 - 0s - loss: 0.0065 - val_loss: 0.0086
 - val_f1: 0.9928
Epoch 138/300
 - 0s - loss: 0.0062 - val_loss: 0.0085
 - val_f1: 0.9934
Epoch 139/300
 - 0s - loss: 0.0064 - val_loss: 0.0085
 - val_f1: 0.9933
Epoch 140/300
 - 0s - loss: 0.0063 - val_loss: 0.0085
 - val_f1: 0.9936
Epoch 141/300
 - 0s - loss: 0.0065 - val_loss: 0.0086
 - val_f1: 0.9929
Epoch 142/300
 - 0s - loss: 0.0061 - val_loss: 0.0086
 - val_f1: 0.9929
Epoch 143/300
 - 0s - loss: 0.0065 - val_loss: 0.0086
 - val_f1: 0.9936
Epoch 144/300
 - 0s - loss: 0.0063 - val_loss: 0.0085
 - val_f1: 0.9933
Epoch 145/300
 - 0s - loss: 0.0062 - val_loss: 0.0087
 - val_f1: 0.9927
Epoch 146/300
 - 0s - loss: 0.0063 - val_loss: 0.0088
 - val_f1: 0.9930
Epoch 147/300
 - 0s - loss: 0.0061 - val_loss: 0.0085
 - val_f1: 0.9933
Epoch 148/300
 - 0s - loss: 0.0060 - val_loss: 0.0085
 - val_f1: 0.9933
Epoch 149/300
 - 0s - loss: 0.0062 - val_loss: 0.0086
 - val_f1: 0.9929
Epoch 150/300
 - 0s - loss: 0.0061 - val_loss: 0.0085
 - val_f1: 0.9934
Epoch 151/300
 - 0s - loss: 0.0061 - val_loss: 0.0085
2019-12-26 12:42:52,113 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_150.pickle
 - val_f1: 0.9935
Epoch 152/300
 - 0s - loss: 0.0059 - val_loss: 0.0085
 - val_f1: 0.9931
Epoch 153/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 154/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9932
Epoch 155/300
 - 0s - loss: 0.0059 - val_loss: 0.0085
 - val_f1: 0.9930
Epoch 156/300
 - 0s - loss: 0.0060 - val_loss: 0.0084
 - val_f1: 0.9932
Epoch 157/300
 - 0s - loss: 0.0056 - val_loss: 0.0084
 - val_f1: 0.9931
Epoch 158/300
 - 0s - loss: 0.0057 - val_loss: 0.0084
 - val_f1: 0.9931
Epoch 159/300
 - 0s - loss: 0.0057 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 160/300
 - 0s - loss: 0.0059 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 161/300
 - 0s - loss: 0.0055 - val_loss: 0.0082
 - val_f1: 0.9936
Epoch 162/300
 - 0s - loss: 0.0055 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 163/300
 - 0s - loss: 0.0056 - val_loss: 0.0083
 - val_f1: 0.9937
Epoch 164/300
 - 0s - loss: 0.0055 - val_loss: 0.0084
 - val_f1: 0.9931
Epoch 165/300
 - 0s - loss: 0.0055 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 166/300
 - 0s - loss: 0.0055 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 167/300
 - 0s - loss: 0.0053 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 168/300
 - 0s - loss: 0.0055 - val_loss: 0.0085
 - val_f1: 0.9932
Epoch 169/300
 - 0s - loss: 0.0052 - val_loss: 0.0083
 - val_f1: 0.9938
Epoch 170/300
 - 0s - loss: 0.0054 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 171/300
 - 0s - loss: 0.0052 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 172/300
 - 0s - loss: 0.0052 - val_loss: 0.0083
 - val_f1: 0.9932
Epoch 173/300
 - 0s - loss: 0.0053 - val_loss: 0.0083
 - val_f1: 0.9936
Epoch 174/300
 - 0s - loss: 0.0050 - val_loss: 0.0083
 - val_f1: 0.9937
Epoch 175/300
 - 0s - loss: 0.0051 - val_loss: 0.0083
 - val_f1: 0.9933
Epoch 176/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9933
Epoch 177/300
 - 0s - loss: 0.0051 - val_loss: 0.0085
 - val_f1: 0.9935
Epoch 178/300
 - 0s - loss: 0.0051 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 179/300
 - 0s - loss: 0.0050 - val_loss: 0.0084
 - val_f1: 0.9929
Epoch 180/300
 - 0s - loss: 0.0048 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 181/300
 - 0s - loss: 0.0049 - val_loss: 0.0083
2019-12-26 12:43:04,037 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_180.pickle
 - val_f1: 0.9937
Epoch 182/300
 - 0s - loss: 0.0051 - val_loss: 0.0084
 - val_f1: 0.9935
Epoch 183/300
 - 0s - loss: 0.0049 - val_loss: 0.0084
 - val_f1: 0.9934
Epoch 184/300
 - 0s - loss: 0.0048 - val_loss: 0.0082
 - val_f1: 0.9932
Epoch 185/300
 - 0s - loss: 0.0048 - val_loss: 0.0083
 - val_f1: 0.9929
Epoch 186/300
 - 0s - loss: 0.0050 - val_loss: 0.0083
 - val_f1: 0.9932
Epoch 187/300
 - 0s - loss: 0.0048 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 188/300
 - 0s - loss: 0.0046 - val_loss: 0.0084
 - val_f1: 0.9932
Epoch 189/300
 - 0s - loss: 0.0048 - val_loss: 0.0085
 - val_f1: 0.9936
Epoch 190/300
 - 0s - loss: 0.0048 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 191/300
 - 0s - loss: 0.0047 - val_loss: 0.0083
 - val_f1: 0.9934
Epoch 192/300
 - 0s - loss: 0.0045 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 193/300
 - 0s - loss: 0.0048 - val_loss: 0.0085
 - val_f1: 0.9932
Epoch 194/300
 - 0s - loss: 0.0046 - val_loss: 0.0083
 - val_f1: 0.9934
Epoch 195/300
 - 0s - loss: 0.0047 - val_loss: 0.0083
 - val_f1: 0.9935
Epoch 196/300
 - 0s - loss: 0.0044 - val_loss: 0.0085
 - val_f1: 0.9935
Epoch 197/300
 - 0s - loss: 0.0046 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 198/300
 - 0s - loss: 0.0044 - val_loss: 0.0086
 - val_f1: 0.9934
Epoch 199/300
 - 0s - loss: 0.0046 - val_loss: 0.0084
 - val_f1: 0.9937
Epoch 200/300
 - 0s - loss: 0.0045 - val_loss: 0.0084
 - val_f1: 0.9936
Epoch 201/300
 - 0s - loss: 0.0046 - val_loss: 0.0084
 - val_f1: 0.9935
Epoch 202/300
 - 0s - loss: 0.0042 - val_loss: 0.0086
 - val_f1: 0.9931
Epoch 203/300
 - 0s - loss: 0.0044 - val_loss: 0.0084
 - val_f1: 0.9937
Epoch 204/300
 - 0s - loss: 0.0043 - val_loss: 0.0084
 - val_f1: 0.9937
Epoch 205/300
 - 0s - loss: 0.0044 - val_loss: 0.0083
 - val_f1: 0.9933
Epoch 206/300
 - 0s - loss: 0.0043 - val_loss: 0.0085
 - val_f1: 0.9932
Epoch 207/300
 - 0s - loss: 0.0043 - val_loss: 0.0084
 - val_f1: 0.9935
Epoch 208/300
 - 0s - loss: 0.0043 - val_loss: 0.0084
 - val_f1: 0.9932
Epoch 209/300
 - 0s - loss: 0.0042 - val_loss: 0.0085
 - val_f1: 0.9937
Epoch 210/300
 - 0s - loss: 0.0042 - val_loss: 0.0085
 - val_f1: 0.9936
Epoch 211/300
 - 0s - loss: 0.0040 - val_loss: 0.0086
2019-12-26 12:43:15,938 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/_model_epoch_210.pickle
2019-12-26 12:43:16,007 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 12:43:16,536 [INFO] Last epoch loss evaluation: train_loss = 0.003766, val_loss = 0.008202
2019-12-26 12:43:16,536 [INFO] Training complete. time_to_train = 87.62 sec, 1.46 min
2019-12-26 12:43:16,540 [INFO] Model saved to results_selected_models/selected_nsl_lstm_shallow_rep4/best_model.pickle
2019-12-26 12:43:16,543 [INFO] Training history saved to: results_selected_models/selected_nsl_lstm_shallow_rep4/training_error_history.csv
2019-12-26 12:43:16,671 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep4/training_error_history.png
2019-12-26 12:43:16,788 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep4/training_f1_history.png
2019-12-26 12:43:16,788 [INFO] Making predictions on training, validation, testing data
2019-12-26 12:43:17,142 [INFO] Evaluating predictions (results)
2019-12-26 12:43:17,451 [INFO] Dataset: Testing. Classification report below
2019-12-26 12:43:17,451 [INFO] 
              precision    recall  f1-score   support

         dos       0.93      0.84      0.88      7450
      normal       0.68      0.93      0.79      9704
       probe       0.78      0.69      0.73      2420
         r2l       0.82      0.12      0.21      2421
         u2r       0.67      0.03      0.06       533

   micro avg       0.77      0.77      0.77     22528
   macro avg       0.78      0.52      0.53     22528
weighted avg       0.79      0.77      0.73     22528

2019-12-26 12:43:17,451 [INFO] Overall accuracy (micro avg): 0.7673561789772727
2019-12-26 12:43:17,786 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7674         0.7674                       0.7674                0.0582                   0.2326  0.7674
1     Macro avg        0.9069         0.7757                       0.5221                0.0775                   0.4779  0.5333
2  Weighted avg        0.8656         0.7882                       0.7674                0.1549                   0.2326  0.7335
2019-12-26 12:43:18,129 [INFO] Dataset: Validation. Classification report below
2019-12-26 12:43:18,129 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9183
      normal       0.99      0.99      0.99     13462
       probe       0.98      0.99      0.99      2330
         r2l       0.90      0.82      0.86       199
         u2r       1.00      0.40      0.57        10

   micro avg       0.99      0.99      0.99     25184
   macro avg       0.98      0.84      0.88     25184
weighted avg       0.99      0.99      0.99     25184

2019-12-26 12:43:18,129 [INFO] Overall accuracy (micro avg): 0.9938055908513341
2019-12-26 12:43:18,508 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9938         0.9938                       0.9938                0.0015                   0.0062  0.9938
1     Macro avg        0.9975         0.9754                       0.8396                0.0021                   0.1604  0.8814
2  Weighted avg        0.9961         0.9937                       0.9938                0.0043                   0.0062  0.9937
2019-12-26 12:43:20,018 [INFO] Dataset: Training. Classification report below
2019-12-26 12:43:20,018 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36738
      normal       1.00      1.00      1.00     53871
       probe       1.00      0.99      1.00      9321
         r2l       0.95      0.90      0.93       796
         u2r       0.96      0.62      0.75        42

   micro avg       1.00      1.00      1.00    100768
   macro avg       0.98      0.90      0.93    100768
weighted avg       1.00      1.00      1.00    100768

2019-12-26 12:43:20,018 [INFO] Overall accuracy (micro avg): 0.9975389012384884
2019-12-26 12:43:21,727 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9975         0.9975                       0.9975                0.0006                   0.0025  0.9975
1     Macro avg        0.9990         0.9811                       0.9027                0.0009                   0.0973  0.9343
2  Weighted avg        0.9985         0.9975                       0.9975                0.0019                   0.0025  0.9975
2019-12-26 12:43:21,748 [INFO] Results saved to: results_selected_models/selected_nsl_lstm_shallow_rep4/selected_nsl_lstm_shallow_rep4_results.xlsx
2019-12-26 12:43:21,748 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-26 12:43:21,752 [INFO] Created directory: results_selected_models/selected_nsl_lstm_shallow_rep5
2019-12-26 12:43:21,752 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_lstm_shallow_rep5/run_log.log
2019-12-26 12:43:21,752 [INFO] ================= Running experiment no. 5  ================= 

2019-12-26 12:43:21,752 [INFO] Experiment parameters given below
2019-12-26 12:43:21,752 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_nsl_lstm_shallow_rep5', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_lstm_shallow_rep5'}
2019-12-26 12:43:21,752 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_lstm_shallow_rep5/tf_logs_run_2019_12_26-12_43_21
2019-12-26 12:43:21,753 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-26 12:43:21,753 [INFO] Reading X, y files
2019-12-26 12:43:21,753 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-26 12:43:22,011 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 12:43:22,012 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-26 12:43:22,079 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 12:43:22,079 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-26 12:43:22,142 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-26 12:43:22,142 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-26 12:43:22,150 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-26 12:43:22,150 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-26 12:43:22,154 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:43:22,154 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-26 12:43:22,158 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-26 12:43:22,310 [INFO] Preparing flow sequences
2019-12-26 12:43:23,473 [INFO] Extracting flows complete. time_taken = 1.16 sec
2019-12-26 12:43:23,523 [INFO] Initializing model
2019-12-26 12:43:23,868 [INFO] _________________________________________________________________
2019-12-26 12:43:23,868 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:43:23,868 [INFO] =================================================================
2019-12-26 12:43:23,868 [INFO] lstm_5 (LSTM)                (None, 32, 32)            19840     
2019-12-26 12:43:23,869 [INFO] _________________________________________________________________
2019-12-26 12:43:23,869 [INFO] batch_normalization_5 (Batch (None, 32, 32)            128       
2019-12-26 12:43:23,869 [INFO] _________________________________________________________________
2019-12-26 12:43:23,869 [INFO] dropout_5 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:43:23,869 [INFO] _________________________________________________________________
2019-12-26 12:43:23,869 [INFO] time_distributed_5 (TimeDist (None, 32, 5)             165       
2019-12-26 12:43:23,869 [INFO] =================================================================
2019-12-26 12:43:23,869 [INFO] Total params: 20,133
2019-12-26 12:43:23,869 [INFO] Trainable params: 20,069
2019-12-26 12:43:23,869 [INFO] Non-trainable params: 64
2019-12-26 12:43:23,869 [INFO] _________________________________________________________________
2019-12-26 12:43:23,869 [INFO] Training model
 - val_f1: 0.9936
Epoch 00211: early stopping
Train on 3149 samples, validate on 787 samples
Epoch 1/300
 - 1s - loss: 0.5074 - val_loss: 0.3818
 - val_f1: 0.3385
Epoch 2/300
 - 0s - loss: 0.3497 - val_loss: 0.2594
 - val_f1: 0.7140
Epoch 3/300
 - 0s - loss: 0.2385 - val_loss: 0.1666
 - val_f1: 0.8826
Epoch 4/300
 - 0s - loss: 0.1600 - val_loss: 0.1076
 - val_f1: 0.9330
Epoch 5/300
 - 0s - loss: 0.1129 - val_loss: 0.0848
 - val_f1: 0.9491
Epoch 6/300
 - 0s - loss: 0.0881 - val_loss: 0.0731
 - val_f1: 0.9586
Epoch 7/300
 - 0s - loss: 0.0734 - val_loss: 0.0647
 - val_f1: 0.9633
Epoch 8/300
 - 0s - loss: 0.0653 - val_loss: 0.0586
 - val_f1: 0.9657
Epoch 9/300
 - 0s - loss: 0.0600 - val_loss: 0.0542
 - val_f1: 0.9669
Epoch 10/300
 - 0s - loss: 0.0555 - val_loss: 0.0503
 - val_f1: 0.9673
Epoch 11/300
 - 0s - loss: 0.0521 - val_loss: 0.0472
 - val_f1: 0.9685
Epoch 12/300
 - 0s - loss: 0.0490 - val_loss: 0.0445
 - val_f1: 0.9696
Epoch 13/300
 - 0s - loss: 0.0467 - val_loss: 0.0421
 - val_f1: 0.9706
Epoch 14/300
 - 0s - loss: 0.0446 - val_loss: 0.0402
 - val_f1: 0.9716
Epoch 15/300
 - 0s - loss: 0.0425 - val_loss: 0.0385
 - val_f1: 0.9723
Epoch 16/300
 - 0s - loss: 0.0407 - val_loss: 0.0369
 - val_f1: 0.9729
Epoch 17/300
 - 0s - loss: 0.0392 - val_loss: 0.0356
 - val_f1: 0.9735
Epoch 18/300
 - 0s - loss: 0.0376 - val_loss: 0.0344
 - val_f1: 0.9736
Epoch 19/300
 - 0s - loss: 0.0361 - val_loss: 0.0332
 - val_f1: 0.9743
Epoch 20/300
 - 0s - loss: 0.0348 - val_loss: 0.0321
 - val_f1: 0.9751
Epoch 21/300
 - 0s - loss: 0.0339 - val_loss: 0.0311
 - val_f1: 0.9757
Epoch 22/300
 - 0s - loss: 0.0324 - val_loss: 0.0300
 - val_f1: 0.9758
Epoch 23/300
 - 0s - loss: 0.0309 - val_loss: 0.0290
 - val_f1: 0.9767
Epoch 24/300
 - 0s - loss: 0.0299 - val_loss: 0.0279
 - val_f1: 0.9770
Epoch 25/300
 - 0s - loss: 0.0282 - val_loss: 0.0268
 - val_f1: 0.9774
Epoch 26/300
 - 0s - loss: 0.0273 - val_loss: 0.0257
 - val_f1: 0.9781
Epoch 27/300
 - 0s - loss: 0.0258 - val_loss: 0.0246
 - val_f1: 0.9782
Epoch 28/300
 - 0s - loss: 0.0245 - val_loss: 0.0233
 - val_f1: 0.9794
Epoch 29/300
 - 0s - loss: 0.0233 - val_loss: 0.0222
 - val_f1: 0.9800
Epoch 30/300
 - 0s - loss: 0.0221 - val_loss: 0.0207
 - val_f1: 0.9810
Epoch 31/300
 - 0s - loss: 0.0207 - val_loss: 0.0197
2019-12-26 12:43:40,037 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep5/_model_epoch_30.pickle
 - val_f1: 0.9823
Epoch 32/300
 - 0s - loss: 0.0199 - val_loss: 0.0188
 - val_f1: 0.9830
Epoch 33/300
 - 0s - loss: 0.0189 - val_loss: 0.0179
 - val_f1: 0.9841
Epoch 34/300
 - 0s - loss: 0.0181 - val_loss: 0.0172
 - val_f1: 0.9842
Epoch 35/300
 - 0s - loss: 0.0173 - val_loss: 0.0164
 - val_f1: 0.9862
Epoch 36/300
 - 0s - loss: 0.0166 - val_loss: 0.0159
 - val_f1: 0.9860
Epoch 37/300
 - 0s - loss: 0.0160 - val_loss: 0.0152
 - val_f1: 0.9869
Epoch 38/300
 - 0s - loss: 0.0157 - val_loss: 0.0146
 - val_f1: 0.9879
Epoch 39/300
 - 0s - loss: 0.0152 - val_loss: 0.0143
 - val_f1: 0.9872
Epoch 40/300
 - 0s - loss: 0.0145 - val_loss: 0.0137
 - val_f1: 0.9892
Epoch 41/300
 - 0s - loss: 0.0144 - val_loss: 0.0134
 - val_f1: 0.9885
Epoch 42/300
 - 0s - loss: 0.0140 - val_loss: 0.0129
 - val_f1: 0.9899
Epoch 43/300
 - 0s - loss: 0.0136 - val_loss: 0.0126
 - val_f1: 0.9901
Epoch 44/300
 - 0s - loss: 0.0131 - val_loss: 0.0123
 - val_f1: 0.9904
Epoch 45/300
 - 0s - loss: 0.0128 - val_loss: 0.0120
 - val_f1: 0.9907
Epoch 46/300
 - 0s - loss: 0.0127 - val_loss: 0.0117
 - val_f1: 0.9909
Epoch 47/300
 - 0s - loss: 0.0124 - val_loss: 0.0114
 - val_f1: 0.9915
Epoch 48/300
 - 0s - loss: 0.0122 - val_loss: 0.0113
 - val_f1: 0.9909
Epoch 49/300
 - 0s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9919
Epoch 50/300
 - 0s - loss: 0.0120 - val_loss: 0.0110
 - val_f1: 0.9911
Epoch 51/300
 - 0s - loss: 0.0116 - val_loss: 0.0107
 - val_f1: 0.9922
Epoch 52/300
 - 0s - loss: 0.0116 - val_loss: 0.0106
 - val_f1: 0.9921
Epoch 53/300
 - 0s - loss: 0.0112 - val_loss: 0.0105
 - val_f1: 0.9922
Epoch 54/300
 - 0s - loss: 0.0112 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 55/300
 - 0s - loss: 0.0108 - val_loss: 0.0102
 - val_f1: 0.9922
Epoch 56/300
 - 0s - loss: 0.0108 - val_loss: 0.0100
 - val_f1: 0.9926
Epoch 57/300
 - 0s - loss: 0.0105 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 58/300
 - 0s - loss: 0.0105 - val_loss: 0.0099
 - val_f1: 0.9925
Epoch 59/300
 - 0s - loss: 0.0103 - val_loss: 0.0099
 - val_f1: 0.9923
Epoch 60/300
 - 0s - loss: 0.0104 - val_loss: 0.0097
 - val_f1: 0.9926
Epoch 61/300
 - 0s - loss: 0.0101 - val_loss: 0.0096
2019-12-26 12:43:52,023 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep5/_model_epoch_60.pickle
 - val_f1: 0.9928
Epoch 62/300
 - 0s - loss: 0.0099 - val_loss: 0.0097
 - val_f1: 0.9927
Epoch 63/300
 - 0s - loss: 0.0099 - val_loss: 0.0097
 - val_f1: 0.9922
Epoch 64/300
 - 0s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9929
Epoch 65/300
 - 0s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9926
Epoch 66/300
 - 0s - loss: 0.0096 - val_loss: 0.0094
 - val_f1: 0.9930
Epoch 67/300
 - 0s - loss: 0.0095 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 68/300
 - 0s - loss: 0.0094 - val_loss: 0.0094
 - val_f1: 0.9924
Epoch 69/300
 - 0s - loss: 0.0093 - val_loss: 0.0092
 - val_f1: 0.9931
Epoch 70/300
 - 0s - loss: 0.0091 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 71/300
 - 0s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9929
Epoch 72/300
 - 0s - loss: 0.0089 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 73/300
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9933
Epoch 74/300
 - 0s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 75/300
 - 0s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 76/300
 - 0s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9931
Epoch 77/300
 - 0s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9932
Epoch 78/300
 - 0s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9929
Epoch 79/300
 - 0s - loss: 0.0083 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 80/300
 - 0s - loss: 0.0083 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 81/300
 - 0s - loss: 0.0080 - val_loss: 0.0091
 - val_f1: 0.9931
Epoch 82/300
 - 0s - loss: 0.0078 - val_loss: 0.0090
 - val_f1: 0.9932
Epoch 83/300
 - 0s - loss: 0.0080 - val_loss: 0.0090
 - val_f1: 0.9931
Epoch 84/300
 - 0s - loss: 0.0080 - val_loss: 0.0090
 - val_f1: 0.9932
Epoch 85/300
 - 0s - loss: 0.0077 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 86/300
 - 0s - loss: 0.0076 - val_loss: 0.0089
 - val_f1: 0.9931
Epoch 87/300
 - 0s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 88/300
 - 0s - loss: 0.0077 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 89/300
 - 0s - loss: 0.0075 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 90/300
 - 0s - loss: 0.0075 - val_loss: 0.0088
 - val_f1: 0.9933
Epoch 91/300
 - 0s - loss: 0.0072 - val_loss: 0.0088
2019-12-26 12:44:03,991 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep5/_model_epoch_90.pickle
 - val_f1: 0.9934
Epoch 92/300
 - 0s - loss: 0.0072 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 93/300
 - 0s - loss: 0.0071 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 94/300
 - 0s - loss: 0.0071 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 95/300
 - 0s - loss: 0.0072 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 96/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9938
Epoch 97/300
 - 0s - loss: 0.0072 - val_loss: 0.0087
 - val_f1: 0.9933
Epoch 98/300
 - 0s - loss: 0.0070 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 99/300
 - 0s - loss: 0.0068 - val_loss: 0.0088
 - val_f1: 0.9933
Epoch 100/300
 - 0s - loss: 0.0067 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 101/300
 - 0s - loss: 0.0070 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 102/300
 - 0s - loss: 0.0066 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 103/300
 - 0s - loss: 0.0067 - val_loss: 0.0088
 - val_f1: 0.9937
Epoch 104/300
 - 0s - loss: 0.0065 - val_loss: 0.0087
 - val_f1: 0.9938
Epoch 105/300
 - 0s - loss: 0.0065 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 106/300
 - 0s - loss: 0.0067 - val_loss: 0.0088
 - val_f1: 0.9933
Epoch 107/300
 - 0s - loss: 0.0063 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 108/300
 - 0s - loss: 0.0064 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 109/300
 - 0s - loss: 0.0063 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 110/300
 - 0s - loss: 0.0062 - val_loss: 0.0088
 - val_f1: 0.9937
Epoch 111/300
 - 0s - loss: 0.0063 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 112/300
 - 0s - loss: 0.0062 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 113/300
 - 0s - loss: 0.0059 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 114/300
 - 0s - loss: 0.0059 - val_loss: 0.0088
 - val_f1: 0.9934
Epoch 115/300
 - 0s - loss: 0.0060 - val_loss: 0.0088
 - val_f1: 0.9937
Epoch 116/300
 - 0s - loss: 0.0060 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 117/300
 - 0s - loss: 0.0060 - val_loss: 0.0088
 - val_f1: 0.9938
Epoch 118/300
 - 0s - loss: 0.0059 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 119/300
 - 0s - loss: 0.0059 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 120/300
 - 0s - loss: 0.0057 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 121/300
 - 0s - loss: 0.0058 - val_loss: 0.0088
2019-12-26 12:44:15,974 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_lstm_shallow_rep5/_model_epoch_120.pickle
 - val_f1: 0.9935
Epoch 122/300
 - 0s - loss: 0.0056 - val_loss: 0.0089
 - val_f1: 0.9938
Epoch 123/300
 - 0s - loss: 0.0056 - val_loss: 0.0088
 - val_f1: 0.9938
Epoch 124/300
 - 0s - loss: 0.0056 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 125/300
 - 0s - loss: 0.0056 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 126/300
 - 0s - loss: 0.0055 - val_loss: 0.0090
 - val_f1: 0.9936
Epoch 127/300
 - 0s - loss: 0.0054 - val_loss: 0.0090
 - val_f1: 0.9934
Epoch 128/300
 - 0s - loss: 0.0054 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 129/300
 - 0s - loss: 0.0055 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 130/300
 - 0s - loss: 0.0054 - val_loss: 0.0091
 - val_f1: 0.9933
Epoch 131/300
 - 0s - loss: 0.0053 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 132/300
 - 0s - loss: 0.0054 - val_loss: 0.0089
 - val_f1: 0.9933
Epoch 133/300
 - 0s - loss: 0.0051 - val_loss: 0.0089
 - val_f1: 0.9936
Epoch 134/300
 - 0s - loss: 0.0053 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 135/300
 - 0s - loss: 0.0051 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 136/300
 - 0s - loss: 0.0052 - val_loss: 0.0087
 - val_f1: 0.9936
Epoch 137/300
 - 0s - loss: 0.0051 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 138/300
 - 0s - loss: 0.0050 - val_loss: 0.0087
 - val_f1: 0.9935
Epoch 139/300
 - 0s - loss: 0.0050 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 140/300
 - 0s - loss: 0.0049 - val_loss: 0.0089
 - val_f1: 0.9934
Epoch 141/300
 - 0s - loss: 0.0048 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 142/300
 - 0s - loss: 0.0049 - val_loss: 0.0091
2019-12-26 12:44:24,436 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 12:44:25,021 [INFO] Last epoch loss evaluation: train_loss = 0.005186, val_loss = 0.008683
2019-12-26 12:44:25,021 [INFO] Training complete. time_to_train = 61.15 sec, 1.02 min
2019-12-26 12:44:25,025 [INFO] Model saved to results_selected_models/selected_nsl_lstm_shallow_rep5/best_model.pickle
2019-12-26 12:44:25,027 [INFO] Training history saved to: results_selected_models/selected_nsl_lstm_shallow_rep5/training_error_history.csv
2019-12-26 12:44:25,164 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep5/training_error_history.png
2019-12-26 12:44:25,293 [INFO] Plot saved to: results_selected_models/selected_nsl_lstm_shallow_rep5/training_f1_history.png
2019-12-26 12:44:25,293 [INFO] Making predictions on training, validation, testing data
2019-12-26 12:44:25,653 [INFO] Evaluating predictions (results)
2019-12-26 12:44:25,945 [INFO] Dataset: Testing. Classification report below
2019-12-26 12:44:25,945 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.85      0.89      7450
      normal       0.69      0.93      0.79      9704
       probe       0.74      0.73      0.73      2420
         r2l       0.95      0.11      0.20      2421
         u2r       0.58      0.02      0.04       533

   micro avg       0.77      0.77      0.77     22528
   macro avg       0.78      0.53      0.53     22528
weighted avg       0.80      0.77      0.74     22528

2019-12-26 12:44:25,945 [INFO] Overall accuracy (micro avg): 0.771484375
2019-12-26 12:44:26,282 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7715         0.7715                       0.7715                0.0571                   0.2285  0.7715
1     Macro avg        0.9086         0.7797                       0.5274                0.0758                   0.4726  0.5310
2  Weighted avg        0.8690         0.8035                       0.7715                0.1503                   0.2285  0.7368
2019-12-26 12:44:26,624 [INFO] Dataset: Validation. Classification report below
2019-12-26 12:44:26,624 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9183
      normal       0.99      0.99      0.99     13462
       probe       0.99      0.99      0.99      2330
         r2l       0.88      0.82      0.85       199
         u2r       1.00      0.30      0.46        10

   micro avg       0.99      0.99      0.99     25184
   macro avg       0.97      0.82      0.86     25184
weighted avg       0.99      0.99      0.99     25184

2019-12-26 12:44:26,624 [INFO] Overall accuracy (micro avg): 0.9938850063532402
2019-12-26 12:44:27,004 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9939         0.9939                       0.9939                0.0015                   0.0061  0.9939
1     Macro avg        0.9976         0.9709                       0.8200                0.0020                   0.1800  0.8576
2  Weighted avg        0.9962         0.9938                       0.9939                0.0041                   0.0061  0.9938
2019-12-26 12:44:28,507 [INFO] Dataset: Training. Classification report below
2019-12-26 12:44:28,507 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36738
      normal       1.00      1.00      1.00     53871
       probe       0.99      0.99      0.99      9321
         r2l       0.94      0.86      0.90       796
         u2r       0.89      0.57      0.70        42

   micro avg       1.00      1.00      1.00    100768
   macro avg       0.96      0.88      0.92    100768
weighted avg       1.00      1.00      1.00    100768

2019-12-26 12:44:28,507 [INFO] Overall accuracy (micro avg): 0.9965465227056208
2019-12-26 12:44:30,208 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9965         0.9965                       0.9965                0.0009                   0.0035  0.9965
1     Macro avg        0.9986         0.9642                       0.8844                0.0012                   0.1156  0.9170
2  Weighted avg        0.9979         0.9965                       0.9965                0.0027                   0.0035  0.9965
2019-12-26 12:44:30,229 [INFO] Results saved to: results_selected_models/selected_nsl_lstm_shallow_rep5/selected_nsl_lstm_shallow_rep5_results.xlsx
2019-12-26 12:44:30,229 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-26 12:44:30,232 [INFO] Created directory: results_selected_models/selected_ids17_lstm_shallow_rep1
2019-12-26 12:44:30,233 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_lstm_shallow_rep1/run_log.log
2019-12-26 12:44:30,233 [INFO] ================= Running experiment no. 1  ================= 

2019-12-26 12:44:30,233 [INFO] Experiment parameters given below
2019-12-26 12:44:30,233 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_lstm_shallow_rep1', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_lstm_shallow_rep1'}
2019-12-26 12:44:30,233 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_lstm_shallow_rep1/tf_logs_run_2019_12_26-12_44_30
2019-12-26 12:44:30,233 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-26 12:44:30,244 [INFO] Reading X, y files
2019-12-26 12:44:30,244 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-26 12:44:36,077 [INFO] Reading complete. time_to_read=5.83 seconds
2019-12-26 12:44:36,077 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-26 12:44:37,647 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-26 12:44:37,647 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-26 12:44:39,265 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-26 12:44:39,265 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-26 12:44:39,716 [INFO] Reading complete. time_to_read=0.45 seconds
2019-12-26 12:44:39,716 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-26 12:44:39,878 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-26 12:44:39,878 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-26 12:44:40,039 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-26 12:44:42,452 [INFO] Preparing flow sequences
2019-12-26 12:45:04,281 [INFO] Extracting flows complete. time_taken = 21.83 sec
2019-12-26 12:45:05,428 [INFO] Initializing model
2019-12-26 12:45:05,666 [INFO] _________________________________________________________________
2019-12-26 12:45:05,666 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 12:45:05,666 [INFO] =================================================================
2019-12-26 12:45:05,667 [INFO] lstm_6 (LSTM)                (None, 32, 32)            14208     
2019-12-26 12:45:05,667 [INFO] _________________________________________________________________
2019-12-26 12:45:05,667 [INFO] batch_normalization_6 (Batch (None, 32, 32)            128       
2019-12-26 12:45:05,667 [INFO] _________________________________________________________________
2019-12-26 12:45:05,667 [INFO] dropout_6 (Dropout)          (None, 32, 32)            0         
2019-12-26 12:45:05,667 [INFO] _________________________________________________________________
2019-12-26 12:45:05,667 [INFO] time_distributed_6 (TimeDist (None, 32, 12)            396       
2019-12-26 12:45:05,667 [INFO] =================================================================
2019-12-26 12:45:05,667 [INFO] Total params: 14,732
2019-12-26 12:45:05,667 [INFO] Trainable params: 14,668
2019-12-26 12:45:05,667 [INFO] Non-trainable params: 64
2019-12-26 12:45:05,667 [INFO] _________________________________________________________________
2019-12-26 12:45:05,667 [INFO] Training model
 - val_f1: 0.9935
Epoch 00142: early stopping
Train on 53021 samples, validate on 17673 samples
Epoch 1/300
 - 6s - loss: 0.1286 - val_loss: 0.0515
 - val_f1: 0.9186
Epoch 2/300
 - 5s - loss: 0.0283 - val_loss: 0.0229
 - val_f1: 0.9502
Epoch 3/300
 - 5s - loss: 0.0204 - val_loss: 0.0172
 - val_f1: 0.9587
Epoch 4/300
 - 5s - loss: 0.0170 - val_loss: 0.0143
 - val_f1: 0.9630
Epoch 5/300
 - 5s - loss: 0.0150 - val_loss: 0.0124
 - val_f1: 0.9656
Epoch 6/300
 - 5s - loss: 0.0136 - val_loss: 0.0118
 - val_f1: 0.9666
Epoch 7/300
 - 5s - loss: 0.0126 - val_loss: 0.0109
 - val_f1: 0.9705
Epoch 8/300
 - 5s - loss: 0.0119 - val_loss: 0.0106
 - val_f1: 0.9692
Epoch 9/300
 - 5s - loss: 0.0113 - val_loss: 0.0098
 - val_f1: 0.9741
Epoch 10/300
 - 5s - loss: 0.0107 - val_loss: 0.0093
 - val_f1: 0.9756
Epoch 11/300
 - 5s - loss: 0.0102 - val_loss: 0.0091
 - val_f1: 0.9753
Epoch 12/300
 - 5s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9806
Epoch 13/300
 - 5s - loss: 0.0093 - val_loss: 0.0098
 - val_f1: 0.9697
Epoch 14/300
 - 5s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9741
Epoch 15/300
 - 5s - loss: 0.0086 - val_loss: 0.0118
 - val_f1: 0.9603
Epoch 16/300
 - 5s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9667
Epoch 17/300
 - 5s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9747
Epoch 18/300
 - 5s - loss: 0.0073 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 19/300
 - 5s - loss: 0.0079 - val_loss: 0.0089
 - val_f1: 0.9752
Epoch 20/300
 - 5s - loss: 0.0077 - val_loss: 0.0068
 - val_f1: 0.9837
Epoch 21/300
 - 5s - loss: 0.0063 - val_loss: 0.0057
 - val_f1: 0.9887
Epoch 22/300
 - 5s - loss: 0.0058 - val_loss: 0.0055
 - val_f1: 0.9881
Epoch 23/300
 - 5s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9915
Epoch 24/300
 - 5s - loss: 0.0053 - val_loss: 0.0042
 - val_f1: 0.9911
Epoch 25/300
 - 5s - loss: 0.0053 - val_loss: 0.0043
 - val_f1: 0.9919
Epoch 26/300
 - 5s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 27/300
 - 5s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 28/300
 - 5s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 29/300
 - 5s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 30/300
 - 5s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 31/300
 - 5s - loss: 0.0045 - val_loss: 0.0040
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 12:48:52,715 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_30.pickle
 - val_f1: 0.9916
Epoch 32/300
 - 5s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 33/300
 - 5s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9929
Epoch 34/300
 - 5s - loss: 0.0042 - val_loss: 0.0037
 - val_f1: 0.9925
Epoch 35/300
 - 5s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 36/300
 - 5s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 37/300
 - 5s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 38/300
 - 5s - loss: 0.0041 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 39/300
 - 5s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 40/300
 - 6s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 41/300
 - 6s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 42/300
 - 6s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 43/300
 - 5s - loss: 0.0038 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 44/300
 - 6s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 45/300
 - 6s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 46/300
 - 6s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 47/300
 - 6s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 48/300
 - 5s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 49/300
 - 6s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 50/300
 - 6s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9915
Epoch 51/300
 - 6s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 52/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 53/300
 - 6s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 54/300
 - 6s - loss: 0.0036 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 55/300
 - 6s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 56/300
 - 6s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 57/300
 - 6s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 58/300
 - 6s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 59/300
 - 6s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9927
Epoch 60/300
 - 6s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 61/300
 - 6s - loss: 0.0034 - val_loss: 0.0028
2019-12-26 12:52:31,616 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_60.pickle
 - val_f1: 0.9942
Epoch 62/300
 - 6s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9929
Epoch 63/300
 - 6s - loss: 0.0039 - val_loss: 0.0069
 - val_f1: 0.9739
Epoch 64/300
 - 6s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 65/300
 - 6s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 66/300
 - 6s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 67/300
 - 6s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 68/300
 - 6s - loss: 0.0036 - val_loss: 0.0056
 - val_f1: 0.9906
Epoch 69/300
 - 6s - loss: 0.0037 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 70/300
 - 6s - loss: 0.0036 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 71/300
 - 6s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 72/300
 - 6s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 73/300
 - 6s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9930
Epoch 74/300
 - 6s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9919
Epoch 75/300
 - 6s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 76/300
 - 6s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9918
Epoch 77/300
 - 6s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9917
Epoch 78/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 79/300
 - 6s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 80/300
 - 6s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 81/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 82/300
 - 6s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 83/300
 - 6s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 84/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9923
Epoch 85/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 86/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 87/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 88/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 89/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 90/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 91/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
2019-12-26 12:56:11,202 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_90.pickle
 - val_f1: 0.9948
Epoch 92/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 93/300
 - 6s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 94/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 95/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9925
Epoch 96/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 97/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 98/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 99/300
 - 6s - loss: 0.0031 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 100/300
 - 6s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9916
Epoch 101/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 102/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 103/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 104/300
 - 6s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 105/300
 - 6s - loss: 0.0034 - val_loss: 0.0072
 - val_f1: 0.9700
Epoch 106/300
 - 6s - loss: 0.0034 - val_loss: 0.0056
 - val_f1: 0.9860
Epoch 107/300
 - 6s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 108/300
 - 6s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 109/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 110/300
 - 5s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 111/300
 - 6s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9934
Epoch 112/300
 - 6s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9919
Epoch 113/300
 - 6s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 114/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 115/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 116/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 117/300
 - 5s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 118/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 119/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 120/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 121/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
2019-12-26 12:59:50,665 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_120.pickle
 - val_f1: 0.9936
Epoch 122/300
 - 6s - loss: 0.0030 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 123/300
 - 6s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9915
Epoch 124/300
 - 6s - loss: 0.0031 - val_loss: 0.0054
 - val_f1: 0.9900
Epoch 125/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 126/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 127/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 128/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 129/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 130/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 131/300
 - 6s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 132/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 133/300
 - 6s - loss: 0.0029 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 134/300
 - 6s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 135/300
 - 5s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 136/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 137/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 138/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 139/300
 - 6s - loss: 0.0037 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 140/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 141/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 142/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 143/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 144/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 145/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 146/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 147/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 148/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 149/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 150/300
 - 5s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 151/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
2019-12-26 13:03:30,534 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_150.pickle
 - val_f1: 0.9934
Epoch 152/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 153/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 154/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 155/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 156/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 157/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 158/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 159/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9948
Epoch 160/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9952
Epoch 161/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 162/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 163/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 164/300
 - 5s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 165/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 166/300
 - 5s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 167/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 168/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 169/300
 - 6s - loss: 0.0029 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 170/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 171/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 172/300
 - 6s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 173/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 174/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 175/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 176/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 177/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 178/300
 - 6s - loss: 0.0035 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 179/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 180/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 181/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
2019-12-26 13:07:11,239 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_180.pickle
 - val_f1: 0.9928
Epoch 182/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 183/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 184/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 185/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 186/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 187/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 188/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 189/300
 - 6s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 190/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 191/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9946
Epoch 192/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 193/300
 - 6s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 194/300
 - 6s - loss: 0.0034 - val_loss: 0.0061
 - val_f1: 0.9838
Epoch 195/300
 - 6s - loss: 0.0028 - val_loss: 0.0067
 - val_f1: 0.9768
Epoch 196/300
 - 6s - loss: 0.0027 - val_loss: 0.0058
 - val_f1: 0.9811
Epoch 197/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 198/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 199/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 200/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 201/300
 - 6s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 202/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 203/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 204/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 205/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 206/300
 - 6s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9902
Epoch 207/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 208/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 209/300
 - 5s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 210/300
 - 6s - loss: 0.0027 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 211/300
 - 5s - loss: 0.0028 - val_loss: 0.0025
2019-12-26 13:10:52,952 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_210.pickle
 - val_f1: 0.9940
Epoch 212/300
 - 6s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 213/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 214/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 215/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 216/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 217/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 218/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 219/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 220/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9930
Epoch 221/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 222/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 223/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 224/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 225/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 226/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 227/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 228/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 229/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 230/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 231/300
 - 6s - loss: 0.0027 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 232/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 233/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 234/300
 - 6s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 235/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 236/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9943
Epoch 237/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 238/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 239/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 240/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 241/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
2019-12-26 13:14:34,838 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_240.pickle
 - val_f1: 0.9935
Epoch 242/300
 - 5s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9934
Epoch 243/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 244/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9933
Epoch 245/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 246/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 247/300
 - 6s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 248/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 249/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 250/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 251/300
 - 6s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 252/300
 - 6s - loss: 0.0026 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 253/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9937
Epoch 254/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 255/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 256/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 257/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 258/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 259/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9935
Epoch 260/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 261/300
 - 6s - loss: 0.0026 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 262/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 263/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 264/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 265/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 266/300
 - 6s - loss: 0.0041 - val_loss: 0.1629
 - val_f1: 0.8434
Epoch 267/300
 - 6s - loss: 0.0047 - val_loss: 0.0733
 - val_f1: 0.9308
Epoch 268/300
 - 6s - loss: 0.0027 - val_loss: 0.0246
 - val_f1: 0.9496
Epoch 269/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 270/300
 - 5s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 271/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
2019-12-26 13:18:16,587 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/_model_epoch_270.pickle
 - val_f1: 0.9933
Epoch 272/300
 - 5s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 273/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 274/300
 - 6s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 275/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9933
Epoch 276/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 277/300
 - 6s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9955
Epoch 278/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 279/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 280/300
 - 6s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 281/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 282/300
 - 6s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9932
Epoch 283/300
 - 6s - loss: 0.0030 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 284/300
 - 6s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9929
Epoch 285/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 286/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 287/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 288/300
 - 6s - loss: 0.0026 - val_loss: 0.0045
 - val_f1: 0.9910
Epoch 289/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 290/300
 - 6s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9956
Epoch 291/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 292/300
 - 6s - loss: 0.0028 - val_loss: 0.0045
 - val_f1: 0.9920
Epoch 293/300
 - 6s - loss: 0.0027 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 294/300
 - 6s - loss: 0.0027 - val_loss: 0.0056
 - val_f1: 0.9855
Epoch 295/300
 - 6s - loss: 0.0028 - val_loss: 0.0069
 - val_f1: 0.9783
Epoch 296/300
 - 6s - loss: 0.0029 - val_loss: 0.0074
 - val_f1: 0.9735
Epoch 297/300
 - 5s - loss: 0.0028 - val_loss: 0.0065
 - val_f1: 0.9807
Epoch 298/300
 - 6s - loss: 0.0026 - val_loss: 0.0057
 - val_f1: 0.9845
Epoch 299/300
 - 6s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 300/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
2019-12-26 13:21:52,886 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 13:21:58,998 [INFO] Last epoch loss evaluation: train_loss = 0.002022, val_loss = 0.002203
2019-12-26 13:21:58,999 [INFO] Training complete. time_to_train = 2213.33 sec, 36.89 min
2019-12-26 13:21:59,002 [INFO] Model saved to results_selected_models/selected_ids17_lstm_shallow_rep1/best_model.pickle
2019-12-26 13:21:59,005 [INFO] Training history saved to: results_selected_models/selected_ids17_lstm_shallow_rep1/training_error_history.csv
2019-12-26 13:21:59,146 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep1/training_error_history.png
2019-12-26 13:21:59,277 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep1/training_f1_history.png
2019-12-26 13:21:59,277 [INFO] Making predictions on training, validation, testing data
2019-12-26 13:22:06,415 [INFO] Evaluating predictions (results)
2019-12-26 13:22:16,793 [INFO] Dataset: Testing. Classification report below
2019-12-26 13:22:16,793 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.88      0.40      0.55       391
                  DDoS       1.00      1.00      1.00     25604
         DoS GoldenEye       1.00      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.98     46023
      DoS Slowhttptest       0.89      0.99      0.94      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       1.00      1.00      1.00      1586
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.67      0.83      0.74       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.86      0.85      0.84    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 13:22:16,793 [INFO] Overall accuracy (micro avg): 0.9956554489899847
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-26 13:22:28,579 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.8609                       0.8452                0.0008                   0.1548  0.8446
2  Weighted avg        0.9965         0.9955                       0.9957                0.0054                   0.0043  0.9955
2019-12-26 13:22:38,977 [INFO] Dataset: Validation. Classification report below
2019-12-26 13:22:38,977 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.88      0.37      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46023
      DoS Slowhttptest       0.89      0.98      0.94      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      1.00      1.00     31758
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.67      0.81      0.74       301
        Web Attack XSS       0.75      0.02      0.04       131

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.92      0.84      0.84    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 13:22:38,977 [INFO] Overall accuracy (micro avg): 0.9958145900526226
2019-12-26 13:22:50,792 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0004                   0.0042  0.9958
1     Macro avg        0.9993         0.9233                       0.8422                0.0008                   0.1578  0.8448
2  Weighted avg        0.9967         0.9958                       0.9958                0.0052                   0.0042  0.9956
2019-12-26 13:23:25,015 [INFO] Dataset: Training. Classification report below
2019-12-26 13:23:25,015 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362781
                   Bot       0.92      0.40      0.56      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       1.00      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138073
      DoS Slowhttptest       0.91      0.99      0.95      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95281
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.70      0.88      0.78       904
        Web Attack XSS       1.00      0.02      0.04       391

             micro avg       1.00      1.00      1.00   1696672
             macro avg       0.95      0.85      0.85   1696672
          weighted avg       1.00      1.00      1.00   1696672

2019-12-26 13:23:25,015 [INFO] Overall accuracy (micro avg): 0.9960310537334264
2019-12-26 13:24:03,894 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9960         0.9960                       0.9960                0.0004                   0.0040  0.9960
1     Macro avg        0.9993         0.9525                       0.8523                0.0007                   0.1477  0.8534
2  Weighted avg        0.9968         0.9961                       0.9960                0.0049                   0.0040  0.9959
2019-12-26 13:24:03,940 [INFO] Results saved to: results_selected_models/selected_ids17_lstm_shallow_rep1/selected_ids17_lstm_shallow_rep1_results.xlsx
2019-12-26 13:24:03,945 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-26 13:24:04,017 [INFO] Created directory: results_selected_models/selected_ids17_lstm_shallow_rep2
2019-12-26 13:24:04,017 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_lstm_shallow_rep2/run_log.log
2019-12-26 13:24:04,018 [INFO] ================= Running experiment no. 2  ================= 

2019-12-26 13:24:04,018 [INFO] Experiment parameters given below
2019-12-26 13:24:04,018 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids17_lstm_shallow_rep2', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_lstm_shallow_rep2'}
2019-12-26 13:24:04,018 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_lstm_shallow_rep2/tf_logs_run_2019_12_26-13_24_04
2019-12-26 13:24:04,018 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-26 13:24:04,018 [INFO] Reading X, y files
2019-12-26 13:24:04,018 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-26 13:24:08,208 [INFO] Reading complete. time_to_read=4.19 seconds
2019-12-26 13:24:08,209 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-26 13:24:09,632 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-26 13:24:09,632 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-26 13:24:11,059 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-26 13:24:11,059 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-26 13:24:11,289 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-26 13:24:11,289 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-26 13:24:11,362 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 13:24:11,363 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-26 13:24:11,435 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 13:24:13,853 [INFO] Preparing flow sequences
2019-12-26 13:24:35,714 [INFO] Extracting flows complete. time_taken = 21.86 sec
2019-12-26 13:24:36,854 [INFO] Initializing model
2019-12-26 13:24:37,092 [INFO] _________________________________________________________________
2019-12-26 13:24:37,092 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 13:24:37,092 [INFO] =================================================================
2019-12-26 13:24:37,092 [INFO] lstm_7 (LSTM)                (None, 32, 32)            14208     
2019-12-26 13:24:37,092 [INFO] _________________________________________________________________
2019-12-26 13:24:37,092 [INFO] batch_normalization_7 (Batch (None, 32, 32)            128       
2019-12-26 13:24:37,092 [INFO] _________________________________________________________________
2019-12-26 13:24:37,092 [INFO] dropout_7 (Dropout)          (None, 32, 32)            0         
2019-12-26 13:24:37,092 [INFO] _________________________________________________________________
2019-12-26 13:24:37,093 [INFO] time_distributed_7 (TimeDist (None, 32, 12)            396       
2019-12-26 13:24:37,093 [INFO] =================================================================
2019-12-26 13:24:37,093 [INFO] Total params: 14,732
2019-12-26 13:24:37,093 [INFO] Trainable params: 14,668
2019-12-26 13:24:37,093 [INFO] Non-trainable params: 64
2019-12-26 13:24:37,093 [INFO] _________________________________________________________________
2019-12-26 13:24:37,093 [INFO] Training model
 - val_f1: 0.9926
Train on 53021 samples, validate on 17673 samples
Epoch 1/300
 - 6s - loss: 0.1242 - val_loss: 0.0475
 - val_f1: 0.9051
Epoch 2/300
 - 5s - loss: 0.0286 - val_loss: 0.0225
 - val_f1: 0.9551
Epoch 3/300
 - 5s - loss: 0.0203 - val_loss: 0.0165
 - val_f1: 0.9599
Epoch 4/300
 - 6s - loss: 0.0170 - val_loss: 0.0138
 - val_f1: 0.9648
Epoch 5/300
 - 5s - loss: 0.0151 - val_loss: 0.0126
 - val_f1: 0.9658
Epoch 6/300
 - 5s - loss: 0.0138 - val_loss: 0.0112
 - val_f1: 0.9698
Epoch 7/300
 - 5s - loss: 0.0128 - val_loss: 0.0119
 - val_f1: 0.9638
Epoch 8/300
 - 5s - loss: 0.0120 - val_loss: 0.0104
 - val_f1: 0.9711
Epoch 9/300
 - 5s - loss: 0.0113 - val_loss: 0.0105
 - val_f1: 0.9661
Epoch 10/300
 - 5s - loss: 0.0108 - val_loss: 0.0102
 - val_f1: 0.9669
Epoch 11/300
 - 5s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9777
Epoch 12/300
 - 5s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9782
Epoch 13/300
 - 5s - loss: 0.0093 - val_loss: 0.0107
 - val_f1: 0.9640
Epoch 14/300
 - 5s - loss: 0.0089 - val_loss: 0.0109
 - val_f1: 0.9716
Epoch 15/300
 - 5s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9809
Epoch 16/300
 - 5s - loss: 0.0079 - val_loss: 0.0069
 - val_f1: 0.9854
Epoch 17/300
 - 5s - loss: 0.0073 - val_loss: 0.0066
 - val_f1: 0.9847
Epoch 18/300
 - 6s - loss: 0.0067 - val_loss: 0.0055
 - val_f1: 0.9900
Epoch 19/300
 - 6s - loss: 0.0062 - val_loss: 0.0046
 - val_f1: 0.9916
Epoch 20/300
 - 5s - loss: 0.0057 - val_loss: 0.0043
 - val_f1: 0.9922
Epoch 21/300
 - 5s - loss: 0.0053 - val_loss: 0.0064
 - val_f1: 0.9858
Epoch 22/300
 - 5s - loss: 0.0052 - val_loss: 0.0042
 - val_f1: 0.9917
Epoch 23/300
 - 5s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 24/300
 - 5s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9928
Epoch 25/300
 - 5s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 26/300
 - 5s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 27/300
 - 5s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 28/300
 - 5s - loss: 0.0043 - val_loss: 0.0048
 - val_f1: 0.9906
Epoch 29/300
 - 5s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9925
Epoch 30/300
 - 5s - loss: 0.0041 - val_loss: 0.0039
 - val_f1: 0.9901
Epoch 31/300
 - 5s - loss: 0.0040 - val_loss: 0.0035
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 13:28:25,032 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep2/_model_epoch_30.pickle
 - val_f1: 0.9914
Epoch 32/300
 - 5s - loss: 0.0041 - val_loss: 0.0048
 - val_f1: 0.9898
Epoch 33/300
 - 5s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 34/300
 - 5s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 35/300
 - 5s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9915
Epoch 36/300
 - 5s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 37/300
 - 5s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 38/300
 - 5s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 39/300
 - 5s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 40/300
 - 5s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 41/300
 - 6s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 42/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 43/300
 - 6s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 44/300
 - 6s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 45/300
 - 6s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 46/300
 - 6s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 47/300
 - 6s - loss: 0.0036 - val_loss: 0.0051
 - val_f1: 0.9895
Epoch 48/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 49/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 50/300
 - 6s - loss: 0.0035 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 51/300
 - 6s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 52/300
 - 6s - loss: 0.0035 - val_loss: 0.0064
 - val_f1: 0.9762
Epoch 53/300
 - 6s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 54/300
 - 6s - loss: 0.0040 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 55/300
 - 6s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 56/300
 - 6s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 57/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 58/300
 - 6s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 59/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 60/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 61/300
 - 6s - loss: 0.0034 - val_loss: 0.0029
2019-12-26 13:32:04,133 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep2/_model_epoch_60.pickle
 - val_f1: 0.9944
Epoch 62/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 63/300
 - 6s - loss: 0.0037 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 64/300
 - 6s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 65/300
 - 6s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 66/300
 - 6s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 67/300
 - 6s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 68/300
 - 6s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 69/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 70/300
 - 6s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 71/300
 - 6s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9913
Epoch 72/300
 - 6s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 73/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 74/300
 - 6s - loss: 0.0033 - val_loss: 0.0051
 - val_f1: 0.9868
Epoch 75/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 76/300
 - 6s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 77/300
 - 6s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 78/300
 - 6s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9930
Epoch 79/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 80/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 81/300
 - 6s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 82/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 83/300
 - 6s - loss: 0.0031 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 84/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 85/300
 - 6s - loss: 0.0031 - val_loss: 0.0040
 - val_f1: 0.9926
Epoch 86/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 87/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 88/300
 - 6s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 89/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 90/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 91/300
 - 6s - loss: 0.0030 - val_loss: 0.0033
2019-12-26 13:35:43,808 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep2/_model_epoch_90.pickle
 - val_f1: 0.9918
Epoch 92/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 93/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 94/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 95/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 96/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 97/300
 - 6s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 98/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 99/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 100/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 101/300
 - 6s - loss: 0.0032 - val_loss: 0.0051
 - val_f1: 0.9911
Epoch 102/300
 - 6s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 103/300
 - 6s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9921
Epoch 104/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 105/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 106/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 107/300
 - 6s - loss: 0.0031 - val_loss: 0.0044
 - val_f1: 0.9926
Epoch 108/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 109/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 110/300
 - 6s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 111/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 112/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 113/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9924
Epoch 114/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 115/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 116/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 117/300
 - 6s - loss: 0.0032 - val_loss: 0.0061
 - val_f1: 0.9839
Epoch 118/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 119/300
 - 6s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 120/300
 - 6s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 121/300
 - 6s - loss: 0.0032 - val_loss: 0.0042
2019-12-26 13:39:23,407 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep2/_model_epoch_120.pickle
 - val_f1: 0.9905
Epoch 122/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 123/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 124/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 125/300
 - 6s - loss: 0.0031 - val_loss: 0.0053
 - val_f1: 0.9838
Epoch 126/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9934
Epoch 127/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 128/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 129/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9926
Epoch 130/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 131/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 132/300
 - 6s - loss: 0.0030 - val_loss: 0.0042
 - val_f1: 0.9920
Epoch 133/300
 - 6s - loss: 0.0030 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 134/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 135/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9929
Epoch 136/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 137/300
 - 6s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 138/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 139/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 140/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 141/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9946
Epoch 142/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 143/300
 - 6s - loss: 0.0030 - val_loss: 0.0041
 - val_f1: 0.9916
Epoch 144/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
2019-12-26 13:42:13,454 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 13:42:19,634 [INFO] Last epoch loss evaluation: train_loss = 0.002296, val_loss = 0.002441
2019-12-26 13:42:19,634 [INFO] Training complete. time_to_train = 1062.54 sec, 17.71 min
2019-12-26 13:42:19,638 [INFO] Model saved to results_selected_models/selected_ids17_lstm_shallow_rep2/best_model.pickle
2019-12-26 13:42:19,640 [INFO] Training history saved to: results_selected_models/selected_ids17_lstm_shallow_rep2/training_error_history.csv
2019-12-26 13:42:19,782 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep2/training_error_history.png
2019-12-26 13:42:19,903 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep2/training_f1_history.png
2019-12-26 13:42:19,904 [INFO] Making predictions on training, validation, testing data
2019-12-26 13:42:26,692 [INFO] Evaluating predictions (results)
2019-12-26 13:42:37,056 [INFO] Dataset: Testing. Classification report below
2019-12-26 13:42:37,056 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.99      0.36      0.53       391
                  DDoS       1.00      1.00      1.00     25604
         DoS GoldenEye       0.99      0.98      0.98      2058
              DoS Hulk       0.97      0.99      0.98     46023
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1586
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.97      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565536
             macro avg       0.89      0.78      0.80    565536
          weighted avg       0.99      0.99      0.99    565536

2019-12-26 13:42:37,057 [INFO] Overall accuracy (micro avg): 0.9948668166129123
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-26 13:42:48,839 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8926                       0.7799                0.0011                   0.2201  0.7951
2  Weighted avg        0.9957         0.9947                       0.9949                0.0081                   0.0051  0.9945
2019-12-26 13:42:59,246 [INFO] Dataset: Validation. Classification report below
2019-12-26 13:42:59,246 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.98      0.31      0.47       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.97      0.99      0.98     46023
      DoS Slowhttptest       0.89      0.98      0.93      1099
         DoS slowloris       0.98      0.97      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31758
           SSH-Patator       0.94      0.97      0.96      1180
Web Attack Brute Force       0.90      0.06      0.12       301
        Web Attack XSS       1.00      0.02      0.03       131

             micro avg       0.99      0.99      0.99    565536
             macro avg       0.97      0.77      0.79    565536
          weighted avg       0.99      0.99      0.99    565536

2019-12-26 13:42:59,246 [INFO] Overall accuracy (micro avg): 0.9949799835907882
2019-12-26 13:43:11,084 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.9705                       0.7722                0.0011                   0.2278  0.7866
2  Weighted avg        0.9958         0.9950                       0.9950                0.0081                   0.0050  0.9945
2019-12-26 13:43:45,242 [INFO] Dataset: Training. Classification report below
2019-12-26 13:43:45,242 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362781
                   Bot       0.98      0.35      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.97      0.99      0.98    138073
      DoS Slowhttptest       0.90      0.99      0.94      3300
         DoS slowloris       0.99      0.98      0.99      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95281
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.85      0.09      0.17       904
        Web Attack XSS       1.00      0.03      0.05       391

             micro avg       1.00      1.00      1.00   1696672
             macro avg       0.97      0.78      0.80   1696672
          weighted avg       1.00      1.00      0.99   1696672

2019-12-26 13:43:45,242 [INFO] Overall accuracy (micro avg): 0.9952424511042794
2019-12-26 13:44:24,057 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.9687                       0.7815                0.0010                   0.2185  0.7988
2  Weighted avg        0.9960         0.9952                       0.9952                0.0076                   0.0048  0.9948
2019-12-26 13:44:24,082 [INFO] Results saved to: results_selected_models/selected_ids17_lstm_shallow_rep2/selected_ids17_lstm_shallow_rep2_results.xlsx
2019-12-26 13:44:24,086 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-26 13:44:24,156 [INFO] Created directory: results_selected_models/selected_ids17_lstm_shallow_rep3
2019-12-26 13:44:24,157 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_lstm_shallow_rep3/run_log.log
2019-12-26 13:44:24,157 [INFO] ================= Running experiment no. 3  ================= 

2019-12-26 13:44:24,157 [INFO] Experiment parameters given below
2019-12-26 13:44:24,157 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids17_lstm_shallow_rep3', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_lstm_shallow_rep3'}
2019-12-26 13:44:24,157 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_lstm_shallow_rep3/tf_logs_run_2019_12_26-13_44_24
2019-12-26 13:44:24,157 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-26 13:44:24,157 [INFO] Reading X, y files
2019-12-26 13:44:24,157 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-26 13:44:28,365 [INFO] Reading complete. time_to_read=4.21 seconds
2019-12-26 13:44:28,365 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-26 13:44:29,798 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-26 13:44:29,799 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-26 13:44:31,233 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-26 13:44:31,234 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-26 13:44:31,456 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-26 13:44:31,456 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-26 13:44:31,530 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 13:44:31,530 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-26 13:44:31,607 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-26 13:44:34,025 [INFO] Preparing flow sequences
2019-12-26 13:44:55,987 [INFO] Extracting flows complete. time_taken = 21.96 sec
2019-12-26 13:44:57,135 [INFO] Initializing model
2019-12-26 13:44:57,373 [INFO] _________________________________________________________________
2019-12-26 13:44:57,373 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 13:44:57,374 [INFO] =================================================================
2019-12-26 13:44:57,374 [INFO] lstm_8 (LSTM)                (None, 32, 32)            14208     
2019-12-26 13:44:57,374 [INFO] _________________________________________________________________
2019-12-26 13:44:57,374 [INFO] batch_normalization_8 (Batch (None, 32, 32)            128       
2019-12-26 13:44:57,374 [INFO] _________________________________________________________________
2019-12-26 13:44:57,374 [INFO] dropout_8 (Dropout)          (None, 32, 32)            0         
2019-12-26 13:44:57,374 [INFO] _________________________________________________________________
2019-12-26 13:44:57,374 [INFO] time_distributed_8 (TimeDist (None, 32, 12)            396       
2019-12-26 13:44:57,374 [INFO] =================================================================
2019-12-26 13:44:57,374 [INFO] Total params: 14,732
2019-12-26 13:44:57,374 [INFO] Trainable params: 14,668
2019-12-26 13:44:57,374 [INFO] Non-trainable params: 64
2019-12-26 13:44:57,374 [INFO] _________________________________________________________________
2019-12-26 13:44:57,374 [INFO] Training model
 - val_f1: 0.9925
Epoch 00144: early stopping
Train on 53021 samples, validate on 17673 samples
Epoch 1/300
 - 6s - loss: 0.1264 - val_loss: 0.0418
 - val_f1: 0.9200
Epoch 2/300
 - 5s - loss: 0.0290 - val_loss: 0.0248
 - val_f1: 0.9335
Epoch 3/300
 - 5s - loss: 0.0213 - val_loss: 0.0212
 - val_f1: 0.9383
Epoch 4/300
 - 5s - loss: 0.0180 - val_loss: 0.0192
 - val_f1: 0.9418
Epoch 5/300
 - 6s - loss: 0.0158 - val_loss: 0.0156
 - val_f1: 0.9445
Epoch 6/300
 - 6s - loss: 0.0141 - val_loss: 0.0134
 - val_f1: 0.9525
Epoch 7/300
 - 6s - loss: 0.0131 - val_loss: 0.0124
 - val_f1: 0.9553
Epoch 8/300
 - 6s - loss: 0.0121 - val_loss: 0.0102
 - val_f1: 0.9744
Epoch 9/300
 - 6s - loss: 0.0114 - val_loss: 0.0094
 - val_f1: 0.9774
Epoch 10/300
 - 6s - loss: 0.0107 - val_loss: 0.0107
 - val_f1: 0.9668
Epoch 11/300
 - 6s - loss: 0.0099 - val_loss: 0.0084
 - val_f1: 0.9801
Epoch 12/300
 - 6s - loss: 0.0093 - val_loss: 0.0081
 - val_f1: 0.9810
Epoch 13/300
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9838
Epoch 14/300
 - 6s - loss: 0.0081 - val_loss: 0.0075
 - val_f1: 0.9797
Epoch 15/300
 - 6s - loss: 0.0074 - val_loss: 0.0066
 - val_f1: 0.9850
Epoch 16/300
 - 6s - loss: 0.0071 - val_loss: 0.0054
 - val_f1: 0.9885
Epoch 17/300
 - 6s - loss: 0.0066 - val_loss: 0.0069
 - val_f1: 0.9833
Epoch 18/300
 - 6s - loss: 0.0061 - val_loss: 0.0060
 - val_f1: 0.9876
Epoch 19/300
 - 6s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9912
Epoch 20/300
 - 6s - loss: 0.0056 - val_loss: 0.0069
 - val_f1: 0.9812
Epoch 21/300
 - 6s - loss: 0.0054 - val_loss: 0.0042
 - val_f1: 0.9898
Epoch 22/300
 - 6s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9812
Epoch 23/300
 - 6s - loss: 0.0060 - val_loss: 0.0046
 - val_f1: 0.9902
Epoch 24/300
 - 6s - loss: 0.0055 - val_loss: 0.0046
 - val_f1: 0.9917
Epoch 25/300
 - 6s - loss: 0.0051 - val_loss: 0.0046
 - val_f1: 0.9893
Epoch 26/300
 - 6s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 27/300
 - 6s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9907
Epoch 28/300
 - 6s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9929
Epoch 29/300
 - 6s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9910
Epoch 30/300
 - 6s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 31/300
 - 6s - loss: 0.0043 - val_loss: 0.0034
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 13:48:48,558 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_30.pickle
 - val_f1: 0.9927
Epoch 32/300
 - 6s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 33/300
 - 6s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9899
Epoch 34/300
 - 6s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9925
Epoch 35/300
 - 6s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 36/300
 - 6s - loss: 0.0048 - val_loss: 0.0048
 - val_f1: 0.9904
Epoch 37/300
 - 6s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9896
Epoch 38/300
 - 6s - loss: 0.0046 - val_loss: 0.0063
 - val_f1: 0.9807
Epoch 39/300
 - 6s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 40/300
 - 6s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 41/300
 - 6s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9908
Epoch 42/300
 - 6s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 43/300
 - 6s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9920
Epoch 44/300
 - 6s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 45/300
 - 6s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 46/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 47/300
 - 6s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 48/300
 - 6s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9929
Epoch 49/300
 - 6s - loss: 0.0036 - val_loss: 0.0040
 - val_f1: 0.9908
Epoch 50/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 51/300
 - 6s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 52/300
 - 6s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 53/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 54/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 55/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 56/300
 - 6s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 57/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 58/300
 - 6s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 59/300
 - 6s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 60/300
 - 6s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 61/300
 - 6s - loss: 0.0034 - val_loss: 0.0034
2019-12-26 13:52:29,194 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_60.pickle
 - val_f1: 0.9922
Epoch 62/300
 - 6s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 63/300
 - 6s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 64/300
 - 6s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 65/300
 - 6s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 66/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 67/300
 - 6s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9928
Epoch 68/300
 - 6s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9885
Epoch 69/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 70/300
 - 6s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 71/300
 - 6s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 72/300
 - 6s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 73/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 74/300
 - 6s - loss: 0.0033 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 75/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 76/300
 - 6s - loss: 0.0033 - val_loss: 0.0100
 - val_f1: 0.9639
Epoch 77/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 78/300
 - 6s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9908
Epoch 79/300
 - 6s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 80/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 81/300
 - 6s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 82/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 83/300
 - 6s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 84/300
 - 6s - loss: 0.0036 - val_loss: 0.0045
 - val_f1: 0.9896
Epoch 85/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 86/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 87/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 88/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 89/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 90/300
 - 6s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 91/300
 - 6s - loss: 0.0032 - val_loss: 0.0034
2019-12-26 13:56:10,445 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_90.pickle
 - val_f1: 0.9921
Epoch 92/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 93/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 94/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 95/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 96/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 97/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 98/300
 - 6s - loss: 0.0031 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 99/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 100/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 101/300
 - 6s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 102/300
 - 6s - loss: 0.0031 - val_loss: 0.0141
 - val_f1: 0.9635
Epoch 103/300
 - 6s - loss: 0.0034 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 104/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 105/300
 - 6s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 106/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 107/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 108/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 109/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9934
Epoch 110/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9939
Epoch 111/300
 - 6s - loss: 0.0030 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 112/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 113/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 114/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 115/300
 - 6s - loss: 0.0030 - val_loss: 0.0036
 - val_f1: 0.9915
Epoch 116/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9928
Epoch 117/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 118/300
 - 6s - loss: 0.0030 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 119/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 120/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 121/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
2019-12-26 13:59:51,411 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_120.pickle
 - val_f1: 0.9943
Epoch 122/300
 - 6s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 123/300
 - 6s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 124/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9935
Epoch 125/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 126/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 127/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 128/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 129/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 130/300
 - 6s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 131/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9924
Epoch 132/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 133/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 134/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9929
Epoch 135/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9928
Epoch 136/300
 - 6s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 137/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 138/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 139/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 140/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 141/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 142/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 143/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9936
Epoch 144/300
 - 6s - loss: 0.0029 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 145/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 146/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 147/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 148/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 149/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 150/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 151/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
2019-12-26 14:03:32,951 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_150.pickle
 - val_f1: 0.9949
Epoch 152/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9934
Epoch 153/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9944
Epoch 154/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 155/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 156/300
 - 6s - loss: 0.0030 - val_loss: 0.0044
 - val_f1: 0.9926
Epoch 157/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 158/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 159/300
 - 6s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 160/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 161/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 162/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9937
Epoch 163/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 164/300
 - 6s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9927
Epoch 165/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 166/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 167/300
 - 6s - loss: 0.0028 - val_loss: 0.0051
 - val_f1: 0.9880
Epoch 168/300
 - 6s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 169/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 170/300
 - 6s - loss: 0.0028 - val_loss: 0.0040
 - val_f1: 0.9923
Epoch 171/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9938
Epoch 172/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 173/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 174/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 175/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 176/300
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9907
Epoch 177/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 178/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9932
Epoch 179/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 180/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 181/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
2019-12-26 14:07:14,713 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_180.pickle
 - val_f1: 0.9946
Epoch 182/300
 - 6s - loss: 0.0027 - val_loss: 0.0071
 - val_f1: 0.9672
Epoch 183/300
 - 6s - loss: 0.0028 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 184/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 185/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9930
Epoch 186/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 187/300
 - 6s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 188/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9943
Epoch 189/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 190/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9929
Epoch 191/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 192/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 193/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9953
Epoch 194/300
 - 6s - loss: 0.0027 - val_loss: 0.0079
 - val_f1: 0.9659
Epoch 195/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9933
Epoch 196/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 197/300
 - 6s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 198/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 199/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 200/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 201/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 202/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 203/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9934
Epoch 204/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 205/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 206/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 207/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 208/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 209/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 210/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 211/300
 - 6s - loss: 0.0027 - val_loss: 0.0035
2019-12-26 14:10:56,348 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_210.pickle
 - val_f1: 0.9925
Epoch 212/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 213/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 214/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9931
Epoch 215/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 216/300
 - 6s - loss: 0.0027 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 217/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 218/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9930
Epoch 219/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 220/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 221/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 222/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 223/300
 - 6s - loss: 0.0026 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 224/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9945
Epoch 225/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 226/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9952
Epoch 227/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 228/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 229/300
 - 6s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 230/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9934
Epoch 231/300
 - 6s - loss: 0.0026 - val_loss: 0.0056
 - val_f1: 0.9815
Epoch 232/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 233/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 234/300
 - 6s - loss: 0.0027 - val_loss: 0.0022
 - val_f1: 0.9953
Epoch 235/300
 - 6s - loss: 0.0026 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 236/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 237/300
 - 6s - loss: 0.0026 - val_loss: 0.0049
 - val_f1: 0.9910
Epoch 238/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 239/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9955
Epoch 240/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 241/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
2019-12-26 14:14:38,057 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_240.pickle
 - val_f1: 0.9939
Epoch 242/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 243/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 244/300
 - 6s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 245/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 246/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9930
Epoch 247/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 248/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 249/300
 - 6s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 250/300
 - 6s - loss: 0.0028 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 251/300
 - 6s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9950
Epoch 252/300
 - 6s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9953
Epoch 253/300
 - 6s - loss: 0.0026 - val_loss: 0.0036
 - val_f1: 0.9938
Epoch 254/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 255/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 256/300
 - 6s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 257/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 258/300
 - 6s - loss: 0.0025 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 259/300
 - 6s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 260/300
 - 6s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 261/300
 - 6s - loss: 0.0026 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 262/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 263/300
 - 6s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 264/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 265/300
 - 6s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 266/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 267/300
 - 6s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9954
Epoch 268/300
 - 6s - loss: 0.0025 - val_loss: 0.0039
 - val_f1: 0.9937
Epoch 269/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 270/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9941
Epoch 271/300
 - 6s - loss: 0.0025 - val_loss: 0.0024
2019-12-26 14:18:19,934 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/_model_epoch_270.pickle
 - val_f1: 0.9946
Epoch 272/300
 - 6s - loss: 0.0026 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 273/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 274/300
 - 6s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 275/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9954
Epoch 276/300
 - 6s - loss: 0.0025 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 277/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 278/300
 - 6s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 279/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9943
Epoch 280/300
 - 6s - loss: 0.0025 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 281/300
 - 6s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 282/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 283/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 284/300
 - 6s - loss: 0.0026 - val_loss: 0.0022
 - val_f1: 0.9954
Epoch 285/300
 - 6s - loss: 0.0025 - val_loss: 0.0024
 - val_f1: 0.9933
Epoch 286/300
 - 6s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9933
Epoch 287/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9944
Epoch 288/300
 - 6s - loss: 0.0025 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 289/300
 - 6s - loss: 0.0026 - val_loss: 0.0027
 - val_f1: 0.9931
Epoch 290/300
 - 6s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 291/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9957
Epoch 292/300
 - 6s - loss: 0.0025 - val_loss: 0.0022
 - val_f1: 0.9952
Epoch 293/300
 - 6s - loss: 0.0025 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 294/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 295/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9955
Epoch 296/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 297/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9952
Epoch 298/300
 - 6s - loss: 0.0025 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 299/300
 - 6s - loss: 0.0025 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 300/300
 - 6s - loss: 0.0025 - val_loss: 0.0024
2019-12-26 14:21:56,147 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 14:22:02,559 [INFO] Last epoch loss evaluation: train_loss = 0.001981, val_loss = 0.002182
2019-12-26 14:22:02,559 [INFO] Training complete. time_to_train = 2225.18 sec, 37.09 min
2019-12-26 14:22:02,563 [INFO] Model saved to results_selected_models/selected_ids17_lstm_shallow_rep3/best_model.pickle
2019-12-26 14:22:02,566 [INFO] Training history saved to: results_selected_models/selected_ids17_lstm_shallow_rep3/training_error_history.csv
2019-12-26 14:22:02,703 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep3/training_error_history.png
2019-12-26 14:22:02,838 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep3/training_f1_history.png
2019-12-26 14:22:02,839 [INFO] Making predictions on training, validation, testing data
2019-12-26 14:22:09,818 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 14:22:20,222 [INFO] Dataset: Testing. Classification report below
2019-12-26 14:22:20,223 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.88      0.40      0.55       391
                  DDoS       1.00      1.00      1.00     25604
         DoS GoldenEye       1.00      0.97      0.99      2058
              DoS Hulk       0.98      0.99      0.98     46023
      DoS Slowhttptest       0.91      0.99      0.95      1100
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1586
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.65      0.40      0.50       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.86      0.81      0.82    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 14:22:20,223 [INFO] Overall accuracy (micro avg): 0.9954910032252589
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 14:22:31,994 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9992         0.8614                       0.8081                0.0011                   0.1919  0.8247
2  Weighted avg        0.9963         0.9952                       0.9955                0.0084                   0.0045  0.9952
2019-12-26 14:22:42,367 [INFO] Dataset: Validation. Classification report below
2019-12-26 14:22:42,367 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.92      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.99     46023
      DoS Slowhttptest       0.91      0.98      0.94      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31758
           SSH-Patator       0.96      0.97      0.96      1180
Web Attack Brute Force       0.61      0.34      0.43       301
        Web Attack XSS       1.00      0.03      0.06       131

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.95      0.80      0.82    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 14:22:42,367 [INFO] Overall accuracy (micro avg): 0.9956607536920726
2019-12-26 14:22:54,165 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.9452                       0.8016                0.0010                   0.1984  0.8224
2  Weighted avg        0.9965         0.9956                       0.9957                0.0081                   0.0043  0.9954
2019-12-26 14:23:28,350 [INFO] Dataset: Training. Classification report below
2019-12-26 14:23:28,350 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362781
                   Bot       0.92      0.41      0.57      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       1.00      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138073
      DoS Slowhttptest       0.94      0.99      0.96      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95281
           SSH-Patator       0.97      0.98      0.97      3538
Web Attack Brute Force       0.67      0.40      0.50       904
        Web Attack XSS       1.00      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696672
             macro avg       0.95      0.81      0.84   1696672
          weighted avg       1.00      1.00      1.00   1696672

2019-12-26 14:23:28,350 [INFO] Overall accuracy (micro avg): 0.9959414665887102
2019-12-26 14:24:07,186 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0004                   0.0041  0.9959
1     Macro avg        0.9993         0.9543                       0.8136                0.0010                   0.1864  0.8354
2  Weighted avg        0.9967         0.9959                       0.9959                0.0078                   0.0041  0.9957
2019-12-26 14:24:07,210 [INFO] Results saved to: results_selected_models/selected_ids17_lstm_shallow_rep3/selected_ids17_lstm_shallow_rep3_results.xlsx
2019-12-26 14:24:07,214 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-26 14:24:07,284 [INFO] Created directory: results_selected_models/selected_ids17_lstm_shallow_rep4
2019-12-26 14:24:07,284 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_lstm_shallow_rep4/run_log.log
2019-12-26 14:24:07,284 [INFO] ================= Running experiment no. 4  ================= 

2019-12-26 14:24:07,284 [INFO] Experiment parameters given below
2019-12-26 14:24:07,285 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids17_lstm_shallow_rep4', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_lstm_shallow_rep4'}
2019-12-26 14:24:07,285 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_lstm_shallow_rep4/tf_logs_run_2019_12_26-14_24_07
2019-12-26 14:24:07,285 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-26 14:24:07,285 [INFO] Reading X, y files
2019-12-26 14:24:07,285 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-26 14:24:11,460 [INFO] Reading complete. time_to_read=4.18 seconds
2019-12-26 14:24:11,460 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-26 14:24:12,897 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-26 14:24:12,898 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-26 14:24:14,335 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-26 14:24:14,335 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-26 14:24:14,554 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-26 14:24:14,554 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-26 14:24:14,628 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 14:24:14,628 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-26 14:24:14,702 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 14:24:17,137 [INFO] Preparing flow sequences
2019-12-26 14:24:39,013 [INFO] Extracting flows complete. time_taken = 21.88 sec
2019-12-26 14:24:40,165 [INFO] Initializing model
2019-12-26 14:24:40,613 [INFO] _________________________________________________________________
2019-12-26 14:24:40,613 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 14:24:40,613 [INFO] =================================================================
2019-12-26 14:24:40,614 [INFO] lstm_9 (LSTM)                (None, 32, 32)            14208     
2019-12-26 14:24:40,614 [INFO] _________________________________________________________________
2019-12-26 14:24:40,614 [INFO] batch_normalization_9 (Batch (None, 32, 32)            128       
2019-12-26 14:24:40,614 [INFO] _________________________________________________________________
2019-12-26 14:24:40,614 [INFO] dropout_9 (Dropout)          (None, 32, 32)            0         
2019-12-26 14:24:40,614 [INFO] _________________________________________________________________
2019-12-26 14:24:40,614 [INFO] time_distributed_9 (TimeDist (None, 32, 12)            396       
2019-12-26 14:24:40,614 [INFO] =================================================================
2019-12-26 14:24:40,614 [INFO] Total params: 14,732
2019-12-26 14:24:40,614 [INFO] Trainable params: 14,668
2019-12-26 14:24:40,614 [INFO] Non-trainable params: 64
2019-12-26 14:24:40,614 [INFO] _________________________________________________________________
2019-12-26 14:24:40,614 [INFO] Training model
 - val_f1: 0.9949
Train on 53021 samples, validate on 17673 samples
Epoch 1/300
 - 6s - loss: 0.1343 - val_loss: 0.0484
 - val_f1: 0.8795
Epoch 2/300
 - 5s - loss: 0.0296 - val_loss: 0.0264
 - val_f1: 0.9330
Epoch 3/300
 - 5s - loss: 0.0211 - val_loss: 0.0190
 - val_f1: 0.9405
Epoch 4/300
 - 5s - loss: 0.0173 - val_loss: 0.0150
 - val_f1: 0.9547
Epoch 5/300
 - 6s - loss: 0.0151 - val_loss: 0.0129
 - val_f1: 0.9645
Epoch 6/300
 - 6s - loss: 0.0137 - val_loss: 0.0114
 - val_f1: 0.9706
Epoch 7/300
 - 6s - loss: 0.0128 - val_loss: 0.0104
 - val_f1: 0.9727
Epoch 8/300
 - 5s - loss: 0.0120 - val_loss: 0.0098
 - val_f1: 0.9770
Epoch 9/300
 - 6s - loss: 0.0114 - val_loss: 0.0100
 - val_f1: 0.9730
Epoch 10/300
 - 5s - loss: 0.0108 - val_loss: 0.0092
 - val_f1: 0.9751
Epoch 11/300
 - 6s - loss: 0.0103 - val_loss: 0.0086
 - val_f1: 0.9787
Epoch 12/300
 - 5s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9761
Epoch 13/300
 - 6s - loss: 0.0096 - val_loss: 0.0089
 - val_f1: 0.9770
Epoch 14/300
 - 6s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9785
Epoch 15/300
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9830
Epoch 16/300
 - 6s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9783
Epoch 17/300
 - 6s - loss: 0.0083 - val_loss: 0.0074
 - val_f1: 0.9825
Epoch 18/300
 - 6s - loss: 0.0078 - val_loss: 0.0069
 - val_f1: 0.9831
Epoch 19/300
 - 6s - loss: 0.0071 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 20/300
 - 6s - loss: 0.0066 - val_loss: 0.0051
 - val_f1: 0.9903
Epoch 21/300
 - 6s - loss: 0.0060 - val_loss: 0.0051
 - val_f1: 0.9897
Epoch 22/300
 - 6s - loss: 0.0058 - val_loss: 0.0049
 - val_f1: 0.9917
Epoch 23/300
 - 6s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9894
Epoch 24/300
 - 6s - loss: 0.0052 - val_loss: 0.0045
 - val_f1: 0.9902
Epoch 25/300
 - 6s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9907
Epoch 26/300
 - 6s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9911
Epoch 27/300
 - 6s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9903
Epoch 28/300
 - 6s - loss: 0.0047 - val_loss: 0.0038
 - val_f1: 0.9925
Epoch 29/300
 - 6s - loss: 0.0045 - val_loss: 0.0056
 - val_f1: 0.9876
Epoch 30/300
 - 6s - loss: 0.0045 - val_loss: 0.0042
 - val_f1: 0.9896
Epoch 31/300
 - 6s - loss: 0.0044 - val_loss: 0.0037
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 14:28:32,471 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_30.pickle
 - val_f1: 0.9922
Epoch 32/300
 - 6s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9918
Epoch 33/300
 - 6s - loss: 0.0046 - val_loss: 0.0049
 - val_f1: 0.9888
Epoch 34/300
 - 6s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 35/300
 - 6s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 36/300
 - 6s - loss: 0.0041 - val_loss: 0.0056
 - val_f1: 0.9881
Epoch 37/300
 - 6s - loss: 0.0042 - val_loss: 0.0038
 - val_f1: 0.9905
Epoch 38/300
 - 6s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 39/300
 - 6s - loss: 0.0040 - val_loss: 0.0051
 - val_f1: 0.9891
Epoch 40/300
 - 6s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 41/300
 - 6s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 42/300
 - 6s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 43/300
 - 6s - loss: 0.0039 - val_loss: 0.0038
 - val_f1: 0.9921
Epoch 44/300
 - 6s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 45/300
 - 6s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 46/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 47/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 48/300
 - 6s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 49/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 50/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 51/300
 - 6s - loss: 0.0037 - val_loss: 0.0059
 - val_f1: 0.9838
Epoch 52/300
 - 6s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9918
Epoch 53/300
 - 6s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 54/300
 - 6s - loss: 0.0037 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 55/300
 - 6s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9931
Epoch 56/300
 - 6s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 57/300
 - 6s - loss: 0.0037 - val_loss: 0.0032
 - val_f1: 0.9914
Epoch 58/300
 - 6s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 59/300
 - 6s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 60/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 61/300
 - 6s - loss: 0.0036 - val_loss: 0.0035
2019-12-26 14:32:13,530 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_60.pickle
 - val_f1: 0.9919
Epoch 62/300
 - 6s - loss: 0.0036 - val_loss: 0.0039
 - val_f1: 0.9935
Epoch 63/300
 - 6s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 64/300
 - 6s - loss: 0.0035 - val_loss: 0.0056
 - val_f1: 0.9893
Epoch 65/300
 - 6s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9935
Epoch 66/300
 - 6s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 67/300
 - 6s - loss: 0.0034 - val_loss: 0.0043
 - val_f1: 0.9899
Epoch 68/300
 - 6s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 69/300
 - 6s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9926
Epoch 70/300
 - 6s - loss: 0.0034 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 71/300
 - 6s - loss: 0.0034 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 72/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 73/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 74/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 75/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 76/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 77/300
 - 6s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 78/300
 - 6s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 79/300
 - 6s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 80/300
 - 6s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 81/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9941
Epoch 82/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 83/300
 - 6s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 84/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 85/300
 - 6s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 86/300
 - 6s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 87/300
 - 6s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 88/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 89/300
 - 6s - loss: 0.0032 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 90/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 91/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
2019-12-26 14:35:54,663 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_90.pickle
 - val_f1: 0.9945
Epoch 92/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 93/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 94/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 95/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 96/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 97/300
 - 6s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 98/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 99/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9932
Epoch 100/300
 - 6s - loss: 0.0031 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 101/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9932
Epoch 102/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 103/300
 - 6s - loss: 0.0030 - val_loss: 0.0031
 - val_f1: 0.9932
Epoch 104/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 105/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 106/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 107/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 108/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 109/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 110/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 111/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 112/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 113/300
 - 6s - loss: 0.0030 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 114/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 115/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 116/300
 - 6s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9923
Epoch 117/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9949
Epoch 118/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 119/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9930
Epoch 120/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 121/300
 - 6s - loss: 0.0030 - val_loss: 0.0024
2019-12-26 14:39:35,852 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_120.pickle
 - val_f1: 0.9939
Epoch 122/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 123/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 124/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 125/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 126/300
 - 6s - loss: 0.0029 - val_loss: 0.0038
 - val_f1: 0.9899
Epoch 127/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 128/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 129/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 130/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 131/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 132/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9930
Epoch 133/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9942
Epoch 134/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 135/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9921
Epoch 136/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 137/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 138/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 139/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 140/300
 - 6s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9946
Epoch 141/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 142/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 143/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 144/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 145/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 146/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9951
Epoch 147/300
 - 6s - loss: 0.0027 - val_loss: 0.0045
 - val_f1: 0.9908
Epoch 148/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 149/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 150/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 151/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
2019-12-26 14:43:17,083 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_150.pickle
 - val_f1: 0.9945
Epoch 152/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 153/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9947
Epoch 154/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 155/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 156/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 157/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 158/300
 - 6s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 159/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 160/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 161/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 162/300
 - 6s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 163/300
 - 6s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 164/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 165/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 166/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 167/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 168/300
 - 6s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9867
Epoch 169/300
 - 6s - loss: 0.0030 - val_loss: 0.0060
 - val_f1: 0.9831
Epoch 170/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 171/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9941
Epoch 172/300
 - 6s - loss: 0.0030 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 173/300
 - 6s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 174/300
 - 6s - loss: 0.0029 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 175/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 176/300
 - 6s - loss: 0.0029 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 177/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 178/300
 - 6s - loss: 0.0029 - val_loss: 0.0043
 - val_f1: 0.9918
Epoch 179/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 180/300
 - 6s - loss: 0.0029 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 181/300
 - 6s - loss: 0.0028 - val_loss: 0.0051
2019-12-26 14:46:58,292 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/_model_epoch_180.pickle
 - val_f1: 0.9873
Epoch 182/300
 - 6s - loss: 0.0028 - val_loss: 0.0039
 - val_f1: 0.9932
Epoch 183/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 184/300
 - 6s - loss: 0.0028 - val_loss: 0.0045
 - val_f1: 0.9857
Epoch 185/300
 - 6s - loss: 0.0028 - val_loss: 0.0032
 - val_f1: 0.9944
Epoch 186/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9947
Epoch 187/300
 - 6s - loss: 0.0030 - val_loss: 0.0064
 - val_f1: 0.9778
Epoch 188/300
 - 6s - loss: 0.0028 - val_loss: 0.0047
 - val_f1: 0.9918
Epoch 189/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9927
Epoch 190/300
 - 6s - loss: 0.0029 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 191/300
 - 6s - loss: 0.0032 - val_loss: 0.0036
2019-12-26 14:48:13,805 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 14:48:20,172 [INFO] Last epoch loss evaluation: train_loss = 0.002156, val_loss = 0.002312
2019-12-26 14:48:20,173 [INFO] Training complete. time_to_train = 1419.56 sec, 23.66 min
2019-12-26 14:48:20,177 [INFO] Model saved to results_selected_models/selected_ids17_lstm_shallow_rep4/best_model.pickle
2019-12-26 14:48:20,179 [INFO] Training history saved to: results_selected_models/selected_ids17_lstm_shallow_rep4/training_error_history.csv
2019-12-26 14:48:20,344 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep4/training_error_history.png
2019-12-26 14:48:20,506 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep4/training_f1_history.png
2019-12-26 14:48:20,506 [INFO] Making predictions on training, validation, testing data
2019-12-26 14:48:27,405 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 14:48:37,821 [INFO] Dataset: Testing. Classification report below
2019-12-26 14:48:37,821 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.96      0.37      0.54       391
                  DDoS       1.00      1.00      1.00     25604
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.98     46023
      DoS Slowhttptest       0.93      0.98      0.95      1100
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1586
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.94      0.10      0.18       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.89      0.78      0.80    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 14:48:37,821 [INFO] Overall accuracy (micro avg): 0.9954308832682623
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 14:48:49,638 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.8925                       0.7807                0.0011                   0.2193  0.7974
2  Weighted avg        0.9962         0.9952                       0.9954                0.0080                   0.0046  0.9950
2019-12-26 14:49:00,057 [INFO] Dataset: Validation. Classification report below
2019-12-26 14:49:00,057 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.96      0.34      0.50       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46023
      DoS Slowhttptest       0.92      0.96      0.94      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31758
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.72      0.06      0.11       301
        Web Attack XSS       0.80      0.03      0.06       131

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.94      0.78      0.79    565536
          weighted avg       1.00      1.00      1.00    565536

2019-12-26 14:49:00,057 [INFO] Overall accuracy (micro avg): 0.9954644797148192
2019-12-26 14:49:11,912 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9955         0.9955                       0.9955                0.0004                   0.0045  0.9955
1     Macro avg        0.9992         0.9408                       0.7752                0.0010                   0.2248  0.7924
2  Weighted avg        0.9963         0.9953                       0.9955                0.0080                   0.0045  0.9950
2019-12-26 14:49:46,152 [INFO] Dataset: Training. Classification report below
2019-12-26 14:49:46,152 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362781
                   Bot       0.99      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138073
      DoS Slowhttptest       0.95      0.98      0.96      3300
         DoS slowloris       0.98      0.99      0.99      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95281
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.98      0.09      0.17       904
        Web Attack XSS       1.00      0.03      0.05       391

             micro avg       1.00      1.00      1.00   1696672
             macro avg       0.98      0.78      0.80   1696672
          weighted avg       1.00      1.00      1.00   1696672

2019-12-26 14:49:46,152 [INFO] Overall accuracy (micro avg): 0.9957446106259784
2019-12-26 14:50:25,051 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0004                   0.0043  0.9957
1     Macro avg        0.9993         0.9846                       0.7821                0.0010                   0.2179  0.8024
2  Weighted avg        0.9965         0.9958                       0.9957                0.0077                   0.0043  0.9953
2019-12-26 14:50:25,075 [INFO] Results saved to: results_selected_models/selected_ids17_lstm_shallow_rep4/selected_ids17_lstm_shallow_rep4_results.xlsx
2019-12-26 14:50:25,079 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-26 14:50:25,149 [INFO] Created directory: results_selected_models/selected_ids17_lstm_shallow_rep5
2019-12-26 14:50:25,149 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_lstm_shallow_rep5/run_log.log
2019-12-26 14:50:25,149 [INFO] ================= Running experiment no. 5  ================= 

2019-12-26 14:50:25,149 [INFO] Experiment parameters given below
2019-12-26 14:50:25,149 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids17_lstm_shallow_rep5', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_lstm_shallow_rep5'}
2019-12-26 14:50:25,149 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_lstm_shallow_rep5/tf_logs_run_2019_12_26-14_50_25
2019-12-26 14:50:25,149 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-26 14:50:25,149 [INFO] Reading X, y files
2019-12-26 14:50:25,149 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-26 14:50:29,377 [INFO] Reading complete. time_to_read=4.23 seconds
2019-12-26 14:50:29,377 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-26 14:50:30,813 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-26 14:50:30,813 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-26 14:50:32,251 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-26 14:50:32,252 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-26 14:50:32,459 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-26 14:50:32,459 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-26 14:50:32,533 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 14:50:32,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-26 14:50:32,607 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-26 14:50:35,049 [INFO] Preparing flow sequences
2019-12-26 14:50:56,989 [INFO] Extracting flows complete. time_taken = 21.94 sec
2019-12-26 14:50:58,105 [INFO] Initializing model
2019-12-26 14:50:58,344 [INFO] _________________________________________________________________
2019-12-26 14:50:58,344 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 14:50:58,344 [INFO] =================================================================
2019-12-26 14:50:58,344 [INFO] lstm_10 (LSTM)               (None, 32, 32)            14208     
2019-12-26 14:50:58,344 [INFO] _________________________________________________________________
2019-12-26 14:50:58,344 [INFO] batch_normalization_10 (Batc (None, 32, 32)            128       
2019-12-26 14:50:58,344 [INFO] _________________________________________________________________
2019-12-26 14:50:58,344 [INFO] dropout_10 (Dropout)         (None, 32, 32)            0         
2019-12-26 14:50:58,344 [INFO] _________________________________________________________________
2019-12-26 14:50:58,344 [INFO] time_distributed_10 (TimeDis (None, 32, 12)            396       
2019-12-26 14:50:58,344 [INFO] =================================================================
2019-12-26 14:50:58,344 [INFO] Total params: 14,732
2019-12-26 14:50:58,344 [INFO] Trainable params: 14,668
2019-12-26 14:50:58,344 [INFO] Non-trainable params: 64
2019-12-26 14:50:58,345 [INFO] _________________________________________________________________
2019-12-26 14:50:58,345 [INFO] Training model
 - val_f1: 0.9927
Epoch 00191: early stopping
Train on 53021 samples, validate on 17673 samples
Epoch 1/300
 - 6s - loss: 0.1233 - val_loss: 0.0409
 - val_f1: 0.9073
Epoch 2/300
 - 5s - loss: 0.0282 - val_loss: 0.0231
 - val_f1: 0.9381
Epoch 3/300
 - 5s - loss: 0.0205 - val_loss: 0.0174
 - val_f1: 0.9574
Epoch 4/300
 - 6s - loss: 0.0172 - val_loss: 0.0156
 - val_f1: 0.9602
Epoch 5/300
 - 6s - loss: 0.0152 - val_loss: 0.0131
 - val_f1: 0.9620
Epoch 6/300
 - 6s - loss: 0.0138 - val_loss: 0.0114
 - val_f1: 0.9706
Epoch 7/300
 - 6s - loss: 0.0128 - val_loss: 0.0121
 - val_f1: 0.9640
Epoch 8/300
 - 6s - loss: 0.0120 - val_loss: 0.0103
 - val_f1: 0.9734
Epoch 9/300
 - 6s - loss: 0.0114 - val_loss: 0.0102
 - val_f1: 0.9726
Epoch 10/300
 - 6s - loss: 0.0108 - val_loss: 0.0109
 - val_f1: 0.9649
Epoch 11/300
 - 6s - loss: 0.0104 - val_loss: 0.0093
 - val_f1: 0.9748
Epoch 12/300
 - 6s - loss: 0.0101 - val_loss: 0.0101
 - val_f1: 0.9739
Epoch 13/300
 - 6s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 14/300
 - 6s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9810
Epoch 15/300
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9798
Epoch 16/300
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9758
Epoch 17/300
 - 6s - loss: 0.0085 - val_loss: 0.0078
 - val_f1: 0.9799
Epoch 18/300
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9792
Epoch 19/300
 - 6s - loss: 0.0079 - val_loss: 0.0067
 - val_f1: 0.9821
Epoch 20/300
 - 6s - loss: 0.0076 - val_loss: 0.0066
 - val_f1: 0.9832
Epoch 21/300
 - 6s - loss: 0.0073 - val_loss: 0.0060
 - val_f1: 0.9864
Epoch 22/300
 - 6s - loss: 0.0068 - val_loss: 0.0053
 - val_f1: 0.9889
Epoch 23/300
 - 6s - loss: 0.0065 - val_loss: 0.0063
 - val_f1: 0.9850
Epoch 24/300
 - 6s - loss: 0.0060 - val_loss: 0.0046
 - val_f1: 0.9918
Epoch 25/300
 - 6s - loss: 0.0057 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 26/300
 - 6s - loss: 0.0053 - val_loss: 0.0044
 - val_f1: 0.9917
Epoch 27/300
 - 6s - loss: 0.0051 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 28/300
 - 6s - loss: 0.0050 - val_loss: 0.0046
 - val_f1: 0.9900
Epoch 29/300
 - 6s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9909
Epoch 30/300
 - 6s - loss: 0.0047 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 31/300
 - 6s - loss: 0.0046 - val_loss: 0.0039
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 14:54:50,779 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_30.pickle
 - val_f1: 0.9918
Epoch 32/300
 - 6s - loss: 0.0045 - val_loss: 0.0055
 - val_f1: 0.9878
Epoch 33/300
 - 6s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 34/300
 - 6s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 35/300
 - 5s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 36/300
 - 6s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 37/300
 - 6s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 38/300
 - 6s - loss: 0.0041 - val_loss: 0.0050
 - val_f1: 0.9910
Epoch 39/300
 - 6s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 40/300
 - 6s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 41/300
 - 6s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 42/300
 - 6s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 43/300
 - 6s - loss: 0.0039 - val_loss: 0.0044
 - val_f1: 0.9901
Epoch 44/300
 - 6s - loss: 0.0038 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 45/300
 - 6s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9911
Epoch 46/300
 - 6s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 47/300
 - 6s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 48/300
 - 6s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 49/300
 - 6s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 50/300
 - 6s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 51/300
 - 6s - loss: 0.0036 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 52/300
 - 6s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9923
Epoch 53/300
 - 6s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 54/300
 - 6s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 55/300
 - 6s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 56/300
 - 6s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 57/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 58/300
 - 6s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 59/300
 - 6s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9933
Epoch 60/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 61/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
2019-12-26 14:58:31,733 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_60.pickle
 - val_f1: 0.9940
Epoch 62/300
 - 6s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 63/300
 - 6s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 64/300
 - 6s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 65/300
 - 6s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 66/300
 - 6s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 67/300
 - 6s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 68/300
 - 6s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 69/300
 - 6s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9943
Epoch 70/300
 - 6s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 71/300
 - 6s - loss: 0.0033 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 72/300
 - 6s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 73/300
 - 6s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9920
Epoch 74/300
 - 6s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 75/300
 - 6s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9936
Epoch 76/300
 - 6s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9933
Epoch 77/300
 - 6s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 78/300
 - 6s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 79/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 80/300
 - 6s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 81/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 82/300
 - 6s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 83/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 84/300
 - 6s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 85/300
 - 6s - loss: 0.0031 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 86/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9932
Epoch 87/300
 - 6s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 88/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 89/300
 - 6s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9911
Epoch 90/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 91/300
 - 6s - loss: 0.0032 - val_loss: 0.0046
2019-12-26 15:02:12,617 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_90.pickle
 - val_f1: 0.9913
Epoch 92/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 93/300
 - 6s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 94/300
 - 6s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9925
Epoch 95/300
 - 6s - loss: 0.0031 - val_loss: 0.0043
 - val_f1: 0.9926
Epoch 96/300
 - 6s - loss: 0.0031 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 97/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 98/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9946
Epoch 99/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 100/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 101/300
 - 6s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 102/300
 - 5s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 103/300
 - 6s - loss: 0.0031 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 104/300
 - 6s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 105/300
 - 6s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 106/300
 - 6s - loss: 0.0031 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 107/300
 - 6s - loss: 0.0031 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 108/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9944
Epoch 109/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9945
Epoch 110/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 111/300
 - 6s - loss: 0.0031 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 112/300
 - 6s - loss: 0.0031 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 113/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9933
Epoch 114/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 115/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 116/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 117/300
 - 6s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 118/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9935
Epoch 119/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9937
Epoch 120/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9943
Epoch 121/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
2019-12-26 15:05:53,539 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_120.pickle
 - val_f1: 0.9944
Epoch 122/300
 - 6s - loss: 0.0030 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 123/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 124/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9945
Epoch 125/300
 - 6s - loss: 0.0039 - val_loss: 0.0026
 - val_f1: 0.9938
Epoch 126/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9938
Epoch 127/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 128/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9939
Epoch 129/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
 - val_f1: 0.9928
Epoch 130/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 131/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 132/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 133/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 134/300
 - 6s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9946
Epoch 135/300
 - 6s - loss: 0.0030 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 136/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 137/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 138/300
 - 6s - loss: 0.0030 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 139/300
 - 6s - loss: 0.0032 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 140/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 141/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 142/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 143/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 144/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9937
Epoch 145/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 146/300
 - 6s - loss: 0.0029 - val_loss: 0.0048
 - val_f1: 0.9920
Epoch 147/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 148/300
 - 6s - loss: 0.0029 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 149/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 150/300
 - 6s - loss: 0.0030 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 151/300
 - 6s - loss: 0.0030 - val_loss: 0.0026
2019-12-26 15:09:34,515 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_150.pickle
 - val_f1: 0.9928
Epoch 152/300
 - 6s - loss: 0.0029 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 153/300
 - 6s - loss: 0.0029 - val_loss: 0.0026
 - val_f1: 0.9942
Epoch 154/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 155/300
 - 6s - loss: 0.0030 - val_loss: 0.0028
 - val_f1: 0.9944
Epoch 156/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 157/300
 - 6s - loss: 0.0029 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 158/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 159/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 160/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 161/300
 - 6s - loss: 0.0029 - val_loss: 0.0028
 - val_f1: 0.9926
Epoch 162/300
 - 6s - loss: 0.0029 - val_loss: 0.0027
 - val_f1: 0.9936
Epoch 163/300
 - 6s - loss: 0.0032 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 164/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9941
Epoch 165/300
 - 6s - loss: 0.0029 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 166/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 167/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9939
Epoch 168/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 169/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 170/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9935
Epoch 171/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9950
Epoch 172/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 173/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 174/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 175/300
 - 6s - loss: 0.0028 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 176/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 177/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 178/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 179/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 180/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 181/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
2019-12-26 15:13:15,694 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_180.pickle
 - val_f1: 0.9939
Epoch 182/300
 - 6s - loss: 0.0028 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 183/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 184/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9949
Epoch 185/300
 - 6s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 186/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 187/300
 - 6s - loss: 0.0027 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 188/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 189/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 190/300
 - 6s - loss: 0.0028 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 191/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 192/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 193/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 194/300
 - 6s - loss: 0.0028 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 195/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 196/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 197/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9945
Epoch 198/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9927
Epoch 199/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 200/300
 - 6s - loss: 0.0027 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 201/300
 - 6s - loss: 0.0031 - val_loss: 0.0060
 - val_f1: 0.9801
Epoch 202/300
 - 6s - loss: 0.0030 - val_loss: 0.0025
 - val_f1: 0.9940
Epoch 203/300
 - 6s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 204/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 205/300
 - 6s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 206/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 207/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 208/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 209/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 210/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 211/300
 - 6s - loss: 0.0028 - val_loss: 0.0034
2019-12-26 15:16:57,506 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_210.pickle
 - val_f1: 0.9916
Epoch 212/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 213/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 214/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 215/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9946
Epoch 216/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 217/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 218/300
 - 6s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 219/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 220/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9936
Epoch 221/300
 - 6s - loss: 0.0027 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 222/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9930
Epoch 223/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 224/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 225/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 226/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 227/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 228/300
 - 6s - loss: 0.0027 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 229/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 230/300
 - 6s - loss: 0.0027 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 231/300
 - 6s - loss: 0.0027 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 232/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9936
Epoch 233/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9937
Epoch 234/300
 - 6s - loss: 0.0027 - val_loss: 0.0030
 - val_f1: 0.9936
Epoch 235/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9946
Epoch 236/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9924
Epoch 237/300
 - 6s - loss: 0.0027 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 238/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9927
Epoch 239/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 240/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 241/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
2019-12-26 15:20:39,649 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_240.pickle
 - val_f1: 0.9952
Epoch 242/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 243/300
 - 6s - loss: 0.0027 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 244/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9942
Epoch 245/300
 - 6s - loss: 0.0026 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 246/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 247/300
 - 6s - loss: 0.0027 - val_loss: 0.0038
 - val_f1: 0.9931
Epoch 248/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9938
Epoch 249/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 250/300
 - 6s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9891
Epoch 251/300
 - 6s - loss: 0.0028 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 252/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9947
Epoch 253/300
 - 6s - loss: 0.0026 - val_loss: 0.0028
 - val_f1: 0.9940
Epoch 254/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9928
Epoch 255/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 256/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9930
Epoch 257/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9943
Epoch 258/300
 - 6s - loss: 0.0027 - val_loss: 0.0028
 - val_f1: 0.9939
Epoch 259/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 260/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9950
Epoch 261/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9932
Epoch 262/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 263/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9931
Epoch 264/300
 - 6s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 265/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9938
Epoch 266/300
 - 6s - loss: 0.0030 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 267/300
 - 6s - loss: 0.0026 - val_loss: 0.0026
 - val_f1: 0.9929
Epoch 268/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 269/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 270/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9928
Epoch 271/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
2019-12-26 15:24:21,746 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/_model_epoch_270.pickle
 - val_f1: 0.9941
Epoch 272/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 273/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9940
Epoch 274/300
 - 6s - loss: 0.0026 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 275/300
 - 6s - loss: 0.0028 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 276/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9950
Epoch 277/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9947
Epoch 278/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9951
Epoch 279/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9951
Epoch 280/300
 - 6s - loss: 0.0026 - val_loss: 0.0023
 - val_f1: 0.9949
Epoch 281/300
 - 6s - loss: 0.0026 - val_loss: 0.0025
 - val_f1: 0.9929
Epoch 282/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9942
Epoch 283/300
 - 6s - loss: 0.0025 - val_loss: 0.0023
 - val_f1: 0.9948
Epoch 284/300
 - 6s - loss: 0.0028 - val_loss: 0.0026
 - val_f1: 0.9948
Epoch 285/300
 - 6s - loss: 0.0029 - val_loss: 0.0025
 - val_f1: 0.9948
Epoch 286/300
 - 6s - loss: 0.0028 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 287/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 288/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 289/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
 - val_f1: 0.9940
Epoch 290/300
 - 6s - loss: 0.0027 - val_loss: 0.0027
 - val_f1: 0.9940
Epoch 291/300
 - 6s - loss: 0.0027 - val_loss: 0.0025
 - val_f1: 0.9944
Epoch 292/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9945
Epoch 293/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9951
Epoch 294/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9935
Epoch 295/300
 - 6s - loss: 0.0027 - val_loss: 0.0041
 - val_f1: 0.9905
Epoch 296/300
 - 6s - loss: 0.0028 - val_loss: 0.0025
 - val_f1: 0.9950
Epoch 297/300
 - 6s - loss: 0.0027 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 298/300
 - 6s - loss: 0.0026 - val_loss: 0.0024
 - val_f1: 0.9948
Epoch 299/300
 - 6s - loss: 0.0027 - val_loss: 0.0024
 - val_f1: 0.9949
Epoch 300/300
 - 6s - loss: 0.0027 - val_loss: 0.0026
2019-12-26 15:27:58,205 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 15:28:04,693 [INFO] Last epoch loss evaluation: train_loss = 0.002091, val_loss = 0.002266
2019-12-26 15:28:04,693 [INFO] Training complete. time_to_train = 2226.35 sec, 37.11 min
2019-12-26 15:28:04,697 [INFO] Model saved to results_selected_models/selected_ids17_lstm_shallow_rep5/best_model.pickle
2019-12-26 15:28:04,701 [INFO] Training history saved to: results_selected_models/selected_ids17_lstm_shallow_rep5/training_error_history.csv
2019-12-26 15:28:04,841 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep5/training_error_history.png
2019-12-26 15:28:04,963 [INFO] Plot saved to: results_selected_models/selected_ids17_lstm_shallow_rep5/training_f1_history.png
2019-12-26 15:28:04,963 [INFO] Making predictions on training, validation, testing data
2019-12-26 15:28:11,982 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 15:28:22,369 [INFO] Dataset: Testing. Classification report below
2019-12-26 15:28:22,369 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25604
         DoS GoldenEye       0.99      0.98      0.99      2058
              DoS Hulk       0.98      0.99      0.98     46023
      DoS Slowhttptest       0.91      0.99      0.95      1100
         DoS slowloris       0.99      0.98      0.98      1159
           FTP-Patator       0.99      1.00      0.99      1586
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.96      0.96      1179
Web Attack Brute Force       0.94      0.11      0.20       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.89      0.78      0.80    565536
          weighted avg       1.00      1.00      0.99    565536

2019-12-26 15:28:22,370 [INFO] Overall accuracy (micro avg): 0.9952717422056244
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 15:28:34,161 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0004                   0.0047  0.9953
1     Macro avg        0.9992         0.8931                       0.7804                0.0012                   0.2196  0.7979
2  Weighted avg        0.9961         0.9950                       0.9953                0.0101                   0.0047  0.9949
2019-12-26 15:28:44,586 [INFO] Dataset: Validation. Classification report below
2019-12-26 15:28:44,586 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454243
                   Bot       0.96      0.33      0.49       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.98      0.99      2059
              DoS Hulk       0.98      0.99      0.99     46023
      DoS Slowhttptest       0.90      0.98      0.94      1099
         DoS slowloris       0.98      0.98      0.98      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31758
           SSH-Patator       0.96      0.96      0.96      1180
Web Attack Brute Force       0.79      0.08      0.14       301
        Web Attack XSS       0.50      0.02      0.03       131

             micro avg       1.00      1.00      1.00    565536
             macro avg       0.92      0.78      0.79    565536
          weighted avg       1.00      1.00      0.99    565536

2019-12-26 15:28:44,586 [INFO] Overall accuracy (micro avg): 0.9954078962258813
2019-12-26 15:28:56,434 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9954         0.9954                       0.9954                0.0004                   0.0046  0.9954
1     Macro avg        0.9992         0.9213                       0.7753                0.0012                   0.2247  0.7915
2  Weighted avg        0.9962         0.9952                       0.9954                0.0098                   0.0046  0.9950
2019-12-26 15:29:30,668 [INFO] Dataset: Training. Classification report below
2019-12-26 15:29:30,668 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362781
                   Bot       0.98      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.99      6176
              DoS Hulk       0.98      0.99      0.99    138073
      DoS Slowhttptest       0.92      0.99      0.96      3300
         DoS slowloris       0.99      0.99      0.99      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95281
           SSH-Patator       0.97      0.97      0.97      3538
Web Attack Brute Force       0.88      0.11      0.19       904
        Web Attack XSS       1.00      0.02      0.04       391

             micro avg       1.00      1.00      1.00   1696672
             macro avg       0.98      0.78      0.80   1696672
          weighted avg       1.00      1.00      1.00   1696672

2019-12-26 15:29:30,668 [INFO] Overall accuracy (micro avg): 0.9956426463099527
2019-12-26 15:30:09,543 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0004                   0.0044  0.9956
1     Macro avg        0.9993         0.9753                       0.7831                0.0012                   0.2169  0.8030
2  Weighted avg        0.9964         0.9956                       0.9956                0.0096                   0.0044  0.9952
2019-12-26 15:30:09,567 [INFO] Results saved to: results_selected_models/selected_ids17_lstm_shallow_rep5/selected_ids17_lstm_shallow_rep5_results.xlsx
2019-12-26 15:30:09,571 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-26 15:30:09,644 [INFO] Created directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep1
2019-12-26 15:30:09,645 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_lstm_shallow_rep1/run_log.log
2019-12-26 15:30:09,645 [INFO] ================= Running experiment no. 1  ================= 

2019-12-26 15:30:09,645 [INFO] Experiment parameters given below
2019-12-26 15:30:09,645 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_lstm_shallow_rep1', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_lstm_shallow_rep1'}
2019-12-26 15:30:09,645 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep1/tf_logs_run_2019_12_26-15_30_09
2019-12-26 15:30:09,645 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-26 15:30:09,653 [INFO] Reading X, y files
2019-12-26 15:30:09,653 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-26 15:30:15,576 [INFO] Reading complete. time_to_read=5.92 seconds
2019-12-26 15:30:15,576 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-26 15:30:17,250 [INFO] Reading complete. time_to_read=1.67 seconds
2019-12-26 15:30:17,251 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-26 15:30:18,909 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-26 15:30:18,909 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-26 15:30:19,394 [INFO] Reading complete. time_to_read=0.48 seconds
2019-12-26 15:30:19,394 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-26 15:30:19,587 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-26 15:30:19,587 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-26 15:30:19,763 [INFO] Reading complete. time_to_read=0.18 seconds
2019-12-26 15:30:22,545 [INFO] Preparing flow sequences
2019-12-26 15:30:47,552 [INFO] Extracting flows complete. time_taken = 25.01 sec
2019-12-26 15:30:48,872 [INFO] Initializing model
2019-12-26 15:30:49,112 [INFO] _________________________________________________________________
2019-12-26 15:30:49,112 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 15:30:49,112 [INFO] =================================================================
2019-12-26 15:30:49,112 [INFO] lstm_11 (LSTM)               (None, 32, 32)            14080     
2019-12-26 15:30:49,112 [INFO] _________________________________________________________________
2019-12-26 15:30:49,112 [INFO] batch_normalization_11 (Batc (None, 32, 32)            128       
2019-12-26 15:30:49,112 [INFO] _________________________________________________________________
2019-12-26 15:30:49,112 [INFO] dropout_11 (Dropout)         (None, 32, 32)            0         
2019-12-26 15:30:49,112 [INFO] _________________________________________________________________
2019-12-26 15:30:49,112 [INFO] time_distributed_11 (TimeDis (None, 32, 15)            495       
2019-12-26 15:30:49,112 [INFO] =================================================================
2019-12-26 15:30:49,112 [INFO] Total params: 14,703
2019-12-26 15:30:49,113 [INFO] Trainable params: 14,639
2019-12-26 15:30:49,113 [INFO] Non-trainable params: 64
2019-12-26 15:30:49,113 [INFO] _________________________________________________________________
2019-12-26 15:30:49,113 [INFO] Training model
 - val_f1: 0.9941
Train on 60514 samples, validate on 20171 samples
Epoch 1/300
 - 7s - loss: 0.1201 - val_loss: 0.0342
 - val_f1: 0.9302
Epoch 2/300
 - 6s - loss: 0.0240 - val_loss: 0.0178
 - val_f1: 0.9599
Epoch 3/300
 - 6s - loss: 0.0149 - val_loss: 0.0137
 - val_f1: 0.9628
Epoch 4/300
 - 6s - loss: 0.0119 - val_loss: 0.0109
 - val_f1: 0.9723
Epoch 5/300
 - 6s - loss: 0.0107 - val_loss: 0.0103
 - val_f1: 0.9745
Epoch 6/300
 - 6s - loss: 0.0101 - val_loss: 0.0100
 - val_f1: 0.9753
Epoch 7/300
 - 6s - loss: 0.0097 - val_loss: 0.0098
 - val_f1: 0.9748
Epoch 8/300
 - 6s - loss: 0.0094 - val_loss: 0.0092
 - val_f1: 0.9767
Epoch 9/300
 - 6s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9771
Epoch 10/300
 - 6s - loss: 0.0090 - val_loss: 0.0089
 - val_f1: 0.9770
Epoch 11/300
 - 6s - loss: 0.0089 - val_loss: 0.0087
 - val_f1: 0.9772
Epoch 12/300
 - 6s - loss: 0.0088 - val_loss: 0.0088
 - val_f1: 0.9760
Epoch 13/300
 - 6s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 14/300
 - 6s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9767
Epoch 15/300
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 16/300
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 17/300
 - 6s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 18/300
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 19/300
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 20/300
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 21/300
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 22/300
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 23/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 24/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 25/300
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 26/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 27/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 28/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 29/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 30/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9771
Epoch 31/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 15:35:24,699 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_30.pickle
 - val_f1: 0.9777
Epoch 32/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 33/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 34/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 35/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9765
Epoch 36/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 37/300
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9759
Epoch 38/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 39/300
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9768
Epoch 40/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9765
Epoch 41/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 42/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9763
Epoch 43/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9765
Epoch 44/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 45/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9773
Epoch 46/300
 - 6s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9760
Epoch 47/300
 - 6s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 48/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 49/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 50/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 51/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 52/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 53/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 54/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 55/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 56/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 57/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 58/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 59/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 60/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 61/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
2019-12-26 15:39:46,930 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_60.pickle
 - val_f1: 0.9781
Epoch 62/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 63/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 64/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 65/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 66/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 67/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 68/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 69/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 70/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 71/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 72/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 73/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 74/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 75/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 76/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 77/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 78/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 79/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 80/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 81/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 82/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 83/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 84/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 85/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 86/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 87/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 88/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 89/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 90/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 91/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
2019-12-26 15:44:09,174 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_90.pickle
 - val_f1: 0.9778
Epoch 92/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 93/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 94/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 95/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 96/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 97/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 98/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 99/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 100/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 101/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 102/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 103/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 104/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 105/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 106/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 107/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 108/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 109/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 110/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 111/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 112/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 113/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 114/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 115/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 116/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9766
Epoch 117/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 118/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 119/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 120/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 121/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
2019-12-26 15:48:31,412 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_120.pickle
 - val_f1: 0.9778
Epoch 122/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 123/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 124/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 125/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 126/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 127/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 128/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 129/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 130/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 131/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 132/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 133/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 134/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 135/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 136/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 137/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 138/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 139/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 140/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 141/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 142/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 143/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 144/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 145/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 146/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 147/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 148/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 149/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 150/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 151/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
2019-12-26 15:52:53,636 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_150.pickle
 - val_f1: 0.9785
Epoch 152/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 153/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 154/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 155/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 156/300
 - 6s - loss: 0.0078 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 157/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 158/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 159/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 160/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 161/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 162/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 163/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 164/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 165/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 166/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 167/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 168/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 169/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 170/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 171/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 172/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 173/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 174/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 175/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 176/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 177/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 178/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 179/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 180/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 181/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
2019-12-26 15:57:15,744 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/_model_epoch_180.pickle
 - val_f1: 0.9782
Epoch 182/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 183/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 184/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 185/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 186/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
2019-12-26 15:58:01,756 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 15:58:09,368 [INFO] Last epoch loss evaluation: train_loss = 0.007576, val_loss = 0.007736
2019-12-26 15:58:09,368 [INFO] Training complete. time_to_train = 1640.25 sec, 27.34 min
2019-12-26 15:58:09,372 [INFO] Model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep1/best_model.pickle
2019-12-26 15:58:09,374 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep1/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 15:58:09,530 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep1/training_error_history.png
2019-12-26 15:58:09,654 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep1/training_f1_history.png
2019-12-26 15:58:09,654 [INFO] Making predictions on training, validation, testing data
2019-12-26 15:58:18,102 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 15:58:30,160 [INFO] Dataset: Testing. Classification report below
2019-12-26 15:58:30,161 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535639
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.25      0.40        24
        Brute Force -XSS       0.75      0.33      0.46         9
        DDOS attack-HOIC       1.00      1.00      1.00     27446
    DDOS attack-LOIC-UDP       0.67      0.91      0.77        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23008
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18477
DoS attacks-SlowHTTPTest       0.73      0.50      0.59      5596
   DoS attacks-Slowloris       0.96      0.85      0.90       440
          FTP-BruteForce       0.70      0.86      0.78      7718
           Infilteration       0.51      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.82      0.71      0.73    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 15:58:30,161 [INFO] Overall accuracy (micro avg): 0.9833749566208914
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 15:58:43,835 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8191                       0.7137                0.0044                   0.2863  0.7268
2  Weighted avg        0.9910         0.9788                       0.9834                0.0497                   0.0166  0.9784
2019-12-26 15:58:56,119 [INFO] Dataset: Validation. Classification report below
2019-12-26 15:58:56,119 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535636
                     Bot       1.00      1.00      1.00     11464
        Brute Force -Web       0.91      0.40      0.56        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.93      0.80        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.49      0.59      5596
   DoS attacks-Slowloris       0.96      0.87      0.91       439
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.38      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.82      0.75      0.76    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 15:58:56,119 [INFO] Overall accuracy (micro avg): 0.9833656610976154
2019-12-26 15:59:10,091 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8241                       0.7483                0.0044                   0.2517  0.7624
2  Weighted avg        0.9909         0.9775                       0.9834                0.0496                   0.0166  0.9783
2019-12-26 15:59:49,843 [INFO] Dataset: Training. Classification report below
2019-12-26 15:59:49,843 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606935
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.30      0.46        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.92      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.50      0.59     16787
   DoS attacks-Slowloris       0.98      0.91      0.95      1318
          FTP-BruteForce       0.70      0.87      0.78     23153
           Infilteration       0.58      0.01      0.02     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936448
               macro avg       0.91      0.76      0.78   1936448
            weighted avg       0.98      0.98      0.98   1936448

2019-12-26 15:59:49,843 [INFO] Overall accuracy (micro avg): 0.9835848935783456
2019-12-26 16:00:34,982 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.9144                       0.7559                0.0044                   0.2441  0.7849
2  Weighted avg        0.9911         0.9797                       0.9836                0.0493                   0.0164  0.9786
2019-12-26 16:00:35,008 [INFO] Results saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep1/selected_ids18_subset_lstm_shallow_rep1_results.xlsx
2019-12-26 16:00:35,013 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-26 16:00:35,098 [INFO] Created directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep2
2019-12-26 16:00:35,098 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_lstm_shallow_rep2/run_log.log
2019-12-26 16:00:35,098 [INFO] ================= Running experiment no. 2  ================= 

2019-12-26 16:00:35,098 [INFO] Experiment parameters given below
2019-12-26 16:00:35,099 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids18_subset_lstm_shallow_rep2', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_lstm_shallow_rep2'}
2019-12-26 16:00:35,099 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep2/tf_logs_run_2019_12_26-16_00_35
2019-12-26 16:00:35,099 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-26 16:00:35,099 [INFO] Reading X, y files
2019-12-26 16:00:35,099 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-26 16:00:40,712 [INFO] Reading complete. time_to_read=5.61 seconds
2019-12-26 16:00:40,712 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-26 16:00:42,272 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 16:00:42,273 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-26 16:00:43,830 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 16:00:43,831 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-26 16:00:44,083 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-26 16:00:44,083 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-26 16:00:44,169 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 16:00:44,169 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-26 16:00:44,255 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 16:00:47,009 [INFO] Preparing flow sequences
2019-12-26 16:01:13,160 [INFO] Extracting flows complete. time_taken = 26.15 sec
2019-12-26 16:01:14,530 [INFO] Initializing model
2019-12-26 16:01:14,779 [INFO] _________________________________________________________________
2019-12-26 16:01:14,780 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 16:01:14,780 [INFO] =================================================================
2019-12-26 16:01:14,780 [INFO] lstm_12 (LSTM)               (None, 32, 32)            14080     
2019-12-26 16:01:14,780 [INFO] _________________________________________________________________
2019-12-26 16:01:14,780 [INFO] batch_normalization_12 (Batc (None, 32, 32)            128       
2019-12-26 16:01:14,780 [INFO] _________________________________________________________________
2019-12-26 16:01:14,780 [INFO] dropout_12 (Dropout)         (None, 32, 32)            0         
2019-12-26 16:01:14,780 [INFO] _________________________________________________________________
2019-12-26 16:01:14,780 [INFO] time_distributed_12 (TimeDis (None, 32, 15)            495       
2019-12-26 16:01:14,780 [INFO] =================================================================
2019-12-26 16:01:14,780 [INFO] Total params: 14,703
2019-12-26 16:01:14,780 [INFO] Trainable params: 14,639
2019-12-26 16:01:14,780 [INFO] Non-trainable params: 64
2019-12-26 16:01:14,780 [INFO] _________________________________________________________________
2019-12-26 16:01:14,780 [INFO] Training model
 - val_f1: 0.9784
Epoch 00186: early stopping
Train on 60514 samples, validate on 20171 samples
Epoch 1/300
 - 7s - loss: 0.1189 - val_loss: 0.0396
 - val_f1: 0.8717
Epoch 2/300
 - 6s - loss: 0.0232 - val_loss: 0.0208
 - val_f1: 0.9527
Epoch 3/300
 - 6s - loss: 0.0134 - val_loss: 0.0149
 - val_f1: 0.9610
Epoch 4/300
 - 6s - loss: 0.0115 - val_loss: 0.0126
 - val_f1: 0.9643
Epoch 5/300
 - 6s - loss: 0.0106 - val_loss: 0.0114
 - val_f1: 0.9661
Epoch 6/300
 - 6s - loss: 0.0101 - val_loss: 0.0105
 - val_f1: 0.9704
Epoch 7/300
 - 6s - loss: 0.0097 - val_loss: 0.0100
 - val_f1: 0.9735
Epoch 8/300
 - 6s - loss: 0.0094 - val_loss: 0.0096
 - val_f1: 0.9755
Epoch 9/300
 - 6s - loss: 0.0092 - val_loss: 0.0094
 - val_f1: 0.9759
Epoch 10/300
 - 6s - loss: 0.0090 - val_loss: 0.0094
 - val_f1: 0.9756
Epoch 11/300
 - 6s - loss: 0.0089 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 12/300
 - 6s - loss: 0.0088 - val_loss: 0.0088
 - val_f1: 0.9766
Epoch 13/300
 - 6s - loss: 0.0087 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 14/300
 - 6s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9765
Epoch 15/300
 - 6s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9769
Epoch 16/300
 - 6s - loss: 0.0086 - val_loss: 0.0086
 - val_f1: 0.9766
Epoch 17/300
 - 6s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9755
Epoch 18/300
 - 6s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9753
Epoch 19/300
 - 6s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 20/300
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 21/300
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 22/300
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 23/300
 - 6s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9767
Epoch 24/300
 - 6s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9762
Epoch 25/300
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 26/300
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9757
Epoch 27/300
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9753
Epoch 28/300
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 29/300
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 30/300
 - 6s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9766
Epoch 31/300
 - 6s - loss: 0.0082 - val_loss: 0.0082
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 16:05:49,940 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/_model_epoch_30.pickle
 - val_f1: 0.9772
Epoch 32/300
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 33/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9766
Epoch 34/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9755
Epoch 35/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9767
Epoch 36/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9762
Epoch 37/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 38/300
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 39/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 40/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9760
Epoch 41/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 42/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 43/300
 - 6s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9752
Epoch 44/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 45/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 46/300
 - 6s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9768
Epoch 47/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 48/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 49/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 50/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 51/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 52/300
 - 6s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9750
Epoch 53/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 54/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 55/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 56/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 57/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 58/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 59/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 60/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 61/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
2019-12-26 16:10:11,022 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/_model_epoch_60.pickle
 - val_f1: 0.9773
Epoch 62/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9771
Epoch 63/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 64/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9768
Epoch 65/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 66/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 67/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 68/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9771
Epoch 69/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 70/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 71/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 72/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9773
Epoch 73/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 74/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 75/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 76/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 77/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 78/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 79/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 80/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 81/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 82/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 83/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 84/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 85/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 86/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 87/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 88/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 89/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 90/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 91/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
2019-12-26 16:14:32,292 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/_model_epoch_90.pickle
 - val_f1: 0.9780
Epoch 92/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 93/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 94/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 95/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 96/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 97/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 98/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 99/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 100/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 101/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 102/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 103/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 104/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 105/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 106/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 107/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 108/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 109/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 110/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 111/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 112/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 113/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 114/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 115/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 116/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 117/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 118/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 119/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 120/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 121/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
2019-12-26 16:18:53,631 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/_model_epoch_120.pickle
 - val_f1: 0.9781
Epoch 122/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 123/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 124/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 125/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 126/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 127/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 128/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 129/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 130/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 131/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 132/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 133/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 134/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 135/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 136/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 137/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 138/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 139/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 140/300
 - 6s - loss: 0.0080 - val_loss: 0.0085
 - val_f1: 0.9770
Epoch 141/300
 - 6s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 142/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 143/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 144/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 145/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 146/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 147/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 148/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 149/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 150/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 151/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
2019-12-26 16:23:14,898 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/_model_epoch_150.pickle
 - val_f1: 0.9779
Epoch 152/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 153/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 154/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 155/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9754
Epoch 156/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 157/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9762
Epoch 158/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9759
Epoch 159/300
 - 6s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9761
Epoch 160/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9769
Epoch 161/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9760
Epoch 162/300
 - 6s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9748
Epoch 163/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9763
Epoch 164/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 165/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9761
Epoch 166/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9767
Epoch 167/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9758
Epoch 168/300
 - 6s - loss: 0.0078 - val_loss: 0.0089
 - val_f1: 0.9760
Epoch 169/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9762
Epoch 170/300
 - 6s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9762
Epoch 171/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 172/300
 - 6s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9763
Epoch 173/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9763
Epoch 174/300
 - 6s - loss: 0.0078 - val_loss: 0.0084
2019-12-26 16:26:37,572 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 16:26:45,321 [INFO] Last epoch loss evaluation: train_loss = 0.007615, val_loss = 0.007761
2019-12-26 16:26:45,321 [INFO] Training complete. time_to_train = 1530.54 sec, 25.51 min
2019-12-26 16:26:45,325 [INFO] Model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep2/best_model.pickle
2019-12-26 16:26:45,328 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep2/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 16:26:45,493 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep2/training_error_history.png
2019-12-26 16:26:45,617 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep2/training_f1_history.png
2019-12-26 16:26:45,618 [INFO] Making predictions on training, validation, testing data
2019-12-26 16:26:53,981 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 16:27:06,045 [INFO] Dataset: Testing. Classification report below
2019-12-26 16:27:06,045 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535639
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.50      0.04      0.08        24
        Brute Force -XSS       1.00      0.22      0.36         9
        DDOS attack-HOIC       1.00      1.00      1.00     27446
    DDOS attack-LOIC-UDP       0.66      0.85      0.75        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23008
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18477
DoS attacks-SlowHTTPTest       0.74      0.49      0.59      5596
   DoS attacks-Slowloris       0.96      0.88      0.92       440
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.39      0.00      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.79      0.69      0.70    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 16:27:06,045 [INFO] Overall accuracy (micro avg): 0.9833207327351148
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 16:27:19,748 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7950                       0.6896                0.0045                   0.3104  0.6971
2  Weighted avg        0.9909         0.9775                       0.9833                0.0504                   0.0167  0.9782
2019-12-26 16:27:32,038 [INFO] Dataset: Validation. Classification report below
2019-12-26 16:27:32,038 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535636
                     Bot       1.00      1.00      1.00     11464
        Brute Force -Web       1.00      0.08      0.15        25
        Brute Force -XSS       1.00      0.56      0.71         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      0.88      0.79        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.48      0.59      5596
   DoS attacks-Slowloris       0.96      0.91      0.93       439
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.52      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.84      0.72      0.73    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 16:27:32,039 [INFO] Overall accuracy (micro avg): 0.9834555178226166
2019-12-26 16:27:46,007 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.8415                       0.7194                0.0044                   0.2806  0.7302
2  Weighted avg        0.9910         0.9790                       0.9835                0.0501                   0.0165  0.9783
2019-12-26 16:28:25,688 [INFO] Dataset: Training. Classification report below
2019-12-26 16:28:25,688 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606935
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.18      0.30        73
        Brute Force -XSS       1.00      0.42      0.59        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.93      0.81       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.75      0.49      0.59     16787
   DoS attacks-Slowloris       0.97      0.93      0.95      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.66      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936448
               macro avg       0.85      0.72      0.74   1936448
            weighted avg       0.98      0.98      0.98   1936448

2019-12-26 16:28:25,688 [INFO] Overall accuracy (micro avg): 0.9835549418316423
2019-12-26 16:29:10,742 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.8521                       0.7213                0.0044                   0.2787  0.7351
2  Weighted avg        0.9910         0.9805                       0.9836                0.0499                   0.0164  0.9784
2019-12-26 16:29:10,787 [INFO] Results saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep2/selected_ids18_subset_lstm_shallow_rep2_results.xlsx
2019-12-26 16:29:10,794 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-26 16:29:10,878 [INFO] Created directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep3
2019-12-26 16:29:10,884 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_lstm_shallow_rep3/run_log.log
2019-12-26 16:29:10,884 [INFO] ================= Running experiment no. 3  ================= 

2019-12-26 16:29:10,884 [INFO] Experiment parameters given below
2019-12-26 16:29:10,885 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids18_subset_lstm_shallow_rep3', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_lstm_shallow_rep3'}
2019-12-26 16:29:10,885 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep3/tf_logs_run_2019_12_26-16_29_10
2019-12-26 16:29:10,885 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-26 16:29:10,885 [INFO] Reading X, y files
2019-12-26 16:29:10,885 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-26 16:29:15,420 [INFO] Reading complete. time_to_read=4.53 seconds
2019-12-26 16:29:15,420 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-26 16:29:16,980 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 16:29:16,980 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-26 16:29:18,541 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 16:29:18,541 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-26 16:29:18,801 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 16:29:18,801 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-26 16:29:18,887 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 16:29:18,887 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-26 16:29:18,972 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-26 16:29:21,756 [INFO] Preparing flow sequences
2019-12-26 16:29:46,720 [INFO] Extracting flows complete. time_taken = 24.96 sec
2019-12-26 16:29:48,055 [INFO] Initializing model
2019-12-26 16:29:48,295 [INFO] _________________________________________________________________
2019-12-26 16:29:48,295 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 16:29:48,295 [INFO] =================================================================
2019-12-26 16:29:48,296 [INFO] lstm_13 (LSTM)               (None, 32, 32)            14080     
2019-12-26 16:29:48,296 [INFO] _________________________________________________________________
2019-12-26 16:29:48,296 [INFO] batch_normalization_13 (Batc (None, 32, 32)            128       
2019-12-26 16:29:48,296 [INFO] _________________________________________________________________
2019-12-26 16:29:48,296 [INFO] dropout_13 (Dropout)         (None, 32, 32)            0         
2019-12-26 16:29:48,296 [INFO] _________________________________________________________________
2019-12-26 16:29:48,296 [INFO] time_distributed_13 (TimeDis (None, 32, 15)            495       
2019-12-26 16:29:48,296 [INFO] =================================================================
2019-12-26 16:29:48,296 [INFO] Total params: 14,703
2019-12-26 16:29:48,296 [INFO] Trainable params: 14,639
2019-12-26 16:29:48,296 [INFO] Non-trainable params: 64
2019-12-26 16:29:48,296 [INFO] _________________________________________________________________
2019-12-26 16:29:48,296 [INFO] Training model
 - val_f1: 0.9762
Epoch 00174: early stopping
Train on 60514 samples, validate on 20171 samples
Epoch 1/300
 - 7s - loss: 0.1187 - val_loss: 0.0340
 - val_f1: 0.9106
Epoch 2/300
 - 6s - loss: 0.0229 - val_loss: 0.0177
 - val_f1: 0.9494
Epoch 3/300
 - 6s - loss: 0.0139 - val_loss: 0.0126
 - val_f1: 0.9639
Epoch 4/300
 - 6s - loss: 0.0117 - val_loss: 0.0117
 - val_f1: 0.9631
Epoch 5/300
 - 6s - loss: 0.0107 - val_loss: 0.0108
 - val_f1: 0.9659
Epoch 6/300
 - 6s - loss: 0.0101 - val_loss: 0.0095
 - val_f1: 0.9748
Epoch 7/300
 - 6s - loss: 0.0098 - val_loss: 0.0089
 - val_f1: 0.9771
Epoch 8/300
 - 6s - loss: 0.0095 - val_loss: 0.0089
 - val_f1: 0.9771
Epoch 9/300
 - 6s - loss: 0.0093 - val_loss: 0.0094
 - val_f1: 0.9741
Epoch 10/300
 - 6s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 11/300
 - 6s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9772
Epoch 12/300
 - 6s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9774
Epoch 13/300
 - 6s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 14/300
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 15/300
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 16/300
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 17/300
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 18/300
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 19/300
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 20/300
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 21/300
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 22/300
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9763
Epoch 23/300
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 24/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 25/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 26/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 27/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 28/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 29/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 30/300
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 31/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 16:34:25,525 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep3/_model_epoch_30.pickle
 - val_f1: 0.9777
Epoch 32/300
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 33/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 34/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 35/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 36/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 37/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 38/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 39/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 40/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 41/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 42/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 43/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 44/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 45/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 46/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 47/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 48/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 49/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 50/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 51/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 52/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 53/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 54/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 55/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 56/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 57/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 58/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 59/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 60/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 61/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
2019-12-26 16:38:48,946 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep3/_model_epoch_60.pickle
 - val_f1: 0.9781
Epoch 62/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 63/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 64/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 65/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 66/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 67/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 68/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 69/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 70/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 71/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 72/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 73/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 74/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 75/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 76/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 77/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 78/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 79/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 80/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 81/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 82/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 83/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 84/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 85/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 86/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 87/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 88/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 89/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 90/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 91/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
2019-12-26 16:43:12,072 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep3/_model_epoch_90.pickle
 - val_f1: 0.9780
Epoch 92/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 93/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 94/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 95/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 96/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 97/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 98/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 99/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 100/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 101/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 102/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 103/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 104/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 105/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 106/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 107/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 108/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 109/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 110/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 111/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 112/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 113/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 114/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 115/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 116/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 117/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 118/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 119/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
2019-12-26 16:47:20,108 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 16:47:28,117 [INFO] Last epoch loss evaluation: train_loss = 0.007752, val_loss = 0.007856
2019-12-26 16:47:28,117 [INFO] Training complete. time_to_train = 1059.82 sec, 17.66 min
2019-12-26 16:47:28,121 [INFO] Model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep3/best_model.pickle
2019-12-26 16:47:28,123 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep3/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 16:47:28,255 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep3/training_error_history.png
2019-12-26 16:47:28,385 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep3/training_f1_history.png
2019-12-26 16:47:28,385 [INFO] Making predictions on training, validation, testing data
2019-12-26 16:47:36,893 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 16:47:48,987 [INFO] Dataset: Testing. Classification report below
2019-12-26 16:47:48,987 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535639
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.75      0.12      0.21        24
        Brute Force -XSS       0.75      0.33      0.46         9
        DDOS attack-HOIC       1.00      1.00      1.00     27446
    DDOS attack-LOIC-UDP       0.79      0.73      0.76        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23008
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18477
DoS attacks-SlowHTTPTest       0.73      0.47      0.58      5596
   DoS attacks-Slowloris       0.99      0.75      0.85       440
          FTP-BruteForce       0.70      0.87      0.77      7718
           Infilteration       0.58      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.82      0.68      0.71    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 16:47:48,987 [INFO] Overall accuracy (micro avg): 0.9830620073372663
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 16:48:02,700 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.8170                       0.6847                0.0045                   0.3153  0.7079
2  Weighted avg        0.9908         0.9791                       0.9831                0.0512                   0.0169  0.9778
2019-12-26 16:48:14,963 [INFO] Dataset: Validation. Classification report below
2019-12-26 16:48:14,963 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535636
                     Bot       1.00      1.00      1.00     11464
        Brute Force -Web       0.71      0.20      0.31        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.75      0.59      0.66        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.47      0.57      5596
   DoS attacks-Slowloris       0.97      0.81      0.88       439
          FTP-BruteForce       0.69      0.88      0.78      7718
           Infilteration       0.48      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.82      0.71      0.73    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 16:48:14,963 [INFO] Overall accuracy (micro avg): 0.983111583461405
2019-12-26 16:48:28,907 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.8214                       0.7061                0.0045                   0.2939  0.7322
2  Weighted avg        0.9908         0.9782                       0.9831                0.0509                   0.0169  0.9779
2019-12-26 16:49:08,693 [INFO] Dataset: Training. Classification report below
2019-12-26 16:49:08,693 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606935
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.90      0.12      0.22        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.71      0.72       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.47      0.57     16787
   DoS attacks-Slowloris       0.99      0.81      0.89      1318
          FTP-BruteForce       0.69      0.88      0.78     23153
           Infilteration       0.68      0.00      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936448
               macro avg       0.85      0.70      0.72   1936448
            weighted avg       0.98      0.98      0.98   1936448

2019-12-26 16:49:08,694 [INFO] Overall accuracy (micro avg): 0.9831888075486664
2019-12-26 16:49:53,870 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8468                       0.6984                0.0045                   0.3016  0.7218
2  Weighted avg        0.9909         0.9802                       0.9832                0.0508                   0.0168  0.9780
2019-12-26 16:49:53,909 [INFO] Results saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep3/selected_ids18_subset_lstm_shallow_rep3_results.xlsx
2019-12-26 16:49:53,916 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-26 16:49:54,001 [INFO] Created directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep4
2019-12-26 16:49:54,002 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_lstm_shallow_rep4/run_log.log
2019-12-26 16:49:54,002 [INFO] ================= Running experiment no. 4  ================= 

2019-12-26 16:49:54,002 [INFO] Experiment parameters given below
2019-12-26 16:49:54,002 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids18_subset_lstm_shallow_rep4', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_lstm_shallow_rep4'}
2019-12-26 16:49:54,002 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep4/tf_logs_run_2019_12_26-16_49_54
2019-12-26 16:49:54,002 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-26 16:49:54,002 [INFO] Reading X, y files
2019-12-26 16:49:54,002 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-26 16:49:58,504 [INFO] Reading complete. time_to_read=4.50 seconds
2019-12-26 16:49:58,504 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-26 16:50:00,051 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-26 16:50:00,051 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-26 16:50:01,596 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-26 16:50:01,597 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-26 16:50:01,862 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 16:50:01,862 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-26 16:50:01,947 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 16:50:01,947 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-26 16:50:02,033 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 16:50:04,809 [INFO] Preparing flow sequences
2019-12-26 16:50:29,749 [INFO] Extracting flows complete. time_taken = 24.94 sec
2019-12-26 16:50:31,112 [INFO] Initializing model
2019-12-26 16:50:31,361 [INFO] _________________________________________________________________
2019-12-26 16:50:31,361 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 16:50:31,361 [INFO] =================================================================
2019-12-26 16:50:31,361 [INFO] lstm_14 (LSTM)               (None, 32, 32)            14080     
2019-12-26 16:50:31,361 [INFO] _________________________________________________________________
2019-12-26 16:50:31,362 [INFO] batch_normalization_14 (Batc (None, 32, 32)            128       
2019-12-26 16:50:31,362 [INFO] _________________________________________________________________
2019-12-26 16:50:31,362 [INFO] dropout_14 (Dropout)         (None, 32, 32)            0         
2019-12-26 16:50:31,362 [INFO] _________________________________________________________________
2019-12-26 16:50:31,362 [INFO] time_distributed_14 (TimeDis (None, 32, 15)            495       
2019-12-26 16:50:31,362 [INFO] =================================================================
2019-12-26 16:50:31,362 [INFO] Total params: 14,703
2019-12-26 16:50:31,362 [INFO] Trainable params: 14,639
2019-12-26 16:50:31,362 [INFO] Non-trainable params: 64
2019-12-26 16:50:31,362 [INFO] _________________________________________________________________
2019-12-26 16:50:31,362 [INFO] Training model
 - val_f1: 0.9781
Epoch 00119: early stopping
Train on 60514 samples, validate on 20171 samples
Epoch 1/300
 - 7s - loss: 0.1365 - val_loss: 0.0461
 - val_f1: 0.8245
Epoch 2/300
 - 6s - loss: 0.0299 - val_loss: 0.0215
 - val_f1: 0.9552
Epoch 3/300
 - 6s - loss: 0.0180 - val_loss: 0.0138
 - val_f1: 0.9619
Epoch 4/300
 - 6s - loss: 0.0141 - val_loss: 0.0113
 - val_f1: 0.9714
Epoch 5/300
 - 6s - loss: 0.0124 - val_loss: 0.0102
 - val_f1: 0.9735
Epoch 6/300
 - 6s - loss: 0.0114 - val_loss: 0.0097
 - val_f1: 0.9752
Epoch 7/300
 - 6s - loss: 0.0108 - val_loss: 0.0109
 - val_f1: 0.9655
Epoch 8/300
 - 6s - loss: 0.0104 - val_loss: 0.0101
 - val_f1: 0.9726
Epoch 9/300
 - 6s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9760
Epoch 10/300
 - 6s - loss: 0.0098 - val_loss: 0.0095
 - val_f1: 0.9760
Epoch 11/300
 - 6s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9769
Epoch 12/300
 - 6s - loss: 0.0093 - val_loss: 0.0088
 - val_f1: 0.9772
Epoch 13/300
 - 6s - loss: 0.0091 - val_loss: 0.0094
 - val_f1: 0.9744
Epoch 14/300
 - 6s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9751
Epoch 15/300
 - 6s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9773
Epoch 16/300
 - 6s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9770
Epoch 17/300
 - 6s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 18/300
 - 6s - loss: 0.0087 - val_loss: 0.0088
 - val_f1: 0.9762
Epoch 19/300
 - 6s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9753
Epoch 20/300
 - 6s - loss: 0.0086 - val_loss: 0.0087
 - val_f1: 0.9762
Epoch 21/300
 - 6s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 22/300
 - 6s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9764
Epoch 23/300
 - 6s - loss: 0.0084 - val_loss: 0.0088
 - val_f1: 0.9758
Epoch 24/300
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9754
Epoch 25/300
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 26/300
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9768
Epoch 27/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 28/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 29/300
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 30/300
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 31/300
 - 6s - loss: 0.0082 - val_loss: 0.0081
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 16:55:10,315 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_30.pickle
 - val_f1: 0.9775
Epoch 32/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9754
Epoch 33/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 34/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 35/300
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9746
Epoch 36/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9771
Epoch 37/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 38/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 39/300
 - 6s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9758
Epoch 40/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 41/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9753
Epoch 42/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9770
Epoch 43/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 44/300
 - 6s - loss: 0.0081 - val_loss: 0.0083
 - val_f1: 0.9765
Epoch 45/300
 - 6s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 46/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 47/300
 - 6s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9774
Epoch 48/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 49/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 50/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 51/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 52/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9771
Epoch 53/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 54/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 55/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 56/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 57/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 58/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 59/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 60/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9762
Epoch 61/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
2019-12-26 16:59:34,509 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_60.pickle
 - val_f1: 0.9778
Epoch 62/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 63/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 64/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 65/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9776
Epoch 66/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 67/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 68/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 69/300
 - 6s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9760
Epoch 70/300
 - 6s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 71/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9760
Epoch 72/300
 - 6s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9757
Epoch 73/300
 - 6s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9711
Epoch 74/300
 - 6s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9768
Epoch 75/300
 - 6s - loss: 0.0079 - val_loss: 0.0083
 - val_f1: 0.9770
Epoch 76/300
 - 6s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 77/300
 - 6s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9764
Epoch 78/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9761
Epoch 79/300
 - 6s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 80/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9765
Epoch 81/300
 - 6s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 82/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 83/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 84/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 85/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 86/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 87/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 88/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 89/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 90/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 91/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
2019-12-26 17:03:58,518 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_90.pickle
 - val_f1: 0.9782
Epoch 92/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 93/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 94/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 95/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 96/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 97/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 98/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 99/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 100/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 101/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 102/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 103/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 104/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 105/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 106/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 107/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 108/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 109/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 110/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9772
Epoch 111/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 112/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 113/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 114/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 115/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 116/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 117/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 118/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 119/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 120/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 121/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
2019-12-26 17:08:21,929 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_120.pickle
 - val_f1: 0.9782
Epoch 122/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 123/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 124/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 125/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 126/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 127/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 128/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 129/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 130/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 131/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 132/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 133/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 134/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 135/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 136/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 137/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 138/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 139/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 140/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 141/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 142/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 143/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 144/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 145/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 146/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 147/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 148/300
 - 6s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 149/300
 - 6s - loss: 0.0084 - val_loss: 0.0106
 - val_f1: 0.9709
Epoch 150/300
 - 6s - loss: 0.0079 - val_loss: 0.0156
 - val_f1: 0.9516
Epoch 151/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
2019-12-26 17:12:45,286 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_150.pickle
 - val_f1: 0.9756
Epoch 152/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 153/300
 - 6s - loss: 0.0079 - val_loss: 0.0133
 - val_f1: 0.9555
Epoch 154/300
 - 6s - loss: 0.0080 - val_loss: 0.0108
 - val_f1: 0.9720
Epoch 155/300
 - 6s - loss: 0.0079 - val_loss: 0.0099
 - val_f1: 0.9733
Epoch 156/300
 - 6s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9752
Epoch 157/300
 - 6s - loss: 0.0078 - val_loss: 0.0091
 - val_f1: 0.9762
Epoch 158/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 159/300
 - 6s - loss: 0.0078 - val_loss: 0.0088
 - val_f1: 0.9760
Epoch 160/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9765
Epoch 161/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9767
Epoch 162/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9764
Epoch 163/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9763
Epoch 164/300
 - 6s - loss: 0.0078 - val_loss: 0.0087
 - val_f1: 0.9761
Epoch 165/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 166/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9764
Epoch 167/300
 - 6s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 168/300
 - 6s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9763
Epoch 169/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 170/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 171/300
 - 6s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9773
Epoch 172/300
 - 6s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9765
Epoch 173/300
 - 6s - loss: 0.0077 - val_loss: 0.0084
 - val_f1: 0.9765
Epoch 174/300
 - 6s - loss: 0.0078 - val_loss: 0.0083
 - val_f1: 0.9771
Epoch 175/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9771
Epoch 176/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 177/300
 - 6s - loss: 0.0077 - val_loss: 0.0084
 - val_f1: 0.9767
Epoch 178/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 179/300
 - 6s - loss: 0.0077 - val_loss: 0.0084
 - val_f1: 0.9769
Epoch 180/300
 - 6s - loss: 0.0077 - val_loss: 0.0084
 - val_f1: 0.9768
Epoch 181/300
 - 6s - loss: 0.0077 - val_loss: 0.0082
2019-12-26 17:17:08,489 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/_model_epoch_180.pickle
 - val_f1: 0.9777
Epoch 182/300
 - 6s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 183/300
 - 6s - loss: 0.0080 - val_loss: 0.0085
 - val_f1: 0.9764
Epoch 184/300
 - 6s - loss: 0.0079 - val_loss: 0.0096
 - val_f1: 0.9736
Epoch 185/300
 - 6s - loss: 0.0078 - val_loss: 0.0089
2019-12-26 17:17:45,926 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 17:17:53,892 [INFO] Last epoch loss evaluation: train_loss = 0.007613, val_loss = 0.007775
2019-12-26 17:17:53,893 [INFO] Training complete. time_to_train = 1642.53 sec, 27.38 min
2019-12-26 17:17:53,897 [INFO] Model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep4/best_model.pickle
2019-12-26 17:17:53,900 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep4/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 17:17:54,040 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep4/training_error_history.png
2019-12-26 17:17:54,174 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep4/training_f1_history.png
2019-12-26 17:17:54,174 [INFO] Making predictions on training, validation, testing data
2019-12-26 17:18:02,905 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 17:18:14,957 [INFO] Dataset: Testing. Classification report below
2019-12-26 17:18:14,958 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535639
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27446
    DDOS attack-LOIC-UDP       0.69      0.76      0.72        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23008
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18477
DoS attacks-SlowHTTPTest       0.74      0.47      0.58      5596
   DoS attacks-Slowloris       0.97      0.92      0.94       440
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.45      0.01      0.01      6403
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.83      0.72      0.75    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 17:18:14,958 [INFO] Overall accuracy (micro avg): 0.9832572133260622
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-26 17:18:28,650 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.8341                       0.7240                0.0044                   0.2760  0.7451
2  Weighted avg        0.9909         0.9781                       0.9833                0.0497                   0.0167  0.9781
2019-12-26 17:18:40,930 [INFO] Dataset: Validation. Classification report below
2019-12-26 17:18:40,930 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535636
                     Bot       1.00      1.00      1.00     11464
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      0.74      0.72        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.47      0.58      5596
   DoS attacks-Slowloris       0.95      0.94      0.95       439
          FTP-BruteForce       0.70      0.89      0.78      7718
           Infilteration       0.41      0.01      0.01      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.83      0.73      0.75    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 17:18:40,930 [INFO] Overall accuracy (micro avg): 0.9833517178127014
2019-12-26 17:18:54,891 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8323                       0.7297                0.0044                   0.2703  0.7476
2  Weighted avg        0.9909         0.9778                       0.9834                0.0494                   0.0166  0.9782
2019-12-26 17:19:34,650 [INFO] Dataset: Training. Classification report below
2019-12-26 17:19:34,650 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606935
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.01      0.03        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.82      0.78       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.47      0.58     16787
   DoS attacks-Slowloris       0.98      0.97      0.97      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.66      0.01      0.02     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936448
               macro avg       0.92      0.73      0.75   1936448
            weighted avg       0.98      0.98      0.98   1936448

2019-12-26 17:19:34,650 [INFO] Overall accuracy (micro avg): 0.9834754147800508
2019-12-26 17:20:19,794 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.9194                       0.7327                0.0044                   0.2673  0.7533
2  Weighted avg        0.9911         0.9805                       0.9835                0.0491                   0.0165  0.9784
2019-12-26 17:20:19,821 [INFO] Results saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep4/selected_ids18_subset_lstm_shallow_rep4_results.xlsx
2019-12-26 17:20:19,828 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-26 17:20:19,915 [INFO] Created directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep5
2019-12-26 17:20:19,916 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_lstm_shallow_rep5/run_log.log
2019-12-26 17:20:19,916 [INFO] ================= Running experiment no. 5  ================= 

2019-12-26 17:20:19,916 [INFO] Experiment parameters given below
2019-12-26 17:20:19,916 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids18_subset_lstm_shallow_rep5', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'BENIGN', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_lstm_shallow_rep5'}
2019-12-26 17:20:19,916 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_lstm_shallow_rep5/tf_logs_run_2019_12_26-17_20_19
2019-12-26 17:20:19,916 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-26 17:20:19,916 [INFO] Reading X, y files
2019-12-26 17:20:19,916 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-26 17:20:24,435 [INFO] Reading complete. time_to_read=4.52 seconds
2019-12-26 17:20:24,435 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-26 17:20:25,992 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 17:20:25,992 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-26 17:20:27,551 [INFO] Reading complete. time_to_read=1.56 seconds
2019-12-26 17:20:27,551 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-26 17:20:27,806 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-26 17:20:27,806 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-26 17:20:27,893 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 17:20:27,893 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-26 17:20:27,980 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-26 17:20:30,760 [INFO] Preparing flow sequences
2019-12-26 17:20:55,660 [INFO] Extracting flows complete. time_taken = 24.90 sec
2019-12-26 17:20:57,017 [INFO] Initializing model
2019-12-26 17:20:58,132 [INFO] _________________________________________________________________
2019-12-26 17:20:58,132 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-26 17:20:58,132 [INFO] =================================================================
2019-12-26 17:20:58,132 [INFO] lstm_15 (LSTM)               (None, 32, 32)            14080     
2019-12-26 17:20:58,132 [INFO] _________________________________________________________________
2019-12-26 17:20:58,132 [INFO] batch_normalization_15 (Batc (None, 32, 32)            128       
2019-12-26 17:20:58,133 [INFO] _________________________________________________________________
2019-12-26 17:20:58,133 [INFO] dropout_15 (Dropout)         (None, 32, 32)            0         
2019-12-26 17:20:58,133 [INFO] _________________________________________________________________
2019-12-26 17:20:58,133 [INFO] time_distributed_15 (TimeDis (None, 32, 15)            495       
2019-12-26 17:20:58,133 [INFO] =================================================================
2019-12-26 17:20:58,133 [INFO] Total params: 14,703
2019-12-26 17:20:58,133 [INFO] Trainable params: 14,639
2019-12-26 17:20:58,133 [INFO] Non-trainable params: 64
2019-12-26 17:20:58,133 [INFO] _________________________________________________________________
2019-12-26 17:20:58,133 [INFO] Training model
 - val_f1: 0.9757
Epoch 00185: early stopping
Train on 60514 samples, validate on 20171 samples
Epoch 1/300
 - 8s - loss: 0.1320 - val_loss: 0.0449
 - val_f1: 0.8304
Epoch 2/300
 - 6s - loss: 0.0289 - val_loss: 0.0236
 - val_f1: 0.9329
Epoch 3/300
 - 7s - loss: 0.0179 - val_loss: 0.0155
 - val_f1: 0.9591
Epoch 4/300
 - 6s - loss: 0.0133 - val_loss: 0.0115
 - val_f1: 0.9725
Epoch 5/300
 - 6s - loss: 0.0117 - val_loss: 0.0100
 - val_f1: 0.9746
Epoch 6/300
 - 6s - loss: 0.0109 - val_loss: 0.0096
 - val_f1: 0.9748
Epoch 7/300
 - 6s - loss: 0.0104 - val_loss: 0.0095
 - val_f1: 0.9748
Epoch 8/300
 - 6s - loss: 0.0100 - val_loss: 0.0094
 - val_f1: 0.9750
Epoch 9/300
 - 6s - loss: 0.0097 - val_loss: 0.0092
 - val_f1: 0.9751
Epoch 10/300
 - 6s - loss: 0.0094 - val_loss: 0.0092
 - val_f1: 0.9753
Epoch 11/300
 - 6s - loss: 0.0093 - val_loss: 0.0092
 - val_f1: 0.9753
Epoch 12/300
 - 6s - loss: 0.0091 - val_loss: 0.0092
 - val_f1: 0.9753
Epoch 13/300
 - 6s - loss: 0.0090 - val_loss: 0.0090
 - val_f1: 0.9758
Epoch 14/300
 - 6s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9762
Epoch 15/300
 - 6s - loss: 0.0088 - val_loss: 0.0090
 - val_f1: 0.9757
Epoch 16/300
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9766
Epoch 17/300
 - 6s - loss: 0.0087 - val_loss: 0.0087
 - val_f1: 0.9765
Epoch 18/300
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9771
Epoch 19/300
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 20/300
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9772
Epoch 21/300
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 22/300
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 23/300
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 24/300
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 25/300
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 26/300
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 27/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 28/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 29/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 30/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 31/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-26 17:25:37,383 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_30.pickle
 - val_f1: 0.9777
Epoch 32/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 33/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 34/300
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 35/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 36/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 37/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 38/300
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 39/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 40/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 41/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 42/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 43/300
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 44/300
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 45/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 46/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 47/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9760
Epoch 48/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 49/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 50/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 51/300
 - 6s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 52/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 53/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 54/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 55/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 56/300
 - 6s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 57/300
 - 6s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 58/300
 - 6s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 59/300
 - 6s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 60/300
 - 6s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 61/300
 - 6s - loss: 0.0080 - val_loss: 0.0078
2019-12-26 17:30:01,215 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 63/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 64/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 65/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 66/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 67/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 68/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 69/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 70/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 71/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 72/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 73/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 74/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 75/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 76/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 77/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 78/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 79/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 80/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 81/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 82/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 83/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 84/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 85/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 86/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 87/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 88/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9765
Epoch 89/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 90/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 91/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
2019-12-26 17:34:25,177 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_90.pickle
 - val_f1: 0.9781
Epoch 92/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 93/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 94/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 95/300
 - 6s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 96/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 97/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 98/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 99/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 100/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 101/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 102/300
 - 6s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 103/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 104/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 105/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 106/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 107/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 108/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 109/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 110/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 111/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 112/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 113/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 114/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 115/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 116/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 117/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 118/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 119/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 120/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 121/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
2019-12-26 17:38:49,077 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_120.pickle
 - val_f1: 0.9779
Epoch 122/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 123/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 124/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 125/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 126/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 127/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 128/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 129/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 130/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 131/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 132/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 133/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 134/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 135/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 136/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 137/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 138/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 139/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 140/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 141/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 142/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 143/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 144/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 145/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 146/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 147/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 148/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 149/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 150/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 151/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
2019-12-26 17:43:12,968 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_150.pickle
 - val_f1: 0.9781
Epoch 152/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 153/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 154/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 155/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 156/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 157/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 158/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 159/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 160/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 161/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 162/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 163/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 164/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 165/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 166/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 167/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 168/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 169/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 170/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 171/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 172/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 173/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 174/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 175/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 176/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 177/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 178/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 179/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 180/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 181/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
2019-12-26 17:47:36,601 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_180.pickle
 - val_f1: 0.9782
Epoch 182/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 183/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 184/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 185/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 186/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 187/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 188/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 189/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 190/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 191/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 192/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 193/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 194/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 195/300
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 196/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 197/300
 - 6s - loss: 0.0082 - val_loss: 0.0094
 - val_f1: 0.9743
Epoch 198/300
 - 6s - loss: 0.0079 - val_loss: 0.0088
 - val_f1: 0.9744
Epoch 199/300
 - 6s - loss: 0.0078 - val_loss: 0.0092
 - val_f1: 0.9742
Epoch 200/300
 - 6s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 201/300
 - 6s - loss: 0.0078 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 202/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 203/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 204/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 205/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 206/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 207/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 208/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 209/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 210/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 211/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
2019-12-26 17:52:00,769 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_210.pickle
 - val_f1: 0.9783
Epoch 212/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 213/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 214/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 215/300
 - 6s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 216/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 217/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 218/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 219/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 220/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 221/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 222/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 223/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 224/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 225/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 226/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 227/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 228/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 229/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9784
Epoch 230/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 231/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 232/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 233/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 234/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 235/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 236/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 237/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 238/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 239/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 240/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 241/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
2019-12-26 17:56:24,645 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/_model_epoch_240.pickle
 - val_f1: 0.9782
Epoch 242/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 243/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 244/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 245/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 246/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 247/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 248/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 249/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 250/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 251/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 252/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9788
Epoch 253/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 254/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 255/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 256/300
 - 6s - loss: 0.0078 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 257/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 258/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 259/300
 - 6s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9785
Epoch 260/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 261/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 262/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 263/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 264/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 265/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 266/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 267/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 268/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 269/300
 - 6s - loss: 0.0077 - val_loss: 0.0078
2019-12-26 18:00:33,499 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-26 18:00:41,672 [INFO] Last epoch loss evaluation: train_loss = 0.007529, val_loss = 0.007740
2019-12-26 18:00:41,672 [INFO] Training complete. time_to_train = 2383.54 sec, 39.73 min
2019-12-26 18:00:41,676 [INFO] Model saved to results_selected_models/selected_ids18_subset_lstm_shallow_rep5/best_model.pickle
2019-12-26 18:00:41,712 [INFO] Training history saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep5/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-26 18:00:41,907 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep5/training_error_history.png
2019-12-26 18:00:42,033 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep5/training_f1_history.png
2019-12-26 18:00:42,033 [INFO] Making predictions on training, validation, testing data
2019-12-26 18:00:50,633 [INFO] Evaluating predictions (results)
2019-12-26 18:01:02,684 [INFO] Dataset: Testing. Classification report below
2019-12-26 18:01:02,684 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535639
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.17      0.29        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27446
    DDOS attack-LOIC-UDP       0.70      0.79      0.74        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23008
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18477
DoS attacks-SlowHTTPTest       0.74      0.48      0.58      5596
   DoS attacks-Slowloris       0.93      0.96      0.95       440
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.55      0.02      0.03      6403
           SQL Injection       0.67      0.50      0.57         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.88      0.74      0.76    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 18:01:02,684 [INFO] Overall accuracy (micro avg): 0.9833687596053741
2019-12-26 18:01:16,409 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8830                       0.7413                0.0044                   0.2587  0.7611
2  Weighted avg        0.9910         0.9792                       0.9834                0.0490                   0.0166  0.9784
2019-12-26 18:01:28,722 [INFO] Dataset: Validation. Classification report below
2019-12-26 18:01:28,722 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535636
                     Bot       1.00      1.00      1.00     11464
        Brute Force -Web       0.88      0.28      0.42        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.69      0.72      0.71        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.48      0.58      5596
   DoS attacks-Slowloris       0.92      0.97      0.95       439
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.48      0.01      0.03      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645472
               macro avg       0.89      0.75      0.78    645472
            weighted avg       0.98      0.98      0.98    645472

2019-12-26 18:01:28,722 [INFO] Overall accuracy (micro avg): 0.9834415745377026
2019-12-26 18:01:42,702 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.8919                       0.7506                0.0044                   0.2494  0.7766
2  Weighted avg        0.9910         0.9787                       0.9834                0.0491                   0.0166  0.9785
2019-12-26 18:02:22,408 [INFO] Dataset: Training. Classification report below
2019-12-26 18:02:22,408 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606935
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.96      0.32      0.47        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.75      0.89      0.81       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.49      0.59     16787
   DoS attacks-Slowloris       0.96      0.99      0.97      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.63      0.02      0.04     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936448
               macro avg       0.91      0.76      0.79   1936448
            weighted avg       0.98      0.98      0.98   1936448

2019-12-26 18:02:22,408 [INFO] Overall accuracy (micro avg): 0.9836876590541032
2019-12-26 18:03:07,491 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.9141                       0.7608                0.0043                   0.2392  0.7879
2  Weighted avg        0.9912         0.9804                       0.9837                0.0485                   0.0163  0.9788
2019-12-26 18:03:07,533 [INFO] Results saved to: results_selected_models/selected_ids18_subset_lstm_shallow_rep5/selected_ids18_subset_lstm_shallow_rep5_results.xlsx
2019-12-26 18:03:07,540 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-26 18:03:07,627 [INFO] ================= Finished running 15 experiments ================= 

 - val_f1: 0.9784
Epoch 00269: early stopping
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2019-12-27 20:07:42,364 [INFO] Read 10 experiments from file: experiment_specs/selected_model_tests/selected_lstm.csv
2019-12-27 20:07:42,364 [INFO] ================= Started running experiments ================= 

2019-12-27 20:07:42,364 [INFO] Created directory: results_selected_models/selected_kdd99_lstm_shallow_rep1
2019-12-27 20:07:42,364 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_lstm_shallow_rep1/run_log.log
2019-12-27 20:07:42,364 [INFO] ================= Running experiment no. 1  ================= 

2019-12-27 20:07:42,364 [INFO] Experiment parameters given below
2019-12-27 20:07:42,365 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_lstm_shallow_rep1', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_lstm_shallow_rep1'}
2019-12-27 20:07:42,365 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_lstm_shallow_rep1/tf_logs_run_2019_12_27-20_07_42
2019-12-27 20:07:42,365 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-27 20:07:42,366 [INFO] Reading X, y files
2019-12-27 20:07:42,366 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-27 20:07:42,374 [INFO] NumExpr defaulting to 8 threads.
2019-12-27 20:07:48,789 [INFO] Reading complete. time_to_read=6.42 seconds
2019-12-27 20:07:48,790 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-27 20:07:50,422 [INFO] Reading complete. time_to_read=1.63 seconds
2019-12-27 20:07:50,422 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-27 20:07:50,880 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-27 20:07:50,880 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-27 20:07:51,100 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-27 20:07:51,101 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-27 20:07:51,156 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-27 20:07:51,156 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-27 20:07:51,176 [INFO] Reading complete. time_to_read=0.02 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28158 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28171 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28172 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28173 thread 3 bound to OS proc set 3
2019-12-27 20:07:56,960 [INFO] Preparing flow sequences
2019-12-27 20:08:44,387 [INFO] Extracting flows complete. time_taken = 47.43 sec
2019-12-27 20:08:46,047 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-27 20:08:46,061 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-27 20:08:46,283 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-27 20:08:46,327 [INFO] _________________________________________________________________
2019-12-27 20:08:46,327 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 20:08:46,327 [INFO] =================================================================
2019-12-27 20:08:46,327 [INFO] lstm_1 (LSTM)                (None, 32, 32)            19968     
2019-12-27 20:08:46,327 [INFO] _________________________________________________________________
2019-12-27 20:08:46,327 [INFO] batch_normalization_1 (Batch (None, 32, 32)            128       
2019-12-27 20:08:46,328 [INFO] _________________________________________________________________
2019-12-27 20:08:46,328 [INFO] dropout_1 (Dropout)          (None, 32, 32)            0         
2019-12-27 20:08:46,328 [INFO] _________________________________________________________________
2019-12-27 20:08:46,328 [INFO] time_distributed_1 (TimeDist (None, 32, 5)             165       
2019-12-27 20:08:46,328 [INFO] =================================================================
2019-12-27 20:08:46,328 [INFO] Total params: 20,261
2019-12-27 20:08:46,328 [INFO] Trainable params: 20,197
2019-12-27 20:08:46,328 [INFO] Non-trainable params: 64
2019-12-27 20:08:46,328 [INFO] _________________________________________________________________
2019-12-27 20:08:46,328 [INFO] Training model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-27 20:08:46,744 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-27 20:08:47.535220: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2019-12-27 20:08:47.555562: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2019-12-27 20:08:47.555696: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557563f375c0 executing computations on platform Host. Devices:
2019-12-27 20:08:47.555717: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-27 20:08:47.555803: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28181 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28200 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28201 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28203 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28202 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28182 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28204 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28205 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28206 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28207 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28208 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28209 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28210 thread 16 bound to OS proc set 0
Train on 122460 samples, validate on 30615 samples
Epoch 1/300
 - 29s - loss: 0.0646 - val_loss: 0.0037
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28224 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28225 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 28158 tid 28226 thread 19 bound to OS proc set 3
 - val_f1: 0.9984
Epoch 2/300
 - 28s - loss: 0.0031 - val_loss: 0.0017
 - val_f1: 0.9991
Epoch 3/300
 - 28s - loss: 0.0017 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 4/300
 - 28s - loss: 0.0012 - val_loss: 9.3437e-04
 - val_f1: 0.9995
Epoch 5/300
 - 28s - loss: 9.8530e-04 - val_loss: 6.8597e-04
 - val_f1: 0.9996
Epoch 6/300
 - 28s - loss: 8.2056e-04 - val_loss: 6.0227e-04
 - val_f1: 0.9997
Epoch 7/300
 - 28s - loss: 7.1134e-04 - val_loss: 5.8191e-04
 - val_f1: 0.9997
Epoch 8/300
 - 28s - loss: 6.4678e-04 - val_loss: 5.4189e-04
 - val_f1: 0.9997
Epoch 9/300
 - 28s - loss: 5.8720e-04 - val_loss: 5.1190e-04
 - val_f1: 0.9997
Epoch 10/300
 - 28s - loss: 5.3304e-04 - val_loss: 4.7767e-04
 - val_f1: 0.9997
Epoch 11/300
 - 28s - loss: 5.0562e-04 - val_loss: 4.7819e-04
 - val_f1: 0.9997
Epoch 12/300
 - 28s - loss: 4.8522e-04 - val_loss: 4.7231e-04
 - val_f1: 0.9997
Epoch 13/300
 - 28s - loss: 4.7064e-04 - val_loss: 4.4039e-04
 - val_f1: 0.9997
Epoch 14/300
 - 28s - loss: 4.4509e-04 - val_loss: 4.2794e-04
 - val_f1: 0.9998
Epoch 15/300
 - 28s - loss: 4.4042e-04 - val_loss: 4.3070e-04
 - val_f1: 0.9997
Epoch 16/300
 - 28s - loss: 3.9799e-04 - val_loss: 4.0361e-04
 - val_f1: 0.9998
Epoch 17/300
 - 28s - loss: 3.8498e-04 - val_loss: 3.8885e-04
 - val_f1: 0.9998
Epoch 18/300
 - 28s - loss: 3.6343e-04 - val_loss: 3.7551e-04
 - val_f1: 0.9998
Epoch 19/300
 - 28s - loss: 3.5040e-04 - val_loss: 3.7922e-04
 - val_f1: 0.9998
Epoch 20/300
 - 28s - loss: 3.4328e-04 - val_loss: 3.8364e-04
 - val_f1: 0.9998
Epoch 21/300
 - 28s - loss: 3.4229e-04 - val_loss: 3.5615e-04
 - val_f1: 0.9998
Epoch 22/300
 - 28s - loss: 3.3272e-04 - val_loss: 3.8695e-04
 - val_f1: 0.9998
Epoch 23/300
 - 28s - loss: 3.2217e-04 - val_loss: 3.6903e-04
 - val_f1: 0.9998
Epoch 24/300
 - 28s - loss: 3.2319e-04 - val_loss: 3.5956e-04
 - val_f1: 0.9998
Epoch 25/300
 - 28s - loss: 3.1980e-04 - val_loss: 3.7356e-04
 - val_f1: 0.9998
Epoch 26/300
 - 28s - loss: 3.0517e-04 - val_loss: 3.6637e-04
 - val_f1: 0.9998
Epoch 27/300
 - 28s - loss: 3.0343e-04 - val_loss: 3.5372e-04
 - val_f1: 0.9998
Epoch 28/300
 - 28s - loss: 3.0506e-04 - val_loss: 3.5435e-04
 - val_f1: 0.9998
Epoch 29/300
 - 28s - loss: 2.8326e-04 - val_loss: 3.7792e-04
 - val_f1: 0.9998
Epoch 30/300
 - 28s - loss: 2.8440e-04 - val_loss: 3.5660e-04
 - val_f1: 0.9998
Epoch 31/300
 - 28s - loss: 2.8074e-04 - val_loss: 3.5277e-04
2019-12-27 20:27:00,999 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep1/_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 28s - loss: 2.7097e-04 - val_loss: 3.3580e-04
 - val_f1: 0.9998
Epoch 33/300
 - 28s - loss: 2.6851e-04 - val_loss: 3.5073e-04
 - val_f1: 0.9998
Epoch 34/300
 - 28s - loss: 2.6871e-04 - val_loss: 3.4586e-04
 - val_f1: 0.9998
Epoch 35/300
 - 28s - loss: 2.5445e-04 - val_loss: 3.5449e-04
 - val_f1: 0.9998
Epoch 36/300
 - 28s - loss: 2.6759e-04 - val_loss: 3.3927e-04
 - val_f1: 0.9998
Epoch 37/300
 - 28s - loss: 2.5073e-04 - val_loss: 3.6573e-04
 - val_f1: 0.9998
Epoch 38/300
 - 28s - loss: 2.5525e-04 - val_loss: 3.6511e-04
 - val_f1: 0.9998
Epoch 39/300
 - 28s - loss: 2.5263e-04 - val_loss: 3.6329e-04
 - val_f1: 0.9998
Epoch 40/300
 - 28s - loss: 2.5250e-04 - val_loss: 3.7888e-04
 - val_f1: 0.9998
Epoch 41/300
 - 28s - loss: 2.5229e-04 - val_loss: 3.5577e-04
 - val_f1: 0.9998
Epoch 42/300
 - 28s - loss: 2.3575e-04 - val_loss: 3.5786e-04
 - val_f1: 0.9998
Epoch 43/300
 - 28s - loss: 2.4431e-04 - val_loss: 3.4552e-04
 - val_f1: 0.9998
Epoch 44/300
 - 28s - loss: 2.3317e-04 - val_loss: 3.4552e-04
 - val_f1: 0.9998
Epoch 45/300
 - 28s - loss: 2.2925e-04 - val_loss: 3.4204e-04
 - val_f1: 0.9998
Epoch 46/300
 - 28s - loss: 2.2646e-04 - val_loss: 3.4124e-04
 - val_f1: 0.9998
Epoch 47/300
 - 28s - loss: 2.2618e-04 - val_loss: 3.6638e-04
 - val_f1: 0.9998
Epoch 48/300
 - 28s - loss: 2.2781e-04 - val_loss: 3.5284e-04
 - val_f1: 0.9998
Epoch 49/300
 - 28s - loss: 2.2416e-04 - val_loss: 3.4171e-04
 - val_f1: 0.9998
Epoch 50/300
 - 28s - loss: 2.1694e-04 - val_loss: 3.5238e-04
 - val_f1: 0.9998
Epoch 51/300
 - 28s - loss: 2.0943e-04 - val_loss: 3.5843e-04
 - val_f1: 0.9998
Epoch 52/300
 - 28s - loss: 2.2238e-04 - val_loss: 3.4879e-04
 - val_f1: 0.9998
Epoch 53/300
 - 28s - loss: 2.1312e-04 - val_loss: 3.6231e-04
 - val_f1: 0.9998
Epoch 54/300
 - 28s - loss: 2.0958e-04 - val_loss: 3.7207e-04
 - val_f1: 0.9998
Epoch 55/300
 - 28s - loss: 2.1087e-04 - val_loss: 3.8654e-04
 - val_f1: 0.9998
Epoch 56/300
 - 28s - loss: 2.1222e-04 - val_loss: 3.9164e-04
 - val_f1: 0.9998
Epoch 57/300
 - 28s - loss: 2.0803e-04 - val_loss: 3.6308e-04
 - val_f1: 0.9998
Epoch 58/300
 - 28s - loss: 2.0696e-04 - val_loss: 3.7137e-04
 - val_f1: 0.9998
Epoch 59/300
 - 28s - loss: 2.0362e-04 - val_loss: 3.6507e-04
 - val_f1: 0.9998
Epoch 60/300
 - 28s - loss: 1.9979e-04 - val_loss: 3.7715e-04
 - val_f1: 0.9998
Epoch 61/300
 - 28s - loss: 2.0264e-04 - val_loss: 3.6308e-04
2019-12-27 20:44:45,741 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep1/_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 28s - loss: 1.9301e-04 - val_loss: 3.5661e-04
 - val_f1: 0.9998
Epoch 63/300
 - 28s - loss: 1.9486e-04 - val_loss: 3.5132e-04
 - val_f1: 0.9998
Epoch 64/300
 - 28s - loss: 1.9922e-04 - val_loss: 3.6166e-04
 - val_f1: 0.9998
Epoch 65/300
 - 28s - loss: 1.8963e-04 - val_loss: 3.7267e-04
 - val_f1: 0.9998
Epoch 66/300
 - 28s - loss: 1.8698e-04 - val_loss: 3.5022e-04
 - val_f1: 0.9998
Epoch 67/300
 - 28s - loss: 1.7735e-04 - val_loss: 3.5788e-04
 - val_f1: 0.9998
Epoch 68/300
 - 28s - loss: 1.7903e-04 - val_loss: 3.4335e-04
 - val_f1: 0.9998
Epoch 69/300
 - 28s - loss: 1.8611e-04 - val_loss: 3.5889e-04
 - val_f1: 0.9998
Epoch 70/300
 - 28s - loss: 1.8435e-04 - val_loss: 3.3768e-04
 - val_f1: 0.9998
Epoch 71/300
 - 28s - loss: 1.8206e-04 - val_loss: 3.5798e-04
 - val_f1: 0.9998
Epoch 72/300
 - 28s - loss: 1.7620e-04 - val_loss: 3.4523e-04
 - val_f1: 0.9998
Epoch 73/300
 - 28s - loss: 1.8138e-04 - val_loss: 3.5693e-04
 - val_f1: 0.9998
Epoch 74/300
 - 28s - loss: 1.8501e-04 - val_loss: 3.4923e-04
 - val_f1: 0.9998
Epoch 75/300
 - 28s - loss: 1.7811e-04 - val_loss: 3.4083e-04
 - val_f1: 0.9998
Epoch 76/300
 - 28s - loss: 1.8296e-04 - val_loss: 3.5284e-04
 - val_f1: 0.9998
Epoch 77/300
 - 28s - loss: 1.7564e-04 - val_loss: 3.5884e-04
 - val_f1: 0.9998
Epoch 78/300
 - 28s - loss: 1.7852e-04 - val_loss: 3.6890e-04
 - val_f1: 0.9998
Epoch 79/300
 - 28s - loss: 1.7382e-04 - val_loss: 3.6793e-04
 - val_f1: 0.9998
Epoch 80/300
 - 28s - loss: 1.6508e-04 - val_loss: 3.5479e-04
 - val_f1: 0.9998
Epoch 81/300
 - 28s - loss: 1.6518e-04 - val_loss: 3.5849e-04
 - val_f1: 0.9998
Epoch 82/300
 - 28s - loss: 1.6700e-04 - val_loss: 3.6267e-04
2019-12-27 20:57:18,959 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 20:57:51,890 [INFO] Last epoch loss evaluation: train_loss = 0.000189, val_loss = 0.000336
2019-12-27 20:57:51,890 [INFO] Training complete. time_to_train = 2945.56 sec, 49.09 min
2019-12-27 20:57:51,894 [INFO] Model saved to results_selected_models/selected_kdd99_lstm_shallow_rep1/best_model.pickle
2019-12-27 20:57:51,900 [INFO] Training history saved to: results_selected_models/selected_kdd99_lstm_shallow_rep1/training_error_history.csv
2019-12-27 20:57:52,098 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep1/training_error_history.png
2019-12-27 20:57:52,284 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep1/training_f1_history.png
2019-12-27 20:57:52,284 [INFO] Making predictions on training, validation, testing data
2019-12-27 20:58:27,653 [INFO] Evaluating predictions (results)
2019-12-27 20:58:36,424 [INFO] Dataset: Testing. Classification report below
2019-12-27 20:58:36,424 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60580
       probe       0.76      0.78      0.77      4166
         r2l       0.92      0.03      0.06     13773
         u2r       0.27      0.00      0.01      2636

    accuracy                           0.92    311008
   macro avg       0.73      0.56      0.53    311008
weighted avg       0.93      0.92      0.90    311008

2019-12-27 20:58:36,424 [INFO] Overall accuracy (micro avg): 0.9235807439036938
2019-12-27 20:58:45,747 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9236         0.9236                       0.9236                0.0191                   0.0764  0.9236
1     Macro avg        0.9694         0.7344                       0.5552                0.0197                   0.4448  0.5320
2  Weighted avg        0.9682         0.9324                       0.9236                0.0221                   0.0764  0.9047
2019-12-27 20:59:16,336 [INFO] Dataset: Validation. Classification report below
2019-12-27 20:59:16,336 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776671
     normal.       1.00      1.00      1.00    194553
       probe       1.00      0.99      1.00      8221
         r2l       0.82      0.87      0.85       225
         u2r       0.29      0.20      0.24        10

    accuracy                           1.00    979680
   macro avg       0.82      0.81      0.82    979680
weighted avg       1.00      1.00      1.00    979680

2019-12-27 20:59:16,336 [INFO] Overall accuracy (micro avg): 0.9998091213457455
2019-12-27 20:59:49,338 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8211                       0.8128                0.0001                   0.1872  0.8153
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-27 21:02:02,591 [INFO] Dataset: Training. Classification report below
2019-12-27 21:02:02,591 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106675
     normal.       1.00      1.00      1.00    778221
       probe       1.00      1.00      1.00     32881
         r2l       0.83      0.92      0.87       901
         u2r       0.77      0.48      0.59        42

    accuracy                           1.00   3918720
   macro avg       0.92      0.88      0.89   3918720
weighted avg       1.00      1.00      1.00   3918720

2019-12-27 21:02:02,591 [INFO] Overall accuracy (micro avg): 0.9998586273068757
2019-12-27 21:04:26,441 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.9195                       0.8780                0.0000                   0.1220  0.8914
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-27 21:04:26,488 [INFO] Results saved to: results_selected_models/selected_kdd99_lstm_shallow_rep1/selected_kdd99_lstm_shallow_rep1_results.xlsx
2019-12-27 21:04:26,495 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-27 21:04:26,610 [INFO] Created directory: results_selected_models/selected_kdd99_lstm_shallow_rep2
2019-12-27 21:04:26,610 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_lstm_shallow_rep2/run_log.log
2019-12-27 21:04:26,611 [INFO] ================= Running experiment no. 2  ================= 

2019-12-27 21:04:26,611 [INFO] Experiment parameters given below
2019-12-27 21:04:26,611 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_kdd99_lstm_shallow_rep2', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_lstm_shallow_rep2'}
2019-12-27 21:04:26,611 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_lstm_shallow_rep2/tf_logs_run_2019_12_27-21_04_26
2019-12-27 21:04:26,611 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-27 21:04:26,611 [INFO] Reading X, y files
2019-12-27 21:04:26,611 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-27 21:04:32,996 [INFO] Reading complete. time_to_read=6.38 seconds
2019-12-27 21:04:32,996 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-27 21:04:34,617 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-27 21:04:34,617 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-27 21:04:35,072 [INFO] Reading complete. time_to_read=0.45 seconds
2019-12-27 21:04:35,072 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-27 21:04:35,282 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-27 21:04:35,282 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-27 21:04:35,336 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-27 21:04:35,336 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-27 21:04:35,356 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-27 21:04:41,077 [INFO] Preparing flow sequences
2019-12-27 21:05:28,298 [INFO] Extracting flows complete. time_taken = 47.22 sec
2019-12-27 21:05:29,921 [INFO] Initializing model
2019-12-27 21:05:30,168 [INFO] _________________________________________________________________
2019-12-27 21:05:30,168 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 21:05:30,169 [INFO] =================================================================
2019-12-27 21:05:30,169 [INFO] lstm_2 (LSTM)                (None, 32, 32)            19968     
2019-12-27 21:05:30,169 [INFO] _________________________________________________________________
2019-12-27 21:05:30,169 [INFO] batch_normalization_2 (Batch (None, 32, 32)            128       
2019-12-27 21:05:30,169 [INFO] _________________________________________________________________
2019-12-27 21:05:30,169 [INFO] dropout_2 (Dropout)          (None, 32, 32)            0         
2019-12-27 21:05:30,169 [INFO] _________________________________________________________________
2019-12-27 21:05:30,169 [INFO] time_distributed_2 (TimeDist (None, 32, 5)             165       
2019-12-27 21:05:30,169 [INFO] =================================================================
2019-12-27 21:05:30,169 [INFO] Total params: 20,261
2019-12-27 21:05:30,170 [INFO] Trainable params: 20,197
2019-12-27 21:05:30,170 [INFO] Non-trainable params: 64
2019-12-27 21:05:30,170 [INFO] _________________________________________________________________
2019-12-27 21:05:30,170 [INFO] Training model
 - val_f1: 0.9998
Epoch 00082: early stopping
Train on 122460 samples, validate on 30615 samples
Epoch 1/300
 - 29s - loss: 0.0548 - val_loss: 0.0049
 - val_f1: 0.9984
Epoch 2/300
 - 28s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9989
Epoch 3/300
 - 28s - loss: 0.0027 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 4/300
 - 28s - loss: 0.0014 - val_loss: 9.6062e-04
 - val_f1: 0.9995
Epoch 5/300
 - 28s - loss: 0.0011 - val_loss: 8.5526e-04
 - val_f1: 0.9996
Epoch 6/300
 - 28s - loss: 9.4986e-04 - val_loss: 6.4211e-04
 - val_f1: 0.9996
Epoch 7/300
 - 28s - loss: 7.5133e-04 - val_loss: 5.8562e-04
 - val_f1: 0.9997
Epoch 8/300
 - 28s - loss: 6.8256e-04 - val_loss: 5.3386e-04
 - val_f1: 0.9997
Epoch 9/300
 - 28s - loss: 6.2358e-04 - val_loss: 5.0292e-04
 - val_f1: 0.9997
Epoch 10/300
 - 28s - loss: 5.7670e-04 - val_loss: 4.7169e-04
 - val_f1: 0.9998
Epoch 11/300
 - 28s - loss: 5.4300e-04 - val_loss: 4.4370e-04
 - val_f1: 0.9998
Epoch 12/300
 - 28s - loss: 4.8736e-04 - val_loss: 4.2277e-04
 - val_f1: 0.9998
Epoch 13/300
 - 28s - loss: 4.6787e-04 - val_loss: 4.1762e-04
 - val_f1: 0.9998
Epoch 14/300
 - 28s - loss: 4.2569e-04 - val_loss: 4.0834e-04
 - val_f1: 0.9998
Epoch 15/300
 - 28s - loss: 4.2067e-04 - val_loss: 3.9131e-04
 - val_f1: 0.9998
Epoch 16/300
 - 28s - loss: 3.9499e-04 - val_loss: 3.5957e-04
 - val_f1: 0.9998
Epoch 17/300
 - 28s - loss: 3.6592e-04 - val_loss: 3.4654e-04
 - val_f1: 0.9998
Epoch 18/300
 - 28s - loss: 3.6056e-04 - val_loss: 3.3152e-04
 - val_f1: 0.9998
Epoch 19/300
 - 28s - loss: 3.5813e-04 - val_loss: 3.5749e-04
 - val_f1: 0.9998
Epoch 20/300
 - 28s - loss: 3.3832e-04 - val_loss: 3.3856e-04
 - val_f1: 0.9998
Epoch 21/300
 - 28s - loss: 3.2628e-04 - val_loss: 3.4187e-04
 - val_f1: 0.9998
Epoch 22/300
 - 28s - loss: 3.2144e-04 - val_loss: 3.4220e-04
 - val_f1: 0.9998
Epoch 23/300
 - 28s - loss: 3.0824e-04 - val_loss: 3.3268e-04
 - val_f1: 0.9998
Epoch 24/300
 - 28s - loss: 3.1320e-04 - val_loss: 3.1820e-04
 - val_f1: 0.9998
Epoch 25/300
 - 28s - loss: 2.9602e-04 - val_loss: 3.4413e-04
 - val_f1: 0.9998
Epoch 26/300
 - 28s - loss: 2.9092e-04 - val_loss: 3.1967e-04
 - val_f1: 0.9998
Epoch 27/300
 - 28s - loss: 2.9119e-04 - val_loss: 3.2042e-04
 - val_f1: 0.9998
Epoch 28/300
 - 28s - loss: 2.7273e-04 - val_loss: 3.1982e-04
 - val_f1: 0.9998
Epoch 29/300
 - 28s - loss: 2.7541e-04 - val_loss: 3.2137e-04
 - val_f1: 0.9998
Epoch 30/300
 - 28s - loss: 2.8145e-04 - val_loss: 3.1658e-04
 - val_f1: 0.9998
Epoch 31/300
 - 28s - loss: 2.6749e-04 - val_loss: 3.0509e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-27 21:23:36,633 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep2/_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 28s - loss: 2.6050e-04 - val_loss: 3.1508e-04
 - val_f1: 0.9998
Epoch 33/300
 - 28s - loss: 2.6045e-04 - val_loss: 2.9941e-04
 - val_f1: 0.9998
Epoch 34/300
 - 28s - loss: 2.5466e-04 - val_loss: 3.1295e-04
 - val_f1: 0.9998
Epoch 35/300
 - 28s - loss: 2.4563e-04 - val_loss: 3.1543e-04
 - val_f1: 0.9998
Epoch 36/300
 - 28s - loss: 2.3627e-04 - val_loss: 3.0110e-04
 - val_f1: 0.9998
Epoch 37/300
 - 28s - loss: 2.4312e-04 - val_loss: 3.1223e-04
 - val_f1: 0.9998
Epoch 38/300
 - 28s - loss: 2.3565e-04 - val_loss: 3.0868e-04
 - val_f1: 0.9998
Epoch 39/300
 - 28s - loss: 2.4661e-04 - val_loss: 3.2019e-04
 - val_f1: 0.9998
Epoch 40/300
 - 28s - loss: 2.3097e-04 - val_loss: 3.2859e-04
 - val_f1: 0.9998
Epoch 41/300
 - 28s - loss: 2.2950e-04 - val_loss: 3.1286e-04
 - val_f1: 0.9998
Epoch 42/300
 - 28s - loss: 2.2564e-04 - val_loss: 3.5708e-04
 - val_f1: 0.9998
Epoch 43/300
 - 28s - loss: 2.2610e-04 - val_loss: 3.1807e-04
 - val_f1: 0.9998
Epoch 44/300
 - 28s - loss: 2.2198e-04 - val_loss: 3.2143e-04
 - val_f1: 0.9998
Epoch 45/300
 - 28s - loss: 2.2743e-04 - val_loss: 3.2248e-04
 - val_f1: 0.9998
Epoch 46/300
 - 28s - loss: 2.1846e-04 - val_loss: 3.1189e-04
 - val_f1: 0.9998
Epoch 47/300
 - 28s - loss: 2.1709e-04 - val_loss: 3.1831e-04
 - val_f1: 0.9998
Epoch 48/300
 - 28s - loss: 2.1409e-04 - val_loss: 3.1180e-04
 - val_f1: 0.9998
Epoch 49/300
 - 28s - loss: 2.1351e-04 - val_loss: 3.2433e-04
 - val_f1: 0.9998
Epoch 50/300
 - 28s - loss: 2.0869e-04 - val_loss: 3.2944e-04
 - val_f1: 0.9998
Epoch 51/300
 - 28s - loss: 2.1445e-04 - val_loss: 3.3452e-04
 - val_f1: 0.9998
Epoch 52/300
 - 28s - loss: 2.0864e-04 - val_loss: 3.2301e-04
 - val_f1: 0.9998
Epoch 53/300
 - 28s - loss: 2.0008e-04 - val_loss: 3.2323e-04
 - val_f1: 0.9998
Epoch 54/300
 - 28s - loss: 2.0528e-04 - val_loss: 3.1662e-04
 - val_f1: 0.9998
Epoch 55/300
 - 28s - loss: 1.9559e-04 - val_loss: 3.0225e-04
 - val_f1: 0.9998
Epoch 56/300
 - 28s - loss: 1.9525e-04 - val_loss: 3.3198e-04
 - val_f1: 0.9998
Epoch 57/300
 - 28s - loss: 1.9544e-04 - val_loss: 3.1002e-04
 - val_f1: 0.9998
Epoch 58/300
 - 28s - loss: 1.9528e-04 - val_loss: 3.2005e-04
 - val_f1: 0.9998
Epoch 59/300
 - 28s - loss: 1.9128e-04 - val_loss: 3.1691e-04
 - val_f1: 0.9998
Epoch 60/300
 - 28s - loss: 1.8489e-04 - val_loss: 3.1575e-04
 - val_f1: 0.9998
Epoch 61/300
 - 28s - loss: 1.8090e-04 - val_loss: 3.0708e-04
2019-12-27 21:41:13,425 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep2/_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 28s - loss: 1.8970e-04 - val_loss: 3.3096e-04
 - val_f1: 0.9998
Epoch 63/300
 - 28s - loss: 1.9223e-04 - val_loss: 3.2702e-04
 - val_f1: 0.9998
Epoch 64/300
 - 28s - loss: 1.8603e-04 - val_loss: 3.0828e-04
 - val_f1: 0.9998
Epoch 65/300
 - 28s - loss: 1.8200e-04 - val_loss: 3.2861e-04
 - val_f1: 0.9998
Epoch 66/300
 - 28s - loss: 1.7801e-04 - val_loss: 3.2522e-04
 - val_f1: 0.9998
Epoch 67/300
 - 28s - loss: 1.7925e-04 - val_loss: 3.1810e-04
 - val_f1: 0.9998
Epoch 68/300
 - 28s - loss: 1.8436e-04 - val_loss: 3.2665e-04
 - val_f1: 0.9998
Epoch 69/300
 - 28s - loss: 1.7849e-04 - val_loss: 3.2085e-04
 - val_f1: 0.9998
Epoch 70/300
 - 28s - loss: 1.7446e-04 - val_loss: 3.1115e-04
 - val_f1: 0.9998
Epoch 71/300
 - 28s - loss: 1.7298e-04 - val_loss: 3.1995e-04
 - val_f1: 0.9998
Epoch 72/300
 - 28s - loss: 1.7037e-04 - val_loss: 3.2041e-04
 - val_f1: 0.9998
Epoch 73/300
 - 28s - loss: 1.8011e-04 - val_loss: 3.3361e-04
 - val_f1: 0.9998
Epoch 74/300
 - 28s - loss: 1.7122e-04 - val_loss: 3.3064e-04
 - val_f1: 0.9998
Epoch 75/300
 - 28s - loss: 1.7422e-04 - val_loss: 3.4458e-04
 - val_f1: 0.9998
Epoch 76/300
 - 28s - loss: 1.6341e-04 - val_loss: 3.3609e-04
 - val_f1: 0.9998
Epoch 77/300
 - 28s - loss: 1.6883e-04 - val_loss: 3.4427e-04
 - val_f1: 0.9998
Epoch 78/300
 - 28s - loss: 1.6720e-04 - val_loss: 3.4136e-04
 - val_f1: 0.9998
Epoch 79/300
 - 28s - loss: 1.6769e-04 - val_loss: 3.3995e-04
 - val_f1: 0.9998
Epoch 80/300
 - 28s - loss: 1.7486e-04 - val_loss: 3.3600e-04
 - val_f1: 0.9998
Epoch 81/300
 - 28s - loss: 1.5621e-04 - val_loss: 3.5739e-04
 - val_f1: 0.9998
Epoch 82/300
 - 28s - loss: 1.5308e-04 - val_loss: 3.3486e-04
 - val_f1: 0.9998
Epoch 83/300
 - 28s - loss: 1.5053e-04 - val_loss: 3.4687e-04
2019-12-27 21:54:15,789 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 21:54:49,345 [INFO] Last epoch loss evaluation: train_loss = 0.000175, val_loss = 0.000299
2019-12-27 21:54:49,346 [INFO] Training complete. time_to_train = 2959.18 sec, 49.32 min
2019-12-27 21:54:49,349 [INFO] Model saved to results_selected_models/selected_kdd99_lstm_shallow_rep2/best_model.pickle
2019-12-27 21:54:49,351 [INFO] Training history saved to: results_selected_models/selected_kdd99_lstm_shallow_rep2/training_error_history.csv
2019-12-27 21:54:49,521 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep2/training_error_history.png
2019-12-27 21:54:49,692 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep2/training_f1_history.png
2019-12-27 21:54:49,692 [INFO] Making predictions on training, validation, testing data
2019-12-27 21:55:25,162 [INFO] Evaluating predictions (results)
2019-12-27 21:55:33,867 [INFO] Dataset: Testing. Classification report below
2019-12-27 21:55:33,867 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60580
       probe       0.69      0.81      0.74      4166
         r2l       0.89      0.04      0.07     13773
         u2r       0.22      0.00      0.00      2636

    accuracy                           0.92    311008
   macro avg       0.71      0.56      0.53    311008
weighted avg       0.93      0.92      0.90    311008

2019-12-27 21:55:33,867 [INFO] Overall accuracy (micro avg): 0.9227801214116679
2019-12-27 21:55:43,210 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9228         0.9228                       0.9228                0.0193                   0.0772  0.9228
1     Macro avg        0.9691         0.7066                       0.5602                0.0195                   0.4398  0.5278
2  Weighted avg        0.9676         0.9307                       0.9228                0.0203                   0.0772  0.9045
2019-12-27 21:56:13,800 [INFO] Dataset: Validation. Classification report below
2019-12-27 21:56:13,800 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776671
     normal.       1.00      1.00      1.00    194553
       probe       1.00      0.99      0.99      8221
         r2l       0.89      0.81      0.85       225
         u2r       0.60      0.30      0.40        10

    accuracy                           1.00    979680
   macro avg       0.90      0.82      0.85    979680
weighted avg       1.00      1.00      1.00    979680

2019-12-27 21:56:13,800 [INFO] Overall accuracy (micro avg): 0.9998203495018781
2019-12-27 21:56:46,795 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8970                       0.8211                0.0001                   0.1789  0.8487
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-27 21:58:59,924 [INFO] Dataset: Training. Classification report below
2019-12-27 21:58:59,924 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106675
     normal.       1.00      1.00      1.00    778221
       probe       1.00      0.99      1.00     32881
         r2l       0.92      0.87      0.89       901
         u2r       0.92      0.57      0.71        42

    accuracy                           1.00   3918720
   macro avg       0.97      0.89      0.92   3918720
weighted avg       1.00      1.00      1.00   3918720

2019-12-27 21:58:59,924 [INFO] Overall accuracy (micro avg): 0.9998798076923077
2019-12-27 22:01:23,644 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9680                       0.8877                0.0000                   0.1123  0.9194
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-27 22:01:23,690 [INFO] Results saved to: results_selected_models/selected_kdd99_lstm_shallow_rep2/selected_kdd99_lstm_shallow_rep2_results.xlsx
2019-12-27 22:01:23,697 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-27 22:01:23,811 [INFO] Created directory: results_selected_models/selected_kdd99_lstm_shallow_rep3
2019-12-27 22:01:23,811 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_lstm_shallow_rep3/run_log.log
2019-12-27 22:01:23,811 [INFO] ================= Running experiment no. 3  ================= 

2019-12-27 22:01:23,811 [INFO] Experiment parameters given below
2019-12-27 22:01:23,811 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_kdd99_lstm_shallow_rep3', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_lstm_shallow_rep3'}
2019-12-27 22:01:23,811 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_lstm_shallow_rep3/tf_logs_run_2019_12_27-22_01_23
2019-12-27 22:01:23,811 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-27 22:01:23,812 [INFO] Reading X, y files
2019-12-27 22:01:23,812 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-27 22:01:30,200 [INFO] Reading complete. time_to_read=6.39 seconds
2019-12-27 22:01:30,200 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-27 22:01:31,816 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-27 22:01:31,816 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-27 22:01:32,281 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-27 22:01:32,281 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-27 22:01:32,477 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-27 22:01:32,477 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-27 22:01:32,530 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-27 22:01:32,530 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-27 22:01:32,549 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-27 22:01:38,270 [INFO] Preparing flow sequences
2019-12-27 22:02:25,698 [INFO] Extracting flows complete. time_taken = 47.43 sec
2019-12-27 22:02:27,316 [INFO] Initializing model
2019-12-27 22:02:27,559 [INFO] _________________________________________________________________
2019-12-27 22:02:27,560 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 22:02:27,560 [INFO] =================================================================
2019-12-27 22:02:27,560 [INFO] lstm_3 (LSTM)                (None, 32, 32)            19968     
2019-12-27 22:02:27,560 [INFO] _________________________________________________________________
2019-12-27 22:02:27,560 [INFO] batch_normalization_3 (Batch (None, 32, 32)            128       
2019-12-27 22:02:27,560 [INFO] _________________________________________________________________
2019-12-27 22:02:27,560 [INFO] dropout_3 (Dropout)          (None, 32, 32)            0         
2019-12-27 22:02:27,560 [INFO] _________________________________________________________________
2019-12-27 22:02:27,560 [INFO] time_distributed_3 (TimeDist (None, 32, 5)             165       
2019-12-27 22:02:27,560 [INFO] =================================================================
2019-12-27 22:02:27,561 [INFO] Total params: 20,261
2019-12-27 22:02:27,561 [INFO] Trainable params: 20,197
2019-12-27 22:02:27,561 [INFO] Non-trainable params: 64
2019-12-27 22:02:27,561 [INFO] _________________________________________________________________
2019-12-27 22:02:27,561 [INFO] Training model
 - val_f1: 0.9998
Epoch 00083: early stopping
Train on 122460 samples, validate on 30615 samples
Epoch 1/300
 - 29s - loss: 0.0611 - val_loss: 0.0032
 - val_f1: 0.9986
Epoch 2/300
 - 27s - loss: 0.0027 - val_loss: 0.0015
 - val_f1: 0.9992
Epoch 3/300
 - 28s - loss: 0.0016 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 4/300
 - 27s - loss: 0.0012 - val_loss: 8.3161e-04
 - val_f1: 0.9996
Epoch 5/300
 - 28s - loss: 9.7278e-04 - val_loss: 6.8789e-04
 - val_f1: 0.9996
Epoch 6/300
 - 28s - loss: 8.1277e-04 - val_loss: 5.8057e-04
 - val_f1: 0.9996
Epoch 7/300
 - 28s - loss: 7.0179e-04 - val_loss: 5.6792e-04
 - val_f1: 0.9996
Epoch 8/300
 - 28s - loss: 6.3374e-04 - val_loss: 5.0056e-04
 - val_f1: 0.9997
Epoch 9/300
 - 27s - loss: 5.7833e-04 - val_loss: 4.7747e-04
 - val_f1: 0.9997
Epoch 10/300
 - 27s - loss: 5.5388e-04 - val_loss: 4.4417e-04
 - val_f1: 0.9997
Epoch 11/300
 - 27s - loss: 5.1386e-04 - val_loss: 4.1596e-04
 - val_f1: 0.9997
Epoch 12/300
 - 27s - loss: 4.7715e-04 - val_loss: 4.1499e-04
 - val_f1: 0.9997
Epoch 13/300
 - 27s - loss: 4.5857e-04 - val_loss: 3.9503e-04
 - val_f1: 0.9998
Epoch 14/300
 - 27s - loss: 4.5235e-04 - val_loss: 3.7704e-04
 - val_f1: 0.9998
Epoch 15/300
 - 27s - loss: 4.1855e-04 - val_loss: 3.9942e-04
 - val_f1: 0.9998
Epoch 16/300
 - 27s - loss: 3.8626e-04 - val_loss: 3.5844e-04
 - val_f1: 0.9998
Epoch 17/300
 - 27s - loss: 3.8902e-04 - val_loss: 3.5778e-04
 - val_f1: 0.9998
Epoch 18/300
 - 27s - loss: 3.6813e-04 - val_loss: 3.5492e-04
 - val_f1: 0.9998
Epoch 19/300
 - 27s - loss: 3.5925e-04 - val_loss: 3.6558e-04
 - val_f1: 0.9998
Epoch 20/300
 - 27s - loss: 3.3689e-04 - val_loss: 3.6925e-04
 - val_f1: 0.9998
Epoch 21/300
 - 27s - loss: 3.3115e-04 - val_loss: 3.3809e-04
 - val_f1: 0.9998
Epoch 22/300
 - 27s - loss: 3.3003e-04 - val_loss: 3.3597e-04
 - val_f1: 0.9998
Epoch 23/300
 - 27s - loss: 3.0876e-04 - val_loss: 3.4576e-04
 - val_f1: 0.9998
Epoch 24/300
 - 27s - loss: 3.0681e-04 - val_loss: 3.4397e-04
 - val_f1: 0.9998
Epoch 25/300
 - 28s - loss: 3.0529e-04 - val_loss: 3.2814e-04
 - val_f1: 0.9998
Epoch 26/300
 - 27s - loss: 2.8863e-04 - val_loss: 3.4944e-04
 - val_f1: 0.9998
Epoch 27/300
 - 27s - loss: 2.9326e-04 - val_loss: 3.4746e-04
 - val_f1: 0.9998
Epoch 28/300
 - 27s - loss: 2.9378e-04 - val_loss: 3.5229e-04
 - val_f1: 0.9998
Epoch 29/300
 - 27s - loss: 2.9511e-04 - val_loss: 3.3499e-04
 - val_f1: 0.9998
Epoch 30/300
 - 27s - loss: 2.8375e-04 - val_loss: 3.5035e-04
 - val_f1: 0.9998
Epoch 31/300
 - 27s - loss: 2.7250e-04 - val_loss: 3.3135e-04
2019-12-27 22:20:28,187 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep3/_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 27s - loss: 2.5649e-04 - val_loss: 3.3143e-04
 - val_f1: 0.9998
Epoch 33/300
 - 27s - loss: 2.7303e-04 - val_loss: 3.3775e-04
 - val_f1: 0.9998
Epoch 34/300
 - 27s - loss: 2.5857e-04 - val_loss: 3.3649e-04
 - val_f1: 0.9998
Epoch 35/300
 - 27s - loss: 2.6781e-04 - val_loss: 3.2681e-04
 - val_f1: 0.9998
Epoch 36/300
 - 27s - loss: 2.5308e-04 - val_loss: 3.2774e-04
 - val_f1: 0.9998
Epoch 37/300
 - 27s - loss: 2.5806e-04 - val_loss: 3.3530e-04
 - val_f1: 0.9998
Epoch 38/300
 - 27s - loss: 2.3703e-04 - val_loss: 3.2687e-04
 - val_f1: 0.9998
Epoch 39/300
 - 27s - loss: 2.4259e-04 - val_loss: 3.3938e-04
 - val_f1: 0.9998
Epoch 40/300
 - 27s - loss: 2.4363e-04 - val_loss: 3.3675e-04
 - val_f1: 0.9998
Epoch 41/300
 - 27s - loss: 2.2872e-04 - val_loss: 3.1708e-04
 - val_f1: 0.9998
Epoch 42/300
 - 27s - loss: 2.2838e-04 - val_loss: 3.5023e-04
 - val_f1: 0.9998
Epoch 43/300
 - 27s - loss: 2.2256e-04 - val_loss: 3.4637e-04
 - val_f1: 0.9998
Epoch 44/300
 - 27s - loss: 2.2609e-04 - val_loss: 3.3770e-04
 - val_f1: 0.9998
Epoch 45/300
 - 27s - loss: 2.1462e-04 - val_loss: 3.3910e-04
 - val_f1: 0.9998
Epoch 46/300
 - 27s - loss: 2.0965e-04 - val_loss: 3.2176e-04
 - val_f1: 0.9998
Epoch 47/300
 - 27s - loss: 2.0374e-04 - val_loss: 3.2853e-04
 - val_f1: 0.9998
Epoch 48/300
 - 27s - loss: 2.0905e-04 - val_loss: 3.3606e-04
 - val_f1: 0.9998
Epoch 49/300
 - 27s - loss: 2.2139e-04 - val_loss: 3.2690e-04
 - val_f1: 0.9998
Epoch 50/300
 - 27s - loss: 2.1046e-04 - val_loss: 3.2005e-04
 - val_f1: 0.9998
Epoch 51/300
 - 27s - loss: 2.0589e-04 - val_loss: 3.4958e-04
 - val_f1: 0.9998
Epoch 52/300
 - 27s - loss: 2.0409e-04 - val_loss: 3.7066e-04
 - val_f1: 0.9998
Epoch 53/300
 - 27s - loss: 2.0200e-04 - val_loss: 3.3937e-04
 - val_f1: 0.9998
Epoch 54/300
 - 27s - loss: 1.9358e-04 - val_loss: 3.3754e-04
 - val_f1: 0.9998
Epoch 55/300
 - 27s - loss: 1.9368e-04 - val_loss: 3.3209e-04
 - val_f1: 0.9998
Epoch 56/300
 - 27s - loss: 1.8836e-04 - val_loss: 3.2508e-04
 - val_f1: 0.9998
Epoch 57/300
 - 27s - loss: 1.9518e-04 - val_loss: 3.4988e-04
 - val_f1: 0.9998
Epoch 58/300
 - 27s - loss: 1.8872e-04 - val_loss: 3.3537e-04
 - val_f1: 0.9998
Epoch 59/300
 - 27s - loss: 1.9940e-04 - val_loss: 3.3852e-04
 - val_f1: 0.9998
Epoch 60/300
 - 28s - loss: 1.9107e-04 - val_loss: 3.4463e-04
 - val_f1: 0.9998
Epoch 61/300
 - 27s - loss: 1.8779e-04 - val_loss: 3.3484e-04
2019-12-27 22:37:56,357 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep3/_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 27s - loss: 2.0100e-04 - val_loss: 3.4299e-04
 - val_f1: 0.9998
Epoch 63/300
 - 27s - loss: 1.9353e-04 - val_loss: 3.2913e-04
 - val_f1: 0.9998
Epoch 64/300
 - 27s - loss: 1.8284e-04 - val_loss: 3.4683e-04
 - val_f1: 0.9998
Epoch 65/300
 - 27s - loss: 1.7906e-04 - val_loss: 3.3267e-04
 - val_f1: 0.9998
Epoch 66/300
 - 27s - loss: 1.8647e-04 - val_loss: 3.4890e-04
 - val_f1: 0.9998
Epoch 67/300
 - 27s - loss: 1.7923e-04 - val_loss: 3.3532e-04
 - val_f1: 0.9998
Epoch 68/300
 - 27s - loss: 1.7908e-04 - val_loss: 3.3339e-04
 - val_f1: 0.9998
Epoch 69/300
 - 27s - loss: 1.7873e-04 - val_loss: 3.2172e-04
 - val_f1: 0.9998
Epoch 70/300
 - 27s - loss: 1.7617e-04 - val_loss: 3.4318e-04
 - val_f1: 0.9998
Epoch 71/300
 - 27s - loss: 1.8260e-04 - val_loss: 3.4231e-04
 - val_f1: 0.9998
Epoch 72/300
 - 27s - loss: 1.8001e-04 - val_loss: 3.3946e-04
 - val_f1: 0.9998
Epoch 73/300
 - 27s - loss: 1.7631e-04 - val_loss: 3.6426e-04
 - val_f1: 0.9998
Epoch 74/300
 - 27s - loss: 1.7576e-04 - val_loss: 3.6540e-04
 - val_f1: 0.9998
Epoch 75/300
 - 27s - loss: 1.7166e-04 - val_loss: 3.5598e-04
 - val_f1: 0.9998
Epoch 76/300
 - 27s - loss: 1.8030e-04 - val_loss: 3.4509e-04
 - val_f1: 0.9998
Epoch 77/300
 - 28s - loss: 1.7111e-04 - val_loss: 3.3127e-04
 - val_f1: 0.9998
Epoch 78/300
 - 27s - loss: 1.6377e-04 - val_loss: 3.4833e-04
 - val_f1: 0.9998
Epoch 79/300
 - 27s - loss: 1.6978e-04 - val_loss: 3.4125e-04
 - val_f1: 0.9998
Epoch 80/300
 - 27s - loss: 1.6900e-04 - val_loss: 3.4417e-04
 - val_f1: 0.9998
Epoch 81/300
 - 27s - loss: 1.7358e-04 - val_loss: 3.3431e-04
 - val_f1: 0.9998
Epoch 82/300
 - 27s - loss: 1.6490e-04 - val_loss: 3.3044e-04
 - val_f1: 0.9998
Epoch 83/300
 - 27s - loss: 1.6994e-04 - val_loss: 3.4511e-04
 - val_f1: 0.9998
Epoch 84/300
 - 27s - loss: 1.6752e-04 - val_loss: 3.3799e-04
 - val_f1: 0.9998
Epoch 85/300
 - 27s - loss: 1.6776e-04 - val_loss: 3.6371e-04
 - val_f1: 0.9998
Epoch 86/300
 - 27s - loss: 1.6620e-04 - val_loss: 3.4671e-04
 - val_f1: 0.9998
Epoch 87/300
 - 27s - loss: 1.7181e-04 - val_loss: 3.5430e-04
 - val_f1: 0.9998
Epoch 88/300
 - 27s - loss: 1.6209e-04 - val_loss: 3.4920e-04
 - val_f1: 0.9998
Epoch 89/300
 - 27s - loss: 1.6534e-04 - val_loss: 3.3774e-04
 - val_f1: 0.9998
Epoch 90/300
 - 27s - loss: 1.6984e-04 - val_loss: 3.3970e-04
 - val_f1: 0.9998
Epoch 91/300
 - 27s - loss: 1.6614e-04 - val_loss: 3.4000e-04
2019-12-27 22:55:24,098 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep3/_model_epoch_90.pickle
2019-12-27 22:55:31,612 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-27 22:56:04,923 [INFO] Last epoch loss evaluation: train_loss = 0.000161, val_loss = 0.000317
2019-12-27 22:56:04,923 [INFO] Training complete. time_to_train = 3217.36 sec, 53.62 min
2019-12-27 22:56:04,927 [INFO] Model saved to results_selected_models/selected_kdd99_lstm_shallow_rep3/best_model.pickle
2019-12-27 22:56:04,929 [INFO] Training history saved to: results_selected_models/selected_kdd99_lstm_shallow_rep3/training_error_history.csv
2019-12-27 22:56:05,105 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep3/training_error_history.png
2019-12-27 22:56:05,271 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep3/training_f1_history.png
2019-12-27 22:56:05,271 [INFO] Making predictions on training, validation, testing data
2019-12-27 22:56:40,712 [INFO] Evaluating predictions (results)
2019-12-27 22:56:49,398 [INFO] Dataset: Testing. Classification report below
2019-12-27 22:56:49,398 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60580
       probe       0.73      0.74      0.74      4166
         r2l       0.87      0.03      0.06     13773
         u2r       0.12      0.00      0.00      2636

    accuracy                           0.92    311008
   macro avg       0.69      0.55      0.52    311008
weighted avg       0.93      0.92      0.90    311008

2019-12-27 22:56:49,398 [INFO] Overall accuracy (micro avg): 0.9226643687622184
2019-12-27 22:56:58,744 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9227         0.9227                       0.9227                0.0193                   0.0773  0.9227
1     Macro avg        0.9691         0.6902                       0.5467                0.0201                   0.4533  0.5240
2  Weighted avg        0.9677         0.9283                       0.9227                0.0230                   0.0773  0.9038
2019-12-27 22:57:29,327 [INFO] Dataset: Validation. Classification report below
2019-12-27 22:57:29,327 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776671
     normal.       1.00      1.00      1.00    194553
       probe       1.00      0.99      1.00      8221
         r2l       0.91      0.78      0.84       225
         u2r       0.25      0.10      0.14        10

    accuracy                           1.00    979680
   macro avg       0.83      0.78      0.80    979680
weighted avg       1.00      1.00      1.00    979680

2019-12-27 22:57:29,327 [INFO] Overall accuracy (micro avg): 0.999823411726278
2019-12-27 22:58:02,328 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8317                       0.7751                0.0001                   0.2249  0.7960
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-27 23:00:15,465 [INFO] Dataset: Training. Classification report below
2019-12-27 23:00:15,466 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106675
     normal.       1.00      1.00      1.00    778221
       probe       1.00      1.00      1.00     32881
         r2l       0.92      0.84      0.88       901
         u2r       0.88      0.50      0.64        42

    accuracy                           1.00   3918720
   macro avg       0.96      0.87      0.90   3918720
weighted avg       1.00      1.00      1.00   3918720

2019-12-27 23:00:15,466 [INFO] Overall accuracy (micro avg): 0.9998828699167075
2019-12-27 23:02:39,161 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9585                       0.8671                0.0000                   0.1329  0.9022
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-27 23:02:39,208 [INFO] Results saved to: results_selected_models/selected_kdd99_lstm_shallow_rep3/selected_kdd99_lstm_shallow_rep3_results.xlsx
2019-12-27 23:02:39,215 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-27 23:02:39,327 [INFO] Created directory: results_selected_models/selected_kdd99_lstm_shallow_rep4
2019-12-27 23:02:39,328 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_lstm_shallow_rep4/run_log.log
2019-12-27 23:02:39,328 [INFO] ================= Running experiment no. 4  ================= 

2019-12-27 23:02:39,328 [INFO] Experiment parameters given below
2019-12-27 23:02:39,328 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_kdd99_lstm_shallow_rep4', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_lstm_shallow_rep4'}
2019-12-27 23:02:39,328 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_lstm_shallow_rep4/tf_logs_run_2019_12_27-23_02_39
2019-12-27 23:02:39,328 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-27 23:02:39,328 [INFO] Reading X, y files
2019-12-27 23:02:39,328 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-27 23:02:45,728 [INFO] Reading complete. time_to_read=6.40 seconds
2019-12-27 23:02:45,728 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-27 23:02:47,358 [INFO] Reading complete. time_to_read=1.63 seconds
2019-12-27 23:02:47,358 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-27 23:02:47,826 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-27 23:02:47,826 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-27 23:02:48,025 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-27 23:02:48,025 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-27 23:02:48,078 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-27 23:02:48,078 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-27 23:02:48,098 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-27 23:02:53,776 [INFO] Preparing flow sequences
2019-12-27 23:03:41,481 [INFO] Extracting flows complete. time_taken = 47.70 sec
2019-12-27 23:03:43,110 [INFO] Initializing model
2019-12-27 23:03:43,354 [INFO] _________________________________________________________________
2019-12-27 23:03:43,354 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-27 23:03:43,354 [INFO] =================================================================
2019-12-27 23:03:43,354 [INFO] lstm_4 (LSTM)                (None, 32, 32)            19968     
2019-12-27 23:03:43,354 [INFO] _________________________________________________________________
2019-12-27 23:03:43,354 [INFO] batch_normalization_4 (Batch (None, 32, 32)            128       
2019-12-27 23:03:43,355 [INFO] _________________________________________________________________
2019-12-27 23:03:43,355 [INFO] dropout_4 (Dropout)          (None, 32, 32)            0         
2019-12-27 23:03:43,355 [INFO] _________________________________________________________________
2019-12-27 23:03:43,355 [INFO] time_distributed_4 (TimeDist (None, 32, 5)             165       
2019-12-27 23:03:43,355 [INFO] =================================================================
2019-12-27 23:03:43,355 [INFO] Total params: 20,261
2019-12-27 23:03:43,355 [INFO] Trainable params: 20,197
2019-12-27 23:03:43,355 [INFO] Non-trainable params: 64
2019-12-27 23:03:43,355 [INFO] _________________________________________________________________
2019-12-27 23:03:43,355 [INFO] Training model
 - val_f1: 0.9998
Epoch 00091: early stopping
Train on 122460 samples, validate on 30615 samples
Epoch 1/300
 - 29s - loss: 0.0555 - val_loss: 0.0035
 - val_f1: 0.9986
Epoch 2/300
 - 28s - loss: 0.0029 - val_loss: 0.0014
 - val_f1: 0.9992
Epoch 3/300
 - 28s - loss: 0.0016 - val_loss: 9.7116e-04
 - val_f1: 0.9994
Epoch 4/300
 - 28s - loss: 0.0011 - val_loss: 7.2064e-04
 - val_f1: 0.9995
Epoch 5/300
 - 28s - loss: 9.0645e-04 - val_loss: 6.4132e-04
 - val_f1: 0.9996
Epoch 6/300
 - 28s - loss: 7.7335e-04 - val_loss: 5.9894e-04
 - val_f1: 0.9996
Epoch 7/300
 - 28s - loss: 6.9024e-04 - val_loss: 5.2918e-04
 - val_f1: 0.9997
Epoch 8/300
 - 28s - loss: 6.2896e-04 - val_loss: 5.0100e-04
 - val_f1: 0.9997
Epoch 9/300
 - 28s - loss: 5.9525e-04 - val_loss: 4.8397e-04
 - val_f1: 0.9997
Epoch 10/300
 - 28s - loss: 5.3349e-04 - val_loss: 4.3170e-04
 - val_f1: 0.9997
Epoch 11/300
 - 28s - loss: 5.0749e-04 - val_loss: 4.2714e-04
 - val_f1: 0.9997
Epoch 12/300
 - 28s - loss: 4.7947e-04 - val_loss: 3.9837e-04
 - val_f1: 0.9998
Epoch 13/300
 - 28s - loss: 4.5605e-04 - val_loss: 3.9742e-04
 - val_f1: 0.9998
Epoch 14/300
 - 28s - loss: 4.3475e-04 - val_loss: 3.8997e-04
 - val_f1: 0.9998
Epoch 15/300
 - 28s - loss: 4.2260e-04 - val_loss: 3.6669e-04
 - val_f1: 0.9998
Epoch 16/300
 - 28s - loss: 3.9739e-04 - val_loss: 3.8094e-04
 - val_f1: 0.9998
Epoch 17/300
 - 28s - loss: 3.8635e-04 - val_loss: 3.7650e-04
 - val_f1: 0.9998
Epoch 18/300
 - 28s - loss: 3.6262e-04 - val_loss: 3.5566e-04
 - val_f1: 0.9998
Epoch 19/300
 - 28s - loss: 3.6573e-04 - val_loss: 3.4680e-04
 - val_f1: 0.9998
Epoch 20/300
 - 28s - loss: 3.3852e-04 - val_loss: 3.5974e-04
 - val_f1: 0.9998
Epoch 21/300
 - 28s - loss: 3.2974e-04 - val_loss: 3.5214e-04
 - val_f1: 0.9998
Epoch 22/300
 - 28s - loss: 3.2400e-04 - val_loss: 3.4362e-04
 - val_f1: 0.9998
Epoch 23/300
 - 28s - loss: 3.0908e-04 - val_loss: 3.5162e-04
 - val_f1: 0.9998
Epoch 24/300
 - 28s - loss: 3.0133e-04 - val_loss: 3.2814e-04
 - val_f1: 0.9998
Epoch 25/300
 - 28s - loss: 3.0706e-04 - val_loss: 3.2519e-04
 - val_f1: 0.9998
Epoch 26/300
 - 28s - loss: 2.9392e-04 - val_loss: 3.3437e-04
 - val_f1: 0.9998
Epoch 27/300
 - 28s - loss: 2.8863e-04 - val_loss: 3.2989e-04
 - val_f1: 0.9998
Epoch 28/300
 - 28s - loss: 2.7657e-04 - val_loss: 3.2470e-04
 - val_f1: 0.9998
Epoch 29/300
 - 28s - loss: 2.8091e-04 - val_loss: 3.1256e-04
 - val_f1: 0.9998
Epoch 30/300
 - 28s - loss: 2.7280e-04 - val_loss: 3.2650e-04
 - val_f1: 0.9998
Epoch 31/300
 - 28s - loss: 2.7582e-04 - val_loss: 3.2877e-04
2019-12-27 23:22:00,997 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep4/_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 28s - loss: 2.6389e-04 - val_loss: 3.2463e-04
 - val_f1: 0.9998
Epoch 33/300
 - 28s - loss: 2.5527e-04 - val_loss: 3.2166e-04
 - val_f1: 0.9998
Epoch 34/300
 - 28s - loss: 2.5879e-04 - val_loss: 3.2920e-04
 - val_f1: 0.9998
Epoch 35/300
 - 28s - loss: 2.5950e-04 - val_loss: 3.0561e-04
 - val_f1: 0.9998
Epoch 36/300
 - 27s - loss: 2.4957e-04 - val_loss: 3.0316e-04
 - val_f1: 0.9998
Epoch 37/300
 - 27s - loss: 2.4594e-04 - val_loss: 3.1357e-04
 - val_f1: 0.9998
Epoch 38/300
 - 27s - loss: 2.3785e-04 - val_loss: 3.1092e-04
 - val_f1: 0.9998
Epoch 39/300
 - 27s - loss: 2.2876e-04 - val_loss: 3.1128e-04
 - val_f1: 0.9998
Epoch 40/300
 - 28s - loss: 2.2879e-04 - val_loss: 3.0779e-04
 - val_f1: 0.9998
Epoch 41/300
 - 28s - loss: 2.3290e-04 - val_loss: 3.0365e-04
 - val_f1: 0.9998
Epoch 42/300
 - 28s - loss: 2.1963e-04 - val_loss: 3.0121e-04
 - val_f1: 0.9998
Epoch 43/300
 - 28s - loss: 2.2103e-04 - val_loss: 2.9598e-04
 - val_f1: 0.9998
Epoch 44/300
 - 28s - loss: 2.1518e-04 - val_loss: 3.0330e-04
 - val_f1: 0.9998
Epoch 45/300
 - 28s - loss: 2.1240e-04 - val_loss: 2.9716e-04
 - val_f1: 0.9998
Epoch 46/300
 - 28s - loss: 2.1228e-04 - val_loss: 3.0074e-04
 - val_f1: 0.9998
Epoch 47/300
 - 28s - loss: 2.1606e-04 - val_loss: 2.9810e-04
 - val_f1: 0.9998
Epoch 48/300
 - 28s - loss: 2.1589e-04 - val_loss: 3.0324e-04
 - val_f1: 0.9998
Epoch 49/300
 - 27s - loss: 1.9812e-04 - val_loss: 3.0459e-04
 - val_f1: 0.9998
Epoch 50/300
 - 28s - loss: 2.1478e-04 - val_loss: 3.0229e-04
 - val_f1: 0.9998
Epoch 51/300
 - 28s - loss: 1.9968e-04 - val_loss: 3.0437e-04
 - val_f1: 0.9998
Epoch 52/300
 - 28s - loss: 1.9975e-04 - val_loss: 3.1581e-04
 - val_f1: 0.9998
Epoch 53/300
 - 28s - loss: 1.9416e-04 - val_loss: 2.9689e-04
 - val_f1: 0.9998
Epoch 54/300
 - 28s - loss: 1.9117e-04 - val_loss: 2.9224e-04
 - val_f1: 0.9998
Epoch 55/300
 - 27s - loss: 1.9743e-04 - val_loss: 2.9332e-04
 - val_f1: 0.9998
Epoch 56/300
 - 27s - loss: 1.8380e-04 - val_loss: 3.0279e-04
 - val_f1: 0.9998
Epoch 57/300
 - 28s - loss: 1.8690e-04 - val_loss: 3.4467e-04
 - val_f1: 0.9998
Epoch 58/300
 - 27s - loss: 2.0028e-04 - val_loss: 3.1566e-04
 - val_f1: 0.9998
Epoch 59/300
 - 27s - loss: 1.8959e-04 - val_loss: 3.1766e-04
 - val_f1: 0.9998
Epoch 60/300
 - 28s - loss: 2.0590e-04 - val_loss: 3.0658e-04
 - val_f1: 0.9998
Epoch 61/300
 - 27s - loss: 1.9175e-04 - val_loss: 2.9636e-04
2019-12-27 23:39:39,154 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep4/_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 28s - loss: 1.8057e-04 - val_loss: 3.1309e-04
 - val_f1: 0.9998
Epoch 63/300
 - 27s - loss: 1.7821e-04 - val_loss: 3.1443e-04
 - val_f1: 0.9998
Epoch 64/300
 - 28s - loss: 1.7798e-04 - val_loss: 3.1741e-04
 - val_f1: 0.9998
Epoch 65/300
 - 27s - loss: 1.7115e-04 - val_loss: 3.2896e-04
 - val_f1: 0.9998
Epoch 66/300
 - 27s - loss: 1.8145e-04 - val_loss: 3.1386e-04
 - val_f1: 0.9998
Epoch 67/300
 - 27s - loss: 1.6922e-04 - val_loss: 3.1822e-04
 - val_f1: 0.9998
Epoch 68/300
 - 27s - loss: 1.7391e-04 - val_loss: 3.3717e-04
 - val_f1: 0.9998
Epoch 69/300
 - 27s - loss: 1.7210e-04 - val_loss: 3.0583e-04
 - val_f1: 0.9998
Epoch 70/300
 - 27s - loss: 1.6713e-04 - val_loss: 3.1599e-04
 - val_f1: 0.9998
Epoch 71/300
 - 28s - loss: 1.6512e-04 - val_loss: 3.0438e-04
 - val_f1: 0.9998
Epoch 72/300
 - 27s - loss: 1.7691e-04 - val_loss: 3.1098e-04
 - val_f1: 0.9998
Epoch 73/300
 - 27s - loss: 1.6331e-04 - val_loss: 3.1199e-04
 - val_f1: 0.9998
Epoch 74/300
 - 28s - loss: 1.6051e-04 - val_loss: 3.1326e-04
 - val_f1: 0.9998
Epoch 75/300
 - 28s - loss: 1.6549e-04 - val_loss: 3.2105e-04
 - val_f1: 0.9998
Epoch 76/300
 - 27s - loss: 1.6478e-04 - val_loss: 3.2406e-04
 - val_f1: 0.9998
Epoch 77/300
 - 27s - loss: 1.6247e-04 - val_loss: 3.2773e-04
 - val_f1: 0.9998
Epoch 78/300
 - 27s - loss: 1.6764e-04 - val_loss: 3.3526e-04
 - val_f1: 0.9998
Epoch 79/300
 - 27s - loss: 1.7985e-04 - val_loss: 3.5859e-04
 - val_f1: 0.9998
Epoch 80/300
 - 27s - loss: 1.7625e-04 - val_loss: 3.7149e-04
 - val_f1: 0.9998
Epoch 81/300
 - 27s - loss: 1.7008e-04 - val_loss: 3.2654e-04
 - val_f1: 0.9998
Epoch 82/300
 - 27s - loss: 1.6577e-04 - val_loss: 3.5338e-04
 - val_f1: 0.9998
Epoch 83/300
 - 27s - loss: 1.5337e-04 - val_loss: 3.7015e-04
 - val_f1: 0.9998
Epoch 84/300
 - 28s - loss: 1.6303e-04 - val_loss: 3.6057e-04
 - val_f1: 0.9998
Epoch 85/300
 - 28s - loss: 1.5171e-04 - val_loss: 3.3148e-04
 - val_f1: 0.9998
Epoch 86/300
 - 27s - loss: 1.5268e-04 - val_loss: 3.3979e-04
 - val_f1: 0.9998
Epoch 87/300
 - 27s - loss: 1.4963e-04 - val_loss: 3.2919e-04
 - val_f1: 0.9998
Epoch 88/300
 - 28s - loss: 1.4983e-04 - val_loss: 3.3331e-04
 - val_f1: 0.9998
Epoch 89/300
 - 27s - loss: 1.5099e-04 - val_loss: 3.3370e-04
 - val_f1: 0.9998
Epoch 90/300
 - 28s - loss: 1.5377e-04 - val_loss: 3.4931e-04
 - val_f1: 0.9998
Epoch 91/300
 - 28s - loss: 1.5876e-04 - val_loss: 3.5299e-04
2019-12-27 23:57:09,120 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep4/_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 28s - loss: 1.4638e-04 - val_loss: 3.3110e-04
 - val_f1: 0.9998
Epoch 93/300
 - 27s - loss: 1.4721e-04 - val_loss: 3.4072e-04
 - val_f1: 0.9998
Epoch 94/300
 - 28s - loss: 1.3898e-04 - val_loss: 3.0982e-04
 - val_f1: 0.9998
Epoch 95/300
 - 27s - loss: 1.4697e-04 - val_loss: 2.9849e-04
 - val_f1: 0.9999
Epoch 96/300
 - 28s - loss: 1.4343e-04 - val_loss: 3.3016e-04
 - val_f1: 0.9998
Epoch 97/300
 - 28s - loss: 1.4419e-04 - val_loss: 3.3280e-04
 - val_f1: 0.9998
Epoch 98/300
 - 27s - loss: 1.3677e-04 - val_loss: 3.4171e-04
 - val_f1: 0.9998
Epoch 99/300
 - 27s - loss: 1.4860e-04 - val_loss: 3.3558e-04
 - val_f1: 0.9998
Epoch 100/300
 - 28s - loss: 1.4562e-04 - val_loss: 3.5854e-04
 - val_f1: 0.9998
Epoch 101/300
 - 28s - loss: 1.4724e-04 - val_loss: 3.5188e-04
 - val_f1: 0.9998
Epoch 102/300
 - 28s - loss: 1.4908e-04 - val_loss: 3.6685e-04
 - val_f1: 0.9998
Epoch 103/300
 - 27s - loss: 1.3431e-04 - val_loss: 3.8395e-04
 - val_f1: 0.9998
Epoch 104/300
 - 27s - loss: 1.4642e-04 - val_loss: 3.6500e-04
2019-12-28 00:04:51,654 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-28 00:05:25,103 [INFO] Last epoch loss evaluation: train_loss = 0.000125, val_loss = 0.000292
2019-12-28 00:05:25,103 [INFO] Training complete. time_to_train = 3701.75 sec, 61.70 min
2019-12-28 00:05:25,107 [INFO] Model saved to results_selected_models/selected_kdd99_lstm_shallow_rep4/best_model.pickle
2019-12-28 00:05:25,109 [INFO] Training history saved to: results_selected_models/selected_kdd99_lstm_shallow_rep4/training_error_history.csv
2019-12-28 00:05:25,283 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep4/training_error_history.png
2019-12-28 00:05:25,454 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep4/training_f1_history.png
2019-12-28 00:05:25,454 [INFO] Making predictions on training, validation, testing data
2019-12-28 00:06:01,904 [INFO] Evaluating predictions (results)
2019-12-28 00:06:10,597 [INFO] Dataset: Testing. Classification report below
2019-12-28 00:06:10,597 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60580
       probe       0.75      0.80      0.77      4166
         r2l       0.90      0.03      0.07     13773
         u2r       0.22      0.00      0.01      2636

    accuracy                           0.92    311008
   macro avg       0.72      0.56      0.53    311008
weighted avg       0.93      0.92      0.91    311008

2019-12-28 00:06:10,598 [INFO] Overall accuracy (micro avg): 0.9239569400144048
2019-12-28 00:06:19,926 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9240         0.9240                       0.9240                0.0190                   0.0760  0.9240
1     Macro avg        0.9696         0.7213                       0.5586                0.0195                   0.4414  0.5349
2  Weighted avg        0.9685         0.9317                       0.9240                0.0214                   0.0760  0.9054
2019-12-28 00:06:50,520 [INFO] Dataset: Validation. Classification report below
2019-12-28 00:06:50,520 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776671
     normal.       1.00      1.00      1.00    194553
       probe       1.00      0.99      0.99      8221
         r2l       0.93      0.89      0.91       225
         u2r       0.33      0.10      0.15        10

    accuracy                           1.00    979680
   macro avg       0.85      0.80      0.81    979680
weighted avg       1.00      1.00      1.00    979680

2019-12-28 00:06:50,520 [INFO] Overall accuracy (micro avg): 0.9998315776580108
2019-12-28 00:07:23,536 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8509                       0.7964                0.0001                   0.2036  0.8110
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-28 00:09:36,708 [INFO] Dataset: Training. Classification report below
2019-12-28 00:09:36,708 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106675
     normal.       1.00      1.00      1.00    778221
       probe       1.00      1.00      1.00     32881
         r2l       0.92      0.95      0.93       901
         u2r       0.87      0.62      0.72        42

    accuracy                           1.00   3918720
   macro avg       0.96      0.91      0.93   3918720
weighted avg       1.00      1.00      1.00   3918720

2019-12-28 00:09:36,708 [INFO] Overall accuracy (micro avg): 0.9999127266046056
2019-12-28 00:12:00,491 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9574                       0.9127                0.0000                   0.0873  0.9309
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-28 00:12:00,537 [INFO] Results saved to: results_selected_models/selected_kdd99_lstm_shallow_rep4/selected_kdd99_lstm_shallow_rep4_results.xlsx
2019-12-28 00:12:00,544 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-28 00:12:00,658 [INFO] Created directory: results_selected_models/selected_kdd99_lstm_shallow_rep5
2019-12-28 00:12:00,659 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_lstm_shallow_rep5/run_log.log
2019-12-28 00:12:00,659 [INFO] ================= Running experiment no. 5  ================= 

2019-12-28 00:12:00,659 [INFO] Experiment parameters given below
2019-12-28 00:12:00,659 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_kdd99_lstm_shallow_rep5', 'model': 'lstm', 'model_type': 'classifier', 'normal_label': 'normal', 'lstm_time_steps': 32, 'lstm_layer_units': [32], 'lstm_layer_activations': ['relu'], 'lstm_layer_dropout_rates': [0.2], 'batch_size': 256, 'epochs': 300, 'early_stop_patience': 50, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_lstm_shallow_rep5'}
2019-12-28 00:12:00,659 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_lstm_shallow_rep5/tf_logs_run_2019_12_28-00_12_00
2019-12-28 00:12:00,659 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-28 00:12:00,659 [INFO] Reading X, y files
2019-12-28 00:12:00,659 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-28 00:12:07,062 [INFO] Reading complete. time_to_read=6.40 seconds
2019-12-28 00:12:07,062 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-28 00:12:08,726 [INFO] Reading complete. time_to_read=1.66 seconds
2019-12-28 00:12:08,726 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-28 00:12:09,198 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-28 00:12:09,198 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-28 00:12:09,404 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-28 00:12:09,404 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-28 00:12:09,456 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-28 00:12:09,456 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-28 00:12:09,476 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-28 00:12:15,207 [INFO] Preparing flow sequences
2019-12-28 00:13:02,706 [INFO] Extracting flows complete. time_taken = 47.50 sec
2019-12-28 00:13:04,326 [INFO] Initializing model
2019-12-28 00:13:04,568 [INFO] _________________________________________________________________
2019-12-28 00:13:04,569 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-28 00:13:04,569 [INFO] =================================================================
2019-12-28 00:13:04,569 [INFO] lstm_5 (LSTM)                (None, 32, 32)            19968     
2019-12-28 00:13:04,569 [INFO] _________________________________________________________________
2019-12-28 00:13:04,569 [INFO] batch_normalization_5 (Batch (None, 32, 32)            128       
2019-12-28 00:13:04,569 [INFO] _________________________________________________________________
2019-12-28 00:13:04,569 [INFO] dropout_5 (Dropout)          (None, 32, 32)            0         
2019-12-28 00:13:04,569 [INFO] _________________________________________________________________
2019-12-28 00:13:04,569 [INFO] time_distributed_5 (TimeDist (None, 32, 5)             165       
2019-12-28 00:13:04,570 [INFO] =================================================================
2019-12-28 00:13:04,570 [INFO] Total params: 20,261
2019-12-28 00:13:04,570 [INFO] Trainable params: 20,197
2019-12-28 00:13:04,570 [INFO] Non-trainable params: 64
2019-12-28 00:13:04,570 [INFO] _________________________________________________________________
2019-12-28 00:13:04,570 [INFO] Training model
 - val_f1: 0.9998
Epoch 00104: early stopping
Train on 122460 samples, validate on 30615 samples
Epoch 1/300
 - 29s - loss: 0.0573 - val_loss: 0.0041
 - val_f1: 0.9985
Epoch 2/300
 - 28s - loss: 0.0032 - val_loss: 0.0014
 - val_f1: 0.9993
Epoch 3/300
 - 28s - loss: 0.0015 - val_loss: 9.3660e-04
 - val_f1: 0.9995
Epoch 4/300
 - 28s - loss: 0.0011 - val_loss: 7.2070e-04
 - val_f1: 0.9996
Epoch 5/300
 - 27s - loss: 8.9359e-04 - val_loss: 6.1539e-04
 - val_f1: 0.9996
Epoch 6/300
 - 28s - loss: 7.7377e-04 - val_loss: 5.5382e-04
 - val_f1: 0.9997
Epoch 7/300
 - 28s - loss: 6.6986e-04 - val_loss: 5.1187e-04
 - val_f1: 0.9997
Epoch 8/300
 - 28s - loss: 6.1151e-04 - val_loss: 4.9205e-04
 - val_f1: 0.9997
Epoch 9/300
 - 28s - loss: 5.5065e-04 - val_loss: 4.5949e-04
 - val_f1: 0.9997
Epoch 10/300
 - 28s - loss: 5.0666e-04 - val_loss: 4.3015e-04
 - val_f1: 0.9997
Epoch 11/300
 - 28s - loss: 4.7174e-04 - val_loss: 4.0279e-04
 - val_f1: 0.9998
Epoch 12/300
 - 28s - loss: 4.5545e-04 - val_loss: 3.9095e-04
 - val_f1: 0.9998
Epoch 13/300
 - 28s - loss: 4.2605e-04 - val_loss: 3.6516e-04
 - val_f1: 0.9998
Epoch 14/300
 - 28s - loss: 3.9258e-04 - val_loss: 3.5567e-04
 - val_f1: 0.9998
Epoch 15/300
 - 28s - loss: 3.9478e-04 - val_loss: 3.7203e-04
 - val_f1: 0.9998
Epoch 16/300
 - 28s - loss: 3.7423e-04 - val_loss: 3.4696e-04
 - val_f1: 0.9998
Epoch 17/300
 - 28s - loss: 3.4544e-04 - val_loss: 3.3074e-04
 - val_f1: 0.9998
Epoch 18/300
 - 28s - loss: 3.4158e-04 - val_loss: 3.3394e-04
 - val_f1: 0.9998
Epoch 19/300
 - 28s - loss: 3.2369e-04 - val_loss: 3.4732e-04
 - val_f1: 0.9998
Epoch 20/300
 - 28s - loss: 3.1472e-04 - val_loss: 3.4303e-04
 - val_f1: 0.9998
Epoch 21/300
 - 28s - loss: 3.0544e-04 - val_loss: 3.1908e-04
 - val_f1: 0.9998
Epoch 22/300
 - 28s - loss: 3.1499e-04 - val_loss: 3.3657e-04
 - val_f1: 0.9998
Epoch 23/300
 - 28s - loss: 2.9897e-04 - val_loss: 3.6623e-04
 - val_f1: 0.9998
Epoch 24/300
 - 28s - loss: 2.8913e-04 - val_loss: 3.3195e-04
 - val_f1: 0.9998
Epoch 25/300
 - 28s - loss: 2.9228e-04 - val_loss: 3.2350e-04
 - val_f1: 0.9998
Epoch 26/300
 - 28s - loss: 2.8111e-04 - val_loss: 3.3677e-04
 - val_f1: 0.9998
Epoch 27/300
 - 28s - loss: 2.7215e-04 - val_loss: 3.3230e-04
 - val_f1: 0.9998
Epoch 28/300
 - 28s - loss: 2.6711e-04 - val_loss: 3.3512e-04
 - val_f1: 0.9998
Epoch 29/300
 - 28s - loss: 2.6218e-04 - val_loss: 3.4407e-04
 - val_f1: 0.9998
Epoch 30/300
 - 28s - loss: 2.5272e-04 - val_loss: 3.0628e-04
 - val_f1: 0.9998
Epoch 31/300
 - 28s - loss: 2.4601e-04 - val_loss: 3.0764e-04
2019-12-28 00:31:10,764 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep5/_model_epoch_30.pickle
 - val_f1: 0.9998
Epoch 32/300
 - 28s - loss: 2.3878e-04 - val_loss: 3.1141e-04
 - val_f1: 0.9998
Epoch 33/300
 - 28s - loss: 2.3657e-04 - val_loss: 3.1820e-04
 - val_f1: 0.9998
Epoch 34/300
 - 28s - loss: 2.3786e-04 - val_loss: 3.0207e-04
 - val_f1: 0.9998
Epoch 35/300
 - 28s - loss: 2.3067e-04 - val_loss: 3.5762e-04
 - val_f1: 0.9998
Epoch 36/300
 - 28s - loss: 2.2840e-04 - val_loss: 3.3620e-04
 - val_f1: 0.9998
Epoch 37/300
 - 28s - loss: 2.2777e-04 - val_loss: 3.3839e-04
 - val_f1: 0.9998
Epoch 38/300
 - 28s - loss: 2.2764e-04 - val_loss: 3.2720e-04
 - val_f1: 0.9998
Epoch 39/300
 - 28s - loss: 2.3297e-04 - val_loss: 3.2676e-04
 - val_f1: 0.9998
Epoch 40/300
 - 28s - loss: 2.2495e-04 - val_loss: 3.5661e-04
 - val_f1: 0.9998
Epoch 41/300
 - 28s - loss: 2.1819e-04 - val_loss: 3.5646e-04
 - val_f1: 0.9998
Epoch 42/300
 - 27s - loss: 2.1646e-04 - val_loss: 3.3333e-04
 - val_f1: 0.9998
Epoch 43/300
 - 28s - loss: 2.0759e-04 - val_loss: 3.2815e-04
 - val_f1: 0.9998
Epoch 44/300
 - 28s - loss: 2.1945e-04 - val_loss: 3.4826e-04
 - val_f1: 0.9998
Epoch 45/300
 - 28s - loss: 2.0583e-04 - val_loss: 3.1847e-04
 - val_f1: 0.9998
Epoch 46/300
 - 28s - loss: 2.0449e-04 - val_loss: 3.3795e-04
 - val_f1: 0.9998
Epoch 47/300
 - 28s - loss: 2.1471e-04 - val_loss: 3.5102e-04
 - val_f1: 0.9998
Epoch 48/300
 - 28s - loss: 2.0865e-04 - val_loss: 3.5630e-04
 - val_f1: 0.9998
Epoch 49/300
 - 28s - loss: 2.0213e-04 - val_loss: 3.2966e-04
 - val_f1: 0.9998
Epoch 50/300
 - 28s - loss: 2.0045e-04 - val_loss: 3.4830e-04
 - val_f1: 0.9998
Epoch 51/300
 - 28s - loss: 1.9516e-04 - val_loss: 3.6212e-04
 - val_f1: 0.9998
Epoch 52/300
 - 28s - loss: 1.9613e-04 - val_loss: 3.3343e-04
 - val_f1: 0.9998
Epoch 53/300
 - 28s - loss: 1.8515e-04 - val_loss: 3.4340e-04
 - val_f1: 0.9998
Epoch 54/300
 - 28s - loss: 1.9108e-04 - val_loss: 3.2740e-04
 - val_f1: 0.9998
Epoch 55/300
 - 28s - loss: 1.8838e-04 - val_loss: 3.5765e-04
 - val_f1: 0.9998
Epoch 56/300
 - 28s - loss: 1.9254e-04 - val_loss: 3.2599e-04
 - val_f1: 0.9998
Epoch 57/300
 - 28s - loss: 1.9600e-04 - val_loss: 3.6577e-04
 - val_f1: 0.9998
Epoch 58/300
 - 28s - loss: 1.9269e-04 - val_loss: 3.3884e-04
 - val_f1: 0.9998
Epoch 59/300
 - 28s - loss: 1.7797e-04 - val_loss: 3.6248e-04
 - val_f1: 0.9998
Epoch 60/300
 - 28s - loss: 1.8128e-04 - val_loss: 3.5487e-04
 - val_f1: 0.9998
Epoch 61/300
 - 27s - loss: 1.9299e-04 - val_loss: 3.4205e-04
2019-12-28 00:48:42,823 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_lstm_shallow_rep5/_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 28s - loss: 1.7905e-04 - val_loss: 3.5299e-04
 - val_f1: 0.9998
Epoch 63/300
 - 28s - loss: 1.8291e-04 - val_loss: 3.4551e-04
 - val_f1: 0.9998
Epoch 64/300
 - 28s - loss: 1.8359e-04 - val_loss: 3.3986e-04
 - val_f1: 0.9998
Epoch 65/300
 - 28s - loss: 1.7316e-04 - val_loss: 3.5115e-04
 - val_f1: 0.9998
Epoch 66/300
 - 28s - loss: 1.7995e-04 - val_loss: 3.4726e-04
 - val_f1: 0.9998
Epoch 67/300
 - 27s - loss: 1.7748e-04 - val_loss: 3.3807e-04
 - val_f1: 0.9998
Epoch 68/300
 - 28s - loss: 1.7531e-04 - val_loss: 3.4674e-04
 - val_f1: 0.9998
Epoch 69/300
 - 28s - loss: 1.6706e-04 - val_loss: 3.5114e-04
 - val_f1: 0.9998
Epoch 70/300
 - 28s - loss: 1.6381e-04 - val_loss: 3.6808e-04
 - val_f1: 0.9998
Epoch 71/300
 - 28s - loss: 1.7054e-04 - val_loss: 3.5259e-04
 - val_f1: 0.9998
Epoch 72/300
 - 28s - loss: 1.5888e-04 - val_loss: 3.6219e-04
 - val_f1: 0.9998
Epoch 73/300
 - 28s - loss: 1.6878e-04 - val_loss: 3.7421e-04
 - val_f1: 0.9998
Epoch 74/300
 - 28s - loss: 1.7141e-04 - val_loss: 3.7302e-04
 - val_f1: 0.9998
Epoch 75/300
 - 28s - loss: 1.6314e-04 - val_loss: 4.1326e-04
 - val_f1: 0.9998
Epoch 76/300
 - 28s - loss: 1.6156e-04 - val_loss: 3.5089e-04
 - val_f1: 0.9998
Epoch 77/300
 - 28s - loss: 1.5805e-04 - val_loss: 3.5293e-04
 - val_f1: 0.9998
Epoch 78/300
 - 28s - loss: 1.6600e-04 - val_loss: 3.5210e-04
 - val_f1: 0.9998
Epoch 79/300
 - 28s - loss: 1.6791e-04 - val_loss: 3.8370e-04
 - val_f1: 0.9998
Epoch 80/300
 - 28s - loss: 1.5569e-04 - val_loss: 3.9087e-04
 - val_f1: 0.9998
Epoch 81/300
 - 28s - loss: 1.5417e-04 - val_loss: 3.7931e-04
 - val_f1: 0.9998
Epoch 82/300
 - 27s - loss: 1.5804e-04 - val_loss: 3.8398e-04
 - val_f1: 0.9998
Epoch 83/300
 - 28s - loss: 1.5748e-04 - val_loss: 3.8344e-04
 - val_f1: 0.9998
Epoch 84/300
 - 28s - loss: 1.6653e-04 - val_loss: 3.6677e-04
2019-12-28 01:02:16,856 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-28 01:02:50,811 [INFO] Last epoch loss evaluation: train_loss = 0.000163, val_loss = 0.000302
2019-12-28 01:02:50,811 [INFO] Training complete. time_to_train = 2986.24 sec, 49.77 min
2019-12-28 01:02:50,815 [INFO] Model saved to results_selected_models/selected_kdd99_lstm_shallow_rep5/best_model.pickle
2019-12-28 01:02:50,817 [INFO] Training history saved to: results_selected_models/selected_kdd99_lstm_shallow_rep5/training_error_history.csv
2019-12-28 01:02:50,992 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep5/training_error_history.png
2019-12-28 01:02:51,158 [INFO] Plot saved to: results_selected_models/selected_kdd99_lstm_shallow_rep5/training_f1_history.png
2019-12-28 01:02:51,158 [INFO] Making predictions on training, validation, testing data
2019-12-28 01:03:26,816 [INFO] Evaluating predictions (results)
2019-12-28 01:03:35,517 [INFO] Dataset: Testing. Classification report below
2019-12-28 01:03:35,517 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60580
       probe       0.71      0.76      0.74      4166
         r2l       0.98      0.05      0.09     13773
         u2r       0.06      0.00      0.00      2636

    accuracy                           0.92    311008
   macro avg       0.69      0.55      0.53    311008
weighted avg       0.93      0.92      0.90    311008

2019-12-28 01:03:35,517 [INFO] Overall accuracy (micro avg): 0.9227961981685359
2019-12-28 01:03:44,851 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9228         0.9228                       0.9228                0.0193                   0.0772  0.9228
1     Macro avg        0.9691         0.6937                       0.5532                0.0198                   0.4468  0.5298
2  Weighted avg        0.9675         0.9327                       0.9228                0.0216                   0.0772  0.9050
2019-12-28 01:04:15,453 [INFO] Dataset: Validation. Classification report below
2019-12-28 01:04:15,453 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776671
     normal.       1.00      1.00      1.00    194553
       probe       1.00      0.99      1.00      8221
         r2l       0.89      0.84      0.86       225
         u2r       1.00      0.10      0.18        10

    accuracy                           1.00    979680
   macro avg       0.98      0.79      0.81    979680
weighted avg       1.00      1.00      1.00    979680

2019-12-28 01:04:15,454 [INFO] Overall accuracy (micro avg): 0.9998254532092111
2019-12-28 01:04:48,449 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9765                       0.7860                0.0001                   0.2140  0.8074
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-28 01:07:01,985 [INFO] Dataset: Training. Classification report below
2019-12-28 01:07:01,985 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106675
     normal.       1.00      1.00      1.00    778221
       probe       1.00      1.00      1.00     32881
         r2l       0.89      0.87      0.88       901
         u2r       0.92      0.57      0.71        42

    accuracy                           1.00   3918720
   macro avg       0.96      0.89      0.92   3918720
weighted avg       1.00      1.00      1.00   3918720

2019-12-28 01:07:01,986 [INFO] Overall accuracy (micro avg): 0.9998787869508411
2019-12-28 01:09:26,078 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        1.0000         0.9630                       0.8881                0.0000                   0.1119  0.9172
2  Weighted avg        1.0000         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-28 01:09:26,125 [INFO] Results saved to: results_selected_models/selected_kdd99_lstm_shallow_rep5/selected_kdd99_lstm_shallow_rep5_results.xlsx
2019-12-28 01:09:26,132 [INFO] ================= Finished running experiment no. 5 ================= 

