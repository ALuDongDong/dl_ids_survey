Using TensorFlow backend.
2019-12-21 10:40:58,431 [INFO] Read 20 experiments from file: experiment_specs/selected_model_tests/selected_ae_ann.csv
2019-12-21 10:40:58,431 [INFO] ================= Started running experiments ================= 

2019-12-21 10:40:58,431 [INFO] Created directory: results_selected_models/selected_nsl_ae_ann_shallow_rep1
2019-12-21 10:40:58,431 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ae_ann_shallow_rep1/run_log.log
2019-12-21 10:40:58,431 [INFO] ================= Running experiment no. 1  ================= 

2019-12-21 10:40:58,431 [INFO] Experiment parameters given below
2019-12-21 10:40:58,431 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ae_ann_shallow_rep1'}
2019-12-21 10:40:58,431 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ae_ann_shallow_rep1/tf_logs_run_2019_12_21-10_40_58
2019-12-21 10:40:58,431 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-21 10:40:58,432 [INFO] Reading X, y files
2019-12-21 10:40:58,432 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-21 10:40:58,726 [INFO] Reading complete. time_to_read=0.29 seconds
2019-12-21 10:40:58,726 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-21 10:40:58,799 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 10:40:58,799 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-21 10:40:58,867 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 10:40:58,867 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-21 10:40:58,878 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:40:58,879 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-21 10:40:58,886 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:40:58,886 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-21 10:40:58,892 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:40:59,080 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-21 10:40:59,101 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-21 10:40:59,171 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-21 10:40:59,210 [INFO] _________________________________________________________________
2019-12-21 10:40:59,210 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:40:59,210 [INFO] =================================================================
2019-12-21 10:40:59,210 [INFO] dense_1 (Dense)              (None, 32)                3936      
2019-12-21 10:40:59,210 [INFO] _________________________________________________________________
2019-12-21 10:40:59,210 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2019-12-21 10:40:59,210 [INFO] _________________________________________________________________
2019-12-21 10:40:59,210 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2019-12-21 10:40:59,210 [INFO] _________________________________________________________________
2019-12-21 10:40:59,210 [INFO] dense_2 (Dense)              (None, 122)               4026      
2019-12-21 10:40:59,210 [INFO] =================================================================
2019-12-21 10:40:59,210 [INFO] Total params: 8,090
2019-12-21 10:40:59,210 [INFO] Trainable params: 8,026
2019-12-21 10:40:59,210 [INFO] Non-trainable params: 64
2019-12-21 10:40:59,211 [INFO] _________________________________________________________________
2019-12-21 10:40:59,314 [INFO] _________________________________________________________________
2019-12-21 10:40:59,315 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:40:59,315 [INFO] =================================================================
2019-12-21 10:40:59,315 [INFO] dense_3 (Dense)              (None, 32)                1056      
2019-12-21 10:40:59,315 [INFO] _________________________________________________________________
2019-12-21 10:40:59,315 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-21 10:40:59,315 [INFO] _________________________________________________________________
2019-12-21 10:40:59,315 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-21 10:40:59,315 [INFO] _________________________________________________________________
2019-12-21 10:40:59,315 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-21 10:40:59,315 [INFO] =================================================================
2019-12-21 10:40:59,315 [INFO] Total params: 1,349
2019-12-21 10:40:59,315 [INFO] Trainable params: 1,285
2019-12-21 10:40:59,315 [INFO] Non-trainable params: 64
2019-12-21 10:40:59,315 [INFO] _________________________________________________________________
2019-12-21 10:40:59,315 [INFO] Training model
2019-12-21 10:40:59,315 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 10:40:59,907 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389
2019-12-21 10:40:59,907 [INFO] Training autoencoder
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-21 10:41:00,505 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-21 10:41:00.778925: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-21 10:41:00.812745: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2019-12-21 10:41:00.814075: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x27e25d0 executing computations on platform Host. Devices:
2019-12-21 10:41:00.814094: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3302 - val_loss: -2.2362e-01
Epoch 2/200
 - 1s - loss: -6.8792e-01 - val_loss: -1.3045e+00
Epoch 3/200
 - 1s - loss: -1.5938e+00 - val_loss: -2.0425e+00
Epoch 4/200
 - 1s - loss: -2.2307e+00 - val_loss: -2.5666e+00
Epoch 5/200
 - 1s - loss: -2.5917e+00 - val_loss: -2.8407e+00
Epoch 6/200
 - 1s - loss: -2.7848e+00 - val_loss: -2.9824e+00
Epoch 7/200
 - 1s - loss: -2.8879e+00 - val_loss: -3.0533e+00
Epoch 8/200
 - 1s - loss: -2.9470e+00 - val_loss: -3.0940e+00
Epoch 9/200
 - 1s - loss: -2.9893e+00 - val_loss: -3.1208e+00
Epoch 10/200
 - 1s - loss: -3.0186e+00 - val_loss: -3.1399e+00
Epoch 11/200
 - 1s - loss: -3.0397e+00 - val_loss: -3.1539e+00
Epoch 12/200
 - 1s - loss: -3.0582e+00 - val_loss: -3.1652e+00
Epoch 13/200
 - 1s - loss: -3.0708e+00 - val_loss: -3.1728e+00
Epoch 14/200
 - 1s - loss: -3.0830e+00 - val_loss: -3.1793e+00
Epoch 15/200
 - 1s - loss: -3.0929e+00 - val_loss: -3.1852e+00
Epoch 16/200
 - 1s - loss: -3.1008e+00 - val_loss: -3.1885e+00
Epoch 17/200
 - 1s - loss: -3.1062e+00 - val_loss: -3.1922e+00
Epoch 18/200
 - 1s - loss: -3.1147e+00 - val_loss: -3.1950e+00
Epoch 19/200
 - 1s - loss: -3.1189e+00 - val_loss: -3.1980e+00
Epoch 20/200
 - 1s - loss: -3.1236e+00 - val_loss: -3.2003e+00
Epoch 21/200
 - 1s - loss: -3.1272e+00 - val_loss: -3.2018e+00
2019-12-21 10:41:15,917 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_20.pickle
Epoch 22/200
 - 1s - loss: -3.1296e+00 - val_loss: -3.2039e+00
Epoch 23/200
 - 1s - loss: -3.1354e+00 - val_loss: -3.2058e+00
Epoch 24/200
 - 1s - loss: -3.1394e+00 - val_loss: -3.2066e+00
Epoch 25/200
 - 1s - loss: -3.1395e+00 - val_loss: -3.2078e+00
Epoch 26/200
 - 1s - loss: -3.1437e+00 - val_loss: -3.2091e+00
Epoch 27/200
 - 1s - loss: -3.1461e+00 - val_loss: -3.2097e+00
Epoch 28/200
 - 1s - loss: -3.1498e+00 - val_loss: -3.2109e+00
Epoch 29/200
 - 1s - loss: -3.1500e+00 - val_loss: -3.2113e+00
Epoch 30/200
 - 1s - loss: -3.1527e+00 - val_loss: -3.2124e+00
Epoch 31/200
 - 1s - loss: -3.1536e+00 - val_loss: -3.2130e+00
Epoch 32/200
 - 1s - loss: -3.1569e+00 - val_loss: -3.2135e+00
Epoch 33/200
 - 1s - loss: -3.1566e+00 - val_loss: -3.2142e+00
Epoch 34/200
 - 1s - loss: -3.1585e+00 - val_loss: -3.2153e+00
Epoch 35/200
 - 1s - loss: -3.1617e+00 - val_loss: -3.2154e+00
Epoch 36/200
 - 1s - loss: -3.1603e+00 - val_loss: -3.2160e+00
Epoch 37/200
 - 1s - loss: -3.1624e+00 - val_loss: -3.2168e+00
Epoch 38/200
 - 1s - loss: -3.1637e+00 - val_loss: -3.2165e+00
Epoch 39/200
 - 1s - loss: -3.1639e+00 - val_loss: -3.2167e+00
Epoch 40/200
 - 1s - loss: -3.1659e+00 - val_loss: -3.2175e+00
Epoch 41/200
 - 1s - loss: -3.1663e+00 - val_loss: -3.2173e+00
2019-12-21 10:41:29,756 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_40.pickle
Epoch 42/200
 - 1s - loss: -3.1674e+00 - val_loss: -3.2175e+00
Epoch 43/200
 - 1s - loss: -3.1682e+00 - val_loss: -3.2182e+00
Epoch 44/200
 - 1s - loss: -3.1682e+00 - val_loss: -3.2184e+00
Epoch 45/200
 - 1s - loss: -3.1699e+00 - val_loss: -3.2182e+00
Epoch 46/200
 - 1s - loss: -3.1720e+00 - val_loss: -3.2186e+00
Epoch 47/200
 - 1s - loss: -3.1713e+00 - val_loss: -3.2191e+00
Epoch 48/200
 - 1s - loss: -3.1724e+00 - val_loss: -3.2194e+00
Epoch 49/200
 - 1s - loss: -3.1736e+00 - val_loss: -3.2199e+00
Epoch 50/200
 - 1s - loss: -3.1734e+00 - val_loss: -3.2200e+00
Epoch 51/200
 - 1s - loss: -3.1739e+00 - val_loss: -3.2200e+00
Epoch 52/200
 - 1s - loss: -3.1735e+00 - val_loss: -3.2201e+00
Epoch 53/200
 - 1s - loss: -3.1753e+00 - val_loss: -3.2209e+00
Epoch 54/200
 - 1s - loss: -3.1756e+00 - val_loss: -3.2202e+00
Epoch 55/200
 - 1s - loss: -3.1756e+00 - val_loss: -3.2206e+00
Epoch 56/200
 - 1s - loss: -3.1770e+00 - val_loss: -3.2210e+00
Epoch 57/200
 - 1s - loss: -3.1774e+00 - val_loss: -3.2213e+00
Epoch 58/200
 - 1s - loss: -3.1768e+00 - val_loss: -3.2209e+00
Epoch 59/200
 - 1s - loss: -3.1784e+00 - val_loss: -3.2215e+00
Epoch 60/200
 - 1s - loss: -3.1781e+00 - val_loss: -3.2218e+00
Epoch 61/200
 - 1s - loss: -3.1777e+00 - val_loss: -3.2214e+00
2019-12-21 10:41:43,635 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_60.pickle
Epoch 62/200
 - 1s - loss: -3.1789e+00 - val_loss: -3.2223e+00
Epoch 63/200
 - 1s - loss: -3.1802e+00 - val_loss: -3.2226e+00
Epoch 64/200
 - 1s - loss: -3.1812e+00 - val_loss: -3.2221e+00
Epoch 65/200
 - 1s - loss: -3.1789e+00 - val_loss: -3.2226e+00
Epoch 66/200
 - 1s - loss: -3.1806e+00 - val_loss: -3.2226e+00
Epoch 67/200
 - 1s - loss: -3.1791e+00 - val_loss: -3.2225e+00
Epoch 68/200
 - 1s - loss: -3.1819e+00 - val_loss: -3.2227e+00
Epoch 69/200
 - 1s - loss: -3.1810e+00 - val_loss: -3.2230e+00
Epoch 70/200
 - 1s - loss: -3.1829e+00 - val_loss: -3.2230e+00
Epoch 71/200
 - 1s - loss: -3.1819e+00 - val_loss: -3.2234e+00
Epoch 72/200
 - 1s - loss: -3.1831e+00 - val_loss: -3.2240e+00
Epoch 73/200
 - 1s - loss: -3.1838e+00 - val_loss: -3.2240e+00
Epoch 74/200
 - 1s - loss: -3.1832e+00 - val_loss: -3.2237e+00
Epoch 75/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2236e+00
Epoch 76/200
 - 1s - loss: -3.1839e+00 - val_loss: -3.2241e+00
Epoch 77/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2238e+00
Epoch 78/200
 - 1s - loss: -3.1841e+00 - val_loss: -3.2241e+00
Epoch 79/200
 - 1s - loss: -3.1846e+00 - val_loss: -3.2243e+00
Epoch 80/200
 - 1s - loss: -3.1858e+00 - val_loss: -3.2246e+00
Epoch 81/200
 - 1s - loss: -3.1842e+00 - val_loss: -3.2244e+00
2019-12-21 10:41:57,428 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_80.pickle
Epoch 82/200
 - 1s - loss: -3.1856e+00 - val_loss: -3.2245e+00
Epoch 83/200
 - 1s - loss: -3.1862e+00 - val_loss: -3.2249e+00
Epoch 84/200
 - 1s - loss: -3.1853e+00 - val_loss: -3.2246e+00
Epoch 85/200
 - 1s - loss: -3.1856e+00 - val_loss: -3.2251e+00
Epoch 86/200
 - 1s - loss: -3.1870e+00 - val_loss: -3.2251e+00
Epoch 87/200
 - 1s - loss: -3.1867e+00 - val_loss: -3.2251e+00
Epoch 88/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2246e+00
Epoch 89/200
 - 1s - loss: -3.1871e+00 - val_loss: -3.2252e+00
Epoch 90/200
 - 1s - loss: -3.1881e+00 - val_loss: -3.2249e+00
Epoch 91/200
 - 1s - loss: -3.1879e+00 - val_loss: -3.2250e+00
Epoch 92/200
 - 1s - loss: -3.1873e+00 - val_loss: -3.2250e+00
Epoch 93/200
 - 1s - loss: -3.1862e+00 - val_loss: -3.2258e+00
Epoch 94/200
 - 1s - loss: -3.1876e+00 - val_loss: -3.2255e+00
Epoch 95/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2255e+00
Epoch 96/200
 - 1s - loss: -3.1880e+00 - val_loss: -3.2252e+00
Epoch 97/200
 - 1s - loss: -3.1887e+00 - val_loss: -3.2252e+00
Epoch 98/200
 - 1s - loss: -3.1865e+00 - val_loss: -3.2251e+00
Epoch 99/200
 - 1s - loss: -3.1911e+00 - val_loss: -3.2261e+00
Epoch 100/200
 - 1s - loss: -3.1896e+00 - val_loss: -3.2261e+00
Epoch 101/200
 - 1s - loss: -3.1905e+00 - val_loss: -3.2263e+00
2019-12-21 10:42:11,277 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_100.pickle
Epoch 102/200
 - 1s - loss: -3.1891e+00 - val_loss: -3.2261e+00
Epoch 103/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2255e+00
Epoch 104/200
 - 1s - loss: -3.1882e+00 - val_loss: -3.2251e+00
Epoch 105/200
 - 1s - loss: -3.1898e+00 - val_loss: -3.2260e+00
Epoch 106/200
 - 1s - loss: -3.1901e+00 - val_loss: -3.2258e+00
Epoch 107/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2260e+00
Epoch 108/200
 - 1s - loss: -3.1911e+00 - val_loss: -3.2260e+00
Epoch 109/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2256e+00
Epoch 110/200
 - 1s - loss: -3.1902e+00 - val_loss: -3.2258e+00
Epoch 111/200
 - 1s - loss: -3.1915e+00 - val_loss: -3.2260e+00
Epoch 112/200
 - 1s - loss: -3.1911e+00 - val_loss: -3.2268e+00
Epoch 113/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2263e+00
Epoch 114/200
 - 1s - loss: -3.1918e+00 - val_loss: -3.2261e+00
Epoch 115/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2258e+00
Epoch 116/200
 - 1s - loss: -3.1907e+00 - val_loss: -3.2264e+00
Epoch 117/200
 - 1s - loss: -3.1905e+00 - val_loss: -3.2266e+00
Epoch 118/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2267e+00
Epoch 119/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2264e+00
Epoch 120/200
 - 1s - loss: -3.1910e+00 - val_loss: -3.2265e+00
Epoch 121/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2264e+00
2019-12-21 10:42:25,138 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_120.pickle
Epoch 122/200
 - 1s - loss: -3.1919e+00 - val_loss: -3.2268e+00
Epoch 123/200
 - 1s - loss: -3.1925e+00 - val_loss: -3.2269e+00
Epoch 124/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2268e+00
Epoch 125/200
 - 1s - loss: -3.1924e+00 - val_loss: -3.2275e+00
Epoch 126/200
 - 1s - loss: -3.1927e+00 - val_loss: -3.2268e+00
Epoch 127/200
 - 1s - loss: -3.1936e+00 - val_loss: -3.2273e+00
Epoch 128/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2273e+00
Epoch 129/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2274e+00
Epoch 130/200
 - 1s - loss: -3.1944e+00 - val_loss: -3.2267e+00
Epoch 131/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2274e+00
Epoch 132/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2273e+00
Epoch 133/200
 - 1s - loss: -3.1952e+00 - val_loss: -3.2269e+00
Epoch 134/200
 - 1s - loss: -3.1940e+00 - val_loss: -3.2275e+00
Epoch 135/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2277e+00
Epoch 136/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2275e+00
Epoch 137/200
 - 1s - loss: -3.1954e+00 - val_loss: -3.2272e+00
Epoch 138/200
 - 1s - loss: -3.1924e+00 - val_loss: -3.2275e+00
Epoch 139/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2273e+00
Epoch 140/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2279e+00
Epoch 141/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2282e+00
2019-12-21 10:42:38,986 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_140.pickle
Epoch 142/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2272e+00
Epoch 143/200
 - 1s - loss: -3.1938e+00 - val_loss: -3.2274e+00
Epoch 144/200
 - 1s - loss: -3.1944e+00 - val_loss: -3.2277e+00
Epoch 145/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2280e+00
Epoch 146/200
 - 1s - loss: -3.1944e+00 - val_loss: -3.2280e+00
Epoch 147/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2281e+00
Epoch 148/200
 - 1s - loss: -3.1958e+00 - val_loss: -3.2281e+00
Epoch 149/200
 - 1s - loss: -3.1965e+00 - val_loss: -3.2278e+00
Epoch 150/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2279e+00
Epoch 151/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2281e+00
Epoch 152/200
 - 1s - loss: -3.1961e+00 - val_loss: -3.2279e+00
Epoch 153/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2280e+00
Epoch 154/200
 - 1s - loss: -3.1964e+00 - val_loss: -3.2281e+00
Epoch 155/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2283e+00
Epoch 156/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2279e+00
Epoch 157/200
 - 1s - loss: -3.1950e+00 - val_loss: -3.2286e+00
Epoch 158/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2282e+00
Epoch 159/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2283e+00
Epoch 160/200
 - 1s - loss: -3.1969e+00 - val_loss: -3.2283e+00
Epoch 161/200
 - 1s - loss: -3.1980e+00 - val_loss: -3.2279e+00
2019-12-21 10:42:52,868 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_160.pickle
Epoch 162/200
 - 1s - loss: -3.1966e+00 - val_loss: -3.2281e+00
Epoch 163/200
 - 1s - loss: -3.1976e+00 - val_loss: -3.2287e+00
Epoch 164/200
 - 1s - loss: -3.1978e+00 - val_loss: -3.2287e+00
Epoch 165/200
 - 1s - loss: -3.1944e+00 - val_loss: -3.2278e+00
Epoch 166/200
 - 1s - loss: -3.1978e+00 - val_loss: -3.2284e+00
Epoch 167/200
 - 1s - loss: -3.1965e+00 - val_loss: -3.2281e+00
Epoch 168/200
 - 1s - loss: -3.1991e+00 - val_loss: -3.2281e+00
Epoch 169/200
 - 1s - loss: -3.1983e+00 - val_loss: -3.2279e+00
Epoch 170/200
 - 1s - loss: -3.1977e+00 - val_loss: -3.2285e+00
Epoch 171/200
 - 1s - loss: -3.1981e+00 - val_loss: -3.2284e+00
Epoch 172/200
 - 1s - loss: -3.1978e+00 - val_loss: -3.2282e+00
Epoch 173/200
 - 1s - loss: -3.1989e+00 - val_loss: -3.2279e+00
Epoch 174/200
 - 1s - loss: -3.1976e+00 - val_loss: -3.2285e+00
Epoch 175/200
 - 1s - loss: -3.1974e+00 - val_loss: -3.2283e+00
Epoch 176/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2284e+00
Epoch 177/200
 - 1s - loss: -3.1991e+00 - val_loss: -3.2283e+00
Epoch 178/200
 - 1s - loss: -3.1990e+00 - val_loss: -3.2285e+00
Epoch 179/200
 - 1s - loss: -3.1979e+00 - val_loss: -3.2284e+00
Epoch 180/200
 - 1s - loss: -3.1973e+00 - val_loss: -3.2285e+00
Epoch 181/200
 - 1s - loss: -3.1982e+00 - val_loss: -3.2283e+00
2019-12-21 10:43:06,685 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ae_model_epoch_180.pickle
Epoch 182/200
 - 1s - loss: -3.1994e+00 - val_loss: -3.2284e+00
Epoch 183/200
 - 1s - loss: -3.1989e+00 - val_loss: -3.2286e+00
Epoch 184/200
 - 1s - loss: -3.1987e+00 - val_loss: -3.2284e+00
Epoch 185/200
 - 1s - loss: -3.1979e+00 - val_loss: -3.2288e+00
Epoch 186/200
 - 1s - loss: -3.1993e+00 - val_loss: -3.2292e+00
Epoch 187/200
 - 1s - loss: -3.1996e+00 - val_loss: -3.2292e+00
Epoch 188/200
 - 1s - loss: -3.1999e+00 - val_loss: -3.2291e+00
Epoch 189/200
 - 1s - loss: -3.1985e+00 - val_loss: -3.2290e+00
Epoch 190/200
 - 1s - loss: -3.1994e+00 - val_loss: -3.2291e+00
Epoch 191/200
 - 1s - loss: -3.1996e+00 - val_loss: -3.2286e+00
Epoch 192/200
 - 1s - loss: -3.1998e+00 - val_loss: -3.2289e+00
Epoch 193/200
 - 1s - loss: -3.1989e+00 - val_loss: -3.2291e+00
Epoch 194/200
 - 1s - loss: -3.2011e+00 - val_loss: -3.2291e+00
Epoch 195/200
 - 1s - loss: -3.2001e+00 - val_loss: -3.2293e+00
Epoch 196/200
 - 1s - loss: -3.1998e+00 - val_loss: -3.2288e+00
Epoch 197/200
 - 1s - loss: -3.2002e+00 - val_loss: -3.2285e+00
Epoch 198/200
 - 1s - loss: -3.2008e+00 - val_loss: -3.2291e+00
Epoch 199/200
 - 1s - loss: -3.2004e+00 - val_loss: -3.2294e+00
Epoch 200/200
 - 1s - loss: -3.2006e+00 - val_loss: -3.2291e+00
2019-12-21 10:43:19,818 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:43:20,814 [INFO] Last epoch loss evaluation: train_loss = -3.252217, val_loss = -3.229369
2019-12-21 10:43:20,814 [INFO] Training autoencoder complete
2019-12-21 10:43:20,814 [INFO] Encoding data for supervised training
2019-12-21 10:43:21,493 [INFO] Encoding complete
2019-12-21 10:43:21,494 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 0s - loss: 0.2266 - val_loss: 0.0658
 - val_f1: 0.9581
Epoch 2/200
 - 0s - loss: 0.0632 - val_loss: 0.0406
 - val_f1: 0.9707
Epoch 3/200
 - 0s - loss: 0.0457 - val_loss: 0.0311
 - val_f1: 0.9754
Epoch 4/200
 - 0s - loss: 0.0366 - val_loss: 0.0255
 - val_f1: 0.9785
Epoch 5/200
 - 0s - loss: 0.0313 - val_loss: 0.0212
 - val_f1: 0.9830
Epoch 6/200
 - 0s - loss: 0.0282 - val_loss: 0.0184
 - val_f1: 0.9851
Epoch 7/200
 - 0s - loss: 0.0250 - val_loss: 0.0166
 - val_f1: 0.9862
Epoch 8/200
 - 0s - loss: 0.0224 - val_loss: 0.0157
 - val_f1: 0.9868
Epoch 9/200
 - 0s - loss: 0.0213 - val_loss: 0.0147
 - val_f1: 0.9880
Epoch 10/200
 - 0s - loss: 0.0198 - val_loss: 0.0140
 - val_f1: 0.9891
Epoch 11/200
 - 0s - loss: 0.0187 - val_loss: 0.0134
 - val_f1: 0.9889
Epoch 12/200
 - 0s - loss: 0.0186 - val_loss: 0.0130
 - val_f1: 0.9896
Epoch 13/200
 - 0s - loss: 0.0181 - val_loss: 0.0129
 - val_f1: 0.9906
Epoch 14/200
 - 0s - loss: 0.0167 - val_loss: 0.0129
 - val_f1: 0.9904
Epoch 15/200
 - 0s - loss: 0.0165 - val_loss: 0.0127
 - val_f1: 0.9907
Epoch 16/200
 - 0s - loss: 0.0161 - val_loss: 0.0123
 - val_f1: 0.9922
Epoch 17/200
 - 0s - loss: 0.0154 - val_loss: 0.0123
 - val_f1: 0.9917
Epoch 18/200
 - 0s - loss: 0.0149 - val_loss: 0.0127
 - val_f1: 0.9916
Epoch 19/200
 - 0s - loss: 0.0153 - val_loss: 0.0124
 - val_f1: 0.9923
Epoch 20/200
 - 0s - loss: 0.0149 - val_loss: 0.0122
 - val_f1: 0.9926
Epoch 21/200
 - 0s - loss: 0.0140 - val_loss: 0.0119
2019-12-21 10:43:32,049 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9924
Epoch 22/200
 - 0s - loss: 0.0142 - val_loss: 0.0121
 - val_f1: 0.9917
Epoch 23/200
 - 0s - loss: 0.0142 - val_loss: 0.0120
 - val_f1: 0.9921
Epoch 24/200
 - 0s - loss: 0.0133 - val_loss: 0.0123
 - val_f1: 0.9921
Epoch 25/200
 - 0s - loss: 0.0139 - val_loss: 0.0119
 - val_f1: 0.9926
Epoch 26/200
 - 0s - loss: 0.0135 - val_loss: 0.0118
 - val_f1: 0.9928
Epoch 27/200
 - 0s - loss: 0.0131 - val_loss: 0.0115
 - val_f1: 0.9921
Epoch 28/200
 - 0s - loss: 0.0127 - val_loss: 0.0116
 - val_f1: 0.9925
Epoch 29/200
 - 0s - loss: 0.0128 - val_loss: 0.0115
 - val_f1: 0.9921
Epoch 30/200
 - 0s - loss: 0.0126 - val_loss: 0.0114
 - val_f1: 0.9922
Epoch 31/200
 - 0s - loss: 0.0128 - val_loss: 0.0114
 - val_f1: 0.9922
Epoch 32/200
 - 0s - loss: 0.0118 - val_loss: 0.0112
 - val_f1: 0.9928
Epoch 33/200
 - 0s - loss: 0.0122 - val_loss: 0.0113
 - val_f1: 0.9924
Epoch 34/200
 - 0s - loss: 0.0118 - val_loss: 0.0110
 - val_f1: 0.9926
Epoch 35/200
 - 0s - loss: 0.0120 - val_loss: 0.0109
 - val_f1: 0.9928
Epoch 36/200
 - 0s - loss: 0.0119 - val_loss: 0.0111
 - val_f1: 0.9922
Epoch 37/200
 - 0s - loss: 0.0120 - val_loss: 0.0109
 - val_f1: 0.9929
Epoch 38/200
 - 0s - loss: 0.0110 - val_loss: 0.0110
 - val_f1: 0.9927
Epoch 39/200
 - 0s - loss: 0.0115 - val_loss: 0.0107
 - val_f1: 0.9930
Epoch 40/200
 - 0s - loss: 0.0112 - val_loss: 0.0110
 - val_f1: 0.9924
Epoch 41/200
 - 0s - loss: 0.0113 - val_loss: 0.0106
2019-12-21 10:43:41,421 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9932
Epoch 42/200
 - 0s - loss: 0.0113 - val_loss: 0.0108
 - val_f1: 0.9924
Epoch 43/200
 - 0s - loss: 0.0113 - val_loss: 0.0107
 - val_f1: 0.9926
Epoch 44/200
 - 0s - loss: 0.0110 - val_loss: 0.0106
 - val_f1: 0.9926
Epoch 45/200
 - 0s - loss: 0.0109 - val_loss: 0.0108
 - val_f1: 0.9929
Epoch 46/200
 - 0s - loss: 0.0109 - val_loss: 0.0105
 - val_f1: 0.9929
Epoch 47/200
 - 0s - loss: 0.0104 - val_loss: 0.0108
 - val_f1: 0.9928
Epoch 48/200
 - 0s - loss: 0.0105 - val_loss: 0.0106
 - val_f1: 0.9933
Epoch 49/200
 - 0s - loss: 0.0103 - val_loss: 0.0107
 - val_f1: 0.9932
Epoch 50/200
 - 0s - loss: 0.0099 - val_loss: 0.0108
 - val_f1: 0.9933
Epoch 51/200
 - 0s - loss: 0.0101 - val_loss: 0.0106
 - val_f1: 0.9926
Epoch 52/200
 - 0s - loss: 0.0099 - val_loss: 0.0105
 - val_f1: 0.9934
Epoch 53/200
 - 0s - loss: 0.0102 - val_loss: 0.0101
 - val_f1: 0.9935
Epoch 54/200
 - 0s - loss: 0.0099 - val_loss: 0.0106
 - val_f1: 0.9929
Epoch 55/200
 - 0s - loss: 0.0102 - val_loss: 0.0107
 - val_f1: 0.9926
Epoch 56/200
 - 0s - loss: 0.0099 - val_loss: 0.0104
 - val_f1: 0.9935
Epoch 57/200
 - 0s - loss: 0.0101 - val_loss: 0.0103
 - val_f1: 0.9930
Epoch 58/200
 - 0s - loss: 0.0091 - val_loss: 0.0102
 - val_f1: 0.9930
Epoch 59/200
 - 0s - loss: 0.0098 - val_loss: 0.0104
 - val_f1: 0.9929
Epoch 60/200
 - 0s - loss: 0.0093 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 61/200
 - 0s - loss: 0.0094 - val_loss: 0.0107
2019-12-21 10:43:50,811 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9927
Epoch 62/200
 - 0s - loss: 0.0093 - val_loss: 0.0104
 - val_f1: 0.9930
Epoch 63/200
 - 0s - loss: 0.0096 - val_loss: 0.0103
 - val_f1: 0.9933
Epoch 64/200
 - 0s - loss: 0.0095 - val_loss: 0.0108
 - val_f1: 0.9928
Epoch 65/200
 - 0s - loss: 0.0091 - val_loss: 0.0101
 - val_f1: 0.9933
Epoch 66/200
 - 0s - loss: 0.0095 - val_loss: 0.0104
 - val_f1: 0.9930
Epoch 67/200
 - 0s - loss: 0.0093 - val_loss: 0.0100
 - val_f1: 0.9936
Epoch 68/200
 - 0s - loss: 0.0091 - val_loss: 0.0104
 - val_f1: 0.9932
Epoch 69/200
 - 0s - loss: 0.0089 - val_loss: 0.0103
 - val_f1: 0.9931
Epoch 70/200
 - 0s - loss: 0.0095 - val_loss: 0.0105
 - val_f1: 0.9928
Epoch 71/200
 - 0s - loss: 0.0091 - val_loss: 0.0106
 - val_f1: 0.9929
Epoch 72/200
 - 0s - loss: 0.0088 - val_loss: 0.0106
 - val_f1: 0.9925
Epoch 73/200
 - 0s - loss: 0.0089 - val_loss: 0.0104
 - val_f1: 0.9926
Epoch 74/200
 - 0s - loss: 0.0090 - val_loss: 0.0110
 - val_f1: 0.9924
Epoch 75/200
 - 0s - loss: 0.0088 - val_loss: 0.0106
 - val_f1: 0.9928
Epoch 76/200
 - 0s - loss: 0.0088 - val_loss: 0.0104
 - val_f1: 0.9934
Epoch 77/200
 - 0s - loss: 0.0089 - val_loss: 0.0104
 - val_f1: 0.9935
Epoch 78/200
 - 0s - loss: 0.0086 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 79/200
 - 0s - loss: 0.0091 - val_loss: 0.0100
 - val_f1: 0.9942
Epoch 80/200
 - 0s - loss: 0.0088 - val_loss: 0.0102
 - val_f1: 0.9934
Epoch 81/200
 - 0s - loss: 0.0087 - val_loss: 0.0100
2019-12-21 10:44:00,211 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9940
Epoch 82/200
 - 0s - loss: 0.0085 - val_loss: 0.0101
 - val_f1: 0.9938
Epoch 83/200
 - 0s - loss: 0.0087 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 84/200
 - 0s - loss: 0.0085 - val_loss: 0.0100
 - val_f1: 0.9937
Epoch 85/200
 - 0s - loss: 0.0091 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 86/200
 - 0s - loss: 0.0086 - val_loss: 0.0103
 - val_f1: 0.9935
Epoch 87/200
 - 0s - loss: 0.0089 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 88/200
 - 0s - loss: 0.0084 - val_loss: 0.0104
 - val_f1: 0.9935
Epoch 89/200
 - 0s - loss: 0.0079 - val_loss: 0.0100
 - val_f1: 0.9939
Epoch 90/200
 - 0s - loss: 0.0087 - val_loss: 0.0104
 - val_f1: 0.9930
Epoch 91/200
 - 0s - loss: 0.0088 - val_loss: 0.0103
 - val_f1: 0.9937
Epoch 92/200
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9935
Epoch 93/200
 - 0s - loss: 0.0088 - val_loss: 0.0105
 - val_f1: 0.9930
Epoch 94/200
 - 0s - loss: 0.0082 - val_loss: 0.0101
 - val_f1: 0.9938
Epoch 95/200
 - 0s - loss: 0.0079 - val_loss: 0.0107
 - val_f1: 0.9931
Epoch 96/200
 - 0s - loss: 0.0085 - val_loss: 0.0104
 - val_f1: 0.9933
Epoch 97/200
 - 0s - loss: 0.0086 - val_loss: 0.0100
 - val_f1: 0.9938
Epoch 98/200
 - 0s - loss: 0.0084 - val_loss: 0.0103
 - val_f1: 0.9931
Epoch 99/200
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9941
Epoch 100/200
 - 0s - loss: 0.0085 - val_loss: 0.0101
 - val_f1: 0.9940
Epoch 101/200
 - 0s - loss: 0.0079 - val_loss: 0.0101
2019-12-21 10:44:09,636 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9936
Epoch 102/200
 - 0s - loss: 0.0081 - val_loss: 0.0102
 - val_f1: 0.9941
Epoch 103/200
 - 0s - loss: 0.0083 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 104/200
 - 0s - loss: 0.0084 - val_loss: 0.0103
 - val_f1: 0.9935
Epoch 105/200
 - 0s - loss: 0.0081 - val_loss: 0.0105
 - val_f1: 0.9932
Epoch 106/200
 - 0s - loss: 0.0080 - val_loss: 0.0105
 - val_f1: 0.9937
Epoch 107/200
 - 0s - loss: 0.0084 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 108/200
 - 0s - loss: 0.0082 - val_loss: 0.0102
 - val_f1: 0.9939
Epoch 109/200
 - 0s - loss: 0.0082 - val_loss: 0.0107
 - val_f1: 0.9933
Epoch 110/200
 - 0s - loss: 0.0080 - val_loss: 0.0104
 - val_f1: 0.9937
Epoch 111/200
 - 0s - loss: 0.0082 - val_loss: 0.0099
 - val_f1: 0.9945
Epoch 112/200
 - 0s - loss: 0.0079 - val_loss: 0.0104
 - val_f1: 0.9936
Epoch 113/200
 - 0s - loss: 0.0078 - val_loss: 0.0103
 - val_f1: 0.9935
Epoch 114/200
 - 0s - loss: 0.0080 - val_loss: 0.0104
 - val_f1: 0.9937
Epoch 115/200
 - 0s - loss: 0.0081 - val_loss: 0.0103
 - val_f1: 0.9940
Epoch 116/200
 - 0s - loss: 0.0078 - val_loss: 0.0106
 - val_f1: 0.9934
Epoch 117/200
 - 0s - loss: 0.0082 - val_loss: 0.0102
 - val_f1: 0.9937
Epoch 118/200
 - 0s - loss: 0.0076 - val_loss: 0.0101
 - val_f1: 0.9938
Epoch 119/200
 - 0s - loss: 0.0080 - val_loss: 0.0104
 - val_f1: 0.9937
Epoch 120/200
 - 0s - loss: 0.0080 - val_loss: 0.0103
 - val_f1: 0.9940
Epoch 121/200
 - 0s - loss: 0.0084 - val_loss: 0.0103
2019-12-21 10:44:19,018 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9939
Epoch 122/200
 - 0s - loss: 0.0078 - val_loss: 0.0101
 - val_f1: 0.9942
Epoch 123/200
 - 0s - loss: 0.0078 - val_loss: 0.0102
 - val_f1: 0.9939
Epoch 124/200
 - 0s - loss: 0.0076 - val_loss: 0.0104
 - val_f1: 0.9936
Epoch 125/200
 - 0s - loss: 0.0076 - val_loss: 0.0101
 - val_f1: 0.9941
Epoch 126/200
 - 0s - loss: 0.0075 - val_loss: 0.0105
 - val_f1: 0.9939
Epoch 127/200
 - 0s - loss: 0.0075 - val_loss: 0.0101
 - val_f1: 0.9942
Epoch 128/200
 - 0s - loss: 0.0079 - val_loss: 0.0097
 - val_f1: 0.9948
Epoch 129/200
 - 0s - loss: 0.0075 - val_loss: 0.0100
 - val_f1: 0.9943
Epoch 130/200
 - 0s - loss: 0.0078 - val_loss: 0.0104
 - val_f1: 0.9940
Epoch 131/200
 - 0s - loss: 0.0078 - val_loss: 0.0106
 - val_f1: 0.9935
Epoch 132/200
 - 0s - loss: 0.0082 - val_loss: 0.0103
 - val_f1: 0.9939
Epoch 133/200
 - 0s - loss: 0.0079 - val_loss: 0.0104
 - val_f1: 0.9941
Epoch 134/200
 - 0s - loss: 0.0079 - val_loss: 0.0100
 - val_f1: 0.9944
Epoch 135/200
 - 0s - loss: 0.0080 - val_loss: 0.0103
 - val_f1: 0.9938
Epoch 136/200
 - 0s - loss: 0.0078 - val_loss: 0.0104
 - val_f1: 0.9937
Epoch 137/200
 - 0s - loss: 0.0080 - val_loss: 0.0101
 - val_f1: 0.9941
Epoch 138/200
 - 0s - loss: 0.0075 - val_loss: 0.0100
 - val_f1: 0.9943
Epoch 139/200
 - 0s - loss: 0.0078 - val_loss: 0.0104
 - val_f1: 0.9938
Epoch 140/200
 - 0s - loss: 0.0077 - val_loss: 0.0104
 - val_f1: 0.9940
Epoch 141/200
 - 0s - loss: 0.0076 - val_loss: 0.0105
2019-12-21 10:44:28,389 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9936
Epoch 142/200
 - 0s - loss: 0.0077 - val_loss: 0.0103
 - val_f1: 0.9940
Epoch 143/200
 - 0s - loss: 0.0076 - val_loss: 0.0102
 - val_f1: 0.9940
Epoch 144/200
 - 0s - loss: 0.0077 - val_loss: 0.0103
 - val_f1: 0.9940
Epoch 145/200
 - 0s - loss: 0.0073 - val_loss: 0.0104
 - val_f1: 0.9939
Epoch 146/200
 - 0s - loss: 0.0077 - val_loss: 0.0105
 - val_f1: 0.9935
Epoch 147/200
 - 0s - loss: 0.0074 - val_loss: 0.0103
 - val_f1: 0.9942
Epoch 148/200
 - 0s - loss: 0.0073 - val_loss: 0.0104
 - val_f1: 0.9944
Epoch 149/200
 - 0s - loss: 0.0076 - val_loss: 0.0106
 - val_f1: 0.9940
Epoch 150/200
 - 0s - loss: 0.0080 - val_loss: 0.0104
 - val_f1: 0.9941
Epoch 151/200
 - 0s - loss: 0.0079 - val_loss: 0.0105
 - val_f1: 0.9940
Epoch 152/200
 - 0s - loss: 0.0079 - val_loss: 0.0107
 - val_f1: 0.9939
Epoch 153/200
 - 0s - loss: 0.0078 - val_loss: 0.0112
 - val_f1: 0.9931
Epoch 154/200
 - 0s - loss: 0.0077 - val_loss: 0.0105
 - val_f1: 0.9942
Epoch 155/200
 - 0s - loss: 0.0075 - val_loss: 0.0105
 - val_f1: 0.9937
Epoch 156/200
 - 0s - loss: 0.0077 - val_loss: 0.0104
 - val_f1: 0.9942
Epoch 157/200
 - 0s - loss: 0.0076 - val_loss: 0.0107
 - val_f1: 0.9937
Epoch 158/200
 - 0s - loss: 0.0078 - val_loss: 0.0106
 - val_f1: 0.9941
Epoch 159/200
 - 0s - loss: 0.0074 - val_loss: 0.0105
 - val_f1: 0.9936
Epoch 160/200
 - 0s - loss: 0.0076 - val_loss: 0.0101
 - val_f1: 0.9945
Epoch 161/200
 - 0s - loss: 0.0072 - val_loss: 0.0113
2019-12-21 10:44:37,777 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9922
Epoch 162/200
 - 0s - loss: 0.0077 - val_loss: 0.0102
 - val_f1: 0.9945
Epoch 163/200
 - 0s - loss: 0.0072 - val_loss: 0.0103
 - val_f1: 0.9941
Epoch 164/200
 - 0s - loss: 0.0074 - val_loss: 0.0104
 - val_f1: 0.9938
Epoch 165/200
 - 0s - loss: 0.0077 - val_loss: 0.0105
 - val_f1: 0.9941
Epoch 166/200
 - 0s - loss: 0.0074 - val_loss: 0.0104
 - val_f1: 0.9941
Epoch 167/200
 - 0s - loss: 0.0079 - val_loss: 0.0104
 - val_f1: 0.9936
Epoch 168/200
 - 0s - loss: 0.0073 - val_loss: 0.0103
 - val_f1: 0.9939
Epoch 169/200
 - 0s - loss: 0.0072 - val_loss: 0.0104
 - val_f1: 0.9940
Epoch 170/200
 - 0s - loss: 0.0070 - val_loss: 0.0107
 - val_f1: 0.9937
Epoch 171/200
 - 0s - loss: 0.0072 - val_loss: 0.0106
 - val_f1: 0.9937
Epoch 172/200
 - 0s - loss: 0.0076 - val_loss: 0.0106
 - val_f1: 0.9936
Epoch 173/200
 - 0s - loss: 0.0073 - val_loss: 0.0102
 - val_f1: 0.9940
Epoch 174/200
 - 0s - loss: 0.0074 - val_loss: 0.0107
 - val_f1: 0.9938
Epoch 175/200
 - 0s - loss: 0.0075 - val_loss: 0.0104
 - val_f1: 0.9941
Epoch 176/200
 - 0s - loss: 0.0077 - val_loss: 0.0108
 - val_f1: 0.9937
Epoch 177/200
 - 0s - loss: 0.0068 - val_loss: 0.0108
 - val_f1: 0.9941
Epoch 178/200
 - 0s - loss: 0.0076 - val_loss: 0.0104
2019-12-21 10:44:45,867 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:44:46,679 [INFO] Last epoch loss evaluation: train_loss = 0.004594, val_loss = 0.009678
2019-12-21 10:44:46,682 [INFO] Training complete. time_to_train = 227.37 sec, 3.79 min
2019-12-21 10:44:46,691 [INFO] Model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep1/best_model.pickle
2019-12-21 10:44:46,886 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep1/training_error_history.png
2019-12-21 10:44:47,064 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep1/training_f1_history.png
2019-12-21 10:44:47,064 [INFO] Making predictions on training, validation, testing data
2019-12-21 10:44:49,421 [INFO] Evaluating predictions (results)
2019-12-21 10:44:49,807 [INFO] Dataset: Testing. Classification report below
2019-12-21 10:44:49,807 [INFO] 
              precision    recall  f1-score   support

         dos       0.93      0.82      0.87      7458
      normal       0.68      0.93      0.78      9711
       probe       0.75      0.69      0.72      2421
         r2l       0.90      0.12      0.21      2421
         u2r       0.27      0.01      0.01       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.70      0.51      0.52     22544
weighted avg       0.78      0.76      0.72     22544

2019-12-21 10:44:49,807 [INFO] Overall accuracy (micro avg): 0.7589602555003548
2019-12-21 10:44:50,106 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7590         0.7590                       0.7590                0.0603                   0.2410  0.7590
1     Macro avg        0.9036         0.7031                       0.5125                0.0802                   0.4875  0.5185
2  Weighted avg        0.8602         0.7804                       0.7590                0.1599                   0.2410  0.7247
2019-12-21 10:44:50,442 [INFO] Dataset: Validation. Classification report below
2019-12-21 10:44:50,442 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.98      0.99      2331
         r2l       0.93      0.83      0.88       199
         u2r       1.00      0.50      0.67        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.98      0.86      0.90     25195
weighted avg       0.99      0.99      0.99     25195

2019-12-21 10:44:50,442 [INFO] Overall accuracy (micro avg): 0.9947608652510419
2019-12-21 10:44:50,796 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0013                   0.0052  0.9948
1     Macro avg        0.9979         0.9816                       0.8616                0.0018                   0.1384  0.9044
2  Weighted avg        0.9969         0.9947                       0.9948                0.0037                   0.0052  0.9947
2019-12-21 10:44:52,233 [INFO] Dataset: Training. Classification report below
2019-12-21 10:44:52,233 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.91      0.81      0.86       796
         u2r       0.73      0.52      0.61        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.93      0.86      0.89    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-21 10:44:52,233 [INFO] Overall accuracy (micro avg): 0.9953065153108813
2019-12-21 10:44:53,848 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0012                   0.0047  0.9953
1     Macro avg        0.9981         0.9263                       0.8638                0.0017                   0.1362  0.8910
2  Weighted avg        0.9972         0.9952                       0.9953                0.0037                   0.0047  0.9952
2019-12-21 10:44:53,886 [INFO] Results saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep1/selected_nsl_ae_ann_shallow_rep1_results.xlsx
2019-12-21 10:44:53,887 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-21 10:44:53,890 [INFO] Created directory: results_selected_models/selected_nsl_ae_ann_shallow_rep2
2019-12-21 10:44:53,890 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ae_ann_shallow_rep2/run_log.log
2019-12-21 10:44:53,890 [INFO] ================= Running experiment no. 2  ================= 

2019-12-21 10:44:53,890 [INFO] Experiment parameters given below
2019-12-21 10:44:53,890 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_nsl_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ae_ann_shallow_rep2'}
2019-12-21 10:44:53,891 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ae_ann_shallow_rep2/tf_logs_run_2019_12_21-10_44_53
2019-12-21 10:44:53,891 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-21 10:44:53,891 [INFO] Reading X, y files
2019-12-21 10:44:53,891 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-21 10:44:54,136 [INFO] Reading complete. time_to_read=0.24 seconds
2019-12-21 10:44:54,136 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-21 10:44:54,200 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:44:54,200 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-21 10:44:54,259 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:44:54,259 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-21 10:44:54,266 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:44:54,266 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-21 10:44:54,270 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:44:54,270 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-21 10:44:54,273 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:44:54,459 [INFO] Initializing model
2019-12-21 10:44:54,564 [INFO] _________________________________________________________________
2019-12-21 10:44:54,564 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:44:54,564 [INFO] =================================================================
2019-12-21 10:44:54,565 [INFO] dense_5 (Dense)              (None, 32)                3936      
2019-12-21 10:44:54,565 [INFO] _________________________________________________________________
2019-12-21 10:44:54,565 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-21 10:44:54,565 [INFO] _________________________________________________________________
2019-12-21 10:44:54,565 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-21 10:44:54,565 [INFO] _________________________________________________________________
2019-12-21 10:44:54,565 [INFO] dense_6 (Dense)              (None, 122)               4026      
2019-12-21 10:44:54,565 [INFO] =================================================================
2019-12-21 10:44:54,565 [INFO] Total params: 8,090
2019-12-21 10:44:54,565 [INFO] Trainable params: 8,026
2019-12-21 10:44:54,565 [INFO] Non-trainable params: 64
2019-12-21 10:44:54,565 [INFO] _________________________________________________________________
2019-12-21 10:44:54,670 [INFO] _________________________________________________________________
2019-12-21 10:44:54,670 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:44:54,670 [INFO] =================================================================
2019-12-21 10:44:54,670 [INFO] dense_7 (Dense)              (None, 32)                1056      
2019-12-21 10:44:54,670 [INFO] _________________________________________________________________
2019-12-21 10:44:54,670 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-21 10:44:54,670 [INFO] _________________________________________________________________
2019-12-21 10:44:54,670 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-21 10:44:54,670 [INFO] _________________________________________________________________
2019-12-21 10:44:54,670 [INFO] dense_8 (Dense)              (None, 5)                 165       
2019-12-21 10:44:54,670 [INFO] =================================================================
2019-12-21 10:44:54,671 [INFO] Total params: 1,349
2019-12-21 10:44:54,671 [INFO] Trainable params: 1,285
2019-12-21 10:44:54,671 [INFO] Non-trainable params: 64
2019-12-21 10:44:54,671 [INFO] _________________________________________________________________
2019-12-21 10:44:54,671 [INFO] Training model
2019-12-21 10:44:54,671 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 10:44:55,276 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389
2019-12-21 10:44:55,276 [INFO] Training autoencoder
 - val_f1: 0.9943
Epoch 00178: early stopping
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3236 - val_loss: -2.1386e-01
Epoch 2/200
 - 1s - loss: -6.8495e-01 - val_loss: -1.2833e+00
Epoch 3/200
 - 1s - loss: -1.5862e+00 - val_loss: -2.0268e+00
Epoch 4/200
 - 1s - loss: -2.2006e+00 - val_loss: -2.5381e+00
Epoch 5/200
 - 1s - loss: -2.5711e+00 - val_loss: -2.8245e+00
Epoch 6/200
 - 1s - loss: -2.7702e+00 - val_loss: -2.9709e+00
Epoch 7/200
 - 1s - loss: -2.8804e+00 - val_loss: -3.0449e+00
Epoch 8/200
 - 1s - loss: -2.9491e+00 - val_loss: -3.0902e+00
Epoch 9/200
 - 1s - loss: -2.9857e+00 - val_loss: -3.1176e+00
Epoch 10/200
 - 1s - loss: -3.0170e+00 - val_loss: -3.1368e+00
Epoch 11/200
 - 1s - loss: -3.0421e+00 - val_loss: -3.1508e+00
Epoch 12/200
 - 1s - loss: -3.0592e+00 - val_loss: -3.1612e+00
Epoch 13/200
 - 1s - loss: -3.0700e+00 - val_loss: -3.1697e+00
Epoch 14/200
 - 1s - loss: -3.0832e+00 - val_loss: -3.1757e+00
Epoch 15/200
 - 1s - loss: -3.0940e+00 - val_loss: -3.1803e+00
Epoch 16/200
 - 1s - loss: -3.1038e+00 - val_loss: -3.1846e+00
Epoch 17/200
 - 1s - loss: -3.1074e+00 - val_loss: -3.1882e+00
Epoch 18/200
 - 1s - loss: -3.1153e+00 - val_loss: -3.1911e+00
Epoch 19/200
 - 1s - loss: -3.1193e+00 - val_loss: -3.1933e+00
Epoch 20/200
 - 1s - loss: -3.1241e+00 - val_loss: -3.1954e+00
Epoch 21/200
 - 1s - loss: -3.1294e+00 - val_loss: -3.1970e+00
2019-12-21 10:45:11,231 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_20.pickle
Epoch 22/200
 - 1s - loss: -3.1329e+00 - val_loss: -3.1989e+00
Epoch 23/200
 - 1s - loss: -3.1378e+00 - val_loss: -3.2007e+00
Epoch 24/200
 - 1s - loss: -3.1385e+00 - val_loss: -3.2019e+00
Epoch 25/200
 - 1s - loss: -3.1419e+00 - val_loss: -3.2023e+00
Epoch 26/200
 - 1s - loss: -3.1443e+00 - val_loss: -3.2034e+00
Epoch 27/200
 - 1s - loss: -3.1457e+00 - val_loss: -3.2043e+00
Epoch 28/200
 - 1s - loss: -3.1499e+00 - val_loss: -3.2056e+00
Epoch 29/200
 - 1s - loss: -3.1508e+00 - val_loss: -3.2069e+00
Epoch 30/200
 - 1s - loss: -3.1536e+00 - val_loss: -3.2074e+00
Epoch 31/200
 - 1s - loss: -3.1545e+00 - val_loss: -3.2079e+00
Epoch 32/200
 - 1s - loss: -3.1562e+00 - val_loss: -3.2084e+00
Epoch 33/200
 - 1s - loss: -3.1590e+00 - val_loss: -3.2083e+00
Epoch 34/200
 - 1s - loss: -3.1591e+00 - val_loss: -3.2089e+00
Epoch 35/200
 - 1s - loss: -3.1598e+00 - val_loss: -3.2100e+00
Epoch 36/200
 - 1s - loss: -3.1603e+00 - val_loss: -3.2099e+00
Epoch 37/200
 - 1s - loss: -3.1623e+00 - val_loss: -3.2101e+00
Epoch 38/200
 - 1s - loss: -3.1639e+00 - val_loss: -3.2113e+00
Epoch 39/200
 - 1s - loss: -3.1643e+00 - val_loss: -3.2113e+00
Epoch 40/200
 - 1s - loss: -3.1655e+00 - val_loss: -3.2113e+00
Epoch 41/200
 - 1s - loss: -3.1670e+00 - val_loss: -3.2112e+00
2019-12-21 10:45:25,150 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_40.pickle
Epoch 42/200
 - 1s - loss: -3.1676e+00 - val_loss: -3.2122e+00
Epoch 43/200
 - 1s - loss: -3.1680e+00 - val_loss: -3.2118e+00
Epoch 44/200
 - 1s - loss: -3.1690e+00 - val_loss: -3.2126e+00
Epoch 45/200
 - 1s - loss: -3.1710e+00 - val_loss: -3.2131e+00
Epoch 46/200
 - 1s - loss: -3.1720e+00 - val_loss: -3.2133e+00
Epoch 47/200
 - 1s - loss: -3.1722e+00 - val_loss: -3.2131e+00
Epoch 48/200
 - 1s - loss: -3.1713e+00 - val_loss: -3.2140e+00
Epoch 49/200
 - 1s - loss: -3.1721e+00 - val_loss: -3.2136e+00
Epoch 50/200
 - 1s - loss: -3.1729e+00 - val_loss: -3.2142e+00
Epoch 51/200
 - 1s - loss: -3.1754e+00 - val_loss: -3.2147e+00
Epoch 52/200
 - 1s - loss: -3.1743e+00 - val_loss: -3.2146e+00
Epoch 53/200
 - 1s - loss: -3.1748e+00 - val_loss: -3.2151e+00
Epoch 54/200
 - 1s - loss: -3.1751e+00 - val_loss: -3.2146e+00
Epoch 55/200
 - 1s - loss: -3.1762e+00 - val_loss: -3.2147e+00
Epoch 56/200
 - 1s - loss: -3.1759e+00 - val_loss: -3.2150e+00
Epoch 57/200
 - 1s - loss: -3.1756e+00 - val_loss: -3.2158e+00
Epoch 58/200
 - 1s - loss: -3.1776e+00 - val_loss: -3.2158e+00
Epoch 59/200
 - 1s - loss: -3.1780e+00 - val_loss: -3.2155e+00
Epoch 60/200
 - 1s - loss: -3.1790e+00 - val_loss: -3.2162e+00
Epoch 61/200
 - 1s - loss: -3.1779e+00 - val_loss: -3.2163e+00
2019-12-21 10:45:39,054 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_60.pickle
Epoch 62/200
 - 1s - loss: -3.1799e+00 - val_loss: -3.2159e+00
Epoch 63/200
 - 1s - loss: -3.1787e+00 - val_loss: -3.2169e+00
Epoch 64/200
 - 1s - loss: -3.1791e+00 - val_loss: -3.2166e+00
Epoch 65/200
 - 1s - loss: -3.1793e+00 - val_loss: -3.2163e+00
Epoch 66/200
 - 1s - loss: -3.1793e+00 - val_loss: -3.2168e+00
Epoch 67/200
 - 1s - loss: -3.1805e+00 - val_loss: -3.2167e+00
Epoch 68/200
 - 1s - loss: -3.1818e+00 - val_loss: -3.2168e+00
Epoch 69/200
 - 1s - loss: -3.1808e+00 - val_loss: -3.2174e+00
Epoch 70/200
 - 1s - loss: -3.1814e+00 - val_loss: -3.2170e+00
Epoch 71/200
 - 1s - loss: -3.1815e+00 - val_loss: -3.2173e+00
Epoch 72/200
 - 1s - loss: -3.1824e+00 - val_loss: -3.2168e+00
Epoch 73/200
 - 1s - loss: -3.1802e+00 - val_loss: -3.2172e+00
Epoch 74/200
 - 1s - loss: -3.1808e+00 - val_loss: -3.2178e+00
Epoch 75/200
 - 1s - loss: -3.1833e+00 - val_loss: -3.2179e+00
Epoch 76/200
 - 1s - loss: -3.1826e+00 - val_loss: -3.2177e+00
Epoch 77/200
 - 1s - loss: -3.1839e+00 - val_loss: -3.2179e+00
Epoch 78/200
 - 1s - loss: -3.1845e+00 - val_loss: -3.2182e+00
Epoch 79/200
 - 1s - loss: -3.1838e+00 - val_loss: -3.2180e+00
Epoch 80/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2179e+00
Epoch 81/200
 - 1s - loss: -3.1845e+00 - val_loss: -3.2179e+00
2019-12-21 10:45:52,948 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_80.pickle
Epoch 82/200
 - 1s - loss: -3.1850e+00 - val_loss: -3.2177e+00
Epoch 83/200
 - 1s - loss: -3.1840e+00 - val_loss: -3.2179e+00
Epoch 84/200
 - 1s - loss: -3.1836e+00 - val_loss: -3.2181e+00
Epoch 85/200
 - 1s - loss: -3.1861e+00 - val_loss: -3.2183e+00
Epoch 86/200
 - 1s - loss: -3.1848e+00 - val_loss: -3.2179e+00
Epoch 87/200
 - 1s - loss: -3.1858e+00 - val_loss: -3.2179e+00
Epoch 88/200
 - 1s - loss: -3.1858e+00 - val_loss: -3.2183e+00
Epoch 89/200
 - 1s - loss: -3.1872e+00 - val_loss: -3.2184e+00
Epoch 90/200
 - 1s - loss: -3.1860e+00 - val_loss: -3.2190e+00
Epoch 91/200
 - 1s - loss: -3.1869e+00 - val_loss: -3.2189e+00
Epoch 92/200
 - 1s - loss: -3.1875e+00 - val_loss: -3.2192e+00
Epoch 93/200
 - 1s - loss: -3.1885e+00 - val_loss: -3.2191e+00
Epoch 94/200
 - 1s - loss: -3.1865e+00 - val_loss: -3.2190e+00
Epoch 95/200
 - 1s - loss: -3.1866e+00 - val_loss: -3.2190e+00
Epoch 96/200
 - 1s - loss: -3.1873e+00 - val_loss: -3.2191e+00
Epoch 97/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2187e+00
Epoch 98/200
 - 1s - loss: -3.1875e+00 - val_loss: -3.2198e+00
Epoch 99/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2192e+00
Epoch 100/200
 - 1s - loss: -3.1859e+00 - val_loss: -3.2192e+00
Epoch 101/200
 - 1s - loss: -3.1877e+00 - val_loss: -3.2193e+00
2019-12-21 10:46:06,866 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_100.pickle
Epoch 102/200
 - 1s - loss: -3.1888e+00 - val_loss: -3.2192e+00
Epoch 103/200
 - 1s - loss: -3.1876e+00 - val_loss: -3.2196e+00
Epoch 104/200
 - 1s - loss: -3.1878e+00 - val_loss: -3.2198e+00
Epoch 105/200
 - 1s - loss: -3.1890e+00 - val_loss: -3.2199e+00
Epoch 106/200
 - 1s - loss: -3.1902e+00 - val_loss: -3.2199e+00
Epoch 107/200
 - 1s - loss: -3.1906e+00 - val_loss: -3.2197e+00
Epoch 108/200
 - 1s - loss: -3.1899e+00 - val_loss: -3.2196e+00
Epoch 109/200
 - 1s - loss: -3.1895e+00 - val_loss: -3.2195e+00
Epoch 110/200
 - 1s - loss: -3.1892e+00 - val_loss: -3.2198e+00
Epoch 111/200
 - 1s - loss: -3.1886e+00 - val_loss: -3.2196e+00
Epoch 112/200
 - 1s - loss: -3.1891e+00 - val_loss: -3.2198e+00
Epoch 113/200
 - 1s - loss: -3.1895e+00 - val_loss: -3.2196e+00
Epoch 114/200
 - 1s - loss: -3.1904e+00 - val_loss: -3.2203e+00
Epoch 115/200
 - 1s - loss: -3.1895e+00 - val_loss: -3.2208e+00
Epoch 116/200
 - 1s - loss: -3.1890e+00 - val_loss: -3.2205e+00
Epoch 117/200
 - 1s - loss: -3.1901e+00 - val_loss: -3.2203e+00
Epoch 118/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2200e+00
Epoch 119/200
 - 1s - loss: -3.1900e+00 - val_loss: -3.2201e+00
Epoch 120/200
 - 1s - loss: -3.1914e+00 - val_loss: -3.2202e+00
Epoch 121/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2205e+00
2019-12-21 10:46:20,758 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_120.pickle
Epoch 122/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2207e+00
Epoch 123/200
 - 1s - loss: -3.1910e+00 - val_loss: -3.2204e+00
Epoch 124/200
 - 1s - loss: -3.1915e+00 - val_loss: -3.2206e+00
Epoch 125/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2208e+00
Epoch 126/200
 - 1s - loss: -3.1914e+00 - val_loss: -3.2199e+00
Epoch 127/200
 - 1s - loss: -3.1920e+00 - val_loss: -3.2203e+00
Epoch 128/200
 - 1s - loss: -3.1911e+00 - val_loss: -3.2207e+00
Epoch 129/200
 - 1s - loss: -3.1915e+00 - val_loss: -3.2209e+00
Epoch 130/200
 - 1s - loss: -3.1930e+00 - val_loss: -3.2206e+00
Epoch 131/200
 - 1s - loss: -3.1919e+00 - val_loss: -3.2211e+00
Epoch 132/200
 - 1s - loss: -3.1921e+00 - val_loss: -3.2211e+00
Epoch 133/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2206e+00
Epoch 134/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2208e+00
Epoch 135/200
 - 1s - loss: -3.1921e+00 - val_loss: -3.2212e+00
Epoch 136/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2211e+00
Epoch 137/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2215e+00
Epoch 138/200
 - 1s - loss: -3.1935e+00 - val_loss: -3.2212e+00
Epoch 139/200
 - 1s - loss: -3.1951e+00 - val_loss: -3.2215e+00
Epoch 140/200
 - 1s - loss: -3.1931e+00 - val_loss: -3.2214e+00
Epoch 141/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2214e+00
2019-12-21 10:46:34,753 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_140.pickle
Epoch 142/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2213e+00
Epoch 143/200
 - 1s - loss: -3.1931e+00 - val_loss: -3.2217e+00
Epoch 144/200
 - 1s - loss: -3.1951e+00 - val_loss: -3.2216e+00
Epoch 145/200
 - 1s - loss: -3.1943e+00 - val_loss: -3.2214e+00
Epoch 146/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2218e+00
Epoch 147/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2215e+00
Epoch 148/200
 - 1s - loss: -3.1942e+00 - val_loss: -3.2216e+00
Epoch 149/200
 - 1s - loss: -3.1942e+00 - val_loss: -3.2213e+00
Epoch 150/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2215e+00
Epoch 151/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2217e+00
Epoch 152/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2220e+00
Epoch 153/200
 - 1s - loss: -3.1943e+00 - val_loss: -3.2217e+00
Epoch 154/200
 - 1s - loss: -3.1939e+00 - val_loss: -3.2218e+00
Epoch 155/200
 - 1s - loss: -3.1956e+00 - val_loss: -3.2220e+00
Epoch 156/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2218e+00
Epoch 157/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2221e+00
Epoch 158/200
 - 1s - loss: -3.1952e+00 - val_loss: -3.2223e+00
Epoch 159/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2220e+00
Epoch 160/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2221e+00
Epoch 161/200
 - 1s - loss: -3.1940e+00 - val_loss: -3.2221e+00
2019-12-21 10:46:48,668 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_160.pickle
Epoch 162/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2219e+00
Epoch 163/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2221e+00
Epoch 164/200
 - 1s - loss: -3.1956e+00 - val_loss: -3.2222e+00
Epoch 165/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2226e+00
Epoch 166/200
 - 1s - loss: -3.1967e+00 - val_loss: -3.2220e+00
Epoch 167/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2220e+00
Epoch 168/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2221e+00
Epoch 169/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2223e+00
Epoch 170/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2225e+00
Epoch 171/200
 - 1s - loss: -3.1971e+00 - val_loss: -3.2222e+00
Epoch 172/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2228e+00
Epoch 173/200
 - 1s - loss: -3.1961e+00 - val_loss: -3.2224e+00
Epoch 174/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2223e+00
Epoch 175/200
 - 1s - loss: -3.1967e+00 - val_loss: -3.2220e+00
Epoch 176/200
 - 1s - loss: -3.1969e+00 - val_loss: -3.2222e+00
Epoch 177/200
 - 1s - loss: -3.1964e+00 - val_loss: -3.2221e+00
Epoch 178/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2229e+00
Epoch 179/200
 - 1s - loss: -3.1967e+00 - val_loss: -3.2229e+00
Epoch 180/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2228e+00
Epoch 181/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2223e+00
2019-12-21 10:47:02,624 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ae_model_epoch_180.pickle
Epoch 182/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2220e+00
Epoch 183/200
 - 1s - loss: -3.1973e+00 - val_loss: -3.2226e+00
Epoch 184/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2230e+00
Epoch 185/200
 - 1s - loss: -3.1971e+00 - val_loss: -3.2227e+00
Epoch 186/200
 - 1s - loss: -3.1977e+00 - val_loss: -3.2228e+00
Epoch 187/200
 - 1s - loss: -3.1960e+00 - val_loss: -3.2231e+00
Epoch 188/200
 - 1s - loss: -3.1976e+00 - val_loss: -3.2227e+00
Epoch 189/200
 - 1s - loss: -3.1982e+00 - val_loss: -3.2229e+00
Epoch 190/200
 - 1s - loss: -3.1974e+00 - val_loss: -3.2224e+00
Epoch 191/200
 - 1s - loss: -3.1976e+00 - val_loss: -3.2224e+00
Epoch 192/200
 - 1s - loss: -3.1971e+00 - val_loss: -3.2228e+00
Epoch 193/200
 - 1s - loss: -3.1971e+00 - val_loss: -3.2228e+00
Epoch 194/200
 - 1s - loss: -3.1975e+00 - val_loss: -3.2232e+00
Epoch 195/200
 - 1s - loss: -3.1989e+00 - val_loss: -3.2229e+00
Epoch 196/200
 - 1s - loss: -3.1977e+00 - val_loss: -3.2230e+00
Epoch 197/200
 - 1s - loss: -3.1972e+00 - val_loss: -3.2229e+00
Epoch 198/200
 - 1s - loss: -3.1974e+00 - val_loss: -3.2229e+00
Epoch 199/200
 - 1s - loss: -3.1980e+00 - val_loss: -3.2230e+00
Epoch 200/200
 - 1s - loss: -3.1988e+00 - val_loss: -3.2227e+00
2019-12-21 10:47:15,896 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:47:17,022 [INFO] Last epoch loss evaluation: train_loss = -3.249095, val_loss = -3.223242
2019-12-21 10:47:17,022 [INFO] Training autoencoder complete
2019-12-21 10:47:17,022 [INFO] Encoding data for supervised training
2019-12-21 10:47:17,844 [INFO] Encoding complete
2019-12-21 10:47:17,845 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 0s - loss: 0.1910 - val_loss: 0.0599
 - val_f1: 0.9648
Epoch 2/200
 - 0s - loss: 0.0584 - val_loss: 0.0391
 - val_f1: 0.9708
Epoch 3/200
 - 0s - loss: 0.0430 - val_loss: 0.0298
 - val_f1: 0.9750
Epoch 4/200
 - 0s - loss: 0.0355 - val_loss: 0.0248
 - val_f1: 0.9792
Epoch 5/200
 - 0s - loss: 0.0300 - val_loss: 0.0213
 - val_f1: 0.9830
Epoch 6/200
 - 0s - loss: 0.0270 - val_loss: 0.0189
 - val_f1: 0.9853
Epoch 7/200
 - 0s - loss: 0.0237 - val_loss: 0.0170
 - val_f1: 0.9861
Epoch 8/200
 - 0s - loss: 0.0221 - val_loss: 0.0154
 - val_f1: 0.9890
Epoch 9/200
 - 0s - loss: 0.0208 - val_loss: 0.0148
 - val_f1: 0.9886
Epoch 10/200
 - 0s - loss: 0.0199 - val_loss: 0.0148
 - val_f1: 0.9893
Epoch 11/200
 - 0s - loss: 0.0188 - val_loss: 0.0137
 - val_f1: 0.9894
Epoch 12/200
 - 0s - loss: 0.0177 - val_loss: 0.0130
 - val_f1: 0.9912
Epoch 13/200
 - 0s - loss: 0.0174 - val_loss: 0.0128
 - val_f1: 0.9908
Epoch 14/200
 - 0s - loss: 0.0165 - val_loss: 0.0124
 - val_f1: 0.9912
Epoch 15/200
 - 0s - loss: 0.0166 - val_loss: 0.0122
 - val_f1: 0.9901
Epoch 16/200
 - 0s - loss: 0.0157 - val_loss: 0.0122
 - val_f1: 0.9901
Epoch 17/200
 - 0s - loss: 0.0152 - val_loss: 0.0118
 - val_f1: 0.9920
Epoch 18/200
 - 0s - loss: 0.0151 - val_loss: 0.0118
 - val_f1: 0.9921
Epoch 19/200
 - 0s - loss: 0.0149 - val_loss: 0.0118
 - val_f1: 0.9912
Epoch 20/200
 - 0s - loss: 0.0146 - val_loss: 0.0114
 - val_f1: 0.9913
Epoch 21/200
 - 0s - loss: 0.0141 - val_loss: 0.0117
2019-12-21 10:47:29,553 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9918
Epoch 22/200
 - 0s - loss: 0.0142 - val_loss: 0.0117
 - val_f1: 0.9904
Epoch 23/200
 - 0s - loss: 0.0143 - val_loss: 0.0112
 - val_f1: 0.9919
Epoch 24/200
 - 0s - loss: 0.0143 - val_loss: 0.0113
 - val_f1: 0.9918
Epoch 25/200
 - 0s - loss: 0.0140 - val_loss: 0.0112
 - val_f1: 0.9921
Epoch 26/200
 - 0s - loss: 0.0139 - val_loss: 0.0109
 - val_f1: 0.9924
Epoch 27/200
 - 0s - loss: 0.0131 - val_loss: 0.0109
 - val_f1: 0.9923
Epoch 28/200
 - 0s - loss: 0.0140 - val_loss: 0.0111
 - val_f1: 0.9922
Epoch 29/200
 - 0s - loss: 0.0133 - val_loss: 0.0107
 - val_f1: 0.9925
Epoch 30/200
 - 0s - loss: 0.0135 - val_loss: 0.0105
 - val_f1: 0.9920
Epoch 31/200
 - 0s - loss: 0.0128 - val_loss: 0.0105
 - val_f1: 0.9927
Epoch 32/200
 - 0s - loss: 0.0129 - val_loss: 0.0104
 - val_f1: 0.9927
Epoch 33/200
 - 0s - loss: 0.0125 - val_loss: 0.0109
 - val_f1: 0.9909
Epoch 34/200
 - 0s - loss: 0.0118 - val_loss: 0.0102
 - val_f1: 0.9929
Epoch 35/200
 - 0s - loss: 0.0121 - val_loss: 0.0101
 - val_f1: 0.9931
Epoch 36/200
 - 0s - loss: 0.0124 - val_loss: 0.0101
 - val_f1: 0.9931
Epoch 37/200
 - 0s - loss: 0.0120 - val_loss: 0.0100
 - val_f1: 0.9924
Epoch 38/200
 - 0s - loss: 0.0118 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 39/200
 - 0s - loss: 0.0118 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 40/200
 - 0s - loss: 0.0113 - val_loss: 0.0101
 - val_f1: 0.9922
Epoch 41/200
 - 0s - loss: 0.0124 - val_loss: 0.0097
2019-12-21 10:47:39,679 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9926
Epoch 42/200
 - 0s - loss: 0.0119 - val_loss: 0.0099
 - val_f1: 0.9930
Epoch 43/200
 - 0s - loss: 0.0112 - val_loss: 0.0104
 - val_f1: 0.9915
Epoch 44/200
 - 0s - loss: 0.0114 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 45/200
 - 0s - loss: 0.0115 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 46/200
 - 0s - loss: 0.0118 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 47/200
 - 0s - loss: 0.0112 - val_loss: 0.0103
 - val_f1: 0.9930
Epoch 48/200
 - 0s - loss: 0.0111 - val_loss: 0.0099
 - val_f1: 0.9929
Epoch 49/200
 - 0s - loss: 0.0114 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 50/200
 - 0s - loss: 0.0108 - val_loss: 0.0102
 - val_f1: 0.9920
Epoch 51/200
 - 0s - loss: 0.0107 - val_loss: 0.0102
 - val_f1: 0.9924
Epoch 52/200
 - 0s - loss: 0.0108 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 53/200
 - 0s - loss: 0.0111 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 54/200
 - 0s - loss: 0.0107 - val_loss: 0.0095
 - val_f1: 0.9930
Epoch 55/200
 - 0s - loss: 0.0109 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 56/200
 - 0s - loss: 0.0112 - val_loss: 0.0098
 - val_f1: 0.9932
Epoch 57/200
 - 0s - loss: 0.0106 - val_loss: 0.0099
 - val_f1: 0.9922
Epoch 58/200
 - 0s - loss: 0.0107 - val_loss: 0.0104
 - val_f1: 0.9919
Epoch 59/200
 - 0s - loss: 0.0102 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 60/200
 - 0s - loss: 0.0106 - val_loss: 0.0097
 - val_f1: 0.9927
Epoch 61/200
 - 0s - loss: 0.0109 - val_loss: 0.0099
2019-12-21 10:47:49,802 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9931
Epoch 62/200
 - 0s - loss: 0.0104 - val_loss: 0.0097
 - val_f1: 0.9939
Epoch 63/200
 - 0s - loss: 0.0104 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 64/200
 - 0s - loss: 0.0102 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 65/200
 - 0s - loss: 0.0103 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 66/200
 - 0s - loss: 0.0101 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 67/200
 - 0s - loss: 0.0102 - val_loss: 0.0096
 - val_f1: 0.9928
Epoch 68/200
 - 0s - loss: 0.0104 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 69/200
 - 0s - loss: 0.0103 - val_loss: 0.0099
 - val_f1: 0.9927
Epoch 70/200
 - 0s - loss: 0.0100 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 71/200
 - 0s - loss: 0.0103 - val_loss: 0.0099
 - val_f1: 0.9934
Epoch 72/200
 - 0s - loss: 0.0103 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 73/200
 - 0s - loss: 0.0099 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 74/200
 - 0s - loss: 0.0102 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 75/200
 - 0s - loss: 0.0100 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 76/200
 - 0s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 77/200
 - 0s - loss: 0.0099 - val_loss: 0.0098
 - val_f1: 0.9930
Epoch 78/200
 - 0s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 79/200
 - 0s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 80/200
 - 0s - loss: 0.0095 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 81/200
 - 0s - loss: 0.0098 - val_loss: 0.0094
2019-12-21 10:47:59,931 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9935
Epoch 82/200
 - 0s - loss: 0.0102 - val_loss: 0.0094
 - val_f1: 0.9940
Epoch 83/200
 - 0s - loss: 0.0094 - val_loss: 0.0102
 - val_f1: 0.9916
Epoch 84/200
 - 0s - loss: 0.0099 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 85/200
 - 0s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 86/200
 - 0s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 87/200
 - 0s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 88/200
 - 0s - loss: 0.0096 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 89/200
 - 0s - loss: 0.0098 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 90/200
 - 0s - loss: 0.0097 - val_loss: 0.0098
 - val_f1: 0.9932
Epoch 91/200
 - 0s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9932
Epoch 92/200
 - 0s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9943
Epoch 93/200
 - 0s - loss: 0.0099 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 94/200
 - 0s - loss: 0.0099 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 95/200
 - 0s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 96/200
 - 0s - loss: 0.0094 - val_loss: 0.0097
 - val_f1: 0.9937
Epoch 97/200
 - 0s - loss: 0.0096 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 98/200
 - 0s - loss: 0.0097 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 99/200
 - 0s - loss: 0.0096 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 100/200
 - 0s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9941
Epoch 101/200
 - 0s - loss: 0.0093 - val_loss: 0.0095
2019-12-21 10:48:10,033 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9934
Epoch 102/200
 - 0s - loss: 0.0096 - val_loss: 0.0093
 - val_f1: 0.9941
Epoch 103/200
 - 0s - loss: 0.0092 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 104/200
 - 0s - loss: 0.0090 - val_loss: 0.0094
 - val_f1: 0.9934
Epoch 105/200
 - 0s - loss: 0.0090 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 106/200
 - 0s - loss: 0.0096 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 107/200
 - 0s - loss: 0.0092 - val_loss: 0.0110
 - val_f1: 0.9924
Epoch 108/200
 - 0s - loss: 0.0098 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 109/200
 - 0s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 110/200
 - 0s - loss: 0.0091 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 111/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 112/200
 - 0s - loss: 0.0094 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 113/200
 - 0s - loss: 0.0093 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 114/200
 - 0s - loss: 0.0097 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 115/200
 - 0s - loss: 0.0090 - val_loss: 0.0095
 - val_f1: 0.9928
Epoch 116/200
 - 0s - loss: 0.0093 - val_loss: 0.0093
 - val_f1: 0.9931
Epoch 117/200
 - 0s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9940
Epoch 118/200
 - 0s - loss: 0.0092 - val_loss: 0.0093
 - val_f1: 0.9933
Epoch 119/200
 - 0s - loss: 0.0091 - val_loss: 0.0095
 - val_f1: 0.9940
Epoch 120/200
 - 0s - loss: 0.0090 - val_loss: 0.0101
 - val_f1: 0.9937
Epoch 121/200
 - 0s - loss: 0.0091 - val_loss: 0.0094
2019-12-21 10:48:20,169 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9939
Epoch 122/200
 - 0s - loss: 0.0090 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 123/200
 - 0s - loss: 0.0088 - val_loss: 0.0090
 - val_f1: 0.9941
Epoch 124/200
 - 0s - loss: 0.0093 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 125/200
 - 0s - loss: 0.0091 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 126/200
 - 0s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 127/200
 - 0s - loss: 0.0088 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 128/200
 - 0s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 129/200
 - 0s - loss: 0.0091 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 130/200
 - 0s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 131/200
 - 0s - loss: 0.0091 - val_loss: 0.0091
 - val_f1: 0.9947
Epoch 132/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9941
Epoch 133/200
 - 0s - loss: 0.0089 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 134/200
 - 0s - loss: 0.0087 - val_loss: 0.0094
 - val_f1: 0.9939
Epoch 135/200
 - 0s - loss: 0.0092 - val_loss: 0.0100
 - val_f1: 0.9936
Epoch 136/200
 - 0s - loss: 0.0087 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 137/200
 - 0s - loss: 0.0091 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 138/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9940
Epoch 139/200
 - 0s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9942
Epoch 140/200
 - 0s - loss: 0.0088 - val_loss: 0.0095
 - val_f1: 0.9938
Epoch 141/200
 - 0s - loss: 0.0082 - val_loss: 0.0095
2019-12-21 10:48:30,219 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9937
Epoch 142/200
 - 0s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9938
Epoch 143/200
 - 0s - loss: 0.0086 - val_loss: 0.0089
 - val_f1: 0.9943
Epoch 144/200
 - 0s - loss: 0.0089 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 145/200
 - 0s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 146/200
 - 0s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 147/200
 - 0s - loss: 0.0084 - val_loss: 0.0095
 - val_f1: 0.9926
Epoch 148/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 149/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 150/200
 - 0s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9943
Epoch 151/200
 - 0s - loss: 0.0086 - val_loss: 0.0096
 - val_f1: 0.9927
Epoch 152/200
 - 0s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 153/200
 - 0s - loss: 0.0088 - val_loss: 0.0090
 - val_f1: 0.9946
Epoch 154/200
 - 0s - loss: 0.0086 - val_loss: 0.0099
 - val_f1: 0.9937
Epoch 155/200
 - 0s - loss: 0.0088 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 156/200
 - 0s - loss: 0.0089 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 157/200
 - 0s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9946
Epoch 158/200
 - 0s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9945
Epoch 159/200
 - 0s - loss: 0.0091 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 160/200
 - 0s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 161/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
2019-12-21 10:48:40,277 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9941
Epoch 162/200
 - 0s - loss: 0.0081 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 163/200
 - 0s - loss: 0.0085 - val_loss: 0.0092
 - val_f1: 0.9946
Epoch 164/200
 - 0s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9944
Epoch 165/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9941
Epoch 166/200
 - 0s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9941
Epoch 167/200
 - 0s - loss: 0.0079 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 168/200
 - 0s - loss: 0.0084 - val_loss: 0.0094
 - val_f1: 0.9944
Epoch 169/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 170/200
 - 0s - loss: 0.0081 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 171/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9948
Epoch 172/200
 - 0s - loss: 0.0081 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 173/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9941
Epoch 174/200
 - 0s - loss: 0.0087 - val_loss: 0.0089
 - val_f1: 0.9941
Epoch 175/200
 - 0s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9941
Epoch 176/200
 - 0s - loss: 0.0082 - val_loss: 0.0095
 - val_f1: 0.9930
Epoch 177/200
 - 0s - loss: 0.0088 - val_loss: 0.0092
 - val_f1: 0.9934
Epoch 178/200
 - 0s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9940
Epoch 179/200
 - 0s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 180/200
 - 0s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 181/200
 - 0s - loss: 0.0084 - val_loss: 0.0092
2019-12-21 10:48:50,465 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9940
Epoch 182/200
 - 0s - loss: 0.0088 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 183/200
 - 0s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9944
Epoch 184/200
 - 0s - loss: 0.0091 - val_loss: 0.0091
 - val_f1: 0.9942
Epoch 185/200
 - 0s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 186/200
 - 0s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 187/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9944
Epoch 188/200
 - 0s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9945
Epoch 189/200
 - 0s - loss: 0.0084 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 190/200
 - 0s - loss: 0.0084 - val_loss: 0.0094
 - val_f1: 0.9945
Epoch 191/200
 - 0s - loss: 0.0084 - val_loss: 0.0098
 - val_f1: 0.9923
Epoch 192/200
 - 0s - loss: 0.0089 - val_loss: 0.0091
 - val_f1: 0.9934
Epoch 193/200
 - 0s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 194/200
 - 0s - loss: 0.0082 - val_loss: 0.0090
 - val_f1: 0.9937
Epoch 195/200
 - 0s - loss: 0.0088 - val_loss: 0.0094
 - val_f1: 0.9933
Epoch 196/200
 - 0s - loss: 0.0083 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 197/200
 - 0s - loss: 0.0089 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 198/200
 - 0s - loss: 0.0081 - val_loss: 0.0088
 - val_f1: 0.9943
Epoch 199/200
 - 0s - loss: 0.0079 - val_loss: 0.0093
 - val_f1: 0.9937
Epoch 200/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
2019-12-21 10:49:00,419 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:49:01,358 [INFO] Last epoch loss evaluation: train_loss = 0.005339, val_loss = 0.008795
2019-12-21 10:49:01,362 [INFO] Training complete. time_to_train = 246.69 sec, 4.11 min
2019-12-21 10:49:01,369 [INFO] Model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep2/best_model.pickle
2019-12-21 10:49:01,562 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep2/training_error_history.png
2019-12-21 10:49:01,741 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep2/training_f1_history.png
2019-12-21 10:49:01,742 [INFO] Making predictions on training, validation, testing data
2019-12-21 10:49:04,494 [INFO] Evaluating predictions (results)
2019-12-21 10:49:04,755 [INFO] Dataset: Testing. Classification report below
2019-12-21 10:49:04,755 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.82      0.88      7458
      normal       0.68      0.93      0.78      9711
       probe       0.71      0.73      0.72      2421
         r2l       0.90      0.15      0.25      2421
         u2r       0.86      0.02      0.04       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.82      0.53      0.54     22544
weighted avg       0.80      0.77      0.74     22544

2019-12-21 10:49:04,755 [INFO] Overall accuracy (micro avg): 0.7661905606813343
2019-12-21 10:49:05,051 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7662         0.7662                       0.7662                0.0585                   0.2338  0.7662
1     Macro avg        0.9065         0.8215                       0.5303                0.0772                   0.4697  0.5374
2  Weighted avg        0.8650         0.8030                       0.7662                0.1521                   0.2338  0.7361
2019-12-21 10:49:05,382 [INFO] Dataset: Validation. Classification report below
2019-12-21 10:49:05,382 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.89      0.80      0.84       199
         u2r       1.00      0.30      0.46        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.97      0.82      0.86     25195
weighted avg       0.99      0.99      0.99     25195

2019-12-21 10:49:05,382 [INFO] Overall accuracy (micro avg): 0.9942051994443342
2019-12-21 10:49:05,737 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9942         0.9942                       0.9942                0.0014                   0.0058  0.9942
1     Macro avg        0.9977         0.9734                       0.8170                0.0019                   0.1830  0.8571
2  Weighted avg        0.9965         0.9941                       0.9942                0.0039                   0.0058  0.9941
2019-12-21 10:49:07,170 [INFO] Dataset: Training. Classification report below
2019-12-21 10:49:07,170 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.90      0.81      0.85       796
         u2r       0.72      0.50      0.59        42

   micro avg       0.99      0.99      0.99    100778
   macro avg       0.92      0.86      0.89    100778
weighted avg       0.99      0.99      0.99    100778

2019-12-21 10:49:07,170 [INFO] Overall accuracy (micro avg): 0.9946218420687055
2019-12-21 10:49:08,783 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0013                   0.0054  0.9946
1     Macro avg        0.9978         0.9220                       0.8574                0.0019                   0.1426  0.8850
2  Weighted avg        0.9967         0.9945                       0.9946                0.0039                   0.0054  0.9945
2019-12-21 10:49:08,821 [INFO] Results saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep2/selected_nsl_ae_ann_shallow_rep2_results.xlsx
2019-12-21 10:49:08,821 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-21 10:49:08,824 [INFO] Created directory: results_selected_models/selected_nsl_ae_ann_shallow_rep3
2019-12-21 10:49:08,824 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ae_ann_shallow_rep3/run_log.log
2019-12-21 10:49:08,824 [INFO] ================= Running experiment no. 3  ================= 

2019-12-21 10:49:08,824 [INFO] Experiment parameters given below
2019-12-21 10:49:08,824 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_nsl_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ae_ann_shallow_rep3'}
2019-12-21 10:49:08,824 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ae_ann_shallow_rep3/tf_logs_run_2019_12_21-10_49_08
2019-12-21 10:49:08,824 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-21 10:49:08,825 [INFO] Reading X, y files
2019-12-21 10:49:08,825 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-21 10:49:09,073 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-21 10:49:09,073 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-21 10:49:09,135 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:49:09,136 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-21 10:49:09,194 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:49:09,195 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-21 10:49:09,202 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:49:09,202 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-21 10:49:09,206 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:49:09,206 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-21 10:49:09,209 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:49:09,394 [INFO] Initializing model
2019-12-21 10:49:09,500 [INFO] _________________________________________________________________
2019-12-21 10:49:09,500 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:49:09,500 [INFO] =================================================================
2019-12-21 10:49:09,500 [INFO] dense_9 (Dense)              (None, 32)                3936      
2019-12-21 10:49:09,501 [INFO] _________________________________________________________________
2019-12-21 10:49:09,501 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-21 10:49:09,501 [INFO] _________________________________________________________________
2019-12-21 10:49:09,501 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-21 10:49:09,501 [INFO] _________________________________________________________________
2019-12-21 10:49:09,501 [INFO] dense_10 (Dense)             (None, 122)               4026      
2019-12-21 10:49:09,501 [INFO] =================================================================
2019-12-21 10:49:09,501 [INFO] Total params: 8,090
2019-12-21 10:49:09,501 [INFO] Trainable params: 8,026
2019-12-21 10:49:09,501 [INFO] Non-trainable params: 64
2019-12-21 10:49:09,501 [INFO] _________________________________________________________________
2019-12-21 10:49:09,609 [INFO] _________________________________________________________________
2019-12-21 10:49:09,609 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:49:09,609 [INFO] =================================================================
2019-12-21 10:49:09,609 [INFO] dense_11 (Dense)             (None, 32)                1056      
2019-12-21 10:49:09,609 [INFO] _________________________________________________________________
2019-12-21 10:49:09,609 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2019-12-21 10:49:09,609 [INFO] _________________________________________________________________
2019-12-21 10:49:09,609 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2019-12-21 10:49:09,610 [INFO] _________________________________________________________________
2019-12-21 10:49:09,610 [INFO] dense_12 (Dense)             (None, 5)                 165       
2019-12-21 10:49:09,610 [INFO] =================================================================
2019-12-21 10:49:09,610 [INFO] Total params: 1,349
2019-12-21 10:49:09,610 [INFO] Trainable params: 1,285
2019-12-21 10:49:09,610 [INFO] Non-trainable params: 64
2019-12-21 10:49:09,610 [INFO] _________________________________________________________________
2019-12-21 10:49:09,610 [INFO] Training model
2019-12-21 10:49:09,610 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 10:49:10,218 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389
2019-12-21 10:49:10,219 [INFO] Training autoencoder
 - val_f1: 0.9938
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3278 - val_loss: -2.7495e-01
Epoch 2/200
 - 1s - loss: -7.1320e-01 - val_loss: -1.3646e+00
Epoch 3/200
 - 1s - loss: -1.6370e+00 - val_loss: -2.0896e+00
Epoch 4/200
 - 1s - loss: -2.2735e+00 - val_loss: -2.6185e+00
Epoch 5/200
 - 1s - loss: -2.6277e+00 - val_loss: -2.8784e+00
Epoch 6/200
 - 1s - loss: -2.8099e+00 - val_loss: -3.0038e+00
Epoch 7/200
 - 1s - loss: -2.9062e+00 - val_loss: -3.0706e+00
Epoch 8/200
 - 1s - loss: -2.9649e+00 - val_loss: -3.1082e+00
Epoch 9/200
 - 1s - loss: -3.0030e+00 - val_loss: -3.1308e+00
Epoch 10/200
 - 1s - loss: -3.0310e+00 - val_loss: -3.1484e+00
Epoch 11/200
 - 1s - loss: -3.0521e+00 - val_loss: -3.1609e+00
Epoch 12/200
 - 1s - loss: -3.0672e+00 - val_loss: -3.1695e+00
Epoch 13/200
 - 1s - loss: -3.0808e+00 - val_loss: -3.1779e+00
Epoch 14/200
 - 1s - loss: -3.0922e+00 - val_loss: -3.1836e+00
Epoch 15/200
 - 1s - loss: -3.1002e+00 - val_loss: -3.1881e+00
Epoch 16/200
 - 1s - loss: -3.1093e+00 - val_loss: -3.1918e+00
Epoch 17/200
 - 1s - loss: -3.1146e+00 - val_loss: -3.1958e+00
Epoch 18/200
 - 1s - loss: -3.1233e+00 - val_loss: -3.1984e+00
Epoch 19/200
 - 1s - loss: -3.1256e+00 - val_loss: -3.2012e+00
Epoch 20/200
 - 1s - loss: -3.1303e+00 - val_loss: -3.2033e+00
Epoch 21/200
 - 1s - loss: -3.1326e+00 - val_loss: -3.2044e+00
2019-12-21 10:49:26,876 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_20.pickle
Epoch 22/200
 - 1s - loss: -3.1384e+00 - val_loss: -3.2060e+00
Epoch 23/200
 - 1s - loss: -3.1394e+00 - val_loss: -3.2081e+00
Epoch 24/200
 - 1s - loss: -3.1449e+00 - val_loss: -3.2090e+00
Epoch 25/200
 - 1s - loss: -3.1466e+00 - val_loss: -3.2104e+00
Epoch 26/200
 - 1s - loss: -3.1508e+00 - val_loss: -3.2110e+00
Epoch 27/200
 - 1s - loss: -3.1514e+00 - val_loss: -3.2130e+00
Epoch 28/200
 - 1s - loss: -3.1538e+00 - val_loss: -3.2131e+00
Epoch 29/200
 - 1s - loss: -3.1557e+00 - val_loss: -3.2137e+00
Epoch 30/200
 - 1s - loss: -3.1574e+00 - val_loss: -3.2151e+00
Epoch 31/200
 - 1s - loss: -3.1578e+00 - val_loss: -3.2154e+00
Epoch 32/200
 - 1s - loss: -3.1614e+00 - val_loss: -3.2163e+00
Epoch 33/200
 - 1s - loss: -3.1627e+00 - val_loss: -3.2164e+00
Epoch 34/200
 - 1s - loss: -3.1641e+00 - val_loss: -3.2172e+00
Epoch 35/200
 - 1s - loss: -3.1646e+00 - val_loss: -3.2172e+00
Epoch 36/200
 - 1s - loss: -3.1656e+00 - val_loss: -3.2178e+00
Epoch 37/200
 - 1s - loss: -3.1671e+00 - val_loss: -3.2180e+00
Epoch 38/200
 - 1s - loss: -3.1667e+00 - val_loss: -3.2186e+00
Epoch 39/200
 - 1s - loss: -3.1684e+00 - val_loss: -3.2188e+00
Epoch 40/200
 - 1s - loss: -3.1700e+00 - val_loss: -3.2193e+00
Epoch 41/200
 - 1s - loss: -3.1707e+00 - val_loss: -3.2195e+00
2019-12-21 10:49:41,271 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_40.pickle
Epoch 42/200
 - 1s - loss: -3.1719e+00 - val_loss: -3.2197e+00
Epoch 43/200
 - 1s - loss: -3.1715e+00 - val_loss: -3.2199e+00
Epoch 44/200
 - 1s - loss: -3.1726e+00 - val_loss: -3.2208e+00
Epoch 45/200
 - 1s - loss: -3.1750e+00 - val_loss: -3.2205e+00
Epoch 46/200
 - 1s - loss: -3.1752e+00 - val_loss: -3.2208e+00
Epoch 47/200
 - 1s - loss: -3.1753e+00 - val_loss: -3.2211e+00
Epoch 48/200
 - 1s - loss: -3.1776e+00 - val_loss: -3.2212e+00
Epoch 49/200
 - 1s - loss: -3.1767e+00 - val_loss: -3.2217e+00
Epoch 50/200
 - 1s - loss: -3.1766e+00 - val_loss: -3.2219e+00
Epoch 51/200
 - 1s - loss: -3.1781e+00 - val_loss: -3.2218e+00
Epoch 52/200
 - 1s - loss: -3.1789e+00 - val_loss: -3.2221e+00
Epoch 53/200
 - 1s - loss: -3.1786e+00 - val_loss: -3.2221e+00
Epoch 54/200
 - 1s - loss: -3.1797e+00 - val_loss: -3.2224e+00
Epoch 55/200
 - 1s - loss: -3.1795e+00 - val_loss: -3.2224e+00
Epoch 56/200
 - 1s - loss: -3.1798e+00 - val_loss: -3.2229e+00
Epoch 57/200
 - 1s - loss: -3.1808e+00 - val_loss: -3.2231e+00
Epoch 58/200
 - 1s - loss: -3.1822e+00 - val_loss: -3.2232e+00
Epoch 59/200
 - 1s - loss: -3.1824e+00 - val_loss: -3.2233e+00
Epoch 60/200
 - 1s - loss: -3.1809e+00 - val_loss: -3.2234e+00
Epoch 61/200
 - 1s - loss: -3.1811e+00 - val_loss: -3.2236e+00
2019-12-21 10:49:55,585 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_60.pickle
Epoch 62/200
 - 1s - loss: -3.1820e+00 - val_loss: -3.2238e+00
Epoch 63/200
 - 1s - loss: -3.1834e+00 - val_loss: -3.2241e+00
Epoch 64/200
 - 1s - loss: -3.1849e+00 - val_loss: -3.2241e+00
Epoch 65/200
 - 1s - loss: -3.1857e+00 - val_loss: -3.2243e+00
Epoch 66/200
 - 1s - loss: -3.1844e+00 - val_loss: -3.2238e+00
Epoch 67/200
 - 1s - loss: -3.1842e+00 - val_loss: -3.2244e+00
Epoch 68/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2245e+00
Epoch 69/200
 - 1s - loss: -3.1846e+00 - val_loss: -3.2248e+00
Epoch 70/200
 - 1s - loss: -3.1860e+00 - val_loss: -3.2250e+00
Epoch 71/200
 - 1s - loss: -3.1863e+00 - val_loss: -3.2248e+00
Epoch 72/200
 - 1s - loss: -3.1860e+00 - val_loss: -3.2251e+00
Epoch 73/200
 - 1s - loss: -3.1873e+00 - val_loss: -3.2255e+00
Epoch 74/200
 - 1s - loss: -3.1867e+00 - val_loss: -3.2256e+00
Epoch 75/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2245e+00
Epoch 76/200
 - 1s - loss: -3.1860e+00 - val_loss: -3.2261e+00
Epoch 77/200
 - 1s - loss: -3.1876e+00 - val_loss: -3.2258e+00
Epoch 78/200
 - 1s - loss: -3.1895e+00 - val_loss: -3.2259e+00
Epoch 79/200
 - 1s - loss: -3.1896e+00 - val_loss: -3.2259e+00
Epoch 80/200
 - 1s - loss: -3.1880e+00 - val_loss: -3.2262e+00
Epoch 81/200
 - 1s - loss: -3.1880e+00 - val_loss: -3.2265e+00
2019-12-21 10:50:09,888 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_80.pickle
Epoch 82/200
 - 1s - loss: -3.1901e+00 - val_loss: -3.2266e+00
Epoch 83/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2263e+00
Epoch 84/200
 - 1s - loss: -3.1893e+00 - val_loss: -3.2265e+00
Epoch 85/200
 - 1s - loss: -3.1892e+00 - val_loss: -3.2265e+00
Epoch 86/200
 - 1s - loss: -3.1905e+00 - val_loss: -3.2266e+00
Epoch 87/200
 - 1s - loss: -3.1904e+00 - val_loss: -3.2266e+00
Epoch 88/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2266e+00
Epoch 89/200
 - 1s - loss: -3.1907e+00 - val_loss: -3.2271e+00
Epoch 90/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2266e+00
Epoch 91/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2266e+00
Epoch 92/200
 - 1s - loss: -3.1903e+00 - val_loss: -3.2272e+00
Epoch 93/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2265e+00
Epoch 94/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2276e+00
Epoch 95/200
 - 1s - loss: -3.1928e+00 - val_loss: -3.2272e+00
Epoch 96/200
 - 1s - loss: -3.1907e+00 - val_loss: -3.2274e+00
Epoch 97/200
 - 1s - loss: -3.1917e+00 - val_loss: -3.2272e+00
Epoch 98/200
 - 1s - loss: -3.1920e+00 - val_loss: -3.2273e+00
Epoch 99/200
 - 1s - loss: -3.1934e+00 - val_loss: -3.2271e+00
Epoch 100/200
 - 1s - loss: -3.1924e+00 - val_loss: -3.2270e+00
Epoch 101/200
 - 1s - loss: -3.1939e+00 - val_loss: -3.2273e+00
2019-12-21 10:50:24,168 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_100.pickle
Epoch 102/200
 - 1s - loss: -3.1920e+00 - val_loss: -3.2272e+00
Epoch 103/200
 - 1s - loss: -3.1926e+00 - val_loss: -3.2275e+00
Epoch 104/200
 - 1s - loss: -3.1943e+00 - val_loss: -3.2276e+00
Epoch 105/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2277e+00
Epoch 106/200
 - 1s - loss: -3.1923e+00 - val_loss: -3.2277e+00
Epoch 107/200
 - 1s - loss: -3.1950e+00 - val_loss: -3.2280e+00
Epoch 108/200
 - 1s - loss: -3.1938e+00 - val_loss: -3.2278e+00
Epoch 109/200
 - 1s - loss: -3.1936e+00 - val_loss: -3.2283e+00
Epoch 110/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2283e+00
Epoch 111/200
 - 1s - loss: -3.1969e+00 - val_loss: -3.2279e+00
Epoch 112/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2286e+00
Epoch 113/200
 - 1s - loss: -3.1952e+00 - val_loss: -3.2285e+00
Epoch 114/200
 - 1s - loss: -3.1956e+00 - val_loss: -3.2289e+00
Epoch 115/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2287e+00
Epoch 116/200
 - 1s - loss: -3.1951e+00 - val_loss: -3.2291e+00
Epoch 117/200
 - 1s - loss: -3.1954e+00 - val_loss: -3.2290e+00
Epoch 118/200
 - 1s - loss: -3.1943e+00 - val_loss: -3.2292e+00
Epoch 119/200
 - 1s - loss: -3.1956e+00 - val_loss: -3.2289e+00
Epoch 120/200
 - 1s - loss: -3.1962e+00 - val_loss: -3.2290e+00
Epoch 121/200
 - 1s - loss: -3.1969e+00 - val_loss: -3.2291e+00
2019-12-21 10:50:38,410 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_120.pickle
Epoch 122/200
 - 1s - loss: -3.1966e+00 - val_loss: -3.2292e+00
Epoch 123/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2291e+00
Epoch 124/200
 - 1s - loss: -3.1975e+00 - val_loss: -3.2292e+00
Epoch 125/200
 - 1s - loss: -3.1964e+00 - val_loss: -3.2298e+00
Epoch 126/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2291e+00
Epoch 127/200
 - 1s - loss: -3.1981e+00 - val_loss: -3.2289e+00
Epoch 128/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2295e+00
Epoch 129/200
 - 1s - loss: -3.1972e+00 - val_loss: -3.2289e+00
Epoch 130/200
 - 1s - loss: -3.1971e+00 - val_loss: -3.2293e+00
Epoch 131/200
 - 1s - loss: -3.1979e+00 - val_loss: -3.2292e+00
Epoch 132/200
 - 1s - loss: -3.1970e+00 - val_loss: -3.2292e+00
Epoch 133/200
 - 1s - loss: -3.1986e+00 - val_loss: -3.2294e+00
Epoch 134/200
 - 1s - loss: -3.1977e+00 - val_loss: -3.2294e+00
Epoch 135/200
 - 1s - loss: -3.1984e+00 - val_loss: -3.2297e+00
Epoch 136/200
 - 1s - loss: -3.1980e+00 - val_loss: -3.2294e+00
Epoch 137/200
 - 1s - loss: -3.1981e+00 - val_loss: -3.2294e+00
Epoch 138/200
 - 1s - loss: -3.1992e+00 - val_loss: -3.2299e+00
Epoch 139/200
 - 1s - loss: -3.1987e+00 - val_loss: -3.2297e+00
Epoch 140/200
 - 1s - loss: -3.1980e+00 - val_loss: -3.2293e+00
Epoch 141/200
 - 1s - loss: -3.1988e+00 - val_loss: -3.2298e+00
2019-12-21 10:50:52,625 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_140.pickle
Epoch 142/200
 - 1s - loss: -3.1973e+00 - val_loss: -3.2297e+00
Epoch 143/200
 - 1s - loss: -3.1991e+00 - val_loss: -3.2296e+00
Epoch 144/200
 - 1s - loss: -3.1991e+00 - val_loss: -3.2300e+00
Epoch 145/200
 - 1s - loss: -3.1977e+00 - val_loss: -3.2298e+00
Epoch 146/200
 - 1s - loss: -3.1990e+00 - val_loss: -3.2302e+00
Epoch 147/200
 - 1s - loss: -3.1992e+00 - val_loss: -3.2300e+00
Epoch 148/200
 - 1s - loss: -3.1994e+00 - val_loss: -3.2303e+00
Epoch 149/200
 - 1s - loss: -3.1994e+00 - val_loss: -3.2301e+00
Epoch 150/200
 - 1s - loss: -3.1991e+00 - val_loss: -3.2304e+00
Epoch 151/200
 - 1s - loss: -3.1994e+00 - val_loss: -3.2302e+00
Epoch 152/200
 - 1s - loss: -3.2005e+00 - val_loss: -3.2306e+00
Epoch 153/200
 - 1s - loss: -3.2006e+00 - val_loss: -3.2307e+00
Epoch 154/200
 - 1s - loss: -3.1999e+00 - val_loss: -3.2306e+00
Epoch 155/200
 - 1s - loss: -3.2000e+00 - val_loss: -3.2307e+00
Epoch 156/200
 - 1s - loss: -3.1995e+00 - val_loss: -3.2305e+00
Epoch 157/200
 - 1s - loss: -3.2014e+00 - val_loss: -3.2307e+00
Epoch 158/200
 - 1s - loss: -3.2007e+00 - val_loss: -3.2308e+00
Epoch 159/200
 - 1s - loss: -3.2009e+00 - val_loss: -3.2308e+00
Epoch 160/200
 - 1s - loss: -3.2018e+00 - val_loss: -3.2308e+00
Epoch 161/200
 - 1s - loss: -3.2005e+00 - val_loss: -3.2306e+00
2019-12-21 10:51:06,867 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_160.pickle
Epoch 162/200
 - 1s - loss: -3.2009e+00 - val_loss: -3.2309e+00
Epoch 163/200
 - 1s - loss: -3.2008e+00 - val_loss: -3.2312e+00
Epoch 164/200
 - 1s - loss: -3.1995e+00 - val_loss: -3.2308e+00
Epoch 165/200
 - 1s - loss: -3.2020e+00 - val_loss: -3.2307e+00
Epoch 166/200
 - 1s - loss: -3.2017e+00 - val_loss: -3.2310e+00
Epoch 167/200
 - 1s - loss: -3.2014e+00 - val_loss: -3.2307e+00
Epoch 168/200
 - 1s - loss: -3.2004e+00 - val_loss: -3.2308e+00
Epoch 169/200
 - 1s - loss: -3.2005e+00 - val_loss: -3.2307e+00
Epoch 170/200
 - 1s - loss: -3.2022e+00 - val_loss: -3.2309e+00
Epoch 171/200
 - 1s - loss: -3.2018e+00 - val_loss: -3.2310e+00
Epoch 172/200
 - 1s - loss: -3.2019e+00 - val_loss: -3.2308e+00
Epoch 173/200
 - 1s - loss: -3.2028e+00 - val_loss: -3.2311e+00
Epoch 174/200
 - 1s - loss: -3.2014e+00 - val_loss: -3.2312e+00
Epoch 175/200
 - 1s - loss: -3.2028e+00 - val_loss: -3.2313e+00
Epoch 176/200
 - 1s - loss: -3.2017e+00 - val_loss: -3.2306e+00
Epoch 177/200
 - 1s - loss: -3.2023e+00 - val_loss: -3.2311e+00
Epoch 178/200
 - 1s - loss: -3.2009e+00 - val_loss: -3.2311e+00
Epoch 179/200
 - 1s - loss: -3.2028e+00 - val_loss: -3.2309e+00
Epoch 180/200
 - 1s - loss: -3.2030e+00 - val_loss: -3.2310e+00
Epoch 181/200
 - 1s - loss: -3.2034e+00 - val_loss: -3.2311e+00
2019-12-21 10:51:21,122 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ae_model_epoch_180.pickle
Epoch 182/200
 - 1s - loss: -3.2025e+00 - val_loss: -3.2312e+00
Epoch 183/200
 - 1s - loss: -3.2027e+00 - val_loss: -3.2311e+00
Epoch 184/200
 - 1s - loss: -3.2024e+00 - val_loss: -3.2315e+00
Epoch 185/200
 - 1s - loss: -3.2026e+00 - val_loss: -3.2312e+00
Epoch 186/200
 - 1s - loss: -3.2031e+00 - val_loss: -3.2315e+00
Epoch 187/200
 - 1s - loss: -3.2030e+00 - val_loss: -3.2315e+00
Epoch 188/200
 - 1s - loss: -3.2036e+00 - val_loss: -3.2313e+00
Epoch 189/200
 - 1s - loss: -3.2026e+00 - val_loss: -3.2314e+00
Epoch 190/200
 - 1s - loss: -3.2031e+00 - val_loss: -3.2316e+00
Epoch 191/200
 - 1s - loss: -3.2030e+00 - val_loss: -3.2320e+00
Epoch 192/200
 - 1s - loss: -3.2023e+00 - val_loss: -3.2322e+00
Epoch 193/200
 - 1s - loss: -3.2023e+00 - val_loss: -3.2316e+00
Epoch 194/200
 - 1s - loss: -3.2041e+00 - val_loss: -3.2315e+00
Epoch 195/200
 - 1s - loss: -3.2029e+00 - val_loss: -3.2318e+00
Epoch 196/200
 - 1s - loss: -3.2041e+00 - val_loss: -3.2316e+00
Epoch 197/200
 - 1s - loss: -3.2033e+00 - val_loss: -3.2318e+00
Epoch 198/200
 - 1s - loss: -3.2026e+00 - val_loss: -3.2322e+00
Epoch 199/200
 - 1s - loss: -3.2040e+00 - val_loss: -3.2318e+00
Epoch 200/200
 - 1s - loss: -3.2032e+00 - val_loss: -3.2320e+00
2019-12-21 10:51:34,691 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:51:35,918 [INFO] Last epoch loss evaluation: train_loss = -3.254218, val_loss = -3.232226
2019-12-21 10:51:35,919 [INFO] Training autoencoder complete
2019-12-21 10:51:35,919 [INFO] Encoding data for supervised training
2019-12-21 10:51:36,872 [INFO] Encoding complete
2019-12-21 10:51:36,873 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.2275 - val_loss: 0.0653
 - val_f1: 0.9589
Epoch 2/200
 - 0s - loss: 0.0622 - val_loss: 0.0451
 - val_f1: 0.9693
Epoch 3/200
 - 0s - loss: 0.0469 - val_loss: 0.0365
 - val_f1: 0.9728
Epoch 4/200
 - 0s - loss: 0.0397 - val_loss: 0.0313
 - val_f1: 0.9736
Epoch 5/200
 - 0s - loss: 0.0334 - val_loss: 0.0248
 - val_f1: 0.9778
Epoch 6/200
 - 0s - loss: 0.0277 - val_loss: 0.0210
 - val_f1: 0.9812
Epoch 7/200
 - 0s - loss: 0.0253 - val_loss: 0.0185
 - val_f1: 0.9859
Epoch 8/200
 - 0s - loss: 0.0238 - val_loss: 0.0171
 - val_f1: 0.9880
Epoch 9/200
 - 0s - loss: 0.0218 - val_loss: 0.0161
 - val_f1: 0.9890
Epoch 10/200
 - 0s - loss: 0.0199 - val_loss: 0.0152
 - val_f1: 0.9902
Epoch 11/200
 - 0s - loss: 0.0197 - val_loss: 0.0152
 - val_f1: 0.9904
Epoch 12/200
 - 0s - loss: 0.0184 - val_loss: 0.0147
 - val_f1: 0.9897
Epoch 13/200
 - 0s - loss: 0.0174 - val_loss: 0.0140
 - val_f1: 0.9901
Epoch 14/200
 - 0s - loss: 0.0172 - val_loss: 0.0136
 - val_f1: 0.9899
Epoch 15/200
 - 0s - loss: 0.0165 - val_loss: 0.0133
 - val_f1: 0.9907
Epoch 16/200
 - 0s - loss: 0.0153 - val_loss: 0.0130
 - val_f1: 0.9914
Epoch 17/200
 - 0s - loss: 0.0151 - val_loss: 0.0125
 - val_f1: 0.9906
Epoch 18/200
 - 0s - loss: 0.0149 - val_loss: 0.0123
 - val_f1: 0.9918
Epoch 19/200
 - 0s - loss: 0.0151 - val_loss: 0.0121
 - val_f1: 0.9917
Epoch 20/200
 - 0s - loss: 0.0144 - val_loss: 0.0123
 - val_f1: 0.9916
Epoch 21/200
 - 0s - loss: 0.0146 - val_loss: 0.0119
2019-12-21 10:51:49,928 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9919
Epoch 22/200
 - 0s - loss: 0.0141 - val_loss: 0.0116
 - val_f1: 0.9919
Epoch 23/200
 - 0s - loss: 0.0137 - val_loss: 0.0118
 - val_f1: 0.9913
Epoch 24/200
 - 0s - loss: 0.0136 - val_loss: 0.0112
 - val_f1: 0.9925
Epoch 25/200
 - 0s - loss: 0.0133 - val_loss: 0.0110
 - val_f1: 0.9925
Epoch 26/200
 - 0s - loss: 0.0128 - val_loss: 0.0111
 - val_f1: 0.9917
Epoch 27/200
 - 0s - loss: 0.0135 - val_loss: 0.0109
 - val_f1: 0.9922
Epoch 28/200
 - 0s - loss: 0.0123 - val_loss: 0.0109
 - val_f1: 0.9924
Epoch 29/200
 - 0s - loss: 0.0127 - val_loss: 0.0109
 - val_f1: 0.9922
Epoch 30/200
 - 0s - loss: 0.0123 - val_loss: 0.0107
 - val_f1: 0.9924
Epoch 31/200
 - 0s - loss: 0.0122 - val_loss: 0.0105
 - val_f1: 0.9925
Epoch 32/200
 - 0s - loss: 0.0120 - val_loss: 0.0107
 - val_f1: 0.9926
Epoch 33/200
 - 0s - loss: 0.0118 - val_loss: 0.0108
 - val_f1: 0.9916
Epoch 34/200
 - 0s - loss: 0.0120 - val_loss: 0.0105
 - val_f1: 0.9930
Epoch 35/200
 - 0s - loss: 0.0119 - val_loss: 0.0108
 - val_f1: 0.9909
Epoch 36/200
 - 0s - loss: 0.0118 - val_loss: 0.0106
 - val_f1: 0.9929
Epoch 37/200
 - 0s - loss: 0.0114 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 38/200
 - 0s - loss: 0.0108 - val_loss: 0.0105
 - val_f1: 0.9921
Epoch 39/200
 - 0s - loss: 0.0114 - val_loss: 0.0099
 - val_f1: 0.9929
Epoch 40/200
 - 0s - loss: 0.0114 - val_loss: 0.0110
 - val_f1: 0.9920
Epoch 41/200
 - 0s - loss: 0.0114 - val_loss: 0.0100
2019-12-21 10:52:00,799 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9931
Epoch 42/200
 - 0s - loss: 0.0108 - val_loss: 0.0103
 - val_f1: 0.9931
Epoch 43/200
 - 0s - loss: 0.0109 - val_loss: 0.0102
 - val_f1: 0.9929
Epoch 44/200
 - 0s - loss: 0.0116 - val_loss: 0.0105
 - val_f1: 0.9925
Epoch 45/200
 - 0s - loss: 0.0110 - val_loss: 0.0103
 - val_f1: 0.9925
Epoch 46/200
 - 0s - loss: 0.0109 - val_loss: 0.0104
 - val_f1: 0.9923
Epoch 47/200
 - 0s - loss: 0.0110 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 48/200
 - 0s - loss: 0.0109 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 49/200
 - 0s - loss: 0.0110 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 50/200
 - 0s - loss: 0.0110 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 51/200
 - 0s - loss: 0.0109 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 52/200
 - 0s - loss: 0.0106 - val_loss: 0.0100
 - val_f1: 0.9928
Epoch 53/200
 - 0s - loss: 0.0101 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 54/200
 - 0s - loss: 0.0105 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 55/200
 - 0s - loss: 0.0099 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 56/200
 - 0s - loss: 0.0099 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 57/200
 - 0s - loss: 0.0107 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 58/200
 - 0s - loss: 0.0104 - val_loss: 0.0098
 - val_f1: 0.9925
Epoch 59/200
 - 0s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 60/200
 - 0s - loss: 0.0102 - val_loss: 0.0097
 - val_f1: 0.9930
Epoch 61/200
 - 0s - loss: 0.0100 - val_loss: 0.0093
2019-12-21 10:52:11,651 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9935
Epoch 62/200
 - 0s - loss: 0.0102 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 63/200
 - 0s - loss: 0.0104 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 64/200
 - 0s - loss: 0.0100 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 65/200
 - 0s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 66/200
 - 0s - loss: 0.0098 - val_loss: 0.0102
 - val_f1: 0.9925
Epoch 67/200
 - 0s - loss: 0.0099 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 68/200
 - 0s - loss: 0.0099 - val_loss: 0.0095
 - val_f1: 0.9932
Epoch 69/200
 - 0s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9931
Epoch 70/200
 - 0s - loss: 0.0101 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 71/200
 - 0s - loss: 0.0099 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 72/200
 - 0s - loss: 0.0098 - val_loss: 0.0098
 - val_f1: 0.9927
Epoch 73/200
 - 0s - loss: 0.0102 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 74/200
 - 0s - loss: 0.0091 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 75/200
 - 0s - loss: 0.0096 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 76/200
 - 0s - loss: 0.0097 - val_loss: 0.0102
 - val_f1: 0.9927
Epoch 77/200
 - 0s - loss: 0.0097 - val_loss: 0.0101
 - val_f1: 0.9928
Epoch 78/200
 - 0s - loss: 0.0098 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 79/200
 - 0s - loss: 0.0094 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 80/200
 - 0s - loss: 0.0095 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 81/200
 - 0s - loss: 0.0096 - val_loss: 0.0096
2019-12-21 10:52:22,506 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9935
Epoch 82/200
 - 0s - loss: 0.0092 - val_loss: 0.0093
 - val_f1: 0.9937
Epoch 83/200
 - 0s - loss: 0.0095 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 84/200
 - 0s - loss: 0.0092 - val_loss: 0.0092
 - val_f1: 0.9942
Epoch 85/200
 - 0s - loss: 0.0096 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 86/200
 - 0s - loss: 0.0091 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 87/200
 - 0s - loss: 0.0092 - val_loss: 0.0094
 - val_f1: 0.9936
Epoch 88/200
 - 0s - loss: 0.0098 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 89/200
 - 0s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 90/200
 - 0s - loss: 0.0092 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 91/200
 - 0s - loss: 0.0093 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 92/200
 - 0s - loss: 0.0094 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 93/200
 - 0s - loss: 0.0095 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 94/200
 - 0s - loss: 0.0090 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 95/200
 - 0s - loss: 0.0093 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 96/200
 - 0s - loss: 0.0091 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 97/200
 - 0s - loss: 0.0097 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 98/200
 - 0s - loss: 0.0092 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 99/200
 - 0s - loss: 0.0095 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 100/200
 - 0s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 101/200
 - 0s - loss: 0.0087 - val_loss: 0.0092
2019-12-21 10:52:33,371 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9937
Epoch 102/200
 - 0s - loss: 0.0094 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 103/200
 - 0s - loss: 0.0092 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 104/200
 - 0s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9940
Epoch 105/200
 - 0s - loss: 0.0090 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 106/200
 - 0s - loss: 0.0092 - val_loss: 0.0091
 - val_f1: 0.9936
Epoch 107/200
 - 0s - loss: 0.0089 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 108/200
 - 0s - loss: 0.0094 - val_loss: 0.0090
 - val_f1: 0.9942
Epoch 109/200
 - 0s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 110/200
 - 0s - loss: 0.0087 - val_loss: 0.0090
 - val_f1: 0.9937
Epoch 111/200
 - 0s - loss: 0.0089 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 112/200
 - 0s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 113/200
 - 0s - loss: 0.0087 - val_loss: 0.0089
 - val_f1: 0.9939
Epoch 114/200
 - 0s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 115/200
 - 0s - loss: 0.0089 - val_loss: 0.0088
 - val_f1: 0.9938
Epoch 116/200
 - 0s - loss: 0.0091 - val_loss: 0.0088
 - val_f1: 0.9943
Epoch 117/200
 - 0s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 118/200
 - 0s - loss: 0.0087 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 119/200
 - 0s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9943
Epoch 120/200
 - 0s - loss: 0.0087 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 121/200
 - 0s - loss: 0.0092 - val_loss: 0.0090
2019-12-21 10:52:44,232 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9935
Epoch 122/200
 - 0s - loss: 0.0090 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 123/200
 - 0s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9933
Epoch 124/200
 - 0s - loss: 0.0093 - val_loss: 0.0091
 - val_f1: 0.9933
Epoch 125/200
 - 0s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 126/200
 - 0s - loss: 0.0083 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 127/200
 - 0s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9935
Epoch 128/200
 - 0s - loss: 0.0087 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 129/200
 - 0s - loss: 0.0088 - val_loss: 0.0097
 - val_f1: 0.9927
Epoch 130/200
 - 0s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 131/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 132/200
 - 0s - loss: 0.0089 - val_loss: 0.0091
 - val_f1: 0.9936
Epoch 133/200
 - 0s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 134/200
 - 0s - loss: 0.0090 - val_loss: 0.0087
 - val_f1: 0.9941
Epoch 135/200
 - 0s - loss: 0.0087 - val_loss: 0.0089
 - val_f1: 0.9936
Epoch 136/200
 - 0s - loss: 0.0088 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 137/200
 - 0s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 138/200
 - 0s - loss: 0.0087 - val_loss: 0.0090
 - val_f1: 0.9936
Epoch 139/200
 - 0s - loss: 0.0085 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 140/200
 - 0s - loss: 0.0087 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 141/200
 - 0s - loss: 0.0087 - val_loss: 0.0091
2019-12-21 10:52:55,101 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9937
Epoch 142/200
 - 0s - loss: 0.0088 - val_loss: 0.0088
 - val_f1: 0.9942
Epoch 143/200
 - 0s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9938
Epoch 144/200
 - 0s - loss: 0.0091 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 145/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 146/200
 - 0s - loss: 0.0082 - val_loss: 0.0089
 - val_f1: 0.9943
Epoch 147/200
 - 0s - loss: 0.0086 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 148/200
 - 0s - loss: 0.0083 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 149/200
 - 0s - loss: 0.0088 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 150/200
 - 0s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9936
Epoch 151/200
 - 0s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9934
Epoch 152/200
 - 0s - loss: 0.0089 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 153/200
 - 0s - loss: 0.0082 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 154/200
 - 0s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9940
Epoch 155/200
 - 0s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9943
Epoch 156/200
 - 0s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9945
Epoch 157/200
 - 0s - loss: 0.0084 - val_loss: 0.0087
 - val_f1: 0.9946
Epoch 158/200
 - 0s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9941
Epoch 159/200
 - 0s - loss: 0.0084 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 160/200
 - 0s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9929
Epoch 161/200
 - 0s - loss: 0.0087 - val_loss: 0.0095
2019-12-21 10:53:05,988 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9931
Epoch 162/200
 - 0s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 163/200
 - 0s - loss: 0.0087 - val_loss: 0.0088
 - val_f1: 0.9942
Epoch 164/200
 - 0s - loss: 0.0083 - val_loss: 0.0087
 - val_f1: 0.9946
Epoch 165/200
 - 0s - loss: 0.0078 - val_loss: 0.0084
 - val_f1: 0.9945
Epoch 166/200
 - 0s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9944
Epoch 167/200
 - 0s - loss: 0.0085 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 168/200
 - 0s - loss: 0.0089 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 169/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 170/200
 - 0s - loss: 0.0087 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 171/200
 - 0s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9932
Epoch 172/200
 - 0s - loss: 0.0085 - val_loss: 0.0089
 - val_f1: 0.9935
Epoch 173/200
 - 0s - loss: 0.0086 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 174/200
 - 0s - loss: 0.0082 - val_loss: 0.0089
 - val_f1: 0.9939
Epoch 175/200
 - 0s - loss: 0.0083 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 176/200
 - 0s - loss: 0.0088 - val_loss: 0.0090
 - val_f1: 0.9937
Epoch 177/200
 - 0s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9940
Epoch 178/200
 - 0s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9941
Epoch 179/200
 - 0s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9942
Epoch 180/200
 - 0s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 181/200
 - 0s - loss: 0.0080 - val_loss: 0.0087
2019-12-21 10:53:16,868 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9934
Epoch 182/200
 - 0s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9945
Epoch 183/200
 - 0s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9942
Epoch 184/200
 - 0s - loss: 0.0077 - val_loss: 0.0090
 - val_f1: 0.9939
Epoch 185/200
 - 0s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 186/200
 - 0s - loss: 0.0081 - val_loss: 0.0091
 - val_f1: 0.9935
Epoch 187/200
 - 0s - loss: 0.0082 - val_loss: 0.0088
 - val_f1: 0.9941
Epoch 188/200
 - 0s - loss: 0.0079 - val_loss: 0.0084
 - val_f1: 0.9943
Epoch 189/200
 - 0s - loss: 0.0082 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 190/200
 - 0s - loss: 0.0081 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 191/200
 - 0s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 192/200
 - 0s - loss: 0.0080 - val_loss: 0.0084
 - val_f1: 0.9946
Epoch 193/200
 - 0s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9938
Epoch 194/200
 - 0s - loss: 0.0084 - val_loss: 0.0087
 - val_f1: 0.9942
Epoch 195/200
 - 0s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 196/200
 - 0s - loss: 0.0082 - val_loss: 0.0086
 - val_f1: 0.9939
Epoch 197/200
 - 0s - loss: 0.0084 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 198/200
 - 0s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9942
Epoch 199/200
 - 0s - loss: 0.0081 - val_loss: 0.0086
 - val_f1: 0.9945
Epoch 200/200
 - 0s - loss: 0.0081 - val_loss: 0.0093
2019-12-21 10:53:27,458 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:53:28,533 [INFO] Last epoch loss evaluation: train_loss = 0.005185, val_loss = 0.008257
2019-12-21 10:53:28,536 [INFO] Training complete. time_to_train = 258.93 sec, 4.32 min
2019-12-21 10:53:28,545 [INFO] Model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep3/best_model.pickle
2019-12-21 10:53:28,724 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep3/training_error_history.png
2019-12-21 10:53:28,907 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep3/training_f1_history.png
2019-12-21 10:53:28,907 [INFO] Making predictions on training, validation, testing data
2019-12-21 10:53:32,084 [INFO] Evaluating predictions (results)
2019-12-21 10:53:32,344 [INFO] Dataset: Testing. Classification report below
2019-12-21 10:53:32,344 [INFO] 
              precision    recall  f1-score   support

         dos       0.91      0.81      0.86      7458
      normal       0.67      0.93      0.78      9711
       probe       0.84      0.72      0.78      2421
         r2l       0.99      0.13      0.22      2421
         u2r       0.61      0.02      0.04       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.80      0.52      0.54     22544
weighted avg       0.80      0.76      0.73     22544

2019-12-21 10:53:32,344 [INFO] Overall accuracy (micro avg): 0.7613112136266856
2019-12-21 10:53:32,640 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7613         0.7613                       0.7613                0.0597                   0.2387  0.7613
1     Macro avg        0.9045         0.8041                       0.5222                0.0805                   0.4778  0.5355
2  Weighted avg        0.8577         0.8009                       0.7613                0.1638                   0.2387  0.7282
2019-12-21 10:53:32,974 [INFO] Dataset: Validation. Classification report below
2019-12-21 10:53:32,974 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      1.00      1.00     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.91      0.80      0.85       199
         u2r       0.43      0.30      0.35        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.86      0.82      0.84     25195
weighted avg       0.99      0.99      0.99     25195

2019-12-21 10:53:32,974 [INFO] Overall accuracy (micro avg): 0.9942051994443342
2019-12-21 10:53:33,331 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9942         0.9942                       0.9942                0.0014                   0.0058  0.9942
1     Macro avg        0.9977         0.8629                       0.8163                0.0019                   0.1837  0.8366
2  Weighted avg        0.9965         0.9941                       0.9942                0.0038                   0.0058  0.9941
2019-12-21 10:53:34,770 [INFO] Dataset: Training. Classification report below
2019-12-21 10:53:34,770 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.92      0.77      0.84       796
         u2r       0.60      0.43      0.50        42

   micro avg       0.99      0.99      0.99    100778
   macro avg       0.90      0.84      0.86    100778
weighted avg       0.99      0.99      0.99    100778

2019-12-21 10:53:34,770 [INFO] Overall accuracy (micro avg): 0.9945325368632043
2019-12-21 10:53:36,388 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9945         0.9945                       0.9945                0.0014                   0.0055  0.9945
1     Macro avg        0.9978         0.8998                       0.8359                0.0019                   0.1641  0.8637
2  Weighted avg        0.9967         0.9944                       0.9945                0.0041                   0.0055  0.9944
2019-12-21 10:53:36,426 [INFO] Results saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep3/selected_nsl_ae_ann_shallow_rep3_results.xlsx
2019-12-21 10:53:36,426 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-21 10:53:36,429 [INFO] Created directory: results_selected_models/selected_nsl_ae_ann_shallow_rep4
2019-12-21 10:53:36,429 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ae_ann_shallow_rep4/run_log.log
2019-12-21 10:53:36,429 [INFO] ================= Running experiment no. 4  ================= 

2019-12-21 10:53:36,429 [INFO] Experiment parameters given below
2019-12-21 10:53:36,430 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_nsl_ae_ann_shallow_rep4', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ae_ann_shallow_rep4'}
2019-12-21 10:53:36,430 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ae_ann_shallow_rep4/tf_logs_run_2019_12_21-10_53_36
2019-12-21 10:53:36,430 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-21 10:53:36,430 [INFO] Reading X, y files
2019-12-21 10:53:36,430 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-21 10:53:36,681 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-21 10:53:36,682 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-21 10:53:36,744 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:53:36,744 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-21 10:53:36,801 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:53:36,801 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-21 10:53:36,808 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:53:36,808 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-21 10:53:36,812 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:53:36,812 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-21 10:53:36,816 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:53:36,997 [INFO] Initializing model
2019-12-21 10:53:37,103 [INFO] _________________________________________________________________
2019-12-21 10:53:37,103 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:53:37,104 [INFO] =================================================================
2019-12-21 10:53:37,104 [INFO] dense_13 (Dense)             (None, 32)                3936      
2019-12-21 10:53:37,104 [INFO] _________________________________________________________________
2019-12-21 10:53:37,104 [INFO] batch_normalization_7 (Batch (None, 32)                128       
2019-12-21 10:53:37,104 [INFO] _________________________________________________________________
2019-12-21 10:53:37,104 [INFO] dropout_7 (Dropout)          (None, 32)                0         
2019-12-21 10:53:37,104 [INFO] _________________________________________________________________
2019-12-21 10:53:37,104 [INFO] dense_14 (Dense)             (None, 122)               4026      
2019-12-21 10:53:37,104 [INFO] =================================================================
2019-12-21 10:53:37,104 [INFO] Total params: 8,090
2019-12-21 10:53:37,104 [INFO] Trainable params: 8,026
2019-12-21 10:53:37,105 [INFO] Non-trainable params: 64
2019-12-21 10:53:37,105 [INFO] _________________________________________________________________
2019-12-21 10:53:37,212 [INFO] _________________________________________________________________
2019-12-21 10:53:37,212 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:53:37,213 [INFO] =================================================================
2019-12-21 10:53:37,213 [INFO] dense_15 (Dense)             (None, 32)                1056      
2019-12-21 10:53:37,213 [INFO] _________________________________________________________________
2019-12-21 10:53:37,213 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-21 10:53:37,213 [INFO] _________________________________________________________________
2019-12-21 10:53:37,213 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-21 10:53:37,213 [INFO] _________________________________________________________________
2019-12-21 10:53:37,213 [INFO] dense_16 (Dense)             (None, 5)                 165       
2019-12-21 10:53:37,213 [INFO] =================================================================
2019-12-21 10:53:37,213 [INFO] Total params: 1,349
2019-12-21 10:53:37,214 [INFO] Trainable params: 1,285
2019-12-21 10:53:37,214 [INFO] Non-trainable params: 64
2019-12-21 10:53:37,214 [INFO] _________________________________________________________________
2019-12-21 10:53:37,214 [INFO] Training model
2019-12-21 10:53:37,214 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 10:53:37,792 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389
2019-12-21 10:53:37,794 [INFO] Training autoencoder
 - val_f1: 0.9944
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3189 - val_loss: -2.3663e-01
Epoch 2/200
 - 1s - loss: -6.9762e-01 - val_loss: -1.3019e+00
Epoch 3/200
 - 1s - loss: -1.6057e+00 - val_loss: -2.0479e+00
Epoch 4/200
 - 1s - loss: -2.2303e+00 - val_loss: -2.5673e+00
Epoch 5/200
 - 1s - loss: -2.5809e+00 - val_loss: -2.8299e+00
Epoch 6/200
 - 1s - loss: -2.7713e+00 - val_loss: -2.9650e+00
Epoch 7/200
 - 1s - loss: -2.8755e+00 - val_loss: -3.0390e+00
Epoch 8/200
 - 1s - loss: -2.9373e+00 - val_loss: -3.0833e+00
Epoch 9/200
 - 1s - loss: -2.9799e+00 - val_loss: -3.1106e+00
Epoch 10/200
 - 1s - loss: -3.0114e+00 - val_loss: -3.1322e+00
Epoch 11/200
 - 1s - loss: -3.0339e+00 - val_loss: -3.1456e+00
Epoch 12/200
 - 1s - loss: -3.0523e+00 - val_loss: -3.1581e+00
Epoch 13/200
 - 1s - loss: -3.0665e+00 - val_loss: -3.1677e+00
Epoch 14/200
 - 1s - loss: -3.0803e+00 - val_loss: -3.1748e+00
Epoch 15/200
 - 1s - loss: -3.0896e+00 - val_loss: -3.1802e+00
Epoch 16/200
 - 1s - loss: -3.0984e+00 - val_loss: -3.1848e+00
Epoch 17/200
 - 1s - loss: -3.1044e+00 - val_loss: -3.1882e+00
Epoch 18/200
 - 1s - loss: -3.1107e+00 - val_loss: -3.1919e+00
Epoch 19/200
 - 1s - loss: -3.1156e+00 - val_loss: -3.1940e+00
Epoch 20/200
 - 1s - loss: -3.1206e+00 - val_loss: -3.1967e+00
Epoch 21/200
 - 1s - loss: -3.1226e+00 - val_loss: -3.1983e+00
2019-12-21 10:53:55,111 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_20.pickle
Epoch 22/200
 - 1s - loss: -3.1284e+00 - val_loss: -3.1998e+00
Epoch 23/200
 - 1s - loss: -3.1323e+00 - val_loss: -3.2015e+00
Epoch 24/200
 - 1s - loss: -3.1361e+00 - val_loss: -3.2034e+00
Epoch 25/200
 - 1s - loss: -3.1385e+00 - val_loss: -3.2038e+00
Epoch 26/200
 - 1s - loss: -3.1400e+00 - val_loss: -3.2050e+00
Epoch 27/200
 - 1s - loss: -3.1429e+00 - val_loss: -3.2065e+00
Epoch 28/200
 - 1s - loss: -3.1455e+00 - val_loss: -3.2074e+00
Epoch 29/200
 - 1s - loss: -3.1468e+00 - val_loss: -3.2077e+00
Epoch 30/200
 - 1s - loss: -3.1490e+00 - val_loss: -3.2088e+00
Epoch 31/200
 - 1s - loss: -3.1513e+00 - val_loss: -3.2093e+00
Epoch 32/200
 - 1s - loss: -3.1520e+00 - val_loss: -3.2099e+00
Epoch 33/200
 - 1s - loss: -3.1532e+00 - val_loss: -3.2101e+00
Epoch 34/200
 - 1s - loss: -3.1539e+00 - val_loss: -3.2102e+00
Epoch 35/200
 - 1s - loss: -3.1554e+00 - val_loss: -3.2113e+00
Epoch 36/200
 - 1s - loss: -3.1579e+00 - val_loss: -3.2117e+00
Epoch 37/200
 - 1s - loss: -3.1587e+00 - val_loss: -3.2118e+00
Epoch 38/200
 - 1s - loss: -3.1604e+00 - val_loss: -3.2127e+00
Epoch 39/200
 - 1s - loss: -3.1600e+00 - val_loss: -3.2125e+00
Epoch 40/200
 - 1s - loss: -3.1616e+00 - val_loss: -3.2129e+00
Epoch 41/200
 - 1s - loss: -3.1631e+00 - val_loss: -3.2134e+00
2019-12-21 10:54:09,490 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_40.pickle
Epoch 42/200
 - 1s - loss: -3.1639e+00 - val_loss: -3.2140e+00
Epoch 43/200
 - 1s - loss: -3.1640e+00 - val_loss: -3.2134e+00
Epoch 44/200
 - 1s - loss: -3.1639e+00 - val_loss: -3.2146e+00
Epoch 45/200
 - 1s - loss: -3.1641e+00 - val_loss: -3.2147e+00
Epoch 46/200
 - 1s - loss: -3.1656e+00 - val_loss: -3.2155e+00
Epoch 47/200
 - 1s - loss: -3.1665e+00 - val_loss: -3.2151e+00
Epoch 48/200
 - 1s - loss: -3.1666e+00 - val_loss: -3.2151e+00
Epoch 49/200
 - 1s - loss: -3.1666e+00 - val_loss: -3.2150e+00
Epoch 50/200
 - 1s - loss: -3.1682e+00 - val_loss: -3.2159e+00
Epoch 51/200
 - 1s - loss: -3.1698e+00 - val_loss: -3.2159e+00
Epoch 52/200
 - 1s - loss: -3.1697e+00 - val_loss: -3.2167e+00
Epoch 53/200
 - 1s - loss: -3.1707e+00 - val_loss: -3.2163e+00
Epoch 54/200
 - 1s - loss: -3.1706e+00 - val_loss: -3.2165e+00
Epoch 55/200
 - 1s - loss: -3.1717e+00 - val_loss: -3.2168e+00
Epoch 56/200
 - 1s - loss: -3.1719e+00 - val_loss: -3.2166e+00
Epoch 57/200
 - 1s - loss: -3.1730e+00 - val_loss: -3.2165e+00
Epoch 58/200
 - 1s - loss: -3.1725e+00 - val_loss: -3.2174e+00
Epoch 59/200
 - 1s - loss: -3.1736e+00 - val_loss: -3.2177e+00
Epoch 60/200
 - 1s - loss: -3.1747e+00 - val_loss: -3.2176e+00
Epoch 61/200
 - 1s - loss: -3.1745e+00 - val_loss: -3.2181e+00
2019-12-21 10:54:23,963 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_60.pickle
Epoch 62/200
 - 1s - loss: -3.1756e+00 - val_loss: -3.2179e+00
Epoch 63/200
 - 1s - loss: -3.1770e+00 - val_loss: -3.2182e+00
Epoch 64/200
 - 1s - loss: -3.1758e+00 - val_loss: -3.2188e+00
Epoch 65/200
 - 1s - loss: -3.1765e+00 - val_loss: -3.2188e+00
Epoch 66/200
 - 1s - loss: -3.1757e+00 - val_loss: -3.2188e+00
Epoch 67/200
 - 1s - loss: -3.1776e+00 - val_loss: -3.2191e+00
Epoch 68/200
 - 1s - loss: -3.1773e+00 - val_loss: -3.2186e+00
Epoch 69/200
 - 1s - loss: -3.1775e+00 - val_loss: -3.2192e+00
Epoch 70/200
 - 1s - loss: -3.1774e+00 - val_loss: -3.2196e+00
Epoch 71/200
 - 1s - loss: -3.1795e+00 - val_loss: -3.2192e+00
Epoch 72/200
 - 1s - loss: -3.1775e+00 - val_loss: -3.2199e+00
Epoch 73/200
 - 1s - loss: -3.1773e+00 - val_loss: -3.2194e+00
Epoch 74/200
 - 1s - loss: -3.1801e+00 - val_loss: -3.2197e+00
Epoch 75/200
 - 1s - loss: -3.1791e+00 - val_loss: -3.2200e+00
Epoch 76/200
 - 1s - loss: -3.1812e+00 - val_loss: -3.2201e+00
Epoch 77/200
 - 1s - loss: -3.1791e+00 - val_loss: -3.2202e+00
Epoch 78/200
 - 1s - loss: -3.1818e+00 - val_loss: -3.2204e+00
Epoch 79/200
 - 1s - loss: -3.1816e+00 - val_loss: -3.2207e+00
Epoch 80/200
 - 1s - loss: -3.1799e+00 - val_loss: -3.2204e+00
Epoch 81/200
 - 1s - loss: -3.1813e+00 - val_loss: -3.2211e+00
2019-12-21 10:54:38,284 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_80.pickle
Epoch 82/200
 - 1s - loss: -3.1806e+00 - val_loss: -3.2204e+00
Epoch 83/200
 - 1s - loss: -3.1823e+00 - val_loss: -3.2206e+00
Epoch 84/200
 - 1s - loss: -3.1808e+00 - val_loss: -3.2208e+00
Epoch 85/200
 - 1s - loss: -3.1821e+00 - val_loss: -3.2207e+00
Epoch 86/200
 - 1s - loss: -3.1825e+00 - val_loss: -3.2207e+00
Epoch 87/200
 - 1s - loss: -3.1825e+00 - val_loss: -3.2214e+00
Epoch 88/200
 - 1s - loss: -3.1812e+00 - val_loss: -3.2215e+00
Epoch 89/200
 - 1s - loss: -3.1837e+00 - val_loss: -3.2211e+00
Epoch 90/200
 - 1s - loss: -3.1826e+00 - val_loss: -3.2210e+00
Epoch 91/200
 - 1s - loss: -3.1831e+00 - val_loss: -3.2214e+00
Epoch 92/200
 - 1s - loss: -3.1841e+00 - val_loss: -3.2216e+00
Epoch 93/200
 - 1s - loss: -3.1849e+00 - val_loss: -3.2212e+00
Epoch 94/200
 - 1s - loss: -3.1836e+00 - val_loss: -3.2217e+00
Epoch 95/200
 - 1s - loss: -3.1856e+00 - val_loss: -3.2217e+00
Epoch 96/200
 - 1s - loss: -3.1861e+00 - val_loss: -3.2216e+00
Epoch 97/200
 - 1s - loss: -3.1857e+00 - val_loss: -3.2218e+00
Epoch 98/200
 - 1s - loss: -3.1851e+00 - val_loss: -3.2221e+00
Epoch 99/200
 - 1s - loss: -3.1864e+00 - val_loss: -3.2224e+00
Epoch 100/200
 - 1s - loss: -3.1848e+00 - val_loss: -3.2218e+00
Epoch 101/200
 - 1s - loss: -3.1851e+00 - val_loss: -3.2220e+00
2019-12-21 10:54:52,739 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_100.pickle
Epoch 102/200
 - 1s - loss: -3.1869e+00 - val_loss: -3.2223e+00
Epoch 103/200
 - 1s - loss: -3.1836e+00 - val_loss: -3.2222e+00
Epoch 104/200
 - 1s - loss: -3.1863e+00 - val_loss: -3.2226e+00
Epoch 105/200
 - 1s - loss: -3.1867e+00 - val_loss: -3.2222e+00
Epoch 106/200
 - 1s - loss: -3.1863e+00 - val_loss: -3.2227e+00
Epoch 107/200
 - 1s - loss: -3.1863e+00 - val_loss: -3.2226e+00
Epoch 108/200
 - 1s - loss: -3.1870e+00 - val_loss: -3.2228e+00
Epoch 109/200
 - 1s - loss: -3.1875e+00 - val_loss: -3.2226e+00
Epoch 110/200
 - 1s - loss: -3.1853e+00 - val_loss: -3.2225e+00
Epoch 111/200
 - 1s - loss: -3.1871e+00 - val_loss: -3.2223e+00
Epoch 112/200
 - 1s - loss: -3.1869e+00 - val_loss: -3.2226e+00
Epoch 113/200
 - 1s - loss: -3.1883e+00 - val_loss: -3.2227e+00
Epoch 114/200
 - 1s - loss: -3.1882e+00 - val_loss: -3.2227e+00
Epoch 115/200
 - 1s - loss: -3.1878e+00 - val_loss: -3.2228e+00
Epoch 116/200
 - 1s - loss: -3.1874e+00 - val_loss: -3.2225e+00
Epoch 117/200
 - 1s - loss: -3.1873e+00 - val_loss: -3.2225e+00
Epoch 118/200
 - 1s - loss: -3.1886e+00 - val_loss: -3.2232e+00
Epoch 119/200
 - 1s - loss: -3.1877e+00 - val_loss: -3.2228e+00
Epoch 120/200
 - 1s - loss: -3.1885e+00 - val_loss: -3.2227e+00
Epoch 121/200
 - 1s - loss: -3.1887e+00 - val_loss: -3.2227e+00
2019-12-21 10:55:07,121 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_120.pickle
Epoch 122/200
 - 1s - loss: -3.1891e+00 - val_loss: -3.2230e+00
Epoch 123/200
 - 1s - loss: -3.1899e+00 - val_loss: -3.2235e+00
Epoch 124/200
 - 1s - loss: -3.1893e+00 - val_loss: -3.2235e+00
Epoch 125/200
 - 1s - loss: -3.1892e+00 - val_loss: -3.2232e+00
Epoch 126/200
 - 1s - loss: -3.1892e+00 - val_loss: -3.2233e+00
Epoch 127/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2233e+00
Epoch 128/200
 - 1s - loss: -3.1894e+00 - val_loss: -3.2235e+00
Epoch 129/200
 - 1s - loss: -3.1906e+00 - val_loss: -3.2234e+00
Epoch 130/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2238e+00
Epoch 131/200
 - 1s - loss: -3.1898e+00 - val_loss: -3.2234e+00
Epoch 132/200
 - 1s - loss: -3.1904e+00 - val_loss: -3.2231e+00
Epoch 133/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2231e+00
Epoch 134/200
 - 1s - loss: -3.1892e+00 - val_loss: -3.2240e+00
Epoch 135/200
 - 1s - loss: -3.1916e+00 - val_loss: -3.2236e+00
Epoch 136/200
 - 1s - loss: -3.1874e+00 - val_loss: -3.2236e+00
Epoch 137/200
 - 1s - loss: -3.1915e+00 - val_loss: -3.2233e+00
Epoch 138/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2240e+00
Epoch 139/200
 - 1s - loss: -3.1918e+00 - val_loss: -3.2238e+00
Epoch 140/200
 - 1s - loss: -3.1914e+00 - val_loss: -3.2237e+00
Epoch 141/200
 - 1s - loss: -3.1891e+00 - val_loss: -3.2234e+00
2019-12-21 10:55:21,479 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_140.pickle
Epoch 142/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2236e+00
Epoch 143/200
 - 1s - loss: -3.1917e+00 - val_loss: -3.2241e+00
Epoch 144/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2233e+00
Epoch 145/200
 - 1s - loss: -3.1925e+00 - val_loss: -3.2243e+00
Epoch 146/200
 - 1s - loss: -3.1909e+00 - val_loss: -3.2240e+00
Epoch 147/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2240e+00
Epoch 148/200
 - 1s - loss: -3.1918e+00 - val_loss: -3.2237e+00
Epoch 149/200
 - 1s - loss: -3.1917e+00 - val_loss: -3.2236e+00
Epoch 150/200
 - 1s - loss: -3.1926e+00 - val_loss: -3.2243e+00
Epoch 151/200
 - 1s - loss: -3.1921e+00 - val_loss: -3.2238e+00
Epoch 152/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2239e+00
Epoch 153/200
 - 1s - loss: -3.1923e+00 - val_loss: -3.2237e+00
Epoch 154/200
 - 1s - loss: -3.1913e+00 - val_loss: -3.2230e+00
Epoch 155/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2243e+00
Epoch 156/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2243e+00
Epoch 157/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2243e+00
Epoch 158/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2245e+00
Epoch 159/200
 - 1s - loss: -3.1923e+00 - val_loss: -3.2240e+00
Epoch 160/200
 - 1s - loss: -3.1925e+00 - val_loss: -3.2240e+00
Epoch 161/200
 - 1s - loss: -3.1936e+00 - val_loss: -3.2243e+00
2019-12-21 10:55:35,913 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_160.pickle
Epoch 162/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2242e+00
Epoch 163/200
 - 1s - loss: -3.1944e+00 - val_loss: -3.2248e+00
Epoch 164/200
 - 1s - loss: -3.1930e+00 - val_loss: -3.2245e+00
Epoch 165/200
 - 1s - loss: -3.1950e+00 - val_loss: -3.2243e+00
Epoch 166/200
 - 1s - loss: -3.1939e+00 - val_loss: -3.2243e+00
Epoch 167/200
 - 1s - loss: -3.1927e+00 - val_loss: -3.2249e+00
Epoch 168/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2248e+00
Epoch 169/200
 - 1s - loss: -3.1952e+00 - val_loss: -3.2247e+00
Epoch 170/200
 - 1s - loss: -3.1941e+00 - val_loss: -3.2250e+00
Epoch 171/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2248e+00
Epoch 172/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2251e+00
Epoch 173/200
 - 1s - loss: -3.1940e+00 - val_loss: -3.2245e+00
Epoch 174/200
 - 1s - loss: -3.1932e+00 - val_loss: -3.2246e+00
Epoch 175/200
 - 1s - loss: -3.1943e+00 - val_loss: -3.2248e+00
Epoch 176/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2248e+00
Epoch 177/200
 - 1s - loss: -3.1945e+00 - val_loss: -3.2245e+00
Epoch 178/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2246e+00
Epoch 179/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2247e+00
Epoch 180/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2245e+00
Epoch 181/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2247e+00
2019-12-21 10:55:50,350 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ae_model_epoch_180.pickle
Epoch 182/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2248e+00
Epoch 183/200
 - 1s - loss: -3.1961e+00 - val_loss: -3.2249e+00
Epoch 184/200
 - 1s - loss: -3.1962e+00 - val_loss: -3.2244e+00
Epoch 185/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2249e+00
Epoch 186/200
 - 1s - loss: -3.1963e+00 - val_loss: -3.2250e+00
Epoch 187/200
 - 1s - loss: -3.1964e+00 - val_loss: -3.2248e+00
Epoch 188/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2248e+00
Epoch 189/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2250e+00
Epoch 190/200
 - 1s - loss: -3.1950e+00 - val_loss: -3.2251e+00
Epoch 191/200
 - 1s - loss: -3.1955e+00 - val_loss: -3.2249e+00
Epoch 192/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2249e+00
Epoch 193/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2254e+00
Epoch 194/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2251e+00
Epoch 195/200
 - 1s - loss: -3.1962e+00 - val_loss: -3.2252e+00
Epoch 196/200
 - 1s - loss: -3.1976e+00 - val_loss: -3.2252e+00
Epoch 197/200
 - 1s - loss: -3.1972e+00 - val_loss: -3.2257e+00
Epoch 198/200
 - 1s - loss: -3.1962e+00 - val_loss: -3.2249e+00
Epoch 199/200
 - 1s - loss: -3.1962e+00 - val_loss: -3.2255e+00
Epoch 200/200
 - 1s - loss: -3.1969e+00 - val_loss: -3.2257e+00
2019-12-21 10:56:04,064 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:56:05,423 [INFO] Last epoch loss evaluation: train_loss = -3.249013, val_loss = -3.225702
2019-12-21 10:56:05,425 [INFO] Training autoencoder complete
2019-12-21 10:56:05,425 [INFO] Encoding data for supervised training
2019-12-21 10:56:06,515 [INFO] Encoding complete
2019-12-21 10:56:06,515 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.2108 - val_loss: 0.0722
 - val_f1: 0.9542
Epoch 2/200
 - 0s - loss: 0.0677 - val_loss: 0.0460
 - val_f1: 0.9684
Epoch 3/200
 - 0s - loss: 0.0488 - val_loss: 0.0358
 - val_f1: 0.9739
Epoch 4/200
 - 0s - loss: 0.0396 - val_loss: 0.0289
 - val_f1: 0.9764
Epoch 5/200
 - 0s - loss: 0.0331 - val_loss: 0.0230
 - val_f1: 0.9778
Epoch 6/200
 - 0s - loss: 0.0281 - val_loss: 0.0199
 - val_f1: 0.9831
Epoch 7/200
 - 0s - loss: 0.0254 - val_loss: 0.0179
 - val_f1: 0.9865
Epoch 8/200
 - 0s - loss: 0.0235 - val_loss: 0.0169
 - val_f1: 0.9858
Epoch 9/200
 - 0s - loss: 0.0223 - val_loss: 0.0160
 - val_f1: 0.9857
Epoch 10/200
 - 0s - loss: 0.0206 - val_loss: 0.0151
 - val_f1: 0.9875
Epoch 11/200
 - 0s - loss: 0.0197 - val_loss: 0.0147
 - val_f1: 0.9878
Epoch 12/200
 - 0s - loss: 0.0189 - val_loss: 0.0139
 - val_f1: 0.9881
Epoch 13/200
 - 0s - loss: 0.0182 - val_loss: 0.0133
 - val_f1: 0.9885
Epoch 14/200
 - 0s - loss: 0.0176 - val_loss: 0.0130
 - val_f1: 0.9903
Epoch 15/200
 - 0s - loss: 0.0165 - val_loss: 0.0124
 - val_f1: 0.9907
Epoch 16/200
 - 0s - loss: 0.0169 - val_loss: 0.0123
 - val_f1: 0.9906
Epoch 17/200
 - 0s - loss: 0.0161 - val_loss: 0.0120
 - val_f1: 0.9901
Epoch 18/200
 - 0s - loss: 0.0154 - val_loss: 0.0119
 - val_f1: 0.9907
Epoch 19/200
 - 0s - loss: 0.0152 - val_loss: 0.0115
 - val_f1: 0.9912
Epoch 20/200
 - 0s - loss: 0.0148 - val_loss: 0.0113
 - val_f1: 0.9912
Epoch 21/200
 - 0s - loss: 0.0147 - val_loss: 0.0114
2019-12-21 10:56:20,692 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_20.pickle
 - val_f1: 0.9918
Epoch 22/200
 - 0s - loss: 0.0143 - val_loss: 0.0117
 - val_f1: 0.9905
Epoch 23/200
 - 0s - loss: 0.0145 - val_loss: 0.0114
 - val_f1: 0.9914
Epoch 24/200
 - 0s - loss: 0.0140 - val_loss: 0.0114
 - val_f1: 0.9920
Epoch 25/200
 - 0s - loss: 0.0131 - val_loss: 0.0110
 - val_f1: 0.9915
Epoch 26/200
 - 0s - loss: 0.0131 - val_loss: 0.0112
 - val_f1: 0.9912
Epoch 27/200
 - 0s - loss: 0.0129 - val_loss: 0.0117
 - val_f1: 0.9905
Epoch 28/200
 - 0s - loss: 0.0134 - val_loss: 0.0108
 - val_f1: 0.9921
Epoch 29/200
 - 0s - loss: 0.0127 - val_loss: 0.0106
 - val_f1: 0.9926
Epoch 30/200
 - 0s - loss: 0.0127 - val_loss: 0.0108
 - val_f1: 0.9915
Epoch 31/200
 - 0s - loss: 0.0122 - val_loss: 0.0108
 - val_f1: 0.9917
Epoch 32/200
 - 0s - loss: 0.0126 - val_loss: 0.0105
 - val_f1: 0.9924
Epoch 33/200
 - 0s - loss: 0.0124 - val_loss: 0.0111
 - val_f1: 0.9911
Epoch 34/200
 - 0s - loss: 0.0119 - val_loss: 0.0108
 - val_f1: 0.9917
Epoch 35/200
 - 0s - loss: 0.0122 - val_loss: 0.0104
 - val_f1: 0.9927
Epoch 36/200
 - 0s - loss: 0.0118 - val_loss: 0.0105
 - val_f1: 0.9927
Epoch 37/200
 - 0s - loss: 0.0118 - val_loss: 0.0108
 - val_f1: 0.9924
Epoch 38/200
 - 0s - loss: 0.0115 - val_loss: 0.0103
 - val_f1: 0.9928
Epoch 39/200
 - 0s - loss: 0.0114 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 40/200
 - 0s - loss: 0.0116 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 41/200
 - 0s - loss: 0.0117 - val_loss: 0.0105
2019-12-21 10:56:32,298 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_40.pickle
 - val_f1: 0.9931
Epoch 42/200
 - 0s - loss: 0.0110 - val_loss: 0.0102
 - val_f1: 0.9929
Epoch 43/200
 - 0s - loss: 0.0110 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 44/200
 - 0s - loss: 0.0109 - val_loss: 0.0100
 - val_f1: 0.9932
Epoch 45/200
 - 0s - loss: 0.0113 - val_loss: 0.0103
 - val_f1: 0.9922
Epoch 46/200
 - 0s - loss: 0.0112 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 47/200
 - 0s - loss: 0.0110 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 48/200
 - 0s - loss: 0.0113 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 49/200
 - 0s - loss: 0.0107 - val_loss: 0.0102
 - val_f1: 0.9924
Epoch 50/200
 - 0s - loss: 0.0102 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 51/200
 - 0s - loss: 0.0102 - val_loss: 0.0100
 - val_f1: 0.9928
Epoch 52/200
 - 0s - loss: 0.0104 - val_loss: 0.0099
 - val_f1: 0.9932
Epoch 53/200
 - 0s - loss: 0.0102 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 54/200
 - 0s - loss: 0.0101 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 55/200
 - 0s - loss: 0.0103 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 56/200
 - 0s - loss: 0.0100 - val_loss: 0.0099
 - val_f1: 0.9936
Epoch 57/200
 - 0s - loss: 0.0099 - val_loss: 0.0096
 - val_f1: 0.9932
Epoch 58/200
 - 0s - loss: 0.0101 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 59/200
 - 0s - loss: 0.0099 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 60/200
 - 0s - loss: 0.0099 - val_loss: 0.0103
 - val_f1: 0.9925
Epoch 61/200
 - 0s - loss: 0.0098 - val_loss: 0.0102
2019-12-21 10:56:43,899 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9924
Epoch 62/200
 - 0s - loss: 0.0100 - val_loss: 0.0093
 - val_f1: 0.9937
Epoch 63/200
 - 0s - loss: 0.0095 - val_loss: 0.0098
 - val_f1: 0.9932
Epoch 64/200
 - 0s - loss: 0.0096 - val_loss: 0.0095
 - val_f1: 0.9940
Epoch 65/200
 - 0s - loss: 0.0092 - val_loss: 0.0095
 - val_f1: 0.9937
Epoch 66/200
 - 0s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9936
Epoch 67/200
 - 0s - loss: 0.0096 - val_loss: 0.0098
 - val_f1: 0.9935
Epoch 68/200
 - 0s - loss: 0.0095 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 69/200
 - 0s - loss: 0.0093 - val_loss: 0.0095
 - val_f1: 0.9938
Epoch 70/200
 - 0s - loss: 0.0096 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 71/200
 - 0s - loss: 0.0097 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 72/200
 - 0s - loss: 0.0092 - val_loss: 0.0092
 - val_f1: 0.9937
Epoch 73/200
 - 0s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9940
Epoch 74/200
 - 0s - loss: 0.0094 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 75/200
 - 0s - loss: 0.0094 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 76/200
 - 0s - loss: 0.0099 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 77/200
 - 0s - loss: 0.0096 - val_loss: 0.0095
 - val_f1: 0.9936
Epoch 78/200
 - 0s - loss: 0.0092 - val_loss: 0.0095
 - val_f1: 0.9938
Epoch 79/200
 - 0s - loss: 0.0095 - val_loss: 0.0100
 - val_f1: 0.9934
Epoch 80/200
 - 0s - loss: 0.0093 - val_loss: 0.0099
 - val_f1: 0.9935
Epoch 81/200
 - 0s - loss: 0.0091 - val_loss: 0.0093
2019-12-21 10:56:55,509 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_80.pickle
 - val_f1: 0.9938
Epoch 82/200
 - 0s - loss: 0.0087 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 83/200
 - 0s - loss: 0.0095 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 84/200
 - 0s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 85/200
 - 0s - loss: 0.0091 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 86/200
 - 0s - loss: 0.0092 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 87/200
 - 0s - loss: 0.0085 - val_loss: 0.0092
 - val_f1: 0.9940
Epoch 88/200
 - 0s - loss: 0.0088 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 89/200
 - 0s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9939
Epoch 90/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 91/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 92/200
 - 0s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 93/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9943
Epoch 94/200
 - 0s - loss: 0.0089 - val_loss: 0.0095
 - val_f1: 0.9940
Epoch 95/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 96/200
 - 0s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 97/200
 - 0s - loss: 0.0085 - val_loss: 0.0095
 - val_f1: 0.9935
Epoch 98/200
 - 0s - loss: 0.0085 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 99/200
 - 0s - loss: 0.0086 - val_loss: 0.0098
 - val_f1: 0.9938
Epoch 100/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 101/200
 - 0s - loss: 0.0083 - val_loss: 0.0092
2019-12-21 10:57:07,119 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_100.pickle
 - val_f1: 0.9941
Epoch 102/200
 - 0s - loss: 0.0088 - val_loss: 0.0091
 - val_f1: 0.9943
Epoch 103/200
 - 0s - loss: 0.0086 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 104/200
 - 0s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 105/200
 - 0s - loss: 0.0086 - val_loss: 0.0092
 - val_f1: 0.9943
Epoch 106/200
 - 0s - loss: 0.0085 - val_loss: 0.0097
 - val_f1: 0.9937
Epoch 107/200
 - 0s - loss: 0.0082 - val_loss: 0.0091
 - val_f1: 0.9941
Epoch 108/200
 - 0s - loss: 0.0087 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 109/200
 - 0s - loss: 0.0084 - val_loss: 0.0095
 - val_f1: 0.9939
Epoch 110/200
 - 0s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9940
Epoch 111/200
 - 0s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 112/200
 - 0s - loss: 0.0081 - val_loss: 0.0093
 - val_f1: 0.9941
Epoch 113/200
 - 0s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 114/200
 - 0s - loss: 0.0082 - val_loss: 0.0092
 - val_f1: 0.9940
Epoch 115/200
 - 0s - loss: 0.0084 - val_loss: 0.0098
 - val_f1: 0.9937
Epoch 116/200
 - 0s - loss: 0.0087 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 117/200
 - 0s - loss: 0.0085 - val_loss: 0.0092
 - val_f1: 0.9939
Epoch 118/200
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9939
Epoch 119/200
 - 0s - loss: 0.0084 - val_loss: 0.0101
 - val_f1: 0.9934
Epoch 120/200
 - 0s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9938
Epoch 121/200
 - 0s - loss: 0.0085 - val_loss: 0.0100
2019-12-21 10:57:18,718 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9935
Epoch 122/200
 - 0s - loss: 0.0085 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 123/200
 - 0s - loss: 0.0082 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 124/200
 - 0s - loss: 0.0085 - val_loss: 0.0099
 - val_f1: 0.9934
Epoch 125/200
 - 0s - loss: 0.0081 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 126/200
 - 0s - loss: 0.0079 - val_loss: 0.0094
 - val_f1: 0.9938
Epoch 127/200
 - 0s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 128/200
 - 0s - loss: 0.0082 - val_loss: 0.0097
 - val_f1: 0.9927
Epoch 129/200
 - 0s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 130/200
 - 0s - loss: 0.0080 - val_loss: 0.0095
 - val_f1: 0.9939
Epoch 131/200
 - 0s - loss: 0.0080 - val_loss: 0.0093
 - val_f1: 0.9938
Epoch 132/200
 - 0s - loss: 0.0081 - val_loss: 0.0095
 - val_f1: 0.9933
Epoch 133/200
 - 0s - loss: 0.0080 - val_loss: 0.0096
 - val_f1: 0.9937
Epoch 134/200
 - 0s - loss: 0.0080 - val_loss: 0.0096
 - val_f1: 0.9935
Epoch 135/200
 - 0s - loss: 0.0082 - val_loss: 0.0096
2019-12-21 10:57:27,102 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 10:57:28,318 [INFO] Last epoch loss evaluation: train_loss = 0.005781, val_loss = 0.009066
2019-12-21 10:57:28,320 [INFO] Training complete. time_to_train = 231.11 sec, 3.85 min
2019-12-21 10:57:28,328 [INFO] Model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep4/best_model.pickle
2019-12-21 10:57:28,516 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep4/training_error_history.png
2019-12-21 10:57:28,697 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep4/training_f1_history.png
2019-12-21 10:57:28,697 [INFO] Making predictions on training, validation, testing data
2019-12-21 10:57:32,253 [INFO] Evaluating predictions (results)
2019-12-21 10:57:32,516 [INFO] Dataset: Testing. Classification report below
2019-12-21 10:57:32,516 [INFO] 
              precision    recall  f1-score   support

         dos       0.95      0.82      0.88      7458
      normal       0.68      0.97      0.80      9711
       probe       0.85      0.67      0.75      2421
         r2l       0.96      0.14      0.24      2421
         u2r       0.72      0.02      0.05       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.83      0.53      0.54     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-21 10:57:32,516 [INFO] Overall accuracy (micro avg): 0.7790099361249113
2019-12-21 10:57:32,814 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7790         0.7790                       0.7790                0.0552                   0.2210  0.7790
1     Macro avg        0.9116         0.8338                       0.5255                0.0752                   0.4745  0.5446
2  Weighted avg        0.8720         0.8207                       0.7790                0.1550                   0.2210  0.7456
2019-12-21 10:57:33,147 [INFO] Dataset: Validation. Classification report below
2019-12-21 10:57:33,147 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.89      0.80      0.84       199
         u2r       0.50      0.30      0.37        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.87      0.82      0.84     25195
weighted avg       0.99      0.99      0.99     25195

2019-12-21 10:57:33,148 [INFO] Overall accuracy (micro avg): 0.9938479857114507
2019-12-21 10:57:33,505 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9938         0.9938                       0.9938                0.0015                   0.0062  0.9938
1     Macro avg        0.9975         0.8740                       0.8158                0.0020                   0.1842  0.8394
2  Weighted avg        0.9963         0.9937                       0.9938                0.0040                   0.0062  0.9937
2019-12-21 10:57:34,950 [INFO] Dataset: Training. Classification report below
2019-12-21 10:57:34,950 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.91      0.78      0.84       796
         u2r       0.69      0.43      0.53        42

   micro avg       0.99      0.99      0.99    100778
   macro avg       0.92      0.84      0.87    100778
weighted avg       0.99      0.99      0.99    100778

2019-12-21 10:57:34,950 [INFO] Overall accuracy (micro avg): 0.9944134632558693
2019-12-21 10:57:36,572 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9944         0.9944                       0.9944                0.0014                   0.0056  0.9944
1     Macro avg        0.9978         0.9170                       0.8386                0.0020                   0.1614  0.8706
2  Weighted avg        0.9966         0.9943                       0.9944                0.0042                   0.0056  0.9943
2019-12-21 10:57:36,610 [INFO] Results saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep4/selected_nsl_ae_ann_shallow_rep4_results.xlsx
2019-12-21 10:57:36,610 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-21 10:57:36,613 [INFO] Created directory: results_selected_models/selected_nsl_ae_ann_shallow_rep5
2019-12-21 10:57:36,613 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_ae_ann_shallow_rep5/run_log.log
2019-12-21 10:57:36,613 [INFO] ================= Running experiment no. 5  ================= 

2019-12-21 10:57:36,613 [INFO] Experiment parameters given below
2019-12-21 10:57:36,614 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_nsl_ae_ann_shallow_rep5', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_ae_ann_shallow_rep5'}
2019-12-21 10:57:36,614 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_ae_ann_shallow_rep5/tf_logs_run_2019_12_21-10_57_36
2019-12-21 10:57:36,614 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-21 10:57:36,614 [INFO] Reading X, y files
2019-12-21 10:57:36,614 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-21 10:57:36,863 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-21 10:57:36,863 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-21 10:57:36,926 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:57:36,926 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-21 10:57:36,982 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 10:57:36,983 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-21 10:57:36,990 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-21 10:57:36,990 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-21 10:57:36,994 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:57:36,994 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-21 10:57:36,997 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-21 10:57:37,177 [INFO] Initializing model
2019-12-21 10:57:37,286 [INFO] _________________________________________________________________
2019-12-21 10:57:37,286 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:57:37,286 [INFO] =================================================================
2019-12-21 10:57:37,286 [INFO] dense_17 (Dense)             (None, 32)                3936      
2019-12-21 10:57:37,286 [INFO] _________________________________________________________________
2019-12-21 10:57:37,287 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-21 10:57:37,287 [INFO] _________________________________________________________________
2019-12-21 10:57:37,287 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-21 10:57:37,287 [INFO] _________________________________________________________________
2019-12-21 10:57:37,287 [INFO] dense_18 (Dense)             (None, 122)               4026      
2019-12-21 10:57:37,287 [INFO] =================================================================
2019-12-21 10:57:37,287 [INFO] Total params: 8,090
2019-12-21 10:57:37,287 [INFO] Trainable params: 8,026
2019-12-21 10:57:37,287 [INFO] Non-trainable params: 64
2019-12-21 10:57:37,287 [INFO] _________________________________________________________________
2019-12-21 10:57:37,395 [INFO] _________________________________________________________________
2019-12-21 10:57:37,396 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 10:57:37,396 [INFO] =================================================================
2019-12-21 10:57:37,396 [INFO] dense_19 (Dense)             (None, 32)                1056      
2019-12-21 10:57:37,396 [INFO] _________________________________________________________________
2019-12-21 10:57:37,396 [INFO] batch_normalization_10 (Batc (None, 32)                128       
2019-12-21 10:57:37,396 [INFO] _________________________________________________________________
2019-12-21 10:57:37,396 [INFO] dropout_10 (Dropout)         (None, 32)                0         
2019-12-21 10:57:37,396 [INFO] _________________________________________________________________
2019-12-21 10:57:37,396 [INFO] dense_20 (Dense)             (None, 5)                 165       
2019-12-21 10:57:37,396 [INFO] =================================================================
2019-12-21 10:57:37,397 [INFO] Total params: 1,349
2019-12-21 10:57:37,397 [INFO] Trainable params: 1,285
2019-12-21 10:57:37,397 [INFO] Non-trainable params: 64
2019-12-21 10:57:37,397 [INFO] _________________________________________________________________
2019-12-21 10:57:37,397 [INFO] Training model
2019-12-21 10:57:37,397 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 10:57:37,997 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389
2019-12-21 10:57:37,997 [INFO] Training autoencoder
 - val_f1: 0.9938
Epoch 00135: early stopping
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.3249 - val_loss: -2.2597e-01
Epoch 2/200
 - 1s - loss: -6.7658e-01 - val_loss: -1.2538e+00
Epoch 3/200
 - 1s - loss: -1.5774e+00 - val_loss: -2.0167e+00
Epoch 4/200
 - 1s - loss: -2.2152e+00 - val_loss: -2.5582e+00
Epoch 5/200
 - 1s - loss: -2.5784e+00 - val_loss: -2.8251e+00
Epoch 6/200
 - 1s - loss: -2.7720e+00 - val_loss: -2.9703e+00
Epoch 7/200
 - 1s - loss: -2.8801e+00 - val_loss: -3.0492e+00
Epoch 8/200
 - 1s - loss: -2.9437e+00 - val_loss: -3.0919e+00
Epoch 9/200
 - 1s - loss: -2.9873e+00 - val_loss: -3.1210e+00
Epoch 10/200
 - 1s - loss: -3.0174e+00 - val_loss: -3.1408e+00
Epoch 11/200
 - 1s - loss: -3.0376e+00 - val_loss: -3.1539e+00
Epoch 12/200
 - 1s - loss: -3.0569e+00 - val_loss: -3.1643e+00
Epoch 13/200
 - 1s - loss: -3.0715e+00 - val_loss: -3.1724e+00
Epoch 14/200
 - 1s - loss: -3.0825e+00 - val_loss: -3.1790e+00
Epoch 15/200
 - 1s - loss: -3.0917e+00 - val_loss: -3.1832e+00
Epoch 16/200
 - 1s - loss: -3.0980e+00 - val_loss: -3.1879e+00
Epoch 17/200
 - 1s - loss: -3.1065e+00 - val_loss: -3.1908e+00
Epoch 18/200
 - 1s - loss: -3.1127e+00 - val_loss: -3.1938e+00
Epoch 19/200
 - 1s - loss: -3.1163e+00 - val_loss: -3.1965e+00
Epoch 20/200
 - 1s - loss: -3.1210e+00 - val_loss: -3.1983e+00
Epoch 21/200
 - 1s - loss: -3.1251e+00 - val_loss: -3.2011e+00
2019-12-21 10:57:55,631 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_20.pickle
Epoch 22/200
 - 1s - loss: -3.1285e+00 - val_loss: -3.2020e+00
Epoch 23/200
 - 1s - loss: -3.1313e+00 - val_loss: -3.2042e+00
Epoch 24/200
 - 1s - loss: -3.1344e+00 - val_loss: -3.2055e+00
Epoch 25/200
 - 1s - loss: -3.1380e+00 - val_loss: -3.2066e+00
Epoch 26/200
 - 1s - loss: -3.1417e+00 - val_loss: -3.2078e+00
Epoch 27/200
 - 1s - loss: -3.1412e+00 - val_loss: -3.2084e+00
Epoch 28/200
 - 1s - loss: -3.1455e+00 - val_loss: -3.2096e+00
Epoch 29/200
 - 1s - loss: -3.1463e+00 - val_loss: -3.2104e+00
Epoch 30/200
 - 1s - loss: -3.1497e+00 - val_loss: -3.2114e+00
Epoch 31/200
 - 1s - loss: -3.1505e+00 - val_loss: -3.2126e+00
Epoch 32/200
 - 1s - loss: -3.1512e+00 - val_loss: -3.2124e+00
Epoch 33/200
 - 1s - loss: -3.1548e+00 - val_loss: -3.2126e+00
Epoch 34/200
 - 1s - loss: -3.1551e+00 - val_loss: -3.2132e+00
Epoch 35/200
 - 1s - loss: -3.1568e+00 - val_loss: -3.2139e+00
Epoch 36/200
 - 1s - loss: -3.1569e+00 - val_loss: -3.2149e+00
Epoch 37/200
 - 1s - loss: -3.1583e+00 - val_loss: -3.2152e+00
Epoch 38/200
 - 1s - loss: -3.1587e+00 - val_loss: -3.2149e+00
Epoch 39/200
 - 1s - loss: -3.1609e+00 - val_loss: -3.2152e+00
Epoch 40/200
 - 1s - loss: -3.1608e+00 - val_loss: -3.2158e+00
Epoch 41/200
 - 1s - loss: -3.1621e+00 - val_loss: -3.2163e+00
2019-12-21 10:58:10,145 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_40.pickle
Epoch 42/200
 - 1s - loss: -3.1636e+00 - val_loss: -3.2169e+00
Epoch 43/200
 - 1s - loss: -3.1645e+00 - val_loss: -3.2174e+00
Epoch 44/200
 - 1s - loss: -3.1645e+00 - val_loss: -3.2171e+00
Epoch 45/200
 - 1s - loss: -3.1638e+00 - val_loss: -3.2177e+00
Epoch 46/200
 - 1s - loss: -3.1663e+00 - val_loss: -3.2174e+00
Epoch 47/200
 - 1s - loss: -3.1662e+00 - val_loss: -3.2179e+00
Epoch 48/200
 - 1s - loss: -3.1678e+00 - val_loss: -3.2189e+00
Epoch 49/200
 - 1s - loss: -3.1690e+00 - val_loss: -3.2189e+00
Epoch 50/200
 - 1s - loss: -3.1683e+00 - val_loss: -3.2186e+00
Epoch 51/200
 - 1s - loss: -3.1697e+00 - val_loss: -3.2189e+00
Epoch 52/200
 - 1s - loss: -3.1696e+00 - val_loss: -3.2190e+00
Epoch 53/200
 - 1s - loss: -3.1713e+00 - val_loss: -3.2189e+00
Epoch 54/200
 - 1s - loss: -3.1703e+00 - val_loss: -3.2190e+00
Epoch 55/200
 - 1s - loss: -3.1716e+00 - val_loss: -3.2196e+00
Epoch 56/200
 - 1s - loss: -3.1701e+00 - val_loss: -3.2189e+00
Epoch 57/200
 - 1s - loss: -3.1719e+00 - val_loss: -3.2200e+00
Epoch 58/200
 - 1s - loss: -3.1718e+00 - val_loss: -3.2201e+00
Epoch 59/200
 - 1s - loss: -3.1724e+00 - val_loss: -3.2205e+00
Epoch 60/200
 - 1s - loss: -3.1734e+00 - val_loss: -3.2202e+00
Epoch 61/200
 - 1s - loss: -3.1746e+00 - val_loss: -3.2204e+00
2019-12-21 10:58:24,641 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_60.pickle
Epoch 62/200
 - 1s - loss: -3.1724e+00 - val_loss: -3.2210e+00
Epoch 63/200
 - 1s - loss: -3.1743e+00 - val_loss: -3.2213e+00
Epoch 64/200
 - 1s - loss: -3.1753e+00 - val_loss: -3.2214e+00
Epoch 65/200
 - 1s - loss: -3.1758e+00 - val_loss: -3.2213e+00
Epoch 66/200
 - 1s - loss: -3.1761e+00 - val_loss: -3.2210e+00
Epoch 67/200
 - 1s - loss: -3.1755e+00 - val_loss: -3.2213e+00
Epoch 68/200
 - 1s - loss: -3.1779e+00 - val_loss: -3.2215e+00
Epoch 69/200
 - 1s - loss: -3.1786e+00 - val_loss: -3.2212e+00
Epoch 70/200
 - 1s - loss: -3.1774e+00 - val_loss: -3.2222e+00
Epoch 71/200
 - 1s - loss: -3.1771e+00 - val_loss: -3.2213e+00
Epoch 72/200
 - 1s - loss: -3.1783e+00 - val_loss: -3.2212e+00
Epoch 73/200
 - 1s - loss: -3.1788e+00 - val_loss: -3.2221e+00
Epoch 74/200
 - 1s - loss: -3.1771e+00 - val_loss: -3.2215e+00
Epoch 75/200
 - 1s - loss: -3.1773e+00 - val_loss: -3.2216e+00
Epoch 76/200
 - 1s - loss: -3.1792e+00 - val_loss: -3.2215e+00
Epoch 77/200
 - 1s - loss: -3.1796e+00 - val_loss: -3.2218e+00
Epoch 78/200
 - 1s - loss: -3.1794e+00 - val_loss: -3.2226e+00
Epoch 79/200
 - 1s - loss: -3.1817e+00 - val_loss: -3.2224e+00
Epoch 80/200
 - 1s - loss: -3.1793e+00 - val_loss: -3.2222e+00
Epoch 81/200
 - 1s - loss: -3.1816e+00 - val_loss: -3.2223e+00
2019-12-21 10:58:39,162 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_80.pickle
Epoch 82/200
 - 1s - loss: -3.1805e+00 - val_loss: -3.2225e+00
Epoch 83/200
 - 1s - loss: -3.1809e+00 - val_loss: -3.2221e+00
Epoch 84/200
 - 1s - loss: -3.1815e+00 - val_loss: -3.2222e+00
Epoch 85/200
 - 1s - loss: -3.1822e+00 - val_loss: -3.2234e+00
Epoch 86/200
 - 1s - loss: -3.1805e+00 - val_loss: -3.2233e+00
Epoch 87/200
 - 1s - loss: -3.1804e+00 - val_loss: -3.2225e+00
Epoch 88/200
 - 1s - loss: -3.1836e+00 - val_loss: -3.2230e+00
Epoch 89/200
 - 1s - loss: -3.1841e+00 - val_loss: -3.2227e+00
Epoch 90/200
 - 1s - loss: -3.1828e+00 - val_loss: -3.2229e+00
Epoch 91/200
 - 1s - loss: -3.1839e+00 - val_loss: -3.2222e+00
Epoch 92/200
 - 1s - loss: -3.1834e+00 - val_loss: -3.2216e+00
Epoch 93/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2228e+00
Epoch 94/200
 - 1s - loss: -3.1841e+00 - val_loss: -3.2235e+00
Epoch 95/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2241e+00
Epoch 96/200
 - 1s - loss: -3.1835e+00 - val_loss: -3.2233e+00
Epoch 97/200
 - 1s - loss: -3.1838e+00 - val_loss: -3.2232e+00
Epoch 98/200
 - 1s - loss: -3.1852e+00 - val_loss: -3.2221e+00
Epoch 99/200
 - 1s - loss: -3.1840e+00 - val_loss: -3.2219e+00
Epoch 100/200
 - 1s - loss: -3.1846e+00 - val_loss: -3.2227e+00
Epoch 101/200
 - 1s - loss: -3.1852e+00 - val_loss: -3.2223e+00
2019-12-21 10:58:53,615 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_100.pickle
Epoch 102/200
 - 1s - loss: -3.1842e+00 - val_loss: -3.2214e+00
Epoch 103/200
 - 1s - loss: -3.1868e+00 - val_loss: -3.2234e+00
Epoch 104/200
 - 1s - loss: -3.1854e+00 - val_loss: -3.2223e+00
Epoch 105/200
 - 1s - loss: -3.1853e+00 - val_loss: -3.2230e+00
Epoch 106/200
 - 1s - loss: -3.1842e+00 - val_loss: -3.2203e+00
Epoch 107/200
 - 1s - loss: -3.1865e+00 - val_loss: -3.2206e+00
Epoch 108/200
 - 1s - loss: -3.1844e+00 - val_loss: -3.2197e+00
Epoch 109/200
 - 1s - loss: -3.1849e+00 - val_loss: -3.2201e+00
Epoch 110/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2201e+00
Epoch 111/200
 - 1s - loss: -3.1843e+00 - val_loss: -3.2228e+00
Epoch 112/200
 - 1s - loss: -3.1866e+00 - val_loss: -3.2241e+00
Epoch 113/200
 - 1s - loss: -3.1879e+00 - val_loss: -3.2241e+00
Epoch 114/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2234e+00
Epoch 115/200
 - 1s - loss: -3.1871e+00 - val_loss: -3.2237e+00
Epoch 116/200
 - 1s - loss: -3.1881e+00 - val_loss: -3.2240e+00
Epoch 117/200
 - 1s - loss: -3.1874e+00 - val_loss: -3.2238e+00
Epoch 118/200
 - 1s - loss: -3.1884e+00 - val_loss: -3.2244e+00
Epoch 119/200
 - 1s - loss: -3.1881e+00 - val_loss: -3.2244e+00
Epoch 120/200
 - 1s - loss: -3.1893e+00 - val_loss: -3.2244e+00
Epoch 121/200
 - 1s - loss: -3.1884e+00 - val_loss: -3.2239e+00
2019-12-21 10:59:08,092 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_120.pickle
Epoch 122/200
 - 1s - loss: -3.1876e+00 - val_loss: -3.2234e+00
Epoch 123/200
 - 1s - loss: -3.1894e+00 - val_loss: -3.2243e+00
Epoch 124/200
 - 1s - loss: -3.1880e+00 - val_loss: -3.2247e+00
Epoch 125/200
 - 1s - loss: -3.1891e+00 - val_loss: -3.2242e+00
Epoch 126/200
 - 1s - loss: -3.1886e+00 - val_loss: -3.2246e+00
Epoch 127/200
 - 1s - loss: -3.1883e+00 - val_loss: -3.2245e+00
Epoch 128/200
 - 1s - loss: -3.1886e+00 - val_loss: -3.2244e+00
Epoch 129/200
 - 1s - loss: -3.1902e+00 - val_loss: -3.2242e+00
Epoch 130/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2252e+00
Epoch 131/200
 - 1s - loss: -3.1909e+00 - val_loss: -3.2243e+00
Epoch 132/200
 - 1s - loss: -3.1897e+00 - val_loss: -3.2247e+00
Epoch 133/200
 - 1s - loss: -3.1905e+00 - val_loss: -3.2254e+00
Epoch 134/200
 - 1s - loss: -3.1904e+00 - val_loss: -3.2254e+00
Epoch 135/200
 - 1s - loss: -3.1903e+00 - val_loss: -3.2257e+00
Epoch 136/200
 - 1s - loss: -3.1900e+00 - val_loss: -3.2252e+00
Epoch 137/200
 - 1s - loss: -3.1889e+00 - val_loss: -3.2254e+00
Epoch 138/200
 - 1s - loss: -3.1909e+00 - val_loss: -3.2251e+00
Epoch 139/200
 - 1s - loss: -3.1906e+00 - val_loss: -3.2249e+00
Epoch 140/200
 - 1s - loss: -3.1908e+00 - val_loss: -3.2254e+00
Epoch 141/200
 - 1s - loss: -3.1901e+00 - val_loss: -3.2258e+00
2019-12-21 10:59:22,571 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_140.pickle
Epoch 142/200
 - 1s - loss: -3.1918e+00 - val_loss: -3.2249e+00
Epoch 143/200
 - 1s - loss: -3.1911e+00 - val_loss: -3.2255e+00
Epoch 144/200
 - 1s - loss: -3.1919e+00 - val_loss: -3.2252e+00
Epoch 145/200
 - 1s - loss: -3.1917e+00 - val_loss: -3.2256e+00
Epoch 146/200
 - 1s - loss: -3.1912e+00 - val_loss: -3.2259e+00
Epoch 147/200
 - 1s - loss: -3.1906e+00 - val_loss: -3.2263e+00
Epoch 148/200
 - 1s - loss: -3.1921e+00 - val_loss: -3.2256e+00
Epoch 149/200
 - 1s - loss: -3.1920e+00 - val_loss: -3.2260e+00
Epoch 150/200
 - 1s - loss: -3.1918e+00 - val_loss: -3.2263e+00
Epoch 151/200
 - 1s - loss: -3.1922e+00 - val_loss: -3.2263e+00
Epoch 152/200
 - 1s - loss: -3.1936e+00 - val_loss: -3.2265e+00
Epoch 153/200
 - 1s - loss: -3.1917e+00 - val_loss: -3.2262e+00
Epoch 154/200
 - 1s - loss: -3.1923e+00 - val_loss: -3.2264e+00
Epoch 155/200
 - 1s - loss: -3.1927e+00 - val_loss: -3.2260e+00
Epoch 156/200
 - 1s - loss: -3.1933e+00 - val_loss: -3.2266e+00
Epoch 157/200
 - 1s - loss: -3.1932e+00 - val_loss: -3.2264e+00
Epoch 158/200
 - 1s - loss: -3.1923e+00 - val_loss: -3.2269e+00
Epoch 159/200
 - 1s - loss: -3.1915e+00 - val_loss: -3.2266e+00
Epoch 160/200
 - 1s - loss: -3.1929e+00 - val_loss: -3.2273e+00
Epoch 161/200
 - 1s - loss: -3.1904e+00 - val_loss: -3.2264e+00
2019-12-21 10:59:37,053 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_160.pickle
Epoch 162/200
 - 1s - loss: -3.1924e+00 - val_loss: -3.2274e+00
Epoch 163/200
 - 1s - loss: -3.1919e+00 - val_loss: -3.2266e+00
Epoch 164/200
 - 1s - loss: -3.1935e+00 - val_loss: -3.2263e+00
Epoch 165/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2268e+00
Epoch 166/200
 - 1s - loss: -3.1935e+00 - val_loss: -3.2261e+00
Epoch 167/200
 - 1s - loss: -3.1927e+00 - val_loss: -3.2261e+00
Epoch 168/200
 - 1s - loss: -3.1932e+00 - val_loss: -3.2267e+00
Epoch 169/200
 - 1s - loss: -3.1939e+00 - val_loss: -3.2254e+00
Epoch 170/200
 - 1s - loss: -3.1937e+00 - val_loss: -3.2271e+00
Epoch 171/200
 - 1s - loss: -3.1935e+00 - val_loss: -3.2278e+00
Epoch 172/200
 - 1s - loss: -3.1951e+00 - val_loss: -3.2274e+00
Epoch 173/200
 - 1s - loss: -3.1940e+00 - val_loss: -3.2272e+00
Epoch 174/200
 - 1s - loss: -3.1938e+00 - val_loss: -3.2264e+00
Epoch 175/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2257e+00
Epoch 176/200
 - 1s - loss: -3.1939e+00 - val_loss: -3.2269e+00
Epoch 177/200
 - 1s - loss: -3.1946e+00 - val_loss: -3.2277e+00
Epoch 178/200
 - 1s - loss: -3.1955e+00 - val_loss: -3.2274e+00
Epoch 179/200
 - 1s - loss: -3.1953e+00 - val_loss: -3.2276e+00
Epoch 180/200
 - 1s - loss: -3.1952e+00 - val_loss: -3.2260e+00
Epoch 181/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2259e+00
2019-12-21 10:59:51,547 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ae_model_epoch_180.pickle
Epoch 182/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2271e+00
Epoch 183/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2262e+00
Epoch 184/200
 - 1s - loss: -3.1955e+00 - val_loss: -3.2256e+00
Epoch 185/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2278e+00
Epoch 186/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2274e+00
Epoch 187/200
 - 1s - loss: -3.1955e+00 - val_loss: -3.2272e+00
Epoch 188/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2280e+00
Epoch 189/200
 - 1s - loss: -3.1942e+00 - val_loss: -3.2276e+00
Epoch 190/200
 - 1s - loss: -3.1947e+00 - val_loss: -3.2276e+00
Epoch 191/200
 - 1s - loss: -3.1958e+00 - val_loss: -3.2270e+00
Epoch 192/200
 - 1s - loss: -3.1948e+00 - val_loss: -3.2280e+00
Epoch 193/200
 - 1s - loss: -3.1959e+00 - val_loss: -3.2278e+00
Epoch 194/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2280e+00
Epoch 195/200
 - 1s - loss: -3.1949e+00 - val_loss: -3.2274e+00
Epoch 196/200
 - 1s - loss: -3.1956e+00 - val_loss: -3.2277e+00
Epoch 197/200
 - 1s - loss: -3.1957e+00 - val_loss: -3.2269e+00
Epoch 198/200
 - 1s - loss: -3.1950e+00 - val_loss: -3.2274e+00
Epoch 199/200
 - 1s - loss: -3.1954e+00 - val_loss: -3.2271e+00
Epoch 200/200
 - 1s - loss: -3.1968e+00 - val_loss: -3.2276e+00
2019-12-21 11:00:05,299 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 11:00:06,781 [INFO] Last epoch loss evaluation: train_loss = -3.248615, val_loss = -3.227970
2019-12-21 11:00:06,783 [INFO] Training autoencoder complete
2019-12-21 11:00:06,784 [INFO] Encoding data for supervised training
2019-12-21 11:00:08,040 [INFO] Encoding complete
2019-12-21 11:00:08,040 [INFO] Training neural network layers (after autoencoder)
Train on 50389 samples, validate on 25195 samples
Epoch 1/200
 - 1s - loss: 0.1882 - val_loss: 0.0648
 - val_f1: 0.9595
Epoch 2/200
 - 0s - loss: 0.0633 - val_loss: 0.0424
 - val_f1: 0.9710
Epoch 3/200
 - 0s - loss: 0.0474 - val_loss: 0.0336
 - val_f1: 0.9762
Epoch 4/200
 - 0s - loss: 0.0394 - val_loss: 0.0279
 - val_f1: 0.9768
Epoch 5/200
 - 0s - loss: 0.0330 - val_loss: 0.0233
 - val_f1: 0.9788
Epoch 6/200
 - 0s - loss: 0.0284 - val_loss: 0.0194
 - val_f1: 0.9846
Epoch 7/200
 - 0s - loss: 0.0258 - val_loss: 0.0176
 - val_f1: 0.9865
Epoch 8/200
 - 0s - loss: 0.0240 - val_loss: 0.0163
 - val_f1: 0.9890
Epoch 9/200
 - 0s - loss: 0.0217 - val_loss: 0.0151
 - val_f1: 0.9891
Epoch 10/200
 - 0s - loss: 0.0201 - val_loss: 0.0138
 - val_f1: 0.9904
Epoch 11/200
 - 0s - loss: 0.0194 - val_loss: 0.0139
 - val_f1: 0.9898
Epoch 12/200
 - 0s - loss: 0.0178 - val_loss: 0.0134
 - val_f1: 0.9905
Epoch 13/200
 - 0s - loss: 0.0169 - val_loss: 0.0128
 - val_f1: 0.9911
Epoch 14/200
 - 0s - loss: 0.0168 - val_loss: 0.0126
 - val_f1: 0.9913
Epoch 15/200
 - 0s - loss: 0.0162 - val_loss: 0.0127
 - val_f1: 0.9899
Epoch 16/200
 - 0s - loss: 0.0152 - val_loss: 0.0123
 - val_f1: 0.9914
Epoch 17/200
 - 0s - loss: 0.0152 - val_loss: 0.0123
 - val_f1: 0.9905
Epoch 18/200
 - 0s - loss: 0.0154 - val_loss: 0.0120
 - val_f1: 0.9911
Epoch 19/200
 - 0s - loss: 0.0147 - val_loss: 0.0120
 - val_f1: 0.9903
Epoch 20/200
 - 0s - loss: 0.0146 - val_loss: 0.0121
 - val_f1: 0.9900
Epoch 21/200
 - 0s - loss: 0.0142 - val_loss: 0.0118
2019-12-21 11:00:23,512 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_20.pickle
 - val_f1: 0.9910
Epoch 22/200
 - 0s - loss: 0.0135 - val_loss: 0.0114
 - val_f1: 0.9921
Epoch 23/200
 - 0s - loss: 0.0142 - val_loss: 0.0115
 - val_f1: 0.9918
Epoch 24/200
 - 0s - loss: 0.0139 - val_loss: 0.0112
 - val_f1: 0.9921
Epoch 25/200
 - 0s - loss: 0.0131 - val_loss: 0.0112
 - val_f1: 0.9923
Epoch 26/200
 - 0s - loss: 0.0129 - val_loss: 0.0112
 - val_f1: 0.9924
Epoch 27/200
 - 0s - loss: 0.0129 - val_loss: 0.0113
 - val_f1: 0.9918
Epoch 28/200
 - 0s - loss: 0.0127 - val_loss: 0.0112
 - val_f1: 0.9921
Epoch 29/200
 - 0s - loss: 0.0125 - val_loss: 0.0110
 - val_f1: 0.9908
Epoch 30/200
 - 0s - loss: 0.0125 - val_loss: 0.0108
 - val_f1: 0.9925
Epoch 31/200
 - 0s - loss: 0.0123 - val_loss: 0.0109
 - val_f1: 0.9925
Epoch 32/200
 - 0s - loss: 0.0116 - val_loss: 0.0109
 - val_f1: 0.9922
Epoch 33/200
 - 0s - loss: 0.0125 - val_loss: 0.0107
 - val_f1: 0.9928
Epoch 34/200
 - 0s - loss: 0.0119 - val_loss: 0.0108
 - val_f1: 0.9924
Epoch 35/200
 - 0s - loss: 0.0118 - val_loss: 0.0108
 - val_f1: 0.9922
Epoch 36/200
 - 0s - loss: 0.0116 - val_loss: 0.0109
 - val_f1: 0.9925
Epoch 37/200
 - 0s - loss: 0.0113 - val_loss: 0.0107
 - val_f1: 0.9929
Epoch 38/200
 - 0s - loss: 0.0115 - val_loss: 0.0107
 - val_f1: 0.9927
Epoch 39/200
 - 0s - loss: 0.0111 - val_loss: 0.0106
 - val_f1: 0.9929
Epoch 40/200
 - 0s - loss: 0.0110 - val_loss: 0.0105
 - val_f1: 0.9929
Epoch 41/200
 - 0s - loss: 0.0115 - val_loss: 0.0104
2019-12-21 11:00:35,927 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_40.pickle
 - val_f1: 0.9931
Epoch 42/200
 - 0s - loss: 0.0113 - val_loss: 0.0108
 - val_f1: 0.9921
Epoch 43/200
 - 0s - loss: 0.0110 - val_loss: 0.0106
 - val_f1: 0.9924
Epoch 44/200
 - 0s - loss: 0.0111 - val_loss: 0.0106
 - val_f1: 0.9924
Epoch 45/200
 - 0s - loss: 0.0111 - val_loss: 0.0108
 - val_f1: 0.9929
Epoch 46/200
 - 0s - loss: 0.0109 - val_loss: 0.0105
 - val_f1: 0.9927
Epoch 47/200
 - 0s - loss: 0.0108 - val_loss: 0.0110
 - val_f1: 0.9921
Epoch 48/200
 - 0s - loss: 0.0112 - val_loss: 0.0105
 - val_f1: 0.9928
Epoch 49/200
 - 0s - loss: 0.0109 - val_loss: 0.0105
 - val_f1: 0.9921
Epoch 50/200
 - 0s - loss: 0.0105 - val_loss: 0.0105
 - val_f1: 0.9923
Epoch 51/200
 - 0s - loss: 0.0102 - val_loss: 0.0102
 - val_f1: 0.9931
Epoch 52/200
 - 0s - loss: 0.0106 - val_loss: 0.0108
 - val_f1: 0.9925
Epoch 53/200
 - 0s - loss: 0.0104 - val_loss: 0.0108
 - val_f1: 0.9923
Epoch 54/200
 - 0s - loss: 0.0107 - val_loss: 0.0106
 - val_f1: 0.9919
Epoch 55/200
 - 0s - loss: 0.0106 - val_loss: 0.0107
 - val_f1: 0.9924
Epoch 56/200
 - 0s - loss: 0.0105 - val_loss: 0.0102
 - val_f1: 0.9926
Epoch 57/200
 - 0s - loss: 0.0102 - val_loss: 0.0101
 - val_f1: 0.9925
Epoch 58/200
 - 0s - loss: 0.0097 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 59/200
 - 0s - loss: 0.0104 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 60/200
 - 0s - loss: 0.0100 - val_loss: 0.0103
 - val_f1: 0.9930
Epoch 61/200
 - 0s - loss: 0.0097 - val_loss: 0.0103
2019-12-21 11:00:48,242 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9928
Epoch 62/200
 - 0s - loss: 0.0096 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 63/200
 - 0s - loss: 0.0102 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 64/200
 - 0s - loss: 0.0098 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 65/200
 - 0s - loss: 0.0098 - val_loss: 0.0102
 - val_f1: 0.9922
Epoch 66/200
 - 0s - loss: 0.0097 - val_loss: 0.0104
 - val_f1: 0.9920
Epoch 67/200
 - 0s - loss: 0.0099 - val_loss: 0.0103
 - val_f1: 0.9929
Epoch 68/200
 - 0s - loss: 0.0098 - val_loss: 0.0101
 - val_f1: 0.9932
Epoch 69/200
 - 0s - loss: 0.0096 - val_loss: 0.0101
 - val_f1: 0.9933
Epoch 70/200
 - 0s - loss: 0.0091 - val_loss: 0.0099
 - val_f1: 0.9927
Epoch 71/200
 - 0s - loss: 0.0095 - val_loss: 0.0101
 - val_f1: 0.9929
Epoch 72/200
 - 0s - loss: 0.0093 - val_loss: 0.0101
 - val_f1: 0.9930
Epoch 73/200
 - 0s - loss: 0.0095 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 74/200
 - 0s - loss: 0.0093 - val_loss: 0.0099
 - val_f1: 0.9922
Epoch 75/200
 - 0s - loss: 0.0096 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 76/200
 - 0s - loss: 0.0096 - val_loss: 0.0103
 - val_f1: 0.9932
Epoch 77/200
 - 0s - loss: 0.0093 - val_loss: 0.0099
 - val_f1: 0.9928
Epoch 78/200
 - 0s - loss: 0.0095 - val_loss: 0.0100
 - val_f1: 0.9929
Epoch 79/200
 - 0s - loss: 0.0096 - val_loss: 0.0099
 - val_f1: 0.9930
Epoch 80/200
 - 0s - loss: 0.0090 - val_loss: 0.0100
 - val_f1: 0.9928
Epoch 81/200
 - 0s - loss: 0.0089 - val_loss: 0.0102
2019-12-21 11:01:00,647 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_80.pickle
 - val_f1: 0.9924
Epoch 82/200
 - 0s - loss: 0.0088 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 83/200
 - 0s - loss: 0.0092 - val_loss: 0.0104
 - val_f1: 0.9925
Epoch 84/200
 - 0s - loss: 0.0091 - val_loss: 0.0100
 - val_f1: 0.9936
Epoch 85/200
 - 0s - loss: 0.0091 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 86/200
 - 0s - loss: 0.0093 - val_loss: 0.0105
 - val_f1: 0.9927
Epoch 87/200
 - 0s - loss: 0.0091 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 88/200
 - 0s - loss: 0.0090 - val_loss: 0.0101
 - val_f1: 0.9933
Epoch 89/200
 - 0s - loss: 0.0093 - val_loss: 0.0102
 - val_f1: 0.9927
Epoch 90/200
 - 0s - loss: 0.0093 - val_loss: 0.0103
 - val_f1: 0.9924
Epoch 91/200
 - 0s - loss: 0.0090 - val_loss: 0.0100
 - val_f1: 0.9932
Epoch 92/200
 - 0s - loss: 0.0091 - val_loss: 0.0101
 - val_f1: 0.9931
Epoch 93/200
 - 0s - loss: 0.0088 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 94/200
 - 0s - loss: 0.0089 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 95/200
 - 0s - loss: 0.0092 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 96/200
 - 0s - loss: 0.0088 - val_loss: 0.0099
 - val_f1: 0.9931
Epoch 97/200
 - 0s - loss: 0.0091 - val_loss: 0.0098
 - val_f1: 0.9928
Epoch 98/200
 - 0s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 99/200
 - 0s - loss: 0.0089 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 100/200
 - 0s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9926
Epoch 101/200
 - 0s - loss: 0.0093 - val_loss: 0.0098
2019-12-21 11:01:12,951 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_100.pickle
 - val_f1: 0.9933
Epoch 102/200
 - 0s - loss: 0.0089 - val_loss: 0.0102
 - val_f1: 0.9925
Epoch 103/200
 - 0s - loss: 0.0087 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 104/200
 - 0s - loss: 0.0084 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 105/200
 - 0s - loss: 0.0086 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 106/200
 - 0s - loss: 0.0089 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 107/200
 - 0s - loss: 0.0088 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 108/200
 - 0s - loss: 0.0087 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 109/200
 - 0s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 110/200
 - 0s - loss: 0.0086 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 111/200
 - 0s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9937
Epoch 112/200
 - 0s - loss: 0.0089 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 113/200
 - 0s - loss: 0.0089 - val_loss: 0.0098
 - val_f1: 0.9933
Epoch 114/200
 - 0s - loss: 0.0084 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 115/200
 - 0s - loss: 0.0085 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 116/200
 - 0s - loss: 0.0081 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 117/200
 - 0s - loss: 0.0084 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 118/200
 - 0s - loss: 0.0090 - val_loss: 0.0098
 - val_f1: 0.9935
Epoch 119/200
 - 0s - loss: 0.0088 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 120/200
 - 0s - loss: 0.0079 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 121/200
 - 0s - loss: 0.0083 - val_loss: 0.0099
2019-12-21 11:01:25,237 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9929
Epoch 122/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9925
Epoch 123/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9931
Epoch 124/200
 - 0s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 125/200
 - 0s - loss: 0.0083 - val_loss: 0.0098
 - val_f1: 0.9935
Epoch 126/200
 - 0s - loss: 0.0082 - val_loss: 0.0096
 - val_f1: 0.9930
Epoch 127/200
 - 0s - loss: 0.0085 - val_loss: 0.0097
 - val_f1: 0.9930
Epoch 128/200
 - 0s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9935
Epoch 129/200
 - 0s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 130/200
 - 0s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 131/200
 - 0s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 132/200
 - 0s - loss: 0.0085 - val_loss: 0.0100
 - val_f1: 0.9935
Epoch 133/200
 - 0s - loss: 0.0083 - val_loss: 0.0101
 - val_f1: 0.9938
Epoch 134/200
 - 0s - loss: 0.0087 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 135/200
 - 0s - loss: 0.0083 - val_loss: 0.0102
 - val_f1: 0.9935
Epoch 136/200
 - 0s - loss: 0.0086 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 137/200
 - 0s - loss: 0.0085 - val_loss: 0.0102
 - val_f1: 0.9936
Epoch 138/200
 - 0s - loss: 0.0085 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 139/200
 - 0s - loss: 0.0085 - val_loss: 0.0102
 - val_f1: 0.9934
Epoch 140/200
 - 0s - loss: 0.0081 - val_loss: 0.0099
 - val_f1: 0.9937
Epoch 141/200
 - 0s - loss: 0.0079 - val_loss: 0.0098
2019-12-21 11:01:37,626 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_140.pickle
 - val_f1: 0.9933
Epoch 142/200
 - 0s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 143/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9940
Epoch 144/200
 - 0s - loss: 0.0078 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 145/200
 - 0s - loss: 0.0080 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 146/200
 - 0s - loss: 0.0083 - val_loss: 0.0098
 - val_f1: 0.9941
Epoch 147/200
 - 0s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9928
Epoch 148/200
 - 0s - loss: 0.0081 - val_loss: 0.0097
 - val_f1: 0.9935
Epoch 149/200
 - 0s - loss: 0.0086 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 150/200
 - 0s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 151/200
 - 0s - loss: 0.0080 - val_loss: 0.0097
 - val_f1: 0.9934
Epoch 152/200
 - 0s - loss: 0.0081 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 153/200
 - 0s - loss: 0.0079 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 154/200
 - 0s - loss: 0.0081 - val_loss: 0.0096
 - val_f1: 0.9933
Epoch 155/200
 - 0s - loss: 0.0081 - val_loss: 0.0099
 - val_f1: 0.9933
Epoch 156/200
 - 0s - loss: 0.0080 - val_loss: 0.0098
 - val_f1: 0.9937
Epoch 157/200
 - 0s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 158/200
 - 0s - loss: 0.0084 - val_loss: 0.0099
 - val_f1: 0.9932
Epoch 159/200
 - 0s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9929
Epoch 160/200
 - 0s - loss: 0.0084 - val_loss: 0.0096
 - val_f1: 0.9938
Epoch 161/200
 - 0s - loss: 0.0084 - val_loss: 0.0096
2019-12-21 11:01:50,052 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/ann_model_epoch_160.pickle
2019-12-21 11:01:50,388 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 11:01:51,740 [INFO] Last epoch loss evaluation: train_loss = 0.005791, val_loss = 0.009436
2019-12-21 11:01:51,742 [INFO] Training complete. time_to_train = 254.35 sec, 4.24 min
2019-12-21 11:01:51,754 [INFO] Model saved to results_selected_models/selected_nsl_ae_ann_shallow_rep5/best_model.pickle
2019-12-21 11:01:51,949 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep5/training_error_history.png
2019-12-21 11:01:52,132 [INFO] Plot saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep5/training_f1_history.png
2019-12-21 11:01:52,132 [INFO] Making predictions on training, validation, testing data
2019-12-21 11:01:56,004 [INFO] Evaluating predictions (results)
2019-12-21 11:01:56,263 [INFO] Dataset: Testing. Classification report below
2019-12-21 11:01:56,263 [INFO] 
              precision    recall  f1-score   support

         dos       0.93      0.82      0.87      7458
      normal       0.69      0.97      0.81      9711
       probe       0.85      0.72      0.78      2421
         r2l       0.97      0.13      0.22      2421
         u2r       0.79      0.04      0.07       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.85      0.53      0.55     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-21 11:01:56,263 [INFO] Overall accuracy (micro avg): 0.7812721788502484
2019-12-21 11:01:56,560 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7813         0.7813                       0.7813                0.0547                   0.2187  0.7813
1     Macro avg        0.9125         0.8469                       0.5340                0.0740                   0.4660  0.5504
2  Weighted avg        0.8735         0.8205                       0.7813                0.1512                   0.2187  0.7464
2019-12-21 11:01:56,892 [INFO] Dataset: Validation. Classification report below
2019-12-21 11:01:56,892 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.99      0.98      2331
         r2l       0.88      0.82      0.85       199
         u2r       0.80      0.40      0.53        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.93      0.84      0.87     25195
weighted avg       0.99      0.99      0.99     25195

2019-12-21 11:01:56,892 [INFO] Overall accuracy (micro avg): 0.9936098432228617
2019-12-21 11:01:57,248 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9936         0.9936                       0.9936                0.0016                   0.0064  0.9936
1     Macro avg        0.9974         0.9311                       0.8396                0.0021                   0.1604  0.8718
2  Weighted avg        0.9961         0.9935                       0.9936                0.0040                   0.0064  0.9935
2019-12-21 11:01:58,717 [INFO] Dataset: Training. Classification report below
2019-12-21 11:01:58,717 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       0.99      1.00      0.99     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.89      0.80      0.84       796
         u2r       0.71      0.52      0.60        42

   micro avg       0.99      0.99      0.99    100778
   macro avg       0.91      0.86      0.88    100778
weighted avg       0.99      0.99      0.99    100778

2019-12-21 11:01:58,717 [INFO] Overall accuracy (micro avg): 0.9942844668479232
2019-12-21 11:02:00,338 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9943         0.9943                       0.9943                0.0014                   0.0057  0.9943
1     Macro avg        0.9977         0.9149                       0.8614                0.0019                   0.1386  0.8849
2  Weighted avg        0.9965         0.9942                       0.9943                0.0039                   0.0057  0.9942
2019-12-21 11:02:00,376 [INFO] Results saved to: results_selected_models/selected_nsl_ae_ann_shallow_rep5/selected_nsl_ae_ann_shallow_rep5_results.xlsx
2019-12-21 11:02:00,376 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-21 11:02:00,379 [INFO] Created directory: results_selected_models/selected_ids17_ae_ann_shallow_rep1
2019-12-21 11:02:00,379 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_ae_ann_shallow_rep1/run_log.log
2019-12-21 11:02:00,379 [INFO] ================= Running experiment no. 1  ================= 

2019-12-21 11:02:00,379 [INFO] Experiment parameters given below
2019-12-21 11:02:00,379 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_ae_ann_shallow_rep1'}
2019-12-21 11:02:00,379 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_ae_ann_shallow_rep1/tf_logs_run_2019_12_21-11_02_00
2019-12-21 11:02:00,379 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 11:02:00,380 [INFO] Reading X, y files
2019-12-21 11:02:00,380 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 11:02:05,297 [INFO] Reading complete. time_to_read=4.92 seconds
2019-12-21 11:02:05,298 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 11:02:06,727 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 11:02:06,728 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 11:02:08,158 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-21 11:02:08,159 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 11:02:08,407 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-21 11:02:08,407 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 11:02:08,491 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-21 11:02:08,491 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 11:02:08,574 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-21 11:02:11,729 [INFO] Initializing model
2019-12-21 11:02:11,840 [INFO] _________________________________________________________________
2019-12-21 11:02:11,840 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 11:02:11,840 [INFO] =================================================================
2019-12-21 11:02:11,840 [INFO] dense_21 (Dense)             (None, 32)                2528      
2019-12-21 11:02:11,840 [INFO] _________________________________________________________________
2019-12-21 11:02:11,841 [INFO] batch_normalization_11 (Batc (None, 32)                128       
2019-12-21 11:02:11,841 [INFO] _________________________________________________________________
2019-12-21 11:02:11,841 [INFO] dropout_11 (Dropout)         (None, 32)                0         
2019-12-21 11:02:11,841 [INFO] _________________________________________________________________
2019-12-21 11:02:11,841 [INFO] dense_22 (Dense)             (None, 78)                2574      
2019-12-21 11:02:11,841 [INFO] =================================================================
2019-12-21 11:02:11,841 [INFO] Total params: 5,230
2019-12-21 11:02:11,841 [INFO] Trainable params: 5,166
2019-12-21 11:02:11,841 [INFO] Non-trainable params: 64
2019-12-21 11:02:11,841 [INFO] _________________________________________________________________
2019-12-21 11:02:11,949 [INFO] _________________________________________________________________
2019-12-21 11:02:11,950 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 11:02:11,950 [INFO] =================================================================
2019-12-21 11:02:11,950 [INFO] dense_23 (Dense)             (None, 32)                1056      
2019-12-21 11:02:11,950 [INFO] _________________________________________________________________
2019-12-21 11:02:11,950 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2019-12-21 11:02:11,950 [INFO] _________________________________________________________________
2019-12-21 11:02:11,950 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2019-12-21 11:02:11,950 [INFO] _________________________________________________________________
2019-12-21 11:02:11,950 [INFO] dense_24 (Dense)             (None, 12)                396       
2019-12-21 11:02:11,950 [INFO] =================================================================
2019-12-21 11:02:11,951 [INFO] Total params: 1,580
2019-12-21 11:02:11,951 [INFO] Trainable params: 1,516
2019-12-21 11:02:11,951 [INFO] Non-trainable params: 64
2019-12-21 11:02:11,951 [INFO] _________________________________________________________________
2019-12-21 11:02:11,951 [INFO] Training model
2019-12-21 11:02:11,951 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 11:02:28,169 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342
2019-12-21 11:02:28,170 [INFO] Training autoencoder
 - val_f1: 0.9938
Epoch 00161: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 13s - loss: -3.3621e+00 - val_loss: -4.0922e+00
Epoch 2/200
 - 13s - loss: -4.0257e+00 - val_loss: -4.1258e+00
Epoch 3/200
 - 13s - loss: -4.0540e+00 - val_loss: -4.1308e+00
Epoch 4/200
 - 13s - loss: -4.0663e+00 - val_loss: -4.1369e+00
Epoch 5/200
 - 13s - loss: -4.0721e+00 - val_loss: -4.1377e+00
Epoch 6/200
 - 13s - loss: -4.0774e+00 - val_loss: -4.1406e+00
Epoch 7/200
 - 13s - loss: -4.0809e+00 - val_loss: -4.1405e+00
Epoch 8/200
 - 13s - loss: -4.0834e+00 - val_loss: -4.1410e+00
Epoch 9/200
 - 13s - loss: -4.0856e+00 - val_loss: -4.1412e+00
Epoch 10/200
 - 13s - loss: -4.0869e+00 - val_loss: -4.1413e+00
Epoch 11/200
 - 13s - loss: -4.0886e+00 - val_loss: -4.1422e+00
Epoch 12/200
 - 13s - loss: -4.0893e+00 - val_loss: -4.1434e+00
Epoch 13/200
 - 13s - loss: -4.0907e+00 - val_loss: -4.1443e+00
Epoch 14/200
 - 13s - loss: -4.0920e+00 - val_loss: -4.1435e+00
Epoch 15/200
 - 13s - loss: -4.0919e+00 - val_loss: -4.1443e+00
Epoch 16/200
 - 13s - loss: -4.0927e+00 - val_loss: -4.1446e+00
Epoch 17/200
 - 13s - loss: -4.0940e+00 - val_loss: -4.1441e+00
Epoch 18/200
 - 13s - loss: -4.0942e+00 - val_loss: -4.1455e+00
Epoch 19/200
 - 13s - loss: -4.0946e+00 - val_loss: -4.1458e+00
Epoch 20/200
 - 13s - loss: -4.0951e+00 - val_loss: -4.1450e+00
Epoch 21/200
 - 13s - loss: -4.0955e+00 - val_loss: -4.1459e+00
2019-12-21 11:06:58,919 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_20.pickle
Epoch 22/200
 - 13s - loss: -4.0962e+00 - val_loss: -4.1454e+00
Epoch 23/200
 - 13s - loss: -4.0960e+00 - val_loss: -4.1457e+00
Epoch 24/200
 - 13s - loss: -4.0967e+00 - val_loss: -4.1461e+00
Epoch 25/200
 - 13s - loss: -4.0968e+00 - val_loss: -4.1464e+00
Epoch 26/200
 - 13s - loss: -4.0972e+00 - val_loss: -4.1436e+00
Epoch 27/200
 - 13s - loss: -4.0974e+00 - val_loss: -4.1461e+00
Epoch 28/200
 - 13s - loss: -4.0974e+00 - val_loss: -4.1473e+00
Epoch 29/200
 - 13s - loss: -4.0977e+00 - val_loss: -4.1468e+00
Epoch 30/200
 - 13s - loss: -4.0980e+00 - val_loss: -4.1470e+00
Epoch 31/200
 - 13s - loss: -4.0980e+00 - val_loss: -4.1461e+00
Epoch 32/200
 - 13s - loss: -4.0984e+00 - val_loss: -4.1466e+00
Epoch 33/200
 - 13s - loss: -4.0986e+00 - val_loss: -4.1451e+00
Epoch 34/200
 - 13s - loss: -4.0988e+00 - val_loss: -4.1472e+00
Epoch 35/200
 - 13s - loss: -4.0994e+00 - val_loss: -4.1458e+00
Epoch 36/200
 - 13s - loss: -4.0989e+00 - val_loss: -4.1468e+00
Epoch 37/200
 - 13s - loss: -4.0995e+00 - val_loss: -4.1396e+00
Epoch 38/200
 - 13s - loss: -4.0998e+00 - val_loss: -4.1464e+00
Epoch 39/200
 - 13s - loss: -4.0997e+00 - val_loss: -4.1477e+00
Epoch 40/200
 - 13s - loss: -4.0998e+00 - val_loss: -4.1473e+00
Epoch 41/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1470e+00
2019-12-21 11:11:15,053 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_40.pickle
Epoch 42/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1472e+00
Epoch 43/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1461e+00
Epoch 44/200
 - 13s - loss: -4.1003e+00 - val_loss: -4.1456e+00
Epoch 45/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1463e+00
Epoch 46/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1474e+00
Epoch 47/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1476e+00
Epoch 48/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1465e+00
Epoch 49/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1482e+00
Epoch 50/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1480e+00
Epoch 51/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1478e+00
Epoch 52/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1469e+00
Epoch 53/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1477e+00
Epoch 54/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1467e+00
Epoch 55/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1478e+00
Epoch 56/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1476e+00
Epoch 57/200
 - 13s - loss: -4.1020e+00 - val_loss: -4.1484e+00
Epoch 58/200
 - 13s - loss: -4.1021e+00 - val_loss: -4.1480e+00
Epoch 59/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1453e+00
Epoch 60/200
 - 13s - loss: -4.1024e+00 - val_loss: -4.1470e+00
Epoch 61/200
 - 13s - loss: -4.1025e+00 - val_loss: -4.1474e+00
2019-12-21 11:15:29,379 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_60.pickle
Epoch 62/200
 - 13s - loss: -4.1025e+00 - val_loss: -4.1473e+00
Epoch 63/200
 - 13s - loss: -4.1025e+00 - val_loss: -4.1475e+00
Epoch 64/200
 - 13s - loss: -4.1026e+00 - val_loss: -4.1459e+00
Epoch 65/200
 - 13s - loss: -4.1031e+00 - val_loss: -4.1474e+00
Epoch 66/200
 - 13s - loss: -4.1026e+00 - val_loss: -4.1482e+00
Epoch 67/200
 - 13s - loss: -4.1028e+00 - val_loss: -4.1480e+00
Epoch 68/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1482e+00
Epoch 69/200
 - 13s - loss: -4.1031e+00 - val_loss: -4.1487e+00
Epoch 70/200
 - 13s - loss: -4.1031e+00 - val_loss: -4.1484e+00
Epoch 71/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1484e+00
Epoch 72/200
 - 13s - loss: -4.1032e+00 - val_loss: -4.1472e+00
Epoch 73/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1482e+00
Epoch 74/200
 - 13s - loss: -4.1032e+00 - val_loss: -4.1481e+00
Epoch 75/200
 - 13s - loss: -4.1034e+00 - val_loss: -4.1478e+00
Epoch 76/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1481e+00
Epoch 77/200
 - 13s - loss: -4.1034e+00 - val_loss: -4.1478e+00
Epoch 78/200
 - 13s - loss: -4.1034e+00 - val_loss: -4.1483e+00
Epoch 79/200
 - 13s - loss: -4.1040e+00 - val_loss: -4.1480e+00
Epoch 80/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1489e+00
Epoch 81/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1480e+00
2019-12-21 11:19:43,352 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_80.pickle
Epoch 82/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1484e+00
Epoch 83/200
 - 13s - loss: -4.1038e+00 - val_loss: -4.1482e+00
Epoch 84/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1488e+00
Epoch 85/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1476e+00
Epoch 86/200
 - 13s - loss: -4.1038e+00 - val_loss: -4.1486e+00
Epoch 87/200
 - 13s - loss: -4.1038e+00 - val_loss: -4.1492e+00
Epoch 88/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1485e+00
Epoch 89/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1483e+00
Epoch 90/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1483e+00
Epoch 91/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1484e+00
Epoch 92/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1481e+00
Epoch 93/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1489e+00
Epoch 94/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1481e+00
Epoch 95/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1488e+00
Epoch 96/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1489e+00
Epoch 97/200
 - 13s - loss: -4.1038e+00 - val_loss: -4.1488e+00
Epoch 98/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1486e+00
Epoch 99/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1489e+00
Epoch 100/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1492e+00
Epoch 101/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1485e+00
2019-12-21 11:23:57,119 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_100.pickle
Epoch 102/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1484e+00
Epoch 103/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1495e+00
Epoch 104/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1483e+00
Epoch 105/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1485e+00
Epoch 106/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1481e+00
Epoch 107/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1491e+00
Epoch 108/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1486e+00
Epoch 109/200
 - 13s - loss: -4.1040e+00 - val_loss: -4.1487e+00
Epoch 110/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1488e+00
Epoch 111/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1485e+00
Epoch 112/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1486e+00
Epoch 113/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1481e+00
Epoch 114/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1487e+00
Epoch 115/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1493e+00
Epoch 116/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1484e+00
Epoch 117/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1493e+00
Epoch 118/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1487e+00
Epoch 119/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1489e+00
Epoch 120/200
 - 13s - loss: -4.1049e+00 - val_loss: -4.1490e+00
Epoch 121/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1487e+00
2019-12-21 11:28:10,664 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_120.pickle
Epoch 122/200
 - 13s - loss: -4.1046e+00 - val_loss: -4.1480e+00
Epoch 123/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1491e+00
Epoch 124/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1489e+00
Epoch 125/200
 - 13s - loss: -4.1049e+00 - val_loss: -4.1490e+00
Epoch 126/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1483e+00
Epoch 127/200
 - 13s - loss: -4.1046e+00 - val_loss: -4.1491e+00
Epoch 128/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1480e+00
Epoch 129/200
 - 13s - loss: -4.1046e+00 - val_loss: -4.1490e+00
Epoch 130/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1470e+00
Epoch 131/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1483e+00
Epoch 132/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1485e+00
Epoch 133/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1492e+00
Epoch 134/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1485e+00
Epoch 135/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1488e+00
Epoch 136/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1493e+00
Epoch 137/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1492e+00
Epoch 138/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1490e+00
Epoch 139/200
 - 13s - loss: -4.1049e+00 - val_loss: -4.1490e+00
Epoch 140/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1490e+00
Epoch 141/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1472e+00
2019-12-21 11:32:24,235 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ae_model_epoch_140.pickle
Epoch 142/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1492e+00
Epoch 143/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1494e+00
Epoch 144/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1493e+00
Epoch 145/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1484e+00
Epoch 146/200
 - 13s - loss: -4.1054e+00 - val_loss: -4.1492e+00
Epoch 147/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1488e+00
Epoch 148/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1495e+00
Epoch 149/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1492e+00
Epoch 150/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1494e+00
Epoch 151/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1487e+00
Epoch 152/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1485e+00
Epoch 153/200
 - 13s - loss: -4.1054e+00 - val_loss: -4.1495e+00
2019-12-21 11:34:56,566 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 11:35:19,453 [INFO] Last epoch loss evaluation: train_loss = -4.149603, val_loss = -4.149507
2019-12-21 11:35:19,453 [INFO] Training autoencoder complete
2019-12-21 11:35:19,453 [INFO] Encoding data for supervised training
2019-12-21 11:35:39,613 [INFO] Encoding complete
2019-12-21 11:35:39,613 [INFO] Training neural network layers (after autoencoder)
Epoch 00153: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 6s - loss: 0.0323 - val_loss: 0.0137
 - val_f1: 0.9654
Epoch 2/200
 - 6s - loss: 0.0149 - val_loss: 0.0112
 - val_f1: 0.9730
Epoch 3/200
 - 6s - loss: 0.0130 - val_loss: 0.0110
 - val_f1: 0.9731
Epoch 4/200
 - 6s - loss: 0.0121 - val_loss: 0.0098
 - val_f1: 0.9753
Epoch 5/200
 - 6s - loss: 0.0117 - val_loss: 0.0094
 - val_f1: 0.9795
Epoch 6/200
 - 6s - loss: 0.0112 - val_loss: 0.0096
 - val_f1: 0.9767
Epoch 7/200
 - 6s - loss: 0.0111 - val_loss: 0.0090
 - val_f1: 0.9790
Epoch 8/200
 - 6s - loss: 0.0110 - val_loss: 0.0089
 - val_f1: 0.9803
Epoch 9/200
 - 6s - loss: 0.0108 - val_loss: 0.0087
 - val_f1: 0.9774
Epoch 10/200
 - 6s - loss: 0.0106 - val_loss: 0.0089
 - val_f1: 0.9769
Epoch 11/200
 - 6s - loss: 0.0105 - val_loss: 0.0086
 - val_f1: 0.9791
Epoch 12/200
 - 6s - loss: 0.0104 - val_loss: 0.0082
 - val_f1: 0.9773
Epoch 13/200
 - 6s - loss: 0.0102 - val_loss: 0.0083
 - val_f1: 0.9755
Epoch 14/200
 - 6s - loss: 0.0102 - val_loss: 0.0091
 - val_f1: 0.9761
Epoch 15/200
 - 6s - loss: 0.0101 - val_loss: 0.0086
 - val_f1: 0.9776
Epoch 16/200
 - 6s - loss: 0.0100 - val_loss: 0.0079
 - val_f1: 0.9822
Epoch 17/200
 - 6s - loss: 0.0100 - val_loss: 0.0080
 - val_f1: 0.9812
Epoch 18/200
 - 6s - loss: 0.0099 - val_loss: 0.0085
 - val_f1: 0.9821
Epoch 19/200
 - 6s - loss: 0.0101 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 20/200
 - 6s - loss: 0.0099 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 21/200
 - 6s - loss: 0.0098 - val_loss: 0.0081
2019-12-21 11:40:32,035 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9772
Epoch 22/200
 - 6s - loss: 0.0098 - val_loss: 0.0094
 - val_f1: 0.9754
Epoch 23/200
 - 6s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9817
Epoch 24/200
 - 6s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9767
Epoch 25/200
 - 6s - loss: 0.0098 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 26/200
 - 6s - loss: 0.0098 - val_loss: 0.0078
 - val_f1: 0.9825
Epoch 27/200
 - 6s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 28/200
 - 6s - loss: 0.0097 - val_loss: 0.0080
 - val_f1: 0.9819
Epoch 29/200
 - 6s - loss: 0.0096 - val_loss: 0.0082
 - val_f1: 0.9755
Epoch 30/200
 - 6s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9769
Epoch 31/200
 - 6s - loss: 0.0096 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 32/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9786
Epoch 33/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9792
Epoch 34/200
 - 6s - loss: 0.0095 - val_loss: 0.0079
 - val_f1: 0.9826
Epoch 35/200
 - 6s - loss: 0.0095 - val_loss: 0.0078
 - val_f1: 0.9822
Epoch 36/200
 - 6s - loss: 0.0094 - val_loss: 0.0081
 - val_f1: 0.9789
Epoch 37/200
 - 6s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9814
Epoch 38/200
 - 6s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9791
Epoch 39/200
 - 6s - loss: 0.0094 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 40/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9817
Epoch 41/200
 - 6s - loss: 0.0093 - val_loss: 0.0074
2019-12-21 11:45:15,338 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9839
Epoch 42/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9773
Epoch 43/200
 - 6s - loss: 0.0093 - val_loss: 0.0075
 - val_f1: 0.9830
Epoch 44/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 45/200
 - 6s - loss: 0.0092 - val_loss: 0.0074
 - val_f1: 0.9826
Epoch 46/200
 - 6s - loss: 0.0092 - val_loss: 0.0072
 - val_f1: 0.9843
Epoch 47/200
 - 6s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9814
Epoch 48/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9803
Epoch 49/200
 - 6s - loss: 0.0092 - val_loss: 0.0073
 - val_f1: 0.9825
Epoch 50/200
 - 6s - loss: 0.0091 - val_loss: 0.0078
 - val_f1: 0.9776
Epoch 51/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9818
Epoch 52/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9817
Epoch 53/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9821
Epoch 54/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 55/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9831
Epoch 56/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9838
Epoch 57/200
 - 6s - loss: 0.0091 - val_loss: 0.0073
 - val_f1: 0.9823
Epoch 58/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9796
Epoch 59/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 60/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9803
Epoch 61/200
 - 6s - loss: 0.0093 - val_loss: 0.0074
2019-12-21 11:49:58,394 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9834
Epoch 62/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 63/200
 - 6s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9761
Epoch 64/200
 - 6s - loss: 0.0092 - val_loss: 0.0073
 - val_f1: 0.9830
Epoch 65/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9824
Epoch 66/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9839
Epoch 67/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9826
Epoch 68/200
 - 6s - loss: 0.0091 - val_loss: 0.0078
 - val_f1: 0.9793
Epoch 69/200
 - 6s - loss: 0.0091 - val_loss: 0.0072
 - val_f1: 0.9838
Epoch 70/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9835
Epoch 71/200
 - 6s - loss: 0.0090 - val_loss: 0.0074
 - val_f1: 0.9811
Epoch 72/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9839
Epoch 73/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 74/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9834
Epoch 75/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 76/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9799
Epoch 77/200
 - 6s - loss: 0.0090 - val_loss: 0.0074
 - val_f1: 0.9799
Epoch 78/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9808
Epoch 79/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9814
Epoch 80/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9810
Epoch 81/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
2019-12-21 11:54:41,874 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9836
Epoch 82/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9844
Epoch 83/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9822
Epoch 84/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9839
Epoch 85/200
 - 6s - loss: 0.0091 - val_loss: 0.0071
 - val_f1: 0.9841
Epoch 86/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9834
Epoch 87/200
 - 6s - loss: 0.0089 - val_loss: 0.0071
 - val_f1: 0.9845
Epoch 88/200
 - 6s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 89/200
 - 6s - loss: 0.0089 - val_loss: 0.0073
 - val_f1: 0.9842
Epoch 90/200
 - 6s - loss: 0.0089 - val_loss: 0.0071
 - val_f1: 0.9842
Epoch 91/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9827
Epoch 92/200
 - 6s - loss: 0.0089 - val_loss: 0.0073
 - val_f1: 0.9792
Epoch 93/200
 - 6s - loss: 0.0089 - val_loss: 0.0070
 - val_f1: 0.9840
Epoch 94/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9823
Epoch 95/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9820
Epoch 96/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9838
Epoch 97/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9843
Epoch 98/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9830
Epoch 99/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9825
Epoch 100/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9835
Epoch 101/200
 - 6s - loss: 0.0089 - val_loss: 0.0099
2019-12-21 11:59:24,743 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9713
Epoch 102/200
 - 6s - loss: 0.0089 - val_loss: 0.0118
 - val_f1: 0.9681
Epoch 103/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9810
Epoch 104/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9822
Epoch 105/200
 - 6s - loss: 0.0089 - val_loss: 0.0071
 - val_f1: 0.9838
Epoch 106/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9798
Epoch 107/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9819
Epoch 108/200
 - 6s - loss: 0.0089 - val_loss: 0.0071
 - val_f1: 0.9840
Epoch 109/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9843
Epoch 110/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9834
Epoch 111/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9840
Epoch 112/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9802
Epoch 113/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9801
Epoch 114/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9821
Epoch 115/200
 - 6s - loss: 0.0089 - val_loss: 0.0071
 - val_f1: 0.9836
Epoch 116/200
 - 6s - loss: 0.0088 - val_loss: 0.0105
 - val_f1: 0.9759
Epoch 117/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9830
Epoch 118/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9826
Epoch 119/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9843
Epoch 120/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 121/200
 - 6s - loss: 0.0089 - val_loss: 0.0070
2019-12-21 12:04:07,985 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9837
Epoch 122/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9833
Epoch 123/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9789
Epoch 124/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9800
Epoch 125/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9818
Epoch 126/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9788
Epoch 127/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9823
Epoch 128/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9837
Epoch 129/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9821
Epoch 130/200
 - 6s - loss: 0.0088 - val_loss: 0.0070
 - val_f1: 0.9837
Epoch 131/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9806
Epoch 132/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9840
Epoch 133/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 134/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9835
Epoch 135/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9841
Epoch 136/200
 - 6s - loss: 0.0088 - val_loss: 0.0069
 - val_f1: 0.9838
Epoch 137/200
 - 6s - loss: 0.0088 - val_loss: 0.0070
 - val_f1: 0.9842
Epoch 138/200
 - 6s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9846
Epoch 139/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9827
Epoch 140/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9839
Epoch 141/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
2019-12-21 12:08:50,557 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9824
Epoch 142/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9812
Epoch 143/200
 - 6s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9761
Epoch 144/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9817
Epoch 145/200
 - 6s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9775
Epoch 146/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9848
Epoch 147/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9810
Epoch 148/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9846
Epoch 149/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9841
Epoch 150/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9807
Epoch 151/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9806
Epoch 152/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9853
Epoch 153/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9855
Epoch 154/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9829
Epoch 155/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9854
Epoch 156/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9806
Epoch 157/200
 - 6s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9837
Epoch 158/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9840
Epoch 159/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9804
Epoch 160/200
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9775
Epoch 161/200
 - 6s - loss: 0.0087 - val_loss: 0.0123
2019-12-21 12:13:34,014 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9651
Epoch 162/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9845
Epoch 163/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9827
Epoch 164/200
 - 6s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 165/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9799
Epoch 166/200
 - 6s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9844
Epoch 167/200
 - 6s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9799
Epoch 168/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9857
Epoch 169/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9855
Epoch 170/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9847
Epoch 171/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9799
Epoch 172/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9804
Epoch 173/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9844
Epoch 174/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9849
Epoch 175/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9829
Epoch 176/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9846
Epoch 177/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9834
Epoch 178/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9814
Epoch 179/200
 - 6s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9726
Epoch 180/200
 - 6s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9843
Epoch 181/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
2019-12-21 12:18:16,732 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9850
Epoch 182/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9840
Epoch 183/200
 - 6s - loss: 0.0085 - val_loss: 0.0077
 - val_f1: 0.9802
Epoch 184/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9846
Epoch 185/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9848
Epoch 186/200
 - 6s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9787
Epoch 187/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9805
Epoch 188/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9797
Epoch 189/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9812
Epoch 190/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9840
Epoch 191/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9845
Epoch 192/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9852
Epoch 193/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9800
Epoch 194/200
 - 6s - loss: 0.0085 - val_loss: 0.0095
 - val_f1: 0.9713
Epoch 195/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9854
Epoch 196/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9843
Epoch 197/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9839
Epoch 198/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9820
Epoch 199/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9801
Epoch 200/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
2019-12-21 12:22:54,024 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 12:23:16,883 [INFO] Last epoch loss evaluation: train_loss = 0.006603, val_loss = 0.006797
2019-12-21 12:23:16,916 [INFO] Training complete. time_to_train = 4864.97 sec, 81.08 min
2019-12-21 12:23:16,925 [INFO] Model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep1/best_model.pickle
2019-12-21 12:23:17,111 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep1/training_error_history.png
2019-12-21 12:23:17,293 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep1/training_f1_history.png
2019-12-21 12:23:17,293 [INFO] Making predictions on training, validation, testing data
2019-12-21 12:24:38,706 [INFO] Evaluating predictions (results)
2019-12-21 12:24:48,849 [INFO] Dataset: Testing. Classification report below
2019-12-21 12:24:48,849 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       1.00      0.35      0.52       391
                  DDoS       1.00      0.99      1.00     25605
         DoS GoldenEye       0.99      0.94      0.96      2058
              DoS Hulk       0.99      0.97      0.98     46025
      DoS Slowhttptest       0.88      0.97      0.92      1100
         DoS slowloris       0.97      0.95      0.96      1159
           FTP-Patator       1.00      0.94      0.97      1587
              PortScan       0.90      0.95      0.92     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.75      0.77    565562
          weighted avg       0.98      0.99      0.98    565562

2019-12-21 12:24:48,849 [INFO] Overall accuracy (micro avg): 0.9852659832166942
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-21 12:25:00,394 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9853         0.9853                       0.9853                0.0013                   0.0147  0.9853
1     Macro avg        0.9975         0.8056                       0.7530                0.0037                   0.2470  0.7660
2  Weighted avg        0.9875         0.9849                       0.9853                0.0296                   0.0147  0.9849
2019-12-21 12:25:10,716 [INFO] Dataset: Validation. Classification report below
2019-12-21 12:25:10,717 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       1.00      0.31      0.47       391
                  DDoS       1.00      0.99      1.00     25605
         DoS GoldenEye       0.99      0.93      0.96      2059
              DoS Hulk       0.99      0.97      0.98     46025
      DoS Slowhttptest       0.89      0.96      0.92      1099
         DoS slowloris       0.96      0.95      0.96      1159
           FTP-Patator       0.99      0.93      0.96      1587
              PortScan       0.90      0.95      0.92     31761
           SSH-Patator       0.96      0.97      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.10      0.02      0.04       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.75      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 12:25:10,717 [INFO] Overall accuracy (micro avg): 0.9854162761996033
2019-12-21 12:25:22,428 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9854         0.9854                       0.9854                0.0013                   0.0146  0.9854
1     Macro avg        0.9976         0.8142                       0.7476                0.0036                   0.2524  0.7631
2  Weighted avg        0.9877         0.9850                       0.9854                0.0292                   0.0146  0.9850
2019-12-21 12:25:56,497 [INFO] Dataset: Training. Classification report below
2019-12-21 12:25:56,497 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       1.00      0.35      0.52      1174
                  DDoS       1.00      0.99      1.00     76815
         DoS GoldenEye       0.99      0.93      0.96      6176
              DoS Hulk       0.99      0.97      0.98    138074
      DoS Slowhttptest       0.90      0.96      0.93      3300
         DoS slowloris       0.97      0.96      0.96      3478
           FTP-Patator       1.00      0.94      0.97      4761
              PortScan       0.90      0.95      0.92     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.50      0.00      0.00       904
        Web Attack XSS       0.15      0.03      0.05       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.86      0.75      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-21 12:25:56,497 [INFO] Overall accuracy (micro avg): 0.9857516190404342
2019-12-21 12:26:35,166 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9858         0.9858                       0.9858                0.0013                   0.0142  0.9858
1     Macro avg        0.9976         0.8619                       0.7545                0.0036                   0.2455  0.7708
2  Weighted avg        0.9879         0.9856                       0.9858                0.0285                   0.0142  0.9854
2019-12-21 12:26:35,217 [INFO] Results saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep1/selected_ids17_ae_ann_shallow_rep1_results.xlsx
2019-12-21 12:26:35,221 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-21 12:26:35,289 [INFO] Created directory: results_selected_models/selected_ids17_ae_ann_shallow_rep2
2019-12-21 12:26:35,290 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_ae_ann_shallow_rep2/run_log.log
2019-12-21 12:26:35,290 [INFO] ================= Running experiment no. 2  ================= 

2019-12-21 12:26:35,290 [INFO] Experiment parameters given below
2019-12-21 12:26:35,290 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids17_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_ae_ann_shallow_rep2'}
2019-12-21 12:26:35,290 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_ae_ann_shallow_rep2/tf_logs_run_2019_12_21-12_26_35
2019-12-21 12:26:35,290 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 12:26:35,290 [INFO] Reading X, y files
2019-12-21 12:26:35,290 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 12:26:39,334 [INFO] Reading complete. time_to_read=4.04 seconds
2019-12-21 12:26:39,334 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 12:26:40,725 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 12:26:40,726 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 12:26:42,117 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 12:26:42,118 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 12:26:42,324 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-21 12:26:42,325 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 12:26:42,392 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 12:26:42,392 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 12:26:42,460 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 12:26:45,606 [INFO] Initializing model
2019-12-21 12:26:45,720 [INFO] _________________________________________________________________
2019-12-21 12:26:45,720 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 12:26:45,720 [INFO] =================================================================
2019-12-21 12:26:45,720 [INFO] dense_25 (Dense)             (None, 32)                2528      
2019-12-21 12:26:45,720 [INFO] _________________________________________________________________
2019-12-21 12:26:45,720 [INFO] batch_normalization_13 (Batc (None, 32)                128       
2019-12-21 12:26:45,720 [INFO] _________________________________________________________________
2019-12-21 12:26:45,720 [INFO] dropout_13 (Dropout)         (None, 32)                0         
2019-12-21 12:26:45,720 [INFO] _________________________________________________________________
2019-12-21 12:26:45,720 [INFO] dense_26 (Dense)             (None, 78)                2574      
2019-12-21 12:26:45,720 [INFO] =================================================================
2019-12-21 12:26:45,720 [INFO] Total params: 5,230
2019-12-21 12:26:45,720 [INFO] Trainable params: 5,166
2019-12-21 12:26:45,721 [INFO] Non-trainable params: 64
2019-12-21 12:26:45,721 [INFO] _________________________________________________________________
2019-12-21 12:26:45,828 [INFO] _________________________________________________________________
2019-12-21 12:26:45,828 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 12:26:45,828 [INFO] =================================================================
2019-12-21 12:26:45,828 [INFO] dense_27 (Dense)             (None, 32)                1056      
2019-12-21 12:26:45,828 [INFO] _________________________________________________________________
2019-12-21 12:26:45,828 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2019-12-21 12:26:45,828 [INFO] _________________________________________________________________
2019-12-21 12:26:45,829 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2019-12-21 12:26:45,829 [INFO] _________________________________________________________________
2019-12-21 12:26:45,829 [INFO] dense_28 (Dense)             (None, 12)                396       
2019-12-21 12:26:45,829 [INFO] =================================================================
2019-12-21 12:26:45,829 [INFO] Total params: 1,580
2019-12-21 12:26:45,829 [INFO] Trainable params: 1,516
2019-12-21 12:26:45,829 [INFO] Non-trainable params: 64
2019-12-21 12:26:45,829 [INFO] _________________________________________________________________
2019-12-21 12:26:45,829 [INFO] Training model
2019-12-21 12:26:45,829 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 12:27:02,319 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342
2019-12-21 12:27:02,319 [INFO] Training autoencoder
 - val_f1: 0.9845
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 13s - loss: -3.3817e+00 - val_loss: -4.1038e+00
Epoch 2/200
 - 13s - loss: -4.0319e+00 - val_loss: -4.1251e+00
Epoch 3/200
 - 13s - loss: -4.0583e+00 - val_loss: -4.1317e+00
Epoch 4/200
 - 13s - loss: -4.0701e+00 - val_loss: -4.1347e+00
Epoch 5/200
 - 13s - loss: -4.0754e+00 - val_loss: -4.1352e+00
Epoch 6/200
 - 13s - loss: -4.0801e+00 - val_loss: -4.1402e+00
Epoch 7/200
 - 13s - loss: -4.0831e+00 - val_loss: -4.1405e+00
Epoch 8/200
 - 13s - loss: -4.0860e+00 - val_loss: -4.1393e+00
Epoch 9/200
 - 13s - loss: -4.0874e+00 - val_loss: -4.1413e+00
Epoch 10/200
 - 12s - loss: -4.0894e+00 - val_loss: -4.1432e+00
Epoch 11/200
 - 13s - loss: -4.0907e+00 - val_loss: -4.1439e+00
Epoch 12/200
 - 13s - loss: -4.0915e+00 - val_loss: -4.1434e+00
Epoch 13/200
 - 13s - loss: -4.0927e+00 - val_loss: -4.1440e+00
Epoch 14/200
 - 13s - loss: -4.0938e+00 - val_loss: -4.1428e+00
Epoch 15/200
 - 13s - loss: -4.0941e+00 - val_loss: -4.1448e+00
Epoch 16/200
 - 13s - loss: -4.0949e+00 - val_loss: -4.1440e+00
Epoch 17/200
 - 13s - loss: -4.0959e+00 - val_loss: -4.1438e+00
Epoch 18/200
 - 13s - loss: -4.0965e+00 - val_loss: -4.1450e+00
Epoch 19/200
 - 13s - loss: -4.0971e+00 - val_loss: -4.1464e+00
Epoch 20/200
 - 13s - loss: -4.0975e+00 - val_loss: -4.1450e+00
Epoch 21/200
 - 13s - loss: -4.0983e+00 - val_loss: -4.1450e+00
2019-12-21 12:31:30,960 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_20.pickle
Epoch 22/200
 - 13s - loss: -4.0991e+00 - val_loss: -4.1461e+00
Epoch 23/200
 - 13s - loss: -4.0994e+00 - val_loss: -4.1446e+00
Epoch 24/200
 - 13s - loss: -4.0994e+00 - val_loss: -4.1460e+00
Epoch 25/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1464e+00
Epoch 26/200
 - 13s - loss: -4.1004e+00 - val_loss: -4.1470e+00
Epoch 27/200
 - 13s - loss: -4.1006e+00 - val_loss: -4.1464e+00
Epoch 28/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1453e+00
Epoch 29/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1466e+00
Epoch 30/200
 - 13s - loss: -4.1021e+00 - val_loss: -4.1476e+00
Epoch 31/200
 - 13s - loss: -4.1021e+00 - val_loss: -4.1474e+00
Epoch 32/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1467e+00
Epoch 33/200
 - 13s - loss: -4.1027e+00 - val_loss: -4.1477e+00
Epoch 34/200
 - 13s - loss: -4.1027e+00 - val_loss: -4.1477e+00
Epoch 35/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1472e+00
Epoch 36/200
 - 13s - loss: -4.1032e+00 - val_loss: -4.1474e+00
Epoch 37/200
 - 13s - loss: -4.1034e+00 - val_loss: -4.1477e+00
Epoch 38/200
 - 13s - loss: -4.1036e+00 - val_loss: -4.1475e+00
Epoch 39/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1475e+00
Epoch 40/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1429e+00
Epoch 41/200
 - 13s - loss: -4.1039e+00 - val_loss: -4.1475e+00
2019-12-21 12:35:43,268 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_40.pickle
Epoch 42/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1450e+00
Epoch 43/200
 - 13s - loss: -4.1042e+00 - val_loss: -4.1439e+00
Epoch 44/200
 - 13s - loss: -4.1034e+00 - val_loss: -4.1414e+00
Epoch 45/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1398e+00
Epoch 46/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1466e+00
Epoch 47/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1469e+00
Epoch 48/200
 - 13s - loss: -4.1054e+00 - val_loss: -4.1344e+00
Epoch 49/200
 - 13s - loss: -4.1057e+00 - val_loss: -4.1475e+00
Epoch 50/200
 - 13s - loss: -4.1055e+00 - val_loss: -4.1464e+00
Epoch 51/200
 - 13s - loss: -4.1058e+00 - val_loss: -4.1480e+00
Epoch 52/200
 - 13s - loss: -4.1058e+00 - val_loss: -4.1458e+00
Epoch 53/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1476e+00
Epoch 54/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1468e+00
Epoch 55/200
 - 13s - loss: -4.1059e+00 - val_loss: -4.1403e+00
Epoch 56/200
 - 13s - loss: -4.1061e+00 - val_loss: -4.1438e+00
Epoch 57/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1412e+00
Epoch 58/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1401e+00
Epoch 59/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1413e+00
Epoch 60/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1411e+00
Epoch 61/200
 - 13s - loss: -4.1065e+00 - val_loss: -4.1484e+00
2019-12-21 12:39:56,279 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_60.pickle
Epoch 62/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1481e+00
Epoch 63/200
 - 13s - loss: -4.1067e+00 - val_loss: -4.1482e+00
Epoch 64/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1483e+00
Epoch 65/200
 - 13s - loss: -4.1067e+00 - val_loss: -4.1476e+00
Epoch 66/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1407e+00
Epoch 67/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1416e+00
Epoch 68/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1411e+00
Epoch 69/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1448e+00
Epoch 70/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1482e+00
Epoch 71/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1377e+00
Epoch 72/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1440e+00
Epoch 73/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1411e+00
Epoch 74/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1404e+00
Epoch 75/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1410e+00
Epoch 76/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1399e+00
Epoch 77/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1404e+00
Epoch 78/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1413e+00
Epoch 79/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1438e+00
Epoch 80/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1419e+00
Epoch 81/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1404e+00
2019-12-21 12:44:09,609 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_80.pickle
Epoch 82/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1327e+00
Epoch 83/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1413e+00
Epoch 84/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1404e+00
Epoch 85/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1408e+00
Epoch 86/200
 - 12s - loss: -4.1078e+00 - val_loss: -4.1407e+00
Epoch 87/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1410e+00
Epoch 88/200
 - 12s - loss: -4.1079e+00 - val_loss: -4.1407e+00
Epoch 89/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1406e+00
Epoch 90/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1402e+00
Epoch 91/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1402e+00
Epoch 92/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1430e+00
Epoch 93/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1482e+00
Epoch 94/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1476e+00
Epoch 95/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1480e+00
Epoch 96/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1446e+00
Epoch 97/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1476e+00
Epoch 98/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1477e+00
Epoch 99/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1445e+00
Epoch 100/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1485e+00
Epoch 101/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1476e+00
2019-12-21 12:48:21,969 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_100.pickle
Epoch 102/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1484e+00
Epoch 103/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1475e+00
Epoch 104/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1493e+00
Epoch 105/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1477e+00
Epoch 106/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1492e+00
Epoch 107/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1483e+00
Epoch 108/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1484e+00
Epoch 109/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1485e+00
Epoch 110/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1408e+00
Epoch 111/200
 - 13s - loss: -4.1091e+00 - val_loss: -4.1438e+00
Epoch 112/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1488e+00
Epoch 113/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1478e+00
Epoch 114/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1488e+00
Epoch 115/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1480e+00
Epoch 116/200
 - 13s - loss: -4.1090e+00 - val_loss: -4.1492e+00
Epoch 117/200
 - 13s - loss: -4.1090e+00 - val_loss: -4.1485e+00
Epoch 118/200
 - 13s - loss: -4.1092e+00 - val_loss: -4.1487e+00
Epoch 119/200
 - 13s - loss: -4.1089e+00 - val_loss: -4.1487e+00
Epoch 120/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1487e+00
Epoch 121/200
 - 13s - loss: -4.1093e+00 - val_loss: -4.1492e+00
2019-12-21 12:52:35,181 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_120.pickle
Epoch 122/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1491e+00
Epoch 123/200
 - 13s - loss: -4.1090e+00 - val_loss: -4.1492e+00
Epoch 124/200
 - 13s - loss: -4.1090e+00 - val_loss: -4.1481e+00
Epoch 125/200
 - 13s - loss: -4.1091e+00 - val_loss: -4.1491e+00
Epoch 126/200
 - 13s - loss: -4.1090e+00 - val_loss: -4.1487e+00
Epoch 127/200
 - 13s - loss: -4.1093e+00 - val_loss: -4.1485e+00
Epoch 128/200
 - 13s - loss: -4.1093e+00 - val_loss: -4.1485e+00
Epoch 129/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1484e+00
Epoch 130/200
 - 13s - loss: -4.1093e+00 - val_loss: -4.1492e+00
Epoch 131/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1486e+00
Epoch 132/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1490e+00
Epoch 133/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1491e+00
Epoch 134/200
 - 13s - loss: -4.1094e+00 - val_loss: -4.1484e+00
Epoch 135/200
 - 13s - loss: -4.1096e+00 - val_loss: -4.1495e+00
Epoch 136/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1491e+00
Epoch 137/200
 - 13s - loss: -4.1097e+00 - val_loss: -4.1491e+00
Epoch 138/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1485e+00
Epoch 139/200
 - 13s - loss: -4.1093e+00 - val_loss: -4.1497e+00
Epoch 140/200
 - 13s - loss: -4.1094e+00 - val_loss: -4.1491e+00
Epoch 141/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1497e+00
2019-12-21 12:56:48,307 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_140.pickle
Epoch 142/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1497e+00
Epoch 143/200
 - 13s - loss: -4.1096e+00 - val_loss: -4.1491e+00
Epoch 144/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1489e+00
Epoch 145/200
 - 13s - loss: -4.1097e+00 - val_loss: -4.1490e+00
Epoch 146/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1495e+00
Epoch 147/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1495e+00
Epoch 148/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1499e+00
Epoch 149/200
 - 13s - loss: -4.1096e+00 - val_loss: -4.1482e+00
Epoch 150/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1500e+00
Epoch 151/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1495e+00
Epoch 152/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1492e+00
Epoch 153/200
 - 13s - loss: -4.1099e+00 - val_loss: -4.1493e+00
Epoch 154/200
 - 12s - loss: -4.1100e+00 - val_loss: -4.1496e+00
Epoch 155/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1495e+00
Epoch 156/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1501e+00
Epoch 157/200
 - 13s - loss: -4.1095e+00 - val_loss: -4.1487e+00
Epoch 158/200
 - 13s - loss: -4.1100e+00 - val_loss: -4.1495e+00
Epoch 159/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1485e+00
Epoch 160/200
 - 13s - loss: -4.1097e+00 - val_loss: -4.1499e+00
Epoch 161/200
 - 13s - loss: -4.1100e+00 - val_loss: -4.1493e+00
2019-12-21 13:01:01,599 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_160.pickle
Epoch 162/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1492e+00
Epoch 163/200
 - 13s - loss: -4.1099e+00 - val_loss: -4.1496e+00
Epoch 164/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1493e+00
Epoch 165/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1472e+00
Epoch 166/200
 - 13s - loss: -4.1099e+00 - val_loss: -4.1433e+00
Epoch 167/200
 - 13s - loss: -4.1098e+00 - val_loss: -4.1423e+00
Epoch 168/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1428e+00
Epoch 169/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1427e+00
Epoch 170/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1429e+00
Epoch 171/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1459e+00
Epoch 172/200
 - 13s - loss: -4.1104e+00 - val_loss: -4.1495e+00
Epoch 173/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1497e+00
Epoch 174/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1503e+00
Epoch 175/200
 - 13s - loss: -4.1104e+00 - val_loss: -4.1500e+00
Epoch 176/200
 - 13s - loss: -4.1103e+00 - val_loss: -4.1488e+00
Epoch 177/200
 - 13s - loss: -4.1106e+00 - val_loss: -4.1501e+00
Epoch 178/200
 - 13s - loss: -4.1107e+00 - val_loss: -4.1503e+00
Epoch 179/200
 - 13s - loss: -4.1104e+00 - val_loss: -4.1496e+00
Epoch 180/200
 - 13s - loss: -4.1104e+00 - val_loss: -4.1501e+00
Epoch 181/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1471e+00
2019-12-21 13:05:15,431 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ae_model_epoch_180.pickle
Epoch 182/200
 - 13s - loss: -4.1101e+00 - val_loss: -4.1500e+00
Epoch 183/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1490e+00
Epoch 184/200
 - 13s - loss: -4.1108e+00 - val_loss: -4.1502e+00
Epoch 185/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1456e+00
Epoch 186/200
 - 13s - loss: -4.1102e+00 - val_loss: -4.1472e+00
Epoch 187/200
 - 13s - loss: -4.1106e+00 - val_loss: -4.1499e+00
Epoch 188/200
 - 13s - loss: -4.1100e+00 - val_loss: -4.1496e+00
Epoch 189/200
 - 13s - loss: -4.1104e+00 - val_loss: -4.1496e+00
Epoch 190/200
 - 13s - loss: -4.1106e+00 - val_loss: -4.1497e+00
Epoch 191/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1472e+00
Epoch 192/200
 - 13s - loss: -4.1107e+00 - val_loss: -4.1498e+00
Epoch 193/200
 - 13s - loss: -4.1106e+00 - val_loss: -4.1479e+00
Epoch 194/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1474e+00
Epoch 195/200
 - 13s - loss: -4.1108e+00 - val_loss: -4.1500e+00
Epoch 196/200
 - 13s - loss: -4.1107e+00 - val_loss: -4.1501e+00
Epoch 197/200
 - 13s - loss: -4.1108e+00 - val_loss: -4.1485e+00
Epoch 198/200
 - 13s - loss: -4.1107e+00 - val_loss: -4.1504e+00
Epoch 199/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1488e+00
Epoch 200/200
 - 13s - loss: -4.1105e+00 - val_loss: -4.1473e+00
2019-12-21 13:09:16,212 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 13:09:40,586 [INFO] Last epoch loss evaluation: train_loss = -4.153959, val_loss = -4.150396
2019-12-21 13:09:40,586 [INFO] Training autoencoder complete
2019-12-21 13:09:40,586 [INFO] Encoding data for supervised training
2019-12-21 13:10:02,292 [INFO] Encoding complete
2019-12-21 13:10:02,292 [INFO] Training neural network layers (after autoencoder)
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 6s - loss: 0.0315 - val_loss: 0.0134
 - val_f1: 0.9673
Epoch 2/200
 - 6s - loss: 0.0145 - val_loss: 0.0108
 - val_f1: 0.9722
Epoch 3/200
 - 6s - loss: 0.0127 - val_loss: 0.0100
 - val_f1: 0.9749
Epoch 4/200
 - 6s - loss: 0.0119 - val_loss: 0.0103
 - val_f1: 0.9738
Epoch 5/200
 - 6s - loss: 0.0114 - val_loss: 0.0092
 - val_f1: 0.9757
Epoch 6/200
 - 6s - loss: 0.0112 - val_loss: 0.0109
 - val_f1: 0.9754
Epoch 7/200
 - 6s - loss: 0.0108 - val_loss: 0.0090
 - val_f1: 0.9758
Epoch 8/200
 - 6s - loss: 0.0107 - val_loss: 0.0088
 - val_f1: 0.9768
Epoch 9/200
 - 6s - loss: 0.0106 - val_loss: 0.0089
 - val_f1: 0.9770
Epoch 10/200
 - 6s - loss: 0.0104 - val_loss: 0.0085
 - val_f1: 0.9804
Epoch 11/200
 - 6s - loss: 0.0103 - val_loss: 0.0082
 - val_f1: 0.9766
Epoch 12/200
 - 6s - loss: 0.0103 - val_loss: 0.0090
 - val_f1: 0.9764
Epoch 13/200
 - 6s - loss: 0.0101 - val_loss: 0.0085
 - val_f1: 0.9780
Epoch 14/200
 - 6s - loss: 0.0100 - val_loss: 0.0081
 - val_f1: 0.9806
Epoch 15/200
 - 6s - loss: 0.0100 - val_loss: 0.0085
 - val_f1: 0.9775
Epoch 16/200
 - 6s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9823
Epoch 17/200
 - 6s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9778
Epoch 18/200
 - 6s - loss: 0.0098 - val_loss: 0.0080
 - val_f1: 0.9774
Epoch 19/200
 - 6s - loss: 0.0097 - val_loss: 0.0080
 - val_f1: 0.9807
Epoch 20/200
 - 6s - loss: 0.0096 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 21/200
 - 6s - loss: 0.0096 - val_loss: 0.0080
2019-12-21 13:15:09,400 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9785
Epoch 22/200
 - 6s - loss: 0.0096 - val_loss: 0.0080
 - val_f1: 0.9818
Epoch 23/200
 - 6s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9775
Epoch 24/200
 - 6s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9766
Epoch 25/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 26/200
 - 6s - loss: 0.0095 - val_loss: 0.0076
 - val_f1: 0.9826
Epoch 27/200
 - 6s - loss: 0.0094 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 28/200
 - 6s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 29/200
 - 6s - loss: 0.0093 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 30/200
 - 6s - loss: 0.0093 - val_loss: 0.0077
 - val_f1: 0.9794
Epoch 31/200
 - 6s - loss: 0.0093 - val_loss: 0.0080
 - val_f1: 0.9817
Epoch 32/200
 - 6s - loss: 0.0094 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 33/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9793
Epoch 34/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 35/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9831
Epoch 36/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9811
Epoch 37/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 38/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 39/200
 - 6s - loss: 0.0091 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 40/200
 - 6s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 41/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
2019-12-21 13:20:07,429 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9816
Epoch 42/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9793
Epoch 43/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9833
Epoch 44/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9804
Epoch 45/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9806
Epoch 46/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9831
Epoch 47/200
 - 6s - loss: 0.0090 - val_loss: 0.0074
 - val_f1: 0.9806
Epoch 48/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9792
Epoch 49/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 50/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9836
Epoch 51/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9776
Epoch 52/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9817
Epoch 53/200
 - 6s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 54/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9784
Epoch 55/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9807
Epoch 56/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9821
Epoch 57/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9797
Epoch 58/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 59/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9803
Epoch 60/200
 - 6s - loss: 0.0090 - val_loss: 0.0072
 - val_f1: 0.9832
Epoch 61/200
 - 6s - loss: 0.0088 - val_loss: 0.0082
2019-12-21 13:25:05,225 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9820
Epoch 63/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9790
Epoch 64/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 65/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9777
Epoch 66/200
 - 6s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 67/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9821
Epoch 68/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9824
Epoch 69/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9841
Epoch 70/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9796
Epoch 71/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 72/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9839
Epoch 73/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9802
Epoch 74/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9799
Epoch 75/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9803
Epoch 76/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 77/200
 - 6s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9797
Epoch 78/200
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9754
Epoch 79/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9838
Epoch 80/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9797
Epoch 81/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
2019-12-21 13:30:03,796 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9816
Epoch 82/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9786
Epoch 83/200
 - 6s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9839
Epoch 84/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9849
Epoch 85/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9842
Epoch 86/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9792
Epoch 87/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9783
Epoch 88/200
 - 6s - loss: 0.0088 - val_loss: 0.0070
 - val_f1: 0.9841
Epoch 89/200
 - 6s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 90/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9806
Epoch 91/200
 - 6s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9808
Epoch 92/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9799
Epoch 93/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9798
Epoch 94/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9791
Epoch 95/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9837
Epoch 96/200
 - 6s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9755
Epoch 97/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9794
Epoch 98/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9786
Epoch 99/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
 - val_f1: 0.9858
Epoch 100/200
 - 6s - loss: 0.0084 - val_loss: 0.0065
 - val_f1: 0.9863
Epoch 101/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
2019-12-21 13:35:01,930 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9837
Epoch 102/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9798
Epoch 103/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9795
Epoch 104/200
 - 6s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9839
Epoch 105/200
 - 6s - loss: 0.0086 - val_loss: 0.0077
 - val_f1: 0.9782
Epoch 106/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9782
Epoch 107/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9850
Epoch 108/200
 - 6s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9806
Epoch 109/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
 - val_f1: 0.9806
Epoch 110/200
 - 6s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9811
Epoch 111/200
 - 6s - loss: 0.0082 - val_loss: 0.0074
 - val_f1: 0.9812
Epoch 112/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9816
Epoch 113/200
 - 6s - loss: 0.0082 - val_loss: 0.0064
 - val_f1: 0.9879
Epoch 114/200
 - 6s - loss: 0.0081 - val_loss: 0.0066
 - val_f1: 0.9869
Epoch 115/200
 - 6s - loss: 0.0083 - val_loss: 0.0074
 - val_f1: 0.9836
Epoch 116/200
 - 6s - loss: 0.0084 - val_loss: 0.0072
 - val_f1: 0.9799
Epoch 117/200
 - 6s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9784
Epoch 118/200
 - 6s - loss: 0.0085 - val_loss: 0.0076
 - val_f1: 0.9779
Epoch 119/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9804
Epoch 120/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
 - val_f1: 0.9859
Epoch 121/200
 - 6s - loss: 0.0084 - val_loss: 0.0065
2019-12-21 13:40:00,339 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9851
Epoch 122/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9855
Epoch 123/200
 - 6s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9798
Epoch 124/200
 - 6s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9795
Epoch 125/200
 - 6s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9835
Epoch 126/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
 - val_f1: 0.9807
Epoch 127/200
 - 6s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9843
Epoch 128/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9825
Epoch 129/200
 - 6s - loss: 0.0085 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 130/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9842
Epoch 131/200
 - 6s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9768
Epoch 132/200
 - 6s - loss: 0.0089 - val_loss: 0.0073
 - val_f1: 0.9794
Epoch 133/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9834
Epoch 134/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9821
Epoch 135/200
 - 6s - loss: 0.0087 - val_loss: 0.0070
 - val_f1: 0.9846
Epoch 136/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9850
Epoch 137/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9850
Epoch 138/200
 - 6s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9848
Epoch 139/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9787
Epoch 140/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9836
Epoch 141/200
 - 6s - loss: 0.0084 - val_loss: 0.0078
2019-12-21 13:44:57,950 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9798
Epoch 142/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9812
Epoch 143/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9829
Epoch 144/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9829
Epoch 145/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 146/200
 - 6s - loss: 0.0084 - val_loss: 0.0067
 - val_f1: 0.9836
Epoch 147/200
 - 6s - loss: 0.0083 - val_loss: 0.0075
 - val_f1: 0.9829
Epoch 148/200
 - 6s - loss: 0.0083 - val_loss: 0.0064
 - val_f1: 0.9860
Epoch 149/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9808
Epoch 150/200
 - 6s - loss: 0.0083 - val_loss: 0.0067
 - val_f1: 0.9853
Epoch 151/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9831
Epoch 152/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9803
Epoch 153/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9827
Epoch 154/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9832
Epoch 155/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9819
Epoch 156/200
 - 6s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9797
Epoch 157/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9834
Epoch 158/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9804
Epoch 159/200
 - 6s - loss: 0.0083 - val_loss: 0.0066
 - val_f1: 0.9846
Epoch 160/200
 - 6s - loss: 0.0084 - val_loss: 0.0066
 - val_f1: 0.9848
Epoch 161/200
 - 6s - loss: 0.0082 - val_loss: 0.0062
2019-12-21 13:49:56,390 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9870
Epoch 162/200
 - 6s - loss: 0.0082 - val_loss: 0.0067
 - val_f1: 0.9845
Epoch 163/200
 - 6s - loss: 0.0085 - val_loss: 0.0066
 - val_f1: 0.9855
Epoch 164/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9846
Epoch 165/200
 - 6s - loss: 0.0083 - val_loss: 0.0064
 - val_f1: 0.9810
Epoch 166/200
 - 6s - loss: 0.0085 - val_loss: 0.0066
 - val_f1: 0.9840
Epoch 167/200
 - 6s - loss: 0.0084 - val_loss: 0.0072
 - val_f1: 0.9830
Epoch 168/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9830
Epoch 169/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9852
Epoch 170/200
 - 6s - loss: 0.0084 - val_loss: 0.0067
 - val_f1: 0.9835
Epoch 171/200
 - 6s - loss: 0.0083 - val_loss: 0.0068
 - val_f1: 0.9814
Epoch 172/200
 - 6s - loss: 0.0081 - val_loss: 0.0065
 - val_f1: 0.9872
Epoch 173/200
 - 6s - loss: 0.0083 - val_loss: 0.0070
 - val_f1: 0.9859
Epoch 174/200
 - 6s - loss: 0.0083 - val_loss: 0.0068
 - val_f1: 0.9847
Epoch 175/200
 - 6s - loss: 0.0082 - val_loss: 0.0067
 - val_f1: 0.9812
Epoch 176/200
 - 6s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9860
Epoch 177/200
 - 6s - loss: 0.0080 - val_loss: 0.0060
 - val_f1: 0.9863
Epoch 178/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9841
Epoch 179/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9842
Epoch 180/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9800
Epoch 181/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
2019-12-21 13:54:54,913 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9856
Epoch 182/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9824
Epoch 183/200
 - 6s - loss: 0.0083 - val_loss: 0.0063
 - val_f1: 0.9844
Epoch 184/200
 - 6s - loss: 0.0083 - val_loss: 0.0069
 - val_f1: 0.9839
Epoch 185/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9846
Epoch 186/200
 - 6s - loss: 0.0085 - val_loss: 0.0068
 - val_f1: 0.9822
Epoch 187/200
 - 6s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9825
Epoch 188/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9824
Epoch 189/200
 - 6s - loss: 0.0080 - val_loss: 0.0065
 - val_f1: 0.9881
Epoch 190/200
 - 6s - loss: 0.0080 - val_loss: 0.0065
 - val_f1: 0.9858
Epoch 191/200
 - 6s - loss: 0.0082 - val_loss: 0.0061
 - val_f1: 0.9864
Epoch 192/200
 - 6s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9815
Epoch 193/200
 - 6s - loss: 0.0083 - val_loss: 0.0065
 - val_f1: 0.9850
Epoch 194/200
 - 6s - loss: 0.0083 - val_loss: 0.0062
 - val_f1: 0.9904
Epoch 195/200
 - 6s - loss: 0.0082 - val_loss: 0.0067
 - val_f1: 0.9848
Epoch 196/200
 - 6s - loss: 0.0084 - val_loss: 0.0073
 - val_f1: 0.9795
Epoch 197/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9802
Epoch 198/200
 - 6s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9831
Epoch 199/200
 - 6s - loss: 0.0089 - val_loss: 0.0067
 - val_f1: 0.9859
Epoch 200/200
 - 6s - loss: 0.0086 - val_loss: 0.0067
2019-12-21 13:59:47,106 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 14:00:11,413 [INFO] Last epoch loss evaluation: train_loss = 0.006012, val_loss = 0.006041
2019-12-21 14:00:11,449 [INFO] Training complete. time_to_train = 5605.62 sec, 93.43 min
2019-12-21 14:00:11,458 [INFO] Model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep2/best_model.pickle
2019-12-21 14:00:11,645 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep2/training_error_history.png
2019-12-21 14:00:11,825 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep2/training_f1_history.png
2019-12-21 14:00:11,825 [INFO] Making predictions on training, validation, testing data
2019-12-21 14:01:38,961 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 14:01:49,106 [INFO] Dataset: Testing. Classification report below
2019-12-21 14:01:49,106 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       1.00      0.35      0.52       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.97      0.92      0.95      2058
              DoS Hulk       0.99      0.95      0.97     46025
      DoS Slowhttptest       0.88      0.95      0.92      1100
         DoS slowloris       0.98      0.91      0.94      1159
           FTP-Patator       1.00      0.95      0.97      1587
              PortScan       0.92      0.98      0.95     31761
           SSH-Patator       0.98      0.79      0.87      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.73      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 14:01:49,106 [INFO] Overall accuracy (micro avg): 0.9859661717017763
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-21 14:02:00,648 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9860         0.9860                       0.9860                0.0013                   0.0140  0.9860
1     Macro avg        0.9977         0.8086                       0.7328                0.0039                   0.2672  0.7565
2  Weighted avg        0.9881         0.9855                       0.9860                0.0322                   0.0140  0.9855
2019-12-21 14:02:10,960 [INFO] Dataset: Validation. Classification report below
2019-12-21 14:02:10,960 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       1.00      0.31      0.47       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.98      0.92      0.95      2059
              DoS Hulk       0.99      0.95      0.97     46025
      DoS Slowhttptest       0.89      0.94      0.91      1099
         DoS slowloris       0.98      0.92      0.95      1159
           FTP-Patator       1.00      0.94      0.97      1587
              PortScan       0.92      0.98      0.95     31761
           SSH-Patator       0.98      0.79      0.88      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.73      0.75    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 14:02:10,960 [INFO] Overall accuracy (micro avg): 0.9862702939730745
2019-12-21 14:02:22,670 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9863         0.9863                       0.9863                0.0012                   0.0137  0.9863
1     Macro avg        0.9977         0.8099                       0.7279                0.0038                   0.2721  0.7523
2  Weighted avg        0.9883         0.9858                       0.9863                0.0318                   0.0137  0.9858
2019-12-21 14:02:56,727 [INFO] Dataset: Training. Classification report below
2019-12-21 14:02:56,727 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       1.00      0.35      0.51      1174
                  DDoS       1.00      0.99      0.99     76815
         DoS GoldenEye       0.98      0.93      0.95      6176
              DoS Hulk       0.99      0.95      0.97    138074
      DoS Slowhttptest       0.89      0.95      0.92      3300
         DoS slowloris       0.98      0.93      0.95      3478
           FTP-Patator       1.00      0.94      0.97      4761
              PortScan       0.92      0.98      0.95     95282
           SSH-Patator       0.98      0.81      0.89      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.81      0.73      0.76   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-21 14:02:56,727 [INFO] Overall accuracy (micro avg): 0.9863079984251635
2019-12-21 14:03:35,487 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9863         0.9863                       0.9863                0.0012                   0.0137  0.9863
1     Macro avg        0.9977         0.8103                       0.7347                0.0037                   0.2653  0.7583
2  Weighted avg        0.9884         0.9858                       0.9863                0.0313                   0.0137  0.9859
2019-12-21 14:03:35,539 [INFO] Results saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep2/selected_ids17_ae_ann_shallow_rep2_results.xlsx
2019-12-21 14:03:35,542 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-21 14:03:35,607 [INFO] Created directory: results_selected_models/selected_ids17_ae_ann_shallow_rep3
2019-12-21 14:03:35,607 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_ae_ann_shallow_rep3/run_log.log
2019-12-21 14:03:35,607 [INFO] ================= Running experiment no. 3  ================= 

2019-12-21 14:03:35,608 [INFO] Experiment parameters given below
2019-12-21 14:03:35,608 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids17_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_ae_ann_shallow_rep3'}
2019-12-21 14:03:35,608 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_ae_ann_shallow_rep3/tf_logs_run_2019_12_21-14_03_35
2019-12-21 14:03:35,608 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 14:03:35,608 [INFO] Reading X, y files
2019-12-21 14:03:35,608 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 14:03:39,654 [INFO] Reading complete. time_to_read=4.05 seconds
2019-12-21 14:03:39,654 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 14:03:41,042 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 14:03:41,042 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 14:03:42,430 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 14:03:42,430 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 14:03:42,619 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-21 14:03:42,619 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 14:03:42,686 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 14:03:42,687 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 14:03:42,754 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 14:03:45,899 [INFO] Initializing model
2019-12-21 14:03:46,010 [INFO] _________________________________________________________________
2019-12-21 14:03:46,010 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 14:03:46,011 [INFO] =================================================================
2019-12-21 14:03:46,011 [INFO] dense_29 (Dense)             (None, 32)                2528      
2019-12-21 14:03:46,011 [INFO] _________________________________________________________________
2019-12-21 14:03:46,011 [INFO] batch_normalization_15 (Batc (None, 32)                128       
2019-12-21 14:03:46,011 [INFO] _________________________________________________________________
2019-12-21 14:03:46,011 [INFO] dropout_15 (Dropout)         (None, 32)                0         
2019-12-21 14:03:46,011 [INFO] _________________________________________________________________
2019-12-21 14:03:46,011 [INFO] dense_30 (Dense)             (None, 78)                2574      
2019-12-21 14:03:46,011 [INFO] =================================================================
2019-12-21 14:03:46,011 [INFO] Total params: 5,230
2019-12-21 14:03:46,011 [INFO] Trainable params: 5,166
2019-12-21 14:03:46,011 [INFO] Non-trainable params: 64
2019-12-21 14:03:46,011 [INFO] _________________________________________________________________
2019-12-21 14:03:46,119 [INFO] _________________________________________________________________
2019-12-21 14:03:46,119 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 14:03:46,119 [INFO] =================================================================
2019-12-21 14:03:46,119 [INFO] dense_31 (Dense)             (None, 32)                1056      
2019-12-21 14:03:46,119 [INFO] _________________________________________________________________
2019-12-21 14:03:46,119 [INFO] batch_normalization_16 (Batc (None, 32)                128       
2019-12-21 14:03:46,120 [INFO] _________________________________________________________________
2019-12-21 14:03:46,120 [INFO] dropout_16 (Dropout)         (None, 32)                0         
2019-12-21 14:03:46,120 [INFO] _________________________________________________________________
2019-12-21 14:03:46,120 [INFO] dense_32 (Dense)             (None, 12)                396       
2019-12-21 14:03:46,120 [INFO] =================================================================
2019-12-21 14:03:46,120 [INFO] Total params: 1,580
2019-12-21 14:03:46,120 [INFO] Trainable params: 1,516
2019-12-21 14:03:46,120 [INFO] Non-trainable params: 64
2019-12-21 14:03:46,120 [INFO] _________________________________________________________________
2019-12-21 14:03:46,120 [INFO] Training model
2019-12-21 14:03:46,120 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 14:04:02,701 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342
2019-12-21 14:04:02,701 [INFO] Training autoencoder
 - val_f1: 0.9844
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 14s - loss: -3.3811e+00 - val_loss: -4.0993e+00
Epoch 2/200
 - 13s - loss: -4.0291e+00 - val_loss: -4.1236e+00
Epoch 3/200
 - 13s - loss: -4.0567e+00 - val_loss: -4.1137e+00
Epoch 4/200
 - 13s - loss: -4.0674e+00 - val_loss: -4.1358e+00
Epoch 5/200
 - 13s - loss: -4.0746e+00 - val_loss: -4.1367e+00
Epoch 6/200
 - 13s - loss: -4.0784e+00 - val_loss: -4.1400e+00
Epoch 7/200
 - 13s - loss: -4.0814e+00 - val_loss: -4.1397e+00
Epoch 8/200
 - 13s - loss: -4.0837e+00 - val_loss: -4.1390e+00
Epoch 9/200
 - 13s - loss: -4.0855e+00 - val_loss: -4.1399e+00
Epoch 10/200
 - 13s - loss: -4.0878e+00 - val_loss: -4.1423e+00
Epoch 11/200
 - 13s - loss: -4.0892e+00 - val_loss: -4.1420e+00
Epoch 12/200
 - 13s - loss: -4.0901e+00 - val_loss: -4.1429e+00
Epoch 13/200
 - 13s - loss: -4.0914e+00 - val_loss: -4.1431e+00
Epoch 14/200
 - 13s - loss: -4.0923e+00 - val_loss: -4.1439e+00
Epoch 15/200
 - 13s - loss: -4.0939e+00 - val_loss: -4.1449e+00
Epoch 16/200
 - 13s - loss: -4.0947e+00 - val_loss: -4.1440e+00
Epoch 17/200
 - 13s - loss: -4.0950e+00 - val_loss: -4.1455e+00
Epoch 18/200
 - 13s - loss: -4.0957e+00 - val_loss: -4.1450e+00
Epoch 19/200
 - 13s - loss: -4.0962e+00 - val_loss: -4.1447e+00
Epoch 20/200
 - 13s - loss: -4.0963e+00 - val_loss: -4.1446e+00
Epoch 21/200
 - 13s - loss: -4.0971e+00 - val_loss: -4.1454e+00
2019-12-21 14:08:41,584 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_20.pickle
Epoch 22/200
 - 13s - loss: -4.0974e+00 - val_loss: -4.1457e+00
Epoch 23/200
 - 13s - loss: -4.0975e+00 - val_loss: -4.1462e+00
Epoch 24/200
 - 13s - loss: -4.0984e+00 - val_loss: -4.1460e+00
Epoch 25/200
 - 13s - loss: -4.0984e+00 - val_loss: -4.1465e+00
Epoch 26/200
 - 13s - loss: -4.0987e+00 - val_loss: -4.1462e+00
Epoch 27/200
 - 13s - loss: -4.0992e+00 - val_loss: -4.1461e+00
Epoch 28/200
 - 13s - loss: -4.0996e+00 - val_loss: -4.1447e+00
Epoch 29/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1471e+00
Epoch 30/200
 - 13s - loss: -4.1001e+00 - val_loss: -4.1449e+00
Epoch 31/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1468e+00
Epoch 32/200
 - 13s - loss: -4.1003e+00 - val_loss: -4.1471e+00
Epoch 33/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1465e+00
Epoch 34/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1471e+00
Epoch 35/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1471e+00
Epoch 36/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1470e+00
Epoch 37/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1472e+00
Epoch 38/200
 - 13s - loss: -4.1018e+00 - val_loss: -4.1475e+00
Epoch 39/200
 - 13s - loss: -4.1022e+00 - val_loss: -4.1462e+00
Epoch 40/200
 - 13s - loss: -4.1021e+00 - val_loss: -4.1477e+00
Epoch 41/200
 - 13s - loss: -4.1021e+00 - val_loss: -4.1470e+00
2019-12-21 14:13:03,681 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_40.pickle
Epoch 42/200
 - 13s - loss: -4.1026e+00 - val_loss: -4.1470e+00
Epoch 43/200
 - 13s - loss: -4.1029e+00 - val_loss: -4.1470e+00
Epoch 44/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1478e+00
Epoch 45/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1475e+00
Epoch 46/200
 - 13s - loss: -4.1031e+00 - val_loss: -4.1469e+00
Epoch 47/200
 - 13s - loss: -4.1036e+00 - val_loss: -4.1475e+00
Epoch 48/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1471e+00
Epoch 49/200
 - 13s - loss: -4.1036e+00 - val_loss: -4.1474e+00
Epoch 50/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1470e+00
Epoch 51/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1478e+00
Epoch 52/200
 - 13s - loss: -4.1040e+00 - val_loss: -4.1467e+00
Epoch 53/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1471e+00
Epoch 54/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1476e+00
Epoch 55/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1470e+00
Epoch 56/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1459e+00
Epoch 57/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1473e+00
Epoch 58/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1475e+00
Epoch 59/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1477e+00
Epoch 60/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1477e+00
Epoch 61/200
 - 13s - loss: -4.1049e+00 - val_loss: -4.1468e+00
2019-12-21 14:17:25,363 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_60.pickle
Epoch 62/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1449e+00
Epoch 63/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1476e+00
Epoch 64/200
 - 13s - loss: -4.1049e+00 - val_loss: -4.1473e+00
Epoch 65/200
 - 13s - loss: -4.1055e+00 - val_loss: -4.1471e+00
Epoch 66/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1469e+00
Epoch 67/200
 - 13s - loss: -4.1056e+00 - val_loss: -4.1480e+00
Epoch 68/200
 - 13s - loss: -4.1054e+00 - val_loss: -4.1473e+00
Epoch 69/200
 - 13s - loss: -4.1056e+00 - val_loss: -4.1475e+00
Epoch 70/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1466e+00
Epoch 71/200
 - 13s - loss: -4.1057e+00 - val_loss: -4.1474e+00
Epoch 72/200
 - 13s - loss: -4.1057e+00 - val_loss: -4.1468e+00
Epoch 73/200
 - 13s - loss: -4.1057e+00 - val_loss: -4.1468e+00
Epoch 74/200
 - 13s - loss: -4.1056e+00 - val_loss: -4.1467e+00
Epoch 75/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1469e+00
Epoch 76/200
 - 13s - loss: -4.1059e+00 - val_loss: -4.1470e+00
Epoch 77/200
 - 13s - loss: -4.1058e+00 - val_loss: -4.1477e+00
Epoch 78/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1473e+00
Epoch 79/200
 - 13s - loss: -4.1060e+00 - val_loss: -4.1476e+00
Epoch 80/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1472e+00
Epoch 81/200
 - 13s - loss: -4.1065e+00 - val_loss: -4.1468e+00
2019-12-21 14:21:47,276 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_80.pickle
Epoch 82/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1480e+00
Epoch 83/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1481e+00
Epoch 84/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1482e+00
Epoch 85/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1480e+00
Epoch 86/200
 - 13s - loss: -4.1067e+00 - val_loss: -4.1462e+00
Epoch 87/200
 - 13s - loss: -4.1063e+00 - val_loss: -4.1481e+00
Epoch 88/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1479e+00
Epoch 89/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1477e+00
Epoch 90/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1462e+00
Epoch 91/200
 - 13s - loss: -4.1067e+00 - val_loss: -4.1482e+00
Epoch 92/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1476e+00
Epoch 93/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1477e+00
Epoch 94/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1482e+00
Epoch 95/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1478e+00
Epoch 96/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1467e+00
Epoch 97/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1483e+00
Epoch 98/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1484e+00
Epoch 99/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1487e+00
Epoch 100/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1483e+00
Epoch 101/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1486e+00
2019-12-21 14:26:09,308 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_100.pickle
Epoch 102/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1483e+00
Epoch 103/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1487e+00
Epoch 104/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1481e+00
Epoch 105/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1465e+00
Epoch 106/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1480e+00
Epoch 107/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1478e+00
Epoch 108/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1484e+00
Epoch 109/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1483e+00
Epoch 110/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1488e+00
Epoch 111/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1478e+00
Epoch 112/200
 - 13s - loss: -4.1072e+00 - val_loss: -4.1479e+00
Epoch 113/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1469e+00
Epoch 114/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1486e+00
Epoch 115/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1491e+00
Epoch 116/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1484e+00
Epoch 117/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1477e+00
Epoch 118/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1485e+00
Epoch 119/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1490e+00
Epoch 120/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1486e+00
Epoch 121/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1489e+00
2019-12-21 14:30:31,008 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_120.pickle
Epoch 122/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1486e+00
Epoch 123/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1487e+00
Epoch 124/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1488e+00
Epoch 125/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1477e+00
Epoch 126/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1488e+00
Epoch 127/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1482e+00
Epoch 128/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1477e+00
Epoch 129/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1485e+00
Epoch 130/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1489e+00
Epoch 131/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1399e+00
Epoch 132/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1482e+00
Epoch 133/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1483e+00
Epoch 134/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1483e+00
Epoch 135/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1489e+00
Epoch 136/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1489e+00
Epoch 137/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1486e+00
Epoch 138/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1486e+00
Epoch 139/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1485e+00
Epoch 140/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1487e+00
Epoch 141/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1486e+00
2019-12-21 14:34:52,795 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_140.pickle
Epoch 142/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1492e+00
Epoch 143/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1487e+00
Epoch 144/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1485e+00
Epoch 145/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1486e+00
Epoch 146/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1490e+00
Epoch 147/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1486e+00
Epoch 148/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1480e+00
Epoch 149/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1487e+00
Epoch 150/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1486e+00
Epoch 151/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1481e+00
Epoch 152/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1489e+00
Epoch 153/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1485e+00
Epoch 154/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1486e+00
Epoch 155/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1493e+00
Epoch 156/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1486e+00
Epoch 157/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1489e+00
Epoch 158/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1384e+00
Epoch 159/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1412e+00
Epoch 160/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1479e+00
Epoch 161/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1484e+00
2019-12-21 14:39:16,080 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_160.pickle
Epoch 162/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1415e+00
Epoch 163/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1414e+00
Epoch 164/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1447e+00
Epoch 165/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1414e+00
Epoch 166/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1490e+00
Epoch 167/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1484e+00
Epoch 168/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1424e+00
Epoch 169/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1492e+00
Epoch 170/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1489e+00
Epoch 171/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1481e+00
Epoch 172/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1488e+00
Epoch 173/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1487e+00
Epoch 174/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1491e+00
Epoch 175/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1448e+00
Epoch 176/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1415e+00
Epoch 177/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1484e+00
Epoch 178/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1494e+00
Epoch 179/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1493e+00
Epoch 180/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1458e+00
Epoch 181/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1479e+00
2019-12-21 14:43:39,288 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ae_model_epoch_180.pickle
Epoch 182/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1494e+00
Epoch 183/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1487e+00
Epoch 184/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1438e+00
Epoch 185/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1490e+00
Epoch 186/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1415e+00
Epoch 187/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1411e+00
Epoch 188/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1424e+00
Epoch 189/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1485e+00
Epoch 190/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1493e+00
Epoch 191/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1491e+00
Epoch 192/200
 - 13s - loss: -4.1069e+00 - val_loss: -4.1492e+00
Epoch 193/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1486e+00
Epoch 194/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1490e+00
Epoch 195/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1488e+00
Epoch 196/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1496e+00
Epoch 197/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1492e+00
Epoch 198/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1487e+00
Epoch 199/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1486e+00
Epoch 200/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1471e+00
2019-12-21 14:47:48,863 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 14:48:13,954 [INFO] Last epoch loss evaluation: train_loss = -4.151785, val_loss = -4.149631
2019-12-21 14:48:13,954 [INFO] Training autoencoder complete
2019-12-21 14:48:13,954 [INFO] Encoding data for supervised training
2019-12-21 14:48:37,767 [INFO] Encoding complete
2019-12-21 14:48:37,767 [INFO] Training neural network layers (after autoencoder)
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 7s - loss: 0.0331 - val_loss: 0.0138
 - val_f1: 0.9663
Epoch 2/200
 - 6s - loss: 0.0152 - val_loss: 0.0116
 - val_f1: 0.9683
Epoch 3/200
 - 6s - loss: 0.0134 - val_loss: 0.0105
 - val_f1: 0.9729
Epoch 4/200
 - 6s - loss: 0.0126 - val_loss: 0.0101
 - val_f1: 0.9732
Epoch 5/200
 - 6s - loss: 0.0122 - val_loss: 0.0098
 - val_f1: 0.9725
Epoch 6/200
 - 6s - loss: 0.0119 - val_loss: 0.0097
 - val_f1: 0.9758
Epoch 7/200
 - 6s - loss: 0.0116 - val_loss: 0.0098
 - val_f1: 0.9752
Epoch 8/200
 - 6s - loss: 0.0113 - val_loss: 0.0091
 - val_f1: 0.9746
Epoch 9/200
 - 6s - loss: 0.0111 - val_loss: 0.0092
 - val_f1: 0.9760
Epoch 10/200
 - 6s - loss: 0.0109 - val_loss: 0.0092
 - val_f1: 0.9750
Epoch 11/200
 - 6s - loss: 0.0108 - val_loss: 0.0089
 - val_f1: 0.9763
Epoch 12/200
 - 6s - loss: 0.0106 - val_loss: 0.0090
 - val_f1: 0.9761
Epoch 13/200
 - 6s - loss: 0.0106 - val_loss: 0.0085
 - val_f1: 0.9762
Epoch 14/200
 - 6s - loss: 0.0104 - val_loss: 0.0085
 - val_f1: 0.9760
Epoch 15/200
 - 6s - loss: 0.0104 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 16/200
 - 6s - loss: 0.0104 - val_loss: 0.0088
 - val_f1: 0.9787
Epoch 17/200
 - 6s - loss: 0.0103 - val_loss: 0.0087
 - val_f1: 0.9752
Epoch 18/200
 - 6s - loss: 0.0102 - val_loss: 0.0089
 - val_f1: 0.9749
Epoch 19/200
 - 6s - loss: 0.0102 - val_loss: 0.0094
 - val_f1: 0.9736
Epoch 20/200
 - 6s - loss: 0.0101 - val_loss: 0.0082
 - val_f1: 0.9795
Epoch 21/200
 - 6s - loss: 0.0101 - val_loss: 0.0085
2019-12-21 14:54:00,418 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9797
Epoch 22/200
 - 6s - loss: 0.0100 - val_loss: 0.0085
 - val_f1: 0.9774
Epoch 23/200
 - 6s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9765
Epoch 24/200
 - 6s - loss: 0.0099 - val_loss: 0.0083
 - val_f1: 0.9765
Epoch 25/200
 - 6s - loss: 0.0099 - val_loss: 0.0083
 - val_f1: 0.9782
Epoch 26/200
 - 6s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9755
Epoch 27/200
 - 6s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9773
Epoch 28/200
 - 6s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9788
Epoch 29/200
 - 6s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9753
Epoch 30/200
 - 6s - loss: 0.0097 - val_loss: 0.0091
 - val_f1: 0.9759
Epoch 31/200
 - 6s - loss: 0.0096 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 32/200
 - 6s - loss: 0.0097 - val_loss: 0.0078
 - val_f1: 0.9812
Epoch 33/200
 - 6s - loss: 0.0097 - val_loss: 0.0079
 - val_f1: 0.9812
Epoch 34/200
 - 6s - loss: 0.0095 - val_loss: 0.0094
 - val_f1: 0.9768
Epoch 35/200
 - 6s - loss: 0.0096 - val_loss: 0.0079
 - val_f1: 0.9774
Epoch 36/200
 - 6s - loss: 0.0095 - val_loss: 0.0078
 - val_f1: 0.9805
Epoch 37/200
 - 6s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9775
Epoch 38/200
 - 6s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 39/200
 - 6s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9764
Epoch 40/200
 - 6s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9821
Epoch 41/200
 - 6s - loss: 0.0094 - val_loss: 0.0084
2019-12-21 14:59:13,896 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9774
Epoch 42/200
 - 6s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9768
Epoch 43/200
 - 6s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 44/200
 - 6s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 45/200
 - 6s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9821
Epoch 46/200
 - 6s - loss: 0.0094 - val_loss: 0.0077
 - val_f1: 0.9806
Epoch 47/200
 - 6s - loss: 0.0093 - val_loss: 0.0081
 - val_f1: 0.9772
Epoch 48/200
 - 6s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9722
Epoch 49/200
 - 6s - loss: 0.0093 - val_loss: 0.0080
 - val_f1: 0.9759
Epoch 50/200
 - 6s - loss: 0.0093 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 51/200
 - 6s - loss: 0.0093 - val_loss: 0.0078
 - val_f1: 0.9823
Epoch 52/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9820
Epoch 53/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 54/200
 - 6s - loss: 0.0092 - val_loss: 0.0080
 - val_f1: 0.9807
Epoch 55/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9823
Epoch 56/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 57/200
 - 6s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9802
Epoch 58/200
 - 6s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9807
Epoch 59/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9787
Epoch 60/200
 - 6s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 61/200
 - 6s - loss: 0.0092 - val_loss: 0.0076
2019-12-21 15:04:27,864 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9831
Epoch 62/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 63/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 64/200
 - 6s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9822
Epoch 65/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 66/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9818
Epoch 67/200
 - 6s - loss: 0.0091 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 68/200
 - 6s - loss: 0.0091 - val_loss: 0.0073
 - val_f1: 0.9800
Epoch 69/200
 - 6s - loss: 0.0092 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 70/200
 - 6s - loss: 0.0091 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 71/200
 - 6s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9822
Epoch 72/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9822
Epoch 73/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9830
Epoch 74/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9834
Epoch 75/200
 - 6s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9810
Epoch 76/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9819
Epoch 77/200
 - 6s - loss: 0.0091 - val_loss: 0.0074
 - val_f1: 0.9816
Epoch 78/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9775
Epoch 79/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9796
Epoch 80/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9766
Epoch 81/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
2019-12-21 15:09:41,171 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9825
Epoch 82/200
 - 6s - loss: 0.0090 - val_loss: 0.0078
 - val_f1: 0.9778
Epoch 83/200
 - 6s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9798
Epoch 84/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9772
Epoch 85/200
 - 6s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 86/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9799
Epoch 87/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9803
Epoch 88/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9820
Epoch 89/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9819
Epoch 90/200
 - 6s - loss: 0.0090 - val_loss: 0.0074
 - val_f1: 0.9798
Epoch 91/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 92/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9826
Epoch 93/200
 - 6s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 94/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 95/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9830
Epoch 96/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9798
Epoch 97/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9818
Epoch 98/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 99/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9797
Epoch 100/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9818
Epoch 101/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
2019-12-21 15:14:55,335 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9821
Epoch 102/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9807
Epoch 103/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9812
Epoch 104/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9823
Epoch 105/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9770
Epoch 106/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9801
Epoch 107/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9796
Epoch 108/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9806
Epoch 109/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9838
Epoch 110/200
 - 6s - loss: 0.0088 - val_loss: 0.0077
 - val_f1: 0.9798
Epoch 111/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9830
Epoch 112/200
 - 6s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9792
Epoch 113/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9821
Epoch 114/200
 - 6s - loss: 0.0089 - val_loss: 0.0073
 - val_f1: 0.9781
Epoch 115/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9824
Epoch 116/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9841
Epoch 117/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9791
Epoch 118/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9793
Epoch 119/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9807
Epoch 120/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9820
Epoch 121/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
2019-12-21 15:20:08,327 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9810
Epoch 122/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9836
Epoch 123/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9793
Epoch 124/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9804
Epoch 125/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9829
Epoch 126/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9801
Epoch 127/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9783
Epoch 128/200
 - 6s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9836
Epoch 129/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9783
Epoch 130/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9803
Epoch 131/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9833
Epoch 132/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9813
Epoch 133/200
 - 6s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 134/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9832
Epoch 135/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9845
Epoch 136/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9787
Epoch 137/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9813
Epoch 138/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9826
Epoch 139/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9804
Epoch 140/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9790
Epoch 141/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
2019-12-21 15:25:22,136 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9789
Epoch 142/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 143/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9814
Epoch 144/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9836
Epoch 145/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9840
Epoch 146/200
 - 6s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9794
Epoch 147/200
 - 6s - loss: 0.0086 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 148/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9786
Epoch 149/200
 - 6s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9795
Epoch 150/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9840
Epoch 151/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9795
Epoch 152/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9823
Epoch 153/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9858
Epoch 154/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9842
Epoch 155/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 156/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9835
Epoch 157/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9843
Epoch 158/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 159/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9838
Epoch 160/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9796
Epoch 161/200
 - 6s - loss: 0.0086 - val_loss: 0.0079
2019-12-21 15:30:36,027 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9788
Epoch 162/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9833
Epoch 163/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9797
Epoch 164/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9842
Epoch 165/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9814
Epoch 166/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9828
Epoch 167/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9837
Epoch 168/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9835
Epoch 169/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9804
Epoch 170/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 171/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9791
Epoch 172/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9794
Epoch 173/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9809
Epoch 174/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9841
Epoch 175/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9828
Epoch 176/200
 - 6s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9806
Epoch 177/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9826
Epoch 178/200
 - 6s - loss: 0.0086 - val_loss: 0.0068
 - val_f1: 0.9845
Epoch 179/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9793
Epoch 180/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9826
Epoch 181/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
2019-12-21 15:35:49,559 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9841
Epoch 182/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9847
Epoch 183/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9791
Epoch 184/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9836
Epoch 185/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9838
Epoch 186/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9801
Epoch 187/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9838
Epoch 188/200
 - 6s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9805
Epoch 189/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9841
Epoch 190/200
 - 6s - loss: 0.0084 - val_loss: 0.0075
 - val_f1: 0.9790
Epoch 191/200
 - 6s - loss: 0.0084 - val_loss: 0.0070
 - val_f1: 0.9827
Epoch 192/200
 - 6s - loss: 0.0083 - val_loss: 0.0071
 - val_f1: 0.9844
Epoch 193/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9799
Epoch 194/200
 - 6s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9841
Epoch 195/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9815
Epoch 196/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9838
Epoch 197/200
 - 6s - loss: 0.0085 - val_loss: 0.0078
 - val_f1: 0.9805
Epoch 198/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9788
Epoch 199/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9830
Epoch 200/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
2019-12-21 15:40:57,978 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 15:41:24,189 [INFO] Last epoch loss evaluation: train_loss = 0.006645, val_loss = 0.006841
2019-12-21 15:41:24,223 [INFO] Training complete. time_to_train = 5858.10 sec, 97.64 min
2019-12-21 15:41:24,232 [INFO] Model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep3/best_model.pickle
2019-12-21 15:41:24,415 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep3/training_error_history.png
2019-12-21 15:41:24,607 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep3/training_f1_history.png
2019-12-21 15:41:24,607 [INFO] Making predictions on training, validation, testing data
2019-12-21 15:42:58,227 [INFO] Evaluating predictions (results)
2019-12-21 15:43:08,368 [INFO] Dataset: Testing. Classification report below
2019-12-21 15:43:08,368 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       0.97      0.35      0.52       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.99      0.95      0.97      2058
              DoS Hulk       0.95      1.00      0.97     46025
      DoS Slowhttptest       0.88      0.95      0.92      1100
         DoS slowloris       0.98      0.87      0.92      1159
           FTP-Patator       0.99      0.98      0.99      1587
              PortScan       0.89      0.97      0.93     31761
           SSH-Patator       0.96      0.96      0.96      1179
Web Attack Brute Force       0.86      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.87      0.76      0.77    565562
          weighted avg       0.98      0.98      0.98    565562

2019-12-21 15:43:08,368 [INFO] Overall accuracy (micro avg): 0.9845056775384485
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-21 15:43:19,910 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9845         0.9845                       0.9845                0.0014                   0.0155  0.9845
1     Macro avg        0.9974         0.8721                       0.7561                0.0027                   0.2439  0.7725
2  Weighted avg        0.9868         0.9849                       0.9845                0.0175                   0.0155  0.9843
2019-12-21 15:43:30,246 [INFO] Dataset: Validation. Classification report below
2019-12-21 15:43:30,246 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       0.98      0.31      0.47       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.99      0.95      0.97      2059
              DoS Hulk       0.95      1.00      0.97     46025
      DoS Slowhttptest       0.89      0.94      0.91      1099
         DoS slowloris       0.98      0.87      0.92      1159
           FTP-Patator       0.99      0.97      0.98      1587
              PortScan       0.89      0.97      0.93     31761
           SSH-Patator       0.96      0.96      0.96      1180
Web Attack Brute Force       0.92      0.04      0.08       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.88      0.75      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2019-12-21 15:43:30,246 [INFO] Overall accuracy (micro avg): 0.9844508648035052
2019-12-21 15:43:41,980 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9845         0.9845                       0.9845                0.0014                   0.0155  0.9845
1     Macro avg        0.9974         0.8794                       0.7485                0.0028                   0.2515  0.7648
2  Weighted avg        0.9868         0.9849                       0.9845                0.0178                   0.0155  0.9842
2019-12-21 15:44:16,055 [INFO] Dataset: Training. Classification report below
2019-12-21 15:44:16,055 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      0.99   1362791
                   Bot       0.98      0.35      0.51      1174
                  DDoS       1.00      0.99      0.99     76815
         DoS GoldenEye       0.98      0.95      0.97      6176
              DoS Hulk       0.95      1.00      0.97    138074
      DoS Slowhttptest       0.90      0.95      0.92      3300
         DoS slowloris       0.98      0.88      0.93      3478
           FTP-Patator       0.99      0.98      0.99      4761
              PortScan       0.89      0.97      0.93     95282
           SSH-Patator       0.97      0.97      0.97      3538
Web Attack Brute Force       0.86      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.98      0.98      0.98   1696684
             macro avg       0.87      0.76      0.77   1696684
          weighted avg       0.99      0.98      0.98   1696684

2019-12-21 15:44:16,057 [INFO] Overall accuracy (micro avg): 0.9847797232719823
2019-12-21 15:44:54,747 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9848         0.9848                       0.9848                0.0014                   0.0152  0.9848
1     Macro avg        0.9975         0.8749                       0.7556                0.0027                   0.2444  0.7719
2  Weighted avg        0.9870         0.9852                       0.9848                0.0170                   0.0152  0.9845
2019-12-21 15:44:54,798 [INFO] Results saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep3/selected_ids17_ae_ann_shallow_rep3_results.xlsx
2019-12-21 15:44:54,802 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-21 15:44:54,868 [INFO] Created directory: results_selected_models/selected_ids17_ae_ann_shallow_rep4
2019-12-21 15:44:54,868 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_ae_ann_shallow_rep4/run_log.log
2019-12-21 15:44:54,868 [INFO] ================= Running experiment no. 4  ================= 

2019-12-21 15:44:54,868 [INFO] Experiment parameters given below
2019-12-21 15:44:54,868 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids17_ae_ann_shallow_rep4', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_ae_ann_shallow_rep4'}
2019-12-21 15:44:54,868 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_ae_ann_shallow_rep4/tf_logs_run_2019_12_21-15_44_54
2019-12-21 15:44:54,869 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 15:44:54,869 [INFO] Reading X, y files
2019-12-21 15:44:54,869 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 15:44:58,911 [INFO] Reading complete. time_to_read=4.04 seconds
2019-12-21 15:44:58,914 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 15:45:00,302 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 15:45:00,302 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 15:45:01,692 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 15:45:01,692 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 15:45:01,895 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-21 15:45:01,895 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 15:45:01,963 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 15:45:01,963 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 15:45:02,031 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 15:45:05,198 [INFO] Initializing model
2019-12-21 15:45:05,310 [INFO] _________________________________________________________________
2019-12-21 15:45:05,310 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 15:45:05,310 [INFO] =================================================================
2019-12-21 15:45:05,310 [INFO] dense_33 (Dense)             (None, 32)                2528      
2019-12-21 15:45:05,310 [INFO] _________________________________________________________________
2019-12-21 15:45:05,310 [INFO] batch_normalization_17 (Batc (None, 32)                128       
2019-12-21 15:45:05,310 [INFO] _________________________________________________________________
2019-12-21 15:45:05,310 [INFO] dropout_17 (Dropout)         (None, 32)                0         
2019-12-21 15:45:05,310 [INFO] _________________________________________________________________
2019-12-21 15:45:05,310 [INFO] dense_34 (Dense)             (None, 78)                2574      
2019-12-21 15:45:05,310 [INFO] =================================================================
2019-12-21 15:45:05,311 [INFO] Total params: 5,230
2019-12-21 15:45:05,311 [INFO] Trainable params: 5,166
2019-12-21 15:45:05,311 [INFO] Non-trainable params: 64
2019-12-21 15:45:05,311 [INFO] _________________________________________________________________
2019-12-21 15:45:05,422 [INFO] _________________________________________________________________
2019-12-21 15:45:05,422 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 15:45:05,422 [INFO] =================================================================
2019-12-21 15:45:05,422 [INFO] dense_35 (Dense)             (None, 32)                1056      
2019-12-21 15:45:05,422 [INFO] _________________________________________________________________
2019-12-21 15:45:05,422 [INFO] batch_normalization_18 (Batc (None, 32)                128       
2019-12-21 15:45:05,423 [INFO] _________________________________________________________________
2019-12-21 15:45:05,423 [INFO] dropout_18 (Dropout)         (None, 32)                0         
2019-12-21 15:45:05,423 [INFO] _________________________________________________________________
2019-12-21 15:45:05,423 [INFO] dense_36 (Dense)             (None, 12)                396       
2019-12-21 15:45:05,423 [INFO] =================================================================
2019-12-21 15:45:05,423 [INFO] Total params: 1,580
2019-12-21 15:45:05,423 [INFO] Trainable params: 1,516
2019-12-21 15:45:05,423 [INFO] Non-trainable params: 64
2019-12-21 15:45:05,423 [INFO] _________________________________________________________________
2019-12-21 15:45:05,423 [INFO] Training model
2019-12-21 15:45:05,423 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 15:45:21,944 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342
2019-12-21 15:45:21,945 [INFO] Training autoencoder
 - val_f1: 0.9830
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 13s - loss: -3.3693e+00 - val_loss: -4.1021e+00
Epoch 2/200
 - 13s - loss: -4.0237e+00 - val_loss: -4.1189e+00
Epoch 3/200
 - 13s - loss: -4.0507e+00 - val_loss: -4.1296e+00
Epoch 4/200
 - 13s - loss: -4.0627e+00 - val_loss: -4.1372e+00
Epoch 5/200
 - 13s - loss: -4.0692e+00 - val_loss: -4.1380e+00
Epoch 6/200
 - 13s - loss: -4.0733e+00 - val_loss: -4.1362e+00
Epoch 7/200
 - 13s - loss: -4.0765e+00 - val_loss: -4.1411e+00
Epoch 8/200
 - 13s - loss: -4.0775e+00 - val_loss: -4.1404e+00
Epoch 9/200
 - 13s - loss: -4.0793e+00 - val_loss: -4.1426e+00
Epoch 10/200
 - 13s - loss: -4.0825e+00 - val_loss: -4.1431e+00
Epoch 11/200
 - 13s - loss: -4.0838e+00 - val_loss: -4.1417e+00
Epoch 12/200
 - 13s - loss: -4.0847e+00 - val_loss: -4.1437e+00
Epoch 13/200
 - 13s - loss: -4.0858e+00 - val_loss: -4.1447e+00
Epoch 14/200
 - 13s - loss: -4.0872e+00 - val_loss: -4.1449e+00
Epoch 15/200
 - 13s - loss: -4.0878e+00 - val_loss: -4.1450e+00
Epoch 16/200
 - 13s - loss: -4.0889e+00 - val_loss: -4.1452e+00
Epoch 17/200
 - 13s - loss: -4.0890e+00 - val_loss: -4.1451e+00
Epoch 18/200
 - 13s - loss: -4.0899e+00 - val_loss: -4.1450e+00
Epoch 19/200
 - 13s - loss: -4.0906e+00 - val_loss: -4.1452e+00
Epoch 20/200
 - 13s - loss: -4.0899e+00 - val_loss: -4.1459e+00
Epoch 21/200
 - 13s - loss: -4.0915e+00 - val_loss: -4.1458e+00
2019-12-21 15:50:00,575 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_20.pickle
Epoch 22/200
 - 13s - loss: -4.0919e+00 - val_loss: -4.1460e+00
Epoch 23/200
 - 13s - loss: -4.0924e+00 - val_loss: -4.1457e+00
Epoch 24/200
 - 13s - loss: -4.0929e+00 - val_loss: -4.1460e+00
Epoch 25/200
 - 13s - loss: -4.0933e+00 - val_loss: -4.1466e+00
Epoch 26/200
 - 13s - loss: -4.0938e+00 - val_loss: -4.1461e+00
Epoch 27/200
 - 13s - loss: -4.0938e+00 - val_loss: -4.1462e+00
Epoch 28/200
 - 13s - loss: -4.0941e+00 - val_loss: -4.1463e+00
Epoch 29/200
 - 13s - loss: -4.0947e+00 - val_loss: -4.1460e+00
Epoch 30/200
 - 13s - loss: -4.0948e+00 - val_loss: -4.1465e+00
Epoch 31/200
 - 13s - loss: -4.0951e+00 - val_loss: -4.1471e+00
Epoch 32/200
 - 13s - loss: -4.0951e+00 - val_loss: -4.1470e+00
Epoch 33/200
 - 13s - loss: -4.0954e+00 - val_loss: -4.1466e+00
Epoch 34/200
 - 13s - loss: -4.0955e+00 - val_loss: -4.1462e+00
Epoch 35/200
 - 13s - loss: -4.0960e+00 - val_loss: -4.1471e+00
Epoch 36/200
 - 13s - loss: -4.0955e+00 - val_loss: -4.1469e+00
Epoch 37/200
 - 13s - loss: -4.0962e+00 - val_loss: -4.1471e+00
Epoch 38/200
 - 13s - loss: -4.0957e+00 - val_loss: -4.1472e+00
Epoch 39/200
 - 13s - loss: -4.0965e+00 - val_loss: -4.1438e+00
Epoch 40/200
 - 13s - loss: -4.0967e+00 - val_loss: -4.1463e+00
Epoch 41/200
 - 13s - loss: -4.0968e+00 - val_loss: -4.1471e+00
2019-12-21 15:54:20,489 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_40.pickle
Epoch 42/200
 - 13s - loss: -4.0972e+00 - val_loss: -4.1474e+00
Epoch 43/200
 - 13s - loss: -4.0974e+00 - val_loss: -4.1479e+00
Epoch 44/200
 - 13s - loss: -4.0971e+00 - val_loss: -4.1470e+00
Epoch 45/200
 - 13s - loss: -4.0975e+00 - val_loss: -4.1458e+00
Epoch 46/200
 - 13s - loss: -4.0977e+00 - val_loss: -4.1471e+00
Epoch 47/200
 - 13s - loss: -4.0979e+00 - val_loss: -4.1445e+00
Epoch 48/200
 - 13s - loss: -4.0976e+00 - val_loss: -4.1459e+00
Epoch 49/200
 - 13s - loss: -4.0979e+00 - val_loss: -4.1471e+00
Epoch 50/200
 - 13s - loss: -4.0979e+00 - val_loss: -4.1465e+00
Epoch 51/200
 - 13s - loss: -4.0982e+00 - val_loss: -4.1442e+00
Epoch 52/200
 - 13s - loss: -4.0982e+00 - val_loss: -4.1471e+00
Epoch 53/200
 - 13s - loss: -4.0982e+00 - val_loss: -4.1437e+00
Epoch 54/200
 - 13s - loss: -4.0984e+00 - val_loss: -4.1458e+00
Epoch 55/200
 - 13s - loss: -4.0986e+00 - val_loss: -4.1449e+00
Epoch 56/200
 - 13s - loss: -4.0986e+00 - val_loss: -4.1481e+00
Epoch 57/200
 - 13s - loss: -4.0986e+00 - val_loss: -4.1483e+00
Epoch 58/200
 - 13s - loss: -4.0985e+00 - val_loss: -4.1481e+00
Epoch 59/200
 - 13s - loss: -4.0989e+00 - val_loss: -4.1450e+00
Epoch 60/200
 - 13s - loss: -4.0989e+00 - val_loss: -4.1478e+00
Epoch 61/200
 - 13s - loss: -4.0991e+00 - val_loss: -4.1485e+00
2019-12-21 15:58:40,490 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_60.pickle
Epoch 62/200
 - 13s - loss: -4.0984e+00 - val_loss: -4.1478e+00
Epoch 63/200
 - 13s - loss: -4.0992e+00 - val_loss: -4.1478e+00
Epoch 64/200
 - 13s - loss: -4.0992e+00 - val_loss: -4.1471e+00
Epoch 65/200
 - 13s - loss: -4.0991e+00 - val_loss: -4.1470e+00
Epoch 66/200
 - 13s - loss: -4.0994e+00 - val_loss: -4.1449e+00
Epoch 67/200
 - 13s - loss: -4.0996e+00 - val_loss: -4.1463e+00
Epoch 68/200
 - 13s - loss: -4.0993e+00 - val_loss: -4.1487e+00
Epoch 69/200
 - 13s - loss: -4.0995e+00 - val_loss: -4.1485e+00
Epoch 70/200
 - 13s - loss: -4.0997e+00 - val_loss: -4.1486e+00
Epoch 71/200
 - 13s - loss: -4.0999e+00 - val_loss: -4.1485e+00
Epoch 72/200
 - 13s - loss: -4.1001e+00 - val_loss: -4.1486e+00
Epoch 73/200
 - 13s - loss: -4.0992e+00 - val_loss: -4.1480e+00
Epoch 74/200
 - 13s - loss: -4.1002e+00 - val_loss: -4.1485e+00
Epoch 75/200
 - 13s - loss: -4.0999e+00 - val_loss: -4.1486e+00
Epoch 76/200
 - 13s - loss: -4.1001e+00 - val_loss: -4.1478e+00
Epoch 77/200
 - 13s - loss: -4.1002e+00 - val_loss: -4.1489e+00
Epoch 78/200
 - 13s - loss: -4.1001e+00 - val_loss: -4.1489e+00
Epoch 79/200
 - 13s - loss: -4.1002e+00 - val_loss: -4.1437e+00
Epoch 80/200
 - 13s - loss: -4.1002e+00 - val_loss: -4.1451e+00
Epoch 81/200
 - 13s - loss: -4.1002e+00 - val_loss: -4.1485e+00
2019-12-21 16:03:00,387 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_80.pickle
Epoch 82/200
 - 13s - loss: -4.1004e+00 - val_loss: -4.1492e+00
Epoch 83/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1482e+00
Epoch 84/200
 - 13s - loss: -4.1003e+00 - val_loss: -4.1486e+00
Epoch 85/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1487e+00
Epoch 86/200
 - 13s - loss: -4.1004e+00 - val_loss: -4.1488e+00
Epoch 87/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1473e+00
Epoch 88/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1463e+00
Epoch 89/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1493e+00
Epoch 90/200
 - 13s - loss: -4.1004e+00 - val_loss: -4.1487e+00
Epoch 91/200
 - 13s - loss: -4.1003e+00 - val_loss: -4.1411e+00
Epoch 92/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1471e+00
Epoch 93/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1473e+00
Epoch 94/200
 - 13s - loss: -4.1006e+00 - val_loss: -4.1492e+00
Epoch 95/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1493e+00
Epoch 96/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1474e+00
Epoch 97/200
 - 13s - loss: -4.1006e+00 - val_loss: -4.1489e+00
Epoch 98/200
 - 13s - loss: -4.1009e+00 - val_loss: -4.1495e+00
Epoch 99/200
 - 13s - loss: -4.1009e+00 - val_loss: -4.1494e+00
Epoch 100/200
 - 13s - loss: -4.1000e+00 - val_loss: -4.1451e+00
Epoch 101/200
 - 13s - loss: -4.1006e+00 - val_loss: -4.1486e+00
2019-12-21 16:07:20,106 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_100.pickle
Epoch 102/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1478e+00
Epoch 103/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1496e+00
Epoch 104/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1491e+00
Epoch 105/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1468e+00
Epoch 106/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1473e+00
Epoch 107/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1477e+00
Epoch 108/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1487e+00
Epoch 109/200
 - 13s - loss: -4.1009e+00 - val_loss: -4.1489e+00
Epoch 110/200
 - 13s - loss: -4.1004e+00 - val_loss: -4.1489e+00
Epoch 111/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1425e+00
Epoch 112/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1470e+00
Epoch 113/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1470e+00
Epoch 114/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1461e+00
Epoch 115/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1468e+00
Epoch 116/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1475e+00
Epoch 117/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1494e+00
Epoch 118/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1486e+00
Epoch 119/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1488e+00
Epoch 120/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1492e+00
Epoch 121/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1496e+00
2019-12-21 16:11:39,709 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_120.pickle
Epoch 122/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1480e+00
Epoch 123/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1464e+00
Epoch 124/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1441e+00
Epoch 125/200
 - 13s - loss: -4.1005e+00 - val_loss: -4.1418e+00
Epoch 126/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1484e+00
Epoch 127/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1492e+00
Epoch 128/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1495e+00
Epoch 129/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1497e+00
Epoch 130/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1499e+00
Epoch 131/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1494e+00
Epoch 132/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1484e+00
Epoch 133/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1495e+00
Epoch 134/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1491e+00
Epoch 135/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1457e+00
Epoch 136/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1490e+00
Epoch 137/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1491e+00
Epoch 138/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1489e+00
Epoch 139/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1490e+00
Epoch 140/200
 - 13s - loss: -4.1010e+00 - val_loss: -4.1493e+00
Epoch 141/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1494e+00
2019-12-21 16:15:59,151 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_140.pickle
Epoch 142/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1486e+00
Epoch 143/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1483e+00
Epoch 144/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1489e+00
Epoch 145/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1493e+00
Epoch 146/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1497e+00
Epoch 147/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1494e+00
Epoch 148/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1441e+00
Epoch 149/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1451e+00
Epoch 150/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1451e+00
Epoch 151/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1430e+00
Epoch 152/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1486e+00
Epoch 153/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1496e+00
Epoch 154/200
 - 13s - loss: -4.1020e+00 - val_loss: -4.1485e+00
Epoch 155/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1459e+00
Epoch 156/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1491e+00
Epoch 157/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1493e+00
Epoch 158/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1496e+00
Epoch 159/200
 - 13s - loss: -4.1013e+00 - val_loss: -4.1491e+00
Epoch 160/200
 - 13s - loss: -4.1018e+00 - val_loss: -4.1483e+00
Epoch 161/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1436e+00
2019-12-21 16:20:19,031 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ae_model_epoch_160.pickle
Epoch 162/200
 - 13s - loss: -4.1007e+00 - val_loss: -4.1493e+00
Epoch 163/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1495e+00
Epoch 164/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1493e+00
Epoch 165/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1488e+00
Epoch 166/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1491e+00
Epoch 167/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1474e+00
Epoch 168/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1494e+00
Epoch 169/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1493e+00
Epoch 170/200
 - 13s - loss: -4.1008e+00 - val_loss: -4.1494e+00
Epoch 171/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1477e+00
Epoch 172/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1494e+00
Epoch 173/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1485e+00
Epoch 174/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1475e+00
Epoch 175/200
 - 13s - loss: -4.1014e+00 - val_loss: -4.1498e+00
Epoch 176/200
 - 13s - loss: -4.1019e+00 - val_loss: -4.1491e+00
Epoch 177/200
 - 13s - loss: -4.1016e+00 - val_loss: -4.1457e+00
Epoch 178/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1484e+00
Epoch 179/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1482e+00
Epoch 180/200
 - 13s - loss: -4.1017e+00 - val_loss: -4.1426e+00
2019-12-21 16:24:25,943 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 16:24:52,325 [INFO] Last epoch loss evaluation: train_loss = -4.144428, val_loss = -4.149932
2019-12-21 16:24:52,325 [INFO] Training autoencoder complete
2019-12-21 16:24:52,325 [INFO] Encoding data for supervised training
2019-12-21 16:25:17,249 [INFO] Encoding complete
2019-12-21 16:25:17,250 [INFO] Training neural network layers (after autoencoder)
Epoch 00180: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 7s - loss: 0.0318 - val_loss: 0.0129
 - val_f1: 0.9662
Epoch 2/200
 - 6s - loss: 0.0150 - val_loss: 0.0117
 - val_f1: 0.9694
Epoch 3/200
 - 6s - loss: 0.0132 - val_loss: 0.0103
 - val_f1: 0.9728
Epoch 4/200
 - 6s - loss: 0.0124 - val_loss: 0.0100
 - val_f1: 0.9736
Epoch 5/200
 - 6s - loss: 0.0118 - val_loss: 0.0095
 - val_f1: 0.9737
Epoch 6/200
 - 6s - loss: 0.0115 - val_loss: 0.0095
 - val_f1: 0.9740
Epoch 7/200
 - 6s - loss: 0.0112 - val_loss: 0.0093
 - val_f1: 0.9759
Epoch 8/200
 - 6s - loss: 0.0111 - val_loss: 0.0107
 - val_f1: 0.9722
Epoch 9/200
 - 6s - loss: 0.0109 - val_loss: 0.0104
 - val_f1: 0.9741
Epoch 10/200
 - 6s - loss: 0.0107 - val_loss: 0.0099
 - val_f1: 0.9747
Epoch 11/200
 - 6s - loss: 0.0107 - val_loss: 0.0096
 - val_f1: 0.9752
Epoch 12/200
 - 6s - loss: 0.0105 - val_loss: 0.0097
 - val_f1: 0.9742
Epoch 13/200
 - 6s - loss: 0.0104 - val_loss: 0.0102
 - val_f1: 0.9674
Epoch 14/200
 - 6s - loss: 0.0103 - val_loss: 0.0105
 - val_f1: 0.9685
Epoch 15/200
 - 6s - loss: 0.0102 - val_loss: 0.0114
 - val_f1: 0.9662
Epoch 16/200
 - 6s - loss: 0.0102 - val_loss: 0.0083
 - val_f1: 0.9786
Epoch 17/200
 - 6s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9801
Epoch 18/200
 - 6s - loss: 0.0101 - val_loss: 0.0083
 - val_f1: 0.9787
Epoch 19/200
 - 6s - loss: 0.0100 - val_loss: 0.0081
 - val_f1: 0.9793
Epoch 20/200
 - 6s - loss: 0.0099 - val_loss: 0.0085
 - val_f1: 0.9799
Epoch 21/200
 - 6s - loss: 0.0098 - val_loss: 0.0087
2019-12-21 16:30:55,882 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_20.pickle
 - val_f1: 0.9751
Epoch 22/200
 - 6s - loss: 0.0098 - val_loss: 0.0084
 - val_f1: 0.9782
Epoch 23/200
 - 6s - loss: 0.0097 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 24/200
 - 6s - loss: 0.0097 - val_loss: 0.0079
 - val_f1: 0.9826
Epoch 25/200
 - 6s - loss: 0.0097 - val_loss: 0.0082
 - val_f1: 0.9786
Epoch 26/200
 - 6s - loss: 0.0097 - val_loss: 0.0090
 - val_f1: 0.9763
Epoch 27/200
 - 6s - loss: 0.0097 - val_loss: 0.0085
 - val_f1: 0.9781
Epoch 28/200
 - 6s - loss: 0.0096 - val_loss: 0.0079
 - val_f1: 0.9825
Epoch 29/200
 - 6s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9765
Epoch 30/200
 - 6s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9790
Epoch 31/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9768
Epoch 32/200
 - 6s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9772
Epoch 33/200
 - 6s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9763
Epoch 34/200
 - 6s - loss: 0.0095 - val_loss: 0.0079
 - val_f1: 0.9827
Epoch 35/200
 - 6s - loss: 0.0095 - val_loss: 0.0098
 - val_f1: 0.9784
Epoch 36/200
 - 6s - loss: 0.0094 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 37/200
 - 6s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9743
Epoch 38/200
 - 6s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9819
Epoch 39/200
 - 6s - loss: 0.0093 - val_loss: 0.0077
 - val_f1: 0.9815
Epoch 40/200
 - 6s - loss: 0.0094 - val_loss: 0.0076
 - val_f1: 0.9814
Epoch 41/200
 - 6s - loss: 0.0093 - val_loss: 0.0074
2019-12-21 16:36:23,732 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_40.pickle
 - val_f1: 0.9798
Epoch 42/200
 - 6s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9751
Epoch 43/200
 - 6s - loss: 0.0093 - val_loss: 0.0076
 - val_f1: 0.9807
Epoch 44/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9817
Epoch 45/200
 - 6s - loss: 0.0093 - val_loss: 0.0075
 - val_f1: 0.9833
Epoch 46/200
 - 6s - loss: 0.0093 - val_loss: 0.0075
 - val_f1: 0.9812
Epoch 47/200
 - 6s - loss: 0.0093 - val_loss: 0.0088
 - val_f1: 0.9763
Epoch 48/200
 - 6s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9775
Epoch 49/200
 - 6s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9825
Epoch 50/200
 - 6s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 51/200
 - 6s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9786
Epoch 52/200
 - 6s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9805
Epoch 53/200
 - 6s - loss: 0.0091 - val_loss: 0.0097
 - val_f1: 0.9769
Epoch 54/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9827
Epoch 55/200
 - 6s - loss: 0.0092 - val_loss: 0.0074
 - val_f1: 0.9811
Epoch 56/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9819
Epoch 57/200
 - 6s - loss: 0.0091 - val_loss: 0.0094
 - val_f1: 0.9741
Epoch 58/200
 - 6s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9826
Epoch 59/200
 - 6s - loss: 0.0090 - val_loss: 0.0074
 - val_f1: 0.9786
Epoch 60/200
 - 6s - loss: 0.0091 - val_loss: 0.0075
 - val_f1: 0.9821
Epoch 61/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
2019-12-21 16:41:51,701 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9816
Epoch 62/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9790
Epoch 63/200
 - 6s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 64/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9801
Epoch 65/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9806
Epoch 66/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9824
Epoch 67/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9823
Epoch 68/200
 - 6s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9800
Epoch 69/200
 - 6s - loss: 0.0090 - val_loss: 0.0080
 - val_f1: 0.9823
Epoch 70/200
 - 6s - loss: 0.0089 - val_loss: 0.0087
 - val_f1: 0.9784
Epoch 71/200
 - 6s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9839
Epoch 72/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9828
Epoch 73/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9815
Epoch 74/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9823
Epoch 75/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9836
Epoch 76/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9779
Epoch 77/200
 - 6s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9823
Epoch 78/200
 - 6s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 79/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9797
Epoch 80/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9805
Epoch 81/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
2019-12-21 16:47:19,692 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_80.pickle
 - val_f1: 0.9832
Epoch 82/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9831
Epoch 83/200
 - 6s - loss: 0.0089 - val_loss: 0.0072
 - val_f1: 0.9834
Epoch 84/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9811
Epoch 85/200
 - 6s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9813
Epoch 86/200
 - 6s - loss: 0.0089 - val_loss: 0.0088
 - val_f1: 0.9729
Epoch 87/200
 - 6s - loss: 0.0088 - val_loss: 0.0099
 - val_f1: 0.9706
Epoch 88/200
 - 6s - loss: 0.0088 - val_loss: 0.0072
 - val_f1: 0.9810
Epoch 89/200
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9779
Epoch 90/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9835
Epoch 91/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9840
Epoch 92/200
 - 6s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 93/200
 - 6s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9787
Epoch 94/200
 - 6s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9769
Epoch 95/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9822
Epoch 96/200
 - 6s - loss: 0.0088 - val_loss: 0.0071
 - val_f1: 0.9849
Epoch 97/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9816
Epoch 98/200
 - 6s - loss: 0.0088 - val_loss: 0.0104
 - val_f1: 0.9633
Epoch 99/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9809
Epoch 100/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9809
Epoch 101/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
2019-12-21 16:52:47,970 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_100.pickle
 - val_f1: 0.9791
Epoch 102/200
 - 6s - loss: 0.0088 - val_loss: 0.0096
 - val_f1: 0.9742
Epoch 103/200
 - 6s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9757
Epoch 104/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9844
Epoch 105/200
 - 6s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 106/200
 - 6s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9798
Epoch 107/200
 - 6s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9768
Epoch 108/200
 - 6s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9824
Epoch 109/200
 - 6s - loss: 0.0088 - val_loss: 0.0077
 - val_f1: 0.9802
Epoch 110/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9836
Epoch 111/200
 - 6s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9774
Epoch 112/200
 - 6s - loss: 0.0087 - val_loss: 0.0107
 - val_f1: 0.9594
Epoch 113/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9816
Epoch 114/200
 - 6s - loss: 0.0086 - val_loss: 0.0094
 - val_f1: 0.9740
Epoch 115/200
 - 6s - loss: 0.0087 - val_loss: 0.0069
 - val_f1: 0.9855
Epoch 116/200
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9798
Epoch 117/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9844
Epoch 118/200
 - 6s - loss: 0.0087 - val_loss: 0.0097
 - val_f1: 0.9713
Epoch 119/200
 - 6s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9731
Epoch 120/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9827
Epoch 121/200
 - 6s - loss: 0.0086 - val_loss: 0.0088
2019-12-21 16:58:15,656 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9719
Epoch 122/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9853
Epoch 123/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9827
Epoch 124/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
 - val_f1: 0.9828
Epoch 125/200
 - 6s - loss: 0.0086 - val_loss: 0.0102
 - val_f1: 0.9682
Epoch 126/200
 - 6s - loss: 0.0087 - val_loss: 0.0140
 - val_f1: 0.9537
Epoch 127/200
 - 6s - loss: 0.0086 - val_loss: 0.0129
 - val_f1: 0.9570
Epoch 128/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9836
Epoch 129/200
 - 6s - loss: 0.0086 - val_loss: 0.0077
 - val_f1: 0.9826
Epoch 130/200
 - 6s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9787
Epoch 131/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9792
Epoch 132/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9822
Epoch 133/200
 - 6s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9807
Epoch 134/200
 - 6s - loss: 0.0086 - val_loss: 0.0070
 - val_f1: 0.9854
Epoch 135/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9839
Epoch 136/200
 - 6s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9838
Epoch 137/200
 - 6s - loss: 0.0086 - val_loss: 0.0098
 - val_f1: 0.9687
Epoch 138/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9820
Epoch 139/200
 - 6s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9715
Epoch 140/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9843
Epoch 141/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
2019-12-21 17:03:43,325 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_140.pickle
 - val_f1: 0.9829
Epoch 142/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9817
Epoch 143/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9811
Epoch 144/200
 - 6s - loss: 0.0085 - val_loss: 0.0102
 - val_f1: 0.9746
Epoch 145/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9840
Epoch 146/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9848
Epoch 147/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9784
Epoch 148/200
 - 6s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9790
Epoch 149/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9817
Epoch 150/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9840
Epoch 151/200
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9748
Epoch 152/200
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9788
Epoch 153/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9798
Epoch 154/200
 - 6s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9841
Epoch 155/200
 - 6s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 156/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9852
Epoch 157/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9799
Epoch 158/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9824
Epoch 159/200
 - 6s - loss: 0.0085 - val_loss: 0.0075
 - val_f1: 0.9800
Epoch 160/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9820
Epoch 161/200
 - 6s - loss: 0.0085 - val_loss: 0.0078
2019-12-21 17:09:11,124 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_160.pickle
 - val_f1: 0.9781
Epoch 162/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9831
Epoch 163/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9807
Epoch 164/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9817
Epoch 165/200
 - 6s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9796
Epoch 166/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9844
Epoch 167/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9785
Epoch 168/200
 - 6s - loss: 0.0085 - val_loss: 0.0069
 - val_f1: 0.9868
Epoch 169/200
 - 6s - loss: 0.0085 - val_loss: 0.0078
 - val_f1: 0.9802
Epoch 170/200
 - 6s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9808
Epoch 171/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9805
Epoch 172/200
 - 6s - loss: 0.0085 - val_loss: 0.0075
 - val_f1: 0.9833
Epoch 173/200
 - 6s - loss: 0.0085 - val_loss: 0.0067
 - val_f1: 0.9843
Epoch 174/200
 - 6s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9806
Epoch 175/200
 - 6s - loss: 0.0084 - val_loss: 0.0073
 - val_f1: 0.9811
Epoch 176/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9846
Epoch 177/200
 - 6s - loss: 0.0084 - val_loss: 0.0074
 - val_f1: 0.9802
Epoch 178/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9853
Epoch 179/200
 - 6s - loss: 0.0083 - val_loss: 0.0070
 - val_f1: 0.9829
Epoch 180/200
 - 6s - loss: 0.0084 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 181/200
 - 6s - loss: 0.0083 - val_loss: 0.0068
2019-12-21 17:14:39,091 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9868
Epoch 182/200
 - 6s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9805
Epoch 183/200
 - 6s - loss: 0.0082 - val_loss: 0.0066
 - val_f1: 0.9845
Epoch 184/200
 - 6s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9789
Epoch 185/200
 - 6s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9776
Epoch 186/200
 - 6s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9721
Epoch 187/200
 - 6s - loss: 0.0082 - val_loss: 0.0076
 - val_f1: 0.9806
Epoch 188/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9796
Epoch 189/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9779
Epoch 190/200
 - 6s - loss: 0.0082 - val_loss: 0.0116
 - val_f1: 0.9632
Epoch 191/200
 - 6s - loss: 0.0082 - val_loss: 0.0073
 - val_f1: 0.9829
Epoch 192/200
 - 6s - loss: 0.0082 - val_loss: 0.0076
 - val_f1: 0.9827
Epoch 193/200
 - 6s - loss: 0.0082 - val_loss: 0.0068
 - val_f1: 0.9877
Epoch 194/200
 - 6s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 195/200
 - 6s - loss: 0.0082 - val_loss: 0.0100
 - val_f1: 0.9688
Epoch 196/200
 - 6s - loss: 0.0082 - val_loss: 0.0070
 - val_f1: 0.9839
Epoch 197/200
 - 6s - loss: 0.0082 - val_loss: 0.0072
 - val_f1: 0.9844
Epoch 198/200
 - 6s - loss: 0.0083 - val_loss: 0.0072
 - val_f1: 0.9807
Epoch 199/200
 - 6s - loss: 0.0083 - val_loss: 0.0066
 - val_f1: 0.9855
Epoch 200/200
 - 6s - loss: 0.0082 - val_loss: 0.0067
2019-12-21 17:20:00,815 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 17:20:28,360 [INFO] Last epoch loss evaluation: train_loss = 0.006366, val_loss = 0.006555
2019-12-21 17:20:28,396 [INFO] Training complete. time_to_train = 5722.97 sec, 95.38 min
2019-12-21 17:20:28,405 [INFO] Model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep4/best_model.pickle
2019-12-21 17:20:28,591 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep4/training_error_history.png
2019-12-21 17:20:28,780 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep4/training_f1_history.png
2019-12-21 17:20:28,780 [INFO] Making predictions on training, validation, testing data
2019-12-21 17:22:08,299 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 17:22:18,441 [INFO] Dataset: Testing. Classification report below
2019-12-21 17:22:18,441 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       1.00      0.32      0.48       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.99      0.94      0.96      2058
              DoS Hulk       1.00      0.94      0.97     46025
      DoS Slowhttptest       0.88      0.95      0.91      1100
         DoS slowloris       0.97      0.90      0.93      1159
           FTP-Patator       1.00      0.98      0.99      1587
              PortScan       0.91      0.98      0.94     31761
           SSH-Patator       0.96      0.97      0.97      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.75      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 17:22:18,441 [INFO] Overall accuracy (micro avg): 0.985495843072908
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-21 17:22:29,980 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9855         0.9855                       0.9855                0.0013                   0.0145  0.9855
1     Macro avg        0.9976         0.8068                       0.7468                0.0040                   0.2532  0.7617
2  Weighted avg        0.9877         0.9852                       0.9855                0.0332                   0.0145  0.9851
2019-12-21 17:22:40,425 [INFO] Dataset: Validation. Classification report below
2019-12-21 17:22:40,425 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       1.00      0.27      0.43       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.93      0.96      2059
              DoS Hulk       1.00      0.94      0.97     46025
      DoS Slowhttptest       0.88      0.94      0.91      1099
         DoS slowloris       0.97      0.90      0.94      1159
           FTP-Patator       1.00      0.97      0.98      1587
              PortScan       0.91      0.98      0.94     31761
           SSH-Patator       0.97      0.97      0.97      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.74      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 17:22:40,425 [INFO] Overall accuracy (micro avg): 0.9855152927530492
2019-12-21 17:22:52,266 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9855         0.9855                       0.9855                0.0013                   0.0145  0.9855
1     Macro avg        0.9976         0.8073                       0.7400                0.0040                   0.2600  0.7558
2  Weighted avg        0.9877         0.9852                       0.9855                0.0332                   0.0145  0.9851
2019-12-21 17:23:26,309 [INFO] Dataset: Training. Classification report below
2019-12-21 17:23:26,309 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       0.99      0.31      0.47      1174
                  DDoS       1.00      0.99      0.99     76815
         DoS GoldenEye       0.99      0.93      0.96      6176
              DoS Hulk       1.00      0.94      0.97    138074
      DoS Slowhttptest       0.89      0.95      0.92      3300
         DoS slowloris       0.96      0.92      0.94      3478
           FTP-Patator       1.00      0.98      0.99      4761
              PortScan       0.91      0.98      0.95     95282
           SSH-Patator       0.97      0.97      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.81      0.75      0.76   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-21 17:23:26,309 [INFO] Overall accuracy (micro avg): 0.9857757838230337
2019-12-21 17:24:04,972 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9858         0.9858                       0.9858                0.0013                   0.0142  0.9858
1     Macro avg        0.9976         0.8077                       0.7466                0.0039                   0.2534  0.7620
2  Weighted avg        0.9879         0.9854                       0.9858                0.0327                   0.0142  0.9853
2019-12-21 17:24:05,023 [INFO] Results saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep4/selected_ids17_ae_ann_shallow_rep4_results.xlsx
2019-12-21 17:24:05,029 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-21 17:24:05,093 [INFO] Created directory: results_selected_models/selected_ids17_ae_ann_shallow_rep5
2019-12-21 17:24:05,093 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_ae_ann_shallow_rep5/run_log.log
2019-12-21 17:24:05,093 [INFO] ================= Running experiment no. 5  ================= 

2019-12-21 17:24:05,093 [INFO] Experiment parameters given below
2019-12-21 17:24:05,093 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids17_ae_ann_shallow_rep5', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_ae_ann_shallow_rep5'}
2019-12-21 17:24:05,093 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_ae_ann_shallow_rep5/tf_logs_run_2019_12_21-17_24_05
2019-12-21 17:24:05,093 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-21 17:24:05,093 [INFO] Reading X, y files
2019-12-21 17:24:05,093 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-21 17:24:09,153 [INFO] Reading complete. time_to_read=4.06 seconds
2019-12-21 17:24:09,153 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-21 17:24:10,540 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 17:24:10,541 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-21 17:24:11,928 [INFO] Reading complete. time_to_read=1.39 seconds
2019-12-21 17:24:11,928 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-21 17:24:12,120 [INFO] Reading complete. time_to_read=0.19 seconds
2019-12-21 17:24:12,120 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-21 17:24:12,188 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 17:24:12,188 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-21 17:24:12,256 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-21 17:24:15,415 [INFO] Initializing model
2019-12-21 17:24:15,528 [INFO] _________________________________________________________________
2019-12-21 17:24:15,528 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 17:24:15,528 [INFO] =================================================================
2019-12-21 17:24:15,528 [INFO] dense_37 (Dense)             (None, 32)                2528      
2019-12-21 17:24:15,528 [INFO] _________________________________________________________________
2019-12-21 17:24:15,528 [INFO] batch_normalization_19 (Batc (None, 32)                128       
2019-12-21 17:24:15,528 [INFO] _________________________________________________________________
2019-12-21 17:24:15,528 [INFO] dropout_19 (Dropout)         (None, 32)                0         
2019-12-21 17:24:15,528 [INFO] _________________________________________________________________
2019-12-21 17:24:15,529 [INFO] dense_38 (Dense)             (None, 78)                2574      
2019-12-21 17:24:15,529 [INFO] =================================================================
2019-12-21 17:24:15,529 [INFO] Total params: 5,230
2019-12-21 17:24:15,529 [INFO] Trainable params: 5,166
2019-12-21 17:24:15,529 [INFO] Non-trainable params: 64
2019-12-21 17:24:15,529 [INFO] _________________________________________________________________
2019-12-21 17:24:15,638 [INFO] _________________________________________________________________
2019-12-21 17:24:15,638 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-21 17:24:15,638 [INFO] =================================================================
2019-12-21 17:24:15,638 [INFO] dense_39 (Dense)             (None, 32)                1056      
2019-12-21 17:24:15,638 [INFO] _________________________________________________________________
2019-12-21 17:24:15,639 [INFO] batch_normalization_20 (Batc (None, 32)                128       
2019-12-21 17:24:15,639 [INFO] _________________________________________________________________
2019-12-21 17:24:15,639 [INFO] dropout_20 (Dropout)         (None, 32)                0         
2019-12-21 17:24:15,639 [INFO] _________________________________________________________________
2019-12-21 17:24:15,639 [INFO] dense_40 (Dense)             (None, 12)                396       
2019-12-21 17:24:15,639 [INFO] =================================================================
2019-12-21 17:24:15,639 [INFO] Total params: 1,580
2019-12-21 17:24:15,639 [INFO] Trainable params: 1,516
2019-12-21 17:24:15,639 [INFO] Non-trainable params: 64
2019-12-21 17:24:15,639 [INFO] _________________________________________________________________
2019-12-21 17:24:15,639 [INFO] Training model
2019-12-21 17:24:15,639 [INFO] Splitting train set into 2 sets (unsupervised, supervised)
2019-12-21 17:24:32,131 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342
2019-12-21 17:24:32,131 [INFO] Training autoencoder
 - val_f1: 0.9831
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 14s - loss: -3.3745e+00 - val_loss: -4.1034e+00
Epoch 2/200
 - 13s - loss: -4.0305e+00 - val_loss: -4.1222e+00
Epoch 3/200
 - 13s - loss: -4.0572e+00 - val_loss: -4.1301e+00
Epoch 4/200
 - 13s - loss: -4.0684e+00 - val_loss: -4.1330e+00
Epoch 5/200
 - 13s - loss: -4.0754e+00 - val_loss: -4.1375e+00
Epoch 6/200
 - 13s - loss: -4.0800e+00 - val_loss: -4.1388e+00
Epoch 7/200
 - 13s - loss: -4.0830e+00 - val_loss: -4.1398e+00
Epoch 8/200
 - 13s - loss: -4.0856e+00 - val_loss: -4.1403e+00
Epoch 9/200
 - 13s - loss: -4.0874e+00 - val_loss: -4.1410e+00
Epoch 10/200
 - 13s - loss: -4.0884e+00 - val_loss: -4.1424e+00
Epoch 11/200
 - 13s - loss: -4.0905e+00 - val_loss: -4.1433e+00
Epoch 12/200
 - 13s - loss: -4.0912e+00 - val_loss: -4.1422e+00
Epoch 13/200
 - 13s - loss: -4.0925e+00 - val_loss: -4.1438e+00
Epoch 14/200
 - 13s - loss: -4.0931e+00 - val_loss: -4.1441e+00
Epoch 15/200
 - 13s - loss: -4.0940e+00 - val_loss: -4.1434e+00
Epoch 16/200
 - 13s - loss: -4.0945e+00 - val_loss: -4.1440e+00
Epoch 17/200
 - 13s - loss: -4.0950e+00 - val_loss: -4.1384e+00
Epoch 18/200
 - 13s - loss: -4.0960e+00 - val_loss: -4.1439e+00
Epoch 19/200
 - 13s - loss: -4.0967e+00 - val_loss: -4.1402e+00
Epoch 20/200
 - 13s - loss: -4.0963e+00 - val_loss: -4.1400e+00
Epoch 21/200
 - 13s - loss: -4.0979e+00 - val_loss: -4.1433e+00
2019-12-21 17:29:13,202 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_20.pickle
Epoch 22/200
 - 13s - loss: -4.0975e+00 - val_loss: -4.1441e+00
Epoch 23/200
 - 13s - loss: -4.0989e+00 - val_loss: -4.1435e+00
Epoch 24/200
 - 13s - loss: -4.0987e+00 - val_loss: -4.1465e+00
Epoch 25/200
 - 13s - loss: -4.0998e+00 - val_loss: -4.1447e+00
Epoch 26/200
 - 13s - loss: -4.1003e+00 - val_loss: -4.1473e+00
Epoch 27/200
 - 13s - loss: -4.0997e+00 - val_loss: -4.1450e+00
Epoch 28/200
 - 13s - loss: -4.1009e+00 - val_loss: -4.1432e+00
Epoch 29/200
 - 13s - loss: -4.1009e+00 - val_loss: -4.1432e+00
Epoch 30/200
 - 13s - loss: -4.1012e+00 - val_loss: -4.1466e+00
Epoch 31/200
 - 13s - loss: -4.1015e+00 - val_loss: -4.1470e+00
Epoch 32/200
 - 13s - loss: -4.1011e+00 - val_loss: -4.1448e+00
Epoch 33/200
 - 13s - loss: -4.1022e+00 - val_loss: -4.1471e+00
Epoch 34/200
 - 13s - loss: -4.1022e+00 - val_loss: -4.1467e+00
Epoch 35/200
 - 13s - loss: -4.1023e+00 - val_loss: -4.1433e+00
Epoch 36/200
 - 13s - loss: -4.1027e+00 - val_loss: -4.1478e+00
Epoch 37/200
 - 13s - loss: -4.1031e+00 - val_loss: -4.1444e+00
Epoch 38/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1474e+00
Epoch 39/200
 - 13s - loss: -4.1036e+00 - val_loss: -4.1459e+00
Epoch 40/200
 - 13s - loss: -4.1030e+00 - val_loss: -4.1468e+00
Epoch 41/200
 - 13s - loss: -4.1035e+00 - val_loss: -4.1465e+00
2019-12-21 17:33:35,252 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_40.pickle
Epoch 42/200
 - 13s - loss: -4.1033e+00 - val_loss: -4.1467e+00
Epoch 43/200
 - 13s - loss: -4.1038e+00 - val_loss: -4.1463e+00
Epoch 44/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1471e+00
Epoch 45/200
 - 13s - loss: -4.1041e+00 - val_loss: -4.1449e+00
Epoch 46/200
 - 13s - loss: -4.1033e+00 - val_loss: -4.1479e+00
Epoch 47/200
 - 13s - loss: -4.1045e+00 - val_loss: -4.1450e+00
Epoch 48/200
 - 13s - loss: -4.1044e+00 - val_loss: -4.1413e+00
Epoch 49/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1479e+00
Epoch 50/200
 - 13s - loss: -4.1043e+00 - val_loss: -4.1486e+00
Epoch 51/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1467e+00
Epoch 52/200
 - 13s - loss: -4.1047e+00 - val_loss: -4.1475e+00
Epoch 53/200
 - 13s - loss: -4.1053e+00 - val_loss: -4.1458e+00
Epoch 54/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1476e+00
Epoch 55/200
 - 13s - loss: -4.1050e+00 - val_loss: -4.1476e+00
Epoch 56/200
 - 13s - loss: -4.1057e+00 - val_loss: -4.1462e+00
Epoch 57/200
 - 13s - loss: -4.1051e+00 - val_loss: -4.1442e+00
Epoch 58/200
 - 13s - loss: -4.1055e+00 - val_loss: -4.1468e+00
Epoch 59/200
 - 13s - loss: -4.1052e+00 - val_loss: -4.1449e+00
Epoch 60/200
 - 13s - loss: -4.1048e+00 - val_loss: -4.1460e+00
Epoch 61/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1449e+00
2019-12-21 17:37:57,348 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_60.pickle
Epoch 62/200
 - 13s - loss: -4.1060e+00 - val_loss: -4.1489e+00
Epoch 63/200
 - 13s - loss: -4.1060e+00 - val_loss: -4.1484e+00
Epoch 64/200
 - 13s - loss: -4.1060e+00 - val_loss: -4.1485e+00
Epoch 65/200
 - 13s - loss: -4.1061e+00 - val_loss: -4.1482e+00
Epoch 66/200
 - 13s - loss: -4.1061e+00 - val_loss: -4.1463e+00
Epoch 67/200
 - 13s - loss: -4.1058e+00 - val_loss: -4.1473e+00
Epoch 68/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1490e+00
Epoch 69/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1479e+00
Epoch 70/200
 - 13s - loss: -4.1062e+00 - val_loss: -4.1486e+00
Epoch 71/200
 - 13s - loss: -4.1065e+00 - val_loss: -4.1459e+00
Epoch 72/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1456e+00
Epoch 73/200
 - 13s - loss: -4.1064e+00 - val_loss: -4.1477e+00
Epoch 74/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1462e+00
Epoch 75/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1487e+00
Epoch 76/200
 - 13s - loss: -4.1065e+00 - val_loss: -4.1466e+00
Epoch 77/200
 - 13s - loss: -4.1067e+00 - val_loss: -4.1453e+00
Epoch 78/200
 - 13s - loss: -4.1055e+00 - val_loss: -4.1478e+00
Epoch 79/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1475e+00
Epoch 80/200
 - 13s - loss: -4.1066e+00 - val_loss: -4.1479e+00
Epoch 81/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1484e+00
2019-12-21 17:42:19,572 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_80.pickle
Epoch 82/200
 - 13s - loss: -4.1065e+00 - val_loss: -4.1458e+00
Epoch 83/200
 - 13s - loss: -4.1074e+00 - val_loss: -4.1423e+00
Epoch 84/200
 - 13s - loss: -4.1068e+00 - val_loss: -4.1480e+00
Epoch 85/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1490e+00
Epoch 86/200
 - 13s - loss: -4.1070e+00 - val_loss: -4.1488e+00
Epoch 87/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1463e+00
Epoch 88/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1480e+00
Epoch 89/200
 - 13s - loss: -4.1072e+00 - val_loss: -4.1463e+00
Epoch 90/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1472e+00
Epoch 91/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1484e+00
Epoch 92/200
 - 13s - loss: -4.1071e+00 - val_loss: -4.1456e+00
Epoch 93/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1475e+00
Epoch 94/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1459e+00
Epoch 95/200
 - 13s - loss: -4.1072e+00 - val_loss: -4.1446e+00
Epoch 96/200
 - 13s - loss: -4.1075e+00 - val_loss: -4.1461e+00
Epoch 97/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1502e+00
Epoch 98/200
 - 13s - loss: -4.1073e+00 - val_loss: -4.1460e+00
Epoch 99/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1488e+00
Epoch 100/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1391e+00
Epoch 101/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1459e+00
2019-12-21 17:46:42,030 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_100.pickle
Epoch 102/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1496e+00
Epoch 103/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1445e+00
Epoch 104/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1469e+00
Epoch 105/200
 - 13s - loss: -4.1077e+00 - val_loss: -4.1430e+00
Epoch 106/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1444e+00
Epoch 107/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1492e+00
Epoch 108/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1487e+00
Epoch 109/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1483e+00
Epoch 110/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1448e+00
Epoch 111/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1490e+00
Epoch 112/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1441e+00
Epoch 113/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1494e+00
Epoch 114/200
 - 13s - loss: -4.1078e+00 - val_loss: -4.1390e+00
Epoch 115/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1472e+00
Epoch 116/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1453e+00
Epoch 117/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1421e+00
Epoch 118/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1425e+00
Epoch 119/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1463e+00
Epoch 120/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1474e+00
Epoch 121/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1474e+00
2019-12-21 17:51:04,026 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_120.pickle
Epoch 122/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1454e+00
Epoch 123/200
 - 13s - loss: -4.1080e+00 - val_loss: -4.1441e+00
Epoch 124/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1443e+00
Epoch 125/200
 - 13s - loss: -4.1076e+00 - val_loss: -4.1469e+00
Epoch 126/200
 - 13s - loss: -4.1083e+00 - val_loss: -4.1464e+00
Epoch 127/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1427e+00
Epoch 128/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1462e+00
Epoch 129/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1427e+00
Epoch 130/200
 - 13s - loss: -4.1079e+00 - val_loss: -4.1440e+00
Epoch 131/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1488e+00
Epoch 132/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1439e+00
Epoch 133/200
 - 13s - loss: -4.1082e+00 - val_loss: -4.1476e+00
Epoch 134/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1472e+00
Epoch 135/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1488e+00
Epoch 136/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1491e+00
Epoch 137/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1500e+00
Epoch 138/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1441e+00
Epoch 139/200
 - 13s - loss: -4.1081e+00 - val_loss: -4.1471e+00
Epoch 140/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1497e+00
Epoch 141/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1459e+00
2019-12-21 17:55:26,278 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ae_model_epoch_140.pickle
Epoch 142/200
 - 13s - loss: -4.1087e+00 - val_loss: -4.1446e+00
Epoch 143/200
 - 13s - loss: -4.1085e+00 - val_loss: -4.1443e+00
Epoch 144/200
 - 13s - loss: -4.1088e+00 - val_loss: -4.1418e+00
Epoch 145/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1472e+00
Epoch 146/200
 - 13s - loss: -4.1084e+00 - val_loss: -4.1489e+00
Epoch 147/200
 - 13s - loss: -4.1086e+00 - val_loss: -4.1495e+00
2019-12-21 17:56:44,905 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 17:57:12,590 [INFO] Last epoch loss evaluation: train_loss = -4.153160, val_loss = -4.150196
2019-12-21 17:57:12,591 [INFO] Training autoencoder complete
2019-12-21 17:57:12,591 [INFO] Encoding data for supervised training
2019-12-21 17:57:39,255 [INFO] Encoding complete
2019-12-21 17:57:39,255 [INFO] Training neural network layers (after autoencoder)
Epoch 00147: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/200
 - 7s - loss: 0.0319 - val_loss: 0.0139
 - val_f1: 0.9663
Epoch 2/200
 - 6s - loss: 0.0152 - val_loss: 0.0123
 - val_f1: 0.9677
Epoch 3/200
 - 6s - loss: 0.0133 - val_loss: 0.0113
 - val_f1: 0.9685
Epoch 4/200
 - 6s - loss: 0.0124 - val_loss: 0.0116
 - val_f1: 0.9710
Epoch 5/200
 - 6s - loss: 0.0118 - val_loss: 0.0097
 - val_f1: 0.9742
Epoch 6/200
 - 6s - loss: 0.0114 - val_loss: 0.0096
 - val_f1: 0.9771
Epoch 7/200
 - 6s - loss: 0.0112 - val_loss: 0.0094
 - val_f1: 0.9772
Epoch 8/200
 - 6s - loss: 0.0109 - val_loss: 0.0091
 - val_f1: 0.9747
Epoch 9/200
 - 6s - loss: 0.0108 - val_loss: 0.0089
 - val_f1: 0.9751
Epoch 10/200
 - 6s - loss: 0.0107 - val_loss: 0.0090
 - val_f1: 0.9750
Epoch 11/200
 - 6s - loss: 0.0106 - val_loss: 0.0101
 - val_f1: 0.9761
Epoch 12/200
 - 6s - loss: 0.0105 - val_loss: 0.0088
 - val_f1: 0.9752
Epoch 13/200
 - 6s - loss: 0.0103 - val_loss: 0.0087
 - val_f1: 0.9749
Epoch 14/200
 - 6s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9809
Epoch 15/200
 - 6s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9767
Epoch 16/200
 - 6s - loss: 0.0101 - val_loss: 0.0091
 - val_f1: 0.9768
Epoch 17/200
 - 6s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9773
Epoch 18/200
 - 6s - loss: 0.0101 - val_loss: 0.0085
 - val_f1: 0.9759
Epoch 19/200
 - 6s - loss: 0.0101 - val_loss: 0.0088
 - val_f1: 0.9772
Epoch 20/200
 - 6s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9810
Epoch 21/200
 - 6s - loss: 0.0099 - val_loss: 0.0085
2019-12-21 18:03:35,320 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_20.pickle
 - val_f1: 0.9815
Epoch 22/200
 - 6s - loss: 0.0099 - val_loss: 0.0087
 - val_f1: 0.9773
Epoch 23/200
 - 6s - loss: 0.0098 - val_loss: 0.0091
 - val_f1: 0.9773
Epoch 24/200
 - 6s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9813
Epoch 25/200
 - 6s - loss: 0.0097 - val_loss: 0.0083
 - val_f1: 0.9783
Epoch 26/200
 - 6s - loss: 0.0097 - val_loss: 0.0083
 - val_f1: 0.9816
Epoch 27/200
 - 6s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 28/200
 - 6s - loss: 0.0096 - val_loss: 0.0090
 - val_f1: 0.9766
Epoch 29/200
 - 6s - loss: 0.0097 - val_loss: 0.0081
 - val_f1: 0.9805
Epoch 30/200
 - 6s - loss: 0.0096 - val_loss: 0.0082
 - val_f1: 0.9784
Epoch 31/200
 - 6s - loss: 0.0097 - val_loss: 0.0083
 - val_f1: 0.9788
Epoch 32/200
 - 6s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9779
Epoch 33/200
 - 6s - loss: 0.0096 - val_loss: 0.0081
 - val_f1: 0.9789
Epoch 34/200
 - 6s - loss: 0.0096 - val_loss: 0.0091
 - val_f1: 0.9737
Epoch 35/200
 - 6s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9808
Epoch 36/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 37/200
 - 6s - loss: 0.0095 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 38/200
 - 6s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9747
Epoch 39/200
 - 6s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 40/200
 - 6s - loss: 0.0095 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 41/200
 - 6s - loss: 0.0094 - val_loss: 0.0082
2019-12-21 18:09:21,670 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_40.pickle
 - val_f1: 0.9820
Epoch 42/200
 - 6s - loss: 0.0094 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 43/200
 - 6s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9804
Epoch 44/200
 - 6s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9769
Epoch 45/200
 - 6s - loss: 0.0093 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 46/200
 - 6s - loss: 0.0094 - val_loss: 0.0080
 - val_f1: 0.9823
Epoch 47/200
 - 6s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9807
Epoch 48/200
 - 6s - loss: 0.0094 - val_loss: 0.0078
 - val_f1: 0.9766
Epoch 49/200
 - 6s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9795
Epoch 50/200
 - 6s - loss: 0.0093 - val_loss: 0.0080
 - val_f1: 0.9793
Epoch 51/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9819
Epoch 52/200
 - 6s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9780
Epoch 53/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9805
Epoch 54/200
 - 6s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9789
Epoch 55/200
 - 6s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9782
Epoch 56/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 57/200
 - 6s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 58/200
 - 6s - loss: 0.0092 - val_loss: 0.0080
 - val_f1: 0.9793
Epoch 59/200
 - 6s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 60/200
 - 6s - loss: 0.0093 - val_loss: 0.0079
 - val_f1: 0.9808
Epoch 61/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
2019-12-21 18:15:06,222 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9835
Epoch 62/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9810
Epoch 63/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9804
Epoch 64/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 65/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 66/200
 - 6s - loss: 0.0092 - val_loss: 0.0093
 - val_f1: 0.9761
Epoch 67/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9791
Epoch 68/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9793
Epoch 69/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9761
Epoch 70/200
 - 6s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9789
Epoch 71/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9829
Epoch 72/200
 - 6s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9785
Epoch 73/200
 - 6s - loss: 0.0092 - val_loss: 0.0078
 - val_f1: 0.9843
Epoch 74/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9802
Epoch 75/200
 - 6s - loss: 0.0091 - val_loss: 0.0096
 - val_f1: 0.9738
Epoch 76/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9786
Epoch 77/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9811
Epoch 78/200
 - 6s - loss: 0.0091 - val_loss: 0.0076
 - val_f1: 0.9809
Epoch 79/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9793
Epoch 80/200
 - 6s - loss: 0.0090 - val_loss: 0.0078
 - val_f1: 0.9783
Epoch 81/200
 - 6s - loss: 0.0091 - val_loss: 0.0078
2019-12-21 18:20:52,751 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_80.pickle
 - val_f1: 0.9766
Epoch 82/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9796
Epoch 83/200
 - 6s - loss: 0.0091 - val_loss: 0.0080
 - val_f1: 0.9789
Epoch 84/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9812
Epoch 85/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9810
Epoch 86/200
 - 6s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9762
Epoch 87/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9797
Epoch 88/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9781
Epoch 89/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9769
Epoch 90/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9804
Epoch 91/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9798
Epoch 92/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9788
Epoch 93/200
 - 6s - loss: 0.0089 - val_loss: 0.0080
 - val_f1: 0.9772
Epoch 94/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9807
Epoch 95/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9808
Epoch 96/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9794
Epoch 97/200
 - 6s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9822
Epoch 98/200
 - 6s - loss: 0.0091 - val_loss: 0.0078
 - val_f1: 0.9768
Epoch 99/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9814
Epoch 100/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9816
Epoch 101/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
2019-12-21 18:26:36,623 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_100.pickle
 - val_f1: 0.9785
Epoch 102/200
 - 6s - loss: 0.0090 - val_loss: 0.0078
 - val_f1: 0.9785
Epoch 103/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9832
Epoch 104/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9795
Epoch 105/200
 - 6s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9796
Epoch 106/200
 - 6s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9795
Epoch 107/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9811
Epoch 108/200
 - 6s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9823
Epoch 109/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9780
Epoch 110/200
 - 6s - loss: 0.0090 - val_loss: 0.0075
 - val_f1: 0.9829
Epoch 111/200
 - 6s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 112/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9792
Epoch 113/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9800
Epoch 114/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9851
Epoch 115/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9817
Epoch 116/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9852
Epoch 117/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9787
Epoch 118/200
 - 6s - loss: 0.0088 - val_loss: 0.0077
 - val_f1: 0.9762
Epoch 119/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9830
Epoch 120/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9788
Epoch 121/200
 - 6s - loss: 0.0087 - val_loss: 0.0072
2019-12-21 18:32:23,717 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9800
Epoch 122/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9798
Epoch 123/200
 - 6s - loss: 0.0087 - val_loss: 0.0071
 - val_f1: 0.9846
Epoch 124/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 125/200
 - 6s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9809
Epoch 126/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9830
Epoch 127/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9818
Epoch 128/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9761
Epoch 129/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9767
Epoch 130/200
 - 6s - loss: 0.0085 - val_loss: 0.0073
 - val_f1: 0.9822
Epoch 131/200
 - 6s - loss: 0.0087 - val_loss: 0.0088
 - val_f1: 0.9783
Epoch 132/200
 - 6s - loss: 0.0089 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 133/200
 - 6s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9816
Epoch 134/200
 - 6s - loss: 0.0090 - val_loss: 0.0076
 - val_f1: 0.9829
Epoch 135/200
 - 6s - loss: 0.0090 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 136/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9831
Epoch 137/200
 - 6s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9761
Epoch 138/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9802
Epoch 139/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9817
Epoch 140/200
 - 6s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9812
Epoch 141/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
2019-12-21 18:38:10,354 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_140.pickle
 - val_f1: 0.9795
Epoch 142/200
 - 6s - loss: 0.0085 - val_loss: 0.0070
 - val_f1: 0.9819
Epoch 143/200
 - 6s - loss: 0.0086 - val_loss: 0.0073
 - val_f1: 0.9800
Epoch 144/200
 - 6s - loss: 0.0090 - val_loss: 0.0080
 - val_f1: 0.9793
Epoch 145/200
 - 6s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9785
Epoch 146/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9783
Epoch 147/200
 - 6s - loss: 0.0089 - val_loss: 0.0088
 - val_f1: 0.9780
Epoch 148/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9826
Epoch 149/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9824
Epoch 150/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9818
Epoch 151/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9824
Epoch 152/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9820
Epoch 153/200
 - 6s - loss: 0.0089 - val_loss: 0.0077
 - val_f1: 0.9790
Epoch 154/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9792
Epoch 155/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9802
Epoch 156/200
 - 6s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9787
Epoch 157/200
 - 6s - loss: 0.0086 - val_loss: 0.0075
 - val_f1: 0.9787
Epoch 158/200
 - 6s - loss: 0.0085 - val_loss: 0.0075
 - val_f1: 0.9798
Epoch 159/200
 - 6s - loss: 0.0089 - val_loss: 0.0075
 - val_f1: 0.9799
Epoch 160/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9786
Epoch 161/200
 - 6s - loss: 0.0086 - val_loss: 0.0086
2019-12-21 18:43:56,502 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_160.pickle
 - val_f1: 0.9745
Epoch 162/200
 - 6s - loss: 0.0085 - val_loss: 0.0072
 - val_f1: 0.9796
Epoch 163/200
 - 6s - loss: 0.0084 - val_loss: 0.0068
 - val_f1: 0.9859
Epoch 164/200
 - 6s - loss: 0.0083 - val_loss: 0.0069
 - val_f1: 0.9827
Epoch 165/200
 - 6s - loss: 0.0083 - val_loss: 0.0068
 - val_f1: 0.9818
Epoch 166/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9824
Epoch 167/200
 - 6s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9790
Epoch 168/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9838
Epoch 169/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9817
Epoch 170/200
 - 6s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9770
Epoch 171/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9788
Epoch 172/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 173/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9766
Epoch 174/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9837
Epoch 175/200
 - 6s - loss: 0.0085 - val_loss: 0.0076
 - val_f1: 0.9827
Epoch 176/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9794
Epoch 177/200
 - 6s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 178/200
 - 6s - loss: 0.0086 - val_loss: 0.0074
 - val_f1: 0.9799
Epoch 179/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9811
Epoch 180/200
 - 6s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9830
Epoch 181/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
2019-12-21 18:49:40,722 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9836
Epoch 182/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9791
Epoch 183/200
 - 6s - loss: 0.0088 - val_loss: 0.0073
 - val_f1: 0.9835
Epoch 184/200
 - 6s - loss: 0.0086 - val_loss: 0.0072
 - val_f1: 0.9812
Epoch 185/200
 - 6s - loss: 0.0084 - val_loss: 0.0069
 - val_f1: 0.9875
Epoch 186/200
 - 6s - loss: 0.0083 - val_loss: 0.0075
 - val_f1: 0.9828
Epoch 187/200
 - 6s - loss: 0.0089 - val_loss: 0.0074
 - val_f1: 0.9825
Epoch 188/200
 - 6s - loss: 0.0088 - val_loss: 0.0075
 - val_f1: 0.9806
Epoch 189/200
 - 6s - loss: 0.0088 - val_loss: 0.0076
 - val_f1: 0.9798
Epoch 190/200
 - 6s - loss: 0.0087 - val_loss: 0.0073
 - val_f1: 0.9837
Epoch 191/200
 - 6s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9811
Epoch 192/200
 - 6s - loss: 0.0088 - val_loss: 0.0077
 - val_f1: 0.9781
Epoch 193/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
 - val_f1: 0.9844
Epoch 194/200
 - 6s - loss: 0.0087 - val_loss: 0.0074
 - val_f1: 0.9830
Epoch 195/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9815
Epoch 196/200
 - 6s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9788
Epoch 197/200
 - 6s - loss: 0.0086 - val_loss: 0.0071
 - val_f1: 0.9832
Epoch 198/200
 - 6s - loss: 0.0084 - val_loss: 0.0074
 - val_f1: 0.9803
Epoch 199/200
 - 6s - loss: 0.0088 - val_loss: 0.0074
 - val_f1: 0.9818
Epoch 200/200
 - 6s - loss: 0.0087 - val_loss: 0.0075
2019-12-21 18:55:20,351 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-21 18:55:49,259 [INFO] Last epoch loss evaluation: train_loss = 0.006548, val_loss = 0.006763
2019-12-21 18:55:49,296 [INFO] Training complete. time_to_train = 5493.66 sec, 91.56 min
2019-12-21 18:55:49,305 [INFO] Model saved to results_selected_models/selected_ids17_ae_ann_shallow_rep5/best_model.pickle
2019-12-21 18:55:49,490 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep5/training_error_history.png
2019-12-21 18:55:49,667 [INFO] Plot saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep5/training_f1_history.png
2019-12-21 18:55:49,667 [INFO] Making predictions on training, validation, testing data
2019-12-21 18:57:35,206 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-21 18:57:45,358 [INFO] Dataset: Testing. Classification report below
2019-12-21 18:57:45,358 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      0.99    454265
                   Bot       1.00      0.35      0.52       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.99      0.96      0.97      2058
              DoS Hulk       0.95      1.00      0.97     46025
      DoS Slowhttptest       0.88      0.95      0.91      1100
         DoS slowloris       0.97      0.93      0.95      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.90      1.00      0.94     31761
           SSH-Patator       0.96      0.93      0.94      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.80      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 18:57:45,358 [INFO] Overall accuracy (micro avg): 0.9861376825175666
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-21 18:57:56,918 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9861         0.9861                       0.9861                0.0013                   0.0139  0.9861
1     Macro avg        0.9977         0.8031                       0.7566                0.0021                   0.2434  0.7665
2  Weighted avg        0.9882         0.9862                       0.9861                0.0110                   0.0139  0.9858
2019-12-21 18:58:07,232 [INFO] Dataset: Validation. Classification report below
2019-12-21 18:58:07,233 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      0.99    454264
                   Bot       1.00      0.31      0.47       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.99      0.95      0.97      2059
              DoS Hulk       0.95      1.00      0.97     46025
      DoS Slowhttptest       0.89      0.94      0.91      1099
         DoS slowloris       0.97      0.92      0.95      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.90      1.00      0.94     31761
           SSH-Patator       0.96      0.94      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.80      0.75      0.76    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-21 18:58:07,233 [INFO] Overall accuracy (micro avg): 0.9858866048284715
2019-12-21 18:58:18,938 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9859         0.9859                       0.9859                0.0013                   0.0141  0.9859
1     Macro avg        0.9976         0.8037                       0.7511                0.0021                   0.2489  0.7616
2  Weighted avg        0.9880         0.9860                       0.9859                0.0116                   0.0141  0.9856
2019-12-21 18:58:53,110 [INFO] Dataset: Training. Classification report below
2019-12-21 18:58:53,110 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      0.99      0.99   1362791
                   Bot       0.99      0.35      0.51      1174
                  DDoS       1.00      0.99      0.99     76815
         DoS GoldenEye       0.99      0.95      0.97      6176
              DoS Hulk       0.95      1.00      0.97    138074
      DoS Slowhttptest       0.90      0.95      0.92      3300
         DoS slowloris       0.98      0.94      0.96      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.90      1.00      0.94     95282
           SSH-Patator       0.97      0.94      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.80      0.76      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-21 18:58:53,110 [INFO] Overall accuracy (micro avg): 0.9861382555620257
2019-12-21 18:59:31,899 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9861         0.9861                       0.9861                0.0013                   0.0139  0.9861
1     Macro avg        0.9977         0.8049                       0.7568                0.0021                   0.2432  0.7675
2  Weighted avg        0.9882         0.9862                       0.9861                0.0111                   0.0139  0.9858
2019-12-21 18:59:31,950 [INFO] Results saved to: results_selected_models/selected_ids17_ae_ann_shallow_rep5/selected_ids17_ae_ann_shallow_rep5_results.xlsx
2019-12-21 18:59:31,957 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-21 18:59:32,022 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep1
2019-12-21 18:59:32,022 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep1/run_log.log
2019-12-21 18:59:32,022 [INFO] ================= Running experiment no. 1  ================= 

2019-12-21 18:59:32,022 [INFO] Experiment parameters given below
2019-12-21 18:59:32,022 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep1'}
2019-12-21 18:59:32,022 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep1/tf_logs_run_2019_12_21-18_59_32
2019-12-21 18:59:32,022 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-21 18:59:32,024 [INFO] Reading X, y files
2019-12-21 18:59:32,024 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-21 18:59:39,431 [INFO] Reading complete. time_to_read=7.41 seconds
2019-12-21 18:59:39,431 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-21 18:59:41,314 [INFO] Reading complete. time_to_read=1.88 seconds
2019-12-21 18:59:41,314 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-21 18:59:41,856 [INFO] Reading complete. time_to_read=0.54 seconds
2019-12-21 18:59:41,856 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-21 18:59:42,077 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-21 18:59:42,078 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-21 18:59:42,134 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-21 18:59:42,134 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-21 18:59:42,156 [INFO] Reading complete. time_to_read=0.02 seconds
 - val_f1: 0.9797
Traceback (most recent call last):
  File "run_experiments.py", line 658, in <module>
    main()
  File "run_experiments.py", line 652, in main
    run_experiment(exp_params)
  File "run_experiments.py", line 608, in run_experiment
    datasets_orig, datasets_enc, label_encoder = prepare_tabular_data(dataset_dir, concat_train_valid)
  File "run_experiments.py", line 445, in prepare_tabular_data
    datasets_orig = load_datasets(dataset_dir)
  File "run_experiments.py", line 138, in load_datasets
    X_train = pd.concat(X_train_dfs)
  File "/home/sunanda/test/ml_env/lib/python3.6/site-packages/pandas/core/reshape/concat.py", line 229, in concat
    return op.get_result()
  File "/home/sunanda/test/ml_env/lib/python3.6/site-packages/pandas/core/reshape/concat.py", line 426, in get_result
    copy=self.copy)
  File "/home/sunanda/test/ml_env/lib/python3.6/site-packages/pandas/core/internals/managers.py", line 2052, in concatenate_block_managers
    values = values.copy()
MemoryError
Using TensorFlow backend.
2019-12-22 12:17:01,920 [INFO] Read 5 experiments from file: experiment_specs/selected_model_tests/selected_ae_ann.csv
2019-12-22 12:17:01,920 [INFO] ================= Started running experiments ================= 

2019-12-22 12:17:01,920 [INFO] Created directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1
2019-12-22 12:17:01,920 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/run_log.log
2019-12-22 12:17:01,920 [INFO] ================= Running experiment no. 1  ================= 

2019-12-22 12:17:01,920 [INFO] Experiment parameters given below
2019-12-22 12:17:01,920 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ae_ann_shallow_rep1'}
2019-12-22 12:17:01,920 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/tf_logs_run_2019_12_22-12_17_01
2019-12-22 12:17:01,920 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 12:17:01,921 [INFO] Reading X, y files
2019-12-22 12:17:01,921 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 12:17:07,107 [INFO] Reading complete. time_to_read=5.19 seconds
2019-12-22 12:17:07,108 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 12:17:08,627 [INFO] Reading complete. time_to_read=1.52 seconds
2019-12-22 12:17:08,627 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 12:17:10,153 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-22 12:17:10,153 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 12:17:10,462 [INFO] Reading complete. time_to_read=0.31 seconds
2019-12-22 12:17:10,462 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 12:17:10,556 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-22 12:17:10,556 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 12:17:10,651 [INFO] Reading complete. time_to_read=0.10 seconds
2019-12-22 12:17:14,254 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-22 12:17:14,268 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-22 12:17:14,330 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-22 12:17:14,369 [INFO] _________________________________________________________________
2019-12-22 12:17:14,369 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 12:17:14,369 [INFO] =================================================================
2019-12-22 12:17:14,369 [INFO] dense_1 (Dense)              (None, 32)                2496      
2019-12-22 12:17:14,369 [INFO] _________________________________________________________________
2019-12-22 12:17:14,369 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2019-12-22 12:17:14,369 [INFO] _________________________________________________________________
2019-12-22 12:17:14,370 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2019-12-22 12:17:14,370 [INFO] _________________________________________________________________
2019-12-22 12:17:14,370 [INFO] dense_2 (Dense)              (None, 77)                2541      
2019-12-22 12:17:14,370 [INFO] =================================================================
2019-12-22 12:17:14,370 [INFO] Total params: 5,165
2019-12-22 12:17:14,370 [INFO] Trainable params: 5,101
2019-12-22 12:17:14,370 [INFO] Non-trainable params: 64
2019-12-22 12:17:14,370 [INFO] _________________________________________________________________
2019-12-22 12:17:14,472 [INFO] _________________________________________________________________
2019-12-22 12:17:14,472 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 12:17:14,472 [INFO] =================================================================
2019-12-22 12:17:14,472 [INFO] dense_3 (Dense)              (None, 32)                1056      
2019-12-22 12:17:14,472 [INFO] _________________________________________________________________
2019-12-22 12:17:14,473 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-22 12:17:14,473 [INFO] _________________________________________________________________
2019-12-22 12:17:14,473 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-22 12:17:14,473 [INFO] _________________________________________________________________
2019-12-22 12:17:14,473 [INFO] dense_4 (Dense)              (None, 15)                495       
2019-12-22 12:17:14,473 [INFO] =================================================================
2019-12-22 12:17:14,473 [INFO] Total params: 1,679
2019-12-22 12:17:14,473 [INFO] Trainable params: 1,615
2019-12-22 12:17:14,473 [INFO] Non-trainable params: 64
2019-12-22 12:17:14,473 [INFO] _________________________________________________________________
2019-12-22 12:17:14,473 [INFO] Training model
2019-12-22 12:17:14,473 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-22 12:17:34,591 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 16ee950046a693754e189aeb9dece93f897e7c1b
2019-12-22 12:17:34,592 [INFO] Training autoencoder
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-22 12:17:35,115 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-22 12:17:35.386910: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-22 12:17:35.408759: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2019-12-22 12:17:35.408997: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x428ef70 executing computations on platform Host. Devices:
2019-12-22 12:17:35.409032: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 14s - loss: -3.0378e+00 - val_loss: -3.6264e+00
Epoch 2/200
 - 14s - loss: -3.5576e+00 - val_loss: -3.6402e+00
Epoch 3/200
 - 14s - loss: -3.5780e+00 - val_loss: -3.6455e+00
Epoch 4/200
 - 14s - loss: -3.5879e+00 - val_loss: -3.6464e+00
Epoch 5/200
 - 14s - loss: -3.5939e+00 - val_loss: -3.6498e+00
Epoch 6/200
 - 14s - loss: -3.5977e+00 - val_loss: -3.6517e+00
Epoch 7/200
 - 14s - loss: -3.6010e+00 - val_loss: -3.6533e+00
Epoch 8/200
 - 14s - loss: -3.6025e+00 - val_loss: -3.6394e+00
Epoch 9/200
 - 14s - loss: -3.6038e+00 - val_loss: -3.6545e+00
Epoch 10/200
 - 14s - loss: -3.6047e+00 - val_loss: -3.6544e+00
Epoch 11/200
 - 14s - loss: -3.6069e+00 - val_loss: -3.6545e+00
Epoch 12/200
 - 14s - loss: -3.6082e+00 - val_loss: -3.6554e+00
Epoch 13/200
 - 14s - loss: -3.6085e+00 - val_loss: -3.6556e+00
Epoch 14/200
 - 14s - loss: -3.6095e+00 - val_loss: -3.6559e+00
Epoch 15/200
 - 14s - loss: -3.6097e+00 - val_loss: -3.6543e+00
Epoch 16/200
 - 14s - loss: -3.6104e+00 - val_loss: -3.6553e+00
Epoch 17/200
 - 14s - loss: -3.6117e+00 - val_loss: -3.6545e+00
Epoch 18/200
 - 14s - loss: -3.6121e+00 - val_loss: -3.6529e+00
Epoch 19/200
 - 14s - loss: -3.6130e+00 - val_loss: -3.6551e+00
Epoch 20/200
 - 14s - loss: -3.6129e+00 - val_loss: -3.6572e+00
Epoch 21/200
 - 14s - loss: -3.6121e+00 - val_loss: -3.6561e+00
2019-12-22 12:22:21,506 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_20.pickle
Epoch 22/200
 - 14s - loss: -3.6130e+00 - val_loss: -3.6568e+00
Epoch 23/200
 - 14s - loss: -3.6128e+00 - val_loss: -3.6565e+00
Epoch 24/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6550e+00
Epoch 25/200
 - 14s - loss: -3.6146e+00 - val_loss: -3.6554e+00
Epoch 26/200
 - 14s - loss: -3.6152e+00 - val_loss: -3.6569e+00
Epoch 27/200
 - 14s - loss: -3.6145e+00 - val_loss: -3.6574e+00
Epoch 28/200
 - 14s - loss: -3.6147e+00 - val_loss: -3.6579e+00
Epoch 29/200
 - 14s - loss: -3.6151e+00 - val_loss: -3.6557e+00
Epoch 30/200
 - 14s - loss: -3.6157e+00 - val_loss: -3.6573e+00
Epoch 31/200
 - 14s - loss: -3.6156e+00 - val_loss: -3.6578e+00
Epoch 32/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6523e+00
Epoch 33/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.6568e+00
Epoch 34/200
 - 13s - loss: -3.6169e+00 - val_loss: -3.6574e+00
Epoch 35/200
 - 14s - loss: -3.6174e+00 - val_loss: -3.6567e+00
Epoch 36/200
 - 14s - loss: -3.6170e+00 - val_loss: -3.6586e+00
Epoch 37/200
 - 14s - loss: -3.6164e+00 - val_loss: -3.6582e+00
Epoch 38/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6592e+00
Epoch 39/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6586e+00
Epoch 40/200
 - 13s - loss: -3.6182e+00 - val_loss: -3.6559e+00
Epoch 41/200
 - 14s - loss: -3.6170e+00 - val_loss: -3.6528e+00
2019-12-22 12:26:53,292 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_40.pickle
Epoch 42/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6572e+00
Epoch 43/200
 - 14s - loss: -3.6174e+00 - val_loss: -3.6564e+00
Epoch 44/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6593e+00
Epoch 45/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.6536e+00
Epoch 46/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.6575e+00
Epoch 47/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6589e+00
Epoch 48/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6554e+00
Epoch 49/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6555e+00
Epoch 50/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6560e+00
Epoch 51/200
 - 13s - loss: -3.6192e+00 - val_loss: -3.6580e+00
Epoch 52/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.6587e+00
Epoch 53/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6592e+00
Epoch 54/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.6598e+00
Epoch 55/200
 - 14s - loss: -3.6195e+00 - val_loss: -3.6566e+00
Epoch 56/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6598e+00
Epoch 57/200
 - 14s - loss: -3.6197e+00 - val_loss: -3.6589e+00
Epoch 58/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6576e+00
Epoch 59/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6575e+00
Epoch 60/200
 - 14s - loss: -3.6198e+00 - val_loss: -3.6581e+00
Epoch 61/200
 - 14s - loss: -3.6197e+00 - val_loss: -3.6582e+00
2019-12-22 12:31:24,594 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_60.pickle
Epoch 62/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6574e+00
Epoch 63/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6579e+00
Epoch 64/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6578e+00
Epoch 65/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6559e+00
Epoch 66/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6594e+00
Epoch 67/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.6603e+00
Epoch 68/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6542e+00
Epoch 69/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6570e+00
Epoch 70/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6601e+00
Epoch 71/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6538e+00
Epoch 72/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6598e+00
Epoch 73/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6602e+00
Epoch 74/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6564e+00
Epoch 75/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6577e+00
Epoch 76/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6569e+00
Epoch 77/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6599e+00
Epoch 78/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6581e+00
Epoch 79/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6598e+00
Epoch 80/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6606e+00
Epoch 81/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6575e+00
2019-12-22 12:35:55,805 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_80.pickle
Epoch 82/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.6602e+00
Epoch 83/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6609e+00
Epoch 84/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6605e+00
Epoch 85/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6600e+00
Epoch 86/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6608e+00
Epoch 87/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6600e+00
Epoch 88/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6597e+00
Epoch 89/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6591e+00
Epoch 90/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6594e+00
Epoch 91/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6544e+00
Epoch 92/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6567e+00
Epoch 93/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6608e+00
Epoch 94/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6588e+00
Epoch 95/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6599e+00
Epoch 96/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6569e+00
Epoch 97/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6598e+00
Epoch 98/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6580e+00
Epoch 99/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6608e+00
Epoch 100/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6613e+00
Epoch 101/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6613e+00
2019-12-22 12:40:27,822 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_100.pickle
Epoch 102/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6566e+00
Epoch 103/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6609e+00
Epoch 104/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6585e+00
Epoch 105/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6594e+00
Epoch 106/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6618e+00
Epoch 107/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6590e+00
Epoch 108/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6551e+00
Epoch 109/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6615e+00
Epoch 110/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6623e+00
Epoch 111/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6599e+00
Epoch 112/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6607e+00
Epoch 113/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6608e+00
Epoch 114/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6582e+00
Epoch 115/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6624e+00
Epoch 116/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6579e+00
Epoch 117/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6568e+00
Epoch 118/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6586e+00
Epoch 119/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6622e+00
Epoch 120/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6626e+00
Epoch 121/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6579e+00
2019-12-22 12:45:00,093 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_120.pickle
Epoch 122/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6572e+00
Epoch 123/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6581e+00
Epoch 124/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6601e+00
Epoch 125/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6622e+00
Epoch 126/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6620e+00
Epoch 127/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6622e+00
Epoch 128/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6608e+00
Epoch 129/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6606e+00
Epoch 130/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6628e+00
Epoch 131/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6614e+00
Epoch 132/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6595e+00
Epoch 133/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6588e+00
Epoch 134/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6615e+00
Epoch 135/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6610e+00
Epoch 136/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6579e+00
Epoch 137/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6599e+00
Epoch 138/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6601e+00
Epoch 139/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6621e+00
Epoch 140/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6558e+00
Epoch 141/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6629e+00
2019-12-22 12:49:31,450 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_140.pickle
Epoch 142/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6580e+00
Epoch 143/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6590e+00
Epoch 144/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6549e+00
Epoch 145/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6591e+00
Epoch 146/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6628e+00
Epoch 147/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6628e+00
Epoch 148/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6615e+00
Epoch 149/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6597e+00
Epoch 150/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6633e+00
Epoch 151/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6620e+00
Epoch 152/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6596e+00
Epoch 153/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6579e+00
Epoch 154/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6626e+00
Epoch 155/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6587e+00
Epoch 156/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6625e+00
Epoch 157/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6615e+00
Epoch 158/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6589e+00
Epoch 159/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6618e+00
Epoch 160/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6628e+00
Epoch 161/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6603e+00
2019-12-22 12:54:03,968 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_160.pickle
Epoch 162/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6626e+00
Epoch 163/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6612e+00
Epoch 164/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6633e+00
Epoch 165/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6626e+00
Epoch 166/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6612e+00
Epoch 167/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6587e+00
Epoch 168/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6619e+00
Epoch 169/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6630e+00
Epoch 170/200
 - 14s - loss: -3.6240e+00 - val_loss: -3.6631e+00
Epoch 171/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6632e+00
Epoch 172/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6635e+00
Epoch 173/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6623e+00
Epoch 174/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6593e+00
Epoch 175/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6631e+00
Epoch 176/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6623e+00
Epoch 177/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6606e+00
Epoch 178/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6626e+00
Epoch 179/200
 - 14s - loss: -3.6238e+00 - val_loss: -3.6635e+00
Epoch 180/200
 - 14s - loss: -3.6238e+00 - val_loss: -3.6630e+00
Epoch 181/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6609e+00
2019-12-22 12:58:36,790 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ae_model_epoch_180.pickle
Epoch 182/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6622e+00
Epoch 183/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6611e+00
Epoch 184/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6636e+00
Epoch 185/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6626e+00
Epoch 186/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6604e+00
Epoch 187/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6632e+00
Epoch 188/200
 - 14s - loss: -3.6238e+00 - val_loss: -3.6629e+00
Epoch 189/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6610e+00
Epoch 190/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6568e+00
Epoch 191/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6608e+00
Epoch 192/200
 - 14s - loss: -3.6237e+00 - val_loss: -3.6615e+00
Epoch 193/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6627e+00
Epoch 194/200
 - 14s - loss: -3.6237e+00 - val_loss: -3.6621e+00
Epoch 195/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6482e+00
Epoch 196/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6632e+00
Epoch 197/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6633e+00
Epoch 198/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6634e+00
Epoch 199/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6633e+00
Epoch 200/200
 - 14s - loss: -3.6237e+00 - val_loss: -3.6625e+00
2019-12-22 13:02:55,772 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 13:03:14,776 [INFO] Last epoch loss evaluation: train_loss = -3.659928, val_loss = -3.663581
2019-12-22 13:03:14,776 [INFO] Training autoencoder complete
2019-12-22 13:03:14,776 [INFO] Encoding data for supervised training
2019-12-22 13:03:27,371 [INFO] Encoding complete
2019-12-22 13:03:27,371 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 6s - loss: 0.0250 - val_loss: 0.0327
 - val_f1: 0.9005
Epoch 2/200
 - 6s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9824
Epoch 3/200
 - 6s - loss: 0.0094 - val_loss: 0.1436
 - val_f1: 0.8360
Epoch 4/200
 - 6s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 5/200
 - 6s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 6/200
 - 6s - loss: 0.0089 - val_loss: 0.0919
 - val_f1: 0.8526
Epoch 7/200
 - 6s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 8/200
 - 6s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9816
Epoch 9/200
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 10/200
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 11/200
 - 6s - loss: 0.0087 - val_loss: 0.0421
 - val_f1: 0.9189
Epoch 12/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 13/200
 - 6s - loss: 0.0086 - val_loss: 0.0517
 - val_f1: 0.9152
Epoch 14/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 15/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 16/200
 - 6s - loss: 0.0086 - val_loss: 0.0149
 - val_f1: 0.9643
Epoch 17/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 18/200
 - 6s - loss: 0.0086 - val_loss: 0.0087
 - val_f1: 0.9816
Epoch 19/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 20/200
 - 6s - loss: 0.0085 - val_loss: 0.0754
 - val_f1: 0.8646
Epoch 21/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
2019-12-22 13:07:26,392 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9832
Epoch 22/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 23/200
 - 6s - loss: 0.0085 - val_loss: 0.0644
 - val_f1: 0.8952
Epoch 24/200
 - 6s - loss: 0.0085 - val_loss: 0.0864
 - val_f1: 0.8635
Epoch 25/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 26/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 27/200
 - 6s - loss: 0.0085 - val_loss: 0.0751
 - val_f1: 0.8633
Epoch 28/200
 - 6s - loss: 0.0085 - val_loss: 0.0485
 - val_f1: 0.8867
Epoch 29/200
 - 6s - loss: 0.0085 - val_loss: 0.0099
 - val_f1: 0.9814
Epoch 30/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 31/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 32/200
 - 6s - loss: 0.0084 - val_loss: 0.0096
 - val_f1: 0.9805
Epoch 33/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 34/200
 - 6s - loss: 0.0084 - val_loss: 0.0438
 - val_f1: 0.9041
Epoch 35/200
 - 6s - loss: 0.0084 - val_loss: 0.0787
 - val_f1: 0.8750
Epoch 36/200
 - 6s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 37/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 38/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 39/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 40/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 41/200
 - 6s - loss: 0.0084 - val_loss: 0.0664
2019-12-22 13:11:19,324 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.8834
Epoch 42/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 43/200
 - 6s - loss: 0.0084 - val_loss: 0.0501
 - val_f1: 0.8910
Epoch 44/200
 - 6s - loss: 0.0083 - val_loss: 0.0278
 - val_f1: 0.9218
Epoch 45/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 46/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 47/200
 - 6s - loss: 0.0083 - val_loss: 0.0097
 - val_f1: 0.9808
Epoch 48/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 49/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 50/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 51/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 52/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 53/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 54/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 55/200
 - 6s - loss: 0.0083 - val_loss: 0.0568
 - val_f1: 0.8838
Epoch 56/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 57/200
 - 6s - loss: 0.0083 - val_loss: 0.0659
 - val_f1: 0.8810
Epoch 58/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 59/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 60/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 61/200
 - 6s - loss: 0.0083 - val_loss: 0.0149
2019-12-22 13:15:12,290 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9632
Epoch 62/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 63/200
 - 6s - loss: 0.0083 - val_loss: 0.0574
 - val_f1: 0.8802
Epoch 64/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 65/200
 - 6s - loss: 0.0083 - val_loss: 0.0177
 - val_f1: 0.9643
Epoch 66/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 67/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 68/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 69/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 70/200
 - 6s - loss: 0.0083 - val_loss: 0.0120
 - val_f1: 0.9716
Epoch 71/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 72/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 73/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 74/200
 - 6s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 75/200
 - 6s - loss: 0.0083 - val_loss: 0.0444
 - val_f1: 0.9005
Epoch 76/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 77/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 78/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 79/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 80/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 81/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
2019-12-22 13:19:05,368 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9828
Epoch 82/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 83/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 84/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 85/200
 - 6s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 86/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9817
Epoch 87/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 88/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 89/200
 - 6s - loss: 0.0083 - val_loss: 0.0298
 - val_f1: 0.9583
Epoch 90/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 91/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 92/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 93/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 94/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 95/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 96/200
 - 6s - loss: 0.0082 - val_loss: 0.0166
 - val_f1: 0.9599
Epoch 97/200
 - 6s - loss: 0.0082 - val_loss: 0.0104
 - val_f1: 0.9756
Epoch 98/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 99/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 100/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 101/200
 - 6s - loss: 0.0083 - val_loss: 0.0158
2019-12-22 13:22:58,138 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9608
Epoch 102/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 103/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9823
Epoch 104/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 105/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 106/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 107/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 108/200
 - 6s - loss: 0.0082 - val_loss: 0.0129
 - val_f1: 0.9621
Epoch 109/200
 - 6s - loss: 0.0082 - val_loss: 0.0098
 - val_f1: 0.9806
Epoch 110/200
 - 6s - loss: 0.0082 - val_loss: 0.0167
 - val_f1: 0.9557
Epoch 111/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 112/200
 - 6s - loss: 0.0082 - val_loss: 0.0100
 - val_f1: 0.9810
Epoch 113/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 114/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 115/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 116/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 117/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 118/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 119/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 120/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 121/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
2019-12-22 13:26:50,780 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9808
Epoch 122/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 123/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 124/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 125/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 126/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 127/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 128/200
 - 6s - loss: 0.0082 - val_loss: 0.0145
 - val_f1: 0.9601
Epoch 129/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 130/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 131/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 132/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 133/200
 - 6s - loss: 0.0082 - val_loss: 0.0095
 - val_f1: 0.9809
Epoch 134/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 135/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9817
Epoch 136/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 137/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 138/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 139/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 140/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 141/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 13:30:44,079 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9832
Epoch 142/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 143/200
 - 6s - loss: 0.0082 - val_loss: 0.0085
 - val_f1: 0.9805
Epoch 144/200
 - 6s - loss: 0.0082 - val_loss: 0.0130
 - val_f1: 0.9620
Epoch 145/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 146/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 147/200
 - 6s - loss: 0.0082 - val_loss: 0.0100
 - val_f1: 0.9810
Epoch 148/200
 - 6s - loss: 0.0082 - val_loss: 0.0134
 - val_f1: 0.9608
Epoch 149/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9815
Epoch 150/200
 - 6s - loss: 0.0082 - val_loss: 0.0103
 - val_f1: 0.9776
Epoch 151/200
 - 6s - loss: 0.0082 - val_loss: 0.0117
 - val_f1: 0.9673
Epoch 152/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 153/200
 - 6s - loss: 0.0082 - val_loss: 0.0114
 - val_f1: 0.9781
Epoch 154/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 155/200
 - 6s - loss: 0.0082 - val_loss: 0.0094
 - val_f1: 0.9787
Epoch 156/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 157/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 158/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 159/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 160/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 161/200
 - 6s - loss: 0.0082 - val_loss: 0.0097
2019-12-22 13:34:37,188 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9805
Epoch 162/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 163/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 164/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 165/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 166/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 167/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 168/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 169/200
 - 6s - loss: 0.0082 - val_loss: 0.0132
 - val_f1: 0.9604
Epoch 170/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 171/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 172/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 173/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 174/200
 - 6s - loss: 0.0082 - val_loss: 0.0134
 - val_f1: 0.9693
Epoch 175/200
 - 6s - loss: 0.0082 - val_loss: 0.0134
 - val_f1: 0.9579
Epoch 176/200
 - 6s - loss: 0.0082 - val_loss: 0.0086
 - val_f1: 0.9821
Epoch 177/200
 - 6s - loss: 0.0082 - val_loss: 0.0089
 - val_f1: 0.9817
Epoch 178/200
 - 6s - loss: 0.0082 - val_loss: 0.0109
 - val_f1: 0.9706
Epoch 179/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 180/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 181/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
2019-12-22 13:38:29,741 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9827
Epoch 182/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 183/200
 - 6s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9820
Epoch 184/200
 - 6s - loss: 0.0082 - val_loss: 0.0095
 - val_f1: 0.9798
Epoch 185/200
 - 6s - loss: 0.0082 - val_loss: 0.0086
 - val_f1: 0.9823
Epoch 186/200
 - 6s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9823
Epoch 187/200
 - 6s - loss: 0.0081 - val_loss: 0.0110
 - val_f1: 0.9697
Epoch 188/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 189/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 190/200
 - 6s - loss: 0.0082 - val_loss: 0.0101
 - val_f1: 0.9794
Epoch 191/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 192/200
 - 6s - loss: 0.0082 - val_loss: 0.0096
 - val_f1: 0.9798
Epoch 193/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 194/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 195/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 196/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9813
Epoch 197/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 198/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 199/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 200/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 13:42:16,096 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 13:42:33,153 [INFO] Last epoch loss evaluation: train_loss = 0.007830, val_loss = 0.007907
2019-12-22 13:42:33,194 [INFO] Training complete. time_to_train = 5118.72 sec, 85.31 min
2019-12-22 13:42:33,200 [INFO] Model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/best_model.pickle
2019-12-22 13:42:33,399 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/training_error_history.png
2019-12-22 13:42:33,583 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/training_f1_history.png
2019-12-22 13:42:33,583 [INFO] Making predictions on training, validation, testing data
2019-12-22 13:43:25,434 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 13:43:37,517 [INFO] Dataset: Testing. Classification report below
2019-12-22 13:43:37,517 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.60      0.33      0.43         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.46      0.56      5596
   DoS attacks-Slowloris       0.98      0.74      0.84       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.48      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.74      0.69      0.69    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 13:43:37,517 [INFO] Overall accuracy (micro avg): 0.9831352403143049
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-22 13:43:51,133 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9978         0.7437                       0.6934                0.0045                   0.3066  0.6947
2  Weighted avg        0.9909         0.9783                       0.9831                0.0502                   0.0169  0.9779
2019-12-22 13:44:03,162 [INFO] Dataset: Validation. Classification report below
2019-12-22 13:44:03,162 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.75      0.67      0.71         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.98      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.45      0.56      5596
   DoS attacks-Slowloris       0.98      0.77      0.86       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.45      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.76      0.72      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 13:44:03,163 [INFO] Overall accuracy (micro avg): 0.9832281672597589
2019-12-22 13:44:16,806 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7559                       0.7169                0.0044                   0.2831  0.7168
2  Weighted avg        0.9909         0.9781                       0.9832                0.0500                   0.0168  0.9780
2019-12-22 13:44:55,995 [INFO] Dataset: Training. Classification report below
2019-12-22 13:44:55,995 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.76      0.50      0.60        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.98      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.45      0.56     16787
   DoS attacks-Slowloris       0.99      0.76      0.86      1318
          FTP-BruteForce       0.69      0.89      0.78     23153
           Infilteration       0.55      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.76      0.70      0.71   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 13:44:55,995 [INFO] Overall accuracy (micro avg): 0.9831997736077445
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-22 13:45:40,530 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7611                       0.7049                0.0045                   0.2951  0.7080
2  Weighted avg        0.9910         0.9790                       0.9832                0.0500                   0.0168  0.9780
2019-12-22 13:45:40,589 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep1/selected_ids18_subset_ae_ann_shallow_rep1_results.xlsx
2019-12-22 13:45:40,597 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-22 13:45:40,671 [INFO] Created directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2
2019-12-22 13:45:40,671 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/run_log.log
2019-12-22 13:45:40,671 [INFO] ================= Running experiment no. 2  ================= 

2019-12-22 13:45:40,671 [INFO] Experiment parameters given below
2019-12-22 13:45:40,671 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ae_ann_shallow_rep2'}
2019-12-22 13:45:40,671 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/tf_logs_run_2019_12_22-13_45_40
2019-12-22 13:45:40,671 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 13:45:40,672 [INFO] Reading X, y files
2019-12-22 13:45:40,672 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 13:45:44,991 [INFO] Reading complete. time_to_read=4.32 seconds
2019-12-22 13:45:44,991 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 13:45:46,474 [INFO] Reading complete. time_to_read=1.48 seconds
2019-12-22 13:45:46,474 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 13:45:47,964 [INFO] Reading complete. time_to_read=1.49 seconds
2019-12-22 13:45:47,964 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 13:45:48,218 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-22 13:45:48,218 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 13:45:48,296 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 13:45:48,296 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 13:45:48,373 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 13:45:51,970 [INFO] Initializing model
2019-12-22 13:45:52,076 [INFO] _________________________________________________________________
2019-12-22 13:45:52,076 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 13:45:52,076 [INFO] =================================================================
2019-12-22 13:45:52,076 [INFO] dense_5 (Dense)              (None, 32)                2496      
2019-12-22 13:45:52,076 [INFO] _________________________________________________________________
2019-12-22 13:45:52,076 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-22 13:45:52,076 [INFO] _________________________________________________________________
2019-12-22 13:45:52,076 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-22 13:45:52,077 [INFO] _________________________________________________________________
2019-12-22 13:45:52,077 [INFO] dense_6 (Dense)              (None, 77)                2541      
2019-12-22 13:45:52,077 [INFO] =================================================================
2019-12-22 13:45:52,077 [INFO] Total params: 5,165
2019-12-22 13:45:52,077 [INFO] Trainable params: 5,101
2019-12-22 13:45:52,077 [INFO] Non-trainable params: 64
2019-12-22 13:45:52,077 [INFO] _________________________________________________________________
2019-12-22 13:45:52,183 [INFO] _________________________________________________________________
2019-12-22 13:45:52,183 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 13:45:52,183 [INFO] =================================================================
2019-12-22 13:45:52,183 [INFO] dense_7 (Dense)              (None, 32)                1056      
2019-12-22 13:45:52,183 [INFO] _________________________________________________________________
2019-12-22 13:45:52,183 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-22 13:45:52,183 [INFO] _________________________________________________________________
2019-12-22 13:45:52,183 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-22 13:45:52,184 [INFO] _________________________________________________________________
2019-12-22 13:45:52,184 [INFO] dense_8 (Dense)              (None, 15)                495       
2019-12-22 13:45:52,184 [INFO] =================================================================
2019-12-22 13:45:52,184 [INFO] Total params: 1,679
2019-12-22 13:45:52,184 [INFO] Trainable params: 1,615
2019-12-22 13:45:52,184 [INFO] Non-trainable params: 64
2019-12-22 13:45:52,184 [INFO] _________________________________________________________________
2019-12-22 13:45:52,184 [INFO] Training model
2019-12-22 13:45:52,184 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-22 13:46:12,472 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 0a780da5c9dbee98e7837a6c1ca0b18766646a69
2019-12-22 13:46:12,473 [INFO] Training autoencoder
 - val_f1: 0.9832
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 14s - loss: -3.0259e+00 - val_loss: -3.6193e+00
Epoch 2/200
 - 14s - loss: -3.5525e+00 - val_loss: -3.6352e+00
Epoch 3/200
 - 14s - loss: -3.5737e+00 - val_loss: -3.6421e+00
Epoch 4/200
 - 14s - loss: -3.5803e+00 - val_loss: -3.6414e+00
Epoch 5/200
 - 14s - loss: -3.5872e+00 - val_loss: -3.6337e+00
Epoch 6/200
 - 14s - loss: -3.5926e+00 - val_loss: -3.6492e+00
Epoch 7/200
 - 14s - loss: -3.5953e+00 - val_loss: -3.6510e+00
Epoch 8/200
 - 14s - loss: -3.5972e+00 - val_loss: -3.6495e+00
Epoch 9/200
 - 14s - loss: -3.5978e+00 - val_loss: -3.6489e+00
Epoch 10/200
 - 14s - loss: -3.6001e+00 - val_loss: -3.6540e+00
Epoch 11/200
 - 14s - loss: -3.6027e+00 - val_loss: -3.6521e+00
Epoch 12/200
 - 14s - loss: -3.6035e+00 - val_loss: -3.6233e+00
Epoch 13/200
 - 14s - loss: -3.6050e+00 - val_loss: -3.5927e+00
Epoch 14/200
 - 14s - loss: -3.6048e+00 - val_loss: -3.6569e+00
Epoch 15/200
 - 14s - loss: -3.6070e+00 - val_loss: -3.6521e+00
Epoch 16/200
 - 14s - loss: -3.6068e+00 - val_loss: -3.6452e+00
Epoch 17/200
 - 14s - loss: -3.6075e+00 - val_loss: -3.6570e+00
Epoch 18/200
 - 14s - loss: -3.6095e+00 - val_loss: -3.4453e+00
Epoch 19/200
 - 14s - loss: -3.6106e+00 - val_loss: -3.6521e+00
Epoch 20/200
 - 14s - loss: -3.6098e+00 - val_loss: -3.6491e+00
Epoch 21/200
 - 14s - loss: -3.6116e+00 - val_loss: -3.6514e+00
2019-12-22 13:51:02,923 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_20.pickle
Epoch 22/200
 - 14s - loss: -3.6115e+00 - val_loss: -3.6261e+00
Epoch 23/200
 - 14s - loss: -3.6135e+00 - val_loss: -3.6508e+00
Epoch 24/200
 - 14s - loss: -3.6127e+00 - val_loss: -3.6590e+00
Epoch 25/200
 - 14s - loss: -3.6123e+00 - val_loss: -3.6581e+00
Epoch 26/200
 - 14s - loss: -3.6124e+00 - val_loss: -3.6585e+00
Epoch 27/200
 - 14s - loss: -3.6156e+00 - val_loss: -3.6583e+00
Epoch 28/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6336e+00
Epoch 29/200
 - 14s - loss: -3.6142e+00 - val_loss: -3.6595e+00
Epoch 30/200
 - 14s - loss: -3.6149e+00 - val_loss: -3.6567e+00
Epoch 31/200
 - 14s - loss: -3.6148e+00 - val_loss: -3.6545e+00
Epoch 32/200
 - 14s - loss: -3.6161e+00 - val_loss: -3.6600e+00
Epoch 33/200
 - 14s - loss: -3.6136e+00 - val_loss: -3.6586e+00
Epoch 34/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.4851e+00
Epoch 35/200
 - 14s - loss: -3.6149e+00 - val_loss: -3.6594e+00
Epoch 36/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6565e+00
Epoch 37/200
 - 14s - loss: -3.6165e+00 - val_loss: -3.5845e+00
Epoch 38/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.5291e+00
Epoch 39/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6603e+00
Epoch 40/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6612e+00
Epoch 41/200
 - 14s - loss: -3.6159e+00 - val_loss: -3.5819e+00
2019-12-22 13:55:37,929 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_40.pickle
Epoch 42/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6510e+00
Epoch 43/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6612e+00
Epoch 44/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6598e+00
Epoch 45/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.5679e+00
Epoch 46/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6571e+00
Epoch 47/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6597e+00
Epoch 48/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6586e+00
Epoch 49/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6619e+00
Epoch 50/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.5843e+00
Epoch 51/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6407e+00
Epoch 52/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.5624e+00
Epoch 53/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6593e+00
Epoch 54/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.6598e+00
Epoch 55/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6356e+00
Epoch 56/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6613e+00
Epoch 57/200
 - 14s - loss: -3.6199e+00 - val_loss: -3.5633e+00
Epoch 58/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.5727e+00
Epoch 59/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.5580e+00
Epoch 60/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6352e+00
Epoch 61/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6550e+00
2019-12-22 14:00:13,032 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_60.pickle
Epoch 62/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.5584e+00
Epoch 63/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6593e+00
Epoch 64/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.5736e+00
Epoch 65/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6415e+00
Epoch 66/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6620e+00
Epoch 67/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6570e+00
Epoch 68/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6597e+00
Epoch 69/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6572e+00
Epoch 70/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.5706e+00
Epoch 71/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.4562e+00
Epoch 72/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6041e+00
Epoch 73/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6618e+00
Epoch 74/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6615e+00
Epoch 75/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6559e+00
Epoch 76/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6575e+00
Epoch 77/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6575e+00
Epoch 78/200
 - 14s - loss: -3.6199e+00 - val_loss: -3.5315e+00
Epoch 79/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6552e+00
Epoch 80/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.5338e+00
Epoch 81/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6597e+00
2019-12-22 14:04:48,233 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_80.pickle
Epoch 82/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6426e+00
Epoch 83/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.6136e+00
Epoch 84/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6607e+00
Epoch 85/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6557e+00
Epoch 86/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6556e+00
Epoch 87/200
 - 14s - loss: -3.6199e+00 - val_loss: -3.6043e+00
Epoch 88/200
 - 14s - loss: -3.6197e+00 - val_loss: -3.6626e+00
Epoch 89/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6533e+00
Epoch 90/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6621e+00
Epoch 91/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6525e+00
Epoch 92/200
 - 14s - loss: -3.6195e+00 - val_loss: -3.5895e+00
Epoch 93/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.5971e+00
Epoch 94/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6612e+00
Epoch 95/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6561e+00
Epoch 96/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6620e+00
Epoch 97/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6311e+00
Epoch 98/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.4983e+00
Epoch 99/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6308e+00
Epoch 100/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6604e+00
Epoch 101/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.6598e+00
2019-12-22 14:09:23,115 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_100.pickle
Epoch 102/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6627e+00
Epoch 103/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.6614e+00
Epoch 104/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6529e+00
Epoch 105/200
 - 14s - loss: -3.6197e+00 - val_loss: -3.6225e+00
Epoch 106/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6560e+00
Epoch 107/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6128e+00
Epoch 108/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6560e+00
Epoch 109/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6610e+00
Epoch 110/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6398e+00
Epoch 111/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6619e+00
Epoch 112/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6594e+00
Epoch 113/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6627e+00
Epoch 114/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6620e+00
Epoch 115/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6630e+00
Epoch 116/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6604e+00
Epoch 117/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6599e+00
Epoch 118/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.5521e+00
Epoch 119/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6590e+00
Epoch 120/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6134e+00
Epoch 121/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6617e+00
2019-12-22 14:13:57,798 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_120.pickle
Epoch 122/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6616e+00
Epoch 123/200
 - 14s - loss: -3.6197e+00 - val_loss: -3.6507e+00
Epoch 124/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6597e+00
Epoch 125/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.5371e+00
Epoch 126/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6159e+00
Epoch 127/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6614e+00
Epoch 128/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6045e+00
Epoch 129/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6619e+00
Epoch 130/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.5099e+00
Epoch 131/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6346e+00
Epoch 132/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6626e+00
Epoch 133/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6416e+00
Epoch 134/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6171e+00
Epoch 135/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.6612e+00
Epoch 136/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6394e+00
Epoch 137/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6600e+00
Epoch 138/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6608e+00
Epoch 139/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6626e+00
Epoch 140/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6611e+00
Epoch 141/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.5806e+00
2019-12-22 14:18:32,599 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_140.pickle
Epoch 142/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6631e+00
Epoch 143/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.5596e+00
Epoch 144/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.5588e+00
Epoch 145/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6599e+00
Epoch 146/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.5500e+00
Epoch 147/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6610e+00
Epoch 148/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.5474e+00
Epoch 149/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6615e+00
Epoch 150/200
 - 14s - loss: -3.6234e+00 - val_loss: -3.6185e+00
Epoch 151/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6531e+00
Epoch 152/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6496e+00
Epoch 153/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6452e+00
Epoch 154/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6550e+00
Epoch 155/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6557e+00
Epoch 156/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6603e+00
Epoch 157/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6564e+00
Epoch 158/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6597e+00
Epoch 159/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.5248e+00
Epoch 160/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6616e+00
Epoch 161/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6594e+00
2019-12-22 14:23:07,370 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_160.pickle
Epoch 162/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6472e+00
Epoch 163/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6628e+00
Epoch 164/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6605e+00
Epoch 165/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6630e+00
Epoch 166/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6578e+00
Epoch 167/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6614e+00
Epoch 168/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6561e+00
Epoch 169/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6616e+00
Epoch 170/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6462e+00
Epoch 171/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6603e+00
Epoch 172/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.5230e+00
Epoch 173/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6616e+00
Epoch 174/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6619e+00
Epoch 175/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6615e+00
Epoch 176/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.5509e+00
Epoch 177/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6599e+00
Epoch 178/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6638e+00
Epoch 179/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6610e+00
Epoch 180/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.5521e+00
Epoch 181/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6631e+00
2019-12-22 14:27:41,801 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ae_model_epoch_180.pickle
Epoch 182/200
 - 14s - loss: -3.6240e+00 - val_loss: -3.6103e+00
Epoch 183/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.5847e+00
Epoch 184/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.5640e+00
Epoch 185/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6630e+00
Epoch 186/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.5117e+00
Epoch 187/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6400e+00
Epoch 188/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6617e+00
Epoch 189/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6388e+00
Epoch 190/200
 - 14s - loss: -3.6227e+00 - val_loss: -3.6624e+00
Epoch 191/200
 - 14s - loss: -3.6237e+00 - val_loss: -3.6568e+00
Epoch 192/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6535e+00
Epoch 193/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6605e+00
Epoch 194/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6612e+00
Epoch 195/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6595e+00
Epoch 196/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.5590e+00
Epoch 197/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6551e+00
Epoch 198/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.5787e+00
Epoch 199/200
 - 14s - loss: -3.6232e+00 - val_loss: -3.6502e+00
Epoch 200/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6631e+00
2019-12-22 14:32:02,859 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 14:32:23,377 [INFO] Last epoch loss evaluation: train_loss = -3.660805, val_loss = -3.663795
2019-12-22 14:32:23,377 [INFO] Training autoencoder complete
2019-12-22 14:32:23,377 [INFO] Encoding data for supervised training
2019-12-22 14:32:37,798 [INFO] Encoding complete
2019-12-22 14:32:37,798 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 6s - loss: 0.0236 - val_loss: 0.0094
 - val_f1: 0.9809
Epoch 2/200
 - 6s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9814
Epoch 3/200
 - 6s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9824
Epoch 4/200
 - 6s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9803
Epoch 5/200
 - 6s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 6/200
 - 6s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9833
Epoch 7/200
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 8/200
 - 6s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 9/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 10/200
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 11/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 12/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 13/200
 - 6s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 14/200
 - 6s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9813
Epoch 15/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 16/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 17/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 18/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 19/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 20/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 21/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
2019-12-22 14:36:58,326 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9829
Epoch 22/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 23/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 24/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 25/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9818
Epoch 26/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 27/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 28/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 29/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 30/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 31/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 32/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 33/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 34/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 35/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 36/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 37/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 38/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 39/200
 - 6s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9832
Epoch 40/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9813
Epoch 41/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
2019-12-22 14:41:10,860 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9831
Epoch 42/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 43/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 44/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9817
Epoch 45/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 46/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 47/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 48/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 49/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 50/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 51/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 52/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 53/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 54/200
 - 6s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 55/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 56/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 57/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 58/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 59/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 60/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 61/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
2019-12-22 14:45:22,937 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9832
Epoch 62/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 63/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 64/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 65/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 66/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 67/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 68/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 69/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 70/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 71/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 72/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 73/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 74/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 75/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 76/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 77/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 78/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 79/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 80/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 81/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 14:49:34,769 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9829
Epoch 82/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 83/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 84/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 85/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 86/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 87/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 88/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 89/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 90/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 91/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 92/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 93/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 94/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9813
Epoch 95/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 96/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 97/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 98/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 99/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 100/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 101/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 14:53:47,379 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9831
Epoch 102/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 103/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 104/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 105/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 106/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 107/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 108/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 109/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 110/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 111/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 112/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 113/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 114/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 115/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 116/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 117/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 118/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 119/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 120/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 121/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 14:58:00,213 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9830
Epoch 122/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 123/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 124/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 125/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 126/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 127/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 128/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 129/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 130/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 131/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 132/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 133/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 134/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 135/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 136/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 137/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 138/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 139/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 140/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 141/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 15:02:12,039 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9835
Epoch 142/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 143/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 144/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 145/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 146/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 147/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 148/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 149/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 150/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 151/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 152/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 153/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 154/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 155/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 156/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 157/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 158/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 159/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 160/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 161/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
2019-12-22 15:06:24,863 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9832
Epoch 162/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 163/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 164/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 165/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 166/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 167/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 168/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 169/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 170/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 171/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 172/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 173/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 174/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 175/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 176/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 177/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 178/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 179/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 180/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 181/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 15:10:36,689 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9834
Epoch 182/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 183/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 184/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 185/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 186/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 187/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 188/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 189/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 190/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9830
Epoch 191/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 192/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 193/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 194/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 195/200
 - 6s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9822
Epoch 196/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 197/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 198/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 199/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 200/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
2019-12-22 15:14:42,320 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 15:15:01,071 [INFO] Last epoch loss evaluation: train_loss = 0.007833, val_loss = 0.007860
2019-12-22 15:15:01,110 [INFO] Training complete. time_to_train = 5348.93 sec, 89.15 min
2019-12-22 15:15:01,118 [INFO] Model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/best_model.pickle
2019-12-22 15:15:01,382 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/training_error_history.png
2019-12-22 15:15:01,567 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/training_f1_history.png
2019-12-22 15:15:01,567 [INFO] Making predictions on training, validation, testing data
2019-12-22 15:16:01,077 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 15:16:13,046 [INFO] Dataset: Testing. Classification report below
2019-12-22 15:16:13,046 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.73      0.99      0.84        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.46      0.56      5596
   DoS attacks-Slowloris       0.96      0.96      0.96       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.41      0.02      0.03      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.77      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 15:16:13,046 [INFO] Overall accuracy (micro avg): 0.9831770691321915
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-22 15:16:26,666 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7659                       0.7075                0.0044                   0.2925  0.7092
2  Weighted avg        0.9909         0.9778                       0.9832                0.0492                   0.0168  0.9782
2019-12-22 15:16:38,670 [INFO] Dataset: Validation. Classification report below
2019-12-22 15:16:38,671 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.86      0.67      0.75         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.78      0.97      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.45      0.56      5596
   DoS attacks-Slowloris       0.94      0.95      0.95       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.45      0.02      0.04      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.76      0.73      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 15:16:38,671 [INFO] Overall accuracy (micro avg): 0.9832761930139569
2019-12-22 15:16:52,292 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7624                       0.7288                0.0044                   0.2712  0.7275
2  Weighted avg        0.9910         0.9784                       0.9833                0.0490                   0.0167  0.9783
2019-12-22 15:17:31,902 [INFO] Dataset: Training. Classification report below
2019-12-22 15:17:31,902 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.87      0.50      0.63        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.97      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.45      0.56     16787
   DoS attacks-Slowloris       0.96      0.97      0.96      1318
          FTP-BruteForce       0.69      0.89      0.78     23153
           Infilteration       0.46      0.02      0.04     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.76      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 15:17:31,902 [INFO] Overall accuracy (micro avg): 0.9832390204403701
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-22 15:18:16,867 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7617                       0.7182                0.0044                   0.2818  0.7190
2  Weighted avg        0.9910         0.9784                       0.9832                0.0490                   0.0168  0.9783
2019-12-22 15:18:16,925 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep2/selected_ids18_subset_ae_ann_shallow_rep2_results.xlsx
2019-12-22 15:18:16,930 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-22 15:18:17,004 [INFO] Created directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3
2019-12-22 15:18:17,004 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/run_log.log
2019-12-22 15:18:17,004 [INFO] ================= Running experiment no. 3  ================= 

2019-12-22 15:18:17,004 [INFO] Experiment parameters given below
2019-12-22 15:18:17,004 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ae_ann_shallow_rep3'}
2019-12-22 15:18:17,005 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/tf_logs_run_2019_12_22-15_18_17
2019-12-22 15:18:17,005 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 15:18:17,005 [INFO] Reading X, y files
2019-12-22 15:18:17,005 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 15:18:21,312 [INFO] Reading complete. time_to_read=4.31 seconds
2019-12-22 15:18:21,312 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 15:18:22,801 [INFO] Reading complete. time_to_read=1.49 seconds
2019-12-22 15:18:22,801 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 15:18:24,289 [INFO] Reading complete. time_to_read=1.49 seconds
2019-12-22 15:18:24,289 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 15:18:24,517 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-22 15:18:24,517 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 15:18:24,595 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 15:18:24,595 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 15:18:24,672 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 15:18:28,275 [INFO] Initializing model
2019-12-22 15:18:28,383 [INFO] _________________________________________________________________
2019-12-22 15:18:28,383 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 15:18:28,383 [INFO] =================================================================
2019-12-22 15:18:28,383 [INFO] dense_9 (Dense)              (None, 32)                2496      
2019-12-22 15:18:28,383 [INFO] _________________________________________________________________
2019-12-22 15:18:28,384 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-22 15:18:28,384 [INFO] _________________________________________________________________
2019-12-22 15:18:28,384 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-22 15:18:28,384 [INFO] _________________________________________________________________
2019-12-22 15:18:28,384 [INFO] dense_10 (Dense)             (None, 77)                2541      
2019-12-22 15:18:28,384 [INFO] =================================================================
2019-12-22 15:18:28,384 [INFO] Total params: 5,165
2019-12-22 15:18:28,384 [INFO] Trainable params: 5,101
2019-12-22 15:18:28,384 [INFO] Non-trainable params: 64
2019-12-22 15:18:28,384 [INFO] _________________________________________________________________
2019-12-22 15:18:28,490 [INFO] _________________________________________________________________
2019-12-22 15:18:28,490 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 15:18:28,490 [INFO] =================================================================
2019-12-22 15:18:28,490 [INFO] dense_11 (Dense)             (None, 32)                1056      
2019-12-22 15:18:28,490 [INFO] _________________________________________________________________
2019-12-22 15:18:28,490 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2019-12-22 15:18:28,490 [INFO] _________________________________________________________________
2019-12-22 15:18:28,490 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2019-12-22 15:18:28,491 [INFO] _________________________________________________________________
2019-12-22 15:18:28,491 [INFO] dense_12 (Dense)             (None, 15)                495       
2019-12-22 15:18:28,491 [INFO] =================================================================
2019-12-22 15:18:28,491 [INFO] Total params: 1,679
2019-12-22 15:18:28,491 [INFO] Trainable params: 1,615
2019-12-22 15:18:28,491 [INFO] Non-trainable params: 64
2019-12-22 15:18:28,491 [INFO] _________________________________________________________________
2019-12-22 15:18:28,491 [INFO] Training model
2019-12-22 15:18:28,491 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-22 15:18:49,183 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 9c420077b66a169f5873394ce9ba0dfa8d7a8630
2019-12-22 15:18:49,183 [INFO] Training autoencoder
 - val_f1: 0.9831
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 14s - loss: -3.0358e+00 - val_loss: -3.6220e+00
Epoch 2/200
 - 14s - loss: -3.5578e+00 - val_loss: -2.8920e+00
Epoch 3/200
 - 14s - loss: -3.5773e+00 - val_loss: -3.6408e+00
Epoch 4/200
 - 14s - loss: -3.5887e+00 - val_loss: -3.4977e+00
Epoch 5/200
 - 14s - loss: -3.5937e+00 - val_loss: -3.6492e+00
Epoch 6/200
 - 14s - loss: -3.5972e+00 - val_loss: -3.6515e+00
Epoch 7/200
 - 14s - loss: -3.6019e+00 - val_loss: -3.6507e+00
Epoch 8/200
 - 14s - loss: -3.6055e+00 - val_loss: -3.6541e+00
Epoch 9/200
 - 14s - loss: -3.6072e+00 - val_loss: -3.6549e+00
Epoch 10/200
 - 14s - loss: -3.6093e+00 - val_loss: -3.6563e+00
Epoch 11/200
 - 14s - loss: -3.6097e+00 - val_loss: -3.6421e+00
Epoch 12/200
 - 14s - loss: -3.6106e+00 - val_loss: -3.6550e+00
Epoch 13/200
 - 14s - loss: -3.6088e+00 - val_loss: -3.6551e+00
Epoch 14/200
 - 14s - loss: -3.6099e+00 - val_loss: -3.6364e+00
Epoch 15/200
 - 14s - loss: -3.6106e+00 - val_loss: -3.6434e+00
Epoch 16/200
 - 14s - loss: -3.6108e+00 - val_loss: -3.6562e+00
Epoch 17/200
 - 14s - loss: -3.6108e+00 - val_loss: -3.6564e+00
Epoch 18/200
 - 14s - loss: -3.6120e+00 - val_loss: -3.6539e+00
Epoch 19/200
 - 14s - loss: -3.6151e+00 - val_loss: -3.6564e+00
Epoch 20/200
 - 14s - loss: -3.6125e+00 - val_loss: -3.6575e+00
Epoch 21/200
 - 14s - loss: -3.6140e+00 - val_loss: -3.6581e+00
2019-12-22 15:23:38,759 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_20.pickle
Epoch 22/200
 - 14s - loss: -3.6142e+00 - val_loss: -3.6581e+00
Epoch 23/200
 - 14s - loss: -3.6137e+00 - val_loss: -3.6582e+00
Epoch 24/200
 - 14s - loss: -3.6148e+00 - val_loss: -3.6581e+00
Epoch 25/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6578e+00
Epoch 26/200
 - 14s - loss: -3.6148e+00 - val_loss: -3.6579e+00
Epoch 27/200
 - 14s - loss: -3.6159e+00 - val_loss: -3.6584e+00
Epoch 28/200
 - 14s - loss: -3.6167e+00 - val_loss: -3.6585e+00
Epoch 29/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6592e+00
Epoch 30/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6595e+00
Epoch 31/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6599e+00
Epoch 32/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.6169e+00
Epoch 33/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6345e+00
Epoch 34/200
 - 14s - loss: -3.6172e+00 - val_loss: -3.6408e+00
Epoch 35/200
 - 14s - loss: -3.6166e+00 - val_loss: -3.6387e+00
Epoch 36/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6607e+00
Epoch 37/200
 - 14s - loss: -3.6162e+00 - val_loss: -3.6570e+00
Epoch 38/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6609e+00
Epoch 39/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6259e+00
Epoch 40/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6604e+00
Epoch 41/200
 - 14s - loss: -3.6172e+00 - val_loss: -3.6451e+00
2019-12-22 15:28:12,576 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_40.pickle
Epoch 42/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6605e+00
Epoch 43/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6585e+00
Epoch 44/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6617e+00
Epoch 45/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6576e+00
Epoch 46/200
 - 14s - loss: -3.6198e+00 - val_loss: -3.6554e+00
Epoch 47/200
 - 14s - loss: -3.6175e+00 - val_loss: -3.6613e+00
Epoch 48/200
 - 14s - loss: -3.6175e+00 - val_loss: -3.6614e+00
Epoch 49/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6612e+00
Epoch 50/200
 - 14s - loss: -3.6180e+00 - val_loss: -3.6601e+00
Epoch 51/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6615e+00
Epoch 52/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6612e+00
Epoch 53/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6613e+00
Epoch 54/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6608e+00
Epoch 55/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6548e+00
Epoch 56/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6620e+00
Epoch 57/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6325e+00
Epoch 58/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6609e+00
Epoch 59/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.6635e+00
Epoch 60/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6638e+00
Epoch 61/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.6619e+00
2019-12-22 15:32:46,192 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_60.pickle
Epoch 62/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6555e+00
Epoch 63/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6424e+00
Epoch 64/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6622e+00
Epoch 65/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6627e+00
Epoch 66/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6155e+00
Epoch 67/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6629e+00
Epoch 68/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6458e+00
Epoch 69/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6635e+00
Epoch 70/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6328e+00
Epoch 71/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6627e+00
Epoch 72/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6593e+00
Epoch 73/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.6628e+00
Epoch 74/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6260e+00
Epoch 75/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6621e+00
Epoch 76/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6639e+00
Epoch 77/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6602e+00
Epoch 78/200
 - 14s - loss: -3.6199e+00 - val_loss: -3.6625e+00
Epoch 79/200
 - 14s - loss: -3.6244e+00 - val_loss: -3.6629e+00
Epoch 80/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6619e+00
Epoch 81/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6514e+00
2019-12-22 15:37:19,825 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_80.pickle
Epoch 82/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6615e+00
Epoch 83/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6614e+00
Epoch 84/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.6603e+00
Epoch 85/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6609e+00
Epoch 86/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6395e+00
Epoch 87/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6621e+00
Epoch 88/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6491e+00
Epoch 89/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6464e+00
Epoch 90/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6401e+00
Epoch 91/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6614e+00
Epoch 92/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6612e+00
Epoch 93/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6611e+00
Epoch 94/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6493e+00
Epoch 95/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6614e+00
Epoch 96/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6615e+00
Epoch 97/200
 - 14s - loss: -3.6238e+00 - val_loss: -3.6615e+00
Epoch 98/200
 - 14s - loss: -3.6261e+00 - val_loss: -3.6613e+00
Epoch 99/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6602e+00
Epoch 100/200
 - 14s - loss: -3.6243e+00 - val_loss: -3.6452e+00
Epoch 101/200
 - 14s - loss: -3.6245e+00 - val_loss: -3.6614e+00
2019-12-22 15:41:54,414 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_100.pickle
Epoch 102/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6481e+00
Epoch 103/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6608e+00
Epoch 104/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6620e+00
Epoch 105/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6612e+00
Epoch 106/200
 - 14s - loss: -3.6221e+00 - val_loss: -3.6552e+00
Epoch 107/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6614e+00
Epoch 108/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6621e+00
Epoch 109/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6058e+00
Epoch 110/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6628e+00
Epoch 111/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6629e+00
Epoch 112/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6625e+00
Epoch 113/200
 - 14s - loss: -3.6260e+00 - val_loss: -3.6631e+00
Epoch 114/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6632e+00
Epoch 115/200
 - 14s - loss: -3.6239e+00 - val_loss: -3.6627e+00
Epoch 116/200
 - 14s - loss: -3.6264e+00 - val_loss: -3.6636e+00
Epoch 117/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6641e+00
Epoch 118/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6643e+00
Epoch 119/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6481e+00
Epoch 120/200
 - 14s - loss: -3.6254e+00 - val_loss: -3.6629e+00
Epoch 121/200
 - 14s - loss: -3.6240e+00 - val_loss: -3.6563e+00
2019-12-22 15:46:29,030 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_120.pickle
Epoch 122/200
 - 14s - loss: -3.6256e+00 - val_loss: -3.6637e+00
Epoch 123/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6415e+00
Epoch 124/200
 - 14s - loss: -3.6250e+00 - val_loss: -3.6638e+00
Epoch 125/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6539e+00
Epoch 126/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6640e+00
Epoch 127/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6635e+00
Epoch 128/200
 - 14s - loss: -3.6255e+00 - val_loss: -3.6637e+00
Epoch 129/200
 - 14s - loss: -3.6258e+00 - val_loss: -3.6633e+00
Epoch 130/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6468e+00
Epoch 131/200
 - 14s - loss: -3.6249e+00 - val_loss: -3.6642e+00
Epoch 132/200
 - 14s - loss: -3.6251e+00 - val_loss: -3.6640e+00
Epoch 133/200
 - 14s - loss: -3.6263e+00 - val_loss: -3.6633e+00
Epoch 134/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6641e+00
Epoch 135/200
 - 14s - loss: -3.6250e+00 - val_loss: -3.6555e+00
Epoch 136/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6627e+00
Epoch 137/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6635e+00
Epoch 138/200
 - 14s - loss: -3.6241e+00 - val_loss: -3.6631e+00
Epoch 139/200
 - 14s - loss: -3.6253e+00 - val_loss: -3.6644e+00
Epoch 140/200
 - 14s - loss: -3.6235e+00 - val_loss: -3.6623e+00
Epoch 141/200
 - 14s - loss: -3.6242e+00 - val_loss: -3.6635e+00
2019-12-22 15:51:02,513 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_140.pickle
Epoch 142/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6561e+00
Epoch 143/200
 - 14s - loss: -3.6258e+00 - val_loss: -3.6631e+00
Epoch 144/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6634e+00
Epoch 145/200
 - 14s - loss: -3.6243e+00 - val_loss: -3.6633e+00
Epoch 146/200
 - 14s - loss: -3.6233e+00 - val_loss: -3.6615e+00
Epoch 147/200
 - 14s - loss: -3.6251e+00 - val_loss: -3.6600e+00
Epoch 148/200
 - 14s - loss: -3.6251e+00 - val_loss: -3.6633e+00
Epoch 149/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6638e+00
Epoch 150/200
 - 14s - loss: -3.6256e+00 - val_loss: -3.6630e+00
Epoch 151/200
 - 14s - loss: -3.6255e+00 - val_loss: -3.6632e+00
Epoch 152/200
 - 14s - loss: -3.6256e+00 - val_loss: -3.6631e+00
Epoch 153/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6410e+00
Epoch 154/200
 - 14s - loss: -3.6243e+00 - val_loss: -3.6458e+00
Epoch 155/200
 - 14s - loss: -3.6262e+00 - val_loss: -3.6638e+00
Epoch 156/200
 - 14s - loss: -3.6264e+00 - val_loss: -3.6638e+00
Epoch 157/200
 - 14s - loss: -3.6251e+00 - val_loss: -3.6634e+00
Epoch 158/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6629e+00
Epoch 159/200
 - 14s - loss: -3.6262e+00 - val_loss: -3.6629e+00
Epoch 160/200
 - 14s - loss: -3.6260e+00 - val_loss: -3.6632e+00
Epoch 161/200
 - 14s - loss: -3.6252e+00 - val_loss: -3.6479e+00
2019-12-22 15:55:36,360 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_160.pickle
Epoch 162/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6633e+00
Epoch 163/200
 - 14s - loss: -3.6261e+00 - val_loss: -3.6410e+00
Epoch 164/200
 - 14s - loss: -3.6260e+00 - val_loss: -3.6624e+00
Epoch 165/200
 - 14s - loss: -3.6247e+00 - val_loss: -3.6643e+00
Epoch 166/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6630e+00
Epoch 167/200
 - 14s - loss: -3.6251e+00 - val_loss: -3.6117e+00
Epoch 168/200
 - 14s - loss: -3.6268e+00 - val_loss: -3.6477e+00
Epoch 169/200
 - 14s - loss: -3.6274e+00 - val_loss: -3.6435e+00
Epoch 170/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6555e+00
Epoch 171/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6559e+00
Epoch 172/200
 - 14s - loss: -3.6230e+00 - val_loss: -3.6537e+00
Epoch 173/200
 - 14s - loss: -3.6248e+00 - val_loss: -3.6635e+00
Epoch 174/200
 - 14s - loss: -3.6258e+00 - val_loss: -3.6537e+00
Epoch 175/200
 - 14s - loss: -3.6269e+00 - val_loss: -3.6634e+00
Epoch 176/200
 - 14s - loss: -3.6267e+00 - val_loss: -3.6640e+00
Epoch 177/200
 - 14s - loss: -3.6266e+00 - val_loss: -3.6636e+00
Epoch 178/200
 - 14s - loss: -3.6237e+00 - val_loss: -3.6639e+00
Epoch 179/200
 - 14s - loss: -3.6255e+00 - val_loss: -3.6640e+00
Epoch 180/200
 - 14s - loss: -3.6252e+00 - val_loss: -3.6638e+00
Epoch 181/200
 - 14s - loss: -3.6266e+00 - val_loss: -3.6645e+00
2019-12-22 16:00:10,174 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ae_model_epoch_180.pickle
Epoch 182/200
 - 14s - loss: -3.6267e+00 - val_loss: -3.6641e+00
Epoch 183/200
 - 14s - loss: -3.6260e+00 - val_loss: -3.6562e+00
Epoch 184/200
 - 14s - loss: -3.6248e+00 - val_loss: -3.6492e+00
Epoch 185/200
 - 14s - loss: -3.6267e+00 - val_loss: -3.6412e+00
Epoch 186/200
 - 14s - loss: -3.6264e+00 - val_loss: -3.6632e+00
Epoch 187/200
 - 14s - loss: -3.6269e+00 - val_loss: -3.6398e+00
Epoch 188/200
 - 14s - loss: -3.6265e+00 - val_loss: -3.6604e+00
Epoch 189/200
 - 14s - loss: -3.6271e+00 - val_loss: -3.6556e+00
Epoch 190/200
 - 14s - loss: -3.6276e+00 - val_loss: -3.6633e+00
Epoch 191/200
 - 14s - loss: -3.6259e+00 - val_loss: -3.6474e+00
Epoch 192/200
 - 14s - loss: -3.6280e+00 - val_loss: -3.6645e+00
Epoch 193/200
 - 14s - loss: -3.6261e+00 - val_loss: -3.6598e+00
Epoch 194/200
 - 14s - loss: -3.6236e+00 - val_loss: -3.6615e+00
Epoch 195/200
 - 14s - loss: -3.6259e+00 - val_loss: -3.6607e+00
Epoch 196/200
 - 14s - loss: -3.6262e+00 - val_loss: -3.6639e+00
Epoch 197/200
 - 14s - loss: -3.6255e+00 - val_loss: -3.6642e+00
Epoch 198/200
 - 14s - loss: -3.6259e+00 - val_loss: -3.6626e+00
Epoch 199/200
 - 14s - loss: -3.6275e+00 - val_loss: -3.6637e+00
Epoch 200/200
 - 14s - loss: -3.6243e+00 - val_loss: -3.6495e+00
2019-12-22 16:04:30,476 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 16:04:52,198 [INFO] Last epoch loss evaluation: train_loss = -3.664904, val_loss = -3.664516
2019-12-22 16:04:52,198 [INFO] Training autoencoder complete
2019-12-22 16:04:52,198 [INFO] Encoding data for supervised training
2019-12-22 16:05:09,028 [INFO] Encoding complete
2019-12-22 16:05:09,029 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 7s - loss: 0.0239 - val_loss: 0.0092
 - val_f1: 0.9788
Epoch 2/200
 - 6s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 3/200
 - 6s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9823
Epoch 4/200
 - 6s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 5/200
 - 6s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 6/200
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 7/200
 - 6s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 8/200
 - 6s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9806
Epoch 9/200
 - 6s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 10/200
 - 6s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 11/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 12/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 13/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 14/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 15/200
 - 6s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 16/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 17/200
 - 6s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 18/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 19/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 20/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 21/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
2019-12-22 16:09:53,192 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9830
Epoch 22/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 23/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 24/200
 - 6s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9816
Epoch 25/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 26/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 27/200
 - 6s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9817
Epoch 28/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 29/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 30/200
 - 6s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 31/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 32/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 33/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 34/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 35/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 36/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 37/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 38/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 39/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 40/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 41/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
2019-12-22 16:14:30,365 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9833
Epoch 42/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9813
Epoch 43/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 44/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 45/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 46/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 47/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 48/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9813
Epoch 49/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 50/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 51/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 52/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 53/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 54/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 55/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 56/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 57/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 58/200
 - 6s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9822
Epoch 59/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 60/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 61/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
2019-12-22 16:19:07,212 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9832
Epoch 62/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 63/200
 - 6s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 64/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 65/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 66/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 67/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9817
Epoch 68/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 69/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 70/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9818
Epoch 71/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 72/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 73/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 74/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 75/200
 - 6s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 76/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 77/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 78/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 79/200
 - 6s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 80/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 81/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
2019-12-22 16:23:44,267 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9822
Epoch 82/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 83/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 84/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 85/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 86/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 87/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 88/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 89/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 90/200
 - 6s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 91/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 92/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 93/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 94/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 95/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 96/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 97/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 98/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 99/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 100/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 101/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 16:28:21,215 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9833
Epoch 102/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 103/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 104/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 105/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 106/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 107/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 108/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 109/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 110/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 111/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 112/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 113/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 114/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 115/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 116/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 117/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 118/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 119/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 120/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 121/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 16:32:57,884 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9834
Epoch 122/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 123/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 124/200
 - 6s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 125/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 126/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 127/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 128/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 129/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 130/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 131/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 132/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 133/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 134/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 135/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 136/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 137/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 138/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 139/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 140/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 141/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 16:37:34,876 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9836
Epoch 142/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 143/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 144/200
 - 6s - loss: 0.0082 - val_loss: 0.0087
 - val_f1: 0.9810
Epoch 145/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 146/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 147/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 148/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 149/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 150/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9820
Epoch 151/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 152/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 153/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 154/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 155/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 156/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 157/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 158/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 159/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 160/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 161/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 16:42:11,873 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9834
Epoch 162/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 163/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 164/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 165/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 166/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 167/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 168/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 169/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 170/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 171/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 172/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 173/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 174/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 175/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 176/200
 - 6s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 177/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 178/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 179/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 180/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 181/200
 - 6s - loss: 0.0082 - val_loss: 0.0081
2019-12-22 16:46:49,672 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9829
Epoch 182/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9819
Epoch 183/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 184/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 185/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 186/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 187/200
 - 6s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 188/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 189/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 190/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 191/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 192/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 193/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 194/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 195/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 196/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 197/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 198/200
 - 6s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 199/200
 - 6s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 200/200
 - 6s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 16:51:19,939 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 16:51:40,620 [INFO] Last epoch loss evaluation: train_loss = 0.007861, val_loss = 0.007880
2019-12-22 16:51:40,660 [INFO] Training complete. time_to_train = 5592.17 sec, 93.20 min
2019-12-22 16:51:40,668 [INFO] Model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/best_model.pickle
2019-12-22 16:51:40,860 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/training_error_history.png
2019-12-22 16:51:41,035 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/training_f1_history.png
2019-12-22 16:51:41,035 [INFO] Making predictions on training, validation, testing data
2019-12-22 16:52:50,640 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 16:53:02,642 [INFO] Dataset: Testing. Classification report below
2019-12-22 16:53:02,643 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.08      0.15        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.56      5596
   DoS attacks-Slowloris       0.95      0.96      0.96       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.42      0.00      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.76      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 16:53:02,643 [INFO] Overall accuracy (micro avg): 0.9831786183476687
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-22 16:53:16,292 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7642                       0.6914                0.0044                   0.3086  0.6838
2  Weighted avg        0.9910         0.9777                       0.9832                0.0497                   0.0168  0.9780
2019-12-22 16:53:28,332 [INFO] Dataset: Validation. Classification report below
2019-12-22 16:53:28,332 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.08      0.15        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.45      0.56      5596
   DoS attacks-Slowloris       0.93      0.96      0.94       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.51      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.69      0.69    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 16:53:28,332 [INFO] Overall accuracy (micro avg): 0.9832715453603248
2019-12-22 16:53:41,987 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7725                       0.6904                0.0044                   0.3096  0.6851
2  Weighted avg        0.9910         0.9787                       0.9833                0.0494                   0.0167  0.9781
2019-12-22 16:54:21,141 [INFO] Dataset: Training. Classification report below
2019-12-22 16:54:21,142 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.92      0.15      0.26        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.45      0.56     16787
   DoS attacks-Slowloris       0.95      0.98      0.96      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.48      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.76      0.70      0.69   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 16:54:21,142 [INFO] Overall accuracy (micro avg): 0.9832395368460626
2019-12-22 16:55:05,612 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.7644                       0.6957                0.0044                   0.3043  0.6922
2  Weighted avg        0.9910         0.9784                       0.9832                0.0494                   0.0168  0.9781
2019-12-22 16:55:05,670 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep3/selected_ids18_subset_ae_ann_shallow_rep3_results.xlsx
2019-12-22 16:55:05,675 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-22 16:55:05,753 [INFO] Created directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4
2019-12-22 16:55:05,753 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/run_log.log
2019-12-22 16:55:05,753 [INFO] ================= Running experiment no. 4  ================= 

2019-12-22 16:55:05,753 [INFO] Experiment parameters given below
2019-12-22 16:55:05,753 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ae_ann_shallow_rep4'}
2019-12-22 16:55:05,753 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/tf_logs_run_2019_12_22-16_55_05
2019-12-22 16:55:05,754 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 16:55:05,754 [INFO] Reading X, y files
2019-12-22 16:55:05,754 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 16:55:10,085 [INFO] Reading complete. time_to_read=4.33 seconds
2019-12-22 16:55:10,085 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 16:55:11,576 [INFO] Reading complete. time_to_read=1.49 seconds
2019-12-22 16:55:11,576 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 16:55:13,070 [INFO] Reading complete. time_to_read=1.49 seconds
2019-12-22 16:55:13,070 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 16:55:13,320 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-22 16:55:13,321 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 16:55:13,398 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 16:55:13,398 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 16:55:13,477 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 16:55:17,092 [INFO] Initializing model
2019-12-22 16:55:17,201 [INFO] _________________________________________________________________
2019-12-22 16:55:17,201 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 16:55:17,201 [INFO] =================================================================
2019-12-22 16:55:17,201 [INFO] dense_13 (Dense)             (None, 32)                2496      
2019-12-22 16:55:17,201 [INFO] _________________________________________________________________
2019-12-22 16:55:17,201 [INFO] batch_normalization_7 (Batch (None, 32)                128       
2019-12-22 16:55:17,201 [INFO] _________________________________________________________________
2019-12-22 16:55:17,202 [INFO] dropout_7 (Dropout)          (None, 32)                0         
2019-12-22 16:55:17,202 [INFO] _________________________________________________________________
2019-12-22 16:55:17,202 [INFO] dense_14 (Dense)             (None, 77)                2541      
2019-12-22 16:55:17,202 [INFO] =================================================================
2019-12-22 16:55:17,202 [INFO] Total params: 5,165
2019-12-22 16:55:17,202 [INFO] Trainable params: 5,101
2019-12-22 16:55:17,202 [INFO] Non-trainable params: 64
2019-12-22 16:55:17,202 [INFO] _________________________________________________________________
2019-12-22 16:55:17,307 [INFO] _________________________________________________________________
2019-12-22 16:55:17,307 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 16:55:17,307 [INFO] =================================================================
2019-12-22 16:55:17,307 [INFO] dense_15 (Dense)             (None, 32)                1056      
2019-12-22 16:55:17,307 [INFO] _________________________________________________________________
2019-12-22 16:55:17,308 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-22 16:55:17,308 [INFO] _________________________________________________________________
2019-12-22 16:55:17,308 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-22 16:55:17,308 [INFO] _________________________________________________________________
2019-12-22 16:55:17,308 [INFO] dense_16 (Dense)             (None, 15)                495       
2019-12-22 16:55:17,308 [INFO] =================================================================
2019-12-22 16:55:17,308 [INFO] Total params: 1,679
2019-12-22 16:55:17,308 [INFO] Trainable params: 1,615
2019-12-22 16:55:17,308 [INFO] Non-trainable params: 64
2019-12-22 16:55:17,308 [INFO] _________________________________________________________________
2019-12-22 16:55:17,308 [INFO] Training model
2019-12-22 16:55:17,308 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-22 16:55:37,615 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 9ef96dce85a4baa28d8dd2abae0dcd58bd80537a
2019-12-22 16:55:37,615 [INFO] Training autoencoder
 - val_f1: 0.9834
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 15s - loss: -3.0295e+00 - val_loss: -3.6227e+00
Epoch 2/200
 - 14s - loss: -3.5564e+00 - val_loss: -3.6403e+00
Epoch 3/200
 - 14s - loss: -3.5748e+00 - val_loss: -3.6396e+00
Epoch 4/200
 - 14s - loss: -3.5835e+00 - val_loss: -3.4353e+00
Epoch 5/200
 - 14s - loss: -3.5894e+00 - val_loss: -3.6489e+00
Epoch 6/200
 - 14s - loss: -3.5914e+00 - val_loss: -3.6501e+00
Epoch 7/200
 - 14s - loss: -3.5939e+00 - val_loss: -3.6512e+00
Epoch 8/200
 - 14s - loss: -3.5959e+00 - val_loss: -3.6520e+00
Epoch 9/200
 - 14s - loss: -3.5974e+00 - val_loss: -3.6517e+00
Epoch 10/200
 - 14s - loss: -3.5988e+00 - val_loss: -3.6532e+00
Epoch 11/200
 - 14s - loss: -3.6014e+00 - val_loss: -3.6547e+00
Epoch 12/200
 - 14s - loss: -3.6022e+00 - val_loss: -3.6499e+00
Epoch 13/200
 - 14s - loss: -3.6035e+00 - val_loss: -3.6528e+00
Epoch 14/200
 - 14s - loss: -3.6046e+00 - val_loss: -3.6556e+00
Epoch 15/200
 - 14s - loss: -3.6055e+00 - val_loss: -3.6559e+00
Epoch 16/200
 - 14s - loss: -3.6067e+00 - val_loss: -3.6570e+00
Epoch 17/200
 - 14s - loss: -3.6070e+00 - val_loss: -3.6571e+00
Epoch 18/200
 - 14s - loss: -3.6081e+00 - val_loss: -3.6554e+00
Epoch 19/200
 - 14s - loss: -3.6083e+00 - val_loss: -3.6572e+00
Epoch 20/200
 - 14s - loss: -3.6090e+00 - val_loss: -3.3078e+00
Epoch 21/200
 - 14s - loss: -3.6099e+00 - val_loss: -3.6584e+00
2019-12-22 17:00:41,374 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_20.pickle
Epoch 22/200
 - 14s - loss: -3.6097e+00 - val_loss: -3.6529e+00
Epoch 23/200
 - 14s - loss: -3.6109e+00 - val_loss: -3.5862e+00
Epoch 24/200
 - 14s - loss: -3.6120e+00 - val_loss: -3.6586e+00
Epoch 25/200
 - 14s - loss: -3.6117e+00 - val_loss: -3.6591e+00
Epoch 26/200
 - 14s - loss: -3.6121e+00 - val_loss: -3.6400e+00
Epoch 27/200
 - 14s - loss: -3.6135e+00 - val_loss: -3.6598e+00
Epoch 28/200
 - 14s - loss: -3.6120e+00 - val_loss: -3.6556e+00
Epoch 29/200
 - 14s - loss: -3.6134e+00 - val_loss: -3.6597e+00
Epoch 30/200
 - 14s - loss: -3.6138e+00 - val_loss: -3.6583e+00
Epoch 31/200
 - 14s - loss: -3.6131e+00 - val_loss: -3.6598e+00
Epoch 32/200
 - 14s - loss: -3.6127e+00 - val_loss: -3.4046e+00
Epoch 33/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6601e+00
Epoch 34/200
 - 14s - loss: -3.6142e+00 - val_loss: -3.6590e+00
Epoch 35/200
 - 14s - loss: -3.6139e+00 - val_loss: -3.6599e+00
Epoch 36/200
 - 14s - loss: -3.6139e+00 - val_loss: -3.6598e+00
Epoch 37/200
 - 14s - loss: -3.6126e+00 - val_loss: -3.3361e+00
Epoch 38/200
 - 14s - loss: -3.6136e+00 - val_loss: -3.6595e+00
Epoch 39/200
 - 14s - loss: -3.6128e+00 - val_loss: -3.6596e+00
Epoch 40/200
 - 14s - loss: -3.6137e+00 - val_loss: -3.6594e+00
Epoch 41/200
 - 14s - loss: -3.6137e+00 - val_loss: -3.2984e+00
2019-12-22 17:05:26,822 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_40.pickle
Epoch 42/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6592e+00
Epoch 43/200
 - 14s - loss: -3.6146e+00 - val_loss: -3.6552e+00
Epoch 44/200
 - 14s - loss: -3.6148e+00 - val_loss: -3.6343e+00
Epoch 45/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6571e+00
Epoch 46/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6589e+00
Epoch 47/200
 - 14s - loss: -3.6138e+00 - val_loss: -3.6593e+00
Epoch 48/200
 - 14s - loss: -3.6149e+00 - val_loss: -3.6597e+00
Epoch 49/200
 - 14s - loss: -3.6148e+00 - val_loss: -3.6593e+00
Epoch 50/200
 - 14s - loss: -3.6151e+00 - val_loss: -3.6013e+00
Epoch 51/200
 - 14s - loss: -3.6156e+00 - val_loss: -3.6554e+00
Epoch 52/200
 - 14s - loss: -3.6153e+00 - val_loss: -3.6598e+00
Epoch 53/200
 - 14s - loss: -3.6145e+00 - val_loss: -3.6600e+00
Epoch 54/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6603e+00
Epoch 55/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6595e+00
Epoch 56/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6604e+00
Epoch 57/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.5246e+00
Epoch 58/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6597e+00
Epoch 59/200
 - 14s - loss: -3.6163e+00 - val_loss: -3.6596e+00
Epoch 60/200
 - 14s - loss: -3.6168e+00 - val_loss: -3.6535e+00
Epoch 61/200
 - 14s - loss: -3.6160e+00 - val_loss: -3.6609e+00
2019-12-22 17:10:12,430 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_60.pickle
Epoch 62/200
 - 14s - loss: -3.6151e+00 - val_loss: -3.6610e+00
Epoch 63/200
 - 14s - loss: -3.6160e+00 - val_loss: -3.3232e+00
Epoch 64/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6615e+00
Epoch 65/200
 - 14s - loss: -3.6162e+00 - val_loss: -3.5812e+00
Epoch 66/200
 - 14s - loss: -3.6164e+00 - val_loss: -3.6520e+00
Epoch 67/200
 - 14s - loss: -3.6163e+00 - val_loss: -3.6611e+00
Epoch 68/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6617e+00
Epoch 69/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6615e+00
Epoch 70/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.6613e+00
Epoch 71/200
 - 14s - loss: -3.6166e+00 - val_loss: -3.5534e+00
Epoch 72/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6619e+00
Epoch 73/200
 - 14s - loss: -3.6168e+00 - val_loss: -3.6612e+00
Epoch 74/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6493e+00
Epoch 75/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6618e+00
Epoch 76/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6610e+00
Epoch 77/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6623e+00
Epoch 78/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6623e+00
Epoch 79/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6627e+00
Epoch 80/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6616e+00
Epoch 81/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6630e+00
2019-12-22 17:14:57,363 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_80.pickle
Epoch 82/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6553e+00
Epoch 83/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6579e+00
Epoch 84/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6621e+00
Epoch 85/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6270e+00
Epoch 86/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6638e+00
Epoch 87/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6632e+00
Epoch 88/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6636e+00
Epoch 89/200
 - 14s - loss: -3.6194e+00 - val_loss: -3.6624e+00
Epoch 90/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6638e+00
Epoch 91/200
 - 14s - loss: -3.6175e+00 - val_loss: -3.6634e+00
Epoch 92/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6630e+00
Epoch 93/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6633e+00
Epoch 94/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6396e+00
Epoch 95/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6508e+00
Epoch 96/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6497e+00
Epoch 97/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6636e+00
Epoch 98/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6539e+00
Epoch 99/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6636e+00
Epoch 100/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6643e+00
Epoch 101/200
 - 14s - loss: -3.6195e+00 - val_loss: -3.6639e+00
2019-12-22 17:19:42,435 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_100.pickle
Epoch 102/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6639e+00
Epoch 103/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6372e+00
Epoch 104/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6636e+00
Epoch 105/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.5973e+00
Epoch 106/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6639e+00
Epoch 107/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6645e+00
Epoch 108/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6580e+00
Epoch 109/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6632e+00
Epoch 110/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6605e+00
Epoch 111/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6629e+00
Epoch 112/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6631e+00
Epoch 113/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6635e+00
Epoch 114/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6637e+00
Epoch 115/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.6633e+00
Epoch 116/200
 - 14s - loss: -3.6203e+00 - val_loss: -3.6645e+00
Epoch 117/200
 - 14s - loss: -3.6208e+00 - val_loss: -3.6107e+00
Epoch 118/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6634e+00
Epoch 119/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6638e+00
Epoch 120/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6337e+00
Epoch 121/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6109e+00
2019-12-22 17:24:28,136 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_120.pickle
Epoch 122/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6036e+00
Epoch 123/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6641e+00
Epoch 124/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.5505e+00
Epoch 125/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6639e+00
Epoch 126/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.6617e+00
Epoch 127/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6139e+00
Epoch 128/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6641e+00
Epoch 129/200
 - 14s - loss: -3.6204e+00 - val_loss: -3.6642e+00
Epoch 130/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6641e+00
Epoch 131/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6617e+00
Epoch 132/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6630e+00
Epoch 133/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6050e+00
Epoch 134/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6525e+00
Epoch 135/200
 - 14s - loss: -3.6222e+00 - val_loss: -3.6635e+00
Epoch 136/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6318e+00
Epoch 137/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6142e+00
Epoch 138/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6629e+00
Epoch 139/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6641e+00
Epoch 140/200
 - 14s - loss: -3.6199e+00 - val_loss: -3.6641e+00
Epoch 141/200
 - 14s - loss: -3.6181e+00 - val_loss: -3.6629e+00
2019-12-22 17:29:14,335 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_140.pickle
Epoch 142/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6619e+00
Epoch 143/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6644e+00
Epoch 144/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6591e+00
Epoch 145/200
 - 14s - loss: -3.6198e+00 - val_loss: -3.6638e+00
Epoch 146/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6646e+00
Epoch 147/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.5977e+00
Epoch 148/200
 - 14s - loss: -3.6216e+00 - val_loss: -3.6640e+00
Epoch 149/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6609e+00
Epoch 150/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6397e+00
Epoch 151/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6634e+00
Epoch 152/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6371e+00
Epoch 153/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6646e+00
Epoch 154/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6558e+00
Epoch 155/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6641e+00
Epoch 156/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6635e+00
Epoch 157/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6631e+00
Epoch 158/200
 - 14s - loss: -3.6205e+00 - val_loss: -3.6637e+00
Epoch 159/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.6634e+00
Epoch 160/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6631e+00
Epoch 161/200
 - 14s - loss: -3.6196e+00 - val_loss: -3.6633e+00
2019-12-22 17:33:59,556 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_160.pickle
Epoch 162/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6185e+00
Epoch 163/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6448e+00
Epoch 164/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6635e+00
Epoch 165/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6601e+00
Epoch 166/200
 - 14s - loss: -3.6200e+00 - val_loss: -3.6637e+00
Epoch 167/200
 - 14s - loss: -3.6207e+00 - val_loss: -3.5886e+00
Epoch 168/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6638e+00
Epoch 169/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6638e+00
Epoch 170/200
 - 14s - loss: -3.6226e+00 - val_loss: -3.6639e+00
Epoch 171/200
 - 14s - loss: -3.6206e+00 - val_loss: -3.5456e+00
Epoch 172/200
 - 14s - loss: -3.6211e+00 - val_loss: -3.6647e+00
Epoch 173/200
 - 14s - loss: -3.6224e+00 - val_loss: -3.6639e+00
Epoch 174/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6629e+00
Epoch 175/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6643e+00
Epoch 176/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.5679e+00
Epoch 177/200
 - 14s - loss: -3.6201e+00 - val_loss: -3.6637e+00
Epoch 178/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6636e+00
Epoch 179/200
 - 14s - loss: -3.6231e+00 - val_loss: -3.6617e+00
Epoch 180/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.5927e+00
Epoch 181/200
 - 14s - loss: -3.6229e+00 - val_loss: -3.6630e+00
2019-12-22 17:38:44,853 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ae_model_epoch_180.pickle
Epoch 182/200
 - 14s - loss: -3.6220e+00 - val_loss: -3.5001e+00
Epoch 183/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6643e+00
Epoch 184/200
 - 14s - loss: -3.6225e+00 - val_loss: -3.6633e+00
Epoch 185/200
 - 14s - loss: -3.6198e+00 - val_loss: -3.6621e+00
Epoch 186/200
 - 14s - loss: -3.6193e+00 - val_loss: -3.6634e+00
Epoch 187/200
 - 14s - loss: -3.6213e+00 - val_loss: -3.6447e+00
Epoch 188/200
 - 14s - loss: -3.6198e+00 - val_loss: -3.6623e+00
Epoch 189/200
 - 14s - loss: -3.6209e+00 - val_loss: -3.6635e+00
Epoch 190/200
 - 14s - loss: -3.6217e+00 - val_loss: -3.6251e+00
Epoch 191/200
 - 14s - loss: -3.6214e+00 - val_loss: -3.6640e+00
Epoch 192/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6633e+00
Epoch 193/200
 - 14s - loss: -3.6219e+00 - val_loss: -3.6641e+00
Epoch 194/200
 - 14s - loss: -3.6223e+00 - val_loss: -3.6638e+00
Epoch 195/200
 - 14s - loss: -3.6228e+00 - val_loss: -3.6636e+00
Epoch 196/200
 - 14s - loss: -3.6202e+00 - val_loss: -3.6635e+00
Epoch 197/200
 - 14s - loss: -3.6218e+00 - val_loss: -3.6633e+00
Epoch 198/200
 - 14s - loss: -3.6212e+00 - val_loss: -3.6640e+00
Epoch 199/200
 - 14s - loss: -3.6210e+00 - val_loss: -3.6644e+00
Epoch 200/200
 - 14s - loss: -3.6215e+00 - val_loss: -3.6629e+00
2019-12-22 17:43:16,467 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 17:43:40,674 [INFO] Last epoch loss evaluation: train_loss = -3.659115, val_loss = -3.664722
2019-12-22 17:43:40,675 [INFO] Training autoencoder complete
2019-12-22 17:43:40,675 [INFO] Encoding data for supervised training
2019-12-22 17:43:59,048 [INFO] Encoding complete
2019-12-22 17:43:59,048 [INFO] Training neural network layers (after autoencoder)
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 7s - loss: 0.0231 - val_loss: 0.0091
 - val_f1: 0.9818
Epoch 2/200
 - 7s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 3/200
 - 7s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9821
Epoch 4/200
 - 7s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9824
Epoch 5/200
 - 7s - loss: 0.0088 - val_loss: 0.0088
 - val_f1: 0.9823
Epoch 6/200
 - 7s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 7/200
 - 7s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 8/200
 - 7s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 9/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 10/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 11/200
 - 7s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9821
Epoch 12/200
 - 7s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 13/200
 - 7s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 14/200
 - 7s - loss: 0.0085 - val_loss: 0.0147
 - val_f1: 0.9689
Epoch 15/200
 - 7s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9810
Epoch 16/200
 - 7s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 17/200
 - 7s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9821
Epoch 18/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 19/200
 - 7s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9811
Epoch 20/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 21/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
2019-12-22 17:49:05,346 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_20.pickle
 - val_f1: 0.9810
Epoch 22/200
 - 7s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9805
Epoch 23/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9812
Epoch 24/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 25/200
 - 7s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9813
Epoch 26/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 27/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 28/200
 - 7s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9810
Epoch 29/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 30/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 31/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 32/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 33/200
 - 7s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 34/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 35/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 36/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 37/200
 - 7s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 38/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 39/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 40/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 41/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
2019-12-22 17:54:03,769 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_40.pickle
 - val_f1: 0.9831
Epoch 42/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 43/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 44/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 45/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 46/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9827
Epoch 47/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 48/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9811
Epoch 49/200
 - 7s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9809
Epoch 50/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 51/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9828
Epoch 52/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 53/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 54/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 55/200
 - 7s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 56/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 57/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 58/200
 - 7s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 59/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 60/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 61/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 17:59:01,856 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9832
Epoch 62/200
 - 7s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 63/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 64/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 65/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 66/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 67/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 68/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 69/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 70/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 71/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 72/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 73/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 74/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 75/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 76/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 77/200
 - 7s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 78/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 79/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 80/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 81/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
2019-12-22 18:04:00,703 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_80.pickle
 - val_f1: 0.9833
Epoch 82/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 83/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 84/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 85/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 86/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 87/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9812
Epoch 88/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 89/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9813
Epoch 90/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9816
Epoch 91/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9816
Epoch 92/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 93/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9815
Epoch 94/200
 - 7s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 95/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 96/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 97/200
 - 7s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 98/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 99/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 100/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 101/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 18:08:59,650 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_100.pickle
 - val_f1: 0.9830
Epoch 102/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 103/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 104/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 105/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 106/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 107/200
 - 7s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 108/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 109/200
 - 7s - loss: 0.0082 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 110/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 111/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 112/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 113/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 114/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 115/200
 - 7s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 116/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 117/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 118/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 119/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 120/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 121/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 18:13:59,101 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9834
Epoch 122/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9828
Epoch 123/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 124/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 125/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 126/200
 - 7s - loss: 0.0082 - val_loss: 0.0084
 - val_f1: 0.9826
Epoch 127/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 128/200
 - 7s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 129/200
 - 7s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 130/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 131/200
 - 7s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 132/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9814
Epoch 133/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 134/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 135/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 136/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 137/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9815
Epoch 138/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 139/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 140/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 141/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
2019-12-22 18:18:58,149 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_140.pickle
 - val_f1: 0.9830
Epoch 142/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 143/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 144/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 145/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 146/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 147/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 148/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 149/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 150/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 151/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 152/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 153/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 154/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 155/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 156/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 157/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 158/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 159/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 160/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 161/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 18:23:56,871 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_160.pickle
 - val_f1: 0.9834
Epoch 162/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 163/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 164/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 165/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9829
Epoch 166/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 167/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 168/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 169/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 170/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 171/200
 - 7s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9820
Epoch 172/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 173/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 174/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 175/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 176/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 177/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 178/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 179/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 180/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 181/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 18:28:55,058 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9830
Epoch 182/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 183/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 184/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 185/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 186/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 187/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 188/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 189/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 190/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 191/200
 - 7s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 192/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 193/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 194/200
 - 7s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 195/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 196/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 197/200
 - 7s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 198/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 199/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 200/200
 - 7s - loss: 0.0081 - val_loss: 0.0079
2019-12-22 18:33:47,488 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 18:34:10,275 [INFO] Last epoch loss evaluation: train_loss = 0.007800, val_loss = 0.007864
2019-12-22 18:34:10,315 [INFO] Training complete. time_to_train = 5933.01 sec, 98.88 min
2019-12-22 18:34:10,323 [INFO] Model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/best_model.pickle
2019-12-22 18:34:10,514 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/training_error_history.png
2019-12-22 18:34:10,695 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/training_f1_history.png
2019-12-22 18:34:10,695 [INFO] Making predictions on training, validation, testing data
2019-12-22 18:35:27,832 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 18:35:39,795 [INFO] Dataset: Testing. Classification report below
2019-12-22 18:35:39,795 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.99      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.45      0.56      5596
   DoS attacks-Slowloris       0.95      0.96      0.96       440
          FTP-BruteForce       0.69      0.88      0.78      7718
           Infilteration       0.40      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.70      0.69      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 18:35:39,795 [INFO] Overall accuracy (micro avg): 0.9832219963810327
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-22 18:35:53,409 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6971                       0.6857                0.0044                   0.3143  0.6747
2  Weighted avg        0.9910         0.9776                       0.9832                0.0496                   0.0168  0.9781
2019-12-22 18:36:05,395 [INFO] Dataset: Validation. Classification report below
2019-12-22 18:36:05,395 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.45      0.56      5596
   DoS attacks-Slowloris       0.95      0.97      0.96       439
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.36      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.70      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 18:36:05,395 [INFO] Overall accuracy (micro avg): 0.9832668977066927
2019-12-22 18:36:19,002 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.6991                       0.6862                0.0044                   0.3138  0.6771
2  Weighted avg        0.9909         0.9773                       0.9833                0.0497                   0.0167  0.9781
2019-12-22 18:36:58,172 [INFO] Dataset: Training. Classification report below
2019-12-22 18:36:58,172 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      0.98      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.45      0.56     16787
   DoS attacks-Slowloris       0.95      0.99      0.97      1318
          FTP-BruteForce       0.69      0.89      0.78     23153
           Infilteration       0.45      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.70      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 18:36:58,173 [INFO] Overall accuracy (micro avg): 0.9832860133583825
2019-12-22 18:37:42,666 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7029                       0.6871                0.0044                   0.3129  0.6765
2  Weighted avg        0.9910         0.9782                       0.9833                0.0495                   0.0167  0.9782
2019-12-22 18:37:42,723 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep4/selected_ids18_subset_ae_ann_shallow_rep4_results.xlsx
2019-12-22 18:37:42,730 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-22 18:37:42,804 [INFO] Created directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5
2019-12-22 18:37:42,804 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/run_log.log
2019-12-22 18:37:42,804 [INFO] ================= Running experiment no. 5  ================= 

2019-12-22 18:37:42,804 [INFO] Experiment parameters given below
2019-12-22 18:37:42,805 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_ae_ann_shallow_rep5'}
2019-12-22 18:37:42,805 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/tf_logs_run_2019_12_22-18_37_42
2019-12-22 18:37:42,805 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-22 18:37:42,805 [INFO] Reading X, y files
2019-12-22 18:37:42,805 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-22 18:37:47,158 [INFO] Reading complete. time_to_read=4.35 seconds
2019-12-22 18:37:47,158 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-22 18:37:48,639 [INFO] Reading complete. time_to_read=1.48 seconds
2019-12-22 18:37:48,639 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-22 18:37:50,120 [INFO] Reading complete. time_to_read=1.48 seconds
2019-12-22 18:37:50,120 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-22 18:37:50,367 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-22 18:37:50,367 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-22 18:37:50,445 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 18:37:50,445 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-22 18:37:50,524 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-22 18:37:54,134 [INFO] Initializing model
2019-12-22 18:37:54,244 [INFO] _________________________________________________________________
2019-12-22 18:37:54,244 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 18:37:54,244 [INFO] =================================================================
2019-12-22 18:37:54,245 [INFO] dense_17 (Dense)             (None, 32)                2496      
2019-12-22 18:37:54,245 [INFO] _________________________________________________________________
2019-12-22 18:37:54,245 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-22 18:37:54,245 [INFO] _________________________________________________________________
2019-12-22 18:37:54,245 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-22 18:37:54,245 [INFO] _________________________________________________________________
2019-12-22 18:37:54,245 [INFO] dense_18 (Dense)             (None, 77)                2541      
2019-12-22 18:37:54,245 [INFO] =================================================================
2019-12-22 18:37:54,245 [INFO] Total params: 5,165
2019-12-22 18:37:54,245 [INFO] Trainable params: 5,101
2019-12-22 18:37:54,245 [INFO] Non-trainable params: 64
2019-12-22 18:37:54,245 [INFO] _________________________________________________________________
2019-12-22 18:37:54,351 [INFO] _________________________________________________________________
2019-12-22 18:37:54,351 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-22 18:37:54,351 [INFO] =================================================================
2019-12-22 18:37:54,351 [INFO] dense_19 (Dense)             (None, 32)                1056      
2019-12-22 18:37:54,351 [INFO] _________________________________________________________________
2019-12-22 18:37:54,351 [INFO] batch_normalization_10 (Batc (None, 32)                128       
2019-12-22 18:37:54,351 [INFO] _________________________________________________________________
2019-12-22 18:37:54,351 [INFO] dropout_10 (Dropout)         (None, 32)                0         
2019-12-22 18:37:54,351 [INFO] _________________________________________________________________
2019-12-22 18:37:54,351 [INFO] dense_20 (Dense)             (None, 15)                495       
2019-12-22 18:37:54,351 [INFO] =================================================================
2019-12-22 18:37:54,351 [INFO] Total params: 1,679
2019-12-22 18:37:54,351 [INFO] Trainable params: 1,615
2019-12-22 18:37:54,352 [INFO] Non-trainable params: 64
2019-12-22 18:37:54,352 [INFO] _________________________________________________________________
2019-12-22 18:37:54,352 [INFO] Training model
2019-12-22 18:37:54,352 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-22 18:38:15,010 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = ecef8c74b05604674dc8c720c1080a6acb6428f0
2019-12-22 18:38:15,011 [INFO] Training autoencoder
 - val_f1: 0.9833
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 14s - loss: -3.0403e+00 - val_loss: -3.6226e+00
Epoch 2/200
 - 14s - loss: -3.5554e+00 - val_loss: -3.6376e+00
Epoch 3/200
 - 14s - loss: -3.5770e+00 - val_loss: -3.6455e+00
Epoch 4/200
 - 14s - loss: -3.5866e+00 - val_loss: -3.6495e+00
Epoch 5/200
 - 14s - loss: -3.5931e+00 - val_loss: -3.6486e+00
Epoch 6/200
 - 14s - loss: -3.5970e+00 - val_loss: -3.6518e+00
Epoch 7/200
 - 14s - loss: -3.5998e+00 - val_loss: -3.6532e+00
Epoch 8/200
 - 14s - loss: -3.6009e+00 - val_loss: -3.6533e+00
Epoch 9/200
 - 14s - loss: -3.6032e+00 - val_loss: -3.6545e+00
Epoch 10/200
 - 14s - loss: -3.6044e+00 - val_loss: -3.6547e+00
Epoch 11/200
 - 14s - loss: -3.6063e+00 - val_loss: -3.6562e+00
Epoch 12/200
 - 14s - loss: -3.6072e+00 - val_loss: -3.6564e+00
Epoch 13/200
 - 14s - loss: -3.6075e+00 - val_loss: -3.6566e+00
Epoch 14/200
 - 14s - loss: -3.6084e+00 - val_loss: -3.6576e+00
Epoch 15/200
 - 14s - loss: -3.6093e+00 - val_loss: -3.6561e+00
Epoch 16/200
 - 14s - loss: -3.6094e+00 - val_loss: -3.6571e+00
Epoch 17/200
 - 14s - loss: -3.6097e+00 - val_loss: -3.6570e+00
Epoch 18/200
 - 14s - loss: -3.6103e+00 - val_loss: -3.6577e+00
Epoch 19/200
 - 14s - loss: -3.6107e+00 - val_loss: -3.6576e+00
Epoch 20/200
 - 14s - loss: -3.6112e+00 - val_loss: -3.6578e+00
Epoch 21/200
 - 14s - loss: -3.6112e+00 - val_loss: -3.6573e+00
2019-12-22 18:43:13,000 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_20.pickle
Epoch 22/200
 - 14s - loss: -3.6117e+00 - val_loss: -3.6586e+00
Epoch 23/200
 - 14s - loss: -3.6119e+00 - val_loss: -3.6563e+00
Epoch 24/200
 - 14s - loss: -3.6126e+00 - val_loss: -3.6595e+00
Epoch 25/200
 - 14s - loss: -3.6131e+00 - val_loss: -3.6591e+00
Epoch 26/200
 - 14s - loss: -3.6130e+00 - val_loss: -3.6583e+00
Epoch 27/200
 - 14s - loss: -3.6133e+00 - val_loss: -3.6583e+00
Epoch 28/200
 - 14s - loss: -3.6139e+00 - val_loss: -3.6560e+00
Epoch 29/200
 - 14s - loss: -3.6126e+00 - val_loss: -3.6586e+00
Epoch 30/200
 - 14s - loss: -3.6142e+00 - val_loss: -3.6584e+00
Epoch 31/200
 - 14s - loss: -3.6140e+00 - val_loss: -3.6587e+00
Epoch 32/200
 - 14s - loss: -3.6145e+00 - val_loss: -3.6589e+00
Epoch 33/200
 - 14s - loss: -3.6143e+00 - val_loss: -3.6583e+00
Epoch 34/200
 - 14s - loss: -3.6145e+00 - val_loss: -3.6589e+00
Epoch 35/200
 - 14s - loss: -3.6145e+00 - val_loss: -3.6582e+00
Epoch 36/200
 - 14s - loss: -3.6147e+00 - val_loss: -3.6590e+00
Epoch 37/200
 - 14s - loss: -3.6149e+00 - val_loss: -3.6583e+00
Epoch 38/200
 - 14s - loss: -3.6151e+00 - val_loss: -3.6588e+00
Epoch 39/200
 - 14s - loss: -3.6150e+00 - val_loss: -3.6576e+00
Epoch 40/200
 - 14s - loss: -3.6152e+00 - val_loss: -3.6590e+00
Epoch 41/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6598e+00
2019-12-22 18:47:55,844 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_40.pickle
Epoch 42/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6595e+00
Epoch 43/200
 - 14s - loss: -3.6157e+00 - val_loss: -3.6593e+00
Epoch 44/200
 - 14s - loss: -3.6160e+00 - val_loss: -3.6596e+00
Epoch 45/200
 - 14s - loss: -3.6154e+00 - val_loss: -3.6591e+00
Epoch 46/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6591e+00
Epoch 47/200
 - 14s - loss: -3.6157e+00 - val_loss: -3.6599e+00
Epoch 48/200
 - 14s - loss: -3.6159e+00 - val_loss: -3.6591e+00
Epoch 49/200
 - 14s - loss: -3.6165e+00 - val_loss: -3.6600e+00
Epoch 50/200
 - 14s - loss: -3.6160e+00 - val_loss: -3.6597e+00
Epoch 51/200
 - 14s - loss: -3.6158e+00 - val_loss: -3.6600e+00
Epoch 52/200
 - 14s - loss: -3.6164e+00 - val_loss: -3.6590e+00
Epoch 53/200
 - 14s - loss: -3.6159e+00 - val_loss: -3.6593e+00
Epoch 54/200
 - 14s - loss: -3.6164e+00 - val_loss: -3.6586e+00
Epoch 55/200
 - 14s - loss: -3.6162e+00 - val_loss: -3.6594e+00
Epoch 56/200
 - 14s - loss: -3.6164e+00 - val_loss: -3.6599e+00
Epoch 57/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6601e+00
Epoch 58/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6597e+00
Epoch 59/200
 - 14s - loss: -3.6166e+00 - val_loss: -3.6599e+00
Epoch 60/200
 - 14s - loss: -3.6168e+00 - val_loss: -3.6594e+00
Epoch 61/200
 - 14s - loss: -3.6170e+00 - val_loss: -3.6599e+00
2019-12-22 18:52:38,436 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_60.pickle
Epoch 62/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.6600e+00
Epoch 63/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6604e+00
Epoch 64/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6594e+00
Epoch 65/200
 - 14s - loss: -3.6170e+00 - val_loss: -3.6600e+00
Epoch 66/200
 - 14s - loss: -3.6169e+00 - val_loss: -3.6595e+00
Epoch 67/200
 - 14s - loss: -3.6172e+00 - val_loss: -3.6603e+00
Epoch 68/200
 - 14s - loss: -3.6171e+00 - val_loss: -3.6604e+00
Epoch 69/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6608e+00
Epoch 70/200
 - 14s - loss: -3.6172e+00 - val_loss: -3.6599e+00
Epoch 71/200
 - 14s - loss: -3.6174e+00 - val_loss: -3.6603e+00
Epoch 72/200
 - 14s - loss: -3.6174e+00 - val_loss: -3.6600e+00
Epoch 73/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6607e+00
Epoch 74/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6602e+00
Epoch 75/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6608e+00
Epoch 76/200
 - 14s - loss: -3.6173e+00 - val_loss: -3.6609e+00
Epoch 77/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6607e+00
Epoch 78/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6609e+00
Epoch 79/200
 - 14s - loss: -3.6174e+00 - val_loss: -3.6601e+00
Epoch 80/200
 - 14s - loss: -3.6175e+00 - val_loss: -3.6601e+00
Epoch 81/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6612e+00
2019-12-22 18:57:21,098 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_80.pickle
Epoch 82/200
 - 14s - loss: -3.6179e+00 - val_loss: -3.6603e+00
Epoch 83/200
 - 14s - loss: -3.6175e+00 - val_loss: -3.6616e+00
Epoch 84/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6613e+00
Epoch 85/200
 - 14s - loss: -3.6180e+00 - val_loss: -3.6603e+00
Epoch 86/200
 - 14s - loss: -3.6177e+00 - val_loss: -3.6613e+00
Epoch 87/200
 - 14s - loss: -3.6176e+00 - val_loss: -3.6613e+00
Epoch 88/200
 - 14s - loss: -3.6180e+00 - val_loss: -3.6616e+00
Epoch 89/200
 - 14s - loss: -3.6180e+00 - val_loss: -3.6619e+00
Epoch 90/200
 - 14s - loss: -3.6181e+00 - val_loss: -3.6616e+00
Epoch 91/200
 - 14s - loss: -3.6180e+00 - val_loss: -3.6607e+00
Epoch 92/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6616e+00
Epoch 93/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6611e+00
Epoch 94/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6618e+00
Epoch 95/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6611e+00
Epoch 96/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6621e+00
Epoch 97/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6622e+00
Epoch 98/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6619e+00
Epoch 99/200
 - 14s - loss: -3.6181e+00 - val_loss: -3.6620e+00
Epoch 100/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6622e+00
Epoch 101/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6623e+00
2019-12-22 19:02:03,699 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_100.pickle
Epoch 102/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6623e+00
Epoch 103/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6620e+00
Epoch 104/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6621e+00
Epoch 105/200
 - 14s - loss: -3.6185e+00 - val_loss: -3.6624e+00
Epoch 106/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6623e+00
Epoch 107/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6618e+00
Epoch 108/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6622e+00
Epoch 109/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6621e+00
Epoch 110/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6623e+00
Epoch 111/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6626e+00
Epoch 112/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6624e+00
Epoch 113/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6620e+00
Epoch 114/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6626e+00
Epoch 115/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6620e+00
Epoch 116/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6625e+00
Epoch 117/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6621e+00
Epoch 118/200
 - 14s - loss: -3.6184e+00 - val_loss: -3.6614e+00
Epoch 119/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6620e+00
Epoch 120/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6620e+00
Epoch 121/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6619e+00
2019-12-22 19:06:46,835 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_120.pickle
Epoch 122/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6620e+00
Epoch 123/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6624e+00
Epoch 124/200
 - 14s - loss: -3.6183e+00 - val_loss: -3.6615e+00
Epoch 125/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6624e+00
Epoch 126/200
 - 14s - loss: -3.6182e+00 - val_loss: -3.6619e+00
Epoch 127/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6621e+00
Epoch 128/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6623e+00
Epoch 129/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6615e+00
Epoch 130/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6619e+00
Epoch 131/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6622e+00
Epoch 132/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6620e+00
Epoch 133/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6620e+00
Epoch 134/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6606e+00
Epoch 135/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6623e+00
Epoch 136/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6620e+00
Epoch 137/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6618e+00
Epoch 138/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6619e+00
Epoch 139/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6620e+00
Epoch 140/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6623e+00
Epoch 141/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6623e+00
2019-12-22 19:11:30,083 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_140.pickle
Epoch 142/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6622e+00
Epoch 143/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6616e+00
Epoch 144/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6618e+00
Epoch 145/200
 - 14s - loss: -3.6188e+00 - val_loss: -3.6614e+00
Epoch 146/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6621e+00
Epoch 147/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6615e+00
Epoch 148/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6622e+00
Epoch 149/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6610e+00
Epoch 150/200
 - 14s - loss: -3.6186e+00 - val_loss: -3.6622e+00
Epoch 151/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6615e+00
Epoch 152/200
 - 14s - loss: -3.6187e+00 - val_loss: -3.6613e+00
Epoch 153/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6616e+00
Epoch 154/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6619e+00
Epoch 155/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6616e+00
Epoch 156/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6622e+00
Epoch 157/200
 - 14s - loss: -3.6189e+00 - val_loss: -3.6621e+00
Epoch 158/200
 - 14s - loss: -3.6190e+00 - val_loss: -3.6621e+00
Epoch 159/200
 - 14s - loss: -3.6192e+00 - val_loss: -3.6618e+00
Epoch 160/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6620e+00
Epoch 161/200
 - 14s - loss: -3.6191e+00 - val_loss: -3.6618e+00
2019-12-22 19:16:13,301 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ae_model_epoch_160.pickle
2019-12-22 19:16:13,301 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 19:16:38,468 [INFO] Last epoch loss evaluation: train_loss = -3.657134, val_loss = -3.662598
2019-12-22 19:16:38,468 [INFO] Training autoencoder complete
2019-12-22 19:16:38,468 [INFO] Encoding data for supervised training
2019-12-22 19:16:59,624 [INFO] Encoding complete
2019-12-22 19:16:59,624 [INFO] Training neural network layers (after autoencoder)
Epoch 00161: early stopping
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 7s - loss: 0.0239 - val_loss: 0.0093
 - val_f1: 0.9815
Epoch 2/200
 - 7s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9823
Epoch 3/200
 - 7s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9805
Epoch 4/200
 - 7s - loss: 0.0090 - val_loss: 0.0960
 - val_f1: 0.8562
Epoch 5/200
 - 7s - loss: 0.0088 - val_loss: 0.0107
 - val_f1: 0.9704
Epoch 6/200
 - 7s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9824
Epoch 7/200
 - 7s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 8/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 9/200
 - 7s - loss: 0.0086 - val_loss: 0.0097
 - val_f1: 0.9811
Epoch 10/200
 - 7s - loss: 0.0086 - val_loss: 0.0550
 - val_f1: 0.8994
Epoch 11/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 12/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 13/200
 - 7s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 14/200
 - 7s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 15/200
 - 7s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 16/200
 - 7s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 17/200
 - 7s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 18/200
 - 7s - loss: 0.0085 - val_loss: 0.1208
 - val_f1: 0.8457
Epoch 19/200
 - 7s - loss: 0.0085 - val_loss: 0.1217
 - val_f1: 0.8432
Epoch 20/200
 - 7s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9821
Epoch 21/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
2019-12-22 19:22:26,809 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_20.pickle
 - val_f1: 0.9828
Epoch 22/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 23/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 24/200
 - 7s - loss: 0.0084 - val_loss: 0.0100
 - val_f1: 0.9737
Epoch 25/200
 - 7s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 26/200
 - 7s - loss: 0.0084 - val_loss: 0.0247
 - val_f1: 0.9309
Epoch 27/200
 - 7s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9825
Epoch 28/200
 - 7s - loss: 0.0084 - val_loss: 0.0970
 - val_f1: 0.8534
Epoch 29/200
 - 7s - loss: 0.0084 - val_loss: 0.0707
 - val_f1: 0.8837
Epoch 30/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 31/200
 - 7s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9814
Epoch 32/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 33/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 34/200
 - 7s - loss: 0.0084 - val_loss: 0.1214
 - val_f1: 0.8442
Epoch 35/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 36/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 37/200
 - 7s - loss: 0.0084 - val_loss: 0.0394
 - val_f1: 0.9253
Epoch 38/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 39/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 40/200
 - 7s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9823
Epoch 41/200
 - 7s - loss: 0.0084 - val_loss: 0.1001
2019-12-22 19:27:44,923 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_40.pickle
 - val_f1: 0.8789
Epoch 42/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 43/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 44/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 45/200
 - 7s - loss: 0.0083 - val_loss: 0.0110
 - val_f1: 0.9720
Epoch 46/200
 - 7s - loss: 0.0084 - val_loss: 0.0196
 - val_f1: 0.9636
Epoch 47/200
 - 7s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 48/200
 - 7s - loss: 0.0083 - val_loss: 0.1161
 - val_f1: 0.8465
Epoch 49/200
 - 7s - loss: 0.0084 - val_loss: 0.1144
 - val_f1: 0.8466
Epoch 50/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 51/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 52/200
 - 7s - loss: 0.0083 - val_loss: 0.1510
 - val_f1: 0.8393
Epoch 53/200
 - 7s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 54/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 55/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 56/200
 - 7s - loss: 0.0083 - val_loss: 0.0244
 - val_f1: 0.9301
Epoch 57/200
 - 7s - loss: 0.0084 - val_loss: 0.0493
 - val_f1: 0.8903
Epoch 58/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 59/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9817
Epoch 60/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 61/200
 - 7s - loss: 0.0083 - val_loss: 0.0087
2019-12-22 19:33:02,688 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9818
Epoch 62/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 63/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 64/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 65/200
 - 7s - loss: 0.0083 - val_loss: 0.0598
 - val_f1: 0.8903
Epoch 66/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 67/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 68/200
 - 7s - loss: 0.0083 - val_loss: 0.0925
 - val_f1: 0.8825
Epoch 69/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 70/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 71/200
 - 7s - loss: 0.0083 - val_loss: 0.1413
 - val_f1: 0.8422
Epoch 72/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 73/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 74/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 75/200
 - 7s - loss: 0.0083 - val_loss: 0.0134
 - val_f1: 0.9623
Epoch 76/200
 - 7s - loss: 0.0083 - val_loss: 0.0268
 - val_f1: 0.9597
Epoch 77/200
 - 7s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9735
Epoch 78/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 79/200
 - 7s - loss: 0.0083 - val_loss: 0.0249
 - val_f1: 0.9308
Epoch 80/200
 - 7s - loss: 0.0083 - val_loss: 0.0108
 - val_f1: 0.9722
Epoch 81/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
2019-12-22 19:38:21,180 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_80.pickle
 - val_f1: 0.9834
Epoch 82/200
 - 7s - loss: 0.0083 - val_loss: 0.0844
 - val_f1: 0.8868
Epoch 83/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 84/200
 - 7s - loss: 0.0083 - val_loss: 0.0465
 - val_f1: 0.9014
Epoch 85/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 86/200
 - 7s - loss: 0.0083 - val_loss: 0.0098
 - val_f1: 0.9811
Epoch 87/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 88/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 89/200
 - 7s - loss: 0.0083 - val_loss: 0.0892
 - val_f1: 0.8755
Epoch 90/200
 - 7s - loss: 0.0083 - val_loss: 0.1734
 - val_f1: 0.8308
Epoch 91/200
 - 7s - loss: 0.0083 - val_loss: 0.1487
 - val_f1: 0.8381
Epoch 92/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 93/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 94/200
 - 7s - loss: 0.0083 - val_loss: 0.1732
 - val_f1: 0.8310
Epoch 95/200
 - 7s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 96/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 97/200
 - 7s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9817
Epoch 98/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 99/200
 - 7s - loss: 0.0083 - val_loss: 0.1367
 - val_f1: 0.8359
Epoch 100/200
 - 7s - loss: 0.0083 - val_loss: 0.0095
 - val_f1: 0.9814
Epoch 101/200
 - 7s - loss: 0.0083 - val_loss: 0.1594
2019-12-22 19:43:40,450 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_100.pickle
 - val_f1: 0.8313
Epoch 102/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 103/200
 - 7s - loss: 0.0083 - val_loss: 0.0964
 - val_f1: 0.8759
Epoch 104/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 105/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 106/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 107/200
 - 7s - loss: 0.0083 - val_loss: 0.1436
 - val_f1: 0.8350
Epoch 108/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9820
Epoch 109/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 110/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 111/200
 - 7s - loss: 0.0083 - val_loss: 0.1680
 - val_f1: 0.8308
Epoch 112/200
 - 7s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 113/200
 - 7s - loss: 0.0083 - val_loss: 0.1722
 - val_f1: 0.8308
Epoch 114/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 115/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 116/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 117/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 118/200
 - 7s - loss: 0.0082 - val_loss: 0.1725
 - val_f1: 0.8308
Epoch 119/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 120/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 121/200
 - 7s - loss: 0.0083 - val_loss: 0.0082
2019-12-22 19:48:59,235 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9832
Epoch 122/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 123/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 124/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 125/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 126/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 127/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 128/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 129/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 130/200
 - 7s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9812
Epoch 131/200
 - 7s - loss: 0.0082 - val_loss: 0.0165
 - val_f1: 0.9635
Epoch 132/200
 - 7s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 133/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 134/200
 - 7s - loss: 0.0082 - val_loss: 0.1560
 - val_f1: 0.8310
Epoch 135/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 136/200
 - 7s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 137/200
 - 7s - loss: 0.0082 - val_loss: 0.0220
 - val_f1: 0.9627
Epoch 138/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 139/200
 - 7s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 140/200
 - 7s - loss: 0.0082 - val_loss: 0.1525
 - val_f1: 0.8310
Epoch 141/200
 - 7s - loss: 0.0083 - val_loss: 0.0215
2019-12-22 19:54:18,878 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_140.pickle
 - val_f1: 0.9632
Epoch 142/200
 - 7s - loss: 0.0082 - val_loss: 0.1686
 - val_f1: 0.8309
Epoch 143/200
 - 7s - loss: 0.0082 - val_loss: 0.0165
 - val_f1: 0.9636
Epoch 144/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 145/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 146/200
 - 7s - loss: 0.0082 - val_loss: 0.1171
 - val_f1: 0.8392
Epoch 147/200
 - 7s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 148/200
 - 7s - loss: 0.0082 - val_loss: 0.1515
 - val_f1: 0.8310
Epoch 149/200
 - 7s - loss: 0.0082 - val_loss: 0.1719
 - val_f1: 0.8308
Epoch 150/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 151/200
 - 7s - loss: 0.0082 - val_loss: 0.1739
 - val_f1: 0.8310
Epoch 152/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9819
Epoch 153/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 154/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 155/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 156/200
 - 7s - loss: 0.0082 - val_loss: 0.0118
 - val_f1: 0.9726
Epoch 157/200
 - 7s - loss: 0.0082 - val_loss: 0.1758
 - val_f1: 0.8309
Epoch 158/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 159/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 160/200
 - 7s - loss: 0.0082 - val_loss: 0.0443
 - val_f1: 0.9183
Epoch 161/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
2019-12-22 19:59:37,884 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/ann_model_epoch_160.pickle
 - val_f1: 0.9832
Epoch 162/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 163/200
 - 7s - loss: 0.0082 - val_loss: 0.1740
 - val_f1: 0.8308
Epoch 164/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 165/200
 - 7s - loss: 0.0082 - val_loss: 0.0277
 - val_f1: 0.9292
Epoch 166/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 167/200
 - 7s - loss: 0.0082 - val_loss: 0.0364
 - val_f1: 0.9261
Epoch 168/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 169/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 170/200
 - 7s - loss: 0.0082 - val_loss: 0.1513
 - val_f1: 0.8310
Epoch 171/200
 - 7s - loss: 0.0082 - val_loss: 0.1715
 - val_f1: 0.8308
Epoch 172/200
 - 7s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9838
Epoch 173/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 174/200
 - 7s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9834
Epoch 175/200
 - 7s - loss: 0.0082 - val_loss: 0.0083
2019-12-22 20:03:30,151 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-22 20:03:54,746 [INFO] Last epoch loss evaluation: train_loss = 0.007851, val_loss = 0.007895
2019-12-22 20:03:54,784 [INFO] Training complete. time_to_train = 5160.43 sec, 86.01 min
2019-12-22 20:03:54,792 [INFO] Model saved to results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/best_model.pickle
2019-12-22 20:03:54,994 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/training_error_history.png
2019-12-22 20:03:55,195 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/training_f1_history.png
2019-12-22 20:03:55,195 [INFO] Making predictions on training, validation, testing data
2019-12-22 20:05:22,302 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-22 20:05:34,385 [INFO] Dataset: Testing. Classification report below
2019-12-22 20:05:34,385 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      0.99      0.80        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.49      0.59      5596
   DoS attacks-Slowloris       0.96      0.76      0.85       440
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.42      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.76      0.70      0.70    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-22 20:05:34,385 [INFO] Overall accuracy (micro avg): 0.9833660734204199
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-22 20:05:48,131 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7648                       0.6965                0.0044                   0.3035  0.7016
2  Weighted avg        0.9909         0.9780                       0.9834                0.0498                   0.0166  0.9784
2019-12-22 20:06:00,210 [INFO] Dataset: Validation. Classification report below
2019-12-22 20:06:00,211 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      0.99      0.83        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.48      0.59      5596
   DoS attacks-Slowloris       0.94      0.82      0.88       439
          FTP-BruteForce       0.70      0.89      0.78      7718
           Infilteration       0.41      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.72      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-22 20:06:00,211 [INFO] Overall accuracy (micro avg): 0.9834528038519753
2019-12-22 20:06:13,912 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.7662                       0.7226                0.0044                   0.2774  0.7250
2  Weighted avg        0.9909         0.9780                       0.9835                0.0495                   0.0165  0.9784
2019-12-22 20:06:53,118 [INFO] Dataset: Training. Classification report below
2019-12-22 20:06:53,118 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.99      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.75      0.48      0.59     16787
   DoS attacks-Slowloris       0.96      0.79      0.87      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.46      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.77      0.71      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-22 20:06:53,118 [INFO] Overall accuracy (micro avg): 0.9834063358847217
2019-12-22 20:07:37,642 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9834         0.9834                       0.9834                0.0012                   0.0166  0.9834
1     Macro avg        0.9978         0.7694                       0.7098                0.0044                   0.2902  0.7152
2  Weighted avg        0.9909         0.9784                       0.9834                0.0496                   0.0166  0.9784
2019-12-22 20:07:37,701 [INFO] Results saved to: results_selected_models/selected_ids18_subset_ae_ann_shallow_rep5/selected_ids18_subset_ae_ann_shallow_rep5_results.xlsx
2019-12-22 20:07:37,706 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-22 20:07:37,781 [INFO] ================= Finished running 5 experiments ================= 

 - val_f1: 0.9822
Epoch 00175: early stopping
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2019-12-23 12:04:34,170 [INFO] Read 25 experiments from file: experiment_specs/selected_model_tests/selected_ae_ann.csv
2019-12-23 12:04:34,170 [INFO] ================= Started running experiments ================= 

2019-12-23 12:04:34,170 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep1
2019-12-23 12:04:34,170 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep1/run_log.log
2019-12-23 12:04:34,170 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 12:04:34,170 [INFO] Experiment parameters given below
2019-12-23 12:04:34,170 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep1'}
2019-12-23 12:04:34,170 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep1/tf_logs_run_2019_12_23-12_04_34
2019-12-23 12:04:34,171 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-23 12:04:34,171 [INFO] Reading X, y files
2019-12-23 12:04:34,171 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-23 12:04:34,180 [INFO] NumExpr defaulting to 8 threads.
2019-12-23 12:04:40,597 [INFO] Reading complete. time_to_read=6.43 seconds
2019-12-23 12:04:40,598 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-23 12:04:42,219 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-23 12:04:42,219 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-23 12:04:42,673 [INFO] Reading complete. time_to_read=0.45 seconds
2019-12-23 12:04:42,674 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-23 12:04:42,890 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-23 12:04:42,890 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-23 12:04:42,944 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-23 12:04:42,945 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-23 12:04:42,964 [INFO] Reading complete. time_to_read=0.02 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12480 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12492 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12493 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12494 thread 3 bound to OS proc set 3
2019-12-23 12:04:50,199 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-23 12:04:50,213 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 12:04:50,285 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 12:04:50,323 [INFO] _________________________________________________________________
2019-12-23 12:04:50,323 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:04:50,323 [INFO] =================================================================
2019-12-23 12:04:50,323 [INFO] dense_1 (Dense)              (None, 32)                3968      
2019-12-23 12:04:50,323 [INFO] _________________________________________________________________
2019-12-23 12:04:50,323 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2019-12-23 12:04:50,324 [INFO] _________________________________________________________________
2019-12-23 12:04:50,324 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2019-12-23 12:04:50,324 [INFO] _________________________________________________________________
2019-12-23 12:04:50,324 [INFO] dense_2 (Dense)              (None, 123)               4059      
2019-12-23 12:04:50,324 [INFO] =================================================================
2019-12-23 12:04:50,324 [INFO] Total params: 8,155
2019-12-23 12:04:50,324 [INFO] Trainable params: 8,091
2019-12-23 12:04:50,324 [INFO] Non-trainable params: 64
2019-12-23 12:04:50,324 [INFO] _________________________________________________________________
2019-12-23 12:04:50,442 [INFO] _________________________________________________________________
2019-12-23 12:04:50,442 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:04:50,442 [INFO] =================================================================
2019-12-23 12:04:50,442 [INFO] dense_3 (Dense)              (None, 32)                1056      
2019-12-23 12:04:50,442 [INFO] _________________________________________________________________
2019-12-23 12:04:50,443 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-23 12:04:50,443 [INFO] _________________________________________________________________
2019-12-23 12:04:50,443 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-23 12:04:50,443 [INFO] _________________________________________________________________
2019-12-23 12:04:50,443 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-23 12:04:50,443 [INFO] =================================================================
2019-12-23 12:04:50,443 [INFO] Total params: 1,349
2019-12-23 12:04:50,443 [INFO] Trainable params: 1,285
2019-12-23 12:04:50,443 [INFO] Non-trainable params: 64
2019-12-23 12:04:50,443 [INFO] _________________________________________________________________
2019-12-23 12:04:50,443 [INFO] Training model
2019-12-23 12:04:50,444 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:05:31,066 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 7c246928c08fe90eed4d92888ab4408bb2eaafc6
2019-12-23 12:05:31,066 [INFO] Training autoencoder
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-23 12:05:31,474 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-23 12:05:31.747953: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2019-12-23 12:05:31.767588: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2019-12-23 12:05:31.767743: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555c202abed0 executing computations on platform Host. Devices:
2019-12-23 12:05:31.767768: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-23 12:05:31.767859: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12504 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12523 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12524 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12525 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12526 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12505 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12529 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12527 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12528 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12531 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12530 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12532 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12533 thread 16 bound to OS proc set 0
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 30s - loss: 0.5875 - val_loss: 0.4945
Epoch 2/200
 - 30s - loss: 0.4797 - val_loss: 0.4867
Epoch 3/200
 - 30s - loss: 0.4683 - val_loss: 0.4714
Epoch 4/200
 - 29s - loss: 0.4563 - val_loss: 0.4664
Epoch 5/200
 - 30s - loss: 0.4499 - val_loss: 0.6215
Epoch 6/200
 - 30s - loss: 0.4403 - val_loss: 0.8461
Epoch 7/200
 - 29s - loss: 0.4353 - val_loss: 0.9904
Epoch 8/200
 - 30s - loss: 0.4347 - val_loss: 2.0530
Epoch 9/200
 - 29s - loss: 0.4350 - val_loss: 2.3660
Epoch 10/200
 - 30s - loss: 0.4319 - val_loss: 3.1729
Epoch 11/200
 - 30s - loss: 0.4303 - val_loss: 3.3789
Epoch 12/200
 - 29s - loss: 0.4293 - val_loss: 3.3407
Epoch 13/200
 - 29s - loss: 0.4313 - val_loss: 2.9433
Epoch 14/200
 - 29s - loss: 0.4258 - val_loss: 3.0899
Epoch 15/200
 - 29s - loss: 0.4185 - val_loss: 2.5282
Epoch 16/200
 - 29s - loss: 0.4096 - val_loss: 2.2928
Epoch 17/200
 - 30s - loss: 0.4115 - val_loss: 2.7276
Epoch 18/200
 - 29s - loss: 0.4079 - val_loss: 2.0987
Epoch 19/200
 - 29s - loss: 0.4059 - val_loss: 2.2231
Epoch 20/200
 - 29s - loss: 0.4054 - val_loss: 2.3391
Epoch 21/200
 - 30s - loss: 0.4071 - val_loss: 2.0615
2019-12-23 12:15:51,924 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ae_model_epoch_20.pickle
Epoch 22/200
 - 30s - loss: 0.4082 - val_loss: 1.9548
Epoch 23/200
 - 30s - loss: 0.4039 - val_loss: 2.2003
Epoch 24/200
 - 30s - loss: 0.4053 - val_loss: 1.4655
Epoch 25/200
 - 29s - loss: 0.4016 - val_loss: 1.2651
Epoch 26/200
 - 29s - loss: 0.4021 - val_loss: 1.4221
Epoch 27/200
 - 29s - loss: 0.4026 - val_loss: 1.3448
Epoch 28/200
 - 29s - loss: 0.3941 - val_loss: 1.3106
Epoch 29/200
 - 29s - loss: 0.4055 - val_loss: 1.1453
Epoch 30/200
 - 29s - loss: 0.3974 - val_loss: 0.9208
Epoch 31/200
 - 29s - loss: 0.3957 - val_loss: 1.3872
Epoch 32/200
 - 30s - loss: 0.3981 - val_loss: 0.7502
Epoch 33/200
 - 29s - loss: 0.4006 - val_loss: 1.1869
Epoch 34/200
 - 29s - loss: 0.3964 - val_loss: 0.9560
Epoch 35/200
 - 29s - loss: 0.3997 - val_loss: 1.0584
Epoch 36/200
 - 29s - loss: 0.3959 - val_loss: 1.0503
Epoch 37/200
 - 29s - loss: 0.3972 - val_loss: 1.0235
Epoch 38/200
 - 29s - loss: 0.3962 - val_loss: 0.8831
Epoch 39/200
 - 29s - loss: 0.3941 - val_loss: 0.9990
Epoch 40/200
 - 29s - loss: 0.3853 - val_loss: 0.7717
Epoch 41/200
 - 29s - loss: 0.3843 - val_loss: 0.7692
2019-12-23 12:25:40,228 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ae_model_epoch_40.pickle
Epoch 42/200
 - 30s - loss: 0.3905 - val_loss: 0.8716
Epoch 43/200
 - 29s - loss: 0.3816 - val_loss: 1.0097
Epoch 44/200
 - 29s - loss: 0.3873 - val_loss: 0.9092
Epoch 45/200
 - 29s - loss: 0.3877 - val_loss: 0.8468
Epoch 46/200
 - 29s - loss: 0.3854 - val_loss: 0.6867
Epoch 47/200
 - 29s - loss: 0.3899 - val_loss: 0.6924
Epoch 48/200
 - 29s - loss: 0.3854 - val_loss: 0.6487
Epoch 49/200
 - 29s - loss: 0.3817 - val_loss: 0.6789
Epoch 50/200
 - 29s - loss: 0.3789 - val_loss: 0.7068
Epoch 51/200
 - 29s - loss: 0.3729 - val_loss: 0.7345
Epoch 52/200
 - 29s - loss: 0.3748 - val_loss: 0.6913
Epoch 53/200
 - 29s - loss: 0.3769 - val_loss: 0.6937
Epoch 54/200
 - 29s - loss: 0.3708 - val_loss: 0.6615
2019-12-23 12:32:02,957 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:33:05,304 [INFO] Last epoch loss evaluation: train_loss = 0.491331, val_loss = 0.466428
2019-12-23 12:33:05,304 [INFO] Training autoencoder complete
2019-12-23 12:33:05,304 [INFO] Encoding data for supervised training
2019-12-23 12:33:50,017 [INFO] Encoding complete
2019-12-23 12:33:50,018 [INFO] Training neural network layers (after autoencoder)
Epoch 00054: early stopping
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 18s - loss: 0.0124 - val_loss: 0.0020
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12624 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12625 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 12480 tid 12626 thread 19 bound to OS proc set 3
 - val_f1: 0.9990
Epoch 2/200
 - 17s - loss: 0.0021 - val_loss: 0.0015
 - val_f1: 0.9990
Epoch 3/200
 - 17s - loss: 0.0016 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 4/200
 - 17s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9992
Epoch 5/200
 - 17s - loss: 0.0013 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 6/200
 - 17s - loss: 0.0013 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 7/200
 - 17s - loss: 0.0012 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 8/200
 - 17s - loss: 0.0012 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 9/200
 - 17s - loss: 0.0011 - val_loss: 0.0012
 - val_f1: 0.9994
Epoch 10/200
 - 17s - loss: 0.0011 - val_loss: 9.3292e-04
 - val_f1: 0.9994
Epoch 11/200
 - 17s - loss: 0.0011 - val_loss: 9.1038e-04
 - val_f1: 0.9995
Epoch 12/200
 - 17s - loss: 0.0011 - val_loss: 8.8405e-04
 - val_f1: 0.9995
Epoch 13/200
 - 17s - loss: 0.0010 - val_loss: 8.9772e-04
 - val_f1: 0.9995
Epoch 14/200
 - 17s - loss: 0.0010 - val_loss: 9.3393e-04
 - val_f1: 0.9995
Epoch 15/200
 - 17s - loss: 0.0010 - val_loss: 8.9041e-04
 - val_f1: 0.9995
Epoch 16/200
 - 17s - loss: 0.0010 - val_loss: 8.7144e-04
 - val_f1: 0.9995
Epoch 17/200
 - 17s - loss: 9.6649e-04 - val_loss: 9.0871e-04
 - val_f1: 0.9995
Epoch 18/200
 - 17s - loss: 9.9071e-04 - val_loss: 9.3395e-04
 - val_f1: 0.9994
Epoch 19/200
 - 17s - loss: 9.6039e-04 - val_loss: 8.7992e-04
 - val_f1: 0.9995
Epoch 20/200
 - 17s - loss: 9.5651e-04 - val_loss: 8.6773e-04
 - val_f1: 0.9995
Epoch 21/200
 - 17s - loss: 9.5557e-04 - val_loss: 8.7586e-04
2019-12-23 12:44:21,510 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9995
Epoch 22/200
 - 17s - loss: 9.0953e-04 - val_loss: 8.6412e-04
 - val_f1: 0.9995
Epoch 23/200
 - 17s - loss: 9.1418e-04 - val_loss: 9.1843e-04
 - val_f1: 0.9994
Epoch 24/200
 - 17s - loss: 9.1926e-04 - val_loss: 8.5996e-04
 - val_f1: 0.9995
Epoch 25/200
 - 17s - loss: 9.0869e-04 - val_loss: 8.3145e-04
 - val_f1: 0.9995
Epoch 26/200
 - 17s - loss: 8.9678e-04 - val_loss: 8.4286e-04
 - val_f1: 0.9995
Epoch 27/200
 - 17s - loss: 8.8399e-04 - val_loss: 8.0592e-04
 - val_f1: 0.9995
Epoch 28/200
 - 17s - loss: 8.9125e-04 - val_loss: 8.3418e-04
 - val_f1: 0.9995
Epoch 29/200
 - 17s - loss: 8.9964e-04 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 30/200
 - 17s - loss: 9.0273e-04 - val_loss: 8.3724e-04
 - val_f1: 0.9995
Epoch 31/200
 - 17s - loss: 8.9944e-04 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 32/200
 - 17s - loss: 8.5842e-04 - val_loss: 8.7328e-04
 - val_f1: 0.9995
Epoch 33/200
 - 17s - loss: 8.5723e-04 - val_loss: 8.2066e-04
 - val_f1: 0.9995
Epoch 34/200
 - 17s - loss: 8.8613e-04 - val_loss: 9.5621e-04
 - val_f1: 0.9995
Epoch 35/200
 - 17s - loss: 8.6742e-04 - val_loss: 8.2366e-04
 - val_f1: 0.9995
Epoch 36/200
 - 17s - loss: 8.4958e-04 - val_loss: 7.8234e-04
 - val_f1: 0.9995
Epoch 37/200
 - 17s - loss: 8.3757e-04 - val_loss: 8.1642e-04
 - val_f1: 0.9996
Epoch 38/200
 - 17s - loss: 8.4547e-04 - val_loss: 7.7154e-04
 - val_f1: 0.9996
Epoch 39/200
 - 17s - loss: 8.6512e-04 - val_loss: 8.1798e-04
 - val_f1: 0.9995
Epoch 40/200
 - 17s - loss: 8.4270e-04 - val_loss: 7.8720e-04
 - val_f1: 0.9996
Epoch 41/200
 - 17s - loss: 8.4266e-04 - val_loss: 8.0194e-04
2019-12-23 12:54:34,123 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9995
Epoch 42/200
 - 17s - loss: 8.4031e-04 - val_loss: 8.2889e-04
 - val_f1: 0.9995
Epoch 43/200
 - 17s - loss: 8.5369e-04 - val_loss: 7.7076e-04
 - val_f1: 0.9996
Epoch 44/200
 - 17s - loss: 8.2499e-04 - val_loss: 8.2635e-04
 - val_f1: 0.9995
Epoch 45/200
 - 17s - loss: 8.3750e-04 - val_loss: 8.0264e-04
 - val_f1: 0.9995
Epoch 46/200
 - 17s - loss: 8.1901e-04 - val_loss: 7.9810e-04
 - val_f1: 0.9995
Epoch 47/200
 - 17s - loss: 8.3705e-04 - val_loss: 7.6119e-04
 - val_f1: 0.9995
Epoch 48/200
 - 17s - loss: 8.1510e-04 - val_loss: 8.4303e-04
 - val_f1: 0.9995
Epoch 49/200
 - 17s - loss: 8.2073e-04 - val_loss: 8.4315e-04
 - val_f1: 0.9995
Epoch 50/200
 - 17s - loss: 8.0492e-04 - val_loss: 8.4007e-04
 - val_f1: 0.9995
Epoch 51/200
 - 17s - loss: 7.9569e-04 - val_loss: 0.0012
 - val_f1: 0.9994
Epoch 52/200
 - 17s - loss: 8.1512e-04 - val_loss: 9.1139e-04
 - val_f1: 0.9995
Epoch 53/200
 - 17s - loss: 7.9070e-04 - val_loss: 7.7223e-04
 - val_f1: 0.9995
Epoch 54/200
 - 17s - loss: 8.0851e-04 - val_loss: 8.5107e-04
 - val_f1: 0.9995
Epoch 55/200
 - 17s - loss: 8.1072e-04 - val_loss: 7.5049e-04
 - val_f1: 0.9996
Epoch 56/200
 - 17s - loss: 8.0174e-04 - val_loss: 9.3589e-04
 - val_f1: 0.9995
Epoch 57/200
 - 17s - loss: 7.8980e-04 - val_loss: 7.6361e-04
 - val_f1: 0.9996
Epoch 58/200
 - 17s - loss: 7.8407e-04 - val_loss: 7.7396e-04
 - val_f1: 0.9995
Epoch 59/200
 - 17s - loss: 7.8311e-04 - val_loss: 8.7190e-04
 - val_f1: 0.9995
Epoch 60/200
 - 17s - loss: 7.7810e-04 - val_loss: 7.6288e-04
 - val_f1: 0.9995
Epoch 61/200
 - 17s - loss: 7.7873e-04 - val_loss: 8.3248e-04
2019-12-23 13:04:46,615 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9995
Epoch 62/200
 - 17s - loss: 7.6848e-04 - val_loss: 7.5575e-04
 - val_f1: 0.9996
Epoch 63/200
 - 17s - loss: 7.8271e-04 - val_loss: 7.9295e-04
 - val_f1: 0.9995
Epoch 64/200
 - 17s - loss: 7.7931e-04 - val_loss: 7.4817e-04
 - val_f1: 0.9995
Epoch 65/200
 - 17s - loss: 7.6142e-04 - val_loss: 7.7218e-04
 - val_f1: 0.9996
Epoch 66/200
 - 17s - loss: 7.5765e-04 - val_loss: 7.6639e-04
 - val_f1: 0.9996
Epoch 67/200
 - 17s - loss: 7.6107e-04 - val_loss: 7.0735e-04
 - val_f1: 0.9996
Epoch 68/200
 - 17s - loss: 7.4430e-04 - val_loss: 7.6370e-04
 - val_f1: 0.9995
Epoch 69/200
 - 17s - loss: 7.6798e-04 - val_loss: 7.2971e-04
 - val_f1: 0.9996
Epoch 70/200
 - 17s - loss: 7.4853e-04 - val_loss: 7.9669e-04
 - val_f1: 0.9996
Epoch 71/200
 - 17s - loss: 7.6092e-04 - val_loss: 7.4664e-04
 - val_f1: 0.9996
Epoch 72/200
 - 17s - loss: 7.5099e-04 - val_loss: 7.6137e-04
 - val_f1: 0.9996
Epoch 73/200
 - 17s - loss: 7.6106e-04 - val_loss: 7.3019e-04
 - val_f1: 0.9996
Epoch 74/200
 - 17s - loss: 7.2970e-04 - val_loss: 7.1575e-04
 - val_f1: 0.9996
Epoch 75/200
 - 17s - loss: 7.4731e-04 - val_loss: 8.8956e-04
 - val_f1: 0.9995
Epoch 76/200
 - 17s - loss: 7.3568e-04 - val_loss: 7.1295e-04
 - val_f1: 0.9996
Epoch 77/200
 - 17s - loss: 7.4682e-04 - val_loss: 8.2387e-04
 - val_f1: 0.9996
Epoch 78/200
 - 17s - loss: 7.5612e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 79/200
 - 17s - loss: 7.3859e-04 - val_loss: 7.6133e-04
 - val_f1: 0.9995
Epoch 80/200
 - 17s - loss: 7.5981e-04 - val_loss: 8.4508e-04
 - val_f1: 0.9995
Epoch 81/200
 - 17s - loss: 7.4623e-04 - val_loss: 7.8775e-04
2019-12-23 13:14:59,528 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9995
Epoch 82/200
 - 17s - loss: 7.3644e-04 - val_loss: 7.6403e-04
 - val_f1: 0.9995
Epoch 83/200
 - 17s - loss: 7.3451e-04 - val_loss: 7.4359e-04
 - val_f1: 0.9996
Epoch 84/200
 - 17s - loss: 7.2426e-04 - val_loss: 8.5522e-04
 - val_f1: 0.9996
Epoch 85/200
 - 17s - loss: 7.0667e-04 - val_loss: 7.5751e-04
 - val_f1: 0.9995
Epoch 86/200
 - 17s - loss: 7.1645e-04 - val_loss: 7.3503e-04
 - val_f1: 0.9996
Epoch 87/200
 - 17s - loss: 7.3733e-04 - val_loss: 7.7902e-04
 - val_f1: 0.9996
Epoch 88/200
 - 17s - loss: 7.2312e-04 - val_loss: 7.8380e-04
 - val_f1: 0.9995
Epoch 89/200
 - 17s - loss: 7.2740e-04 - val_loss: 9.3361e-04
 - val_f1: 0.9995
Epoch 90/200
 - 17s - loss: 6.9789e-04 - val_loss: 7.6939e-04
 - val_f1: 0.9996
Epoch 91/200
 - 17s - loss: 7.1600e-04 - val_loss: 7.4637e-04
 - val_f1: 0.9996
Epoch 92/200
 - 17s - loss: 7.2559e-04 - val_loss: 7.5504e-04
 - val_f1: 0.9995
Epoch 93/200
 - 17s - loss: 7.3790e-04 - val_loss: 7.1208e-04
 - val_f1: 0.9996
Epoch 94/200
 - 17s - loss: 7.3333e-04 - val_loss: 7.0188e-04
 - val_f1: 0.9996
Epoch 95/200
 - 17s - loss: 7.4681e-04 - val_loss: 8.5887e-04
 - val_f1: 0.9996
Epoch 96/200
 - 17s - loss: 7.0259e-04 - val_loss: 8.6145e-04
 - val_f1: 0.9995
Epoch 97/200
 - 17s - loss: 7.0549e-04 - val_loss: 7.8295e-04
 - val_f1: 0.9996
Epoch 98/200
 - 17s - loss: 7.2015e-04 - val_loss: 7.1747e-04
 - val_f1: 0.9996
Epoch 99/200
 - 17s - loss: 7.0479e-04 - val_loss: 6.9205e-04
 - val_f1: 0.9996
Epoch 100/200
 - 17s - loss: 7.1880e-04 - val_loss: 7.8962e-04
 - val_f1: 0.9996
Epoch 101/200
 - 17s - loss: 6.8846e-04 - val_loss: 7.0538e-04
2019-12-23 13:25:12,412 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9997
Epoch 102/200
 - 17s - loss: 7.0378e-04 - val_loss: 7.5609e-04
 - val_f1: 0.9996
Epoch 103/200
 - 17s - loss: 7.0728e-04 - val_loss: 7.6275e-04
 - val_f1: 0.9996
Epoch 104/200
 - 17s - loss: 7.0190e-04 - val_loss: 8.5442e-04
 - val_f1: 0.9994
Epoch 105/200
 - 17s - loss: 6.9338e-04 - val_loss: 7.8583e-04
 - val_f1: 0.9996
Epoch 106/200
 - 17s - loss: 6.9708e-04 - val_loss: 8.1431e-04
 - val_f1: 0.9995
Epoch 107/200
 - 17s - loss: 7.0692e-04 - val_loss: 7.2646e-04
 - val_f1: 0.9996
Epoch 108/200
 - 17s - loss: 7.0597e-04 - val_loss: 8.0007e-04
 - val_f1: 0.9996
Epoch 109/200
 - 17s - loss: 7.0684e-04 - val_loss: 7.7231e-04
 - val_f1: 0.9996
Epoch 110/200
 - 17s - loss: 7.0522e-04 - val_loss: 6.9134e-04
 - val_f1: 0.9996
Epoch 111/200
 - 17s - loss: 6.8795e-04 - val_loss: 7.2663e-04
 - val_f1: 0.9996
Epoch 112/200
 - 17s - loss: 6.8948e-04 - val_loss: 7.1395e-04
 - val_f1: 0.9997
Epoch 113/200
 - 17s - loss: 6.9562e-04 - val_loss: 6.9623e-04
 - val_f1: 0.9996
Epoch 114/200
 - 17s - loss: 7.1793e-04 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 115/200
 - 17s - loss: 6.6257e-04 - val_loss: 7.1121e-04
 - val_f1: 0.9996
Epoch 116/200
 - 17s - loss: 7.1030e-04 - val_loss: 7.0136e-04
 - val_f1: 0.9996
Epoch 117/200
 - 17s - loss: 6.9875e-04 - val_loss: 7.6570e-04
 - val_f1: 0.9996
Epoch 118/200
 - 17s - loss: 7.1179e-04 - val_loss: 7.1917e-04
 - val_f1: 0.9996
Epoch 119/200
 - 17s - loss: 6.5530e-04 - val_loss: 7.6364e-04
 - val_f1: 0.9996
Epoch 120/200
 - 17s - loss: 6.7479e-04 - val_loss: 7.2144e-04
 - val_f1: 0.9996
Epoch 121/200
 - 17s - loss: 6.7701e-04 - val_loss: 7.0217e-04
2019-12-23 13:35:25,364 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9996
Epoch 122/200
 - 17s - loss: 6.7732e-04 - val_loss: 6.9620e-04
 - val_f1: 0.9996
Epoch 123/200
 - 17s - loss: 6.8114e-04 - val_loss: 7.0981e-04
 - val_f1: 0.9995
Epoch 124/200
 - 17s - loss: 6.7159e-04 - val_loss: 7.0106e-04
 - val_f1: 0.9996
Epoch 125/200
 - 17s - loss: 6.7875e-04 - val_loss: 0.0015
 - val_f1: 0.9994
Epoch 126/200
 - 17s - loss: 6.8533e-04 - val_loss: 6.7135e-04
 - val_f1: 0.9997
Epoch 127/200
 - 17s - loss: 6.8763e-04 - val_loss: 6.6343e-04
 - val_f1: 0.9997
Epoch 128/200
 - 17s - loss: 6.9236e-04 - val_loss: 7.3943e-04
 - val_f1: 0.9996
Epoch 129/200
 - 17s - loss: 6.9166e-04 - val_loss: 7.0152e-04
 - val_f1: 0.9996
Epoch 130/200
 - 17s - loss: 6.9201e-04 - val_loss: 6.9077e-04
 - val_f1: 0.9997
Epoch 131/200
 - 17s - loss: 6.9649e-04 - val_loss: 7.5514e-04
 - val_f1: 0.9996
Epoch 132/200
 - 17s - loss: 6.5418e-04 - val_loss: 7.1077e-04
 - val_f1: 0.9996
Epoch 133/200
 - 17s - loss: 6.8302e-04 - val_loss: 6.6670e-04
 - val_f1: 0.9997
Epoch 134/200
 - 17s - loss: 6.8884e-04 - val_loss: 7.7926e-04
 - val_f1: 0.9996
Epoch 135/200
 - 17s - loss: 6.6987e-04 - val_loss: 7.1511e-04
 - val_f1: 0.9996
Epoch 136/200
 - 17s - loss: 6.7998e-04 - val_loss: 7.6523e-04
 - val_f1: 0.9996
Epoch 137/200
 - 17s - loss: 6.9604e-04 - val_loss: 6.8478e-04
 - val_f1: 0.9996
Epoch 138/200
 - 17s - loss: 6.6465e-04 - val_loss: 7.6661e-04
 - val_f1: 0.9996
Epoch 139/200
 - 17s - loss: 6.6879e-04 - val_loss: 7.2501e-04
 - val_f1: 0.9996
Epoch 140/200
 - 17s - loss: 6.5281e-04 - val_loss: 7.1625e-04
 - val_f1: 0.9996
Epoch 141/200
 - 17s - loss: 6.8237e-04 - val_loss: 8.0377e-04
2019-12-23 13:45:37,577 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9996
Epoch 142/200
 - 17s - loss: 6.5757e-04 - val_loss: 7.7005e-04
 - val_f1: 0.9996
Epoch 143/200
 - 17s - loss: 6.8443e-04 - val_loss: 7.1441e-04
 - val_f1: 0.9997
Epoch 144/200
 - 17s - loss: 6.5700e-04 - val_loss: 7.7380e-04
 - val_f1: 0.9996
Epoch 145/200
 - 17s - loss: 6.8573e-04 - val_loss: 6.9535e-04
 - val_f1: 0.9997
Epoch 146/200
 - 17s - loss: 6.6898e-04 - val_loss: 7.0368e-04
 - val_f1: 0.9996
Epoch 147/200
 - 17s - loss: 6.8089e-04 - val_loss: 6.7057e-04
 - val_f1: 0.9997
Epoch 148/200
 - 17s - loss: 6.6780e-04 - val_loss: 6.8401e-04
 - val_f1: 0.9996
Epoch 149/200
 - 17s - loss: 6.8608e-04 - val_loss: 8.3615e-04
 - val_f1: 0.9996
Epoch 150/200
 - 17s - loss: 6.7464e-04 - val_loss: 6.5551e-04
 - val_f1: 0.9997
Epoch 151/200
 - 17s - loss: 6.6458e-04 - val_loss: 6.5456e-04
 - val_f1: 0.9996
Epoch 152/200
 - 17s - loss: 6.5402e-04 - val_loss: 9.7566e-04
 - val_f1: 0.9996
Epoch 153/200
 - 17s - loss: 6.6489e-04 - val_loss: 7.7963e-04
 - val_f1: 0.9996
Epoch 154/200
 - 17s - loss: 6.8129e-04 - val_loss: 7.5709e-04
 - val_f1: 0.9996
Epoch 155/200
 - 17s - loss: 6.7275e-04 - val_loss: 7.5482e-04
 - val_f1: 0.9996
Epoch 156/200
 - 17s - loss: 6.8059e-04 - val_loss: 8.0619e-04
 - val_f1: 0.9995
Epoch 157/200
 - 17s - loss: 6.6226e-04 - val_loss: 7.0633e-04
 - val_f1: 0.9996
Epoch 158/200
 - 17s - loss: 6.5793e-04 - val_loss: 6.5753e-04
 - val_f1: 0.9996
Epoch 159/200
 - 17s - loss: 6.6488e-04 - val_loss: 8.3989e-04
 - val_f1: 0.9995
Epoch 160/200
 - 17s - loss: 6.7204e-04 - val_loss: 7.1853e-04
 - val_f1: 0.9996
Epoch 161/200
 - 17s - loss: 6.5911e-04 - val_loss: 6.5657e-04
2019-12-23 13:55:49,125 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9997
Epoch 162/200
 - 17s - loss: 6.7931e-04 - val_loss: 6.6331e-04
 - val_f1: 0.9997
Epoch 163/200
 - 17s - loss: 6.6231e-04 - val_loss: 8.0015e-04
 - val_f1: 0.9996
Epoch 164/200
 - 17s - loss: 6.7165e-04 - val_loss: 7.3822e-04
 - val_f1: 0.9996
Epoch 165/200
 - 17s - loss: 6.4331e-04 - val_loss: 6.9799e-04
 - val_f1: 0.9996
Epoch 166/200
 - 17s - loss: 6.6998e-04 - val_loss: 7.1801e-04
 - val_f1: 0.9996
Epoch 167/200
 - 17s - loss: 6.7629e-04 - val_loss: 6.8768e-04
 - val_f1: 0.9996
Epoch 168/200
 - 17s - loss: 6.6331e-04 - val_loss: 6.9372e-04
 - val_f1: 0.9996
Epoch 169/200
 - 17s - loss: 6.7406e-04 - val_loss: 7.1742e-04
 - val_f1: 0.9997
Epoch 170/200
 - 17s - loss: 6.7143e-04 - val_loss: 6.8556e-04
 - val_f1: 0.9996
Epoch 171/200
 - 17s - loss: 6.7531e-04 - val_loss: 7.2948e-04
 - val_f1: 0.9996
Epoch 172/200
 - 17s - loss: 6.6685e-04 - val_loss: 6.6449e-04
 - val_f1: 0.9996
Epoch 173/200
 - 17s - loss: 6.5324e-04 - val_loss: 6.9544e-04
 - val_f1: 0.9996
Epoch 174/200
 - 17s - loss: 6.7127e-04 - val_loss: 7.4563e-04
 - val_f1: 0.9996
Epoch 175/200
 - 17s - loss: 6.7522e-04 - val_loss: 8.3416e-04
 - val_f1: 0.9995
Epoch 176/200
 - 17s - loss: 6.7373e-04 - val_loss: 8.6201e-04
 - val_f1: 0.9996
Epoch 177/200
 - 17s - loss: 6.7568e-04 - val_loss: 6.8638e-04
 - val_f1: 0.9996
Epoch 178/200
 - 17s - loss: 6.5588e-04 - val_loss: 6.9383e-04
 - val_f1: 0.9997
Epoch 179/200
 - 17s - loss: 6.8454e-04 - val_loss: 8.8013e-04
 - val_f1: 0.9996
Epoch 180/200
 - 17s - loss: 6.5253e-04 - val_loss: 7.0115e-04
 - val_f1: 0.9997
Epoch 181/200
 - 17s - loss: 6.7928e-04 - val_loss: 6.8761e-04
2019-12-23 14:06:00,392 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9997
Epoch 182/200
 - 17s - loss: 6.7099e-04 - val_loss: 6.5674e-04
 - val_f1: 0.9996
Epoch 183/200
 - 17s - loss: 6.9105e-04 - val_loss: 7.1319e-04
 - val_f1: 0.9996
Epoch 184/200
 - 17s - loss: 6.6194e-04 - val_loss: 7.3981e-04
 - val_f1: 0.9996
Epoch 185/200
 - 17s - loss: 6.6594e-04 - val_loss: 6.7801e-04
 - val_f1: 0.9996
Epoch 186/200
 - 17s - loss: 6.8501e-04 - val_loss: 6.6454e-04
 - val_f1: 0.9997
Epoch 187/200
 - 17s - loss: 6.5956e-04 - val_loss: 6.3718e-04
 - val_f1: 0.9997
Epoch 188/200
 - 17s - loss: 6.7616e-04 - val_loss: 7.8305e-04
 - val_f1: 0.9996
Epoch 189/200
 - 17s - loss: 6.3171e-04 - val_loss: 6.4504e-04
 - val_f1: 0.9997
Epoch 190/200
 - 17s - loss: 6.4737e-04 - val_loss: 7.6023e-04
 - val_f1: 0.9996
Epoch 191/200
 - 17s - loss: 6.5466e-04 - val_loss: 7.0023e-04
 - val_f1: 0.9996
Epoch 192/200
 - 17s - loss: 6.4725e-04 - val_loss: 7.7945e-04
 - val_f1: 0.9996
Epoch 193/200
 - 17s - loss: 6.6350e-04 - val_loss: 6.8162e-04
 - val_f1: 0.9997
Epoch 194/200
 - 17s - loss: 6.7751e-04 - val_loss: 7.6330e-04
 - val_f1: 0.9996
Epoch 195/200
 - 17s - loss: 6.5066e-04 - val_loss: 6.7463e-04
 - val_f1: 0.9997
Epoch 196/200
 - 17s - loss: 6.2979e-04 - val_loss: 7.0539e-04
 - val_f1: 0.9997
Epoch 197/200
 - 17s - loss: 6.6287e-04 - val_loss: 7.2537e-04
 - val_f1: 0.9996
Epoch 198/200
 - 17s - loss: 6.7569e-04 - val_loss: 7.6978e-04
 - val_f1: 0.9996
Epoch 199/200
 - 17s - loss: 6.6248e-04 - val_loss: 6.9580e-04
 - val_f1: 0.9996
Epoch 200/200
 - 17s - loss: 6.6822e-04 - val_loss: 6.5761e-04
2019-12-23 14:15:55,167 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 14:16:43,169 [INFO] Last epoch loss evaluation: train_loss = 0.000454, val_loss = 0.000637
2019-12-23 14:16:43,191 [INFO] Training complete. time_to_train = 7912.75 sec, 131.88 min
2019-12-23 14:16:43,199 [INFO] Model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep1/best_model.pickle
2019-12-23 14:16:43,393 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep1/training_error_history.png
2019-12-23 14:16:43,583 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep1/training_f1_history.png
2019-12-23 14:16:43,584 [INFO] Making predictions on training, validation, testing data
2019-12-23 14:19:13,538 [INFO] Evaluating predictions (results)
2019-12-23 14:19:22,321 [INFO] Dataset: Testing. Classification report below
2019-12-23 14:19:22,321 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.76      0.74      0.75      4166
         r2l       0.97      0.02      0.05     13781
         u2r       0.06      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.70      0.55      0.53    311029
weighted avg       0.93      0.92      0.90    311029

2019-12-23 14:19:22,321 [INFO] Overall accuracy (micro avg): 0.9225795665355964
2019-12-23 14:19:31,614 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9226         0.9226                       0.9226                0.0194                   0.0774  0.9226
1     Macro avg        0.9690         0.7029                       0.5460                0.0197                   0.4540  0.5259
2  Weighted avg        0.9682         0.9330                       0.9226                0.0213                   0.0774  0.9037
2019-12-23 14:20:01,852 [INFO] Dataset: Validation. Classification report below
2019-12-23 14:20:01,852 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.98      0.99      8221
         r2l       0.95      0.77      0.85       225
         u2r       0.33      0.20      0.25        10

    accuracy                           1.00    979687
   macro avg       0.85      0.79      0.82    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-23 14:20:01,852 [INFO] Overall accuracy (micro avg): 0.9996825516721157
2019-12-23 14:20:34,487 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8540                       0.7905                0.0001                   0.2095  0.8171
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 14:22:48,006 [INFO] Dataset: Training. Classification report below
2019-12-23 14:22:48,006 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.98      0.99     32881
         r2l       0.95      0.81      0.88       901
         u2r       0.59      0.45      0.51        42

    accuracy                           1.00   3918744
   macro avg       0.91      0.85      0.88   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-23 14:22:48,006 [INFO] Overall accuracy (micro avg): 0.999708069728464
2019-12-23 14:25:12,113 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.9066                       0.8503                0.0001                   0.1497  0.8755
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 14:25:12,160 [INFO] Results saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep1/selected_kdd99_ae_ann_shallow_rep1_results.xlsx
2019-12-23 14:25:12,167 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 14:25:12,192 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep2
2019-12-23 14:25:12,193 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep2/run_log.log
2019-12-23 14:25:12,193 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 14:25:12,193 [INFO] Experiment parameters given below
2019-12-23 14:25:12,193 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep2'}
2019-12-23 14:25:12,193 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep2/tf_logs_run_2019_12_23-14_25_12
2019-12-23 14:25:12,193 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-23 14:25:12,193 [INFO] Reading X, y files
2019-12-23 14:25:12,193 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-23 14:25:18,560 [INFO] Reading complete. time_to_read=6.37 seconds
2019-12-23 14:25:18,561 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-23 14:25:20,174 [INFO] Reading complete. time_to_read=1.61 seconds
2019-12-23 14:25:20,174 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-23 14:25:20,629 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-23 14:25:20,629 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-23 14:25:20,836 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-23 14:25:20,836 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-23 14:25:20,889 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-23 14:25:20,889 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-23 14:25:20,908 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-23 14:25:28,052 [INFO] Initializing model
2019-12-23 14:25:28,167 [INFO] _________________________________________________________________
2019-12-23 14:25:28,167 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 14:25:28,167 [INFO] =================================================================
2019-12-23 14:25:28,167 [INFO] dense_5 (Dense)              (None, 32)                3968      
2019-12-23 14:25:28,167 [INFO] _________________________________________________________________
2019-12-23 14:25:28,167 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-23 14:25:28,167 [INFO] _________________________________________________________________
2019-12-23 14:25:28,168 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-23 14:25:28,168 [INFO] _________________________________________________________________
2019-12-23 14:25:28,168 [INFO] dense_6 (Dense)              (None, 123)               4059      
2019-12-23 14:25:28,168 [INFO] =================================================================
2019-12-23 14:25:28,168 [INFO] Total params: 8,155
2019-12-23 14:25:28,168 [INFO] Trainable params: 8,091
2019-12-23 14:25:28,168 [INFO] Non-trainable params: 64
2019-12-23 14:25:28,168 [INFO] _________________________________________________________________
2019-12-23 14:25:28,287 [INFO] _________________________________________________________________
2019-12-23 14:25:28,287 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 14:25:28,288 [INFO] =================================================================
2019-12-23 14:25:28,288 [INFO] dense_7 (Dense)              (None, 32)                1056      
2019-12-23 14:25:28,288 [INFO] _________________________________________________________________
2019-12-23 14:25:28,288 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-23 14:25:28,288 [INFO] _________________________________________________________________
2019-12-23 14:25:28,288 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-23 14:25:28,288 [INFO] _________________________________________________________________
2019-12-23 14:25:28,288 [INFO] dense_8 (Dense)              (None, 5)                 165       
2019-12-23 14:25:28,288 [INFO] =================================================================
2019-12-23 14:25:28,289 [INFO] Total params: 1,349
2019-12-23 14:25:28,289 [INFO] Trainable params: 1,285
2019-12-23 14:25:28,289 [INFO] Non-trainable params: 64
2019-12-23 14:25:28,289 [INFO] _________________________________________________________________
2019-12-23 14:25:28,289 [INFO] Training model
2019-12-23 14:25:28,289 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 14:26:09,065 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = c0034363f187b98ba91274700b7a2d79509e3a71
2019-12-23 14:26:09,065 [INFO] Training autoencoder
 - val_f1: 0.9997
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 31s - loss: 0.6311 - val_loss: 0.5769
Epoch 2/200
 - 30s - loss: 0.5326 - val_loss: 0.5515
Epoch 3/200
 - 30s - loss: 0.5129 - val_loss: 0.5392
Epoch 4/200
 - 30s - loss: 0.5051 - val_loss: 0.5182
Epoch 5/200
 - 30s - loss: 0.5002 - val_loss: 0.5154
Epoch 6/200
 - 30s - loss: 0.4974 - val_loss: 0.4685
Epoch 7/200
 - 30s - loss: 0.4963 - val_loss: 0.4275
Epoch 8/200
 - 30s - loss: 0.4920 - val_loss: 0.4100
Epoch 9/200
 - 30s - loss: 0.4800 - val_loss: 0.3928
Epoch 10/200
 - 30s - loss: 0.4729 - val_loss: 0.4015
Epoch 11/200
 - 30s - loss: 0.4712 - val_loss: 0.4774
Epoch 12/200
 - 30s - loss: 0.4702 - val_loss: 0.5166
Epoch 13/200
 - 30s - loss: 0.4682 - val_loss: 0.5209
Epoch 14/200
 - 30s - loss: 0.4686 - val_loss: 0.7158
Epoch 15/200
 - 30s - loss: 0.4649 - val_loss: 0.9082
Epoch 16/200
 - 30s - loss: 0.4661 - val_loss: 1.1971
Epoch 17/200
 - 30s - loss: 0.4649 - val_loss: 0.9863
Epoch 18/200
 - 30s - loss: 0.4585 - val_loss: 1.3852
Epoch 19/200
 - 30s - loss: 0.4604 - val_loss: 1.6001
Epoch 20/200
 - 30s - loss: 0.4572 - val_loss: 1.3794
Epoch 21/200
 - 30s - loss: 0.4542 - val_loss: 1.2326
2019-12-23 14:36:40,495 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ae_model_epoch_20.pickle
Epoch 22/200
 - 30s - loss: 0.4563 - val_loss: 1.5252
Epoch 23/200
 - 30s - loss: 0.4539 - val_loss: 1.5791
Epoch 24/200
 - 30s - loss: 0.4528 - val_loss: 1.2919
Epoch 25/200
 - 30s - loss: 0.4517 - val_loss: 1.2240
Epoch 26/200
 - 30s - loss: 0.4488 - val_loss: 1.2020
Epoch 27/200
 - 30s - loss: 0.4514 - val_loss: 1.2672
Epoch 28/200
 - 30s - loss: 0.4512 - val_loss: 0.9825
Epoch 29/200
 - 30s - loss: 0.4512 - val_loss: 0.8613
Epoch 30/200
 - 30s - loss: 0.4507 - val_loss: 0.9216
Epoch 31/200
 - 30s - loss: 0.4450 - val_loss: 0.8969
Epoch 32/200
 - 30s - loss: 0.4351 - val_loss: 1.0243
Epoch 33/200
 - 30s - loss: 0.4393 - val_loss: 0.8128
Epoch 34/200
 - 30s - loss: 0.4381 - val_loss: 0.8131
Epoch 35/200
 - 30s - loss: 0.4409 - val_loss: 0.9187
Epoch 36/200
 - 30s - loss: 0.4375 - val_loss: 0.8497
Epoch 37/200
 - 30s - loss: 0.4349 - val_loss: 0.8573
Epoch 38/200
 - 30s - loss: 0.4425 - val_loss: 0.7210
Epoch 39/200
 - 30s - loss: 0.4355 - val_loss: 0.6008
Epoch 40/200
 - 30s - loss: 0.4329 - val_loss: 0.6915
Epoch 41/200
 - 30s - loss: 0.4364 - val_loss: 0.7360
2019-12-23 14:46:38,724 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ae_model_epoch_40.pickle
Epoch 42/200
 - 30s - loss: 0.4333 - val_loss: 0.7126
Epoch 43/200
 - 30s - loss: 0.4246 - val_loss: 0.6585
Epoch 44/200
 - 30s - loss: 0.4257 - val_loss: 0.6719
Epoch 45/200
 - 30s - loss: 0.4212 - val_loss: 0.6838
Epoch 46/200
 - 30s - loss: 0.4180 - val_loss: 0.6794
Epoch 47/200
 - 30s - loss: 0.4268 - val_loss: 0.6433
Epoch 48/200
 - 30s - loss: 0.4275 - val_loss: 0.7157
Epoch 49/200
 - 30s - loss: 0.4225 - val_loss: 0.6633
Epoch 50/200
 - 30s - loss: 0.4185 - val_loss: 0.5870
Epoch 51/200
 - 30s - loss: 0.4254 - val_loss: 0.6953
Epoch 52/200
 - 30s - loss: 0.4284 - val_loss: 0.6077
Epoch 53/200
 - 30s - loss: 0.4199 - val_loss: 0.5571
Epoch 54/200
 - 30s - loss: 0.4157 - val_loss: 0.5842
Epoch 55/200
 - 30s - loss: 0.4188 - val_loss: 0.5745
Epoch 56/200
 - 30s - loss: 0.4172 - val_loss: 0.6841
Epoch 57/200
 - 30s - loss: 0.4177 - val_loss: 0.7043
Epoch 58/200
 - 30s - loss: 0.4212 - val_loss: 0.6906
Epoch 59/200
 - 30s - loss: 0.4205 - val_loss: 0.6795
2019-12-23 14:55:39,349 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 14:56:48,254 [INFO] Last epoch loss evaluation: train_loss = 0.490030, val_loss = 0.392839
2019-12-23 14:56:48,254 [INFO] Training autoencoder complete
2019-12-23 14:56:48,254 [INFO] Encoding data for supervised training
2019-12-23 14:57:38,766 [INFO] Encoding complete
2019-12-23 14:57:38,766 [INFO] Training neural network layers (after autoencoder)
Epoch 00059: early stopping
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 18s - loss: 0.0118 - val_loss: 0.0031
 - val_f1: 0.9988
Epoch 2/200
 - 17s - loss: 0.0020 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 3/200
 - 17s - loss: 0.0014 - val_loss: 9.6876e-04
 - val_f1: 0.9994
Epoch 4/200
 - 17s - loss: 0.0012 - val_loss: 8.8929e-04
 - val_f1: 0.9995
Epoch 5/200
 - 17s - loss: 0.0011 - val_loss: 0.0011
 - val_f1: 0.9992
Epoch 6/200
 - 17s - loss: 0.0011 - val_loss: 8.6662e-04
 - val_f1: 0.9995
Epoch 7/200
 - 17s - loss: 0.0010 - val_loss: 9.3200e-04
 - val_f1: 0.9995
Epoch 8/200
 - 17s - loss: 9.9788e-04 - val_loss: 8.2552e-04
 - val_f1: 0.9996
Epoch 9/200
 - 17s - loss: 9.5349e-04 - val_loss: 9.5252e-04
 - val_f1: 0.9993
Epoch 10/200
 - 17s - loss: 9.4863e-04 - val_loss: 8.1901e-04
 - val_f1: 0.9995
Epoch 11/200
 - 17s - loss: 9.3349e-04 - val_loss: 8.9035e-04
 - val_f1: 0.9995
Epoch 12/200
 - 17s - loss: 9.1923e-04 - val_loss: 8.2273e-04
 - val_f1: 0.9995
Epoch 13/200
 - 17s - loss: 8.8427e-04 - val_loss: 9.3020e-04
 - val_f1: 0.9993
Epoch 14/200
 - 17s - loss: 8.8413e-04 - val_loss: 7.1082e-04
 - val_f1: 0.9996
Epoch 15/200
 - 17s - loss: 8.7250e-04 - val_loss: 8.3675e-04
 - val_f1: 0.9996
Epoch 16/200
 - 17s - loss: 8.8196e-04 - val_loss: 7.7457e-04
 - val_f1: 0.9995
Epoch 17/200
 - 17s - loss: 8.4428e-04 - val_loss: 7.7978e-04
 - val_f1: 0.9996
Epoch 18/200
 - 17s - loss: 8.3573e-04 - val_loss: 7.5947e-04
 - val_f1: 0.9996
Epoch 19/200
 - 17s - loss: 8.2575e-04 - val_loss: 8.0983e-04
 - val_f1: 0.9995
Epoch 20/200
 - 17s - loss: 7.7584e-04 - val_loss: 7.7181e-04
 - val_f1: 0.9995
Epoch 21/200
 - 17s - loss: 7.9669e-04 - val_loss: 7.1378e-04
2019-12-23 15:09:03,004 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9996
Epoch 22/200
 - 17s - loss: 7.7665e-04 - val_loss: 8.2634e-04
 - val_f1: 0.9995
Epoch 23/200
 - 17s - loss: 7.8290e-04 - val_loss: 9.4515e-04
 - val_f1: 0.9995
Epoch 24/200
 - 17s - loss: 7.7134e-04 - val_loss: 9.5122e-04
 - val_f1: 0.9995
Epoch 25/200
 - 17s - loss: 7.5067e-04 - val_loss: 7.0932e-04
 - val_f1: 0.9996
Epoch 26/200
 - 17s - loss: 7.8066e-04 - val_loss: 8.0749e-04
 - val_f1: 0.9996
Epoch 27/200
 - 17s - loss: 7.8292e-04 - val_loss: 7.9384e-04
 - val_f1: 0.9996
Epoch 28/200
 - 17s - loss: 7.6888e-04 - val_loss: 7.4061e-04
 - val_f1: 0.9996
Epoch 29/200
 - 17s - loss: 7.5835e-04 - val_loss: 6.8630e-04
 - val_f1: 0.9996
Epoch 30/200
 - 17s - loss: 7.6559e-04 - val_loss: 6.7998e-04
 - val_f1: 0.9996
Epoch 31/200
 - 17s - loss: 7.3695e-04 - val_loss: 7.0761e-04
 - val_f1: 0.9996
Epoch 32/200
 - 17s - loss: 7.4515e-04 - val_loss: 6.9141e-04
 - val_f1: 0.9996
Epoch 33/200
 - 17s - loss: 7.5156e-04 - val_loss: 7.3632e-04
 - val_f1: 0.9996
Epoch 34/200
 - 17s - loss: 7.6632e-04 - val_loss: 7.3888e-04
 - val_f1: 0.9996
Epoch 35/200
 - 17s - loss: 7.5832e-04 - val_loss: 7.0815e-04
 - val_f1: 0.9996
Epoch 36/200
 - 17s - loss: 7.1913e-04 - val_loss: 7.0291e-04
 - val_f1: 0.9996
Epoch 37/200
 - 17s - loss: 7.4014e-04 - val_loss: 6.7640e-04
 - val_f1: 0.9997
Epoch 38/200
 - 17s - loss: 7.4363e-04 - val_loss: 6.6726e-04
 - val_f1: 0.9997
Epoch 39/200
 - 17s - loss: 7.3839e-04 - val_loss: 6.9114e-04
 - val_f1: 0.9996
Epoch 40/200
 - 17s - loss: 7.3702e-04 - val_loss: 6.6126e-04
 - val_f1: 0.9996
Epoch 41/200
 - 17s - loss: 7.1573e-04 - val_loss: 9.3556e-04
2019-12-23 15:20:08,316 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9993
Epoch 42/200
 - 17s - loss: 7.3453e-04 - val_loss: 7.0007e-04
 - val_f1: 0.9996
Epoch 43/200
 - 17s - loss: 7.3576e-04 - val_loss: 6.6404e-04
 - val_f1: 0.9997
Epoch 44/200
 - 17s - loss: 7.3388e-04 - val_loss: 7.3171e-04
 - val_f1: 0.9996
Epoch 45/200
 - 17s - loss: 7.2521e-04 - val_loss: 6.7040e-04
 - val_f1: 0.9997
Epoch 46/200
 - 17s - loss: 7.2032e-04 - val_loss: 7.8604e-04
 - val_f1: 0.9996
Epoch 47/200
 - 17s - loss: 7.2906e-04 - val_loss: 6.5593e-04
 - val_f1: 0.9997
Epoch 48/200
 - 17s - loss: 6.9798e-04 - val_loss: 6.7322e-04
 - val_f1: 0.9996
Epoch 49/200
 - 17s - loss: 7.3806e-04 - val_loss: 7.2393e-04
 - val_f1: 0.9996
Epoch 50/200
 - 17s - loss: 7.3901e-04 - val_loss: 6.9204e-04
 - val_f1: 0.9996
Epoch 51/200
 - 17s - loss: 7.4308e-04 - val_loss: 7.0610e-04
 - val_f1: 0.9997
Epoch 52/200
 - 17s - loss: 7.2204e-04 - val_loss: 7.3527e-04
 - val_f1: 0.9996
Epoch 53/200
 - 17s - loss: 7.0967e-04 - val_loss: 7.1292e-04
 - val_f1: 0.9996
Epoch 54/200
 - 17s - loss: 7.1165e-04 - val_loss: 7.1975e-04
 - val_f1: 0.9996
Epoch 55/200
 - 17s - loss: 7.2383e-04 - val_loss: 6.9506e-04
 - val_f1: 0.9996
Epoch 56/200
 - 17s - loss: 7.1118e-04 - val_loss: 6.8703e-04
 - val_f1: 0.9997
Epoch 57/200
 - 17s - loss: 6.9527e-04 - val_loss: 8.6905e-04
 - val_f1: 0.9996
Epoch 58/200
 - 17s - loss: 7.1913e-04 - val_loss: 8.4807e-04
 - val_f1: 0.9997
Epoch 59/200
 - 17s - loss: 6.7926e-04 - val_loss: 6.6408e-04
 - val_f1: 0.9997
Epoch 60/200
 - 17s - loss: 7.0169e-04 - val_loss: 7.8984e-04
 - val_f1: 0.9996
Epoch 61/200
 - 17s - loss: 7.0781e-04 - val_loss: 8.4594e-04
2019-12-23 15:31:14,100 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/200
 - 17s - loss: 6.9122e-04 - val_loss: 8.4756e-04
 - val_f1: 0.9996
Epoch 63/200
 - 17s - loss: 6.7859e-04 - val_loss: 7.8729e-04
 - val_f1: 0.9996
Epoch 64/200
 - 17s - loss: 7.0764e-04 - val_loss: 6.7344e-04
 - val_f1: 0.9997
Epoch 65/200
 - 17s - loss: 6.7402e-04 - val_loss: 6.7433e-04
 - val_f1: 0.9997
Epoch 66/200
 - 17s - loss: 6.8907e-04 - val_loss: 8.9616e-04
 - val_f1: 0.9996
Epoch 67/200
 - 17s - loss: 6.8775e-04 - val_loss: 6.3443e-04
 - val_f1: 0.9997
Epoch 68/200
 - 17s - loss: 6.7789e-04 - val_loss: 6.7288e-04
 - val_f1: 0.9996
Epoch 69/200
 - 17s - loss: 6.8477e-04 - val_loss: 7.0624e-04
 - val_f1: 0.9996
Epoch 70/200
 - 17s - loss: 6.9620e-04 - val_loss: 6.4263e-04
 - val_f1: 0.9997
Epoch 71/200
 - 17s - loss: 6.5401e-04 - val_loss: 6.6351e-04
 - val_f1: 0.9997
Epoch 72/200
 - 17s - loss: 6.7641e-04 - val_loss: 6.2731e-04
 - val_f1: 0.9997
Epoch 73/200
 - 17s - loss: 6.7055e-04 - val_loss: 6.5422e-04
 - val_f1: 0.9997
Epoch 74/200
 - 17s - loss: 6.8249e-04 - val_loss: 6.8365e-04
 - val_f1: 0.9996
Epoch 75/200
 - 17s - loss: 6.7508e-04 - val_loss: 6.3975e-04
 - val_f1: 0.9997
Epoch 76/200
 - 17s - loss: 6.8900e-04 - val_loss: 6.6546e-04
 - val_f1: 0.9996
Epoch 77/200
 - 17s - loss: 6.4912e-04 - val_loss: 7.3942e-04
 - val_f1: 0.9995
Epoch 78/200
 - 17s - loss: 6.7976e-04 - val_loss: 6.3360e-04
 - val_f1: 0.9997
Epoch 79/200
 - 17s - loss: 6.7704e-04 - val_loss: 6.5623e-04
 - val_f1: 0.9997
Epoch 80/200
 - 17s - loss: 6.6940e-04 - val_loss: 6.2671e-04
 - val_f1: 0.9997
Epoch 81/200
 - 17s - loss: 6.6481e-04 - val_loss: 6.7556e-04
2019-12-23 15:42:19,790 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9997
Epoch 82/200
 - 17s - loss: 6.7058e-04 - val_loss: 6.5636e-04
 - val_f1: 0.9997
Epoch 83/200
 - 17s - loss: 6.6944e-04 - val_loss: 6.1595e-04
 - val_f1: 0.9997
Epoch 84/200
 - 17s - loss: 6.4977e-04 - val_loss: 6.7838e-04
 - val_f1: 0.9997
Epoch 85/200
 - 17s - loss: 6.5086e-04 - val_loss: 6.1685e-04
 - val_f1: 0.9997
Epoch 86/200
 - 17s - loss: 6.7067e-04 - val_loss: 6.4304e-04
 - val_f1: 0.9997
Epoch 87/200
 - 17s - loss: 6.4160e-04 - val_loss: 6.2957e-04
 - val_f1: 0.9997
Epoch 88/200
 - 17s - loss: 6.5884e-04 - val_loss: 6.2973e-04
 - val_f1: 0.9997
Epoch 89/200
 - 17s - loss: 6.4329e-04 - val_loss: 6.5979e-04
 - val_f1: 0.9997
Epoch 90/200
 - 17s - loss: 6.2398e-04 - val_loss: 6.8772e-04
 - val_f1: 0.9996
Epoch 91/200
 - 17s - loss: 6.4629e-04 - val_loss: 6.6881e-04
 - val_f1: 0.9996
Epoch 92/200
 - 17s - loss: 6.2614e-04 - val_loss: 6.2747e-04
 - val_f1: 0.9997
Epoch 93/200
 - 17s - loss: 6.3111e-04 - val_loss: 7.3273e-04
 - val_f1: 0.9996
Epoch 94/200
 - 17s - loss: 6.5420e-04 - val_loss: 6.4287e-04
 - val_f1: 0.9997
Epoch 95/200
 - 17s - loss: 6.1780e-04 - val_loss: 6.4956e-04
 - val_f1: 0.9997
Epoch 96/200
 - 17s - loss: 6.4688e-04 - val_loss: 6.5589e-04
 - val_f1: 0.9997
Epoch 97/200
 - 17s - loss: 6.4066e-04 - val_loss: 7.0543e-04
 - val_f1: 0.9996
Epoch 98/200
 - 17s - loss: 6.3116e-04 - val_loss: 7.0275e-04
 - val_f1: 0.9997
Epoch 99/200
 - 17s - loss: 6.3565e-04 - val_loss: 6.7936e-04
 - val_f1: 0.9997
Epoch 100/200
 - 17s - loss: 6.2842e-04 - val_loss: 6.4317e-04
 - val_f1: 0.9997
Epoch 101/200
 - 17s - loss: 6.3201e-04 - val_loss: 6.9931e-04
2019-12-23 15:53:24,809 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9996
Epoch 102/200
 - 17s - loss: 6.3808e-04 - val_loss: 6.4937e-04
 - val_f1: 0.9997
Epoch 103/200
 - 17s - loss: 6.3712e-04 - val_loss: 7.1021e-04
 - val_f1: 0.9997
Epoch 104/200
 - 17s - loss: 6.4177e-04 - val_loss: 6.6095e-04
 - val_f1: 0.9997
Epoch 105/200
 - 17s - loss: 6.2583e-04 - val_loss: 6.6408e-04
 - val_f1: 0.9997
Epoch 106/200
 - 17s - loss: 6.4950e-04 - val_loss: 6.3797e-04
 - val_f1: 0.9996
Epoch 107/200
 - 17s - loss: 6.2810e-04 - val_loss: 6.2432e-04
 - val_f1: 0.9997
Epoch 108/200
 - 17s - loss: 6.3436e-04 - val_loss: 6.3769e-04
 - val_f1: 0.9996
Epoch 109/200
 - 17s - loss: 6.4566e-04 - val_loss: 6.2454e-04
 - val_f1: 0.9997
Epoch 110/200
 - 17s - loss: 6.3444e-04 - val_loss: 6.3185e-04
 - val_f1: 0.9997
Epoch 111/200
 - 17s - loss: 6.1418e-04 - val_loss: 6.9314e-04
 - val_f1: 0.9997
Epoch 112/200
 - 17s - loss: 6.1194e-04 - val_loss: 6.0463e-04
 - val_f1: 0.9997
Epoch 113/200
 - 17s - loss: 6.0887e-04 - val_loss: 6.0974e-04
 - val_f1: 0.9997
Epoch 114/200
 - 17s - loss: 6.4311e-04 - val_loss: 6.7368e-04
 - val_f1: 0.9997
Epoch 115/200
 - 17s - loss: 6.2729e-04 - val_loss: 6.1281e-04
 - val_f1: 0.9997
Epoch 116/200
 - 17s - loss: 6.2915e-04 - val_loss: 6.3786e-04
 - val_f1: 0.9997
Epoch 117/200
 - 17s - loss: 6.2179e-04 - val_loss: 6.1869e-04
 - val_f1: 0.9997
Epoch 118/200
 - 17s - loss: 6.1826e-04 - val_loss: 6.1910e-04
 - val_f1: 0.9996
Epoch 119/200
 - 17s - loss: 6.3058e-04 - val_loss: 6.0183e-04
 - val_f1: 0.9997
Epoch 120/200
 - 17s - loss: 6.0835e-04 - val_loss: 6.3441e-04
 - val_f1: 0.9997
Epoch 121/200
 - 17s - loss: 6.5111e-04 - val_loss: 6.2337e-04
2019-12-23 16:04:30,406 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/200
 - 17s - loss: 6.4689e-04 - val_loss: 6.1280e-04
 - val_f1: 0.9997
Epoch 123/200
 - 17s - loss: 6.2963e-04 - val_loss: 5.9355e-04
 - val_f1: 0.9997
Epoch 124/200
 - 17s - loss: 6.1639e-04 - val_loss: 6.0557e-04
 - val_f1: 0.9997
Epoch 125/200
 - 17s - loss: 6.3007e-04 - val_loss: 5.8662e-04
 - val_f1: 0.9997
Epoch 126/200
 - 17s - loss: 6.2273e-04 - val_loss: 6.5817e-04
 - val_f1: 0.9996
Epoch 127/200
 - 17s - loss: 6.0362e-04 - val_loss: 6.1821e-04
 - val_f1: 0.9997
Epoch 128/200
 - 17s - loss: 6.1557e-04 - val_loss: 6.0030e-04
 - val_f1: 0.9997
Epoch 129/200
 - 17s - loss: 6.2780e-04 - val_loss: 6.5736e-04
 - val_f1: 0.9997
Epoch 130/200
 - 17s - loss: 6.2980e-04 - val_loss: 7.0258e-04
 - val_f1: 0.9996
Epoch 131/200
 - 17s - loss: 6.2222e-04 - val_loss: 7.2651e-04
 - val_f1: 0.9997
Epoch 132/200
 - 17s - loss: 6.2798e-04 - val_loss: 7.3217e-04
 - val_f1: 0.9997
Epoch 133/200
 - 17s - loss: 5.9403e-04 - val_loss: 6.5849e-04
 - val_f1: 0.9997
Epoch 134/200
 - 17s - loss: 6.2382e-04 - val_loss: 7.2150e-04
 - val_f1: 0.9996
Epoch 135/200
 - 17s - loss: 5.9833e-04 - val_loss: 7.0373e-04
 - val_f1: 0.9997
Epoch 136/200
 - 17s - loss: 6.2078e-04 - val_loss: 6.3428e-04
 - val_f1: 0.9997
Epoch 137/200
 - 17s - loss: 6.0887e-04 - val_loss: 6.9197e-04
 - val_f1: 0.9997
Epoch 138/200
 - 17s - loss: 5.8131e-04 - val_loss: 6.5076e-04
 - val_f1: 0.9997
Epoch 139/200
 - 17s - loss: 6.1711e-04 - val_loss: 6.2606e-04
 - val_f1: 0.9997
Epoch 140/200
 - 17s - loss: 6.0934e-04 - val_loss: 6.9558e-04
 - val_f1: 0.9997
Epoch 141/200
 - 17s - loss: 6.2449e-04 - val_loss: 6.3715e-04
2019-12-23 16:15:36,071 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9997
Epoch 142/200
 - 17s - loss: 6.2150e-04 - val_loss: 6.8719e-04
 - val_f1: 0.9997
Epoch 143/200
 - 17s - loss: 6.1062e-04 - val_loss: 6.2388e-04
 - val_f1: 0.9997
Epoch 144/200
 - 17s - loss: 6.0617e-04 - val_loss: 6.2386e-04
 - val_f1: 0.9997
Epoch 145/200
 - 17s - loss: 6.1433e-04 - val_loss: 6.5758e-04
 - val_f1: 0.9997
Epoch 146/200
 - 17s - loss: 6.1892e-04 - val_loss: 7.4690e-04
 - val_f1: 0.9997
Epoch 147/200
 - 17s - loss: 5.8522e-04 - val_loss: 6.9271e-04
 - val_f1: 0.9997
Epoch 148/200
 - 17s - loss: 6.1603e-04 - val_loss: 7.0854e-04
 - val_f1: 0.9997
Epoch 149/200
 - 17s - loss: 6.2054e-04 - val_loss: 7.2326e-04
 - val_f1: 0.9997
Epoch 150/200
 - 17s - loss: 5.9766e-04 - val_loss: 6.6561e-04
 - val_f1: 0.9997
Epoch 151/200
 - 17s - loss: 6.1071e-04 - val_loss: 7.0345e-04
 - val_f1: 0.9997
Epoch 152/200
 - 17s - loss: 6.0147e-04 - val_loss: 7.2324e-04
 - val_f1: 0.9996
Epoch 153/200
 - 17s - loss: 6.0848e-04 - val_loss: 6.7066e-04
 - val_f1: 0.9997
Epoch 154/200
 - 17s - loss: 6.1763e-04 - val_loss: 6.6226e-04
 - val_f1: 0.9997
Epoch 155/200
 - 17s - loss: 6.2627e-04 - val_loss: 7.0212e-04
 - val_f1: 0.9997
Epoch 156/200
 - 17s - loss: 6.1263e-04 - val_loss: 7.0833e-04
 - val_f1: 0.9997
Epoch 157/200
 - 17s - loss: 6.0760e-04 - val_loss: 6.4854e-04
 - val_f1: 0.9997
Epoch 158/200
 - 17s - loss: 5.9147e-04 - val_loss: 7.1024e-04
 - val_f1: 0.9996
Epoch 159/200
 - 17s - loss: 5.8724e-04 - val_loss: 6.8431e-04
 - val_f1: 0.9997
Epoch 160/200
 - 17s - loss: 5.9283e-04 - val_loss: 6.8399e-04
 - val_f1: 0.9997
Epoch 161/200
 - 17s - loss: 5.9342e-04 - val_loss: 6.6264e-04
2019-12-23 16:26:41,463 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_160.pickle
 - val_f1: 0.9996
Epoch 162/200
 - 17s - loss: 5.8528e-04 - val_loss: 6.7050e-04
 - val_f1: 0.9997
Epoch 163/200
 - 17s - loss: 6.0670e-04 - val_loss: 5.8566e-04
 - val_f1: 0.9997
Epoch 164/200
 - 17s - loss: 6.0920e-04 - val_loss: 7.5857e-04
 - val_f1: 0.9997
Epoch 165/200
 - 17s - loss: 6.0590e-04 - val_loss: 7.1733e-04
 - val_f1: 0.9997
Epoch 166/200
 - 17s - loss: 5.8380e-04 - val_loss: 6.8262e-04
 - val_f1: 0.9997
Epoch 167/200
 - 17s - loss: 6.0249e-04 - val_loss: 6.6240e-04
 - val_f1: 0.9997
Epoch 168/200
 - 17s - loss: 5.8863e-04 - val_loss: 7.0142e-04
 - val_f1: 0.9997
Epoch 169/200
 - 17s - loss: 6.0137e-04 - val_loss: 7.7015e-04
 - val_f1: 0.9996
Epoch 170/200
 - 17s - loss: 5.8839e-04 - val_loss: 6.6381e-04
 - val_f1: 0.9997
Epoch 171/200
 - 17s - loss: 5.9715e-04 - val_loss: 7.2410e-04
 - val_f1: 0.9996
Epoch 172/200
 - 17s - loss: 6.1034e-04 - val_loss: 6.5350e-04
 - val_f1: 0.9997
Epoch 173/200
 - 17s - loss: 5.8439e-04 - val_loss: 6.7588e-04
 - val_f1: 0.9997
Epoch 174/200
 - 17s - loss: 5.8658e-04 - val_loss: 6.7589e-04
 - val_f1: 0.9997
Epoch 175/200
 - 17s - loss: 5.9286e-04 - val_loss: 7.0721e-04
 - val_f1: 0.9997
Epoch 176/200
 - 17s - loss: 5.9908e-04 - val_loss: 7.3660e-04
 - val_f1: 0.9997
Epoch 177/200
 - 17s - loss: 6.1064e-04 - val_loss: 7.2626e-04
 - val_f1: 0.9997
Epoch 178/200
 - 17s - loss: 5.9340e-04 - val_loss: 6.9768e-04
 - val_f1: 0.9997
Epoch 179/200
 - 17s - loss: 5.9379e-04 - val_loss: 6.8190e-04
 - val_f1: 0.9997
Epoch 180/200
 - 17s - loss: 5.9967e-04 - val_loss: 7.1009e-04
 - val_f1: 0.9997
Epoch 181/200
 - 17s - loss: 5.9538e-04 - val_loss: 6.1350e-04
2019-12-23 16:37:47,153 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9997
Epoch 182/200
 - 17s - loss: 5.7586e-04 - val_loss: 6.7982e-04
 - val_f1: 0.9997
Epoch 183/200
 - 17s - loss: 5.9936e-04 - val_loss: 6.5435e-04
 - val_f1: 0.9997
Epoch 184/200
 - 18s - loss: 5.8800e-04 - val_loss: 7.1660e-04
 - val_f1: 0.9997
Epoch 185/200
 - 17s - loss: 5.7747e-04 - val_loss: 7.5295e-04
 - val_f1: 0.9997
Epoch 186/200
 - 17s - loss: 5.8083e-04 - val_loss: 7.3167e-04
 - val_f1: 0.9996
Epoch 187/200
 - 17s - loss: 5.8597e-04 - val_loss: 7.4610e-04
 - val_f1: 0.9996
Epoch 188/200
 - 17s - loss: 5.9831e-04 - val_loss: 7.1556e-04
 - val_f1: 0.9996
Epoch 189/200
 - 17s - loss: 5.7218e-04 - val_loss: 7.8016e-04
 - val_f1: 0.9997
Epoch 190/200
 - 17s - loss: 6.1608e-04 - val_loss: 7.7419e-04
 - val_f1: 0.9996
Epoch 191/200
 - 17s - loss: 5.8926e-04 - val_loss: 7.2065e-04
 - val_f1: 0.9997
Epoch 192/200
 - 17s - loss: 5.8402e-04 - val_loss: 6.7045e-04
 - val_f1: 0.9997
Epoch 193/200
 - 17s - loss: 5.9171e-04 - val_loss: 7.0100e-04
 - val_f1: 0.9997
Epoch 194/200
 - 17s - loss: 5.8596e-04 - val_loss: 7.1164e-04
 - val_f1: 0.9997
Epoch 195/200
 - 17s - loss: 5.6964e-04 - val_loss: 8.1759e-04
 - val_f1: 0.9997
Epoch 196/200
 - 17s - loss: 5.6869e-04 - val_loss: 7.4372e-04
 - val_f1: 0.9997
Epoch 197/200
 - 17s - loss: 5.7540e-04 - val_loss: 7.4394e-04
 - val_f1: 0.9997
Epoch 198/200
 - 17s - loss: 5.7955e-04 - val_loss: 7.3369e-04
 - val_f1: 0.9997
Epoch 199/200
 - 17s - loss: 5.8214e-04 - val_loss: 7.3090e-04
 - val_f1: 0.9997
Epoch 200/200
 - 17s - loss: 6.1340e-04 - val_loss: 7.0109e-04
2019-12-23 16:48:35,625 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 16:49:30,519 [INFO] Last epoch loss evaluation: train_loss = 0.000431, val_loss = 0.000586
2019-12-23 16:49:30,541 [INFO] Training complete. time_to_train = 8642.25 sec, 144.04 min
2019-12-23 16:49:30,549 [INFO] Model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep2/best_model.pickle
2019-12-23 16:49:30,736 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep2/training_error_history.png
2019-12-23 16:49:30,911 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep2/training_f1_history.png
2019-12-23 16:49:30,911 [INFO] Making predictions on training, validation, testing data
2019-12-23 16:52:21,337 [INFO] Evaluating predictions (results)
2019-12-23 16:52:30,019 [INFO] Dataset: Testing. Classification report below
2019-12-23 16:52:30,019 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.75      0.74      0.75      4166
         r2l       0.99      0.05      0.10     13781
         u2r       0.51      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.80      0.55      0.54    311029
weighted avg       0.94      0.92      0.91    311029

2019-12-23 16:52:30,019 [INFO] Overall accuracy (micro avg): 0.9232676052715342
2019-12-23 16:52:39,314 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9233         0.9233                       0.9233                0.0192                   0.0767  0.9233
1     Macro avg        0.9693         0.7953                       0.5521                0.0199                   0.4479  0.5368
2  Weighted avg        0.9675         0.9370                       0.9233                0.0226                   0.0767  0.9057
2019-12-23 16:53:09,581 [INFO] Dataset: Validation. Classification report below
2019-12-23 16:53:09,582 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.99      0.99      8221
         r2l       0.85      0.78      0.81       225
         u2r       0.21      0.30      0.25        10

    accuracy                           1.00    979687
   macro avg       0.81      0.81      0.81    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-23 16:53:09,582 [INFO] Overall accuracy (micro avg): 0.9996917382796751
2019-12-23 16:53:42,229 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8102                       0.8141                0.0001                   0.1859  0.8105
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 16:55:55,901 [INFO] Dataset: Training. Classification report below
2019-12-23 16:55:55,901 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.87      0.81      0.84       901
         u2r       0.33      0.52      0.41        42

    accuracy                           1.00   3918744
   macro avg       0.84      0.86      0.85   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-23 16:55:55,901 [INFO] Overall accuracy (micro avg): 0.9997203185510459
2019-12-23 16:58:20,161 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8394                       0.8635                0.0001                   0.1365  0.8469
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 16:58:20,208 [INFO] Results saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep2/selected_kdd99_ae_ann_shallow_rep2_results.xlsx
2019-12-23 16:58:20,215 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 16:58:20,239 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep3
2019-12-23 16:58:20,239 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep3/run_log.log
2019-12-23 16:58:20,239 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 16:58:20,239 [INFO] Experiment parameters given below
2019-12-23 16:58:20,239 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep3'}
2019-12-23 16:58:20,239 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep3/tf_logs_run_2019_12_23-16_58_20
2019-12-23 16:58:20,240 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-23 16:58:20,240 [INFO] Reading X, y files
2019-12-23 16:58:20,240 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-23 16:58:26,638 [INFO] Reading complete. time_to_read=6.40 seconds
2019-12-23 16:58:26,638 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-23 16:58:28,264 [INFO] Reading complete. time_to_read=1.63 seconds
2019-12-23 16:58:28,264 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-23 16:58:28,728 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-23 16:58:28,728 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-23 16:58:28,927 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-23 16:58:28,927 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-23 16:58:28,980 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-23 16:58:28,981 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-23 16:58:29,000 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-23 16:58:36,223 [INFO] Initializing model
2019-12-23 16:58:36,338 [INFO] _________________________________________________________________
2019-12-23 16:58:36,338 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 16:58:36,338 [INFO] =================================================================
2019-12-23 16:58:36,338 [INFO] dense_9 (Dense)              (None, 32)                3968      
2019-12-23 16:58:36,338 [INFO] _________________________________________________________________
2019-12-23 16:58:36,339 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-23 16:58:36,339 [INFO] _________________________________________________________________
2019-12-23 16:58:36,339 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-23 16:58:36,339 [INFO] _________________________________________________________________
2019-12-23 16:58:36,339 [INFO] dense_10 (Dense)             (None, 123)               4059      
2019-12-23 16:58:36,339 [INFO] =================================================================
2019-12-23 16:58:36,339 [INFO] Total params: 8,155
2019-12-23 16:58:36,339 [INFO] Trainable params: 8,091
2019-12-23 16:58:36,339 [INFO] Non-trainable params: 64
2019-12-23 16:58:36,340 [INFO] _________________________________________________________________
2019-12-23 16:58:36,560 [INFO] _________________________________________________________________
2019-12-23 16:58:36,560 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 16:58:36,560 [INFO] =================================================================
2019-12-23 16:58:36,560 [INFO] dense_11 (Dense)             (None, 32)                1056      
2019-12-23 16:58:36,561 [INFO] _________________________________________________________________
2019-12-23 16:58:36,561 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2019-12-23 16:58:36,561 [INFO] _________________________________________________________________
2019-12-23 16:58:36,561 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2019-12-23 16:58:36,561 [INFO] _________________________________________________________________
2019-12-23 16:58:36,561 [INFO] dense_12 (Dense)             (None, 5)                 165       
2019-12-23 16:58:36,561 [INFO] =================================================================
2019-12-23 16:58:36,561 [INFO] Total params: 1,349
2019-12-23 16:58:36,562 [INFO] Trainable params: 1,285
2019-12-23 16:58:36,562 [INFO] Non-trainable params: 64
2019-12-23 16:58:36,562 [INFO] _________________________________________________________________
2019-12-23 16:58:36,562 [INFO] Training model
2019-12-23 16:58:36,562 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 16:59:18,327 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 7b10bde4a3c60c551785c8fde8c04adfbf745468
2019-12-23 16:59:18,327 [INFO] Training autoencoder
 - val_f1: 0.9997
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 31s - loss: 0.5587 - val_loss: 0.5055
Epoch 2/200
 - 31s - loss: 0.4481 - val_loss: 0.4792
Epoch 3/200
 - 31s - loss: 0.4314 - val_loss: 0.4810
Epoch 4/200
 - 31s - loss: 0.4253 - val_loss: 0.5346
Epoch 5/200
 - 31s - loss: 0.4233 - val_loss: 0.6433
Epoch 6/200
 - 31s - loss: 0.4211 - val_loss: 0.4942
Epoch 7/200
 - 31s - loss: 0.4200 - val_loss: 0.5042
Epoch 8/200
 - 31s - loss: 0.4196 - val_loss: 0.5041
Epoch 9/200
 - 31s - loss: 0.4191 - val_loss: 0.5103
Epoch 10/200
 - 31s - loss: 0.4191 - val_loss: 0.5002
Epoch 11/200
 - 31s - loss: 0.4191 - val_loss: 0.4734
Epoch 12/200
 - 31s - loss: 0.4184 - val_loss: 0.4669
Epoch 13/200
 - 31s - loss: 0.4188 - val_loss: 0.4654
Epoch 14/200
 - 31s - loss: 0.4177 - val_loss: 0.4594
Epoch 15/200
 - 31s - loss: 0.4173 - val_loss: 0.4630
Epoch 16/200
 - 31s - loss: 0.4171 - val_loss: 0.4572
Epoch 17/200
 - 31s - loss: 0.4171 - val_loss: 0.4586
Epoch 18/200
 - 31s - loss: 0.4169 - val_loss: 0.4546
Epoch 19/200
 - 31s - loss: 0.4150 - val_loss: 0.4521
Epoch 20/200
 - 31s - loss: 0.4152 - val_loss: 0.4504
Epoch 21/200
 - 31s - loss: 0.4136 - val_loss: 0.4478
2019-12-23 17:10:08,151 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ae_model_epoch_20.pickle
Epoch 22/200
 - 31s - loss: 0.4143 - val_loss: 0.4512
Epoch 23/200
 - 31s - loss: 0.4133 - val_loss: 0.4572
Epoch 24/200
 - 31s - loss: 0.4117 - val_loss: 0.4759
Epoch 25/200
 - 31s - loss: 0.4103 - val_loss: 0.4918
Epoch 26/200
 - 31s - loss: 0.4099 - val_loss: 0.5152
Epoch 27/200
 - 31s - loss: 0.4100 - val_loss: 0.5044
Epoch 28/200
 - 31s - loss: 0.4090 - val_loss: 0.5230
Epoch 29/200
 - 31s - loss: 0.4060 - val_loss: 0.6634
Epoch 30/200
 - 31s - loss: 0.4066 - val_loss: 0.7298
Epoch 31/200
 - 31s - loss: 0.4078 - val_loss: 0.7768
Epoch 32/200
 - 31s - loss: 0.4043 - val_loss: 0.7558
Epoch 33/200
 - 31s - loss: 0.4057 - val_loss: 0.5862
Epoch 34/200
 - 31s - loss: 0.4034 - val_loss: 0.7021
Epoch 35/200
 - 31s - loss: 0.4033 - val_loss: 0.7581
Epoch 36/200
 - 31s - loss: 0.4018 - val_loss: 0.7819
Epoch 37/200
 - 31s - loss: 0.4007 - val_loss: 0.9265
Epoch 38/200
 - 31s - loss: 0.4013 - val_loss: 0.7116
Epoch 39/200
 - 31s - loss: 0.3992 - val_loss: 0.9097
Epoch 40/200
 - 31s - loss: 0.3999 - val_loss: 0.9099
Epoch 41/200
 - 31s - loss: 0.4010 - val_loss: 0.7998
2019-12-23 17:20:25,523 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ae_model_epoch_40.pickle
Epoch 42/200
 - 31s - loss: 0.3989 - val_loss: 0.8422
Epoch 43/200
 - 31s - loss: 0.3989 - val_loss: 0.7209
Epoch 44/200
 - 31s - loss: 0.4003 - val_loss: 0.8510
Epoch 45/200
 - 31s - loss: 0.4029 - val_loss: 0.9014
Epoch 46/200
 - 31s - loss: 0.4027 - val_loss: 0.8689
Epoch 47/200
 - 31s - loss: 0.4013 - val_loss: 0.8524
Epoch 48/200
 - 31s - loss: 0.3973 - val_loss: 0.8495
Epoch 49/200
 - 31s - loss: 0.3968 - val_loss: 0.9205
Epoch 50/200
 - 31s - loss: 0.3912 - val_loss: 0.9188
Epoch 51/200
 - 31s - loss: 0.3952 - val_loss: 0.8411
Epoch 52/200
 - 31s - loss: 0.3950 - val_loss: 0.9230
Epoch 53/200
 - 31s - loss: 0.3923 - val_loss: 0.9398
Epoch 54/200
 - 31s - loss: 0.3937 - val_loss: 0.9455
Epoch 55/200
 - 31s - loss: 0.3950 - val_loss: 0.8055
Epoch 56/200
 - 31s - loss: 0.3941 - val_loss: 0.8535
Epoch 57/200
 - 31s - loss: 0.3906 - val_loss: 0.9811
Epoch 58/200
 - 31s - loss: 0.3950 - val_loss: 0.8962
Epoch 59/200
 - 31s - loss: 0.3914 - val_loss: 0.9851
Epoch 60/200
 - 31s - loss: 0.3793 - val_loss: 0.9229
Epoch 61/200
 - 31s - loss: 0.3803 - val_loss: 0.9819
2019-12-23 17:30:43,421 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ae_model_epoch_60.pickle
Epoch 62/200
 - 31s - loss: 0.3790 - val_loss: 0.9566
Epoch 63/200
 - 31s - loss: 0.3661 - val_loss: 1.0015
Epoch 64/200
 - 31s - loss: 0.3642 - val_loss: 0.9637
Epoch 65/200
 - 31s - loss: 0.3700 - val_loss: 1.0164
Epoch 66/200
 - 31s - loss: 0.3724 - val_loss: 0.9359
Epoch 67/200
 - 31s - loss: 0.3672 - val_loss: 1.1364
Epoch 68/200
 - 31s - loss: 0.3679 - val_loss: 0.8652
Epoch 69/200
 - 31s - loss: 0.3674 - val_loss: 0.7477
Epoch 70/200
 - 31s - loss: 0.3694 - val_loss: 1.0361
Epoch 71/200
 - 31s - loss: 0.3634 - val_loss: 0.9996
2019-12-23 17:35:52,267 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 17:37:03,812 [INFO] Last epoch loss evaluation: train_loss = 0.402983, val_loss = 0.447758
2019-12-23 17:37:03,812 [INFO] Training autoencoder complete
2019-12-23 17:37:03,812 [INFO] Encoding data for supervised training
2019-12-23 17:37:57,419 [INFO] Encoding complete
2019-12-23 17:37:57,419 [INFO] Training neural network layers (after autoencoder)
Epoch 00071: early stopping
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 19s - loss: 0.0103 - val_loss: 0.0016
 - val_f1: 0.9991
Epoch 2/200
 - 18s - loss: 0.0018 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 3/200
 - 18s - loss: 0.0015 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 4/200
 - 18s - loss: 0.0012 - val_loss: 9.8136e-04
 - val_f1: 0.9995
Epoch 5/200
 - 18s - loss: 0.0012 - val_loss: 9.4234e-04
 - val_f1: 0.9994
Epoch 6/200
 - 18s - loss: 0.0011 - val_loss: 9.0672e-04
 - val_f1: 0.9995
Epoch 7/200
 - 18s - loss: 0.0011 - val_loss: 9.2679e-04
 - val_f1: 0.9994
Epoch 8/200
 - 18s - loss: 9.9741e-04 - val_loss: 8.2806e-04
 - val_f1: 0.9995
Epoch 9/200
 - 18s - loss: 9.8390e-04 - val_loss: 8.1674e-04
 - val_f1: 0.9995
Epoch 10/200
 - 18s - loss: 9.7341e-04 - val_loss: 8.5987e-04
 - val_f1: 0.9995
Epoch 11/200
 - 18s - loss: 9.5648e-04 - val_loss: 7.9608e-04
 - val_f1: 0.9995
Epoch 12/200
 - 18s - loss: 9.1673e-04 - val_loss: 7.1274e-04
 - val_f1: 0.9996
Epoch 13/200
 - 18s - loss: 9.1540e-04 - val_loss: 8.1108e-04
 - val_f1: 0.9995
Epoch 14/200
 - 18s - loss: 8.8661e-04 - val_loss: 7.3153e-04
 - val_f1: 0.9996
Epoch 15/200
 - 18s - loss: 8.8494e-04 - val_loss: 8.4271e-04
 - val_f1: 0.9994
Epoch 16/200
 - 18s - loss: 8.6116e-04 - val_loss: 7.5916e-04
 - val_f1: 0.9996
Epoch 17/200
 - 18s - loss: 8.5478e-04 - val_loss: 7.9599e-04
 - val_f1: 0.9995
Epoch 18/200
 - 18s - loss: 8.4666e-04 - val_loss: 6.6232e-04
 - val_f1: 0.9996
Epoch 19/200
 - 18s - loss: 8.3729e-04 - val_loss: 7.1768e-04
 - val_f1: 0.9996
Epoch 20/200
 - 18s - loss: 8.3160e-04 - val_loss: 6.8508e-04
 - val_f1: 0.9996
Epoch 21/200
 - 18s - loss: 8.3172e-04 - val_loss: 6.8724e-04
2019-12-23 17:49:56,842 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9996
Epoch 22/200
 - 18s - loss: 8.3851e-04 - val_loss: 6.7424e-04
 - val_f1: 0.9996
Epoch 23/200
 - 18s - loss: 8.3166e-04 - val_loss: 7.2293e-04
 - val_f1: 0.9996
Epoch 24/200
 - 18s - loss: 8.2314e-04 - val_loss: 6.7951e-04
 - val_f1: 0.9996
Epoch 25/200
 - 18s - loss: 7.9251e-04 - val_loss: 7.0133e-04
 - val_f1: 0.9996
Epoch 26/200
 - 18s - loss: 7.8129e-04 - val_loss: 6.8247e-04
 - val_f1: 0.9996
Epoch 27/200
 - 18s - loss: 7.7338e-04 - val_loss: 6.5101e-04
 - val_f1: 0.9996
Epoch 28/200
 - 18s - loss: 8.0821e-04 - val_loss: 6.5465e-04
 - val_f1: 0.9996
Epoch 29/200
 - 18s - loss: 7.7334e-04 - val_loss: 6.6138e-04
 - val_f1: 0.9996
Epoch 30/200
 - 18s - loss: 7.9665e-04 - val_loss: 6.4324e-04
 - val_f1: 0.9997
Epoch 31/200
 - 18s - loss: 7.7386e-04 - val_loss: 6.7318e-04
 - val_f1: 0.9996
Epoch 32/200
 - 18s - loss: 7.7764e-04 - val_loss: 6.2490e-04
 - val_f1: 0.9996
Epoch 33/200
 - 18s - loss: 7.4447e-04 - val_loss: 6.6211e-04
 - val_f1: 0.9996
Epoch 34/200
 - 18s - loss: 7.3310e-04 - val_loss: 6.4982e-04
 - val_f1: 0.9996
Epoch 35/200
 - 18s - loss: 7.7692e-04 - val_loss: 6.3901e-04
 - val_f1: 0.9996
Epoch 36/200
 - 18s - loss: 7.5618e-04 - val_loss: 7.2924e-04
 - val_f1: 0.9995
Epoch 37/200
 - 18s - loss: 7.4670e-04 - val_loss: 6.8942e-04
 - val_f1: 0.9996
Epoch 38/200
 - 18s - loss: 7.5692e-04 - val_loss: 6.4517e-04
 - val_f1: 0.9997
Epoch 39/200
 - 18s - loss: 7.5578e-04 - val_loss: 6.9120e-04
 - val_f1: 0.9996
Epoch 40/200
 - 18s - loss: 7.5317e-04 - val_loss: 6.4352e-04
 - val_f1: 0.9997
Epoch 41/200
 - 18s - loss: 7.4854e-04 - val_loss: 6.1677e-04
2019-12-23 18:01:36,756 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9997
Epoch 42/200
 - 18s - loss: 7.3593e-04 - val_loss: 6.9128e-04
 - val_f1: 0.9996
Epoch 43/200
 - 18s - loss: 7.5004e-04 - val_loss: 6.6277e-04
 - val_f1: 0.9997
Epoch 44/200
 - 18s - loss: 7.2585e-04 - val_loss: 6.7749e-04
 - val_f1: 0.9996
Epoch 45/200
 - 18s - loss: 7.2101e-04 - val_loss: 6.3321e-04
 - val_f1: 0.9997
Epoch 46/200
 - 18s - loss: 7.3897e-04 - val_loss: 6.2950e-04
 - val_f1: 0.9996
Epoch 47/200
 - 18s - loss: 7.0723e-04 - val_loss: 6.1484e-04
 - val_f1: 0.9996
Epoch 48/200
 - 18s - loss: 7.0531e-04 - val_loss: 6.0834e-04
 - val_f1: 0.9997
Epoch 49/200
 - 18s - loss: 7.6015e-04 - val_loss: 6.1202e-04
 - val_f1: 0.9996
Epoch 50/200
 - 18s - loss: 7.3171e-04 - val_loss: 6.5133e-04
 - val_f1: 0.9996
Epoch 51/200
 - 18s - loss: 6.8910e-04 - val_loss: 6.6664e-04
 - val_f1: 0.9996
Epoch 52/200
 - 18s - loss: 6.8853e-04 - val_loss: 5.8842e-04
 - val_f1: 0.9996
Epoch 53/200
 - 18s - loss: 6.8666e-04 - val_loss: 6.6807e-04
 - val_f1: 0.9996
Epoch 54/200
 - 18s - loss: 6.8908e-04 - val_loss: 5.6799e-04
 - val_f1: 0.9997
Epoch 55/200
 - 18s - loss: 6.8051e-04 - val_loss: 6.1049e-04
 - val_f1: 0.9996
Epoch 56/200
 - 18s - loss: 6.9335e-04 - val_loss: 6.3312e-04
 - val_f1: 0.9996
Epoch 57/200
 - 18s - loss: 6.9370e-04 - val_loss: 5.7875e-04
 - val_f1: 0.9997
Epoch 58/200
 - 18s - loss: 6.8012e-04 - val_loss: 6.1595e-04
 - val_f1: 0.9997
Epoch 59/200
 - 18s - loss: 6.7268e-04 - val_loss: 6.2901e-04
 - val_f1: 0.9997
Epoch 60/200
 - 18s - loss: 6.7614e-04 - val_loss: 6.3602e-04
 - val_f1: 0.9996
Epoch 61/200
 - 18s - loss: 6.9342e-04 - val_loss: 6.2827e-04
2019-12-23 18:13:16,166 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9996
Epoch 62/200
 - 18s - loss: 6.5684e-04 - val_loss: 6.3014e-04
 - val_f1: 0.9996
Epoch 63/200
 - 18s - loss: 6.6747e-04 - val_loss: 6.4825e-04
 - val_f1: 0.9996
Epoch 64/200
 - 18s - loss: 6.7338e-04 - val_loss: 6.1010e-04
 - val_f1: 0.9996
Epoch 65/200
 - 18s - loss: 6.9117e-04 - val_loss: 6.1175e-04
 - val_f1: 0.9996
Epoch 66/200
 - 18s - loss: 6.7818e-04 - val_loss: 6.6005e-04
 - val_f1: 0.9996
Epoch 67/200
 - 18s - loss: 6.5894e-04 - val_loss: 6.0496e-04
 - val_f1: 0.9997
Epoch 68/200
 - 18s - loss: 6.9078e-04 - val_loss: 6.0877e-04
 - val_f1: 0.9996
Epoch 69/200
 - 18s - loss: 6.7157e-04 - val_loss: 5.7347e-04
 - val_f1: 0.9996
Epoch 70/200
 - 18s - loss: 6.6086e-04 - val_loss: 6.2948e-04
 - val_f1: 0.9996
Epoch 71/200
 - 18s - loss: 6.6780e-04 - val_loss: 6.6538e-04
 - val_f1: 0.9996
Epoch 72/200
 - 18s - loss: 6.5799e-04 - val_loss: 6.6088e-04
 - val_f1: 0.9996
Epoch 73/200
 - 18s - loss: 6.6063e-04 - val_loss: 5.7580e-04
 - val_f1: 0.9997
Epoch 74/200
 - 18s - loss: 6.3587e-04 - val_loss: 5.8567e-04
 - val_f1: 0.9997
Epoch 75/200
 - 18s - loss: 6.5002e-04 - val_loss: 5.8306e-04
 - val_f1: 0.9997
Epoch 76/200
 - 18s - loss: 6.5927e-04 - val_loss: 6.2830e-04
 - val_f1: 0.9996
Epoch 77/200
 - 18s - loss: 6.9216e-04 - val_loss: 6.0294e-04
 - val_f1: 0.9996
Epoch 78/200
 - 18s - loss: 6.4997e-04 - val_loss: 6.1902e-04
 - val_f1: 0.9997
Epoch 79/200
 - 18s - loss: 6.4185e-04 - val_loss: 5.8931e-04
 - val_f1: 0.9997
Epoch 80/200
 - 18s - loss: 6.5187e-04 - val_loss: 5.5963e-04
 - val_f1: 0.9997
Epoch 81/200
 - 18s - loss: 6.5505e-04 - val_loss: 6.3478e-04
2019-12-23 18:24:55,169 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9996
Epoch 82/200
 - 18s - loss: 6.5023e-04 - val_loss: 5.5833e-04
 - val_f1: 0.9997
Epoch 83/200
 - 18s - loss: 6.4384e-04 - val_loss: 6.0924e-04
 - val_f1: 0.9996
Epoch 84/200
 - 18s - loss: 6.4367e-04 - val_loss: 5.9100e-04
 - val_f1: 0.9996
Epoch 85/200
 - 18s - loss: 6.4052e-04 - val_loss: 5.7906e-04
 - val_f1: 0.9996
Epoch 86/200
 - 18s - loss: 6.4655e-04 - val_loss: 6.0041e-04
 - val_f1: 0.9997
Epoch 87/200
 - 18s - loss: 6.2413e-04 - val_loss: 5.4194e-04
 - val_f1: 0.9997
Epoch 88/200
 - 18s - loss: 6.2834e-04 - val_loss: 5.8851e-04
 - val_f1: 0.9997
Epoch 89/200
 - 18s - loss: 6.2169e-04 - val_loss: 5.8161e-04
 - val_f1: 0.9997
Epoch 90/200
 - 18s - loss: 6.3702e-04 - val_loss: 5.8528e-04
 - val_f1: 0.9997
Epoch 91/200
 - 18s - loss: 6.4046e-04 - val_loss: 6.0416e-04
 - val_f1: 0.9997
Epoch 92/200
 - 18s - loss: 6.3361e-04 - val_loss: 5.5897e-04
 - val_f1: 0.9997
Epoch 93/200
 - 18s - loss: 6.4160e-04 - val_loss: 6.2400e-04
 - val_f1: 0.9996
Epoch 94/200
 - 18s - loss: 6.2632e-04 - val_loss: 6.4159e-04
 - val_f1: 0.9997
Epoch 95/200
 - 18s - loss: 6.4916e-04 - val_loss: 5.8094e-04
 - val_f1: 0.9997
Epoch 96/200
 - 18s - loss: 6.2879e-04 - val_loss: 5.9181e-04
 - val_f1: 0.9997
Epoch 97/200
 - 18s - loss: 6.3662e-04 - val_loss: 5.7931e-04
 - val_f1: 0.9997
Epoch 98/200
 - 18s - loss: 6.3383e-04 - val_loss: 5.3646e-04
 - val_f1: 0.9997
Epoch 99/200
 - 18s - loss: 6.3108e-04 - val_loss: 5.6971e-04
 - val_f1: 0.9997
Epoch 100/200
 - 18s - loss: 6.2634e-04 - val_loss: 5.8435e-04
 - val_f1: 0.9997
Epoch 101/200
 - 18s - loss: 6.2163e-04 - val_loss: 5.5914e-04
2019-12-23 18:36:34,120 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9997
Epoch 102/200
 - 18s - loss: 6.1154e-04 - val_loss: 5.5055e-04
 - val_f1: 0.9997
Epoch 103/200
 - 18s - loss: 6.0493e-04 - val_loss: 6.0411e-04
 - val_f1: 0.9996
Epoch 104/200
 - 18s - loss: 6.3693e-04 - val_loss: 5.7827e-04
 - val_f1: 0.9996
Epoch 105/200
 - 18s - loss: 6.1352e-04 - val_loss: 5.9945e-04
 - val_f1: 0.9997
Epoch 106/200
 - 18s - loss: 6.0111e-04 - val_loss: 5.9051e-04
 - val_f1: 0.9997
Epoch 107/200
 - 18s - loss: 6.2112e-04 - val_loss: 6.1159e-04
 - val_f1: 0.9997
Epoch 108/200
 - 18s - loss: 6.2279e-04 - val_loss: 5.9499e-04
 - val_f1: 0.9997
Epoch 109/200
 - 18s - loss: 6.1074e-04 - val_loss: 5.6785e-04
 - val_f1: 0.9996
Epoch 110/200
 - 18s - loss: 6.2421e-04 - val_loss: 5.5989e-04
 - val_f1: 0.9997
Epoch 111/200
 - 18s - loss: 6.3439e-04 - val_loss: 5.5807e-04
 - val_f1: 0.9997
Epoch 112/200
 - 18s - loss: 6.2150e-04 - val_loss: 5.9322e-04
 - val_f1: 0.9997
Epoch 113/200
 - 18s - loss: 6.1578e-04 - val_loss: 5.9643e-04
 - val_f1: 0.9997
Epoch 114/200
 - 18s - loss: 5.9104e-04 - val_loss: 5.7632e-04
 - val_f1: 0.9997
Epoch 115/200
 - 18s - loss: 6.3725e-04 - val_loss: 5.6454e-04
 - val_f1: 0.9997
Epoch 116/200
 - 18s - loss: 5.9398e-04 - val_loss: 5.6055e-04
 - val_f1: 0.9997
Epoch 117/200
 - 18s - loss: 6.0318e-04 - val_loss: 5.4945e-04
 - val_f1: 0.9997
Epoch 118/200
 - 18s - loss: 5.9023e-04 - val_loss: 5.5799e-04
 - val_f1: 0.9997
Epoch 119/200
 - 18s - loss: 6.1482e-04 - val_loss: 5.4109e-04
 - val_f1: 0.9997
Epoch 120/200
 - 18s - loss: 6.0312e-04 - val_loss: 5.8541e-04
 - val_f1: 0.9997
Epoch 121/200
 - 18s - loss: 6.1583e-04 - val_loss: 5.7362e-04
2019-12-23 18:48:12,494 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/200
 - 18s - loss: 6.0169e-04 - val_loss: 6.2643e-04
 - val_f1: 0.9997
Epoch 123/200
 - 18s - loss: 5.9868e-04 - val_loss: 5.5835e-04
 - val_f1: 0.9997
Epoch 124/200
 - 18s - loss: 6.0639e-04 - val_loss: 5.9082e-04
 - val_f1: 0.9997
Epoch 125/200
 - 18s - loss: 6.0809e-04 - val_loss: 5.8120e-04
 - val_f1: 0.9997
Epoch 126/200
 - 18s - loss: 6.0374e-04 - val_loss: 5.5658e-04
 - val_f1: 0.9997
Epoch 127/200
 - 18s - loss: 5.8472e-04 - val_loss: 5.9995e-04
 - val_f1: 0.9996
Epoch 128/200
 - 18s - loss: 6.1460e-04 - val_loss: 5.5879e-04
 - val_f1: 0.9997
Epoch 129/200
 - 18s - loss: 6.2726e-04 - val_loss: 5.4983e-04
 - val_f1: 0.9997
Epoch 130/200
 - 18s - loss: 6.2941e-04 - val_loss: 5.6033e-04
 - val_f1: 0.9997
Epoch 131/200
 - 18s - loss: 6.0943e-04 - val_loss: 6.3275e-04
 - val_f1: 0.9997
Epoch 132/200
 - 18s - loss: 6.0959e-04 - val_loss: 5.4856e-04
 - val_f1: 0.9997
Epoch 133/200
 - 18s - loss: 6.0940e-04 - val_loss: 5.6006e-04
 - val_f1: 0.9997
Epoch 134/200
 - 18s - loss: 6.1787e-04 - val_loss: 5.5726e-04
 - val_f1: 0.9997
Epoch 135/200
 - 18s - loss: 6.0258e-04 - val_loss: 5.7018e-04
 - val_f1: 0.9997
Epoch 136/200
 - 18s - loss: 5.9359e-04 - val_loss: 5.6997e-04
 - val_f1: 0.9997
Epoch 137/200
 - 18s - loss: 5.8335e-04 - val_loss: 5.2996e-04
 - val_f1: 0.9997
Epoch 138/200
 - 18s - loss: 5.7782e-04 - val_loss: 5.6335e-04
 - val_f1: 0.9997
Epoch 139/200
 - 18s - loss: 5.8977e-04 - val_loss: 5.3413e-04
 - val_f1: 0.9997
Epoch 140/200
 - 18s - loss: 6.0666e-04 - val_loss: 5.6180e-04
 - val_f1: 0.9997
Epoch 141/200
 - 18s - loss: 5.9651e-04 - val_loss: 5.4398e-04
2019-12-23 18:59:51,498 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9997
Epoch 142/200
 - 18s - loss: 5.7025e-04 - val_loss: 5.6486e-04
 - val_f1: 0.9997
Epoch 143/200
 - 18s - loss: 5.9789e-04 - val_loss: 5.8541e-04
 - val_f1: 0.9997
Epoch 144/200
 - 18s - loss: 6.0236e-04 - val_loss: 5.6799e-04
 - val_f1: 0.9997
Epoch 145/200
 - 18s - loss: 5.9429e-04 - val_loss: 6.2560e-04
 - val_f1: 0.9997
Epoch 146/200
 - 18s - loss: 5.6819e-04 - val_loss: 5.8012e-04
 - val_f1: 0.9997
Epoch 147/200
 - 18s - loss: 5.8717e-04 - val_loss: 5.6752e-04
 - val_f1: 0.9997
Epoch 148/200
 - 18s - loss: 6.0971e-04 - val_loss: 5.6550e-04
 - val_f1: 0.9997
Epoch 149/200
 - 18s - loss: 5.8534e-04 - val_loss: 5.3807e-04
 - val_f1: 0.9997
Epoch 150/200
 - 18s - loss: 5.8935e-04 - val_loss: 5.7213e-04
 - val_f1: 0.9997
Epoch 151/200
 - 18s - loss: 5.6853e-04 - val_loss: 5.9875e-04
 - val_f1: 0.9996
Epoch 152/200
 - 18s - loss: 5.8236e-04 - val_loss: 5.6148e-04
 - val_f1: 0.9997
Epoch 153/200
 - 18s - loss: 5.7770e-04 - val_loss: 5.7980e-04
 - val_f1: 0.9997
Epoch 154/200
 - 18s - loss: 5.5443e-04 - val_loss: 5.2986e-04
 - val_f1: 0.9997
Epoch 155/200
 - 18s - loss: 6.0101e-04 - val_loss: 5.5651e-04
 - val_f1: 0.9997
Epoch 156/200
 - 18s - loss: 5.9231e-04 - val_loss: 5.5461e-04
 - val_f1: 0.9997
Epoch 157/200
 - 18s - loss: 6.0256e-04 - val_loss: 5.4943e-04
 - val_f1: 0.9997
Epoch 158/200
 - 18s - loss: 5.7138e-04 - val_loss: 5.8722e-04
 - val_f1: 0.9997
Epoch 159/200
 - 18s - loss: 5.5792e-04 - val_loss: 5.5720e-04
 - val_f1: 0.9997
Epoch 160/200
 - 18s - loss: 5.7341e-04 - val_loss: 5.5272e-04
 - val_f1: 0.9997
Epoch 161/200
 - 18s - loss: 5.8948e-04 - val_loss: 5.2975e-04
2019-12-23 19:11:30,418 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_160.pickle
 - val_f1: 0.9997
Epoch 162/200
 - 18s - loss: 5.6392e-04 - val_loss: 5.6142e-04
 - val_f1: 0.9997
Epoch 163/200
 - 18s - loss: 5.8735e-04 - val_loss: 5.7228e-04
 - val_f1: 0.9997
Epoch 164/200
 - 18s - loss: 5.8733e-04 - val_loss: 5.6802e-04
 - val_f1: 0.9997
Epoch 165/200
 - 18s - loss: 5.8095e-04 - val_loss: 5.3716e-04
 - val_f1: 0.9998
Epoch 166/200
 - 18s - loss: 5.2939e-04 - val_loss: 5.8204e-04
 - val_f1: 0.9997
Epoch 167/200
 - 18s - loss: 5.6671e-04 - val_loss: 5.5891e-04
 - val_f1: 0.9997
Epoch 168/200
 - 18s - loss: 5.9352e-04 - val_loss: 5.4472e-04
 - val_f1: 0.9997
Epoch 169/200
 - 18s - loss: 5.8833e-04 - val_loss: 5.3242e-04
 - val_f1: 0.9998
Epoch 170/200
 - 18s - loss: 5.7613e-04 - val_loss: 5.2711e-04
 - val_f1: 0.9997
Epoch 171/200
 - 18s - loss: 5.6414e-04 - val_loss: 5.8479e-04
 - val_f1: 0.9997
Epoch 172/200
 - 18s - loss: 5.7337e-04 - val_loss: 5.5624e-04
 - val_f1: 0.9996
Epoch 173/200
 - 18s - loss: 5.6854e-04 - val_loss: 5.3952e-04
 - val_f1: 0.9997
Epoch 174/200
 - 18s - loss: 5.7805e-04 - val_loss: 5.5270e-04
 - val_f1: 0.9997
Epoch 175/200
 - 18s - loss: 5.7250e-04 - val_loss: 5.8745e-04
 - val_f1: 0.9997
Epoch 176/200
 - 18s - loss: 5.7120e-04 - val_loss: 6.0286e-04
 - val_f1: 0.9997
Epoch 177/200
 - 18s - loss: 5.6547e-04 - val_loss: 5.3085e-04
 - val_f1: 0.9997
Epoch 178/200
 - 18s - loss: 5.5668e-04 - val_loss: 5.1702e-04
 - val_f1: 0.9997
Epoch 179/200
 - 18s - loss: 5.3929e-04 - val_loss: 6.4246e-04
 - val_f1: 0.9997
Epoch 180/200
 - 18s - loss: 5.7742e-04 - val_loss: 5.8650e-04
 - val_f1: 0.9997
Epoch 181/200
 - 18s - loss: 5.8365e-04 - val_loss: 5.3346e-04
2019-12-23 19:23:08,497 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9997
Epoch 182/200
 - 18s - loss: 5.9170e-04 - val_loss: 5.8778e-04
 - val_f1: 0.9997
Epoch 183/200
 - 18s - loss: 5.8375e-04 - val_loss: 5.5815e-04
 - val_f1: 0.9997
Epoch 184/200
 - 18s - loss: 5.7344e-04 - val_loss: 5.4564e-04
 - val_f1: 0.9997
Epoch 185/200
 - 18s - loss: 5.6904e-04 - val_loss: 5.3439e-04
 - val_f1: 0.9997
Epoch 186/200
 - 18s - loss: 5.8180e-04 - val_loss: 5.5205e-04
 - val_f1: 0.9997
Epoch 187/200
 - 18s - loss: 5.6965e-04 - val_loss: 5.4232e-04
 - val_f1: 0.9997
Epoch 188/200
 - 18s - loss: 5.5758e-04 - val_loss: 5.4406e-04
 - val_f1: 0.9997
Epoch 189/200
 - 18s - loss: 5.6493e-04 - val_loss: 5.2774e-04
 - val_f1: 0.9998
Epoch 190/200
 - 18s - loss: 5.6909e-04 - val_loss: 5.5916e-04
 - val_f1: 0.9998
Epoch 191/200
 - 18s - loss: 5.7810e-04 - val_loss: 5.3853e-04
 - val_f1: 0.9997
Epoch 192/200
 - 18s - loss: 5.5245e-04 - val_loss: 5.4577e-04
 - val_f1: 0.9997
Epoch 193/200
 - 18s - loss: 5.6063e-04 - val_loss: 5.5984e-04
 - val_f1: 0.9997
Epoch 194/200
 - 18s - loss: 5.4884e-04 - val_loss: 5.4783e-04
 - val_f1: 0.9998
Epoch 195/200
 - 18s - loss: 5.9277e-04 - val_loss: 5.3183e-04
 - val_f1: 0.9998
Epoch 196/200
 - 18s - loss: 5.7602e-04 - val_loss: 5.8106e-04
 - val_f1: 0.9997
Epoch 197/200
 - 18s - loss: 5.5675e-04 - val_loss: 5.7852e-04
 - val_f1: 0.9997
Epoch 198/200
 - 18s - loss: 5.7631e-04 - val_loss: 5.9343e-04
 - val_f1: 0.9997
Epoch 199/200
 - 18s - loss: 5.6415e-04 - val_loss: 5.4726e-04
 - val_f1: 0.9997
Epoch 200/200
 - 18s - loss: 5.4448e-04 - val_loss: 5.2586e-04
2019-12-23 19:34:28,826 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 19:35:29,632 [INFO] Last epoch loss evaluation: train_loss = 0.000365, val_loss = 0.000517
2019-12-23 19:35:29,655 [INFO] Training complete. time_to_train = 9413.09 sec, 156.88 min
2019-12-23 19:35:29,664 [INFO] Model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep3/best_model.pickle
2019-12-23 19:35:29,846 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep3/training_error_history.png
2019-12-23 19:35:30,030 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep3/training_f1_history.png
2019-12-23 19:35:30,030 [INFO] Making predictions on training, validation, testing data
2019-12-23 19:38:30,813 [INFO] Evaluating predictions (results)
2019-12-23 19:38:39,506 [INFO] Dataset: Testing. Classification report below
2019-12-23 19:38:39,506 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.74      0.74      0.74      4166
         r2l       0.84      0.06      0.10     13781
         u2r       0.70      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.80      0.55      0.54    311029
weighted avg       0.93      0.92      0.91    311029

2019-12-23 19:38:39,506 [INFO] Overall accuracy (micro avg): 0.9232258085258931
2019-12-23 19:38:48,808 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9232         0.9232                       0.9232                0.0192                   0.0768  0.9232
1     Macro avg        0.9693         0.8006                       0.5517                0.0196                   0.4483  0.5356
2  Weighted avg        0.9677         0.9326                       0.9232                0.0213                   0.0768  0.9059
2019-12-23 19:39:19,034 [INFO] Dataset: Validation. Classification report below
2019-12-23 19:39:19,034 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.99      0.99      8221
         r2l       0.91      0.77      0.84       225
         u2r       0.50      0.20      0.29        10

    accuracy                           1.00    979687
   macro avg       0.88      0.79      0.82    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-23 19:39:19,034 [INFO] Overall accuracy (micro avg): 0.9997386920516451
2019-12-23 19:39:51,652 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8805                       0.7928                0.0001                   0.2072  0.8227
2  Weighted avg        0.9999         0.9997                       0.9997                0.0002                   0.0003  0.9997
2019-12-23 19:42:05,218 [INFO] Dataset: Training. Classification report below
2019-12-23 19:42:05,219 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.92      0.82      0.87       901
         u2r       0.73      0.45      0.56        42

    accuracy                           1.00   3918744
   macro avg       0.93      0.85      0.88   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-23 19:42:05,219 [INFO] Overall accuracy (micro avg): 0.9997624238786713
2019-12-23 19:44:29,438 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0001                   0.0002  0.9998
1     Macro avg        0.9999         0.9292                       0.8517                0.0001                   0.1483  0.8833
2  Weighted avg        0.9999         0.9998                       0.9998                0.0002                   0.0002  0.9998
2019-12-23 19:44:29,486 [INFO] Results saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep3/selected_kdd99_ae_ann_shallow_rep3_results.xlsx
2019-12-23 19:44:29,494 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 19:44:29,518 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep4
2019-12-23 19:44:29,518 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep4/run_log.log
2019-12-23 19:44:29,518 [INFO] ================= Running experiment no. 4  ================= 

2019-12-23 19:44:29,518 [INFO] Experiment parameters given below
2019-12-23 19:44:29,518 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep4', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep4'}
2019-12-23 19:44:29,518 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep4/tf_logs_run_2019_12_23-19_44_29
2019-12-23 19:44:29,519 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-23 19:44:29,519 [INFO] Reading X, y files
2019-12-23 19:44:29,519 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-23 19:44:35,911 [INFO] Reading complete. time_to_read=6.39 seconds
2019-12-23 19:44:35,911 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-23 19:44:37,535 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-23 19:44:37,536 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-23 19:44:38,005 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-23 19:44:38,006 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-23 19:44:38,202 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-23 19:44:38,202 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-23 19:44:38,255 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-23 19:44:38,255 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-23 19:44:38,274 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-23 19:44:45,441 [INFO] Initializing model
2019-12-23 19:44:45,557 [INFO] _________________________________________________________________
2019-12-23 19:44:45,557 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 19:44:45,557 [INFO] =================================================================
2019-12-23 19:44:45,558 [INFO] dense_13 (Dense)             (None, 32)                3968      
2019-12-23 19:44:45,558 [INFO] _________________________________________________________________
2019-12-23 19:44:45,558 [INFO] batch_normalization_7 (Batch (None, 32)                128       
2019-12-23 19:44:45,558 [INFO] _________________________________________________________________
2019-12-23 19:44:45,558 [INFO] dropout_7 (Dropout)          (None, 32)                0         
2019-12-23 19:44:45,558 [INFO] _________________________________________________________________
2019-12-23 19:44:45,558 [INFO] dense_14 (Dense)             (None, 123)               4059      
2019-12-23 19:44:45,558 [INFO] =================================================================
2019-12-23 19:44:45,558 [INFO] Total params: 8,155
2019-12-23 19:44:45,558 [INFO] Trainable params: 8,091
2019-12-23 19:44:45,558 [INFO] Non-trainable params: 64
2019-12-23 19:44:45,559 [INFO] _________________________________________________________________
2019-12-23 19:44:45,791 [INFO] _________________________________________________________________
2019-12-23 19:44:45,791 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 19:44:45,791 [INFO] =================================================================
2019-12-23 19:44:45,792 [INFO] dense_15 (Dense)             (None, 32)                1056      
2019-12-23 19:44:45,792 [INFO] _________________________________________________________________
2019-12-23 19:44:45,792 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-23 19:44:45,792 [INFO] _________________________________________________________________
2019-12-23 19:44:45,792 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-23 19:44:45,792 [INFO] _________________________________________________________________
2019-12-23 19:44:45,792 [INFO] dense_16 (Dense)             (None, 5)                 165       
2019-12-23 19:44:45,792 [INFO] =================================================================
2019-12-23 19:44:45,792 [INFO] Total params: 1,349
2019-12-23 19:44:45,792 [INFO] Trainable params: 1,285
2019-12-23 19:44:45,792 [INFO] Non-trainable params: 64
2019-12-23 19:44:45,792 [INFO] _________________________________________________________________
2019-12-23 19:44:45,793 [INFO] Training model
2019-12-23 19:44:45,793 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 19:45:27,017 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = ee3502406600692897e97b54f832a2153f307c17
2019-12-23 19:45:27,017 [INFO] Training autoencoder
 - val_f1: 0.9997
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 32s - loss: 0.6379 - val_loss: 0.6469
Epoch 2/200
 - 32s - loss: 0.5610 - val_loss: 0.6339
Epoch 3/200
 - 32s - loss: 0.5404 - val_loss: 0.6643
Epoch 4/200
 - 32s - loss: 0.5283 - val_loss: 0.7306
Epoch 5/200
 - 32s - loss: 0.5243 - val_loss: 0.7198
Epoch 6/200
 - 32s - loss: 0.5067 - val_loss: 0.6591
Epoch 7/200
 - 32s - loss: 0.4961 - val_loss: 0.6332
Epoch 8/200
 - 32s - loss: 0.4957 - val_loss: 0.6486
Epoch 9/200
 - 32s - loss: 0.4862 - val_loss: 0.5935
Epoch 10/200
 - 32s - loss: 0.4789 - val_loss: 0.5913
Epoch 11/200
 - 32s - loss: 0.4776 - val_loss: 0.5669
Epoch 12/200
 - 32s - loss: 0.4762 - val_loss: 0.5645
Epoch 13/200
 - 32s - loss: 0.4754 - val_loss: 0.5695
Epoch 14/200
 - 32s - loss: 0.4751 - val_loss: 0.5556
Epoch 15/200
 - 32s - loss: 0.4736 - val_loss: 0.5645
Epoch 16/200
 - 32s - loss: 0.4739 - val_loss: 0.5579
Epoch 17/200
 - 32s - loss: 0.4713 - val_loss: 0.5520
Epoch 18/200
 - 32s - loss: 0.4655 - val_loss: 0.5632
Epoch 19/200
 - 32s - loss: 0.4633 - val_loss: 0.5621
Epoch 20/200
 - 32s - loss: 0.4632 - val_loss: 0.6128
Epoch 21/200
 - 32s - loss: 0.4627 - val_loss: 0.6130
2019-12-23 19:56:35,623 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ae_model_epoch_20.pickle
Epoch 22/200
 - 32s - loss: 0.4624 - val_loss: 0.6432
Epoch 23/200
 - 31s - loss: 0.4629 - val_loss: 0.6925
Epoch 24/200
 - 31s - loss: 0.4605 - val_loss: 0.7097
Epoch 25/200
 - 32s - loss: 0.4567 - val_loss: 0.7146
Epoch 26/200
 - 31s - loss: 0.4538 - val_loss: 0.8351
Epoch 27/200
 - 31s - loss: 0.4523 - val_loss: 0.8603
Epoch 28/200
 - 32s - loss: 0.4514 - val_loss: 0.9410
Epoch 29/200
 - 31s - loss: 0.4522 - val_loss: 0.7822
Epoch 30/200
 - 31s - loss: 0.4537 - val_loss: 0.8611
Epoch 31/200
 - 31s - loss: 0.4512 - val_loss: 0.8045
Epoch 32/200
 - 31s - loss: 0.4529 - val_loss: 1.1527
Epoch 33/200
 - 31s - loss: 0.4508 - val_loss: 1.1405
Epoch 34/200
 - 32s - loss: 0.4507 - val_loss: 1.3032
Epoch 35/200
 - 31s - loss: 0.4486 - val_loss: 0.8910
Epoch 36/200
 - 32s - loss: 0.4501 - val_loss: 1.2901
Epoch 37/200
 - 32s - loss: 0.4465 - val_loss: 1.3063
Epoch 38/200
 - 31s - loss: 0.4429 - val_loss: 1.2077
Epoch 39/200
 - 31s - loss: 0.4442 - val_loss: 1.4768
Epoch 40/200
 - 32s - loss: 0.4376 - val_loss: 1.9831
Epoch 41/200
 - 32s - loss: 0.4356 - val_loss: 2.1849
2019-12-23 20:07:05,640 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ae_model_epoch_40.pickle
Epoch 42/200
 - 31s - loss: 0.4326 - val_loss: 2.2569
Epoch 43/200
 - 31s - loss: 0.4311 - val_loss: 2.3464
Epoch 44/200
 - 32s - loss: 0.4328 - val_loss: 1.6742
Epoch 45/200
 - 31s - loss: 0.4331 - val_loss: 2.1298
Epoch 46/200
 - 31s - loss: 0.4343 - val_loss: 2.1967
Epoch 47/200
 - 32s - loss: 0.4350 - val_loss: 2.2250
Epoch 48/200
 - 31s - loss: 0.4310 - val_loss: 1.9182
Epoch 49/200
 - 31s - loss: 0.4315 - val_loss: 2.0184
Epoch 50/200
 - 31s - loss: 0.4311 - val_loss: 2.2887
Epoch 51/200
 - 31s - loss: 0.4315 - val_loss: 1.1345
Epoch 52/200
 - 31s - loss: 0.4333 - val_loss: 1.3415
Epoch 53/200
 - 32s - loss: 0.4316 - val_loss: 2.2318
Epoch 54/200
 - 31s - loss: 0.4310 - val_loss: 2.2478
Epoch 55/200
 - 31s - loss: 0.4311 - val_loss: 1.7919
Epoch 56/200
 - 32s - loss: 0.4301 - val_loss: 2.5171
Epoch 57/200
 - 31s - loss: 0.4300 - val_loss: 2.6407
Epoch 58/200
 - 31s - loss: 0.4320 - val_loss: 2.3907
Epoch 59/200
 - 31s - loss: 0.4296 - val_loss: 2.5156
Epoch 60/200
 - 32s - loss: 0.4338 - val_loss: 2.5040
Epoch 61/200
 - 32s - loss: 0.4294 - val_loss: 2.7020
2019-12-23 20:17:35,342 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ae_model_epoch_60.pickle
Epoch 62/200
 - 31s - loss: 0.4285 - val_loss: 2.4996
Epoch 63/200
 - 31s - loss: 0.4310 - val_loss: 2.5152
Epoch 64/200
 - 31s - loss: 0.4323 - val_loss: 1.3305
Epoch 65/200
 - 32s - loss: 0.4331 - val_loss: 2.2915
Epoch 66/200
 - 32s - loss: 0.4324 - val_loss: 2.1464
Epoch 67/200
 - 32s - loss: 0.4346 - val_loss: 2.2393
2019-12-23 20:20:44,535 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 20:21:57,652 [INFO] Last epoch loss evaluation: train_loss = 0.482351, val_loss = 0.552024
2019-12-23 20:21:57,652 [INFO] Training autoencoder complete
2019-12-23 20:21:57,652 [INFO] Encoding data for supervised training
2019-12-23 20:22:53,723 [INFO] Encoding complete
2019-12-23 20:22:53,723 [INFO] Training neural network layers (after autoencoder)
Epoch 00067: early stopping
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 20s - loss: 0.0107 - val_loss: 0.0038
 - val_f1: 0.9985
Epoch 2/200
 - 19s - loss: 0.0028 - val_loss: 0.0019
 - val_f1: 0.9988
Epoch 3/200
 - 19s - loss: 0.0018 - val_loss: 0.0022
 - val_f1: 0.9987
Epoch 4/200
 - 19s - loss: 0.0015 - val_loss: 0.0019
 - val_f1: 0.9991
Epoch 5/200
 - 19s - loss: 0.0014 - val_loss: 0.0013
 - val_f1: 0.9993
Epoch 6/200
 - 19s - loss: 0.0013 - val_loss: 0.0014
 - val_f1: 0.9993
Epoch 7/200
 - 19s - loss: 0.0013 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 8/200
 - 19s - loss: 0.0012 - val_loss: 9.0933e-04
 - val_f1: 0.9995
Epoch 9/200
 - 19s - loss: 0.0012 - val_loss: 0.0012
 - val_f1: 0.9992
Epoch 10/200
 - 19s - loss: 0.0011 - val_loss: 9.6344e-04
 - val_f1: 0.9994
Epoch 11/200
 - 19s - loss: 0.0011 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 12/200
 - 19s - loss: 0.0010 - val_loss: 9.1594e-04
 - val_f1: 0.9995
Epoch 13/200
 - 19s - loss: 0.0010 - val_loss: 7.9652e-04
 - val_f1: 0.9995
Epoch 14/200
 - 19s - loss: 0.0010 - val_loss: 9.6096e-04
 - val_f1: 0.9995
Epoch 15/200
 - 19s - loss: 0.0010 - val_loss: 8.3413e-04
 - val_f1: 0.9995
Epoch 16/200
 - 19s - loss: 9.9730e-04 - val_loss: 7.9811e-04
 - val_f1: 0.9995
Epoch 17/200
 - 19s - loss: 9.6972e-04 - val_loss: 8.6019e-04
 - val_f1: 0.9995
Epoch 18/200
 - 19s - loss: 9.7850e-04 - val_loss: 7.8852e-04
 - val_f1: 0.9995
Epoch 19/200
 - 19s - loss: 9.2351e-04 - val_loss: 9.9742e-04
 - val_f1: 0.9994
Epoch 20/200
 - 19s - loss: 9.6374e-04 - val_loss: 0.0010
 - val_f1: 0.9995
Epoch 21/200
 - 19s - loss: 9.3871e-04 - val_loss: 9.3065e-04
2019-12-23 20:35:31,251 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_20.pickle
 - val_f1: 0.9995
Epoch 22/200
 - 19s - loss: 9.3427e-04 - val_loss: 7.9774e-04
 - val_f1: 0.9996
Epoch 23/200
 - 19s - loss: 9.5021e-04 - val_loss: 8.1053e-04
 - val_f1: 0.9996
Epoch 24/200
 - 19s - loss: 9.3173e-04 - val_loss: 8.1758e-04
 - val_f1: 0.9995
Epoch 25/200
 - 19s - loss: 9.1275e-04 - val_loss: 7.5937e-04
 - val_f1: 0.9996
Epoch 26/200
 - 19s - loss: 8.7040e-04 - val_loss: 7.8825e-04
 - val_f1: 0.9996
Epoch 27/200
 - 19s - loss: 8.9839e-04 - val_loss: 8.9938e-04
 - val_f1: 0.9995
Epoch 28/200
 - 19s - loss: 8.6789e-04 - val_loss: 9.0065e-04
 - val_f1: 0.9995
Epoch 29/200
 - 19s - loss: 8.9549e-04 - val_loss: 9.0925e-04
 - val_f1: 0.9995
Epoch 30/200
 - 19s - loss: 8.7499e-04 - val_loss: 9.2030e-04
 - val_f1: 0.9996
Epoch 31/200
 - 19s - loss: 8.8322e-04 - val_loss: 8.5670e-04
 - val_f1: 0.9996
Epoch 32/200
 - 19s - loss: 8.6384e-04 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 33/200
 - 19s - loss: 8.5937e-04 - val_loss: 8.1482e-04
 - val_f1: 0.9996
Epoch 34/200
 - 19s - loss: 8.7874e-04 - val_loss: 9.8712e-04
 - val_f1: 0.9995
Epoch 35/200
 - 19s - loss: 8.5051e-04 - val_loss: 7.7318e-04
 - val_f1: 0.9996
Epoch 36/200
 - 19s - loss: 8.3169e-04 - val_loss: 7.6667e-04
 - val_f1: 0.9996
Epoch 37/200
 - 19s - loss: 8.5368e-04 - val_loss: 7.3930e-04
 - val_f1: 0.9996
Epoch 38/200
 - 19s - loss: 8.4035e-04 - val_loss: 8.2327e-04
 - val_f1: 0.9995
Epoch 39/200
 - 19s - loss: 8.5510e-04 - val_loss: 8.3216e-04
 - val_f1: 0.9996
Epoch 40/200
 - 19s - loss: 8.3774e-04 - val_loss: 7.4031e-04
 - val_f1: 0.9996
Epoch 41/200
 - 19s - loss: 8.3414e-04 - val_loss: 7.3531e-04
2019-12-23 20:47:49,251 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_40.pickle
 - val_f1: 0.9996
Epoch 42/200
 - 19s - loss: 8.3311e-04 - val_loss: 7.6266e-04
 - val_f1: 0.9996
Epoch 43/200
 - 19s - loss: 8.0926e-04 - val_loss: 7.9720e-04
 - val_f1: 0.9996
Epoch 44/200
 - 19s - loss: 8.2728e-04 - val_loss: 8.3733e-04
 - val_f1: 0.9995
Epoch 45/200
 - 19s - loss: 8.1694e-04 - val_loss: 7.8863e-04
 - val_f1: 0.9996
Epoch 46/200
 - 19s - loss: 8.1131e-04 - val_loss: 7.2669e-04
 - val_f1: 0.9996
Epoch 47/200
 - 19s - loss: 8.1297e-04 - val_loss: 8.7600e-04
 - val_f1: 0.9995
Epoch 48/200
 - 19s - loss: 8.1628e-04 - val_loss: 7.4248e-04
 - val_f1: 0.9996
Epoch 49/200
 - 19s - loss: 7.7328e-04 - val_loss: 7.2339e-04
 - val_f1: 0.9996
Epoch 50/200
 - 19s - loss: 7.9362e-04 - val_loss: 7.5034e-04
 - val_f1: 0.9996
Epoch 51/200
 - 19s - loss: 7.8591e-04 - val_loss: 7.9365e-04
 - val_f1: 0.9995
Epoch 52/200
 - 19s - loss: 7.9954e-04 - val_loss: 7.5977e-04
 - val_f1: 0.9995
Epoch 53/200
 - 19s - loss: 7.5330e-04 - val_loss: 6.8605e-04
 - val_f1: 0.9996
Epoch 54/200
 - 19s - loss: 7.8678e-04 - val_loss: 6.9826e-04
 - val_f1: 0.9996
Epoch 55/200
 - 19s - loss: 7.5702e-04 - val_loss: 8.6616e-04
 - val_f1: 0.9996
Epoch 56/200
 - 19s - loss: 7.6028e-04 - val_loss: 7.3178e-04
 - val_f1: 0.9996
Epoch 57/200
 - 19s - loss: 7.4994e-04 - val_loss: 6.9207e-04
 - val_f1: 0.9996
Epoch 58/200
 - 19s - loss: 7.7162e-04 - val_loss: 7.0368e-04
 - val_f1: 0.9996
Epoch 59/200
 - 19s - loss: 7.5878e-04 - val_loss: 6.8871e-04
 - val_f1: 0.9996
Epoch 60/200
 - 19s - loss: 7.8752e-04 - val_loss: 7.4121e-04
 - val_f1: 0.9996
Epoch 61/200
 - 19s - loss: 7.6821e-04 - val_loss: 6.9486e-04
2019-12-23 21:00:06,734 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9996
Epoch 62/200
 - 19s - loss: 7.4497e-04 - val_loss: 8.0977e-04
 - val_f1: 0.9996
Epoch 63/200
 - 19s - loss: 7.5901e-04 - val_loss: 6.9042e-04
 - val_f1: 0.9996
Epoch 64/200
 - 19s - loss: 7.4158e-04 - val_loss: 7.2681e-04
 - val_f1: 0.9996
Epoch 65/200
 - 19s - loss: 7.6042e-04 - val_loss: 7.2010e-04
 - val_f1: 0.9996
Epoch 66/200
 - 19s - loss: 7.4386e-04 - val_loss: 7.0813e-04
 - val_f1: 0.9996
Epoch 67/200
 - 19s - loss: 7.9193e-04 - val_loss: 8.3950e-04
 - val_f1: 0.9995
Epoch 68/200
 - 19s - loss: 7.5113e-04 - val_loss: 7.4514e-04
 - val_f1: 0.9996
Epoch 69/200
 - 19s - loss: 7.7484e-04 - val_loss: 6.9194e-04
 - val_f1: 0.9996
Epoch 70/200
 - 19s - loss: 7.5082e-04 - val_loss: 7.3685e-04
 - val_f1: 0.9996
Epoch 71/200
 - 19s - loss: 7.4459e-04 - val_loss: 8.1584e-04
 - val_f1: 0.9995
Epoch 72/200
 - 19s - loss: 7.5019e-04 - val_loss: 7.4325e-04
 - val_f1: 0.9996
Epoch 73/200
 - 19s - loss: 7.5098e-04 - val_loss: 7.0457e-04
 - val_f1: 0.9997
Epoch 74/200
 - 19s - loss: 7.5495e-04 - val_loss: 7.5714e-04
 - val_f1: 0.9996
Epoch 75/200
 - 19s - loss: 7.3708e-04 - val_loss: 7.0540e-04
 - val_f1: 0.9996
Epoch 76/200
 - 19s - loss: 7.6821e-04 - val_loss: 7.2299e-04
 - val_f1: 0.9996
Epoch 77/200
 - 19s - loss: 7.3164e-04 - val_loss: 7.1248e-04
 - val_f1: 0.9996
Epoch 78/200
 - 19s - loss: 7.4020e-04 - val_loss: 7.4365e-04
 - val_f1: 0.9996
Epoch 79/200
 - 19s - loss: 7.5202e-04 - val_loss: 6.5517e-04
 - val_f1: 0.9997
Epoch 80/200
 - 19s - loss: 7.1950e-04 - val_loss: 6.9599e-04
 - val_f1: 0.9997
Epoch 81/200
 - 19s - loss: 7.4050e-04 - val_loss: 7.0222e-04
2019-12-23 21:12:23,810 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_80.pickle
 - val_f1: 0.9996
Epoch 82/200
 - 19s - loss: 7.3412e-04 - val_loss: 6.7105e-04
 - val_f1: 0.9996
Epoch 83/200
 - 19s - loss: 7.4269e-04 - val_loss: 7.7146e-04
 - val_f1: 0.9996
Epoch 84/200
 - 19s - loss: 7.1883e-04 - val_loss: 6.8886e-04
 - val_f1: 0.9997
Epoch 85/200
 - 19s - loss: 7.4228e-04 - val_loss: 6.5109e-04
 - val_f1: 0.9997
Epoch 86/200
 - 19s - loss: 7.2682e-04 - val_loss: 7.2813e-04
 - val_f1: 0.9996
Epoch 87/200
 - 19s - loss: 7.1654e-04 - val_loss: 6.9052e-04
 - val_f1: 0.9996
Epoch 88/200
 - 19s - loss: 7.2195e-04 - val_loss: 7.0401e-04
 - val_f1: 0.9997
Epoch 89/200
 - 19s - loss: 7.1399e-04 - val_loss: 7.1110e-04
 - val_f1: 0.9996
Epoch 90/200
 - 19s - loss: 7.0052e-04 - val_loss: 6.8771e-04
 - val_f1: 0.9996
Epoch 91/200
 - 19s - loss: 7.1007e-04 - val_loss: 7.0483e-04
 - val_f1: 0.9996
Epoch 92/200
 - 19s - loss: 7.2272e-04 - val_loss: 7.1193e-04
 - val_f1: 0.9997
Epoch 93/200
 - 19s - loss: 7.1714e-04 - val_loss: 6.9925e-04
 - val_f1: 0.9996
Epoch 94/200
 - 19s - loss: 7.2971e-04 - val_loss: 6.7604e-04
 - val_f1: 0.9996
Epoch 95/200
 - 19s - loss: 7.1555e-04 - val_loss: 6.3645e-04
 - val_f1: 0.9997
Epoch 96/200
 - 19s - loss: 7.2117e-04 - val_loss: 7.1959e-04
 - val_f1: 0.9996
Epoch 97/200
 - 19s - loss: 6.9980e-04 - val_loss: 0.0013
 - val_f1: 0.9994
Epoch 98/200
 - 19s - loss: 7.2458e-04 - val_loss: 7.0515e-04
 - val_f1: 0.9996
Epoch 99/200
 - 19s - loss: 7.0800e-04 - val_loss: 6.9272e-04
 - val_f1: 0.9996
Epoch 100/200
 - 19s - loss: 7.1766e-04 - val_loss: 7.0490e-04
 - val_f1: 0.9996
Epoch 101/200
 - 19s - loss: 7.0825e-04 - val_loss: 7.4748e-04
2019-12-23 21:24:40,354 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_100.pickle
 - val_f1: 0.9997
Epoch 102/200
 - 19s - loss: 7.2858e-04 - val_loss: 7.8159e-04
 - val_f1: 0.9996
Epoch 103/200
 - 19s - loss: 7.1887e-04 - val_loss: 0.0010
 - val_f1: 0.9996
Epoch 104/200
 - 19s - loss: 7.1817e-04 - val_loss: 7.8015e-04
 - val_f1: 0.9996
Epoch 105/200
 - 19s - loss: 7.1490e-04 - val_loss: 6.5455e-04
 - val_f1: 0.9997
Epoch 106/200
 - 19s - loss: 7.1386e-04 - val_loss: 6.4846e-04
 - val_f1: 0.9996
Epoch 107/200
 - 19s - loss: 7.2402e-04 - val_loss: 7.8240e-04
 - val_f1: 0.9996
Epoch 108/200
 - 19s - loss: 7.0005e-04 - val_loss: 0.0013
 - val_f1: 0.9995
Epoch 109/200
 - 19s - loss: 6.9421e-04 - val_loss: 6.7594e-04
 - val_f1: 0.9997
Epoch 110/200
 - 19s - loss: 6.8867e-04 - val_loss: 7.0582e-04
 - val_f1: 0.9996
Epoch 111/200
 - 19s - loss: 6.8886e-04 - val_loss: 7.5897e-04
 - val_f1: 0.9996
Epoch 112/200
 - 19s - loss: 6.5947e-04 - val_loss: 6.6509e-04
 - val_f1: 0.9997
Epoch 113/200
 - 19s - loss: 7.0622e-04 - val_loss: 7.0034e-04
 - val_f1: 0.9996
Epoch 114/200
 - 19s - loss: 7.0364e-04 - val_loss: 8.1364e-04
 - val_f1: 0.9996
Epoch 115/200
 - 19s - loss: 7.0537e-04 - val_loss: 7.2615e-04
 - val_f1: 0.9996
Epoch 116/200
 - 19s - loss: 6.8695e-04 - val_loss: 6.5643e-04
 - val_f1: 0.9996
Epoch 117/200
 - 19s - loss: 6.8810e-04 - val_loss: 6.9737e-04
 - val_f1: 0.9997
Epoch 118/200
 - 19s - loss: 7.1634e-04 - val_loss: 6.8963e-04
 - val_f1: 0.9996
Epoch 119/200
 - 19s - loss: 6.9242e-04 - val_loss: 6.7287e-04
 - val_f1: 0.9997
Epoch 120/200
 - 19s - loss: 7.1546e-04 - val_loss: 6.9020e-04
 - val_f1: 0.9996
Epoch 121/200
 - 19s - loss: 6.8739e-04 - val_loss: 6.3802e-04
2019-12-23 21:36:58,423 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9997
Epoch 122/200
 - 19s - loss: 6.7814e-04 - val_loss: 6.7534e-04
 - val_f1: 0.9996
Epoch 123/200
 - 19s - loss: 6.8908e-04 - val_loss: 6.6481e-04
 - val_f1: 0.9996
Epoch 124/200
 - 19s - loss: 6.8861e-04 - val_loss: 6.5521e-04
 - val_f1: 0.9997
Epoch 125/200
 - 19s - loss: 6.8410e-04 - val_loss: 6.7839e-04
 - val_f1: 0.9997
Epoch 126/200
 - 19s - loss: 6.6984e-04 - val_loss: 6.3045e-04
 - val_f1: 0.9996
Epoch 127/200
 - 19s - loss: 6.9990e-04 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 128/200
 - 19s - loss: 7.2088e-04 - val_loss: 6.5157e-04
 - val_f1: 0.9997
Epoch 129/200
 - 19s - loss: 6.8391e-04 - val_loss: 6.2453e-04
 - val_f1: 0.9997
Epoch 130/200
 - 19s - loss: 6.9116e-04 - val_loss: 6.3686e-04
 - val_f1: 0.9997
Epoch 131/200
 - 19s - loss: 6.9234e-04 - val_loss: 6.8060e-04
 - val_f1: 0.9997
Epoch 132/200
 - 19s - loss: 6.8200e-04 - val_loss: 6.3986e-04
 - val_f1: 0.9997
Epoch 133/200
 - 19s - loss: 6.4209e-04 - val_loss: 6.7266e-04
 - val_f1: 0.9997
Epoch 134/200
 - 19s - loss: 6.9007e-04 - val_loss: 6.3823e-04
 - val_f1: 0.9997
Epoch 135/200
 - 19s - loss: 6.8032e-04 - val_loss: 7.1795e-04
 - val_f1: 0.9996
Epoch 136/200
 - 19s - loss: 6.9550e-04 - val_loss: 6.5213e-04
 - val_f1: 0.9997
Epoch 137/200
 - 19s - loss: 6.7038e-04 - val_loss: 6.5832e-04
 - val_f1: 0.9997
Epoch 138/200
 - 19s - loss: 6.9084e-04 - val_loss: 6.8730e-04
 - val_f1: 0.9997
Epoch 139/200
 - 19s - loss: 6.5992e-04 - val_loss: 6.8395e-04
 - val_f1: 0.9997
Epoch 140/200
 - 19s - loss: 6.8193e-04 - val_loss: 6.4827e-04
 - val_f1: 0.9996
Epoch 141/200
 - 19s - loss: 6.6137e-04 - val_loss: 7.1730e-04
2019-12-23 21:49:15,417 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_140.pickle
 - val_f1: 0.9995
Epoch 142/200
 - 19s - loss: 6.6990e-04 - val_loss: 7.2437e-04
 - val_f1: 0.9997
Epoch 143/200
 - 19s - loss: 6.7610e-04 - val_loss: 6.3729e-04
 - val_f1: 0.9997
Epoch 144/200
 - 19s - loss: 6.5608e-04 - val_loss: 6.7412e-04
 - val_f1: 0.9996
Epoch 145/200
 - 19s - loss: 6.6134e-04 - val_loss: 6.9363e-04
 - val_f1: 0.9996
Epoch 146/200
 - 19s - loss: 6.9568e-04 - val_loss: 6.4577e-04
 - val_f1: 0.9997
Epoch 147/200
 - 19s - loss: 6.8655e-04 - val_loss: 7.4126e-04
 - val_f1: 0.9996
Epoch 148/200
 - 19s - loss: 6.6324e-04 - val_loss: 6.9212e-04
 - val_f1: 0.9996
Epoch 149/200
 - 19s - loss: 6.9030e-04 - val_loss: 8.6748e-04
 - val_f1: 0.9996
Epoch 150/200
 - 19s - loss: 6.6172e-04 - val_loss: 6.6813e-04
 - val_f1: 0.9997
Epoch 151/200
 - 19s - loss: 6.7579e-04 - val_loss: 6.0743e-04
 - val_f1: 0.9997
Epoch 152/200
 - 19s - loss: 6.7577e-04 - val_loss: 7.3292e-04
 - val_f1: 0.9997
Epoch 153/200
 - 19s - loss: 6.6031e-04 - val_loss: 6.6978e-04
 - val_f1: 0.9997
Epoch 154/200
 - 19s - loss: 6.5056e-04 - val_loss: 6.7476e-04
 - val_f1: 0.9997
Epoch 155/200
 - 19s - loss: 6.5919e-04 - val_loss: 7.1409e-04
 - val_f1: 0.9996
Epoch 156/200
 - 19s - loss: 6.5847e-04 - val_loss: 6.3944e-04
 - val_f1: 0.9997
Epoch 157/200
 - 19s - loss: 6.6900e-04 - val_loss: 6.1243e-04
 - val_f1: 0.9997
Epoch 158/200
 - 19s - loss: 6.4916e-04 - val_loss: 6.5331e-04
 - val_f1: 0.9997
Epoch 159/200
 - 19s - loss: 6.4871e-04 - val_loss: 6.5773e-04
 - val_f1: 0.9997
Epoch 160/200
 - 19s - loss: 6.7472e-04 - val_loss: 6.7201e-04
 - val_f1: 0.9997
Epoch 161/200
 - 19s - loss: 6.5880e-04 - val_loss: 6.6222e-04
2019-12-23 22:01:33,119 [INFO] epoch = 160. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_160.pickle
 - val_f1: 0.9997
Epoch 162/200
 - 19s - loss: 6.7068e-04 - val_loss: 6.4627e-04
 - val_f1: 0.9997
Epoch 163/200
 - 19s - loss: 6.6592e-04 - val_loss: 6.4581e-04
 - val_f1: 0.9997
Epoch 164/200
 - 19s - loss: 6.5289e-04 - val_loss: 6.4801e-04
 - val_f1: 0.9997
Epoch 165/200
 - 19s - loss: 6.4485e-04 - val_loss: 6.7650e-04
 - val_f1: 0.9997
Epoch 166/200
 - 19s - loss: 6.6764e-04 - val_loss: 6.7247e-04
 - val_f1: 0.9996
Epoch 167/200
 - 19s - loss: 6.5933e-04 - val_loss: 6.2212e-04
 - val_f1: 0.9996
Epoch 168/200
 - 19s - loss: 6.5347e-04 - val_loss: 6.6871e-04
 - val_f1: 0.9997
Epoch 169/200
 - 19s - loss: 6.2830e-04 - val_loss: 6.2226e-04
 - val_f1: 0.9997
Epoch 170/200
 - 19s - loss: 6.7647e-04 - val_loss: 6.4658e-04
 - val_f1: 0.9997
Epoch 171/200
 - 19s - loss: 6.4571e-04 - val_loss: 6.8707e-04
 - val_f1: 0.9997
Epoch 172/200
 - 19s - loss: 6.4403e-04 - val_loss: 6.3969e-04
 - val_f1: 0.9996
Epoch 173/200
 - 19s - loss: 6.8332e-04 - val_loss: 6.3411e-04
 - val_f1: 0.9997
Epoch 174/200
 - 19s - loss: 6.6003e-04 - val_loss: 6.7447e-04
 - val_f1: 0.9997
Epoch 175/200
 - 19s - loss: 6.4934e-04 - val_loss: 6.2917e-04
 - val_f1: 0.9996
Epoch 176/200
 - 19s - loss: 6.8293e-04 - val_loss: 6.8106e-04
 - val_f1: 0.9996
Epoch 177/200
 - 19s - loss: 6.6610e-04 - val_loss: 6.8795e-04
 - val_f1: 0.9997
Epoch 178/200
 - 19s - loss: 6.5241e-04 - val_loss: 6.3754e-04
 - val_f1: 0.9996
Epoch 179/200
 - 19s - loss: 6.7819e-04 - val_loss: 7.1301e-04
 - val_f1: 0.9997
Epoch 180/200
 - 19s - loss: 6.5307e-04 - val_loss: 6.5769e-04
 - val_f1: 0.9997
Epoch 181/200
 - 19s - loss: 6.5463e-04 - val_loss: 7.3637e-04
2019-12-23 22:13:50,354 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9996
Epoch 182/200
 - 19s - loss: 6.3442e-04 - val_loss: 6.4412e-04
 - val_f1: 0.9997
Epoch 183/200
 - 19s - loss: 6.5257e-04 - val_loss: 6.8390e-04
 - val_f1: 0.9997
Epoch 184/200
 - 19s - loss: 6.4185e-04 - val_loss: 6.8846e-04
 - val_f1: 0.9996
Epoch 185/200
 - 19s - loss: 6.7790e-04 - val_loss: 6.2464e-04
 - val_f1: 0.9997
Epoch 186/200
 - 19s - loss: 6.4504e-04 - val_loss: 7.1495e-04
 - val_f1: 0.9997
Epoch 187/200
 - 19s - loss: 6.4991e-04 - val_loss: 8.5356e-04
 - val_f1: 0.9994
Epoch 188/200
 - 19s - loss: 6.6262e-04 - val_loss: 6.2726e-04
 - val_f1: 0.9996
Epoch 189/200
 - 19s - loss: 6.6317e-04 - val_loss: 6.2170e-04
 - val_f1: 0.9997
Epoch 190/200
 - 19s - loss: 6.4532e-04 - val_loss: 6.5476e-04
 - val_f1: 0.9997
Epoch 191/200
 - 19s - loss: 6.5083e-04 - val_loss: 6.7908e-04
 - val_f1: 0.9996
Epoch 192/200
 - 19s - loss: 6.5834e-04 - val_loss: 6.3956e-04
 - val_f1: 0.9997
Epoch 193/200
 - 19s - loss: 6.4396e-04 - val_loss: 6.7377e-04
 - val_f1: 0.9997
Epoch 194/200
 - 19s - loss: 6.5959e-04 - val_loss: 6.8563e-04
 - val_f1: 0.9997
Epoch 195/200
 - 19s - loss: 6.5517e-04 - val_loss: 8.3141e-04
 - val_f1: 0.9996
Epoch 196/200
 - 19s - loss: 6.3510e-04 - val_loss: 6.5711e-04
 - val_f1: 0.9997
Epoch 197/200
 - 19s - loss: 6.4985e-04 - val_loss: 6.5468e-04
 - val_f1: 0.9997
Epoch 198/200
 - 19s - loss: 6.4267e-04 - val_loss: 6.9350e-04
 - val_f1: 0.9997
Epoch 199/200
 - 19s - loss: 6.6284e-04 - val_loss: 8.2898e-04
 - val_f1: 0.9996
Epoch 200/200
 - 19s - loss: 6.4954e-04 - val_loss: 6.5464e-04
2019-12-23 22:25:48,449 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 22:26:50,830 [INFO] Last epoch loss evaluation: train_loss = 0.000454, val_loss = 0.000607
2019-12-23 22:26:50,852 [INFO] Training complete. time_to_train = 9725.06 sec, 162.08 min
2019-12-23 22:26:50,861 [INFO] Model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep4/best_model.pickle
2019-12-23 22:26:51,044 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep4/training_error_history.png
2019-12-23 22:26:51,223 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep4/training_f1_history.png
2019-12-23 22:26:51,224 [INFO] Making predictions on training, validation, testing data
2019-12-23 22:30:01,243 [INFO] Evaluating predictions (results)
2019-12-23 22:30:09,923 [INFO] Dataset: Testing. Classification report below
2019-12-23 22:30:09,923 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.76      0.76      0.76      4166
         r2l       0.05      0.00      0.00     13781
         u2r       0.69      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.64      0.54      0.52    311029
weighted avg       0.90      0.92      0.90    311029

2019-12-23 22:30:09,924 [INFO] Overall accuracy (micro avg): 0.9214606998061274
2019-12-23 22:30:19,222 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9215         0.9215                       0.9215                0.0196                   0.0785  0.9215
1     Macro avg        0.9686         0.6446                       0.5448                0.0198                   0.4552  0.5186
2  Weighted avg        0.9678         0.8971                       0.9215                0.0206                   0.0785  0.9013
2019-12-23 22:30:49,556 [INFO] Dataset: Validation. Classification report below
2019-12-23 22:30:49,556 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.98      0.99      8221
         r2l       0.86      0.74      0.79       225
         u2r       0.18      0.20      0.19        10

    accuracy                           1.00    979687
   macro avg       0.81      0.78      0.79    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-23 22:30:49,556 [INFO] Overall accuracy (micro avg): 0.9996621369886505
2019-12-23 22:31:22,280 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8061                       0.7843                0.0001                   0.2157  0.7942
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 22:33:36,149 [INFO] Dataset: Training. Classification report below
2019-12-23 22:33:36,150 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.98      0.99     32881
         r2l       0.88      0.76      0.82       901
         u2r       0.43      0.48      0.45        42

    accuracy                           1.00   3918744
   macro avg       0.86      0.84      0.85   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-23 22:33:36,150 [INFO] Overall accuracy (micro avg): 0.9996856135537305
2019-12-23 22:36:00,620 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8602                       0.8444                0.0001                   0.1556  0.8511
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-23 22:36:00,667 [INFO] Results saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep4/selected_kdd99_ae_ann_shallow_rep4_results.xlsx
2019-12-23 22:36:00,674 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-23 22:36:00,697 [INFO] Created directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep5
2019-12-23 22:36:00,698 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_ae_ann_shallow_rep5/run_log.log
2019-12-23 22:36:00,698 [INFO] ================= Running experiment no. 5  ================= 

2019-12-23 22:36:00,698 [INFO] Experiment parameters given below
2019-12-23 22:36:00,698 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_kdd99_ae_ann_shallow_rep5', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.5, 'ae_encoder_units': [32], 'ae_encoder_activations': ['relu'], 'ae_encoder_dropout_rates': [0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': '', 'ae_decoder_activations': '', 'ae_decoder_dropout_rates': '', 'output_activation': 'relu', 'loss_function': 'mean_squared_error', 'ae_epochs': 200, 'ann_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_ae_ann_shallow_rep5'}
2019-12-23 22:36:00,698 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_ae_ann_shallow_rep5/tf_logs_run_2019_12_23-22_36_00
2019-12-23 22:36:00,698 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-23 22:36:00,698 [INFO] Reading X, y files
2019-12-23 22:36:00,698 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-23 22:36:07,126 [INFO] Reading complete. time_to_read=6.43 seconds
2019-12-23 22:36:07,126 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-23 22:36:08,779 [INFO] Reading complete. time_to_read=1.65 seconds
2019-12-23 22:36:08,779 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-23 22:36:09,250 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-23 22:36:09,250 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-23 22:36:09,451 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-23 22:36:09,451 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-23 22:36:09,505 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-23 22:36:09,505 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-23 22:36:09,524 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-23 22:36:16,785 [INFO] Initializing model
2019-12-23 22:36:16,902 [INFO] _________________________________________________________________
2019-12-23 22:36:16,902 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 22:36:16,903 [INFO] =================================================================
2019-12-23 22:36:16,903 [INFO] dense_17 (Dense)             (None, 32)                3968      
2019-12-23 22:36:16,903 [INFO] _________________________________________________________________
2019-12-23 22:36:16,903 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-23 22:36:16,903 [INFO] _________________________________________________________________
2019-12-23 22:36:16,903 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-23 22:36:16,903 [INFO] _________________________________________________________________
2019-12-23 22:36:16,903 [INFO] dense_18 (Dense)             (None, 123)               4059      
2019-12-23 22:36:16,903 [INFO] =================================================================
2019-12-23 22:36:16,903 [INFO] Total params: 8,155
2019-12-23 22:36:16,903 [INFO] Trainable params: 8,091
2019-12-23 22:36:16,904 [INFO] Non-trainable params: 64
2019-12-23 22:36:16,904 [INFO] _________________________________________________________________
2019-12-23 22:36:17,024 [INFO] _________________________________________________________________
2019-12-23 22:36:17,024 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 22:36:17,024 [INFO] =================================================================
2019-12-23 22:36:17,024 [INFO] dense_19 (Dense)             (None, 32)                1056      
2019-12-23 22:36:17,024 [INFO] _________________________________________________________________
2019-12-23 22:36:17,024 [INFO] batch_normalization_10 (Batc (None, 32)                128       
2019-12-23 22:36:17,024 [INFO] _________________________________________________________________
2019-12-23 22:36:17,024 [INFO] dropout_10 (Dropout)         (None, 32)                0         
2019-12-23 22:36:17,024 [INFO] _________________________________________________________________
2019-12-23 22:36:17,025 [INFO] dense_20 (Dense)             (None, 5)                 165       
2019-12-23 22:36:17,025 [INFO] =================================================================
2019-12-23 22:36:17,025 [INFO] Total params: 1,349
2019-12-23 22:36:17,025 [INFO] Trainable params: 1,285
2019-12-23 22:36:17,025 [INFO] Non-trainable params: 64
2019-12-23 22:36:17,025 [INFO] _________________________________________________________________
2019-12-23 22:36:17,025 [INFO] Training model
2019-12-23 22:36:17,025 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 22:37:00,697 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 82497191ada387f6f8afc8dee3920a2a0faa9c53
2019-12-23 22:37:00,697 [INFO] Training autoencoder
 - val_f1: 0.9997
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 33s - loss: 0.5680 - val_loss: 0.5394
Epoch 2/200
 - 33s - loss: 0.4659 - val_loss: 0.5274
Epoch 3/200
 - 32s - loss: 0.4501 - val_loss: 0.5404
Epoch 4/200
 - 33s - loss: 0.4370 - val_loss: 0.6108
Epoch 5/200
 - 32s - loss: 0.4270 - val_loss: 0.6173
Epoch 6/200
 - 33s - loss: 0.4276 - val_loss: 0.5338
Epoch 7/200
 - 32s - loss: 0.4196 - val_loss: 0.5002
Epoch 8/200
 - 33s - loss: 0.4162 - val_loss: 0.5097
Epoch 9/200
 - 32s - loss: 0.4099 - val_loss: 0.4731
Epoch 10/200
 - 33s - loss: 0.4027 - val_loss: 0.4580
Epoch 11/200
 - 32s - loss: 0.3955 - val_loss: 0.4743
Epoch 12/200
 - 33s - loss: 0.3950 - val_loss: 0.4554
Epoch 13/200
 - 32s - loss: 0.3977 - val_loss: 0.4423
Epoch 14/200
 - 33s - loss: 0.3956 - val_loss: 0.4468
Epoch 15/200
 - 33s - loss: 0.3922 - val_loss: 0.4474
Epoch 16/200
 - 33s - loss: 0.3918 - val_loss: 0.4491
Epoch 17/200
 - 32s - loss: 0.3936 - val_loss: 0.4559
Epoch 18/200
 - 33s - loss: 0.3944 - val_loss: 0.4513
Epoch 19/200
 - 33s - loss: 0.3930 - val_loss: 0.4441
Epoch 20/200
 - 33s - loss: 0.3913 - val_loss: 0.4482
Epoch 21/200
 - 32s - loss: 0.3912 - val_loss: 0.4436
2019-12-23 22:48:26,888 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ae_model_epoch_20.pickle
Epoch 22/200
 - 32s - loss: 0.3940 - val_loss: 0.4738
Epoch 23/200
 - 32s - loss: 0.3923 - val_loss: 0.4577
Epoch 24/200
 - 33s - loss: 0.3917 - val_loss: 0.4409
Epoch 25/200
 - 32s - loss: 0.3880 - val_loss: 0.4386
Epoch 26/200
 - 32s - loss: 0.3846 - val_loss: 0.4370
Epoch 27/200
 - 32s - loss: 0.3804 - val_loss: 0.4360
Epoch 28/200
 - 32s - loss: 0.3752 - val_loss: 0.4661
Epoch 29/200
 - 32s - loss: 0.3749 - val_loss: 0.4603
Epoch 30/200
 - 32s - loss: 0.3720 - val_loss: 0.4503
Epoch 31/200
 - 32s - loss: 0.3723 - val_loss: 0.4434
Epoch 32/200
 - 32s - loss: 0.3720 - val_loss: 0.4505
Epoch 33/200
 - 32s - loss: 0.3738 - val_loss: 0.4366
Epoch 34/200
 - 33s - loss: 0.3720 - val_loss: 0.4294
Epoch 35/200
 - 32s - loss: 0.3749 - val_loss: 0.4248
Epoch 36/200
 - 32s - loss: 0.3710 - val_loss: 0.4679
Epoch 37/200
 - 32s - loss: 0.3645 - val_loss: 0.3945
Epoch 38/200
 - 32s - loss: 0.3631 - val_loss: 0.4051
Epoch 39/200
 - 32s - loss: 0.3656 - val_loss: 0.4024
Epoch 40/200
 - 32s - loss: 0.3609 - val_loss: 0.3942
Epoch 41/200
 - 32s - loss: 0.3620 - val_loss: 0.3956
2019-12-23 22:59:14,170 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ae_model_epoch_40.pickle
Epoch 42/200
 - 32s - loss: 0.3621 - val_loss: 0.3811
Epoch 43/200
 - 32s - loss: 0.3604 - val_loss: 0.4458
Epoch 44/200
 - 32s - loss: 0.3579 - val_loss: 0.4537
Epoch 45/200
 - 32s - loss: 0.3565 - val_loss: 0.4824
Epoch 46/200
 - 32s - loss: 0.3580 - val_loss: 0.5110
Epoch 47/200
 - 32s - loss: 0.3590 - val_loss: 0.5660
Epoch 48/200
 - 32s - loss: 0.3623 - val_loss: 0.5897
Epoch 49/200
 - 32s - loss: 0.3643 - val_loss: 0.6127
Epoch 50/200
 - 32s - loss: 0.3598 - val_loss: 0.6190
Epoch 51/200
 - 32s - loss: 0.3591 - val_loss: 0.6707
Epoch 52/200
 - 32s - loss: 0.3596 - val_loss: 0.6365
Epoch 53/200
 - 32s - loss: 0.3583 - val_loss: 0.7074
Epoch 54/200
 - 32s - loss: 0.3623 - val_loss: 0.6955
Epoch 55/200
 - 32s - loss: 0.3565 - val_loss: 0.7609
Epoch 56/200
 - 32s - loss: 0.3618 - val_loss: 0.7643
Epoch 57/200
 - 32s - loss: 0.3574 - val_loss: 0.7622
Epoch 58/200
 - 32s - loss: 0.3593 - val_loss: 0.7153
Epoch 59/200
 - 32s - loss: 0.3584 - val_loss: 0.8813
Epoch 60/200
 - 32s - loss: 0.3563 - val_loss: 0.7843
Epoch 61/200
 - 32s - loss: 0.3549 - val_loss: 0.7797
2019-12-23 23:10:01,667 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ae_model_epoch_60.pickle
Epoch 62/200
 - 32s - loss: 0.3560 - val_loss: 0.8327
Epoch 63/200
 - 32s - loss: 0.3568 - val_loss: 0.7634
Epoch 64/200
 - 32s - loss: 0.3533 - val_loss: 0.7518
Epoch 65/200
 - 32s - loss: 0.3541 - val_loss: 0.7227
Epoch 66/200
 - 33s - loss: 0.3580 - val_loss: 0.6891
Epoch 67/200
 - 32s - loss: 0.3553 - val_loss: 0.7137
Epoch 68/200
 - 32s - loss: 0.3571 - val_loss: 0.6528
Epoch 69/200
 - 32s - loss: 0.3550 - val_loss: 0.7117
Epoch 70/200
 - 32s - loss: 0.3535 - val_loss: 0.7391
Epoch 71/200
 - 32s - loss: 0.3524 - val_loss: 0.6477
Epoch 72/200
 - 32s - loss: 0.3511 - val_loss: 0.6929
Epoch 73/200
 - 32s - loss: 0.3519 - val_loss: 0.6256
Epoch 74/200
 - 33s - loss: 0.3522 - val_loss: 0.6136
Epoch 75/200
 - 32s - loss: 0.3512 - val_loss: 0.7437
Epoch 76/200
 - 32s - loss: 0.3546 - val_loss: 0.6948
Epoch 77/200
 - 32s - loss: 0.3548 - val_loss: 0.6876
Epoch 78/200
 - 32s - loss: 0.3612 - val_loss: 0.7349
Epoch 79/200
 - 32s - loss: 0.3481 - val_loss: 0.7441
Epoch 80/200
 - 32s - loss: 0.3474 - val_loss: 0.8016
Epoch 81/200
 - 32s - loss: 0.3525 - val_loss: 0.8646
2019-12-23 23:20:49,283 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ae_model_epoch_80.pickle
Epoch 82/200
 - 32s - loss: 0.3519 - val_loss: 0.7807
Epoch 83/200
 - 32s - loss: 0.3446 - val_loss: 0.8018
Epoch 84/200
 - 32s - loss: 0.3493 - val_loss: 0.8064
Epoch 85/200
 - 32s - loss: 0.3530 - val_loss: 0.8443
Epoch 86/200
 - 32s - loss: 0.3542 - val_loss: 0.7700
Epoch 87/200
 - 32s - loss: 0.3442 - val_loss: 0.7926
Epoch 88/200
 - 32s - loss: 0.3471 - val_loss: 0.7570
Epoch 89/200
 - 32s - loss: 0.3569 - val_loss: 0.7296
Epoch 90/200
 - 32s - loss: 0.3494 - val_loss: 0.7148
Epoch 91/200
 - 32s - loss: 0.3528 - val_loss: 0.7863
Epoch 92/200
 - 32s - loss: 0.3467 - val_loss: 0.7762
2019-12-23 23:26:45,456 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 23:27:59,620 [INFO] Last epoch loss evaluation: train_loss = 0.399793, val_loss = 0.381076
2019-12-23 23:27:59,620 [INFO] Training autoencoder complete
2019-12-23 23:27:59,620 [INFO] Encoding data for supervised training
2019-12-23 23:28:58,846 [INFO] Encoding complete
2019-12-23 23:28:58,846 [INFO] Training neural network layers (after autoencoder)
Epoch 00092: early stopping
Train on 1959372 samples, validate on 979687 samples
Epoch 1/200
 - 20s - loss: 0.0098 - val_loss: 0.0014
 - val_f1: 0.9993
Epoch 2/200
 - 20s - loss: 0.0018 - val_loss: 0.0012
 - val_f1: 0.9994
Epoch 3/200
 - 20s - loss: 0.0015 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 4/200
 - 20s - loss: 0.0013 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 5/200
 - 20s - loss: 0.0012 - val_loss: 9.9944e-04
 - val_f1: 0.9994
Epoch 6/200
 - 20s - loss: 0.0011 - val_loss: 9.8912e-04
 - val_f1: 0.9995
Epoch 7/200
 - 20s - loss: 0.0011 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 8/200
 - 20s - loss: 0.0010 - val_loss: 8.9061e-04
 - val_f1: 0.9995
Epoch 9/200
 - 20s - loss: 0.0010 - val_loss: 8.8604e-04
 - val_f1: 0.9995
Epoch 10/200
 - 20s - loss: 9.7656e-04 - val_loss: 8.7258e-04
 - val_f1: 0.9995
Epoch 11/200
 - 20s - loss: 9.4266e-04 - val_loss: 8.7368e-04
 - val_f1: 0.9995
Epoch 12/200
 - 20s - loss: 9.2609e-04 - val_loss: 9.2263e-04
 - val_f1: 0.9995
Epoch 13/200
 - 20s - loss: 9.3450e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 14/200
 - 20s - loss: 9.0410e-04 - val_loss: 9.7516e-04
 - val_f1: 0.9995
Epoch 15/200
 - 20s - loss: 9.2881e-04 - val_loss: 0.0012
 - val_f1: 0.9995
Epoch 16/200
 - 20s - loss: 8.7337e-04 - val_loss: 9.5068e-04
 - val_f1: 0.9995
Epoch 17/200
 - 20s - loss: 8.7750e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 18/200
 - 20s - loss: 8.6644e-04 - val_loss: 8.5495e-04
 - val_f1: 0.9996
Epoch 19/200
 - 20s - loss: 8.4874e-04 - val_loss: 8.4567e-04
 - val_f1: 0.9995
Epoch 20/200
 - 20s - loss: 8.3535e-04 - val_loss: 8.2593e-04
 - val_f1: 0.9996
Epoch 21/200
 - 20s - loss: 8.5077e-04 - val_loss: 8.8948e-04
2019-12-23 23:42:03,007 [INFO] epoch = 20. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_20.pickle
 - val_f1: 0.9996
Epoch 22/200
 - 20s - loss: 8.2226e-04 - val_loss: 8.7007e-04
 - val_f1: 0.9996
Epoch 23/200
 - 20s - loss: 8.1904e-04 - val_loss: 0.0012
 - val_f1: 0.9995
Epoch 24/200
 - 20s - loss: 8.1252e-04 - val_loss: 0.0012
 - val_f1: 0.9995
Epoch 25/200
 - 20s - loss: 7.9628e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 26/200
 - 20s - loss: 8.0524e-04 - val_loss: 8.6149e-04
 - val_f1: 0.9995
Epoch 27/200
 - 20s - loss: 7.7361e-04 - val_loss: 8.6415e-04
 - val_f1: 0.9996
Epoch 28/200
 - 20s - loss: 7.7227e-04 - val_loss: 8.6166e-04
 - val_f1: 0.9996
Epoch 29/200
 - 20s - loss: 7.7626e-04 - val_loss: 8.6304e-04
 - val_f1: 0.9996
Epoch 30/200
 - 20s - loss: 7.5276e-04 - val_loss: 9.3760e-04
 - val_f1: 0.9995
Epoch 31/200
 - 20s - loss: 7.5906e-04 - val_loss: 0.0010
 - val_f1: 0.9995
Epoch 32/200
 - 20s - loss: 7.4326e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 33/200
 - 20s - loss: 7.6566e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 34/200
 - 20s - loss: 7.6160e-04 - val_loss: 8.6239e-04
 - val_f1: 0.9996
Epoch 35/200
 - 20s - loss: 7.5400e-04 - val_loss: 8.8600e-04
 - val_f1: 0.9995
Epoch 36/200
 - 20s - loss: 7.2764e-04 - val_loss: 9.7531e-04
 - val_f1: 0.9996
Epoch 37/200
 - 20s - loss: 7.4803e-04 - val_loss: 9.3128e-04
 - val_f1: 0.9996
Epoch 38/200
 - 20s - loss: 7.3492e-04 - val_loss: 9.5388e-04
 - val_f1: 0.9995
Epoch 39/200
 - 20s - loss: 7.2968e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 40/200
 - 20s - loss: 7.1147e-04 - val_loss: 9.4674e-04
 - val_f1: 0.9996
Epoch 41/200
 - 20s - loss: 7.4033e-04 - val_loss: 9.3896e-04
2019-12-23 23:54:45,263 [INFO] epoch = 40. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_40.pickle
 - val_f1: 0.9995
Epoch 42/200
 - 20s - loss: 7.2722e-04 - val_loss: 8.5220e-04
 - val_f1: 0.9995
Epoch 43/200
 - 20s - loss: 7.0589e-04 - val_loss: 8.9693e-04
 - val_f1: 0.9996
Epoch 44/200
 - 20s - loss: 7.1843e-04 - val_loss: 9.4107e-04
 - val_f1: 0.9996
Epoch 45/200
 - 20s - loss: 6.8165e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 46/200
 - 20s - loss: 7.0143e-04 - val_loss: 9.6929e-04
 - val_f1: 0.9995
Epoch 47/200
 - 20s - loss: 7.2124e-04 - val_loss: 0.0010
 - val_f1: 0.9996
Epoch 48/200
 - 20s - loss: 7.0172e-04 - val_loss: 0.0010
 - val_f1: 0.9996
Epoch 49/200
 - 20s - loss: 6.7368e-04 - val_loss: 7.5846e-04
 - val_f1: 0.9996
Epoch 50/200
 - 20s - loss: 7.0999e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 51/200
 - 20s - loss: 6.9340e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 52/200
 - 20s - loss: 6.9396e-04 - val_loss: 9.9262e-04
 - val_f1: 0.9996
Epoch 53/200
 - 20s - loss: 6.7596e-04 - val_loss: 9.9040e-04
 - val_f1: 0.9996
Epoch 54/200
 - 20s - loss: 6.8850e-04 - val_loss: 7.7363e-04
 - val_f1: 0.9996
Epoch 55/200
 - 20s - loss: 6.8650e-04 - val_loss: 9.8403e-04
 - val_f1: 0.9996
Epoch 56/200
 - 20s - loss: 6.8178e-04 - val_loss: 0.0011
 - val_f1: 0.9996
Epoch 57/200
 - 20s - loss: 6.7170e-04 - val_loss: 0.0011
 - val_f1: 0.9995
Epoch 58/200
 - 20s - loss: 6.5629e-04 - val_loss: 9.5975e-04
 - val_f1: 0.9995
Epoch 59/200
 - 20s - loss: 6.6974e-04 - val_loss: 0.0010
 - val_f1: 0.9996
Epoch 60/200
 - 20s - loss: 6.5734e-04 - val_loss: 9.6399e-04
 - val_f1: 0.9996
Epoch 61/200
 - 20s - loss: 6.6950e-04 - val_loss: 0.0011
2019-12-24 00:07:26,727 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9995
Epoch 62/200
 - 20s - loss: 6.7557e-04 - val_loss: 0.0010
 - val_f1: 0.9995
Epoch 63/200
 - 20s - loss: 6.6887e-04 - val_loss: 7.3521e-04
 - val_f1: 0.9996
Epoch 64/200
 - 20s - loss: 6.7994e-04 - val_loss: 9.6966e-04
 - val_f1: 0.9995
Epoch 65/200
 - 20s - loss: 6.6496e-04 - val_loss: 0.0012
 - val_f1: 0.9995
Epoch 66/200
 - 20s - loss: 6.8551e-04 - val_loss: 9.6748e-04
 - val_f1: 0.9996
Epoch 67/200
 - 20s - loss: 6.5287e-04 - val_loss: 8.3045e-04
 - val_f1: 0.9996
Epoch 68/200
 - 20s - loss: 6.6721e-04 - val_loss: 6.9417e-04
 - val_f1: 0.9996
Epoch 69/200
 - 20s - loss: 6.5884e-04 - val_loss: 8.6212e-04
 - val_f1: 0.9996
Epoch 70/200
 - 20s - loss: 6.5808e-04 - val_loss: 8.2364e-04
 - val_f1: 0.9996
Epoch 71/200
 - 20s - loss: 6.7146e-04 - val_loss: 0.0011
 - val_f1: 0.9996
Epoch 72/200
 - 20s - loss: 6.5062e-04 - val_loss: 9.6696e-04
 - val_f1: 0.9996
Epoch 73/200
 - 20s - loss: 6.5490e-04 - val_loss: 9.8034e-04
 - val_f1: 0.9995
Epoch 74/200
 - 20s - loss: 6.4853e-04 - val_loss: 8.0992e-04
 - val_f1: 0.9996
Epoch 75/200
 - 20s - loss: 6.5878e-04 - val_loss: 7.5487e-04
 - val_f1: 0.9996
Epoch 76/200
 - 20s - loss: 6.3449e-04 - val_loss: 7.3139e-04
 - val_f1: 0.9996
Epoch 77/200
 - 20s - loss: 6.5198e-04 - val_loss: 8.8431e-04
 - val_f1: 0.9996
Epoch 78/200
 - 20s - loss: 6.2568e-04 - val_loss: 0.0011
 - val_f1: 0.9996
Epoch 79/200
 - 20s - loss: 6.4129e-04 - val_loss: 9.0647e-04
 - val_f1: 0.9996
Epoch 80/200
 - 20s - loss: 6.4541e-04 - val_loss: 7.4447e-04
 - val_f1: 0.9997
Epoch 81/200
 - 20s - loss: 6.3443e-04 - val_loss: 0.0010
2019-12-24 00:20:08,679 [INFO] epoch = 80. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_80.pickle
 - val_f1: 0.9996
Epoch 82/200
 - 20s - loss: 6.3025e-04 - val_loss: 9.1754e-04
 - val_f1: 0.9996
Epoch 83/200
 - 20s - loss: 6.2238e-04 - val_loss: 0.0010
 - val_f1: 0.9995
Epoch 84/200
 - 20s - loss: 6.3608e-04 - val_loss: 9.2212e-04
 - val_f1: 0.9996
Epoch 85/200
 - 20s - loss: 6.0924e-04 - val_loss: 9.7634e-04
 - val_f1: 0.9996
Epoch 86/200
 - 20s - loss: 6.2909e-04 - val_loss: 8.8039e-04
 - val_f1: 0.9996
Epoch 87/200
 - 20s - loss: 6.5747e-04 - val_loss: 0.0010
 - val_f1: 0.9995
Epoch 88/200
 - 20s - loss: 6.2646e-04 - val_loss: 8.7850e-04
 - val_f1: 0.9996
Epoch 89/200
 - 20s - loss: 6.3213e-04 - val_loss: 7.7055e-04
 - val_f1: 0.9996
Epoch 90/200
 - 20s - loss: 6.2991e-04 - val_loss: 8.1833e-04
 - val_f1: 0.9996
Epoch 91/200
 - 20s - loss: 6.2994e-04 - val_loss: 8.4442e-04
 - val_f1: 0.9996
Epoch 92/200
 - 20s - loss: 6.2509e-04 - val_loss: 8.5939e-04
 - val_f1: 0.9996
Epoch 93/200
 - 20s - loss: 6.3110e-04 - val_loss: 8.7985e-04
 - val_f1: 0.9996
Epoch 94/200
 - 20s - loss: 6.1079e-04 - val_loss: 8.3410e-04
 - val_f1: 0.9996
Epoch 95/200
 - 20s - loss: 6.0532e-04 - val_loss: 7.6107e-04
 - val_f1: 0.9996
Epoch 96/200
 - 20s - loss: 6.0672e-04 - val_loss: 6.5799e-04
 - val_f1: 0.9997
Epoch 97/200
 - 20s - loss: 6.2956e-04 - val_loss: 7.2842e-04
 - val_f1: 0.9996
Epoch 98/200
 - 20s - loss: 6.0914e-04 - val_loss: 7.3638e-04
 - val_f1: 0.9997
Epoch 99/200
 - 20s - loss: 6.0474e-04 - val_loss: 9.7696e-04
 - val_f1: 0.9996
Epoch 100/200
 - 20s - loss: 6.1166e-04 - val_loss: 7.4497e-04
 - val_f1: 0.9996
Epoch 101/200
 - 20s - loss: 6.2029e-04 - val_loss: 9.6314e-04
2019-12-24 00:32:49,964 [INFO] epoch = 100. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_100.pickle
 - val_f1: 0.9996
Epoch 102/200
 - 20s - loss: 6.3761e-04 - val_loss: 9.4325e-04
 - val_f1: 0.9996
Epoch 103/200
 - 20s - loss: 6.4204e-04 - val_loss: 7.2805e-04
 - val_f1: 0.9996
Epoch 104/200
 - 20s - loss: 6.3148e-04 - val_loss: 8.6284e-04
 - val_f1: 0.9996
Epoch 105/200
 - 20s - loss: 6.1650e-04 - val_loss: 7.9581e-04
 - val_f1: 0.9996
Epoch 106/200
 - 20s - loss: 6.0571e-04 - val_loss: 7.6061e-04
 - val_f1: 0.9996
Epoch 107/200
 - 20s - loss: 6.1918e-04 - val_loss: 7.1792e-04
 - val_f1: 0.9997
Epoch 108/200
 - 20s - loss: 6.0935e-04 - val_loss: 6.8646e-04
 - val_f1: 0.9997
Epoch 109/200
 - 20s - loss: 5.8456e-04 - val_loss: 7.1299e-04
 - val_f1: 0.9997
Epoch 110/200
 - 20s - loss: 6.1130e-04 - val_loss: 7.5329e-04
 - val_f1: 0.9996
Epoch 111/200
 - 20s - loss: 6.0376e-04 - val_loss: 8.6629e-04
 - val_f1: 0.9996
Epoch 112/200
 - 20s - loss: 5.9261e-04 - val_loss: 6.9080e-04
 - val_f1: 0.9997
Epoch 113/200
 - 20s - loss: 6.3250e-04 - val_loss: 7.9445e-04
 - val_f1: 0.9996
Epoch 114/200
 - 20s - loss: 6.0264e-04 - val_loss: 8.6726e-04
 - val_f1: 0.9996
Epoch 115/200
 - 20s - loss: 6.0521e-04 - val_loss: 7.3946e-04
 - val_f1: 0.9997
Epoch 116/200
 - 20s - loss: 5.8762e-04 - val_loss: 6.8566e-04
 - val_f1: 0.9997
Epoch 117/200
 - 20s - loss: 5.9777e-04 - val_loss: 8.1166e-04
 - val_f1: 0.9996
Epoch 118/200
 - 20s - loss: 6.0608e-04 - val_loss: 0.0010
 - val_f1: 0.9996
Epoch 119/200
 - 20s - loss: 5.9352e-04 - val_loss: 8.0371e-04
 - val_f1: 0.9996
Epoch 120/200
 - 20s - loss: 6.0798e-04 - val_loss: 8.9042e-04
 - val_f1: 0.9996
Epoch 121/200
 - 20s - loss: 6.1153e-04 - val_loss: 9.1300e-04
2019-12-24 00:45:30,878 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9996
Epoch 122/200
 - 20s - loss: 5.9475e-04 - val_loss: 8.2455e-04
 - val_f1: 0.9996
Epoch 123/200
 - 20s - loss: 5.7224e-04 - val_loss: 7.6347e-04
 - val_f1: 0.9996
Epoch 124/200
 - 20s - loss: 5.8569e-04 - val_loss: 7.1024e-04
 - val_f1: 0.9997
Epoch 125/200
 - 20s - loss: 6.0102e-04 - val_loss: 8.8703e-04
 - val_f1: 0.9996
Epoch 126/200
 - 20s - loss: 5.8325e-04 - val_loss: 7.5247e-04
 - val_f1: 0.9996
Epoch 127/200
 - 20s - loss: 6.1477e-04 - val_loss: 9.6247e-04
 - val_f1: 0.9996
Epoch 128/200
 - 20s - loss: 5.7224e-04 - val_loss: 8.3909e-04
 - val_f1: 0.9996
Epoch 129/200
 - 20s - loss: 5.9833e-04 - val_loss: 9.1430e-04
 - val_f1: 0.9996
Epoch 130/200
 - 20s - loss: 5.8980e-04 - val_loss: 9.5954e-04
 - val_f1: 0.9996
Epoch 131/200
 - 20s - loss: 5.8552e-04 - val_loss: 6.7387e-04
 - val_f1: 0.9997
Epoch 132/200
 - 20s - loss: 5.8922e-04 - val_loss: 8.0898e-04
 - val_f1: 0.9996
Epoch 133/200
 - 20s - loss: 5.9738e-04 - val_loss: 7.4630e-04
 - val_f1: 0.9996
Epoch 134/200
 - 20s - loss: 5.8137e-04 - val_loss: 6.8678e-04
 - val_f1: 0.9996
Epoch 135/200
 - 20s - loss: 5.6666e-04 - val_loss: 0.0011
 - val_f1: 0.9996
Epoch 136/200
 - 20s - loss: 5.8981e-04 - val_loss: 7.8631e-04
 - val_f1: 0.9996
Epoch 137/200
 - 20s - loss: 5.8901e-04 - val_loss: 6.8228e-04
 - val_f1: 0.9997
Epoch 138/200
 - 20s - loss: 5.7650e-04 - val_loss: 8.0739e-04
 - val_f1: 0.9996
Epoch 139/200
 - 20s - loss: 5.9921e-04 - val_loss: 7.0454e-04
 - val_f1: 0.9997
Epoch 140/200
 - 20s - loss: 6.1313e-04 - val_loss: 9.4933e-04
 - val_f1: 0.9996
Epoch 141/200
 - 20s - loss: 5.7837e-04 - val_loss: 7.7233e-04
2019-12-24 00:58:12,421 [INFO] epoch = 140. Intermediate model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/ann_model_epoch_140.pickle
 - val_f1: 0.9996
Epoch 142/200
 - 20s - loss: 6.0233e-04 - val_loss: 7.1765e-04
 - val_f1: 0.9996
Epoch 143/200
 - 20s - loss: 5.8125e-04 - val_loss: 8.0342e-04
 - val_f1: 0.9996
Epoch 144/200
 - 20s - loss: 5.7951e-04 - val_loss: 6.8516e-04
 - val_f1: 0.9997
Epoch 145/200
 - 20s - loss: 5.8175e-04 - val_loss: 8.0199e-04
 - val_f1: 0.9997
Epoch 146/200
 - 20s - loss: 5.4229e-04 - val_loss: 8.0823e-04
2019-12-24 01:01:41,201 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 01:02:45,746 [INFO] Last epoch loss evaluation: train_loss = 0.000502, val_loss = 0.000658
2019-12-24 01:02:45,768 [INFO] Training complete. time_to_train = 8788.74 sec, 146.48 min
2019-12-24 01:02:45,778 [INFO] Model saved to results_selected_models/selected_kdd99_ae_ann_shallow_rep5/best_model.pickle
2019-12-24 01:02:45,957 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep5/training_error_history.png
2019-12-24 01:02:46,129 [INFO] Plot saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep5/training_f1_history.png
2019-12-24 01:02:46,129 [INFO] Making predictions on training, validation, testing data
2019-12-24 01:06:05,032 [INFO] Evaluating predictions (results)
2019-12-24 01:06:13,718 [INFO] Dataset: Testing. Classification report below
2019-12-24 01:06:13,718 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.72      0.76      0.74      4166
         r2l       0.98      0.03      0.06     13781
         u2r       0.59      0.00      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.80      0.55      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-24 01:06:13,718 [INFO] Overall accuracy (micro avg): 0.9218207948454967
2019-12-24 01:06:23,020 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9218         0.9218                       0.9218                0.0195                   0.0782  0.9218
1     Macro avg        0.9687         0.8034                       0.5507                0.0196                   0.4493  0.5258
2  Weighted avg        0.9673         0.9374                       0.9218                0.0198                   0.0782  0.9033
2019-12-24 01:06:53,299 [INFO] Dataset: Validation. Classification report below
2019-12-24 01:06:53,299 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.99      0.99      8221
         r2l       0.84      0.74      0.79       225
         u2r       0.50      0.30      0.37        10

    accuracy                           1.00    979687
   macro avg       0.87      0.80      0.83    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-24 01:06:53,299 [INFO] Overall accuracy (micro avg): 0.9996754065329029
2019-12-24 01:07:25,976 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8667                       0.8047                0.0001                   0.1953  0.8300
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-24 01:09:39,354 [INFO] Dataset: Training. Classification report below
2019-12-24 01:09:39,355 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.87      0.75      0.81       901
         u2r       0.59      0.40      0.48        42

    accuracy                           1.00   3918744
   macro avg       0.89      0.83      0.85   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-24 01:09:39,355 [INFO] Overall accuracy (micro avg): 0.9996896964945912
2019-12-24 01:12:03,284 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9997         0.9997                       0.9997                0.0001                   0.0003  0.9997
1     Macro avg        0.9999         0.8891                       0.8288                0.0001                   0.1712  0.8548
2  Weighted avg        0.9999         0.9997                       0.9997                0.0003                   0.0003  0.9997
2019-12-24 01:12:03,331 [INFO] Results saved to: results_selected_models/selected_kdd99_ae_ann_shallow_rep5/selected_kdd99_ae_ann_shallow_rep5_results.xlsx
2019-12-24 01:12:03,338 [INFO] ================= Finished running experiment no. 5 ================= 

