Using TensorFlow backend.
2020-01-14 12:43:14,694 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_deep_rep1/run_log.log
2020-01-14 12:43:14,694 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:43:14,694 [INFO] Experiment parameters given below
2020-01-14 12:43:14,694 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.749049194, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_deep_rep1'}
2020-01-14 12:43:14,694 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_deep_rep1/tf_logs_run_2020_01_14-12_43_14
2020-01-14 12:43:14,694 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:43:14,702 [INFO] Reading X, y files
2020-01-14 12:43:14,702 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:43:15,229 [INFO] Reading complete. time_to_read=0.53 seconds
2020-01-14 12:43:15,229 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:43:15,364 [INFO] Reading complete. time_to_read=0.13 seconds
2020-01-14 12:43:15,364 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:43:15,490 [INFO] Reading complete. time_to_read=0.13 seconds
2020-01-14 12:43:15,490 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:43:15,514 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 12:43:15,514 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:43:15,534 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 12:43:15,534 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:43:15,551 [INFO] Reading complete. time_to_read=0.02 seconds
2020-01-14 12:43:15,751 [INFO] Initializing model
2020-01-14 12:43:15,751 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2020-01-14 12:43:15,778 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2020-01-14 12:43:15,779 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2020-01-14 12:43:15,830 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2020-01-14 12:43:15,843 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-14 12:43:16,203 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-01-14 12:43:16,215 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2020-01-14 12:43:16,218 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:16,227 [INFO] =================================================================
2020-01-14 12:43:16,227 [INFO] dense_1 (Dense)              (None, 128)               15744     
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] batch_normalization_1 (Batch (None, 128)               512       
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] dropout_1 (Dropout)          (None, 128)               0         
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] dense_2 (Dense)              (None, 64)                8256      
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-14 12:43:16,227 [INFO] _________________________________________________________________
2020-01-14 12:43:16,227 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dense_3 (Dense)              (None, 32)                2080      
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dense_4 (Dense)              (None, 64)                2112      
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dense_5 (Dense)              (None, 128)               8320      
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] batch_normalization_5 (Batch (None, 128)               512       
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,228 [INFO] dropout_5 (Dropout)          (None, 128)               0         
2020-01-14 12:43:16,228 [INFO] _________________________________________________________________
2020-01-14 12:43:16,229 [INFO] dense_6 (Dense)              (None, 122)               15738     
2020-01-14 12:43:16,229 [INFO] =================================================================
2020-01-14 12:43:16,229 [INFO] Total params: 53,914
2020-01-14 12:43:16,229 [INFO] Trainable params: 53,082
2020-01-14 12:43:16,229 [INFO] Non-trainable params: 832
2020-01-14 12:43:16,229 [INFO] _________________________________________________________________
2020-01-14 12:43:16,331 [INFO] _________________________________________________________________
2020-01-14 12:43:16,331 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:16,331 [INFO] =================================================================
2020-01-14 12:43:16,331 [INFO] dense_7 (Dense)              (None, 64)                2112      
2020-01-14 12:43:16,331 [INFO] _________________________________________________________________
2020-01-14 12:43:16,331 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2020-01-14 12:43:16,331 [INFO] _________________________________________________________________
2020-01-14 12:43:16,332 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2020-01-14 12:43:16,332 [INFO] _________________________________________________________________
2020-01-14 12:43:16,332 [INFO] dense_8 (Dense)              (None, 5)                 325       
2020-01-14 12:43:16,332 [INFO] =================================================================
2020-01-14 12:43:16,332 [INFO] Total params: 2,693
2020-01-14 12:43:16,332 [INFO] Trainable params: 2,565
2020-01-14 12:43:16,332 [INFO] Non-trainable params: 128
2020-01-14 12:43:16,332 [INFO] _________________________________________________________________
2020-01-14 12:43:16,332 [INFO] Training model
2020-01-14 12:43:16,332 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:43:17,157 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 2407f5fdeb47e7789a05422f0e3b0d7889f4a040
2020-01-14 12:43:17,157 [INFO] Training autoencoder
2020-01-14 12:43:20.331214: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-14 12:43:20.496954: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2020-01-14 12:43:20.497212: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55689c5401d0 executing computations on platform Host. Devices:
2020-01-14 12:43:20.497241: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-01-14 12:43:20.901898: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-01-14 12:43:20,914 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2020-01-14 12:43:20,914 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Train on 25194 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.4113 - val_loss: -5.1924e-01
Epoch 2/10
 - 1s - loss: -6.3347e-01 - val_loss: -1.3348e+00
Epoch 3/10
 - 1s - loss: -1.3842e+00 - val_loss: -1.8338e+00
Epoch 4/10
 - 1s - loss: -1.8604e+00 - val_loss: -2.2214e+00
Epoch 5/10
 - 1s - loss: -2.1749e+00 - val_loss: -2.4811e+00
Epoch 6/10
 - 1s - loss: -2.3820e+00 - val_loss: -2.6535e+00
Epoch 7/10
 - 1s - loss: -2.5280e+00 - val_loss: -2.7842e+00
Epoch 8/10
 - 1s - loss: -2.6320e+00 - val_loss: -2.8797e+00
Epoch 9/10
 - 1s - loss: -2.7146e+00 - val_loss: -2.9389e+00
Epoch 10/10
 - 1s - loss: -2.7737e+00 - val_loss: -2.9735e+00
2020-01-14 12:43:30,313 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:43:31,470 [INFO] Last epoch loss evaluation: train_loss = -2.998357, val_loss = -2.973496
2020-01-14 12:43:31,470 [INFO] Training autoencoder complete
2020-01-14 12:43:31,470 [INFO] Encoding data for supervised training
2020-01-14 12:43:33,048 [INFO] Encoding complete
2020-01-14 12:43:33,048 [INFO] Training neural network layers (after autoencoder)
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.1229 - val_loss: 0.0513
 - val_f1: 0.9642
 - out_of_sample_accuracy: 0.7112
Epoch 2/100
 - 1s - loss: 0.0498 - val_loss: 0.0399
 - val_f1: 0.9662
 - out_of_sample_accuracy: 0.7127
Epoch 3/100
 - 0s - loss: 0.0394 - val_loss: 0.0330
 - val_f1: 0.9698
 - out_of_sample_accuracy: 0.7121
Epoch 4/100
 - 0s - loss: 0.0334 - val_loss: 0.0257
 - val_f1: 0.9805
 - out_of_sample_accuracy: 0.7242
Epoch 5/100
 - 1s - loss: 0.0302 - val_loss: 0.0243
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.7210
Epoch 6/100
 - 0s - loss: 0.0284 - val_loss: 0.0224
 - val_f1: 0.9827
 - out_of_sample_accuracy: 0.7378
Epoch 7/100
 - 0s - loss: 0.0267 - val_loss: 0.0211
 - val_f1: 0.9825
 - out_of_sample_accuracy: 0.7453
Epoch 8/100
 - 1s - loss: 0.0251 - val_loss: 0.0205
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:43:46,120 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7490, current_metric = 0.7509, num_epochs = 8
2020-01-14 12:43:46,121 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:43:47,670 [INFO] Last epoch loss evaluation: train_loss = 0.019307, val_loss = 0.020455
2020-01-14 12:43:47,674 [INFO] Training complete. time_to_train = 31.34 sec, 0.52 min
2020-01-14 12:43:48,441 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_deep_rep1/best_model.pickle
2020-01-14 12:43:48,456 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep1/training_error_history.csv
2020-01-14 12:43:48,654 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep1/training_error_history.png
2020-01-14 12:43:48,784 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep1/training_f1_history.png
2020-01-14 12:43:48,784 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:43:52,989 [INFO] Making predictions complete. time_to_predict = 4.20 sec, 0.07 min
2020-01-14 12:43:52,994 [INFO] Evaluating predictions (results)
2020-01-14 12:43:53,312 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:43:53,312 [INFO] 
              precision    recall  f1-score   support

         dos       0.89      0.81      0.85      7458
      normal       0.67      0.94      0.78      9711
       probe       0.81      0.64      0.72      2421
         r2l       0.95      0.13      0.23      2421
         u2r       1.00      0.01      0.03       533

   micro avg       0.75      0.75      0.75     22544
   macro avg       0.87      0.51      0.52     22544
weighted avg       0.80      0.75      0.72     22544

2020-01-14 12:43:53,312 [INFO] Overall accuracy (micro avg): 0.7547019162526615
2020-01-14 12:43:53,636 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7547         0.7547                       0.7547                0.0613                   0.2453  0.7547
1     Macro avg        0.9019         0.8661                       0.5058                0.0824                   0.4942  0.5205
2  Weighted avg        0.8557         0.7981                       0.7547                0.1667                   0.2453  0.7204
2020-01-14 12:43:53,990 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:43:53,990 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99      9186
      normal       0.98      0.99      0.99     13469
       probe       0.97      0.95      0.96      2331
         r2l       0.75      0.54      0.63       199
         u2r       1.00      0.10      0.18        10

   micro avg       0.98      0.98      0.98     25195
   macro avg       0.94      0.72      0.75     25195
weighted avg       0.98      0.98      0.98     25195

2020-01-14 12:43:53,990 [INFO] Overall accuracy (micro avg): 0.9837666203611828
2020-01-14 12:43:54,370 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9838         0.9838                       0.9838                0.0041                   0.0162  0.9838
1     Macro avg        0.9935         0.9381                       0.7150                0.0057                   0.2850  0.7495
2  Weighted avg        0.9897         0.9832                       0.9838                0.0120                   0.0162  0.9832
2020-01-14 12:43:55,881 [INFO] Dataset: Training. Classification report below
2020-01-14 12:43:55,881 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99     36741
      normal       0.98      0.99      0.99     53874
       probe       0.97      0.95      0.96      9325
         r2l       0.84      0.55      0.66       796
         u2r       0.29      0.05      0.08        42

   micro avg       0.98      0.98      0.98    100778
   macro avg       0.81      0.71      0.74    100778
weighted avg       0.98      0.98      0.98    100778

2020-01-14 12:43:55,881 [INFO] Overall accuracy (micro avg): 0.9837365297981703
2020-01-14 12:43:57,592 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0041                   0.0163  0.9837
1     Macro avg        0.9935         0.8128                       0.7056                0.0058                   0.2944  0.7361
2  Weighted avg        0.9895         0.9831                       0.9837                0.0130                   0.0163  0.9831
2020-01-14 12:43:57,612 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep1/train_time_nsl_ae_ann_deep_rep1_results.xlsx
2020-01-14 12:43:57,612 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 12:43:57,617 [INFO] Created directory: results_additional_exps/train_time_nsl_ae_ann_deep_rep2
2020-01-14 12:43:57,617 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_deep_rep2/run_log.log
2020-01-14 12:43:57,617 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 12:43:57,617 [INFO] Experiment parameters given below
2020-01-14 12:43:57,617 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.749049194, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_deep_rep2'}
2020-01-14 12:43:57,617 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_deep_rep2/tf_logs_run_2020_01_14-12_43_57
2020-01-14 12:43:57,618 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:43:57,618 [INFO] Reading X, y files
2020-01-14 12:43:57,618 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:43:57,874 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-14 12:43:57,874 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:43:57,941 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 12:43:57,941 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:43:57,999 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:43:57,999 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:43:58,007 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:43:58,007 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:43:58,011 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:43:58,011 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:43:58,014 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:43:58,214 [INFO] Initializing model
2020-01-14 12:43:58,607 [INFO] _________________________________________________________________
2020-01-14 12:43:58,607 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:58,607 [INFO] =================================================================
2020-01-14 12:43:58,607 [INFO] dense_9 (Dense)              (None, 128)               15744     
2020-01-14 12:43:58,607 [INFO] _________________________________________________________________
2020-01-14 12:43:58,607 [INFO] batch_normalization_7 (Batch (None, 128)               512       
2020-01-14 12:43:58,607 [INFO] _________________________________________________________________
2020-01-14 12:43:58,607 [INFO] dropout_7 (Dropout)          (None, 128)               0         
2020-01-14 12:43:58,607 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dense_10 (Dense)             (None, 64)                8256      
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] batch_normalization_8 (Batch (None, 64)                256       
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dropout_8 (Dropout)          (None, 64)                0         
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dense_11 (Dense)             (None, 32)                2080      
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dense_12 (Dense)             (None, 64)                2112      
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] batch_normalization_10 (Batc (None, 64)                256       
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,608 [INFO] dropout_10 (Dropout)         (None, 64)                0         
2020-01-14 12:43:58,608 [INFO] _________________________________________________________________
2020-01-14 12:43:58,609 [INFO] dense_13 (Dense)             (None, 128)               8320      
2020-01-14 12:43:58,609 [INFO] _________________________________________________________________
2020-01-14 12:43:58,609 [INFO] batch_normalization_11 (Batc (None, 128)               512       
2020-01-14 12:43:58,609 [INFO] _________________________________________________________________
2020-01-14 12:43:58,609 [INFO] dropout_11 (Dropout)         (None, 128)               0         
2020-01-14 12:43:58,609 [INFO] _________________________________________________________________
2020-01-14 12:43:58,609 [INFO] dense_14 (Dense)             (None, 122)               15738     
2020-01-14 12:43:58,609 [INFO] =================================================================
2020-01-14 12:43:58,609 [INFO] Total params: 53,914
2020-01-14 12:43:58,609 [INFO] Trainable params: 53,082
2020-01-14 12:43:58,609 [INFO] Non-trainable params: 832
2020-01-14 12:43:58,609 [INFO] _________________________________________________________________
2020-01-14 12:43:58,712 [INFO] _________________________________________________________________
2020-01-14 12:43:58,713 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:43:58,713 [INFO] =================================================================
2020-01-14 12:43:58,713 [INFO] dense_15 (Dense)             (None, 64)                2112      
2020-01-14 12:43:58,713 [INFO] _________________________________________________________________
2020-01-14 12:43:58,713 [INFO] batch_normalization_12 (Batc (None, 64)                256       
2020-01-14 12:43:58,713 [INFO] _________________________________________________________________
2020-01-14 12:43:58,713 [INFO] dropout_12 (Dropout)         (None, 64)                0         
2020-01-14 12:43:58,713 [INFO] _________________________________________________________________
2020-01-14 12:43:58,713 [INFO] dense_16 (Dense)             (None, 5)                 325       
2020-01-14 12:43:58,713 [INFO] =================================================================
2020-01-14 12:43:58,713 [INFO] Total params: 2,693
2020-01-14 12:43:58,713 [INFO] Trainable params: 2,565
2020-01-14 12:43:58,713 [INFO] Non-trainable params: 128
2020-01-14 12:43:58,713 [INFO] _________________________________________________________________
2020-01-14 12:43:58,713 [INFO] Training model
2020-01-14 12:43:58,713 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:43:59,440 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 7a0f7b91c552741428861ef52f12336f7f1a2755
2020-01-14 12:43:59,441 [INFO] Training autoencoder
 - val_f1: 0.9831
 - out_of_sample_accuracy: 0.7509
Train on 25194 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.4265 - val_loss: -4.6504e-01
Epoch 2/10
 - 1s - loss: -6.1398e-01 - val_loss: -1.3005e+00
Epoch 3/10
 - 1s - loss: -1.3625e+00 - val_loss: -1.8107e+00
Epoch 4/10
 - 1s - loss: -1.8398e+00 - val_loss: -2.1955e+00
Epoch 5/10
 - 1s - loss: -2.1543e+00 - val_loss: -2.4637e+00
Epoch 6/10
 - 1s - loss: -2.3713e+00 - val_loss: -2.6577e+00
Epoch 7/10
 - 1s - loss: -2.5243e+00 - val_loss: -2.7927e+00
Epoch 8/10
 - 1s - loss: -2.6296e+00 - val_loss: -2.8793e+00
Epoch 9/10
 - 1s - loss: -2.7106e+00 - val_loss: -2.9348e+00
Epoch 10/10
 - 1s - loss: -2.7633e+00 - val_loss: -2.9716e+00
2020-01-14 12:44:11,141 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:44:12,506 [INFO] Last epoch loss evaluation: train_loss = -2.991241, val_loss = -2.971611
2020-01-14 12:44:12,506 [INFO] Training autoencoder complete
2020-01-14 12:44:12,506 [INFO] Encoding data for supervised training
2020-01-14 12:44:14,495 [INFO] Encoding complete
2020-01-14 12:44:14,495 [INFO] Training neural network layers (after autoencoder)
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.1561 - val_loss: 0.0506
 - val_f1: 0.9577
 - out_of_sample_accuracy: 0.7208
Epoch 2/100
 - 1s - loss: 0.0515 - val_loss: 0.0375
 - val_f1: 0.9675
 - out_of_sample_accuracy: 0.7217
Epoch 3/100
 - 1s - loss: 0.0401 - val_loss: 0.0299
 - val_f1: 0.9692
 - out_of_sample_accuracy: 0.7218
Epoch 4/100
 - 1s - loss: 0.0343 - val_loss: 0.0263
 - val_f1: 0.9723
 - out_of_sample_accuracy: 0.7218
Epoch 5/100
 - 1s - loss: 0.0309 - val_loss: 0.0238
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.7219
Epoch 6/100
 - 1s - loss: 0.0284 - val_loss: 0.0220
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.7221
Epoch 7/100
 - 1s - loss: 0.0260 - val_loss: 0.0206
 - val_f1: 0.9828
 - out_of_sample_accuracy: 0.7361
Epoch 8/100
 - 1s - loss: 0.0248 - val_loss: 0.0197
 - val_f1: 0.9829
 - out_of_sample_accuracy: 0.7331
Epoch 9/100
 - 1s - loss: 0.0236 - val_loss: 0.0186
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:44:31,805 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7490, current_metric = 0.7556, num_epochs = 9
2020-01-14 12:44:31,806 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:44:33,750 [INFO] Last epoch loss evaluation: train_loss = 0.017829, val_loss = 0.018605
2020-01-14 12:44:33,754 [INFO] Training complete. time_to_train = 35.04 sec, 0.58 min
2020-01-14 12:44:35,305 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_deep_rep2/best_model.pickle
2020-01-14 12:44:35,306 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep2/training_error_history.csv
2020-01-14 12:44:35,449 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep2/training_error_history.png
2020-01-14 12:44:35,581 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep2/training_f1_history.png
2020-01-14 12:44:35,581 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:44:40,638 [INFO] Making predictions complete. time_to_predict = 5.06 sec, 0.08 min
2020-01-14 12:44:40,643 [INFO] Evaluating predictions (results)
2020-01-14 12:44:40,929 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:44:40,929 [INFO] 
              precision    recall  f1-score   support

         dos       0.92      0.80      0.85      7458
      normal       0.67      0.97      0.79      9711
       probe       0.82      0.68      0.74      2421
         r2l       0.98      0.06      0.11      2421
         u2r       0.58      0.02      0.04       533

   micro avg       0.76      0.76      0.76     22544
   macro avg       0.79      0.50      0.51     22544
weighted avg       0.80      0.76      0.72     22544

2020-01-14 12:44:40,929 [INFO] Overall accuracy (micro avg): 0.7595369056068133
2020-01-14 12:44:41,254 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7595         0.7595                       0.7595                0.0601                   0.2405  0.7595
1     Macro avg        0.9038         0.7947                       0.5039                0.0812                   0.4961  0.5078
2  Weighted avg        0.8605         0.8012                       0.7595                0.1654                   0.2405  0.7169
2020-01-14 12:44:41,596 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:44:41,596 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99      9186
      normal       0.98      0.99      0.99     13469
       probe       0.97      0.96      0.97      2331
         r2l       0.94      0.51      0.66       199
         u2r       0.67      0.20      0.31        10

   micro avg       0.98      0.98      0.98     25195
   macro avg       0.91      0.73      0.78     25195
weighted avg       0.98      0.98      0.98     25195

2020-01-14 12:44:41,596 [INFO] Overall accuracy (micro avg): 0.9845207382417146
2020-01-14 12:44:41,976 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9845         0.9845                       0.9845                0.0039                   0.0155  0.9845
1     Macro avg        0.9938         0.9119                       0.7316                0.0058                   0.2684  0.7838
2  Weighted avg        0.9895         0.9843                       0.9845                0.0137                   0.0155  0.9838
2020-01-14 12:44:43,493 [INFO] Dataset: Training. Classification report below
2020-01-14 12:44:43,493 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      0.99      0.99     36741
      normal       0.98      0.99      0.99     53874
       probe       0.98      0.95      0.97      9325
         r2l       0.95      0.49      0.65       796
         u2r       0.67      0.24      0.35        42

   micro avg       0.98      0.98      0.98    100778
   macro avg       0.91      0.73      0.79    100778
weighted avg       0.98      0.98      0.98    100778

2020-01-14 12:44:43,493 [INFO] Overall accuracy (micro avg): 0.9839746770128401
2020-01-14 12:44:45,210 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9840         0.9840                       0.9840                0.0040                   0.0160  0.9840
1     Macro avg        0.9936         0.9136                       0.7332                0.0062                   0.2668  0.7884
2  Weighted avg        0.9892         0.9838                       0.9840                0.0148                   0.0160  0.9832
2020-01-14 12:44:45,230 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep2/train_time_nsl_ae_ann_deep_rep2_results.xlsx
2020-01-14 12:44:45,230 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 12:44:45,234 [INFO] Created directory: results_additional_exps/train_time_nsl_ae_ann_deep_rep3
2020-01-14 12:44:45,235 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_nsl_ae_ann_deep_rep3/run_log.log
2020-01-14 12:44:45,235 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 12:44:45,235 [INFO] Experiment parameters given below
2020-01-14 12:44:45,235 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_nsl_ae_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.749049194, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'train_time_nsl_ae_ann_deep_rep3'}
2020-01-14 12:44:45,235 [INFO] Created tensorboard log directory: results_additional_exps/train_time_nsl_ae_ann_deep_rep3/tf_logs_run_2020_01_14-12_44_45
2020-01-14 12:44:45,235 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2020-01-14 12:44:45,235 [INFO] Reading X, y files
2020-01-14 12:44:45,235 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2020-01-14 12:44:45,498 [INFO] Reading complete. time_to_read=0.26 seconds
2020-01-14 12:44:45,498 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2020-01-14 12:44:45,564 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 12:44:45,564 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2020-01-14 12:44:45,622 [INFO] Reading complete. time_to_read=0.06 seconds
2020-01-14 12:44:45,622 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2020-01-14 12:44:45,630 [INFO] Reading complete. time_to_read=0.01 seconds
2020-01-14 12:44:45,630 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2020-01-14 12:44:45,634 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:44:45,635 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2020-01-14 12:44:45,638 [INFO] Reading complete. time_to_read=0.00 seconds
2020-01-14 12:44:45,834 [INFO] Initializing model
2020-01-14 12:44:46,345 [INFO] _________________________________________________________________
2020-01-14 12:44:46,345 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:44:46,345 [INFO] =================================================================
2020-01-14 12:44:46,345 [INFO] dense_17 (Dense)             (None, 128)               15744     
2020-01-14 12:44:46,345 [INFO] _________________________________________________________________
2020-01-14 12:44:46,345 [INFO] batch_normalization_13 (Batc (None, 128)               512       
2020-01-14 12:44:46,345 [INFO] _________________________________________________________________
2020-01-14 12:44:46,345 [INFO] dropout_13 (Dropout)         (None, 128)               0         
2020-01-14 12:44:46,345 [INFO] _________________________________________________________________
2020-01-14 12:44:46,345 [INFO] dense_18 (Dense)             (None, 64)                8256      
2020-01-14 12:44:46,345 [INFO] _________________________________________________________________
2020-01-14 12:44:46,345 [INFO] batch_normalization_14 (Batc (None, 64)                256       
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dropout_14 (Dropout)         (None, 64)                0         
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dense_19 (Dense)             (None, 32)                2080      
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] batch_normalization_15 (Batc (None, 32)                128       
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dropout_15 (Dropout)         (None, 32)                0         
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dense_20 (Dense)             (None, 64)                2112      
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] batch_normalization_16 (Batc (None, 64)                256       
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dropout_16 (Dropout)         (None, 64)                0         
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] dense_21 (Dense)             (None, 128)               8320      
2020-01-14 12:44:46,346 [INFO] _________________________________________________________________
2020-01-14 12:44:46,346 [INFO] batch_normalization_17 (Batc (None, 128)               512       
2020-01-14 12:44:46,347 [INFO] _________________________________________________________________
2020-01-14 12:44:46,347 [INFO] dropout_17 (Dropout)         (None, 128)               0         
2020-01-14 12:44:46,347 [INFO] _________________________________________________________________
2020-01-14 12:44:46,347 [INFO] dense_22 (Dense)             (None, 122)               15738     
2020-01-14 12:44:46,347 [INFO] =================================================================
2020-01-14 12:44:46,347 [INFO] Total params: 53,914
2020-01-14 12:44:46,347 [INFO] Trainable params: 53,082
2020-01-14 12:44:46,347 [INFO] Non-trainable params: 832
2020-01-14 12:44:46,347 [INFO] _________________________________________________________________
2020-01-14 12:44:46,451 [INFO] _________________________________________________________________
2020-01-14 12:44:46,451 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:44:46,451 [INFO] =================================================================
2020-01-14 12:44:46,451 [INFO] dense_23 (Dense)             (None, 64)                2112      
2020-01-14 12:44:46,451 [INFO] _________________________________________________________________
2020-01-14 12:44:46,451 [INFO] batch_normalization_18 (Batc (None, 64)                256       
2020-01-14 12:44:46,451 [INFO] _________________________________________________________________
2020-01-14 12:44:46,451 [INFO] dropout_18 (Dropout)         (None, 64)                0         
2020-01-14 12:44:46,451 [INFO] _________________________________________________________________
2020-01-14 12:44:46,451 [INFO] dense_24 (Dense)             (None, 5)                 325       
2020-01-14 12:44:46,451 [INFO] =================================================================
2020-01-14 12:44:46,452 [INFO] Total params: 2,693
2020-01-14 12:44:46,452 [INFO] Trainable params: 2,565
2020-01-14 12:44:46,452 [INFO] Non-trainable params: 128
2020-01-14 12:44:46,452 [INFO] _________________________________________________________________
2020-01-14 12:44:46,452 [INFO] Training model
2020-01-14 12:44:46,452 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:44:47,276 [INFO] Split sizes (instances). total = 100778, unsupervised = 25194, supervised = 75584, unsupervised dataset hash = 950586e2c8296a24ebeddf6231bcd2c9ac120a1f
2020-01-14 12:44:47,276 [INFO] Training autoencoder
 - val_f1: 0.9837
 - out_of_sample_accuracy: 0.7556
Train on 25194 samples, validate on 25195 samples
Epoch 1/10
 - 2s - loss: 0.4013 - val_loss: -4.4634e-01
Epoch 2/10
 - 1s - loss: -6.0343e-01 - val_loss: -1.2775e+00
Epoch 3/10
 - 1s - loss: -1.3404e+00 - val_loss: -1.7820e+00
Epoch 4/10
 - 1s - loss: -1.8095e+00 - val_loss: -2.1613e+00
Epoch 5/10
 - 1s - loss: -2.1299e+00 - val_loss: -2.4396e+00
Epoch 6/10
 - 1s - loss: -2.3602e+00 - val_loss: -2.6470e+00
Epoch 7/10
 - 1s - loss: -2.5202e+00 - val_loss: -2.7867e+00
Epoch 8/10
 - 1s - loss: -2.6308e+00 - val_loss: -2.8713e+00
Epoch 9/10
 - 1s - loss: -2.7088e+00 - val_loss: -2.9315e+00
Epoch 10/10
 - 1s - loss: -2.7609e+00 - val_loss: -2.9704e+00
2020-01-14 12:44:59,901 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:45:01,490 [INFO] Last epoch loss evaluation: train_loss = -2.996238, val_loss = -2.970453
2020-01-14 12:45:01,490 [INFO] Training autoencoder complete
2020-01-14 12:45:01,490 [INFO] Encoding data for supervised training
2020-01-14 12:45:03,772 [INFO] Encoding complete
2020-01-14 12:45:03,772 [INFO] Training neural network layers (after autoencoder)
Train on 75584 samples, validate on 25195 samples
Epoch 1/100
 - 1s - loss: 0.1374 - val_loss: 0.0536
 - val_f1: 0.9591
 - out_of_sample_accuracy: 0.7193
Epoch 2/100
 - 1s - loss: 0.0538 - val_loss: 0.0392
 - val_f1: 0.9660
 - out_of_sample_accuracy: 0.7243
Epoch 3/100
 - 1s - loss: 0.0432 - val_loss: 0.0334
 - val_f1: 0.9729
 - out_of_sample_accuracy: 0.7247
Epoch 4/100
 - 1s - loss: 0.0371 - val_loss: 0.0287
 - val_f1: 0.9737
 - out_of_sample_accuracy: 0.7266
Epoch 5/100
 - 1s - loss: 0.0327 - val_loss: 0.0243
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.7284
Epoch 6/100
 - 1s - loss: 0.0290 - val_loss: 0.0218
 - val_f1: 0.9798
 - out_of_sample_accuracy: 0.7317
Epoch 7/100
 - 1s - loss: 0.0269 - val_loss: 0.0204
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.7305
Epoch 8/100
 - 1s - loss: 0.0256 - val_loss: 0.0199
 - val_f1: 0.9826
 - out_of_sample_accuracy: 0.7319
Epoch 9/100
 - 1s - loss: 0.0241 - val_loss: 0.0177
 - val_f1: 0.9831
 - out_of_sample_accuracy: 0.7362
Epoch 10/100
 - 1s - loss: 0.0227 - val_loss: 0.0176
 - val_f1: 0.9834
 - out_of_sample_accuracy: 0.7323
Epoch 11/100
 - 1s - loss: 0.0222 - val_loss: 0.0165
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:45:27,239 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_nsl_ae_ann_deep_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9848
 - out_of_sample_accuracy: 0.7393
Epoch 12/100
 - 1s - loss: 0.0212 - val_loss: 0.0156
 - val_f1: 0.9856
 - out_of_sample_accuracy: 0.7425
Epoch 13/100
 - 1s - loss: 0.0205 - val_loss: 0.0163
2020-01-14 12:45:32,496 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.7490, current_metric = 0.7516, num_epochs = 13
2020-01-14 12:45:32,496 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:45:34,821 [INFO] Last epoch loss evaluation: train_loss = 0.015397, val_loss = 0.015585
2020-01-14 12:45:34,824 [INFO] Training complete. time_to_train = 48.37 sec, 0.81 min
2020-01-14 12:45:36,356 [INFO] Model saved to results_additional_exps/train_time_nsl_ae_ann_deep_rep3/best_model.pickle
2020-01-14 12:45:36,357 [INFO] Training history saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep3/training_error_history.csv
2020-01-14 12:45:36,492 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep3/training_error_history.png
2020-01-14 12:45:36,616 [INFO] Plot saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep3/training_f1_history.png
2020-01-14 12:45:36,616 [INFO] Making predictions on training, validation, testing data
2020-01-14 12:45:42,465 [INFO] Making predictions complete. time_to_predict = 5.85 sec, 0.10 min
2020-01-14 12:45:42,471 [INFO] Evaluating predictions (results)
2020-01-14 12:45:42,757 [INFO] Dataset: Testing. Classification report below
2020-01-14 12:45:42,757 [INFO] 
              precision    recall  f1-score   support

         dos       0.91      0.79      0.84      7458
      normal       0.66      0.97      0.79      9711
       probe       0.85      0.57      0.68      2421
         r2l       0.98      0.07      0.13      2421
         u2r       0.00      0.00      0.00       533

   micro avg       0.75      0.75      0.75     22544
   macro avg       0.68      0.48      0.49     22544
weighted avg       0.78      0.75      0.70     22544

2020-01-14 12:45:42,757 [INFO] Overall accuracy (micro avg): 0.7476046841731725
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 12:45:43,093 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7476         0.7476                       0.7476                0.0631                   0.2524  0.7476
1     Macro avg        0.8990         0.6796                       0.4788                0.0859                   0.5212  0.4873
2  Weighted avg        0.8529         0.7818                       0.7476                0.1770                   0.2524  0.7047
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:45:43,440 [INFO] Dataset: Validation. Classification report below
2020-01-14 12:45:43,441 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      1.00      0.99      9186
      normal       0.99      0.99      0.99     13469
       probe       0.98      0.96      0.97      2331
         r2l       0.92      0.53      0.67       199
         u2r       0.00      0.00      0.00        10

   micro avg       0.99      0.99      0.99     25195
   macro avg       0.77      0.70      0.72     25195
weighted avg       0.99      0.99      0.99     25195

2020-01-14 12:45:43,441 [INFO] Overall accuracy (micro avg): 0.9864655685651915
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 12:45:43,819 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9865         0.9865                       0.9865                0.0034                   0.0135  0.9865
1     Macro avg        0.9946         0.7745                       0.6953                0.0048                   0.3047  0.7242
2  Weighted avg        0.9914         0.9858                       0.9865                0.0105                   0.0135  0.9857
2020-01-14 12:45:45,447 [INFO] Dataset: Training. Classification report below
2020-01-14 12:45:45,447 [INFO] 
              precision    recall  f1-score   support

         dos       0.99      1.00      0.99     36741
      normal       0.99      0.99      0.99     53874
       probe       0.98      0.96      0.97      9325
         r2l       0.93      0.51      0.66       796
         u2r       0.00      0.00      0.00        42

   micro avg       0.99      0.99      0.99    100778
   macro avg       0.78      0.69      0.72    100778
weighted avg       0.99      0.99      0.99    100778

2020-01-14 12:45:45,447 [INFO] Overall accuracy (micro avg): 0.9866240647760424
2020-01-14 12:45:47,157 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9866         0.9866                       0.9866                0.0033                   0.0134  0.9866
1     Macro avg        0.9946         0.7776                       0.6912                0.0049                   0.3088  0.7219
2  Weighted avg        0.9915         0.9860                       0.9866                0.0111                   0.0134  0.9858
2020-01-14 12:45:47,177 [INFO] Results saved to: results_additional_exps/train_time_nsl_ae_ann_deep_rep3/train_time_nsl_ae_ann_deep_rep3_results.xlsx
2020-01-14 12:45:47,177 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 12:45:47,181 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep1
2020-01-14 12:45:47,181 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_deep_rep1/run_log.log
2020-01-14 12:45:47,181 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 12:45:47,181 [INFO] Experiment parameters given below
2020-01-14 12:45:47,181 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982649002, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_deep_rep1'}
2020-01-14 12:45:47,181 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep1/tf_logs_run_2020_01_14-12_45_47
2020-01-14 12:45:47,181 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 12:45:47,193 [INFO] Reading X, y files
2020-01-14 12:45:47,193 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 12:45:53,158 [INFO] Reading complete. time_to_read=5.97 seconds
2020-01-14 12:45:53,158 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 12:45:54,712 [INFO] Reading complete. time_to_read=1.55 seconds
2020-01-14 12:45:54,712 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 12:45:56,289 [INFO] Reading complete. time_to_read=1.58 seconds
2020-01-14 12:45:56,289 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 12:45:56,730 [INFO] Reading complete. time_to_read=0.44 seconds
2020-01-14 12:45:56,730 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 12:45:56,897 [INFO] Reading complete. time_to_read=0.17 seconds
2020-01-14 12:45:56,897 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 12:45:57,064 [INFO] Reading complete. time_to_read=0.17 seconds
2020-01-14 12:46:00,481 [INFO] Initializing model
2020-01-14 12:46:00,904 [INFO] _________________________________________________________________
2020-01-14 12:46:00,904 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:46:00,904 [INFO] =================================================================
2020-01-14 12:46:00,904 [INFO] dense_25 (Dense)             (None, 128)               10112     
2020-01-14 12:46:00,904 [INFO] _________________________________________________________________
2020-01-14 12:46:00,904 [INFO] batch_normalization_19 (Batc (None, 128)               512       
2020-01-14 12:46:00,904 [INFO] _________________________________________________________________
2020-01-14 12:46:00,904 [INFO] dropout_19 (Dropout)         (None, 128)               0         
2020-01-14 12:46:00,904 [INFO] _________________________________________________________________
2020-01-14 12:46:00,904 [INFO] dense_26 (Dense)             (None, 64)                8256      
2020-01-14 12:46:00,904 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] batch_normalization_20 (Batc (None, 64)                256       
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dropout_20 (Dropout)         (None, 64)                0         
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dense_27 (Dense)             (None, 32)                2080      
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] batch_normalization_21 (Batc (None, 32)                128       
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dropout_21 (Dropout)         (None, 32)                0         
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dense_28 (Dense)             (None, 64)                2112      
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] batch_normalization_22 (Batc (None, 64)                256       
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dropout_22 (Dropout)         (None, 64)                0         
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,905 [INFO] dense_29 (Dense)             (None, 128)               8320      
2020-01-14 12:46:00,905 [INFO] _________________________________________________________________
2020-01-14 12:46:00,906 [INFO] batch_normalization_23 (Batc (None, 128)               512       
2020-01-14 12:46:00,906 [INFO] _________________________________________________________________
2020-01-14 12:46:00,906 [INFO] dropout_23 (Dropout)         (None, 128)               0         
2020-01-14 12:46:00,906 [INFO] _________________________________________________________________
2020-01-14 12:46:00,906 [INFO] dense_30 (Dense)             (None, 78)                10062     
2020-01-14 12:46:00,906 [INFO] =================================================================
2020-01-14 12:46:00,906 [INFO] Total params: 42,606
2020-01-14 12:46:00,906 [INFO] Trainable params: 41,774
2020-01-14 12:46:00,906 [INFO] Non-trainable params: 832
2020-01-14 12:46:00,906 [INFO] _________________________________________________________________
2020-01-14 12:46:01,013 [INFO] _________________________________________________________________
2020-01-14 12:46:01,013 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 12:46:01,013 [INFO] =================================================================
2020-01-14 12:46:01,014 [INFO] dense_31 (Dense)             (None, 64)                2112      
2020-01-14 12:46:01,014 [INFO] _________________________________________________________________
2020-01-14 12:46:01,014 [INFO] batch_normalization_24 (Batc (None, 64)                256       
2020-01-14 12:46:01,014 [INFO] _________________________________________________________________
2020-01-14 12:46:01,014 [INFO] dropout_24 (Dropout)         (None, 64)                0         
2020-01-14 12:46:01,014 [INFO] _________________________________________________________________
2020-01-14 12:46:01,014 [INFO] dense_32 (Dense)             (None, 12)                780       
2020-01-14 12:46:01,014 [INFO] =================================================================
2020-01-14 12:46:01,014 [INFO] Total params: 3,148
2020-01-14 12:46:01,014 [INFO] Trainable params: 3,020
2020-01-14 12:46:01,014 [INFO] Non-trainable params: 128
2020-01-14 12:46:01,014 [INFO] _________________________________________________________________
2020-01-14 12:46:01,014 [INFO] Training model
2020-01-14 12:46:01,014 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 12:46:21,911 [INFO] Split sizes (instances). total = 1696684, unsupervised = 424171, supervised = 1272513, unsupervised dataset hash = 48e7f1673689b5563cf848e2831f4d9c00700bf3
2020-01-14 12:46:21,911 [INFO] Training autoencoder
 - val_f1: 0.9854
 - out_of_sample_accuracy: 0.7516
Train on 424171 samples, validate on 565562 samples
Epoch 1/10
 - 17s - loss: -3.2167e+00 - val_loss: -4.0025e+00
Epoch 2/10
 - 16s - loss: -3.9075e+00 - val_loss: -4.0578e+00
Epoch 3/10
 - 16s - loss: -3.9633e+00 - val_loss: -4.0863e+00
Epoch 4/10
 - 16s - loss: -3.9948e+00 - val_loss: -4.0959e+00
Epoch 5/10
 - 16s - loss: -4.0148e+00 - val_loss: -4.1068e+00
Epoch 6/10
 - 16s - loss: -4.0273e+00 - val_loss: -4.1141e+00
Epoch 7/10
 - 16s - loss: -4.0371e+00 - val_loss: -4.1159e+00
Epoch 8/10
 - 16s - loss: -4.0436e+00 - val_loss: -4.1217e+00
Epoch 9/10
 - 16s - loss: -4.0506e+00 - val_loss: -4.1244e+00
Epoch 10/10
 - 16s - loss: -4.0541e+00 - val_loss: -4.1266e+00
2020-01-14 12:49:07,710 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 12:49:32,550 [INFO] Last epoch loss evaluation: train_loss = -4.126453, val_loss = -4.126601
2020-01-14 12:49:32,551 [INFO] Training autoencoder complete
2020-01-14 12:49:32,551 [INFO] Encoding data for supervised training
2020-01-14 12:50:14,417 [INFO] Encoding complete
2020-01-14 12:50:14,417 [INFO] Training neural network layers (after autoencoder)
Train on 1272513 samples, validate on 565562 samples
Epoch 1/100
 - 11s - loss: 0.0230 - val_loss: 0.0129
 - val_f1: 0.9697
 - out_of_sample_accuracy: 0.9705
Epoch 2/100
 - 11s - loss: 0.0132 - val_loss: 0.0109
 - val_f1: 0.9710
 - out_of_sample_accuracy: 0.9716
Epoch 3/100
 - 11s - loss: 0.0121 - val_loss: 0.0104
 - val_f1: 0.9714
 - out_of_sample_accuracy: 0.9695
Epoch 4/100
 - 11s - loss: 0.0115 - val_loss: 0.0100
 - val_f1: 0.9728
 - out_of_sample_accuracy: 0.9733
Epoch 5/100
 - 11s - loss: 0.0111 - val_loss: 0.0096
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9753
Epoch 6/100
 - 11s - loss: 0.0110 - val_loss: 0.0094
 - val_f1: 0.9733
 - out_of_sample_accuracy: 0.9736
Epoch 7/100
 - 11s - loss: 0.0108 - val_loss: 0.0095
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9743
Epoch 8/100
 - 11s - loss: 0.0107 - val_loss: 0.0093
 - val_f1: 0.9736
 - out_of_sample_accuracy: 0.9735
Epoch 9/100
 - 11s - loss: 0.0105 - val_loss: 0.0091
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9752
Epoch 10/100
 - 11s - loss: 0.0105 - val_loss: 0.0097
 - val_f1: 0.9743
 - out_of_sample_accuracy: 0.9748
Epoch 11/100
 - 11s - loss: 0.0103 - val_loss: 0.0092
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 12:58:40,809 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_10.pickle
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9741
Epoch 12/100
 - 11s - loss: 0.0103 - val_loss: 0.0093
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9763
Epoch 13/100
 - 11s - loss: 0.0102 - val_loss: 0.0092
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9765
Epoch 14/100
 - 11s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9772
Epoch 15/100
 - 11s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9755
Epoch 16/100
 - 11s - loss: 0.0100 - val_loss: 0.0091
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9767
Epoch 17/100
 - 11s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9770
Epoch 18/100
 - 11s - loss: 0.0098 - val_loss: 0.0089
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9759
Epoch 19/100
 - 11s - loss: 0.0098 - val_loss: 0.0088
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9759
Epoch 20/100
 - 11s - loss: 0.0099 - val_loss: 0.0089
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9769
Epoch 21/100
 - 11s - loss: 0.0099 - val_loss: 0.0090
2020-01-14 13:06:54,784 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9742
Epoch 22/100
 - 11s - loss: 0.0098 - val_loss: 0.0090
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 23/100
 - 11s - loss: 0.0097 - val_loss: 0.0098
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9758
Epoch 24/100
 - 11s - loss: 0.0097 - val_loss: 0.0091
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9763
Epoch 25/100
 - 11s - loss: 0.0097 - val_loss: 0.0089
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9766
Epoch 26/100
 - 11s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9771
Epoch 27/100
 - 11s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9745
Epoch 28/100
 - 11s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9773
Epoch 29/100
 - 11s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9778
Epoch 30/100
 - 11s - loss: 0.0095 - val_loss: 0.0094
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 31/100
 - 11s - loss: 0.0096 - val_loss: 0.0086
2020-01-14 13:15:09,438 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9775
Epoch 32/100
 - 11s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9768
Epoch 33/100
 - 11s - loss: 0.0095 - val_loss: 0.0091
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9766
Epoch 34/100
 - 11s - loss: 0.0094 - val_loss: 0.0088
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9769
Epoch 35/100
 - 11s - loss: 0.0095 - val_loss: 0.0102
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9756
Epoch 36/100
 - 11s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9787
 - out_of_sample_accuracy: 0.9788
Epoch 37/100
 - 11s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9767
Epoch 38/100
 - 11s - loss: 0.0094 - val_loss: 0.0090
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9770
Epoch 39/100
 - 11s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9765
Epoch 40/100
 - 11s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9797
 - out_of_sample_accuracy: 0.9798
Epoch 41/100
 - 11s - loss: 0.0093 - val_loss: 0.0084
2020-01-14 13:23:23,204 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9775
Epoch 42/100
 - 11s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9763
Epoch 43/100
 - 11s - loss: 0.0093 - val_loss: 0.0084
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9773
Epoch 44/100
 - 11s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9775
Epoch 45/100
 - 11s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9802
Epoch 46/100
 - 11s - loss: 0.0093 - val_loss: 0.0090
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9772
Epoch 47/100
 - 11s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9768
Epoch 48/100
 - 11s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9757
Epoch 49/100
 - 11s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9775
Epoch 50/100
 - 11s - loss: 0.0091 - val_loss: 0.0081
 - val_f1: 0.9788
 - out_of_sample_accuracy: 0.9791
Epoch 51/100
 - 11s - loss: 0.0092 - val_loss: 0.0080
2020-01-14 13:31:37,194 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_50.pickle
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9782
Epoch 52/100
 - 11s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9774
Epoch 53/100
 - 11s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9772
Epoch 54/100
 - 11s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9776
Epoch 55/100
 - 11s - loss: 0.0091 - val_loss: 0.0088
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9761
Epoch 56/100
 - 11s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9773
Epoch 57/100
 - 11s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9780
Epoch 58/100
 - 11s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9793
 - out_of_sample_accuracy: 0.9796
Epoch 59/100
 - 11s - loss: 0.0091 - val_loss: 0.0089
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9767
Epoch 60/100
 - 11s - loss: 0.0090 - val_loss: 0.0080
 - val_f1: 0.9804
 - out_of_sample_accuracy: 0.9804
Epoch 61/100
 - 11s - loss: 0.0090 - val_loss: 0.0084
2020-01-14 13:39:51,469 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9776
Epoch 62/100
 - 11s - loss: 0.0091 - val_loss: 0.0081
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9763
Epoch 63/100
 - 11s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9820
 - out_of_sample_accuracy: 0.9822
Epoch 64/100
 - 11s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9773
Epoch 65/100
 - 11s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9780
Epoch 66/100
 - 11s - loss: 0.0090 - val_loss: 0.0081
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9788
Epoch 67/100
 - 11s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9778
Epoch 68/100
 - 11s - loss: 0.0090 - val_loss: 0.0087
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9779
Epoch 69/100
 - 11s - loss: 0.0091 - val_loss: 0.0079
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9793
Epoch 70/100
 - 11s - loss: 0.0090 - val_loss: 0.0087
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9773
Epoch 71/100
 - 11s - loss: 0.0090 - val_loss: 0.0081
2020-01-14 13:48:04,388 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_70.pickle
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.9800
Epoch 72/100
 - 11s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9769
Epoch 73/100
 - 11s - loss: 0.0090 - val_loss: 0.0090
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9762
Epoch 74/100
 - 11s - loss: 0.0090 - val_loss: 0.0093
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9772
Epoch 75/100
 - 11s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9772
Epoch 76/100
 - 11s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9796
 - out_of_sample_accuracy: 0.9797
Epoch 77/100
 - 11s - loss: 0.0089 - val_loss: 0.0094
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9756
Epoch 78/100
 - 11s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9771
Epoch 79/100
 - 11s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9773
Epoch 80/100
 - 11s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9797
Epoch 81/100
 - 11s - loss: 0.0090 - val_loss: 0.0083
2020-01-14 13:56:16,393 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9763
Epoch 82/100
 - 11s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9779
Epoch 83/100
 - 11s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9777
Epoch 84/100
 - 11s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9805
 - out_of_sample_accuracy: 0.9807
Epoch 85/100
 - 11s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9778
Epoch 86/100
 - 11s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9793
Epoch 87/100
 - 11s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9787
 - out_of_sample_accuracy: 0.9790
Epoch 88/100
 - 11s - loss: 0.0089 - val_loss: 0.0079
 - val_f1: 0.9800
 - out_of_sample_accuracy: 0.9801
Epoch 89/100
 - 11s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9784
Epoch 90/100
 - 11s - loss: 0.0089 - val_loss: 0.0085
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9766
Epoch 91/100
 - 11s - loss: 0.0088 - val_loss: 0.0095
2020-01-14 14:04:28,927 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9754
Epoch 92/100
 - 11s - loss: 0.0088 - val_loss: 0.0081
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9781
Epoch 93/100
 - 11s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9781
Epoch 94/100
 - 11s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9805
Epoch 95/100
 - 11s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9785
Epoch 96/100
 - 11s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9780
Epoch 97/100
 - 11s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9795
Epoch 98/100
 - 11s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9764
Epoch 99/100
 - 11s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9774
Epoch 100/100
 - 11s - loss: 0.0088 - val_loss: 0.0081
2020-01-14 14:12:30,449 [INFO] StopperOnGoal: did not reach goal, num_epochs = 100
2020-01-14 14:12:30,449 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 14:13:12,417 [INFO] Last epoch loss evaluation: train_loss = 0.007752, val_loss = 0.007878
2020-01-14 14:13:12,458 [INFO] Training complete. time_to_train = 5231.44 sec, 87.19 min
2020-01-14 14:13:14,505 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep1/best_model.pickle
2020-01-14 14:13:14,507 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep1/training_error_history.csv
2020-01-14 14:13:14,645 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep1/training_error_history.png
2020-01-14 14:13:14,771 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep1/training_f1_history.png
2020-01-14 14:13:14,772 [INFO] Making predictions on training, validation, testing data
2020-01-14 14:15:21,048 [INFO] Making predictions complete. time_to_predict = 126.28 sec, 2.10 min
2020-01-14 14:15:21,111 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 14:15:31,414 [INFO] Dataset: Testing. Classification report below
2020-01-14 14:15:31,415 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99    454265
                   Bot       0.59      0.61      0.60       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.96      0.94      0.95      2058
              DoS Hulk       0.93      0.98      0.95     46025
      DoS Slowhttptest       0.87      0.93      0.90      1100
         DoS slowloris       0.96      0.93      0.95      1159
           FTP-Patator       1.00      0.94      0.97      1587
              PortScan       0.90      0.94      0.92     31761
           SSH-Patator       0.96      0.94      0.95      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.76      0.76      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 14:15:31,415 [INFO] Overall accuracy (micro avg): 0.9793815708976205
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 14:15:43,131 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9794         0.9794                       0.9794                0.0019                   0.0206  0.9794
1     Macro avg        0.9966         0.7642                       0.7641                0.0045                   0.2359  0.7638
2  Weighted avg        0.9824         0.9791                       0.9794                0.0329                   0.0206  0.9792
2020-01-14 14:15:53,578 [INFO] Dataset: Validation. Classification report below
2020-01-14 14:15:53,579 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99    454264
                   Bot       0.58      0.56      0.57       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.97      0.93      0.95      2059
              DoS Hulk       0.94      0.98      0.96     46025
      DoS Slowhttptest       0.88      0.93      0.90      1099
         DoS slowloris       0.96      0.92      0.94      1159
           FTP-Patator       1.00      0.93      0.96      1587
              PortScan       0.90      0.94      0.92     31761
           SSH-Patator       0.97      0.94      0.95      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.76      0.76      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 14:15:53,579 [INFO] Overall accuracy (micro avg): 0.9796096626010942
2020-01-14 14:16:05,464 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9796         0.9796                       0.9796                0.0019                   0.0204  0.9796
1     Macro avg        0.9966         0.7640                       0.7575                0.0044                   0.2425  0.7604
2  Weighted avg        0.9826         0.9793                       0.9796                0.0328                   0.0204  0.9794
2020-01-14 14:16:40,136 [INFO] Dataset: Training. Classification report below
2020-01-14 14:16:40,137 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.98      0.99   1362791
                   Bot       0.58      0.60      0.59      1174
                  DDoS       1.00      0.98      0.99     76815
         DoS GoldenEye       0.97      0.94      0.95      6176
              DoS Hulk       0.93      0.98      0.95    138074
      DoS Slowhttptest       0.88      0.94      0.91      3300
         DoS slowloris       0.97      0.93      0.95      3478
           FTP-Patator       1.00      0.94      0.97      4761
              PortScan       0.90      0.94      0.92     95282
           SSH-Patator       0.97      0.94      0.96      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.98      0.98      0.98   1696684
             macro avg       0.77      0.76      0.77   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 14:16:40,137 [INFO] Overall accuracy (micro avg): 0.9798347836132126
2020-01-14 14:17:19,520 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9798         0.9798                       0.9798                0.0018                   0.0202  0.9798
1     Macro avg        0.9966         0.7663                       0.7644                0.0043                   0.2356  0.7650
2  Weighted avg        0.9828         0.9796                       0.9798                0.0320                   0.0202  0.9796
2020-01-14 14:17:19,544 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep1/train_time_ids17_ae_ann_deep_rep1_results.xlsx
2020-01-14 14:17:19,551 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 14:17:19,620 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep2
2020-01-14 14:17:19,620 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_deep_rep2/run_log.log
2020-01-14 14:17:19,620 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 14:17:19,620 [INFO] Experiment parameters given below
2020-01-14 14:17:19,620 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982649002, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_deep_rep2'}
2020-01-14 14:17:19,620 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep2/tf_logs_run_2020_01_14-14_17_19
2020-01-14 14:17:19,620 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 14:17:19,620 [INFO] Reading X, y files
2020-01-14 14:17:19,620 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 14:17:23,855 [INFO] Reading complete. time_to_read=4.23 seconds
2020-01-14 14:17:23,855 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 14:17:25,294 [INFO] Reading complete. time_to_read=1.44 seconds
2020-01-14 14:17:25,294 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 14:17:26,732 [INFO] Reading complete. time_to_read=1.44 seconds
2020-01-14 14:17:26,732 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 14:17:26,958 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 14:17:26,958 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 14:17:27,034 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-14 14:17:27,034 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 14:17:27,108 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 14:17:30,559 [INFO] Initializing model
2020-01-14 14:17:31,160 [INFO] _________________________________________________________________
2020-01-14 14:17:31,160 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 14:17:31,160 [INFO] =================================================================
2020-01-14 14:17:31,160 [INFO] dense_33 (Dense)             (None, 128)               10112     
2020-01-14 14:17:31,160 [INFO] _________________________________________________________________
2020-01-14 14:17:31,160 [INFO] batch_normalization_25 (Batc (None, 128)               512       
2020-01-14 14:17:31,160 [INFO] _________________________________________________________________
2020-01-14 14:17:31,160 [INFO] dropout_25 (Dropout)         (None, 128)               0         
2020-01-14 14:17:31,160 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dense_34 (Dense)             (None, 64)                8256      
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] batch_normalization_26 (Batc (None, 64)                256       
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dropout_26 (Dropout)         (None, 64)                0         
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dense_35 (Dense)             (None, 32)                2080      
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] batch_normalization_27 (Batc (None, 32)                128       
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dropout_27 (Dropout)         (None, 32)                0         
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dense_36 (Dense)             (None, 64)                2112      
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] batch_normalization_28 (Batc (None, 64)                256       
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,161 [INFO] dropout_28 (Dropout)         (None, 64)                0         
2020-01-14 14:17:31,161 [INFO] _________________________________________________________________
2020-01-14 14:17:31,162 [INFO] dense_37 (Dense)             (None, 128)               8320      
2020-01-14 14:17:31,162 [INFO] _________________________________________________________________
2020-01-14 14:17:31,162 [INFO] batch_normalization_29 (Batc (None, 128)               512       
2020-01-14 14:17:31,162 [INFO] _________________________________________________________________
2020-01-14 14:17:31,162 [INFO] dropout_29 (Dropout)         (None, 128)               0         
2020-01-14 14:17:31,162 [INFO] _________________________________________________________________
2020-01-14 14:17:31,162 [INFO] dense_38 (Dense)             (None, 78)                10062     
2020-01-14 14:17:31,162 [INFO] =================================================================
2020-01-14 14:17:31,162 [INFO] Total params: 42,606
2020-01-14 14:17:31,162 [INFO] Trainable params: 41,774
2020-01-14 14:17:31,162 [INFO] Non-trainable params: 832
2020-01-14 14:17:31,162 [INFO] _________________________________________________________________
2020-01-14 14:17:31,269 [INFO] _________________________________________________________________
2020-01-14 14:17:31,269 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 14:17:31,269 [INFO] =================================================================
2020-01-14 14:17:31,269 [INFO] dense_39 (Dense)             (None, 64)                2112      
2020-01-14 14:17:31,269 [INFO] _________________________________________________________________
2020-01-14 14:17:31,269 [INFO] batch_normalization_30 (Batc (None, 64)                256       
2020-01-14 14:17:31,269 [INFO] _________________________________________________________________
2020-01-14 14:17:31,269 [INFO] dropout_30 (Dropout)         (None, 64)                0         
2020-01-14 14:17:31,269 [INFO] _________________________________________________________________
2020-01-14 14:17:31,269 [INFO] dense_40 (Dense)             (None, 12)                780       
2020-01-14 14:17:31,269 [INFO] =================================================================
2020-01-14 14:17:31,270 [INFO] Total params: 3,148
2020-01-14 14:17:31,270 [INFO] Trainable params: 3,020
2020-01-14 14:17:31,270 [INFO] Non-trainable params: 128
2020-01-14 14:17:31,270 [INFO] _________________________________________________________________
2020-01-14 14:17:31,270 [INFO] Training model
2020-01-14 14:17:31,270 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 14:17:52,259 [INFO] Split sizes (instances). total = 1696684, unsupervised = 424171, supervised = 1272513, unsupervised dataset hash = 8fd6ef9af9d6e4a17523cef9c2e5c7fc3bb13a83
2020-01-14 14:17:52,259 [INFO] Training autoencoder
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9779
Train on 424171 samples, validate on 565562 samples
Epoch 1/10
 - 18s - loss: -3.1768e+00 - val_loss: -4.0031e+00
Epoch 2/10
 - 17s - loss: -3.9079e+00 - val_loss: -4.0567e+00
Epoch 3/10
 - 17s - loss: -3.9628e+00 - val_loss: -4.0796e+00
Epoch 4/10
 - 17s - loss: -3.9911e+00 - val_loss: -4.0976e+00
Epoch 5/10
 - 17s - loss: -4.0111e+00 - val_loss: -4.1055e+00
Epoch 6/10
 - 17s - loss: -4.0253e+00 - val_loss: -4.1117e+00
Epoch 7/10
 - 17s - loss: -4.0359e+00 - val_loss: -4.1167e+00
Epoch 8/10
 - 17s - loss: -4.0443e+00 - val_loss: -4.1200e+00
Epoch 9/10
 - 17s - loss: -4.0507e+00 - val_loss: -4.1245e+00
Epoch 10/10
 - 17s - loss: -4.0557e+00 - val_loss: -4.1249e+00
2020-01-14 14:20:43,122 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 14:21:09,825 [INFO] Last epoch loss evaluation: train_loss = -4.127195, val_loss = -4.124868
2020-01-14 14:21:09,826 [INFO] Training autoencoder complete
2020-01-14 14:21:09,826 [INFO] Encoding data for supervised training
2020-01-14 14:21:57,573 [INFO] Encoding complete
2020-01-14 14:21:57,573 [INFO] Training neural network layers (after autoencoder)
Train on 1272513 samples, validate on 565562 samples
Epoch 1/100
 - 12s - loss: 0.0232 - val_loss: 0.0136
 - val_f1: 0.9623
 - out_of_sample_accuracy: 0.9632
Epoch 2/100
 - 12s - loss: 0.0133 - val_loss: 0.0114
 - val_f1: 0.9691
 - out_of_sample_accuracy: 0.9702
Epoch 3/100
 - 12s - loss: 0.0120 - val_loss: 0.0101
 - val_f1: 0.9710
 - out_of_sample_accuracy: 0.9718
Epoch 4/100
 - 12s - loss: 0.0116 - val_loss: 0.0113
 - val_f1: 0.9695
 - out_of_sample_accuracy: 0.9707
Epoch 5/100
 - 12s - loss: 0.0112 - val_loss: 0.0102
 - val_f1: 0.9724
 - out_of_sample_accuracy: 0.9732
Epoch 6/100
 - 12s - loss: 0.0110 - val_loss: 0.0095
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9780
Epoch 7/100
 - 12s - loss: 0.0108 - val_loss: 0.0094
 - val_f1: 0.9742
 - out_of_sample_accuracy: 0.9749
Epoch 8/100
 - 12s - loss: 0.0107 - val_loss: 0.0096
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9759
Epoch 9/100
 - 12s - loss: 0.0106 - val_loss: 0.0093
 - val_f1: 0.9758
 - out_of_sample_accuracy: 0.9764
Epoch 10/100
 - 12s - loss: 0.0105 - val_loss: 0.0098
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9747
Epoch 11/100
 - 12s - loss: 0.0104 - val_loss: 0.0092
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 14:31:18,695 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/ann_model_epoch_10.pickle
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9781
Epoch 12/100
 - 12s - loss: 0.0103 - val_loss: 0.0097
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9746
Epoch 13/100
 - 12s - loss: 0.0102 - val_loss: 0.0108
 - val_f1: 0.9714
 - out_of_sample_accuracy: 0.9724
Epoch 14/100
 - 12s - loss: 0.0101 - val_loss: 0.0090
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9755
Epoch 15/100
 - 12s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9770
Epoch 16/100
 - 12s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9780
Epoch 17/100
 - 12s - loss: 0.0100 - val_loss: 0.0089
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9756
Epoch 18/100
 - 12s - loss: 0.0099 - val_loss: 0.0089
 - val_f1: 0.9787
 - out_of_sample_accuracy: 0.9795
Epoch 19/100
 - 12s - loss: 0.0098 - val_loss: 0.0081
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9805
Epoch 20/100
 - 12s - loss: 0.0098 - val_loss: 0.0090
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9786
Epoch 21/100
 - 12s - loss: 0.0097 - val_loss: 0.0091
2020-01-14 14:40:21,147 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9750
Epoch 22/100
 - 12s - loss: 0.0098 - val_loss: 0.0089
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9765
Epoch 23/100
 - 12s - loss: 0.0096 - val_loss: 0.0083
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9798
Epoch 24/100
 - 12s - loss: 0.0097 - val_loss: 0.0084
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9764
Epoch 25/100
 - 12s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9770
Epoch 26/100
 - 12s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9772
Epoch 27/100
 - 12s - loss: 0.0096 - val_loss: 0.0081
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9772
Epoch 28/100
 - 12s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9791
 - out_of_sample_accuracy: 0.9794
Epoch 29/100
 - 12s - loss: 0.0096 - val_loss: 0.0085
 - val_f1: 0.9754
 - out_of_sample_accuracy: 0.9759
Epoch 30/100
 - 12s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9768
Epoch 31/100
 - 12s - loss: 0.0096 - val_loss: 0.0085
2020-01-14 14:49:22,118 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9768
Epoch 32/100
 - 12s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9791
 - out_of_sample_accuracy: 0.9801
Epoch 33/100
 - 12s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9750
 - out_of_sample_accuracy: 0.9754
Epoch 34/100
 - 12s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9798
 - out_of_sample_accuracy: 0.9801
Epoch 35/100
 - 12s - loss: 0.0095 - val_loss: 0.0082
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9766
Epoch 36/100
 - 12s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9771
Epoch 37/100
 - 12s - loss: 0.0096 - val_loss: 0.0089
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9745
Epoch 38/100
 - 12s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9755
 - out_of_sample_accuracy: 0.9760
Epoch 39/100
 - 12s - loss: 0.0095 - val_loss: 0.0096
 - val_f1: 0.9732
 - out_of_sample_accuracy: 0.9741
Epoch 40/100
 - 12s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9743
 - out_of_sample_accuracy: 0.9752
Epoch 41/100
 - 12s - loss: 0.0095 - val_loss: 0.0078
2020-01-14 14:58:21,783 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9818
 - out_of_sample_accuracy: 0.9819
Epoch 42/100
 - 12s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9770
Epoch 43/100
 - 12s - loss: 0.0094 - val_loss: 0.0088
 - val_f1: 0.9747
 - out_of_sample_accuracy: 0.9757
Epoch 44/100
 - 12s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9759
 - out_of_sample_accuracy: 0.9763
Epoch 45/100
 - 12s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9745
Epoch 46/100
 - 12s - loss: 0.0094 - val_loss: 0.0081
 - val_f1: 0.9787
 - out_of_sample_accuracy: 0.9791
Epoch 47/100
 - 12s - loss: 0.0093 - val_loss: 0.0080
 - val_f1: 0.9795
 - out_of_sample_accuracy: 0.9794
Epoch 48/100
 - 12s - loss: 0.0093 - val_loss: 0.0088
 - val_f1: 0.9746
 - out_of_sample_accuracy: 0.9753
Epoch 49/100
 - 12s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9780
 - out_of_sample_accuracy: 0.9783
Epoch 50/100
 - 12s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9811
 - out_of_sample_accuracy: 0.9814
Epoch 51/100
 - 12s - loss: 0.0093 - val_loss: 0.0078
2020-01-14 15:07:22,174 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/ann_model_epoch_50.pickle
2020-01-14 15:08:04,417 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9826, current_metric = 0.9833, num_epochs = 51
2020-01-14 15:08:04,420 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 15:08:49,877 [INFO] Last epoch loss evaluation: train_loss = 0.007629, val_loss = 0.007756
2020-01-14 15:08:49,919 [INFO] Training complete. time_to_train = 3078.65 sec, 51.31 min
2020-01-14 15:08:52,533 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep2/best_model.pickle
2020-01-14 15:08:52,535 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep2/training_error_history.csv
2020-01-14 15:08:52,674 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep2/training_error_history.png
2020-01-14 15:08:52,791 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep2/training_f1_history.png
2020-01-14 15:08:52,791 [INFO] Making predictions on training, validation, testing data
2020-01-14 15:11:13,187 [INFO] Making predictions complete. time_to_predict = 140.40 sec, 2.34 min
2020-01-14 15:11:13,250 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 15:11:23,601 [INFO] Dataset: Testing. Classification report below
2020-01-14 15:11:23,601 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       0.97      0.35      0.52       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.98      0.93      0.95      2058
              DoS Hulk       0.97      0.97      0.97     46025
      DoS Slowhttptest       0.85      0.95      0.90      1100
         DoS slowloris       0.96      0.88      0.92      1159
           FTP-Patator       0.93      0.99      0.96      1587
              PortScan       0.88      0.95      0.91     31761
           SSH-Patator       0.96      0.88      0.92      1179
Web Attack Brute Force       1.00      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.88      0.74      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 15:11:23,602 [INFO] Overall accuracy (micro avg): 0.9819754509673564
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 15:11:35,361 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9820         0.9820                       0.9820                0.0016                   0.0180  0.9820
1     Macro avg        0.9970         0.8753                       0.7437                0.0043                   0.2563  0.7619
2  Weighted avg        0.9848         0.9822                       0.9820                0.0333                   0.0180  0.9817
2020-01-14 15:11:45,825 [INFO] Dataset: Validation. Classification report below
2020-01-14 15:11:45,826 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       0.95      0.31      0.46       391
                  DDoS       1.00      0.98      0.99     25605
         DoS GoldenEye       0.97      0.91      0.94      2059
              DoS Hulk       0.97      0.97      0.97     46025
      DoS Slowhttptest       0.85      0.93      0.89      1099
         DoS slowloris       0.96      0.89      0.92      1159
           FTP-Patator       0.93      0.99      0.96      1587
              PortScan       0.88      0.95      0.92     31761
           SSH-Patator       0.95      0.89      0.92      1180
Web Attack Brute Force       1.00      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.87      0.74      0.75    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 15:11:45,826 [INFO] Overall accuracy (micro avg): 0.9820815401317627
2020-01-14 15:11:57,752 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9821         0.9821                       0.9821                0.0016                   0.0179  0.9821
1     Macro avg        0.9970         0.8717                       0.7367                0.0042                   0.2633  0.7525
2  Weighted avg        0.9849         0.9823                       0.9821                0.0324                   0.0179  0.9818
2020-01-14 15:12:32,260 [INFO] Dataset: Training. Classification report below
2020-01-14 15:12:32,260 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       0.97      0.35      0.51      1174
                  DDoS       1.00      0.98      0.99     76815
         DoS GoldenEye       0.98      0.92      0.95      6176
              DoS Hulk       0.97      0.97      0.97    138074
      DoS Slowhttptest       0.87      0.94      0.90      3300
         DoS slowloris       0.96      0.90      0.93      3478
           FTP-Patator       0.93      0.99      0.96      4761
              PortScan       0.88      0.95      0.92     95282
           SSH-Patator       0.97      0.90      0.93      3538
Web Attack Brute Force       0.95      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.98      0.98      0.98   1696684
             macro avg       0.87      0.74      0.76   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 15:12:32,260 [INFO] Overall accuracy (micro avg): 0.982264817726813
2020-01-14 15:13:11,427 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9823         0.9823                       0.9823                0.0016                   0.0177  0.9823
1     Macro avg        0.9970         0.8727                       0.7448                0.0042                   0.2552  0.7614
2  Weighted avg        0.9850         0.9825                       0.9823                0.0323                   0.0177  0.9820
2020-01-14 15:13:11,451 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep2/train_time_ids17_ae_ann_deep_rep2_results.xlsx
2020-01-14 15:13:11,455 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 15:13:11,525 [INFO] Created directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep3
2020-01-14 15:13:11,526 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids17_ae_ann_deep_rep3/run_log.log
2020-01-14 15:13:11,526 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 15:13:11,526 [INFO] Experiment parameters given below
2020-01-14 15:13:11,526 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids17_ae_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.982649002, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'train_time_ids17_ae_ann_deep_rep3'}
2020-01-14 15:13:11,526 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids17_ae_ann_deep_rep3/tf_logs_run_2020_01_14-15_13_11
2020-01-14 15:13:11,526 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2020-01-14 15:13:11,526 [INFO] Reading X, y files
2020-01-14 15:13:11,526 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2020-01-14 15:13:15,679 [INFO] Reading complete. time_to_read=4.15 seconds
2020-01-14 15:13:15,679 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2020-01-14 15:13:17,110 [INFO] Reading complete. time_to_read=1.43 seconds
2020-01-14 15:13:17,110 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2020-01-14 15:13:18,533 [INFO] Reading complete. time_to_read=1.42 seconds
2020-01-14 15:13:18,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2020-01-14 15:13:18,759 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-14 15:13:18,759 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2020-01-14 15:13:18,834 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 15:13:18,834 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2020-01-14 15:13:18,908 [INFO] Reading complete. time_to_read=0.07 seconds
2020-01-14 15:13:22,358 [INFO] Initializing model
2020-01-14 15:13:22,793 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 15:13:22,794 [INFO] =================================================================
2020-01-14 15:13:22,794 [INFO] dense_41 (Dense)             (None, 128)               10112     
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] batch_normalization_31 (Batc (None, 128)               512       
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] dropout_31 (Dropout)         (None, 128)               0         
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] dense_42 (Dense)             (None, 64)                8256      
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] batch_normalization_32 (Batc (None, 64)                256       
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] dropout_32 (Dropout)         (None, 64)                0         
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,794 [INFO] dense_43 (Dense)             (None, 32)                2080      
2020-01-14 15:13:22,794 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] batch_normalization_33 (Batc (None, 32)                128       
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dropout_33 (Dropout)         (None, 32)                0         
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dense_44 (Dense)             (None, 64)                2112      
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] batch_normalization_34 (Batc (None, 64)                256       
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dropout_34 (Dropout)         (None, 64)                0         
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dense_45 (Dense)             (None, 128)               8320      
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] batch_normalization_35 (Batc (None, 128)               512       
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dropout_35 (Dropout)         (None, 128)               0         
2020-01-14 15:13:22,795 [INFO] _________________________________________________________________
2020-01-14 15:13:22,795 [INFO] dense_46 (Dense)             (None, 78)                10062     
2020-01-14 15:13:22,795 [INFO] =================================================================
2020-01-14 15:13:22,796 [INFO] Total params: 42,606
2020-01-14 15:13:22,796 [INFO] Trainable params: 41,774
2020-01-14 15:13:22,796 [INFO] Non-trainable params: 832
2020-01-14 15:13:22,796 [INFO] _________________________________________________________________
2020-01-14 15:13:22,903 [INFO] _________________________________________________________________
2020-01-14 15:13:22,903 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 15:13:22,903 [INFO] =================================================================
2020-01-14 15:13:22,903 [INFO] dense_47 (Dense)             (None, 64)                2112      
2020-01-14 15:13:22,903 [INFO] _________________________________________________________________
2020-01-14 15:13:22,903 [INFO] batch_normalization_36 (Batc (None, 64)                256       
2020-01-14 15:13:22,903 [INFO] _________________________________________________________________
2020-01-14 15:13:22,904 [INFO] dropout_36 (Dropout)         (None, 64)                0         
2020-01-14 15:13:22,904 [INFO] _________________________________________________________________
2020-01-14 15:13:22,904 [INFO] dense_48 (Dense)             (None, 12)                780       
2020-01-14 15:13:22,904 [INFO] =================================================================
2020-01-14 15:13:22,904 [INFO] Total params: 3,148
2020-01-14 15:13:22,904 [INFO] Trainable params: 3,020
2020-01-14 15:13:22,904 [INFO] Non-trainable params: 128
2020-01-14 15:13:22,904 [INFO] _________________________________________________________________
2020-01-14 15:13:22,904 [INFO] Training model
2020-01-14 15:13:22,904 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 15:13:43,643 [INFO] Split sizes (instances). total = 1696684, unsupervised = 424171, supervised = 1272513, unsupervised dataset hash = ad22eac83472c3b05588c4820cd7e1bd8d4803f3
2020-01-14 15:13:43,643 [INFO] Training autoencoder
 - val_f1: 0.9830
 - out_of_sample_accuracy: 0.9833
Train on 424171 samples, validate on 565562 samples
Epoch 1/10
 - 18s - loss: -3.1890e+00 - val_loss: -3.9938e+00
Epoch 2/10
 - 17s - loss: -3.9065e+00 - val_loss: -4.0631e+00
Epoch 3/10
 - 17s - loss: -3.9634e+00 - val_loss: -4.0838e+00
Epoch 4/10
 - 17s - loss: -3.9918e+00 - val_loss: -4.0989e+00
Epoch 5/10
 - 17s - loss: -4.0120e+00 - val_loss: -4.1028e+00
Epoch 6/10
 - 17s - loss: -4.0220e+00 - val_loss: -4.1122e+00
Epoch 7/10
 - 17s - loss: -4.0354e+00 - val_loss: -4.1179e+00
Epoch 8/10
 - 17s - loss: -4.0399e+00 - val_loss: -4.1203e+00
Epoch 9/10
 - 17s - loss: -4.0488e+00 - val_loss: -4.1234e+00
Epoch 10/10
 - 17s - loss: -4.0527e+00 - val_loss: -4.1273e+00
2020-01-14 15:16:40,416 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 15:17:08,645 [INFO] Last epoch loss evaluation: train_loss = -4.129853, val_loss = -4.127287
2020-01-14 15:17:08,645 [INFO] Training autoencoder complete
2020-01-14 15:17:08,645 [INFO] Encoding data for supervised training
2020-01-14 15:18:00,410 [INFO] Encoding complete
2020-01-14 15:18:00,410 [INFO] Training neural network layers (after autoencoder)
Train on 1272513 samples, validate on 565562 samples
Epoch 1/100
 - 13s - loss: 0.0231 - val_loss: 0.0119
 - val_f1: 0.9680
 - out_of_sample_accuracy: 0.9676
Epoch 2/100
 - 12s - loss: 0.0131 - val_loss: 0.0114
 - val_f1: 0.9714
 - out_of_sample_accuracy: 0.9719
Epoch 3/100
 - 12s - loss: 0.0119 - val_loss: 0.0101
 - val_f1: 0.9737
 - out_of_sample_accuracy: 0.9741
Epoch 4/100
 - 12s - loss: 0.0113 - val_loss: 0.0104
 - val_f1: 0.9728
 - out_of_sample_accuracy: 0.9737
Epoch 5/100
 - 12s - loss: 0.0110 - val_loss: 0.0096
 - val_f1: 0.9741
 - out_of_sample_accuracy: 0.9751
Epoch 6/100
 - 12s - loss: 0.0107 - val_loss: 0.0106
 - val_f1: 0.9734
 - out_of_sample_accuracy: 0.9743
Epoch 7/100
 - 12s - loss: 0.0106 - val_loss: 0.0101
 - val_f1: 0.9756
 - out_of_sample_accuracy: 0.9764
Epoch 8/100
 - 12s - loss: 0.0106 - val_loss: 0.0100
 - val_f1: 0.9729
 - out_of_sample_accuracy: 0.9739
Epoch 9/100
 - 12s - loss: 0.0104 - val_loss: 0.0097
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9746
Epoch 10/100
 - 12s - loss: 0.0103 - val_loss: 0.0092
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9757
Epoch 11/100
 - 12s - loss: 0.0101 - val_loss: 0.0097
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 15:28:02,470 [INFO] epoch = 10. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_10.pickle
 - val_f1: 0.9740
 - out_of_sample_accuracy: 0.9748
Epoch 12/100
 - 12s - loss: 0.0100 - val_loss: 0.0100
 - val_f1: 0.9749
 - out_of_sample_accuracy: 0.9757
Epoch 13/100
 - 12s - loss: 0.0100 - val_loss: 0.0084
 - val_f1: 0.9804
 - out_of_sample_accuracy: 0.9805
Epoch 14/100
 - 12s - loss: 0.0099 - val_loss: 0.0090
 - val_f1: 0.9753
 - out_of_sample_accuracy: 0.9758
Epoch 15/100
 - 12s - loss: 0.0099 - val_loss: 0.0095
 - val_f1: 0.9752
 - out_of_sample_accuracy: 0.9757
Epoch 16/100
 - 12s - loss: 0.0097 - val_loss: 0.0097
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9763
Epoch 17/100
 - 12s - loss: 0.0097 - val_loss: 0.0084
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9766
Epoch 18/100
 - 12s - loss: 0.0097 - val_loss: 0.0092
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9766
Epoch 19/100
 - 12s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9779
Epoch 20/100
 - 12s - loss: 0.0096 - val_loss: 0.0091
 - val_f1: 0.9762
 - out_of_sample_accuracy: 0.9769
Epoch 21/100
 - 12s - loss: 0.0095 - val_loss: 0.0085
2020-01-14 15:37:46,283 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9769
Epoch 22/100
 - 12s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9776
Epoch 23/100
 - 12s - loss: 0.0095 - val_loss: 0.0083
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 24/100
 - 12s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9776
Epoch 25/100
 - 12s - loss: 0.0094 - val_loss: 0.0089
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9770
Epoch 26/100
 - 12s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9790
 - out_of_sample_accuracy: 0.9796
Epoch 27/100
 - 12s - loss: 0.0094 - val_loss: 0.0095
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9763
Epoch 28/100
 - 12s - loss: 0.0093 - val_loss: 0.0081
 - val_f1: 0.9802
 - out_of_sample_accuracy: 0.9804
Epoch 29/100
 - 12s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9766
Epoch 30/100
 - 12s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9764
Epoch 31/100
 - 12s - loss: 0.0093 - val_loss: 0.0088
2020-01-14 15:47:32,429 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9770
Epoch 32/100
 - 12s - loss: 0.0093 - val_loss: 0.0082
 - val_f1: 0.9770
 - out_of_sample_accuracy: 0.9776
Epoch 33/100
 - 12s - loss: 0.0092 - val_loss: 0.0099
 - val_f1: 0.9738
 - out_of_sample_accuracy: 0.9748
Epoch 34/100
 - 12s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9783
 - out_of_sample_accuracy: 0.9788
Epoch 35/100
 - 12s - loss: 0.0092 - val_loss: 0.0081
 - val_f1: 0.9797
 - out_of_sample_accuracy: 0.9798
Epoch 36/100
 - 12s - loss: 0.0092 - val_loss: 0.0090
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 37/100
 - 12s - loss: 0.0091 - val_loss: 0.0087
 - val_f1: 0.9767
 - out_of_sample_accuracy: 0.9773
Epoch 38/100
 - 12s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9774
Epoch 39/100
 - 12s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9784
 - out_of_sample_accuracy: 0.9787
Epoch 40/100
 - 12s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9790
 - out_of_sample_accuracy: 0.9796
Epoch 41/100
 - 12s - loss: 0.0091 - val_loss: 0.0080
2020-01-14 15:57:17,759 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9794
 - out_of_sample_accuracy: 0.9796
Epoch 42/100
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 43/100
 - 12s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9791
 - out_of_sample_accuracy: 0.9794
Epoch 44/100
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9769
 - out_of_sample_accuracy: 0.9774
Epoch 45/100
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9798
 - out_of_sample_accuracy: 0.9802
Epoch 46/100
 - 12s - loss: 0.0091 - val_loss: 0.0090
 - val_f1: 0.9748
 - out_of_sample_accuracy: 0.9757
Epoch 47/100
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9788
 - out_of_sample_accuracy: 0.9793
Epoch 48/100
 - 12s - loss: 0.0090 - val_loss: 0.0077
 - val_f1: 0.9811
 - out_of_sample_accuracy: 0.9814
Epoch 49/100
 - 12s - loss: 0.0090 - val_loss: 0.0079
 - val_f1: 0.9802
 - out_of_sample_accuracy: 0.9803
Epoch 50/100
 - 12s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9774
 - out_of_sample_accuracy: 0.9779
Epoch 51/100
 - 12s - loss: 0.0091 - val_loss: 0.0082
2020-01-14 16:07:03,329 [INFO] epoch = 50. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_50.pickle
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9759
Epoch 52/100
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9775
 - out_of_sample_accuracy: 0.9779
Epoch 53/100
 - 12s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9785
 - out_of_sample_accuracy: 0.9788
Epoch 54/100
 - 12s - loss: 0.0089 - val_loss: 0.0086
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9779
Epoch 55/100
 - 12s - loss: 0.0089 - val_loss: 0.0081
 - val_f1: 0.9757
 - out_of_sample_accuracy: 0.9760
Epoch 56/100
 - 12s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9767
Epoch 57/100
 - 12s - loss: 0.0089 - val_loss: 0.0087
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9776
Epoch 58/100
 - 12s - loss: 0.0088 - val_loss: 0.0099
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9769
Epoch 59/100
 - 12s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9760
 - out_of_sample_accuracy: 0.9757
Epoch 60/100
 - 12s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9776
 - out_of_sample_accuracy: 0.9777
Epoch 61/100
 - 12s - loss: 0.0088 - val_loss: 0.0080
2020-01-14 16:16:48,469 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9798
 - out_of_sample_accuracy: 0.9802
Epoch 62/100
 - 12s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9796
 - out_of_sample_accuracy: 0.9795
Epoch 63/100
 - 12s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9783
Epoch 64/100
 - 12s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9796
 - out_of_sample_accuracy: 0.9798
Epoch 65/100
 - 12s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9796
 - out_of_sample_accuracy: 0.9796
Epoch 66/100
 - 12s - loss: 0.0088 - val_loss: 0.0079
 - val_f1: 0.9782
 - out_of_sample_accuracy: 0.9786
Epoch 67/100
 - 12s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9751
 - out_of_sample_accuracy: 0.9756
Epoch 68/100
 - 12s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9768
Epoch 69/100
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9770
Epoch 70/100
 - 12s - loss: 0.0087 - val_loss: 0.0090
 - val_f1: 0.9771
 - out_of_sample_accuracy: 0.9775
Epoch 71/100
 - 12s - loss: 0.0088 - val_loss: 0.0079
2020-01-14 16:26:35,376 [INFO] epoch = 70. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_70.pickle
 - val_f1: 0.9792
 - out_of_sample_accuracy: 0.9795
Epoch 72/100
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9798
 - out_of_sample_accuracy: 0.9802
Epoch 73/100
 - 12s - loss: 0.0088 - val_loss: 0.0089
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9784
Epoch 74/100
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9767
Epoch 75/100
 - 12s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9805
Epoch 76/100
 - 12s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9789
 - out_of_sample_accuracy: 0.9790
Epoch 77/100
 - 12s - loss: 0.0087 - val_loss: 0.0093
 - val_f1: 0.9766
 - out_of_sample_accuracy: 0.9771
Epoch 78/100
 - 12s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9808
 - out_of_sample_accuracy: 0.9811
Epoch 79/100
 - 12s - loss: 0.0087 - val_loss: 0.0078
 - val_f1: 0.9803
 - out_of_sample_accuracy: 0.9803
Epoch 80/100
 - 12s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9815
 - out_of_sample_accuracy: 0.9819
Epoch 81/100
 - 12s - loss: 0.0087 - val_loss: 0.0082
2020-01-14 16:36:20,972 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9784
Epoch 82/100
 - 12s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9821
 - out_of_sample_accuracy: 0.9823
Epoch 83/100
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9793
 - out_of_sample_accuracy: 0.9795
Epoch 84/100
 - 12s - loss: 0.0087 - val_loss: 0.0080
 - val_f1: 0.9778
 - out_of_sample_accuracy: 0.9782
Epoch 85/100
 - 12s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9779
 - out_of_sample_accuracy: 0.9784
Epoch 86/100
 - 12s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9813
 - out_of_sample_accuracy: 0.9815
Epoch 87/100
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9777
Epoch 88/100
 - 12s - loss: 0.0086 - val_loss: 0.0078
 - val_f1: 0.9806
 - out_of_sample_accuracy: 0.9805
Epoch 89/100
 - 12s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9790
 - out_of_sample_accuracy: 0.9793
Epoch 90/100
 - 12s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9804
 - out_of_sample_accuracy: 0.9805
Epoch 91/100
 - 12s - loss: 0.0086 - val_loss: 0.0077
2020-01-14 16:46:07,239 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.9802
Epoch 92/100
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9764
 - out_of_sample_accuracy: 0.9767
Epoch 93/100
 - 12s - loss: 0.0087 - val_loss: 0.0076
 - val_f1: 0.9812
 - out_of_sample_accuracy: 0.9811
Epoch 94/100
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9773
 - out_of_sample_accuracy: 0.9776
Epoch 95/100
 - 12s - loss: 0.0086 - val_loss: 0.0076
 - val_f1: 0.9800
 - out_of_sample_accuracy: 0.9802
Epoch 96/100
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9804
 - out_of_sample_accuracy: 0.9806
Epoch 97/100
 - 12s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9777
 - out_of_sample_accuracy: 0.9781
Epoch 98/100
 - 12s - loss: 0.0086 - val_loss: 0.0079
 - val_f1: 0.9768
 - out_of_sample_accuracy: 0.9772
Epoch 99/100
 - 12s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9801
 - out_of_sample_accuracy: 0.9802
Epoch 100/100
 - 12s - loss: 0.0086 - val_loss: 0.0078
2020-01-14 16:55:41,414 [INFO] StopperOnGoal: did not reach goal, num_epochs = 100
2020-01-14 16:55:41,415 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 16:56:34,034 [INFO] Last epoch loss evaluation: train_loss = 0.007439, val_loss = 0.007593
2020-01-14 16:56:34,078 [INFO] Training complete. time_to_train = 6191.17 sec, 103.19 min
2020-01-14 16:56:37,204 [INFO] Model saved to results_additional_exps/train_time_ids17_ae_ann_deep_rep3/best_model.pickle
2020-01-14 16:56:37,206 [INFO] Training history saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep3/training_error_history.csv
2020-01-14 16:56:37,342 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep3/training_error_history.png
2020-01-14 16:56:37,471 [INFO] Plot saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep3/training_f1_history.png
2020-01-14 16:56:37,471 [INFO] Making predictions on training, validation, testing data
2020-01-14 16:59:12,095 [INFO] Making predictions complete. time_to_predict = 154.62 sec, 2.58 min
2020-01-14 16:59:12,156 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 16:59:22,473 [INFO] Dataset: Testing. Classification report below
2020-01-14 16:59:22,473 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454265
                   Bot       0.97      0.35      0.52       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.98      0.95      0.96      2058
              DoS Hulk       0.96      0.97      0.96     46025
      DoS Slowhttptest       0.87      0.95      0.91      1100
         DoS slowloris       0.98      0.91      0.94      1159
           FTP-Patator       1.00      0.97      0.98      1587
              PortScan       0.88      0.96      0.92     31761
           SSH-Patator       0.96      0.96      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.80      0.75      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 16:59:22,473 [INFO] Overall accuracy (micro avg): 0.9815104267967084
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 16:59:34,189 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9815         0.9815                       0.9815                0.0017                   0.0185  0.9815
1     Macro avg        0.9969         0.7991                       0.7489                0.0040                   0.2511  0.7614
2  Weighted avg        0.9843         0.9814                       0.9815                0.0300                   0.0185  0.9812
2020-01-14 16:59:44,688 [INFO] Dataset: Validation. Classification report below
2020-01-14 16:59:44,688 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99    454264
                   Bot       0.98      0.31      0.47       391
                  DDoS       1.00      0.99      0.99     25605
         DoS GoldenEye       0.97      0.94      0.95      2059
              DoS Hulk       0.96      0.97      0.96     46025
      DoS Slowhttptest       0.88      0.94      0.91      1099
         DoS slowloris       0.98      0.92      0.95      1159
           FTP-Patator       1.00      0.96      0.98      1587
              PortScan       0.88      0.96      0.92     31761
           SSH-Patator       0.97      0.96      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.98      0.98      0.98    565562
             macro avg       0.80      0.74      0.76    565562
          weighted avg       0.98      0.98      0.98    565562

2020-01-14 16:59:44,688 [INFO] Overall accuracy (micro avg): 0.9815846892117929
2020-01-14 16:59:56,650 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9816         0.9816                       0.9816                0.0017                   0.0184  0.9816
1     Macro avg        0.9969         0.8003                       0.7437                0.0040                   0.2563  0.7568
2  Weighted avg        0.9843         0.9815                       0.9816                0.0298                   0.0184  0.9813
2020-01-14 17:00:31,325 [INFO] Dataset: Training. Classification report below
2020-01-14 17:00:31,325 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       0.99      0.99      0.99   1362791
                   Bot       0.99      0.35      0.51      1174
                  DDoS       1.00      0.99      0.99     76815
         DoS GoldenEye       0.98      0.94      0.96      6176
              DoS Hulk       0.96      0.97      0.96    138074
      DoS Slowhttptest       0.89      0.95      0.92      3300
         DoS slowloris       0.98      0.92      0.95      3478
           FTP-Patator       1.00      0.97      0.98      4761
              PortScan       0.88      0.97      0.92     95282
           SSH-Patator       0.97      0.96      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.98      0.98      0.98   1696684
             macro avg       0.80      0.75      0.76   1696684
          weighted avg       0.98      0.98      0.98   1696684

2020-01-14 17:00:31,325 [INFO] Overall accuracy (micro avg): 0.9819011672179381
2020-01-14 17:01:10,688 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9819         0.9819                       0.9819                0.0016                   0.0181  0.9819
1     Macro avg        0.9970         0.8027                       0.7495                0.0039                   0.2505  0.7630
2  Weighted avg        0.9846         0.9818                       0.9819                0.0292                   0.0181  0.9816
2020-01-14 17:01:10,712 [INFO] Results saved to: results_additional_exps/train_time_ids17_ae_ann_deep_rep3/train_time_ids17_ae_ann_deep_rep3_results.xlsx
2020-01-14 17:01:10,718 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 17:01:10,786 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1
2020-01-14 17:01:10,786 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/run_log.log
2020-01-14 17:01:10,786 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 17:01:10,786 [INFO] Experiment parameters given below
2020-01-14 17:01:10,786 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.977171275, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_deep_rep1'}
2020-01-14 17:01:10,786 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/tf_logs_run_2020_01_14-17_01_10
2020-01-14 17:01:10,786 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 17:01:10,787 [INFO] Reading X, y files
2020-01-14 17:01:10,787 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 17:01:16,015 [INFO] Reading complete. time_to_read=5.23 seconds
2020-01-14 17:01:16,016 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 17:01:17,647 [INFO] Reading complete. time_to_read=1.63 seconds
2020-01-14 17:01:17,647 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 17:01:19,198 [INFO] Reading complete. time_to_read=1.55 seconds
2020-01-14 17:01:19,198 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 17:01:19,467 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-14 17:01:19,467 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 17:01:19,554 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 17:01:19,554 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 17:01:19,640 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 17:01:23,604 [INFO] Initializing model
2020-01-14 17:01:24,071 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:01:24,072 [INFO] =================================================================
2020-01-14 17:01:24,072 [INFO] dense_49 (Dense)             (None, 128)               9984      
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] batch_normalization_37 (Batc (None, 128)               512       
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] dropout_37 (Dropout)         (None, 128)               0         
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] dense_50 (Dense)             (None, 64)                8256      
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] batch_normalization_38 (Batc (None, 64)                256       
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] dropout_38 (Dropout)         (None, 64)                0         
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,072 [INFO] dense_51 (Dense)             (None, 32)                2080      
2020-01-14 17:01:24,072 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] batch_normalization_39 (Batc (None, 32)                128       
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dropout_39 (Dropout)         (None, 32)                0         
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dense_52 (Dense)             (None, 64)                2112      
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] batch_normalization_40 (Batc (None, 64)                256       
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dropout_40 (Dropout)         (None, 64)                0         
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dense_53 (Dense)             (None, 128)               8320      
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] batch_normalization_41 (Batc (None, 128)               512       
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dropout_41 (Dropout)         (None, 128)               0         
2020-01-14 17:01:24,073 [INFO] _________________________________________________________________
2020-01-14 17:01:24,073 [INFO] dense_54 (Dense)             (None, 77)                9933      
2020-01-14 17:01:24,073 [INFO] =================================================================
2020-01-14 17:01:24,074 [INFO] Total params: 42,349
2020-01-14 17:01:24,074 [INFO] Trainable params: 41,517
2020-01-14 17:01:24,074 [INFO] Non-trainable params: 832
2020-01-14 17:01:24,074 [INFO] _________________________________________________________________
2020-01-14 17:01:24,182 [INFO] _________________________________________________________________
2020-01-14 17:01:24,182 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:01:24,182 [INFO] =================================================================
2020-01-14 17:01:24,182 [INFO] dense_55 (Dense)             (None, 64)                2112      
2020-01-14 17:01:24,182 [INFO] _________________________________________________________________
2020-01-14 17:01:24,182 [INFO] batch_normalization_42 (Batc (None, 64)                256       
2020-01-14 17:01:24,182 [INFO] _________________________________________________________________
2020-01-14 17:01:24,182 [INFO] dropout_42 (Dropout)         (None, 64)                0         
2020-01-14 17:01:24,182 [INFO] _________________________________________________________________
2020-01-14 17:01:24,183 [INFO] dense_56 (Dense)             (None, 15)                975       
2020-01-14 17:01:24,183 [INFO] =================================================================
2020-01-14 17:01:24,183 [INFO] Total params: 3,343
2020-01-14 17:01:24,183 [INFO] Trainable params: 3,215
2020-01-14 17:01:24,183 [INFO] Non-trainable params: 128
2020-01-14 17:01:24,183 [INFO] _________________________________________________________________
2020-01-14 17:01:24,183 [INFO] Training model
2020-01-14 17:01:24,183 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:01:51,116 [INFO] Split sizes (instances). total = 1936462, unsupervised = 484115, supervised = 1452347, unsupervised dataset hash = 68856b04d482124ad453c636a52f6791511d4f8e
2020-01-14 17:01:51,116 [INFO] Training autoencoder
 - val_f1: 0.9793
 - out_of_sample_accuracy: 0.9796
Train on 484115 samples, validate on 645487 samples
Epoch 1/10
 - 20s - loss: -2.9008e+00 - val_loss: -3.5511e+00
Epoch 2/10
 - 19s - loss: -3.4818e+00 - val_loss: -3.5997e+00
Epoch 3/10
 - 19s - loss: -3.5259e+00 - val_loss: -3.6141e+00
Epoch 4/10
 - 19s - loss: -3.5475e+00 - val_loss: -3.6217e+00
Epoch 5/10
 - 19s - loss: -3.5590e+00 - val_loss: -3.6268e+00
Epoch 6/10
 - 19s - loss: -3.5692e+00 - val_loss: -3.6319e+00
Epoch 7/10
 - 19s - loss: -3.5766e+00 - val_loss: -3.6367e+00
Epoch 8/10
 - 19s - loss: -3.5807e+00 - val_loss: -3.6398e+00
Epoch 9/10
 - 19s - loss: -3.5858e+00 - val_loss: -3.6423e+00
Epoch 10/10
 - 19s - loss: -3.5899e+00 - val_loss: -3.6403e+00
2020-01-14 17:05:06,770 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:05:40,892 [INFO] Last epoch loss evaluation: train_loss = -3.637256, val_loss = -3.642349
2020-01-14 17:05:40,893 [INFO] Training autoencoder complete
2020-01-14 17:05:40,893 [INFO] Encoding data for supervised training
2020-01-14 17:06:45,284 [INFO] Encoding complete
2020-01-14 17:06:45,284 [INFO] Training neural network layers (after autoencoder)
Train on 1452347 samples, validate on 645487 samples
Epoch 1/100
 - 15s - loss: 0.0162 - val_loss: 0.0091
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:08:04,965 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9772, current_metric = 0.9812, num_epochs = 1
2020-01-14 17:08:05,200 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:09:12,078 [INFO] Last epoch loss evaluation: train_loss = 0.009041, val_loss = 0.009071
2020-01-14 17:09:12,125 [INFO] Training complete. time_to_train = 467.94 sec, 7.80 min
2020-01-14 17:09:17,590 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/best_model.pickle
2020-01-14 17:09:17,610 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/training_error_history.csv
2020-01-14 17:09:17,829 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/training_error_history.png
2020-01-14 17:09:17,940 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/training_f1_history.png
2020-01-14 17:09:17,940 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:12:33,608 [INFO] Making predictions complete. time_to_predict = 195.67 sec, 3.26 min
2020-01-14 17:12:33,678 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:12:45,855 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:12:45,855 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       0.99      0.99      0.99     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.98      0.72      0.83      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.74      0.43      0.55      5596
   DoS attacks-Slowloris       0.99      0.52      0.68       440
          FTP-BruteForce       0.68      0.89      0.77      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      0.99      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.67      0.64      0.64    645488
            weighted avg       0.97      0.98      0.98    645488

2020-01-14 17:12:45,855 [INFO] Overall accuracy (micro avg): 0.9815085640631585
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 17:12:59,698 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9815         0.9815                       0.9815                0.0013                   0.0185  0.9815
1     Macro avg        0.9975         0.6690                       0.6361                0.0049                   0.3639  0.6410
2  Weighted avg        0.9900         0.9720                       0.9815                0.0544                   0.0185  0.9761
2020-01-14 17:13:11,867 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:13:11,867 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       0.99      0.99      0.99     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.98      0.72      0.83      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.76      0.43      0.55      5596
   DoS attacks-Slowloris       0.97      0.54      0.70       439
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      0.99      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.64      0.64    645487
            weighted avg       0.97      0.98      0.98    645487

2020-01-14 17:13:11,867 [INFO] Overall accuracy (micro avg): 0.9816216283209421
2020-01-14 17:13:25,695 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9816         0.9816                       0.9816                0.0013                   0.0184  0.9816
1     Macro avg        0.9975         0.6733                       0.6371                0.0048                   0.3629  0.6450
2  Weighted avg        0.9900         0.9721                       0.9816                0.0541                   0.0184  0.9762
2020-01-14 17:14:05,411 [INFO] Dataset: Training. Classification report below
2020-01-14 17:14:05,411 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       0.99      0.99      0.99     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.98      0.73      0.84      4954
        DoS attacks-Hulk       0.98      1.00      0.99     55435
DoS attacks-SlowHTTPTest       0.75      0.43      0.55     16787
   DoS attacks-Slowloris       0.99      0.50      0.66      1318
          FTP-BruteForce       0.68      0.90      0.78     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       0.99      1.00      0.99     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.67      0.63      0.64   1936462
            weighted avg       0.97      0.98      0.98   1936462

2020-01-14 17:14:05,411 [INFO] Overall accuracy (micro avg): 0.9815529558545429
2020-01-14 17:14:50,509 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9816         0.9816                       0.9816                0.0013                   0.0184  0.9816
1     Macro avg        0.9975         0.6711                       0.6341                0.0048                   0.3659  0.6408
2  Weighted avg        0.9900         0.9720                       0.9816                0.0542                   0.0184  0.9761
2020-01-14 17:14:50,551 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep1/train_time_ids18_subset_ae_ann_deep_rep1_results.xlsx
2020-01-14 17:14:50,556 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 17:14:50,640 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2
2020-01-14 17:14:50,640 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/run_log.log
2020-01-14 17:14:50,640 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 17:14:50,640 [INFO] Experiment parameters given below
2020-01-14 17:14:50,640 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.977171275, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_deep_rep2'}
2020-01-14 17:14:50,640 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/tf_logs_run_2020_01_14-17_14_50
2020-01-14 17:14:50,640 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 17:14:50,641 [INFO] Reading X, y files
2020-01-14 17:14:50,641 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 17:14:56,076 [INFO] Reading complete. time_to_read=5.44 seconds
2020-01-14 17:14:56,077 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 17:14:57,982 [INFO] Reading complete. time_to_read=1.91 seconds
2020-01-14 17:14:57,983 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 17:14:59,675 [INFO] Reading complete. time_to_read=1.69 seconds
2020-01-14 17:14:59,675 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 17:15:00,162 [INFO] Reading complete. time_to_read=0.49 seconds
2020-01-14 17:15:00,163 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 17:15:00,357 [INFO] Reading complete. time_to_read=0.19 seconds
2020-01-14 17:15:00,357 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 17:15:00,531 [INFO] Reading complete. time_to_read=0.17 seconds
2020-01-14 17:15:04,492 [INFO] Initializing model
2020-01-14 17:15:05,176 [INFO] _________________________________________________________________
2020-01-14 17:15:05,176 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:15:05,176 [INFO] =================================================================
2020-01-14 17:15:05,176 [INFO] dense_57 (Dense)             (None, 128)               9984      
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] batch_normalization_43 (Batc (None, 128)               512       
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] dropout_43 (Dropout)         (None, 128)               0         
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] dense_58 (Dense)             (None, 64)                8256      
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] batch_normalization_44 (Batc (None, 64)                256       
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] dropout_44 (Dropout)         (None, 64)                0         
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] dense_59 (Dense)             (None, 32)                2080      
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] batch_normalization_45 (Batc (None, 32)                128       
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,177 [INFO] dropout_45 (Dropout)         (None, 32)                0         
2020-01-14 17:15:05,177 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] dense_60 (Dense)             (None, 64)                2112      
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] batch_normalization_46 (Batc (None, 64)                256       
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] dropout_46 (Dropout)         (None, 64)                0         
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] dense_61 (Dense)             (None, 128)               8320      
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] batch_normalization_47 (Batc (None, 128)               512       
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] dropout_47 (Dropout)         (None, 128)               0         
2020-01-14 17:15:05,178 [INFO] _________________________________________________________________
2020-01-14 17:15:05,178 [INFO] dense_62 (Dense)             (None, 77)                9933      
2020-01-14 17:15:05,178 [INFO] =================================================================
2020-01-14 17:15:05,178 [INFO] Total params: 42,349
2020-01-14 17:15:05,179 [INFO] Trainable params: 41,517
2020-01-14 17:15:05,179 [INFO] Non-trainable params: 832
2020-01-14 17:15:05,179 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:15:05,288 [INFO] =================================================================
2020-01-14 17:15:05,288 [INFO] dense_63 (Dense)             (None, 64)                2112      
2020-01-14 17:15:05,288 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] batch_normalization_48 (Batc (None, 64)                256       
2020-01-14 17:15:05,288 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] dropout_48 (Dropout)         (None, 64)                0         
2020-01-14 17:15:05,288 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] dense_64 (Dense)             (None, 15)                975       
2020-01-14 17:15:05,288 [INFO] =================================================================
2020-01-14 17:15:05,288 [INFO] Total params: 3,343
2020-01-14 17:15:05,288 [INFO] Trainable params: 3,215
2020-01-14 17:15:05,288 [INFO] Non-trainable params: 128
2020-01-14 17:15:05,288 [INFO] _________________________________________________________________
2020-01-14 17:15:05,288 [INFO] Training model
2020-01-14 17:15:05,288 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:15:28,386 [INFO] Split sizes (instances). total = 1936462, unsupervised = 484115, supervised = 1452347, unsupervised dataset hash = 7424b8ba47a1a8d2016208295d66d7f59ede9654
2020-01-14 17:15:28,386 [INFO] Training autoencoder
 - val_f1: 0.9761
 - out_of_sample_accuracy: 0.9812
Train on 484115 samples, validate on 645487 samples
Epoch 1/10
 - 22s - loss: -2.9197e+00 - val_loss: -3.5642e+00
Epoch 2/10
 - 21s - loss: -3.4943e+00 - val_loss: -3.5987e+00
Epoch 3/10
 - 21s - loss: -3.5341e+00 - val_loss: -3.6115e+00
Epoch 4/10
 - 21s - loss: -3.5525e+00 - val_loss: -3.6186e+00
Epoch 5/10
 - 21s - loss: -3.5660e+00 - val_loss: -3.6271e+00
Epoch 6/10
 - 21s - loss: -3.5756e+00 - val_loss: -3.6319e+00
Epoch 7/10
 - 21s - loss: -3.5828e+00 - val_loss: -3.6345e+00
Epoch 8/10
 - 21s - loss: -3.5888e+00 - val_loss: -3.6373e+00
Epoch 9/10
 - 21s - loss: -3.5920e+00 - val_loss: -3.6395e+00
Epoch 10/10
 - 21s - loss: -3.5951e+00 - val_loss: -3.6410e+00
2020-01-14 17:19:01,055 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:19:36,816 [INFO] Last epoch loss evaluation: train_loss = -3.643790, val_loss = -3.641028
2020-01-14 17:19:36,816 [INFO] Training autoencoder complete
2020-01-14 17:19:36,816 [INFO] Encoding data for supervised training
2020-01-14 17:20:48,309 [INFO] Encoding complete
2020-01-14 17:20:48,309 [INFO] Training neural network layers (after autoencoder)
Train on 1452347 samples, validate on 645487 samples
Epoch 1/100
 - 17s - loss: 0.0153 - val_loss: 0.0087
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:22:14,649 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9772, current_metric = 0.9814, num_epochs = 1
2020-01-14 17:22:14,927 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:23:30,408 [INFO] Last epoch loss evaluation: train_loss = 0.008703, val_loss = 0.008734
2020-01-14 17:23:30,457 [INFO] Training complete. time_to_train = 505.17 sec, 8.42 min
2020-01-14 17:23:36,791 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/best_model.pickle
2020-01-14 17:23:36,793 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/training_error_history.csv
2020-01-14 17:23:36,921 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/training_error_history.png
2020-01-14 17:23:37,032 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/training_f1_history.png
2020-01-14 17:23:37,032 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:27:09,333 [INFO] Making predictions complete. time_to_predict = 212.30 sec, 3.54 min
2020-01-14 17:27:09,404 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:27:21,642 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:27:21,642 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.95      0.79      0.86      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.65      0.55      0.59      5596
   DoS attacks-Slowloris       0.99      0.62      0.76       440
          FTP-BruteForce       0.70      0.79      0.74      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.66      0.65      0.65    645488
            weighted avg       0.97      0.98      0.98    645488

2020-01-14 17:27:21,642 [INFO] Overall accuracy (micro avg): 0.9816851746275685
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 17:27:35,551 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9817         0.9817                       0.9817                0.0013                   0.0183  0.9817
1     Macro avg        0.9976         0.6631                       0.6485                0.0047                   0.3515  0.6504
2  Weighted avg        0.9903         0.9718                       0.9817                0.0526                   0.0183  0.9766
2020-01-14 17:27:47,828 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:27:47,828 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.95      0.77      0.85      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.65      0.54      0.59      5596
   DoS attacks-Slowloris       0.98      0.63      0.76       439
          FTP-BruteForce       0.70      0.79      0.74      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.65      0.65    645487
            weighted avg       0.97      0.98      0.98    645487

2020-01-14 17:27:47,828 [INFO] Overall accuracy (micro avg): 0.9817207782650929
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 17:28:01,788 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9817         0.9817                       0.9817                0.0013                   0.0183  0.9817
1     Macro avg        0.9976         0.6668                       0.6467                0.0047                   0.3533  0.6521
2  Weighted avg        0.9904         0.9718                       0.9817                0.0525                   0.0183  0.9766
2020-01-14 17:28:41,521 [INFO] Dataset: Training. Classification report below
2020-01-14 17:28:41,521 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.95      0.78      0.86      4954
        DoS attacks-Hulk       0.98      1.00      0.99     55435
DoS attacks-SlowHTTPTest       0.65      0.54      0.59     16787
   DoS attacks-Slowloris       0.99      0.64      0.78      1318
          FTP-BruteForce       0.70      0.79      0.74     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       0.99      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.66      0.65      0.65   1936462
            weighted avg       0.97      0.98      0.98   1936462

2020-01-14 17:28:41,521 [INFO] Overall accuracy (micro avg): 0.9816799916548841
2020-01-14 17:29:26,656 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9817         0.9817                       0.9817                0.0013                   0.0183  0.9817
1     Macro avg        0.9976         0.6644                       0.6473                0.0047                   0.3527  0.6510
2  Weighted avg        0.9904         0.9718                       0.9817                0.0524                   0.0183  0.9766
2020-01-14 17:29:26,705 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep2/train_time_ids18_subset_ae_ann_deep_rep2_results.xlsx
2020-01-14 17:29:26,710 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 17:29:26,794 [INFO] Created directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3
2020-01-14 17:29:26,794 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/run_log.log
2020-01-14 17:29:26,794 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 17:29:26,794 [INFO] Experiment parameters given below
2020-01-14 17:29:26,794 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.977171275, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'train_time_ids18_subset_ae_ann_deep_rep3'}
2020-01-14 17:29:26,794 [INFO] Created tensorboard log directory: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/tf_logs_run_2020_01_14-17_29_26
2020-01-14 17:29:26,795 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-14 17:29:26,795 [INFO] Reading X, y files
2020-01-14 17:29:26,795 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-14 17:29:31,276 [INFO] Reading complete. time_to_read=4.48 seconds
2020-01-14 17:29:31,277 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-14 17:29:32,834 [INFO] Reading complete. time_to_read=1.56 seconds
2020-01-14 17:29:32,834 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-14 17:29:34,387 [INFO] Reading complete. time_to_read=1.55 seconds
2020-01-14 17:29:34,387 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-14 17:29:34,638 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-14 17:29:34,638 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-14 17:29:34,726 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 17:29:34,727 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-14 17:29:34,813 [INFO] Reading complete. time_to_read=0.09 seconds
2020-01-14 17:29:38,725 [INFO] Initializing model
2020-01-14 17:29:39,171 [INFO] _________________________________________________________________
2020-01-14 17:29:39,171 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:29:39,172 [INFO] =================================================================
2020-01-14 17:29:39,172 [INFO] dense_65 (Dense)             (None, 128)               9984      
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] batch_normalization_49 (Batc (None, 128)               512       
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] dropout_49 (Dropout)         (None, 128)               0         
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] dense_66 (Dense)             (None, 64)                8256      
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] batch_normalization_50 (Batc (None, 64)                256       
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] dropout_50 (Dropout)         (None, 64)                0         
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] dense_67 (Dense)             (None, 32)                2080      
2020-01-14 17:29:39,172 [INFO] _________________________________________________________________
2020-01-14 17:29:39,172 [INFO] batch_normalization_51 (Batc (None, 32)                128       
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dropout_51 (Dropout)         (None, 32)                0         
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dense_68 (Dense)             (None, 64)                2112      
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] batch_normalization_52 (Batc (None, 64)                256       
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dropout_52 (Dropout)         (None, 64)                0         
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dense_69 (Dense)             (None, 128)               8320      
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] batch_normalization_53 (Batc (None, 128)               512       
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dropout_53 (Dropout)         (None, 128)               0         
2020-01-14 17:29:39,173 [INFO] _________________________________________________________________
2020-01-14 17:29:39,173 [INFO] dense_70 (Dense)             (None, 77)                9933      
2020-01-14 17:29:39,173 [INFO] =================================================================
2020-01-14 17:29:39,174 [INFO] Total params: 42,349
2020-01-14 17:29:39,174 [INFO] Trainable params: 41,517
2020-01-14 17:29:39,174 [INFO] Non-trainable params: 832
2020-01-14 17:29:39,174 [INFO] _________________________________________________________________
2020-01-14 17:29:39,284 [INFO] _________________________________________________________________
2020-01-14 17:29:39,284 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:29:39,284 [INFO] =================================================================
2020-01-14 17:29:39,284 [INFO] dense_71 (Dense)             (None, 64)                2112      
2020-01-14 17:29:39,285 [INFO] _________________________________________________________________
2020-01-14 17:29:39,285 [INFO] batch_normalization_54 (Batc (None, 64)                256       
2020-01-14 17:29:39,285 [INFO] _________________________________________________________________
2020-01-14 17:29:39,285 [INFO] dropout_54 (Dropout)         (None, 64)                0         
2020-01-14 17:29:39,285 [INFO] _________________________________________________________________
2020-01-14 17:29:39,285 [INFO] dense_72 (Dense)             (None, 15)                975       
2020-01-14 17:29:39,285 [INFO] =================================================================
2020-01-14 17:29:39,285 [INFO] Total params: 3,343
2020-01-14 17:29:39,285 [INFO] Trainable params: 3,215
2020-01-14 17:29:39,285 [INFO] Non-trainable params: 128
2020-01-14 17:29:39,285 [INFO] _________________________________________________________________
2020-01-14 17:29:39,285 [INFO] Training model
2020-01-14 17:29:39,285 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:30:06,940 [INFO] Split sizes (instances). total = 1936462, unsupervised = 484115, supervised = 1452347, unsupervised dataset hash = 9e118077f5a2fbb0f8c275db3a3e15a3c33514fd
2020-01-14 17:30:06,940 [INFO] Training autoencoder
 - val_f1: 0.9765
 - out_of_sample_accuracy: 0.9814
Train on 484115 samples, validate on 645487 samples
Epoch 1/10
 - 23s - loss: -2.9293e+00 - val_loss: -3.5544e+00
Epoch 2/10
 - 21s - loss: -3.4842e+00 - val_loss: -3.6000e+00
Epoch 3/10
 - 21s - loss: -3.5285e+00 - val_loss: -3.6136e+00
Epoch 4/10
 - 21s - loss: -3.5471e+00 - val_loss: -3.6228e+00
Epoch 5/10
 - 21s - loss: -3.5607e+00 - val_loss: -3.6283e+00
Epoch 6/10
 - 21s - loss: -3.5696e+00 - val_loss: -3.6330e+00
Epoch 7/10
 - 21s - loss: -3.5761e+00 - val_loss: -3.6373e+00
Epoch 8/10
 - 21s - loss: -3.5816e+00 - val_loss: -3.6361e+00
Epoch 9/10
 - 21s - loss: -3.5854e+00 - val_loss: -3.6400e+00
Epoch 10/10
 - 21s - loss: -3.5890e+00 - val_loss: -3.6419e+00
2020-01-14 17:33:46,574 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:34:24,454 [INFO] Last epoch loss evaluation: train_loss = -3.637483, val_loss = -3.641853
2020-01-14 17:34:24,454 [INFO] Training autoencoder complete
2020-01-14 17:34:24,454 [INFO] Encoding data for supervised training
2020-01-14 17:35:41,004 [INFO] Encoding complete
2020-01-14 17:35:41,004 [INFO] Training neural network layers (after autoencoder)
Train on 1452347 samples, validate on 645487 samples
Epoch 1/100
 - 17s - loss: 0.0167 - val_loss: 0.0090
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:37:13,646 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9772, current_metric = 0.9811, num_epochs = 1
2020-01-14 17:37:13,954 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:38:30,590 [INFO] Last epoch loss evaluation: train_loss = 0.008966, val_loss = 0.008970
2020-01-14 17:38:30,642 [INFO] Training complete. time_to_train = 531.36 sec, 8.86 min
2020-01-14 17:38:37,730 [INFO] Model saved to results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/best_model.pickle
2020-01-14 17:38:37,732 [INFO] Training history saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/training_error_history.csv
2020-01-14 17:38:37,867 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/training_error_history.png
2020-01-14 17:38:37,980 [INFO] Plot saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/training_f1_history.png
2020-01-14 17:38:37,980 [INFO] Making predictions on training, validation, testing data
2020-01-14 17:42:28,965 [INFO] Making predictions complete. time_to_predict = 230.98 sec, 3.85 min
2020-01-14 17:42:29,036 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 17:42:41,260 [INFO] Dataset: Testing. Classification report below
2020-01-14 17:42:41,260 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       0.98      1.00      0.99     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.96      0.81      0.88      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.75      0.44      0.56      5596
   DoS attacks-Slowloris       0.99      0.62      0.76       440
          FTP-BruteForce       0.69      0.89      0.78      7718
           Infilteration       0.00      0.00      0.00      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      0.99      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.67      0.65      0.65    645488
            weighted avg       0.97      0.98      0.98    645488

2020-01-14 17:42:41,260 [INFO] Overall accuracy (micro avg): 0.9816650348263639
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 17:42:55,148 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9817         0.9817                       0.9817                0.0013                   0.0183  0.9817
1     Macro avg        0.9976         0.6668                       0.6499                0.0047                   0.3501  0.6498
2  Weighted avg        0.9900         0.9721                       0.9817                0.0529                   0.0183  0.9763
2020-01-14 17:43:07,364 [INFO] Dataset: Validation. Classification report below
2020-01-14 17:43:07,365 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       0.98      1.00      0.99     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.99      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.96      0.80      0.87      1651
        DoS attacks-Hulk       0.98      1.00      0.99     18478
DoS attacks-SlowHTTPTest       0.77      0.44      0.56      5596
   DoS attacks-Slowloris       0.98      0.65      0.78       439
          FTP-BruteForce       0.69      0.90      0.78      7718
           Infilteration       0.00      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       0.99      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.67      0.65      0.65    645487
            weighted avg       0.97      0.98      0.98    645487

2020-01-14 17:43:07,365 [INFO] Overall accuracy (micro avg): 0.9817966899410833
2020-01-14 17:43:21,255 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9818         0.9818                       0.9818                0.0013                   0.0182  0.9818
1     Macro avg        0.9976         0.6711                       0.6501                0.0047                   0.3499  0.6528
2  Weighted avg        0.9901         0.9723                       0.9818                0.0528                   0.0182  0.9764
2020-01-14 17:44:00,967 [INFO] Dataset: Training. Classification report below
2020-01-14 17:44:00,967 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       0.99      1.00      0.99     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      0.98      0.82       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.96      0.80      0.87      4954
        DoS attacks-Hulk       0.98      1.00      0.99     55435
DoS attacks-SlowHTTPTest       0.76      0.44      0.56     16787
   DoS attacks-Slowloris       0.98      0.65      0.78      1318
          FTP-BruteForce       0.69      0.90      0.78     23153
           Infilteration       0.00      0.00      0.00     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       0.99      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.67      0.65      0.65   1936462
            weighted avg       0.97      0.98      0.98   1936462

2020-01-14 17:44:00,967 [INFO] Overall accuracy (micro avg): 0.9817564196973656
2020-01-14 17:44:46,073 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9818         0.9818                       0.9818                0.0013                   0.0182  0.9818
1     Macro avg        0.9976         0.6686                       0.6498                0.0047                   0.3502  0.6513
2  Weighted avg        0.9901         0.9722                       0.9818                0.0527                   0.0182  0.9764
2020-01-14 17:44:46,100 [INFO] Results saved to: results_additional_exps/train_time_ids18_subset_ae_ann_deep_rep3/train_time_ids18_subset_ae_ann_deep_rep3_results.xlsx
2020-01-14 17:44:46,105 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 17:44:46,183 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1
2020-01-14 17:44:46,183 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/run_log.log
2020-01-14 17:44:46,183 [INFO] ================= Running experiment no. 1  ================= 

2020-01-14 17:44:46,183 [INFO] Experiment parameters given below
2020-01-14 17:44:46,183 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_deep_rep1', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.919829173, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_deep_rep1'}
2020-01-14 17:44:46,184 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/tf_logs_run_2020_01_14-17_44_46
2020-01-14 17:44:46,184 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 17:44:46,204 [INFO] Reading X, y files
2020-01-14 17:44:46,204 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 17:44:54,965 [INFO] Reading complete. time_to_read=8.76 seconds
2020-01-14 17:44:54,965 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 17:44:57,219 [INFO] Reading complete. time_to_read=2.25 seconds
2020-01-14 17:44:57,220 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 17:44:57,916 [INFO] Reading complete. time_to_read=0.70 seconds
2020-01-14 17:44:57,917 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 17:44:58,329 [INFO] Reading complete. time_to_read=0.41 seconds
2020-01-14 17:44:58,330 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 17:44:58,453 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-14 17:44:58,453 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 17:44:58,499 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-14 17:45:49,962 [INFO] Initializing model
2020-01-14 17:45:53,687 [INFO] _________________________________________________________________
2020-01-14 17:45:53,689 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:45:53,690 [INFO] =================================================================
2020-01-14 17:45:53,691 [INFO] dense_73 (Dense)             (None, 128)               15872     
2020-01-14 17:45:53,691 [INFO] _________________________________________________________________
2020-01-14 17:45:53,691 [INFO] batch_normalization_55 (Batc (None, 128)               512       
2020-01-14 17:45:53,691 [INFO] _________________________________________________________________
2020-01-14 17:45:53,691 [INFO] dropout_55 (Dropout)         (None, 128)               0         
2020-01-14 17:45:53,691 [INFO] _________________________________________________________________
2020-01-14 17:45:53,692 [INFO] dense_74 (Dense)             (None, 64)                8256      
2020-01-14 17:45:53,692 [INFO] _________________________________________________________________
2020-01-14 17:45:53,692 [INFO] batch_normalization_56 (Batc (None, 64)                256       
2020-01-14 17:45:53,692 [INFO] _________________________________________________________________
2020-01-14 17:45:53,692 [INFO] dropout_56 (Dropout)         (None, 64)                0         
2020-01-14 17:45:53,692 [INFO] _________________________________________________________________
2020-01-14 17:45:53,692 [INFO] dense_75 (Dense)             (None, 32)                2080      
2020-01-14 17:45:53,692 [INFO] _________________________________________________________________
2020-01-14 17:45:53,692 [INFO] batch_normalization_57 (Batc (None, 32)                128       
2020-01-14 17:45:53,693 [INFO] _________________________________________________________________
2020-01-14 17:45:53,693 [INFO] dropout_57 (Dropout)         (None, 32)                0         
2020-01-14 17:45:53,693 [INFO] _________________________________________________________________
2020-01-14 17:45:53,693 [INFO] dense_76 (Dense)             (None, 64)                2112      
2020-01-14 17:45:53,693 [INFO] _________________________________________________________________
2020-01-14 17:45:53,693 [INFO] batch_normalization_58 (Batc (None, 64)                256       
2020-01-14 17:45:53,693 [INFO] _________________________________________________________________
2020-01-14 17:45:53,693 [INFO] dropout_58 (Dropout)         (None, 64)                0         
2020-01-14 17:45:53,693 [INFO] _________________________________________________________________
2020-01-14 17:45:53,694 [INFO] dense_77 (Dense)             (None, 128)               8320      
2020-01-14 17:45:53,694 [INFO] _________________________________________________________________
2020-01-14 17:45:53,694 [INFO] batch_normalization_59 (Batc (None, 128)               512       
2020-01-14 17:45:53,694 [INFO] _________________________________________________________________
2020-01-14 17:45:53,694 [INFO] dropout_59 (Dropout)         (None, 128)               0         
2020-01-14 17:45:53,694 [INFO] _________________________________________________________________
2020-01-14 17:45:53,694 [INFO] dense_78 (Dense)             (None, 123)               15867     
2020-01-14 17:45:53,694 [INFO] =================================================================
2020-01-14 17:45:53,695 [INFO] Total params: 54,171
2020-01-14 17:45:53,695 [INFO] Trainable params: 53,339
2020-01-14 17:45:53,695 [INFO] Non-trainable params: 832
2020-01-14 17:45:53,695 [INFO] _________________________________________________________________
2020-01-14 17:45:54,105 [INFO] _________________________________________________________________
2020-01-14 17:45:54,106 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 17:45:54,106 [INFO] =================================================================
2020-01-14 17:45:54,106 [INFO] dense_79 (Dense)             (None, 64)                2112      
2020-01-14 17:45:54,106 [INFO] _________________________________________________________________
2020-01-14 17:45:54,107 [INFO] batch_normalization_60 (Batc (None, 64)                256       
2020-01-14 17:45:54,107 [INFO] _________________________________________________________________
2020-01-14 17:45:54,108 [INFO] dropout_60 (Dropout)         (None, 64)                0         
2020-01-14 17:45:54,108 [INFO] _________________________________________________________________
2020-01-14 17:45:54,108 [INFO] dense_80 (Dense)             (None, 5)                 325       
2020-01-14 17:45:54,108 [INFO] =================================================================
2020-01-14 17:45:54,109 [INFO] Total params: 2,693
2020-01-14 17:45:54,109 [INFO] Trainable params: 2,565
2020-01-14 17:45:54,109 [INFO] Non-trainable params: 128
2020-01-14 17:45:54,109 [INFO] _________________________________________________________________
2020-01-14 17:45:54,109 [INFO] Training model
2020-01-14 17:45:54,110 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 17:48:51,672 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 2b8a2a8044de4201e2aee21cb1b1c4843394fb61
2020-01-14 17:48:51,698 [INFO] Training autoencoder
 - val_f1: 0.9763
 - out_of_sample_accuracy: 0.9811
Train on 979686 samples, validate on 979687 samples
Epoch 1/10
 - 81s - loss: -1.8435e+00 - val_loss: -2.0673e+00
Epoch 2/10
 - 50s - loss: -2.0549e+00 - val_loss: -2.0912e+00
Epoch 3/10
 - 49s - loss: -2.0718e+00 - val_loss: -2.0966e+00
Epoch 4/10
 - 49s - loss: -2.0796e+00 - val_loss: -2.1013e+00
Epoch 5/10
 - 49s - loss: -2.0852e+00 - val_loss: -2.1038e+00
Epoch 6/10
 - 49s - loss: -2.0887e+00 - val_loss: -2.1059e+00
Epoch 7/10
 - 49s - loss: -2.0906e+00 - val_loss: -2.1069e+00
Epoch 8/10
 - 49s - loss: -2.0927e+00 - val_loss: -2.1087e+00
Epoch 9/10
 - 49s - loss: -2.0943e+00 - val_loss: -2.1091e+00
Epoch 10/10
 - 49s - loss: -2.0954e+00 - val_loss: -2.1099e+00
2020-01-14 17:57:55,695 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 17:59:17,403 [INFO] Last epoch loss evaluation: train_loss = -2.111673, val_loss = -2.109948
2020-01-14 17:59:17,416 [INFO] Training autoencoder complete
2020-01-14 17:59:17,416 [INFO] Encoding data for supervised training
2020-01-14 18:01:51,749 [INFO] Encoding complete
2020-01-14 18:01:51,804 [INFO] Training neural network layers (after autoencoder)
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 32s - loss: 0.0050 - val_loss: 0.0013
2020-01-14 18:03:34,099 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9198, current_metric = 0.9233, num_epochs = 1
2020-01-14 18:03:35,095 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 18:06:06,580 [INFO] Last epoch loss evaluation: train_loss = 0.001273, val_loss = 0.001250
2020-01-14 18:06:06,823 [INFO] Training complete. time_to_train = 1212.71 sec, 20.21 min
2020-01-14 18:06:14,991 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/best_model.pickle
2020-01-14 18:06:15,091 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/training_error_history.csv
2020-01-14 18:06:15,596 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/training_error_history.png
2020-01-14 18:06:15,708 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/training_f1_history.png
2020-01-14 18:06:15,708 [INFO] Making predictions on training, validation, testing data
2020-01-14 18:12:46,934 [INFO] Making predictions complete. time_to_predict = 391.23 sec, 6.52 min
2020-01-14 18:12:47,158 [INFO] Evaluating predictions (results)
2020-01-14 18:12:51,849 [INFO] Dataset: Testing. Classification report below
2020-01-14 18:12:51,849 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.73      1.00      0.84     60593
       probe       0.76      0.72      0.74      4166
         r2l       0.94      0.03      0.07     13781
         u2r       0.60      0.00      0.00      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.81      0.55      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2020-01-14 18:12:51,849 [INFO] Overall accuracy (micro avg): 0.9233576290313765
2020-01-14 18:12:57,233 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9234         0.9234                       0.9234                0.0192                   0.0766  0.9234
1     Macro avg        0.9693         0.8054                       0.5452                0.0198                   0.4548  0.5274
2  Weighted avg        0.9672         0.9362                       0.9234                0.0224                   0.0766  0.9046
2020-01-14 18:13:13,642 [INFO] Dataset: Validation. Classification report below
2020-01-14 18:13:13,643 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.96      0.97      8221
         r2l       0.76      0.50      0.61       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.75      0.69      0.72    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 18:13:13,643 [INFO] Overall accuracy (micro avg): 0.9992548640535192
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 18:13:32,247 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9993         0.9993                       0.9993                0.0002                   0.0007  0.9993
1     Macro avg        0.9997         0.7503                       0.6920                0.0004                   0.3080  0.7157
2  Weighted avg        0.9996         0.9992                       0.9993                0.0011                   0.0007  0.9992
2020-01-14 18:14:44,518 [INFO] Dataset: Training. Classification report below
2020-01-14 18:14:44,518 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.96      0.97     32881
         r2l       0.73      0.50      0.59       901
         u2r       1.00      0.02      0.05        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.94      0.70      0.72   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 18:14:44,518 [INFO] Overall accuracy (micro avg): 0.9992364900590598
2020-01-14 18:16:06,362 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.9443                       0.6959                0.0004                   0.3041  0.7226
2  Weighted avg        0.9996         0.9992                       0.9992                0.0012                   0.0008  0.9992
2020-01-14 18:16:06,415 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep1/train_time_kdd99_ae_ann_deep_rep1_results.xlsx
2020-01-14 18:16:06,423 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-14 18:16:06,721 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2
2020-01-14 18:16:06,728 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/run_log.log
2020-01-14 18:16:06,728 [INFO] ================= Running experiment no. 2  ================= 

2020-01-14 18:16:06,728 [INFO] Experiment parameters given below
2020-01-14 18:16:06,728 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_deep_rep2', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.919829173, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_deep_rep2'}
2020-01-14 18:16:06,728 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/tf_logs_run_2020_01_14-18_16_06
2020-01-14 18:16:06,728 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 18:16:06,742 [INFO] Reading X, y files
2020-01-14 18:16:06,742 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 18:16:15,881 [INFO] Reading complete. time_to_read=9.14 seconds
2020-01-14 18:16:15,882 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 18:16:18,118 [INFO] Reading complete. time_to_read=2.24 seconds
2020-01-14 18:16:18,118 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 18:16:18,789 [INFO] Reading complete. time_to_read=0.67 seconds
2020-01-14 18:16:18,789 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 18:16:19,533 [INFO] Reading complete. time_to_read=0.74 seconds
2020-01-14 18:16:19,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 18:16:19,688 [INFO] Reading complete. time_to_read=0.15 seconds
2020-01-14 18:16:19,688 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 18:16:19,730 [INFO] Reading complete. time_to_read=0.04 seconds
2020-01-14 18:17:13,188 [INFO] Initializing model
2020-01-14 18:17:16,338 [INFO] _________________________________________________________________
2020-01-14 18:17:16,339 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:17:16,339 [INFO] =================================================================
2020-01-14 18:17:16,340 [INFO] dense_81 (Dense)             (None, 128)               15872     
2020-01-14 18:17:16,340 [INFO] _________________________________________________________________
2020-01-14 18:17:16,340 [INFO] batch_normalization_61 (Batc (None, 128)               512       
2020-01-14 18:17:16,340 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] dropout_61 (Dropout)         (None, 128)               0         
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] dense_82 (Dense)             (None, 64)                8256      
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] batch_normalization_62 (Batc (None, 64)                256       
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] dropout_62 (Dropout)         (None, 64)                0         
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] dense_83 (Dense)             (None, 32)                2080      
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] batch_normalization_63 (Batc (None, 32)                128       
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,341 [INFO] dropout_63 (Dropout)         (None, 32)                0         
2020-01-14 18:17:16,341 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] dense_84 (Dense)             (None, 64)                2112      
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] batch_normalization_64 (Batc (None, 64)                256       
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] dropout_64 (Dropout)         (None, 64)                0         
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] dense_85 (Dense)             (None, 128)               8320      
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] batch_normalization_65 (Batc (None, 128)               512       
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] dropout_65 (Dropout)         (None, 128)               0         
2020-01-14 18:17:16,342 [INFO] _________________________________________________________________
2020-01-14 18:17:16,342 [INFO] dense_86 (Dense)             (None, 123)               15867     
2020-01-14 18:17:16,342 [INFO] =================================================================
2020-01-14 18:17:16,343 [INFO] Total params: 54,171
2020-01-14 18:17:16,343 [INFO] Trainable params: 53,339
2020-01-14 18:17:16,343 [INFO] Non-trainable params: 832
2020-01-14 18:17:16,343 [INFO] _________________________________________________________________
2020-01-14 18:17:16,665 [INFO] _________________________________________________________________
2020-01-14 18:17:16,665 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:17:16,673 [INFO] =================================================================
2020-01-14 18:17:16,673 [INFO] dense_87 (Dense)             (None, 64)                2112      
2020-01-14 18:17:16,673 [INFO] _________________________________________________________________
2020-01-14 18:17:16,674 [INFO] batch_normalization_66 (Batc (None, 64)                256       
2020-01-14 18:17:16,674 [INFO] _________________________________________________________________
2020-01-14 18:17:16,674 [INFO] dropout_66 (Dropout)         (None, 64)                0         
2020-01-14 18:17:16,674 [INFO] _________________________________________________________________
2020-01-14 18:17:16,674 [INFO] dense_88 (Dense)             (None, 5)                 325       
2020-01-14 18:17:16,674 [INFO] =================================================================
2020-01-14 18:17:16,674 [INFO] Total params: 2,693
2020-01-14 18:17:16,674 [INFO] Trainable params: 2,565
2020-01-14 18:17:16,674 [INFO] Non-trainable params: 128
2020-01-14 18:17:16,674 [INFO] _________________________________________________________________
2020-01-14 18:17:16,674 [INFO] Training model
2020-01-14 18:17:16,675 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 18:19:53,782 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = 2535e3e7d0f7e350085ae147323a3d8bf85901bb
2020-01-14 18:19:53,820 [INFO] Training autoencoder
 - val_f1: 0.9992
 - out_of_sample_accuracy: 0.9233
Train on 979686 samples, validate on 979687 samples
Epoch 1/10
 - 79s - loss: -1.8461e+00 - val_loss: -2.0692e+00
Epoch 2/10
 - 46s - loss: -2.0540e+00 - val_loss: -2.0886e+00
Epoch 3/10
 - 46s - loss: -2.0702e+00 - val_loss: -2.0973e+00
Epoch 4/10
 - 46s - loss: -2.0794e+00 - val_loss: -2.1005e+00
Epoch 5/10
 - 46s - loss: -2.0842e+00 - val_loss: -2.1024e+00
Epoch 6/10
 - 46s - loss: -2.0875e+00 - val_loss: -2.1052e+00
Epoch 7/10
 - 46s - loss: -2.0908e+00 - val_loss: -2.1071e+00
Epoch 8/10
 - 46s - loss: -2.0925e+00 - val_loss: -2.1078e+00
Epoch 9/10
 - 46s - loss: -2.0930e+00 - val_loss: -2.1087e+00
Epoch 10/10
 - 46s - loss: -2.0945e+00 - val_loss: -2.1089e+00
2020-01-14 18:28:33,837 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 18:30:01,140 [INFO] Last epoch loss evaluation: train_loss = -2.110431, val_loss = -2.108862
2020-01-14 18:30:01,141 [INFO] Training autoencoder complete
2020-01-14 18:30:01,141 [INFO] Encoding data for supervised training
2020-01-14 18:32:36,873 [INFO] Encoding complete
2020-01-14 18:32:36,901 [INFO] Training neural network layers (after autoencoder)
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 33s - loss: 0.0054 - val_loss: 0.0010
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 18:34:28,771 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9198, current_metric = 0.9232, num_epochs = 1
2020-01-14 18:34:29,211 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 18:37:09,843 [INFO] Last epoch loss evaluation: train_loss = 0.001061, val_loss = 0.001049
2020-01-14 18:37:10,051 [INFO] Training complete. time_to_train = 1193.38 sec, 19.89 min
2020-01-14 18:37:19,283 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/best_model.pickle
2020-01-14 18:37:19,402 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2020-01-14 18:37:20,029 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/training_error_history.png
2020-01-14 18:37:20,143 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/training_f1_history.png
2020-01-14 18:37:20,144 [INFO] Making predictions on training, validation, testing data
2020-01-14 18:44:50,067 [INFO] Making predictions complete. time_to_predict = 449.92 sec, 7.50 min
2020-01-14 18:44:50,192 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-14 18:44:54,892 [INFO] Dataset: Testing. Classification report below
2020-01-14 18:44:54,892 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.98    229853
     normal.       0.73      0.99      0.84     60593
       probe       0.85      0.70      0.77      4166
         r2l       0.97      0.03      0.05     13781
         u2r       0.00      0.00      0.00      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.71      0.54      0.53    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 18:44:54,892 [INFO] Overall accuracy (micro avg): 0.9235280311482209
/home/hasitha/sunanda/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-14 18:45:00,236 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9235         0.9235                       0.9235                0.0191                   0.0765  0.9235
1     Macro avg        0.9694         0.7086                       0.5393                0.0205                   0.4607  0.5295
2  Weighted avg        0.9674         0.9323                       0.9235                0.0260                   0.0765  0.9041
2020-01-14 18:45:16,669 [INFO] Dataset: Validation. Classification report below
2020-01-14 18:45:16,669 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.95      0.97      8221
         r2l       0.94      0.22      0.35       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.79      0.63      0.66    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 18:45:16,669 [INFO] Overall accuracy (micro avg): 0.9991823919272176
2020-01-14 18:45:35,301 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.7860                       0.6333                0.0004                   0.3667  0.6643
2  Weighted avg        0.9997         0.9992                       0.9992                0.0009                   0.0008  0.9991
2020-01-14 18:46:47,642 [INFO] Dataset: Training. Classification report below
2020-01-14 18:46:47,642 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.95      0.97     32881
         r2l       0.92      0.21      0.35       901
         u2r       0.00      0.00      0.00        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.78      0.63      0.66   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 18:46:47,642 [INFO] Overall accuracy (micro avg): 0.9991744803947388
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 18:48:09,565 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.7823                       0.6323                0.0004                   0.3677  0.6630
2  Weighted avg        0.9997         0.9991                       0.9992                0.0010                   0.0008  0.9991
2020-01-14 18:48:09,646 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep2/train_time_kdd99_ae_ann_deep_rep2_results.xlsx
2020-01-14 18:48:09,654 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-14 18:48:09,983 [INFO] Created directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3
2020-01-14 18:48:09,997 [INFO] Initialized logging. log_filename = results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/run_log.log
2020-01-14 18:48:09,997 [INFO] ================= Running experiment no. 3  ================= 

2020-01-14 18:48:09,998 [INFO] Experiment parameters given below
2020-01-14 18:48:09,998 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/train_time_kdd99_ae_ann_deep_rep3', 'model_type': 'classifier', 'model': 'ae_ann', 'normal_label': 'normal', 'scaling_type': 'NA', 'unsupervised_ratio': 0.25, 'ae_encoder_units': [128, 64, 32], 'ae_encoder_activations': ['relu', 'relu', 'relu'], 'ae_encoder_dropout_rates': [0.2, 0.2, 0.2], 'ae_encoder_l1_param': -1, 'ae_decoder_units': [64, 128], 'ae_decoder_activations': ['relu', 'relu'], 'ae_decoder_dropout_rates': [0.2, 0.2], 'output_activation': 'sigmoid', 'loss_function': 'binary_crossentropy', 'ae_epochs': 10, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'ann_epochs': 100, 'early_stop_patience': 100, 'batch_size': 256, 'goal_metric': 0.919829173, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'train_time_kdd99_ae_ann_deep_rep3'}
2020-01-14 18:48:09,998 [INFO] Created tensorboard log directory: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/tf_logs_run_2020_01_14-18_48_09
2020-01-14 18:48:09,998 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2020-01-14 18:48:10,013 [INFO] Reading X, y files
2020-01-14 18:48:10,013 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2020-01-14 18:48:19,545 [INFO] Reading complete. time_to_read=9.53 seconds
2020-01-14 18:48:19,545 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2020-01-14 18:48:21,843 [INFO] Reading complete. time_to_read=2.30 seconds
2020-01-14 18:48:21,843 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2020-01-14 18:48:22,530 [INFO] Reading complete. time_to_read=0.69 seconds
2020-01-14 18:48:22,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2020-01-14 18:48:23,551 [INFO] Reading complete. time_to_read=1.02 seconds
2020-01-14 18:48:23,551 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2020-01-14 18:48:23,671 [INFO] Reading complete. time_to_read=0.12 seconds
2020-01-14 18:48:23,671 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2020-01-14 18:48:23,725 [INFO] Reading complete. time_to_read=0.05 seconds
2020-01-14 18:49:16,588 [INFO] Initializing model
2020-01-14 18:49:20,489 [INFO] _________________________________________________________________
2020-01-14 18:49:20,491 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:49:20,491 [INFO] =================================================================
2020-01-14 18:49:20,492 [INFO] dense_89 (Dense)             (None, 128)               15872     
2020-01-14 18:49:20,492 [INFO] _________________________________________________________________
2020-01-14 18:49:20,492 [INFO] batch_normalization_67 (Batc (None, 128)               512       
2020-01-14 18:49:20,492 [INFO] _________________________________________________________________
2020-01-14 18:49:20,492 [INFO] dropout_67 (Dropout)         (None, 128)               0         
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] dense_90 (Dense)             (None, 64)                8256      
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] batch_normalization_68 (Batc (None, 64)                256       
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] dropout_68 (Dropout)         (None, 64)                0         
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] dense_91 (Dense)             (None, 32)                2080      
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] batch_normalization_69 (Batc (None, 32)                128       
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,493 [INFO] dropout_69 (Dropout)         (None, 32)                0         
2020-01-14 18:49:20,493 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] dense_92 (Dense)             (None, 64)                2112      
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] batch_normalization_70 (Batc (None, 64)                256       
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] dropout_70 (Dropout)         (None, 64)                0         
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] dense_93 (Dense)             (None, 128)               8320      
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] batch_normalization_71 (Batc (None, 128)               512       
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] dropout_71 (Dropout)         (None, 128)               0         
2020-01-14 18:49:20,494 [INFO] _________________________________________________________________
2020-01-14 18:49:20,494 [INFO] dense_94 (Dense)             (None, 123)               15867     
2020-01-14 18:49:20,495 [INFO] =================================================================
2020-01-14 18:49:20,495 [INFO] Total params: 54,171
2020-01-14 18:49:20,495 [INFO] Trainable params: 53,339
2020-01-14 18:49:20,495 [INFO] Non-trainable params: 832
2020-01-14 18:49:20,495 [INFO] _________________________________________________________________
2020-01-14 18:49:20,888 [INFO] _________________________________________________________________
2020-01-14 18:49:20,889 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-14 18:49:20,889 [INFO] =================================================================
2020-01-14 18:49:20,889 [INFO] dense_95 (Dense)             (None, 64)                2112      
2020-01-14 18:49:20,889 [INFO] _________________________________________________________________
2020-01-14 18:49:20,889 [INFO] batch_normalization_72 (Batc (None, 64)                256       
2020-01-14 18:49:20,889 [INFO] _________________________________________________________________
2020-01-14 18:49:20,889 [INFO] dropout_72 (Dropout)         (None, 64)                0         
2020-01-14 18:49:20,889 [INFO] _________________________________________________________________
2020-01-14 18:49:20,890 [INFO] dense_96 (Dense)             (None, 5)                 325       
2020-01-14 18:49:20,890 [INFO] =================================================================
2020-01-14 18:49:20,890 [INFO] Total params: 2,693
2020-01-14 18:49:20,890 [INFO] Trainable params: 2,565
2020-01-14 18:49:20,890 [INFO] Non-trainable params: 128
2020-01-14 18:49:20,890 [INFO] _________________________________________________________________
2020-01-14 18:49:20,890 [INFO] Training model
2020-01-14 18:49:20,891 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2020-01-14 18:52:03,540 [INFO] Split sizes (instances). total = 3918744, unsupervised = 979686, supervised = 2939058, unsupervised dataset hash = a443f65723b18f3493f1c6b26b71b1f7b3385866
2020-01-14 18:52:03,557 [INFO] Training autoencoder
 - val_f1: 0.9991
 - out_of_sample_accuracy: 0.9232
Train on 979686 samples, validate on 979687 samples
Epoch 1/10
 - 83s - loss: -1.8494e+00 - val_loss: -2.0727e+00
Epoch 2/10
 - 52s - loss: -2.0537e+00 - val_loss: -2.0889e+00
Epoch 3/10
 - 52s - loss: -2.0694e+00 - val_loss: -2.0957e+00
Epoch 4/10
 - 52s - loss: -2.0772e+00 - val_loss: -2.1000e+00
Epoch 5/10
 - 51s - loss: -2.0820e+00 - val_loss: -2.1015e+00
Epoch 6/10
 - 52s - loss: -2.0857e+00 - val_loss: -2.1031e+00
Epoch 7/10
 - 52s - loss: -2.0882e+00 - val_loss: -2.1044e+00
Epoch 8/10
 - 52s - loss: -2.0896e+00 - val_loss: -2.1053e+00
Epoch 9/10
 - 52s - loss: -2.0914e+00 - val_loss: -2.1052e+00
Epoch 10/10
 - 52s - loss: -2.0918e+00 - val_loss: -2.1055e+00
2020-01-14 19:01:35,740 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:03:07,412 [INFO] Last epoch loss evaluation: train_loss = -2.106387, val_loss = -2.105532
2020-01-14 19:03:07,413 [INFO] Training autoencoder complete
2020-01-14 19:03:07,413 [INFO] Encoding data for supervised training
2020-01-14 19:05:45,263 [INFO] Encoding complete
2020-01-14 19:05:45,320 [INFO] Training neural network layers (after autoencoder)
Train on 2939058 samples, validate on 979687 samples
Epoch 1/100
 - 36s - loss: 0.0057 - val_loss: 0.0012
2020-01-14 19:07:46,181 [INFO] StopperOnGoal: reached goal_metric (accuracy). Stopping training. goal_metric = 0.9198, current_metric = 0.9242, num_epochs = 1
2020-01-14 19:07:46,911 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-14 19:10:36,763 [INFO] Last epoch loss evaluation: train_loss = 0.001166, val_loss = 0.001170
2020-01-14 19:10:36,913 [INFO] Training complete. time_to_train = 1276.02 sec, 21.27 min
2020-01-14 19:10:46,907 [INFO] Model saved to results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/best_model.pickle
2020-01-14 19:10:46,998 [INFO] Training history saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/training_error_history.csv
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2020-01-14 19:10:47,427 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/training_error_history.png
2020-01-14 19:10:47,542 [INFO] Plot saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/training_f1_history.png
2020-01-14 19:10:47,542 [INFO] Making predictions on training, validation, testing data
2020-01-14 19:18:11,099 [INFO] Making predictions complete. time_to_predict = 443.56 sec, 7.39 min
2020-01-14 19:18:11,286 [INFO] Evaluating predictions (results)
2020-01-14 19:18:15,969 [INFO] Dataset: Testing. Classification report below
2020-01-14 19:18:15,969 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.99      0.84     60593
       probe       0.88      0.68      0.77      4166
         r2l       0.92      0.03      0.06     13781
         u2r       0.00      0.00      0.00      2636

   micro avg       0.92      0.92      0.92    311029
   macro avg       0.71      0.54      0.53    311029
weighted avg       0.93      0.92      0.90    311029

2020-01-14 19:18:15,969 [INFO] Overall accuracy (micro avg): 0.9242514363612396
/home/hasitha/sunanda/ids_experiments/utility.py:334: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2020-01-14 19:18:21,312 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9243         0.9243                       0.9243                0.0189                   0.0757  0.9243
1     Macro avg        0.9697         0.7068                       0.5364                0.0200                   0.4636  0.5309
2  Weighted avg        0.9679         0.9314                       0.9243                0.0241                   0.0757  0.9050
2020-01-14 19:18:37,686 [INFO] Dataset: Validation. Classification report below
2020-01-14 19:18:37,687 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.96      0.98      8221
         r2l       0.71      0.35      0.47       225
         u2r       0.00      0.00      0.00        10

   micro avg       1.00      1.00      1.00    979687
   macro avg       0.74      0.66      0.69    979687
weighted avg       1.00      1.00      1.00    979687

2020-01-14 19:18:37,687 [INFO] Overall accuracy (micro avg): 0.9992803824078507
2020-01-14 19:18:56,297 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9993         0.9993                       0.9993                0.0002                   0.0007  0.9993
1     Macro avg        0.9997         0.7396                       0.6611                0.0003                   0.3389  0.6879
2  Weighted avg        0.9997         0.9992                       0.9993                0.0010                   0.0007  0.9992
2020-01-14 19:20:08,750 [INFO] Dataset: Training. Classification report below
2020-01-14 19:20:08,750 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.96      0.97     32881
         r2l       0.71      0.38      0.50       901
         u2r       0.00      0.00      0.00        42

   micro avg       1.00      1.00      1.00   3918744
   macro avg       0.74      0.67      0.69   3918744
weighted avg       1.00      1.00      1.00   3918744

2020-01-14 19:20:08,750 [INFO] Overall accuracy (micro avg): 0.999248228514034
2020-01-14 19:21:30,902 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9992         0.9992                       0.9992                0.0002                   0.0008  0.9992
1     Macro avg        0.9997         0.7402                       0.6679                0.0004                   0.3321  0.6941
2  Weighted avg        0.9996         0.9992                       0.9992                0.0011                   0.0008  0.9992
2020-01-14 19:21:30,951 [INFO] Results saved to: results_additional_exps/train_time_kdd99_ae_ann_deep_rep3/train_time_kdd99_ae_ann_deep_rep3_results.xlsx
2020-01-14 19:21:30,959 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-14 19:21:31,256 [INFO] ================= Finished running 12 experiments ================= 

 - val_f1: 0.9992
 - out_of_sample_accuracy: 0.9242
