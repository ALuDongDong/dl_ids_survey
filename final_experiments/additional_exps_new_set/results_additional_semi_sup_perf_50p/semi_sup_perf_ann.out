Using TensorFlow backend.
2019-12-23 13:33:05,259 [INFO] Read 6 experiments from file: experiment_specs/additional_exps/semi_sup_perf_ann.csv
2019-12-23 13:33:05,259 [INFO] ================= Started running experiments ================= 

2019-12-23 13:33:05,260 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep1/run_log.log
2019-12-23 13:33:05,260 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 13:33:05,260 [INFO] Experiment parameters given below
2019-12-23 13:33:05,260 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep1'}
2019-12-23 13:33:05,260 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep1/tf_logs_run_2019_12_23-13_33_05
2019-12-23 13:33:05,260 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 13:33:05,261 [INFO] Reading X, y files
2019-12-23 13:33:05,261 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 13:33:05,524 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-23 13:33:05,524 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 13:33:05,589 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 13:33:05,589 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 13:33:05,648 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 13:33:05,648 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 13:33:05,656 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 13:33:05,656 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 13:33:05,660 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:33:05,660 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 13:33:05,663 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:33:05,853 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-23 13:33:05,866 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 13:33:05,928 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 13:33:05,965 [INFO] _________________________________________________________________
2019-12-23 13:33:05,965 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 13:33:05,965 [INFO] =================================================================
2019-12-23 13:33:05,965 [INFO] dense_1 (Dense)              (None, 64)                7872      
2019-12-23 13:33:05,965 [INFO] _________________________________________________________________
2019-12-23 13:33:05,965 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2019-12-23 13:33:05,965 [INFO] _________________________________________________________________
2019-12-23 13:33:05,965 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2019-12-23 13:33:05,966 [INFO] _________________________________________________________________
2019-12-23 13:33:05,966 [INFO] dense_2 (Dense)              (None, 5)                 325       
2019-12-23 13:33:05,966 [INFO] =================================================================
2019-12-23 13:33:05,966 [INFO] Total params: 8,453
2019-12-23 13:33:05,966 [INFO] Trainable params: 8,325
2019-12-23 13:33:05,966 [INFO] Non-trainable params: 128
2019-12-23 13:33:05,966 [INFO] _________________________________________________________________
2019-12-23 13:33:05,966 [INFO] Training model
2019-12-23 13:33:05,966 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 13:33:06,678 [INFO] Split sizes (instances). total = 100778, set1 = 50389, set2 = 50389, set1 dataset hash = e354a362b75401773a1959143869099e0046a21e
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-23 13:33:07,048 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-23 13:33:07.318355: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-23 13:33:07.340759: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2019-12-23 13:33:07.340953: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x4375450 executing computations on platform Host. Devices:
2019-12-23 13:33:07.340978: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1592 - val_loss: 0.0466
 - val_f1: 0.9709
Epoch 2/300
 - 0s - loss: 0.0436 - val_loss: 0.0317
 - val_f1: 0.9763
Epoch 3/300
 - 0s - loss: 0.0312 - val_loss: 0.0224
 - val_f1: 0.9820
Epoch 4/300
 - 0s - loss: 0.0226 - val_loss: 0.0161
 - val_f1: 0.9868
Epoch 5/300
 - 0s - loss: 0.0182 - val_loss: 0.0137
 - val_f1: 0.9897
Epoch 6/300
 - 0s - loss: 0.0165 - val_loss: 0.0120
 - val_f1: 0.9914
Epoch 7/300
 - 0s - loss: 0.0145 - val_loss: 0.0114
 - val_f1: 0.9929
Epoch 8/300
 - 0s - loss: 0.0139 - val_loss: 0.0107
 - val_f1: 0.9915
Epoch 9/300
 - 0s - loss: 0.0128 - val_loss: 0.0099
 - val_f1: 0.9932
Epoch 10/300
 - 0s - loss: 0.0119 - val_loss: 0.0101
 - val_f1: 0.9921
Epoch 11/300
 - 0s - loss: 0.0113 - val_loss: 0.0092
 - val_f1: 0.9931
Epoch 12/300
 - 0s - loss: 0.0107 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 13/300
 - 0s - loss: 0.0106 - val_loss: 0.0096
 - val_f1: 0.9941
Epoch 14/300
 - 0s - loss: 0.0099 - val_loss: 0.0091
 - val_f1: 0.9942
Epoch 15/300
 - 0s - loss: 0.0102 - val_loss: 0.0092
 - val_f1: 0.9942
Epoch 16/300
 - 0s - loss: 0.0094 - val_loss: 0.0088
 - val_f1: 0.9942
Epoch 17/300
 - 0s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9943
Epoch 18/300
 - 0s - loss: 0.0092 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 19/300
 - 0s - loss: 0.0087 - val_loss: 0.0088
 - val_f1: 0.9944
Epoch 20/300
 - 0s - loss: 0.0087 - val_loss: 0.0089
 - val_f1: 0.9942
Epoch 21/300
 - 0s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9942
Epoch 22/300
 - 0s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9947
Epoch 23/300
 - 0s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9947
Epoch 24/300
 - 0s - loss: 0.0080 - val_loss: 0.0085
 - val_f1: 0.9942
Epoch 25/300
 - 0s - loss: 0.0075 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 26/300
 - 0s - loss: 0.0076 - val_loss: 0.0087
 - val_f1: 0.9948
Epoch 27/300
 - 0s - loss: 0.0076 - val_loss: 0.0084
 - val_f1: 0.9951
Epoch 28/300
 - 0s - loss: 0.0074 - val_loss: 0.0080
 - val_f1: 0.9946
Epoch 29/300
 - 0s - loss: 0.0071 - val_loss: 0.0088
 - val_f1: 0.9935
Epoch 30/300
 - 0s - loss: 0.0074 - val_loss: 0.0089
 - val_f1: 0.9948
Epoch 31/300
 - 0s - loss: 0.0075 - val_loss: 0.0085
2019-12-23 13:33:27,431 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9949
Epoch 32/300
 - 0s - loss: 0.0072 - val_loss: 0.0085
 - val_f1: 0.9949
Epoch 33/300
 - 0s - loss: 0.0071 - val_loss: 0.0085
 - val_f1: 0.9948
Epoch 34/300
 - 0s - loss: 0.0070 - val_loss: 0.0082
 - val_f1: 0.9954
Epoch 35/300
 - 0s - loss: 0.0068 - val_loss: 0.0084
 - val_f1: 0.9952
Epoch 36/300
 - 0s - loss: 0.0067 - val_loss: 0.0086
 - val_f1: 0.9945
Epoch 37/300
 - 0s - loss: 0.0062 - val_loss: 0.0082
 - val_f1: 0.9949
Epoch 38/300
 - 0s - loss: 0.0064 - val_loss: 0.0081
 - val_f1: 0.9947
Epoch 39/300
 - 0s - loss: 0.0065 - val_loss: 0.0083
 - val_f1: 0.9949
Epoch 40/300
 - 0s - loss: 0.0061 - val_loss: 0.0080
 - val_f1: 0.9954
Epoch 41/300
 - 0s - loss: 0.0061 - val_loss: 0.0074
 - val_f1: 0.9954
Epoch 42/300
 - 0s - loss: 0.0061 - val_loss: 0.0090
 - val_f1: 0.9950
Epoch 43/300
 - 0s - loss: 0.0062 - val_loss: 0.0085
 - val_f1: 0.9936
Epoch 44/300
 - 0s - loss: 0.0063 - val_loss: 0.0080
 - val_f1: 0.9957
Epoch 45/300
 - 0s - loss: 0.0058 - val_loss: 0.0077
 - val_f1: 0.9960
Epoch 46/300
 - 0s - loss: 0.0059 - val_loss: 0.0078
 - val_f1: 0.9957
Epoch 47/300
 - 0s - loss: 0.0060 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 48/300
 - 0s - loss: 0.0057 - val_loss: 0.0077
 - val_f1: 0.9958
Epoch 49/300
 - 0s - loss: 0.0056 - val_loss: 0.0086
 - val_f1: 0.9957
Epoch 50/300
 - 0s - loss: 0.0058 - val_loss: 0.0078
 - val_f1: 0.9949
Epoch 51/300
 - 0s - loss: 0.0056 - val_loss: 0.0079
 - val_f1: 0.9950
Epoch 52/300
 - 0s - loss: 0.0055 - val_loss: 0.0073
 - val_f1: 0.9962
Epoch 53/300
 - 0s - loss: 0.0057 - val_loss: 0.0073
 - val_f1: 0.9962
Epoch 54/300
 - 0s - loss: 0.0055 - val_loss: 0.0075
 - val_f1: 0.9961
Epoch 55/300
 - 0s - loss: 0.0052 - val_loss: 0.0076
 - val_f1: 0.9959
Epoch 56/300
 - 0s - loss: 0.0059 - val_loss: 0.0075
 - val_f1: 0.9959
Epoch 57/300
 - 0s - loss: 0.0054 - val_loss: 0.0073
 - val_f1: 0.9958
Epoch 58/300
 - 0s - loss: 0.0053 - val_loss: 0.0074
 - val_f1: 0.9961
Epoch 59/300
 - 0s - loss: 0.0053 - val_loss: 0.0077
 - val_f1: 0.9954
Epoch 60/300
 - 0s - loss: 0.0049 - val_loss: 0.0073
 - val_f1: 0.9962
Epoch 61/300
 - 0s - loss: 0.0052 - val_loss: 0.0071
2019-12-23 13:33:46,620 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9956
Epoch 62/300
 - 0s - loss: 0.0049 - val_loss: 0.0076
 - val_f1: 0.9959
Epoch 63/300
 - 0s - loss: 0.0052 - val_loss: 0.0075
 - val_f1: 0.9954
Epoch 64/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9963
Epoch 65/300
 - 0s - loss: 0.0048 - val_loss: 0.0079
 - val_f1: 0.9959
Epoch 66/300
 - 0s - loss: 0.0048 - val_loss: 0.0070
 - val_f1: 0.9964
Epoch 67/300
 - 0s - loss: 0.0054 - val_loss: 0.0092
 - val_f1: 0.9959
Epoch 68/300
 - 0s - loss: 0.0051 - val_loss: 0.0082
 - val_f1: 0.9959
Epoch 69/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9960
Epoch 70/300
 - 0s - loss: 0.0051 - val_loss: 0.0069
 - val_f1: 0.9963
Epoch 71/300
 - 0s - loss: 0.0047 - val_loss: 0.0071
 - val_f1: 0.9965
Epoch 72/300
 - 0s - loss: 0.0048 - val_loss: 0.0065
 - val_f1: 0.9964
Epoch 73/300
 - 0s - loss: 0.0044 - val_loss: 0.0065
 - val_f1: 0.9961
Epoch 74/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9963
Epoch 75/300
 - 0s - loss: 0.0050 - val_loss: 0.0067
 - val_f1: 0.9963
Epoch 76/300
 - 0s - loss: 0.0046 - val_loss: 0.0073
 - val_f1: 0.9953
Epoch 77/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9963
Epoch 78/300
 - 0s - loss: 0.0045 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 79/300
 - 0s - loss: 0.0047 - val_loss: 0.0072
 - val_f1: 0.9961
Epoch 80/300
 - 0s - loss: 0.0047 - val_loss: 0.0074
 - val_f1: 0.9964
Epoch 81/300
 - 0s - loss: 0.0048 - val_loss: 0.0070
 - val_f1: 0.9961
Epoch 82/300
 - 0s - loss: 0.0046 - val_loss: 0.0069
 - val_f1: 0.9960
Epoch 83/300
 - 0s - loss: 0.0047 - val_loss: 0.0073
 - val_f1: 0.9959
Epoch 84/300
 - 0s - loss: 0.0045 - val_loss: 0.0072
 - val_f1: 0.9962
Epoch 85/300
 - 0s - loss: 0.0046 - val_loss: 0.0070
 - val_f1: 0.9964
Epoch 86/300
 - 0s - loss: 0.0046 - val_loss: 0.0065
 - val_f1: 0.9964
Epoch 87/300
 - 0s - loss: 0.0043 - val_loss: 0.0070
 - val_f1: 0.9965
Epoch 88/300
 - 0s - loss: 0.0045 - val_loss: 0.0071
 - val_f1: 0.9963
Epoch 89/300
 - 0s - loss: 0.0044 - val_loss: 0.0069
 - val_f1: 0.9960
Epoch 90/300
 - 0s - loss: 0.0048 - val_loss: 0.0072
 - val_f1: 0.9962
Epoch 91/300
 - 0s - loss: 0.0045 - val_loss: 0.0074
2019-12-23 13:34:05,819 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9964
Epoch 92/300
 - 0s - loss: 0.0044 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 93/300
 - 0s - loss: 0.0044 - val_loss: 0.0070
 - val_f1: 0.9964
Epoch 94/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9965
Epoch 95/300
 - 0s - loss: 0.0042 - val_loss: 0.0073
 - val_f1: 0.9963
Epoch 96/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9965
Epoch 97/300
 - 0s - loss: 0.0043 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 98/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9960
Epoch 99/300
 - 0s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9960
Epoch 100/300
 - 0s - loss: 0.0041 - val_loss: 0.0068
 - val_f1: 0.9962
Epoch 101/300
 - 0s - loss: 0.0044 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 102/300
 - 0s - loss: 0.0043 - val_loss: 0.0070
 - val_f1: 0.9964
Epoch 103/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9966
Epoch 104/300
 - 0s - loss: 0.0041 - val_loss: 0.0069
 - val_f1: 0.9967
Epoch 105/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9963
Epoch 106/300
 - 0s - loss: 0.0041 - val_loss: 0.0074
 - val_f1: 0.9960
Epoch 107/300
 - 0s - loss: 0.0044 - val_loss: 0.0069
 - val_f1: 0.9967
Epoch 108/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9966
Epoch 109/300
 - 0s - loss: 0.0041 - val_loss: 0.0067
 - val_f1: 0.9967
Epoch 110/300
 - 0s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9966
Epoch 111/300
 - 0s - loss: 0.0042 - val_loss: 0.0072
 - val_f1: 0.9966
Epoch 112/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9964
Epoch 113/300
 - 0s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 114/300
 - 0s - loss: 0.0040 - val_loss: 0.0073
 - val_f1: 0.9967
Epoch 115/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9963
Epoch 116/300
 - 0s - loss: 0.0043 - val_loss: 0.0070
 - val_f1: 0.9966
Epoch 117/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9964
Epoch 118/300
 - 0s - loss: 0.0041 - val_loss: 0.0071
 - val_f1: 0.9965
Epoch 119/300
 - 0s - loss: 0.0039 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 120/300
 - 0s - loss: 0.0040 - val_loss: 0.0072
 - val_f1: 0.9963
Epoch 121/300
 - 0s - loss: 0.0041 - val_loss: 0.0073
2019-12-23 13:34:25,171 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9966
Epoch 122/300
 - 0s - loss: 0.0039 - val_loss: 0.0071
 - val_f1: 0.9966
Epoch 123/300
 - 0s - loss: 0.0037 - val_loss: 0.0070
 - val_f1: 0.9965
Epoch 124/300
 - 0s - loss: 0.0042 - val_loss: 0.0073
 - val_f1: 0.9963
Epoch 125/300
 - 0s - loss: 0.0041 - val_loss: 0.0073
 - val_f1: 0.9962
Epoch 126/300
 - 0s - loss: 0.0039 - val_loss: 0.0076
 - val_f1: 0.9961
Epoch 127/300
 - 0s - loss: 0.0039 - val_loss: 0.0071
 - val_f1: 0.9962
Epoch 128/300
 - 0s - loss: 0.0042 - val_loss: 0.0083
 - val_f1: 0.9960
Epoch 129/300
 - 0s - loss: 0.0043 - val_loss: 0.0082
 - val_f1: 0.9963
Epoch 130/300
 - 0s - loss: 0.0041 - val_loss: 0.0078
 - val_f1: 0.9964
Epoch 131/300
 - 0s - loss: 0.0039 - val_loss: 0.0072
 - val_f1: 0.9964
Epoch 132/300
 - 0s - loss: 0.0040 - val_loss: 0.0072
 - val_f1: 0.9965
Epoch 133/300
 - 0s - loss: 0.0038 - val_loss: 0.0071
 - val_f1: 0.9966
Epoch 134/300
 - 0s - loss: 0.0037 - val_loss: 0.0074
 - val_f1: 0.9964
Epoch 135/300
 - 0s - loss: 0.0043 - val_loss: 0.0077
 - val_f1: 0.9961
Epoch 136/300
 - 0s - loss: 0.0039 - val_loss: 0.0075
2019-12-23 13:34:35,090 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 13:34:35,928 [INFO] Last epoch loss evaluation: train_loss = 0.003131, val_loss = 0.006509
2019-12-23 13:34:35,932 [INFO] Training complete. time_to_train = 89.97 sec, 1.50 min
2019-12-23 13:34:35,935 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep1/best_model.pickle
2019-12-23 13:34:36,133 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/training_error_history.png
2019-12-23 13:34:36,302 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/training_f1_history.png
2019-12-23 13:34:36,302 [INFO] Making predictions on training, validation, testing data
2019-12-23 13:34:37,475 [INFO] Evaluating predictions (results)
2019-12-23 13:34:37,825 [INFO] Dataset: Testing. Classification report below
2019-12-23 13:34:37,826 [INFO] 
              precision    recall  f1-score   support

         dos       0.96      0.84      0.90      7458
      normal       0.68      0.96      0.80      9711
       probe       0.82      0.66      0.73      2421
         r2l       0.80      0.11      0.19      2421
         u2r       0.73      0.05      0.08       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.80      0.52      0.54     22544
weighted avg       0.80      0.78      0.74     22544

2019-12-23 13:34:37,826 [INFO] Overall accuracy (micro avg): 0.7768807665010646
2019-12-23 13:34:38,121 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7769         0.7769                       0.7769                0.0558                   0.2231  0.7769
1     Macro avg        0.9108         0.7981                       0.5240                0.0754                   0.4760  0.5410
2  Weighted avg        0.8721         0.8024                       0.7769                0.1538                   0.2231  0.7419
2019-12-23 13:34:38,455 [INFO] Dataset: Validation. Classification report below
2019-12-23 13:34:38,455 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.87      0.92       199
         u2r       0.67      0.40      0.50        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.92      0.85      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 13:34:38,455 [INFO] Overall accuracy (micro avg): 0.9963484818416353
2019-12-23 13:34:38,813 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9963         0.9963                       0.9963                0.0009                   0.0037  0.9963
1     Macro avg        0.9985         0.9229                       0.8526                0.0013                   0.1474  0.8807
2  Weighted avg        0.9977         0.9963                       0.9963                0.0027                   0.0037  0.9963
2019-12-23 13:34:40,258 [INFO] Dataset: Training. Classification report below
2019-12-23 13:34:40,258 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      0.99      9325
         r2l       0.97      0.89      0.93       796
         u2r       0.83      0.57      0.68        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.96      0.89      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 13:34:40,259 [INFO] Overall accuracy (micro avg): 0.9970231598166266
2019-12-23 13:34:41,885 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0007                   0.0030  0.9970
1     Macro avg        0.9988         0.9570                       0.8907                0.0011                   0.1093  0.9189
2  Weighted avg        0.9981         0.9970                       0.9970                0.0026                   0.0030  0.9970
2019-12-23 13:34:41,924 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep1/semi_sup_perf_nsl_ann_rep1_results.xlsx
2019-12-23 13:34:41,924 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 13:34:41,928 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_ann_rep2
2019-12-23 13:34:41,928 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep2/run_log.log
2019-12-23 13:34:41,928 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 13:34:41,928 [INFO] Experiment parameters given below
2019-12-23 13:34:41,929 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep2'}
2019-12-23 13:34:41,929 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep2/tf_logs_run_2019_12_23-13_34_41
2019-12-23 13:34:41,929 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 13:34:41,929 [INFO] Reading X, y files
2019-12-23 13:34:41,929 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 13:34:42,176 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-23 13:34:42,176 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 13:34:42,240 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 13:34:42,240 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 13:34:42,298 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 13:34:42,299 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 13:34:42,306 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 13:34:42,306 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 13:34:42,310 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:34:42,310 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 13:34:42,313 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:34:42,500 [INFO] Initializing model
2019-12-23 13:34:42,666 [INFO] _________________________________________________________________
2019-12-23 13:34:42,666 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 13:34:42,666 [INFO] =================================================================
2019-12-23 13:34:42,666 [INFO] dense_3 (Dense)              (None, 64)                7872      
2019-12-23 13:34:42,666 [INFO] _________________________________________________________________
2019-12-23 13:34:42,667 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2019-12-23 13:34:42,667 [INFO] _________________________________________________________________
2019-12-23 13:34:42,667 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2019-12-23 13:34:42,667 [INFO] _________________________________________________________________
2019-12-23 13:34:42,667 [INFO] dense_4 (Dense)              (None, 5)                 325       
2019-12-23 13:34:42,667 [INFO] =================================================================
2019-12-23 13:34:42,667 [INFO] Total params: 8,453
2019-12-23 13:34:42,667 [INFO] Trainable params: 8,325
2019-12-23 13:34:42,667 [INFO] Non-trainable params: 128
2019-12-23 13:34:42,667 [INFO] _________________________________________________________________
2019-12-23 13:34:42,667 [INFO] Training model
2019-12-23 13:34:42,667 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 13:34:43,368 [INFO] Split sizes (instances). total = 100778, set1 = 50389, set2 = 50389, set1 dataset hash = 06e3c0571318a4e80f9239b32a18cc0a10c17120
 - val_f1: 0.9967
Epoch 00136: early stopping
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1279 - val_loss: 0.0427
 - val_f1: 0.9696
Epoch 2/300
 - 0s - loss: 0.0399 - val_loss: 0.0287
 - val_f1: 0.9791
Epoch 3/300
 - 0s - loss: 0.0284 - val_loss: 0.0203
 - val_f1: 0.9809
Epoch 4/300
 - 0s - loss: 0.0205 - val_loss: 0.0159
 - val_f1: 0.9900
Epoch 5/300
 - 0s - loss: 0.0173 - val_loss: 0.0135
 - val_f1: 0.9917
Epoch 6/300
 - 0s - loss: 0.0152 - val_loss: 0.0124
 - val_f1: 0.9929
Epoch 7/300
 - 0s - loss: 0.0139 - val_loss: 0.0122
 - val_f1: 0.9916
Epoch 8/300
 - 0s - loss: 0.0132 - val_loss: 0.0114
 - val_f1: 0.9923
Epoch 9/300
 - 0s - loss: 0.0123 - val_loss: 0.0106
 - val_f1: 0.9930
Epoch 10/300
 - 0s - loss: 0.0117 - val_loss: 0.0099
 - val_f1: 0.9934
Epoch 11/300
 - 0s - loss: 0.0111 - val_loss: 0.0100
 - val_f1: 0.9934
Epoch 12/300
 - 0s - loss: 0.0105 - val_loss: 0.0098
 - val_f1: 0.9921
Epoch 13/300
 - 0s - loss: 0.0104 - val_loss: 0.0098
 - val_f1: 0.9934
Epoch 14/300
 - 0s - loss: 0.0103 - val_loss: 0.0100
 - val_f1: 0.9933
Epoch 15/300
 - 0s - loss: 0.0095 - val_loss: 0.0098
 - val_f1: 0.9942
Epoch 16/300
 - 0s - loss: 0.0094 - val_loss: 0.0101
 - val_f1: 0.9927
Epoch 17/300
 - 0s - loss: 0.0097 - val_loss: 0.0097
 - val_f1: 0.9936
Epoch 18/300
 - 0s - loss: 0.0089 - val_loss: 0.0095
 - val_f1: 0.9941
Epoch 19/300
 - 0s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9940
Epoch 20/300
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 21/300
 - 0s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 22/300
 - 0s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9941
Epoch 23/300
 - 0s - loss: 0.0077 - val_loss: 0.0083
 - val_f1: 0.9938
Epoch 24/300
 - 0s - loss: 0.0075 - val_loss: 0.0086
 - val_f1: 0.9928
Epoch 25/300
 - 0s - loss: 0.0080 - val_loss: 0.0090
 - val_f1: 0.9943
Epoch 26/300
 - 0s - loss: 0.0078 - val_loss: 0.0086
 - val_f1: 0.9944
Epoch 27/300
 - 0s - loss: 0.0074 - val_loss: 0.0093
 - val_f1: 0.9943
Epoch 28/300
 - 0s - loss: 0.0074 - val_loss: 0.0082
 - val_f1: 0.9945
Epoch 29/300
 - 0s - loss: 0.0073 - val_loss: 0.0084
 - val_f1: 0.9943
Epoch 30/300
 - 0s - loss: 0.0072 - val_loss: 0.0086
 - val_f1: 0.9943
Epoch 31/300
 - 0s - loss: 0.0071 - val_loss: 0.0085
2019-12-23 13:35:04,648 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9949
Epoch 32/300
 - 0s - loss: 0.0070 - val_loss: 0.0088
 - val_f1: 0.9951
Epoch 33/300
 - 0s - loss: 0.0072 - val_loss: 0.0076
 - val_f1: 0.9947
Epoch 34/300
 - 0s - loss: 0.0074 - val_loss: 0.0083
 - val_f1: 0.9945
Epoch 35/300
 - 0s - loss: 0.0070 - val_loss: 0.0085
 - val_f1: 0.9945
Epoch 36/300
 - 0s - loss: 0.0067 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 37/300
 - 0s - loss: 0.0064 - val_loss: 0.0075
 - val_f1: 0.9952
Epoch 38/300
 - 0s - loss: 0.0064 - val_loss: 0.0092
 - val_f1: 0.9947
Epoch 39/300
 - 0s - loss: 0.0065 - val_loss: 0.0082
 - val_f1: 0.9951
Epoch 40/300
 - 0s - loss: 0.0066 - val_loss: 0.0077
 - val_f1: 0.9949
Epoch 41/300
 - 0s - loss: 0.0061 - val_loss: 0.0077
 - val_f1: 0.9951
Epoch 42/300
 - 0s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9949
Epoch 43/300
 - 0s - loss: 0.0066 - val_loss: 0.0080
 - val_f1: 0.9953
Epoch 44/300
 - 0s - loss: 0.0063 - val_loss: 0.0083
 - val_f1: 0.9948
Epoch 45/300
 - 0s - loss: 0.0063 - val_loss: 0.0082
 - val_f1: 0.9946
Epoch 46/300
 - 0s - loss: 0.0060 - val_loss: 0.0075
 - val_f1: 0.9952
Epoch 47/300
 - 0s - loss: 0.0063 - val_loss: 0.0079
 - val_f1: 0.9951
Epoch 48/300
 - 0s - loss: 0.0060 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 49/300
 - 0s - loss: 0.0060 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 50/300
 - 0s - loss: 0.0059 - val_loss: 0.0075
 - val_f1: 0.9953
Epoch 51/300
 - 0s - loss: 0.0062 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 52/300
 - 0s - loss: 0.0058 - val_loss: 0.0073
 - val_f1: 0.9941
Epoch 53/300
 - 0s - loss: 0.0057 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 54/300
 - 0s - loss: 0.0058 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 55/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 56/300
 - 0s - loss: 0.0057 - val_loss: 0.0076
 - val_f1: 0.9956
Epoch 57/300
 - 0s - loss: 0.0056 - val_loss: 0.0073
 - val_f1: 0.9953
Epoch 58/300
 - 0s - loss: 0.0054 - val_loss: 0.0071
 - val_f1: 0.9958
Epoch 59/300
 - 0s - loss: 0.0057 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 60/300
 - 0s - loss: 0.0051 - val_loss: 0.0072
 - val_f1: 0.9961
Epoch 61/300
 - 0s - loss: 0.0051 - val_loss: 0.0075
2019-12-23 13:35:24,666 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9961
Epoch 62/300
 - 0s - loss: 0.0050 - val_loss: 0.0079
 - val_f1: 0.9953
Epoch 63/300
 - 0s - loss: 0.0056 - val_loss: 0.0074
 - val_f1: 0.9959
Epoch 64/300
 - 0s - loss: 0.0052 - val_loss: 0.0085
 - val_f1: 0.9959
Epoch 65/300
 - 0s - loss: 0.0053 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 66/300
 - 0s - loss: 0.0050 - val_loss: 0.0072
 - val_f1: 0.9953
Epoch 67/300
 - 0s - loss: 0.0054 - val_loss: 0.0089
 - val_f1: 0.9953
Epoch 68/300
 - 0s - loss: 0.0050 - val_loss: 0.0079
 - val_f1: 0.9956
Epoch 69/300
 - 0s - loss: 0.0053 - val_loss: 0.0082
 - val_f1: 0.9956
Epoch 70/300
 - 0s - loss: 0.0051 - val_loss: 0.0082
 - val_f1: 0.9955
Epoch 71/300
 - 0s - loss: 0.0051 - val_loss: 0.0079
 - val_f1: 0.9959
Epoch 72/300
 - 0s - loss: 0.0051 - val_loss: 0.0081
 - val_f1: 0.9959
Epoch 73/300
 - 0s - loss: 0.0048 - val_loss: 0.0076
 - val_f1: 0.9960
Epoch 74/300
 - 0s - loss: 0.0050 - val_loss: 0.0080
 - val_f1: 0.9958
Epoch 75/300
 - 0s - loss: 0.0050 - val_loss: 0.0078
 - val_f1: 0.9960
Epoch 76/300
 - 0s - loss: 0.0047 - val_loss: 0.0075
 - val_f1: 0.9958
Epoch 77/300
 - 0s - loss: 0.0047 - val_loss: 0.0076
 - val_f1: 0.9958
Epoch 78/300
 - 0s - loss: 0.0047 - val_loss: 0.0079
 - val_f1: 0.9960
Epoch 79/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9960
Epoch 80/300
 - 0s - loss: 0.0048 - val_loss: 0.0079
 - val_f1: 0.9958
Epoch 81/300
 - 0s - loss: 0.0045 - val_loss: 0.0077
 - val_f1: 0.9961
Epoch 82/300
 - 0s - loss: 0.0046 - val_loss: 0.0080
 - val_f1: 0.9961
Epoch 83/300
 - 0s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9963
Epoch 84/300
 - 0s - loss: 0.0046 - val_loss: 0.0074
 - val_f1: 0.9958
Epoch 85/300
 - 0s - loss: 0.0047 - val_loss: 0.0070
 - val_f1: 0.9963
Epoch 86/300
 - 0s - loss: 0.0043 - val_loss: 0.0075
 - val_f1: 0.9961
Epoch 87/300
 - 0s - loss: 0.0047 - val_loss: 0.0073
 - val_f1: 0.9961
Epoch 88/300
 - 0s - loss: 0.0050 - val_loss: 0.0078
 - val_f1: 0.9963
Epoch 89/300
 - 0s - loss: 0.0043 - val_loss: 0.0067
 - val_f1: 0.9966
Epoch 90/300
 - 0s - loss: 0.0045 - val_loss: 0.0070
 - val_f1: 0.9961
Epoch 91/300
 - 0s - loss: 0.0044 - val_loss: 0.0072
2019-12-23 13:35:44,680 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9959
Epoch 92/300
 - 0s - loss: 0.0044 - val_loss: 0.0074
 - val_f1: 0.9958
Epoch 93/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9964
Epoch 94/300
 - 0s - loss: 0.0044 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 95/300
 - 0s - loss: 0.0043 - val_loss: 0.0071
 - val_f1: 0.9960
Epoch 96/300
 - 0s - loss: 0.0044 - val_loss: 0.0073
 - val_f1: 0.9964
Epoch 97/300
 - 0s - loss: 0.0045 - val_loss: 0.0077
 - val_f1: 0.9959
Epoch 98/300
 - 0s - loss: 0.0046 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 99/300
 - 0s - loss: 0.0044 - val_loss: 0.0068
 - val_f1: 0.9964
Epoch 100/300
 - 0s - loss: 0.0044 - val_loss: 0.0074
 - val_f1: 0.9959
Epoch 101/300
 - 0s - loss: 0.0042 - val_loss: 0.0068
 - val_f1: 0.9960
Epoch 102/300
 - 0s - loss: 0.0041 - val_loss: 0.0069
 - val_f1: 0.9964
Epoch 103/300
 - 0s - loss: 0.0042 - val_loss: 0.0072
 - val_f1: 0.9960
Epoch 104/300
 - 0s - loss: 0.0042 - val_loss: 0.0069
 - val_f1: 0.9963
Epoch 105/300
 - 0s - loss: 0.0043 - val_loss: 0.0072
 - val_f1: 0.9965
Epoch 106/300
 - 0s - loss: 0.0045 - val_loss: 0.0075
 - val_f1: 0.9962
Epoch 107/300
 - 0s - loss: 0.0040 - val_loss: 0.0077
 - val_f1: 0.9963
Epoch 108/300
 - 0s - loss: 0.0042 - val_loss: 0.0070
 - val_f1: 0.9965
Epoch 109/300
 - 0s - loss: 0.0040 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 110/300
 - 0s - loss: 0.0041 - val_loss: 0.0074
 - val_f1: 0.9964
Epoch 111/300
 - 0s - loss: 0.0041 - val_loss: 0.0072
 - val_f1: 0.9962
Epoch 112/300
 - 0s - loss: 0.0041 - val_loss: 0.0068
 - val_f1: 0.9964
Epoch 113/300
 - 0s - loss: 0.0042 - val_loss: 0.0078
 - val_f1: 0.9961
Epoch 114/300
 - 0s - loss: 0.0043 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 115/300
 - 0s - loss: 0.0043 - val_loss: 0.0072
 - val_f1: 0.9966
Epoch 116/300
 - 0s - loss: 0.0040 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 117/300
 - 0s - loss: 0.0039 - val_loss: 0.0069
 - val_f1: 0.9961
Epoch 118/300
 - 0s - loss: 0.0038 - val_loss: 0.0074
 - val_f1: 0.9962
Epoch 119/300
 - 0s - loss: 0.0039 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 120/300
 - 0s - loss: 0.0042 - val_loss: 0.0076
 - val_f1: 0.9962
Epoch 121/300
 - 0s - loss: 0.0041 - val_loss: 0.0068
2019-12-23 13:36:04,612 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9963
Epoch 122/300
 - 0s - loss: 0.0040 - val_loss: 0.0069
 - val_f1: 0.9963
Epoch 123/300
 - 0s - loss: 0.0037 - val_loss: 0.0070
 - val_f1: 0.9964
Epoch 124/300
 - 0s - loss: 0.0038 - val_loss: 0.0077
 - val_f1: 0.9957
Epoch 125/300
 - 0s - loss: 0.0039 - val_loss: 0.0075
 - val_f1: 0.9960
Epoch 126/300
 - 0s - loss: 0.0040 - val_loss: 0.0069
 - val_f1: 0.9962
Epoch 127/300
 - 0s - loss: 0.0038 - val_loss: 0.0077
 - val_f1: 0.9956
Epoch 128/300
 - 0s - loss: 0.0036 - val_loss: 0.0072
 - val_f1: 0.9962
Epoch 129/300
 - 0s - loss: 0.0037 - val_loss: 0.0068
 - val_f1: 0.9964
Epoch 130/300
 - 0s - loss: 0.0038 - val_loss: 0.0076
 - val_f1: 0.9964
Epoch 131/300
 - 0s - loss: 0.0042 - val_loss: 0.0072
 - val_f1: 0.9964
Epoch 132/300
 - 0s - loss: 0.0037 - val_loss: 0.0073
 - val_f1: 0.9962
Epoch 133/300
 - 0s - loss: 0.0040 - val_loss: 0.0076
 - val_f1: 0.9962
Epoch 134/300
 - 0s - loss: 0.0040 - val_loss: 0.0076
 - val_f1: 0.9964
Epoch 135/300
 - 0s - loss: 0.0040 - val_loss: 0.0078
 - val_f1: 0.9965
Epoch 136/300
 - 0s - loss: 0.0037 - val_loss: 0.0076
 - val_f1: 0.9962
Epoch 137/300
 - 0s - loss: 0.0038 - val_loss: 0.0077
 - val_f1: 0.9965
Epoch 138/300
 - 0s - loss: 0.0038 - val_loss: 0.0076
 - val_f1: 0.9965
Epoch 139/300
 - 0s - loss: 0.0038 - val_loss: 0.0073
2019-12-23 13:36:16,819 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 13:36:17,706 [INFO] Last epoch loss evaluation: train_loss = 0.002989, val_loss = 0.006735
2019-12-23 13:36:17,710 [INFO] Training complete. time_to_train = 95.04 sec, 1.58 min
2019-12-23 13:36:17,713 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep2/best_model.pickle
2019-12-23 13:36:17,895 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/training_error_history.png
2019-12-23 13:36:18,065 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/training_f1_history.png
2019-12-23 13:36:18,065 [INFO] Making predictions on training, validation, testing data
2019-12-23 13:36:19,353 [INFO] Evaluating predictions (results)
2019-12-23 13:36:19,615 [INFO] Dataset: Testing. Classification report below
2019-12-23 13:36:19,616 [INFO] 
              precision    recall  f1-score   support

         dos       0.98      0.84      0.90      7458
      normal       0.68      0.97      0.80      9711
       probe       0.86      0.68      0.76      2421
         r2l       0.93      0.10      0.18      2421
         u2r       0.40      0.05      0.08       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.77      0.53      0.55     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-23 13:36:19,616 [INFO] Overall accuracy (micro avg): 0.7818044712562101
2019-12-23 13:36:19,911 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7818         0.7818                       0.7818                0.0545                   0.2182  0.7818
1     Macro avg        0.9127         0.7688                       0.5279                0.0744                   0.4721  0.5454
2  Weighted avg        0.8743         0.8173                       0.7818                0.1538                   0.2182  0.7467
2019-12-23 13:36:20,244 [INFO] Dataset: Validation. Classification report below
2019-12-23 13:36:20,244 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.88      0.92       199
         u2r       0.45      0.50      0.48        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.88      0.87      0.88     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 13:36:20,244 [INFO] Overall accuracy (micro avg): 0.9965866243302243
2019-12-23 13:36:20,600 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9966         0.9966                       0.9966                0.0009                   0.0034  0.9966
1     Macro avg        0.9986         0.8819                       0.8736                0.0012                   0.1264  0.8771
2  Weighted avg        0.9980         0.9966                       0.9966                0.0024                   0.0034  0.9966
2019-12-23 13:36:22,045 [INFO] Dataset: Training. Classification report below
2019-12-23 13:36:22,045 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       1.00      0.99      0.99      9325
         r2l       0.97      0.90      0.93       796
         u2r       0.76      0.62      0.68        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.95      0.90      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 13:36:22,045 [INFO] Overall accuracy (micro avg): 0.9971422334239616
2019-12-23 13:36:23,667 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9971         0.9971                       0.9971                0.0007                   0.0029  0.9971
1     Macro avg        0.9989         0.9455                       0.9010                0.0010                   0.0990  0.9214
2  Weighted avg        0.9982         0.9971                       0.9971                0.0024                   0.0029  0.9971
2019-12-23 13:36:23,705 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep2/semi_sup_perf_nsl_ann_rep2_results.xlsx
2019-12-23 13:36:23,706 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 13:36:23,709 [INFO] Created directory: results_additional_exps/semi_sup_perf_nsl_ann_rep3
2019-12-23 13:36:23,709 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_nsl_ann_rep3/run_log.log
2019-12-23 13:36:23,709 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 13:36:23,709 [INFO] Experiment parameters given below
2019-12-23 13:36:23,709 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_nsl_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'normal', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'semi_sup_perf_nsl_ann_rep3'}
2019-12-23 13:36:23,709 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_nsl_ann_rep3/tf_logs_run_2019_12_23-13_36_23
2019-12-23 13:36:23,709 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 13:36:23,710 [INFO] Reading X, y files
2019-12-23 13:36:23,710 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 13:36:23,963 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-23 13:36:23,963 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 13:36:24,026 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 13:36:24,026 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 13:36:24,082 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 13:36:24,082 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 13:36:24,090 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 13:36:24,090 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 13:36:24,094 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:36:24,094 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 13:36:24,097 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 13:36:24,283 [INFO] Initializing model
2019-12-23 13:36:24,386 [INFO] _________________________________________________________________
2019-12-23 13:36:24,386 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 13:36:24,386 [INFO] =================================================================
2019-12-23 13:36:24,386 [INFO] dense_5 (Dense)              (None, 64)                7872      
2019-12-23 13:36:24,386 [INFO] _________________________________________________________________
2019-12-23 13:36:24,386 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2019-12-23 13:36:24,387 [INFO] _________________________________________________________________
2019-12-23 13:36:24,387 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2019-12-23 13:36:24,387 [INFO] _________________________________________________________________
2019-12-23 13:36:24,387 [INFO] dense_6 (Dense)              (None, 5)                 325       
2019-12-23 13:36:24,387 [INFO] =================================================================
2019-12-23 13:36:24,387 [INFO] Total params: 8,453
2019-12-23 13:36:24,387 [INFO] Trainable params: 8,325
2019-12-23 13:36:24,387 [INFO] Non-trainable params: 128
2019-12-23 13:36:24,387 [INFO] _________________________________________________________________
2019-12-23 13:36:24,387 [INFO] Training model
2019-12-23 13:36:24,387 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 13:36:25,092 [INFO] Split sizes (instances). total = 100778, set1 = 50389, set2 = 50389, set1 dataset hash = 06e3c0571318a4e80f9239b32a18cc0a10c17120
 - val_f1: 0.9965
Epoch 00139: early stopping
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1550 - val_loss: 0.0439
 - val_f1: 0.9699
Epoch 2/300
 - 0s - loss: 0.0413 - val_loss: 0.0293
 - val_f1: 0.9792
Epoch 3/300
 - 0s - loss: 0.0284 - val_loss: 0.0198
 - val_f1: 0.9842
Epoch 4/300
 - 0s - loss: 0.0214 - val_loss: 0.0155
 - val_f1: 0.9882
Epoch 5/300
 - 0s - loss: 0.0179 - val_loss: 0.0130
 - val_f1: 0.9914
Epoch 6/300
 - 0s - loss: 0.0154 - val_loss: 0.0123
 - val_f1: 0.9924
Epoch 7/300
 - 0s - loss: 0.0147 - val_loss: 0.0124
 - val_f1: 0.9914
Epoch 8/300
 - 0s - loss: 0.0131 - val_loss: 0.0118
 - val_f1: 0.9920
Epoch 9/300
 - 0s - loss: 0.0124 - val_loss: 0.0106
 - val_f1: 0.9933
Epoch 10/300
 - 0s - loss: 0.0120 - val_loss: 0.0111
 - val_f1: 0.9935
Epoch 11/300
 - 0s - loss: 0.0110 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 12/300
 - 0s - loss: 0.0107 - val_loss: 0.0098
 - val_f1: 0.9936
Epoch 13/300
 - 0s - loss: 0.0101 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 14/300
 - 0s - loss: 0.0099 - val_loss: 0.0103
 - val_f1: 0.9934
Epoch 15/300
 - 0s - loss: 0.0098 - val_loss: 0.0092
 - val_f1: 0.9941
Epoch 16/300
 - 0s - loss: 0.0095 - val_loss: 0.0098
 - val_f1: 0.9938
Epoch 17/300
 - 0s - loss: 0.0088 - val_loss: 0.0092
 - val_f1: 0.9945
Epoch 18/300
 - 0s - loss: 0.0085 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 19/300
 - 0s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9943
Epoch 20/300
 - 0s - loss: 0.0083 - val_loss: 0.0090
 - val_f1: 0.9930
Epoch 21/300
 - 0s - loss: 0.0076 - val_loss: 0.0082
 - val_f1: 0.9940
Epoch 22/300
 - 0s - loss: 0.0076 - val_loss: 0.0086
 - val_f1: 0.9946
Epoch 23/300
 - 0s - loss: 0.0079 - val_loss: 0.0085
 - val_f1: 0.9929
Epoch 24/300
 - 0s - loss: 0.0078 - val_loss: 0.0085
 - val_f1: 0.9945
Epoch 25/300
 - 0s - loss: 0.0078 - val_loss: 0.0082
 - val_f1: 0.9945
Epoch 26/300
 - 0s - loss: 0.0071 - val_loss: 0.0085
 - val_f1: 0.9947
Epoch 27/300
 - 0s - loss: 0.0069 - val_loss: 0.0086
 - val_f1: 0.9937
Epoch 28/300
 - 0s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9945
Epoch 29/300
 - 0s - loss: 0.0072 - val_loss: 0.0079
 - val_f1: 0.9946
Epoch 30/300
 - 0s - loss: 0.0069 - val_loss: 0.0085
 - val_f1: 0.9944
Epoch 31/300
 - 0s - loss: 0.0073 - val_loss: 0.0084
2019-12-23 13:36:47,414 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9945
Epoch 32/300
 - 0s - loss: 0.0070 - val_loss: 0.0081
 - val_f1: 0.9951
Epoch 33/300
 - 0s - loss: 0.0072 - val_loss: 0.0079
 - val_f1: 0.9945
Epoch 34/300
 - 0s - loss: 0.0071 - val_loss: 0.0078
 - val_f1: 0.9949
Epoch 35/300
 - 0s - loss: 0.0069 - val_loss: 0.0079
 - val_f1: 0.9950
Epoch 36/300
 - 0s - loss: 0.0064 - val_loss: 0.0079
 - val_f1: 0.9951
Epoch 37/300
 - 0s - loss: 0.0065 - val_loss: 0.0076
 - val_f1: 0.9953
Epoch 38/300
 - 0s - loss: 0.0064 - val_loss: 0.0077
 - val_f1: 0.9949
Epoch 39/300
 - 0s - loss: 0.0064 - val_loss: 0.0083
 - val_f1: 0.9950
Epoch 40/300
 - 0s - loss: 0.0063 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 41/300
 - 0s - loss: 0.0059 - val_loss: 0.0075
 - val_f1: 0.9951
Epoch 42/300
 - 0s - loss: 0.0066 - val_loss: 0.0075
 - val_f1: 0.9953
Epoch 43/300
 - 0s - loss: 0.0069 - val_loss: 0.0087
 - val_f1: 0.9947
Epoch 44/300
 - 0s - loss: 0.0059 - val_loss: 0.0077
 - val_f1: 0.9942
Epoch 45/300
 - 0s - loss: 0.0058 - val_loss: 0.0068
 - val_f1: 0.9948
Epoch 46/300
 - 0s - loss: 0.0059 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 47/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 48/300
 - 0s - loss: 0.0059 - val_loss: 0.0076
 - val_f1: 0.9957
Epoch 49/300
 - 0s - loss: 0.0060 - val_loss: 0.0074
 - val_f1: 0.9957
Epoch 50/300
 - 0s - loss: 0.0058 - val_loss: 0.0074
 - val_f1: 0.9951
Epoch 51/300
 - 0s - loss: 0.0055 - val_loss: 0.0082
 - val_f1: 0.9950
Epoch 52/300
 - 0s - loss: 0.0057 - val_loss: 0.0080
 - val_f1: 0.9955
Epoch 53/300
 - 0s - loss: 0.0057 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 54/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 55/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 56/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 57/300
 - 0s - loss: 0.0053 - val_loss: 0.0070
 - val_f1: 0.9962
Epoch 58/300
 - 0s - loss: 0.0053 - val_loss: 0.0069
 - val_f1: 0.9961
Epoch 59/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9950
Epoch 60/300
 - 0s - loss: 0.0053 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 61/300
 - 0s - loss: 0.0049 - val_loss: 0.0069
2019-12-23 13:37:07,790 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9959
Epoch 62/300
 - 0s - loss: 0.0046 - val_loss: 0.0078
 - val_f1: 0.9961
Epoch 63/300
 - 0s - loss: 0.0049 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 64/300
 - 0s - loss: 0.0049 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 65/300
 - 0s - loss: 0.0049 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 66/300
 - 0s - loss: 0.0050 - val_loss: 0.0072
 - val_f1: 0.9960
Epoch 67/300
 - 0s - loss: 0.0046 - val_loss: 0.0069
 - val_f1: 0.9960
Epoch 68/300
 - 0s - loss: 0.0051 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 69/300
 - 0s - loss: 0.0050 - val_loss: 0.0070
 - val_f1: 0.9961
Epoch 70/300
 - 0s - loss: 0.0047 - val_loss: 0.0066
 - val_f1: 0.9961
Epoch 71/300
 - 0s - loss: 0.0048 - val_loss: 0.0070
 - val_f1: 0.9961
Epoch 72/300
 - 0s - loss: 0.0049 - val_loss: 0.0070
 - val_f1: 0.9961
Epoch 73/300
 - 0s - loss: 0.0046 - val_loss: 0.0069
 - val_f1: 0.9961
Epoch 74/300
 - 0s - loss: 0.0044 - val_loss: 0.0073
 - val_f1: 0.9961
Epoch 75/300
 - 0s - loss: 0.0046 - val_loss: 0.0076
 - val_f1: 0.9952
Epoch 76/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9963
Epoch 77/300
 - 0s - loss: 0.0045 - val_loss: 0.0067
 - val_f1: 0.9962
Epoch 78/300
 - 0s - loss: 0.0045 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 79/300
 - 0s - loss: 0.0046 - val_loss: 0.0069
 - val_f1: 0.9960
Epoch 80/300
 - 0s - loss: 0.0046 - val_loss: 0.0065
 - val_f1: 0.9963
Epoch 81/300
 - 0s - loss: 0.0043 - val_loss: 0.0072
 - val_f1: 0.9956
Epoch 82/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9960
Epoch 83/300
 - 0s - loss: 0.0043 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 84/300
 - 0s - loss: 0.0043 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 85/300
 - 0s - loss: 0.0042 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 86/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9961
Epoch 87/300
 - 0s - loss: 0.0045 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 88/300
 - 0s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9959
Epoch 89/300
 - 0s - loss: 0.0042 - val_loss: 0.0070
 - val_f1: 0.9960
Epoch 90/300
 - 0s - loss: 0.0044 - val_loss: 0.0066
 - val_f1: 0.9963
Epoch 91/300
 - 0s - loss: 0.0045 - val_loss: 0.0068
2019-12-23 13:37:28,342 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9960
Epoch 92/300
 - 0s - loss: 0.0045 - val_loss: 0.0080
 - val_f1: 0.9959
Epoch 93/300
 - 0s - loss: 0.0041 - val_loss: 0.0075
 - val_f1: 0.9962
Epoch 94/300
 - 0s - loss: 0.0044 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 95/300
 - 0s - loss: 0.0042 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 96/300
 - 0s - loss: 0.0040 - val_loss: 0.0068
 - val_f1: 0.9960
Epoch 97/300
 - 0s - loss: 0.0042 - val_loss: 0.0070
 - val_f1: 0.9963
Epoch 98/300
 - 0s - loss: 0.0043 - val_loss: 0.0066
 - val_f1: 0.9964
Epoch 99/300
 - 0s - loss: 0.0042 - val_loss: 0.0071
 - val_f1: 0.9961
Epoch 100/300
 - 0s - loss: 0.0041 - val_loss: 0.0070
 - val_f1: 0.9962
Epoch 101/300
 - 0s - loss: 0.0038 - val_loss: 0.0069
 - val_f1: 0.9964
Epoch 102/300
 - 0s - loss: 0.0039 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 103/300
 - 0s - loss: 0.0041 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 104/300
 - 0s - loss: 0.0041 - val_loss: 0.0071
 - val_f1: 0.9964
Epoch 105/300
 - 0s - loss: 0.0043 - val_loss: 0.0069
 - val_f1: 0.9966
Epoch 106/300
 - 0s - loss: 0.0042 - val_loss: 0.0071
 - val_f1: 0.9959
Epoch 107/300
 - 0s - loss: 0.0040 - val_loss: 0.0069
 - val_f1: 0.9962
Epoch 108/300
 - 0s - loss: 0.0039 - val_loss: 0.0067
 - val_f1: 0.9965
Epoch 109/300
 - 0s - loss: 0.0038 - val_loss: 0.0067
 - val_f1: 0.9963
Epoch 110/300
 - 0s - loss: 0.0040 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 111/300
 - 0s - loss: 0.0042 - val_loss: 0.0067
 - val_f1: 0.9961
Epoch 112/300
 - 0s - loss: 0.0040 - val_loss: 0.0067
 - val_f1: 0.9962
Epoch 113/300
 - 0s - loss: 0.0043 - val_loss: 0.0067
 - val_f1: 0.9965
Epoch 114/300
 - 0s - loss: 0.0041 - val_loss: 0.0065
 - val_f1: 0.9966
Epoch 115/300
 - 0s - loss: 0.0036 - val_loss: 0.0064
 - val_f1: 0.9963
Epoch 116/300
 - 0s - loss: 0.0042 - val_loss: 0.0062
 - val_f1: 0.9964
Epoch 117/300
 - 0s - loss: 0.0036 - val_loss: 0.0065
 - val_f1: 0.9962
Epoch 118/300
 - 0s - loss: 0.0037 - val_loss: 0.0063
 - val_f1: 0.9968
Epoch 119/300
 - 0s - loss: 0.0039 - val_loss: 0.0065
 - val_f1: 0.9960
Epoch 120/300
 - 0s - loss: 0.0040 - val_loss: 0.0067
 - val_f1: 0.9962
Epoch 121/300
 - 0s - loss: 0.0040 - val_loss: 0.0065
2019-12-23 13:37:48,931 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9962
Epoch 122/300
 - 0s - loss: 0.0037 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 123/300
 - 0s - loss: 0.0040 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 124/300
 - 0s - loss: 0.0035 - val_loss: 0.0068
 - val_f1: 0.9964
Epoch 125/300
 - 0s - loss: 0.0036 - val_loss: 0.0064
 - val_f1: 0.9964
Epoch 126/300
 - 0s - loss: 0.0037 - val_loss: 0.0068
 - val_f1: 0.9963
Epoch 127/300
 - 0s - loss: 0.0036 - val_loss: 0.0065
 - val_f1: 0.9967
Epoch 128/300
 - 0s - loss: 0.0035 - val_loss: 0.0066
 - val_f1: 0.9962
Epoch 129/300
 - 0s - loss: 0.0039 - val_loss: 0.0066
 - val_f1: 0.9963
Epoch 130/300
 - 0s - loss: 0.0035 - val_loss: 0.0066
 - val_f1: 0.9964
Epoch 131/300
 - 0s - loss: 0.0036 - val_loss: 0.0067
 - val_f1: 0.9961
Epoch 132/300
 - 0s - loss: 0.0037 - val_loss: 0.0069
 - val_f1: 0.9963
Epoch 133/300
 - 0s - loss: 0.0036 - val_loss: 0.0063
 - val_f1: 0.9965
Epoch 134/300
 - 0s - loss: 0.0036 - val_loss: 0.0063
 - val_f1: 0.9965
Epoch 135/300
 - 0s - loss: 0.0035 - val_loss: 0.0065
 - val_f1: 0.9965
Epoch 136/300
 - 0s - loss: 0.0036 - val_loss: 0.0066
 - val_f1: 0.9965
Epoch 137/300
 - 0s - loss: 0.0040 - val_loss: 0.0065
 - val_f1: 0.9964
Epoch 138/300
 - 0s - loss: 0.0036 - val_loss: 0.0068
 - val_f1: 0.9965
Epoch 139/300
 - 0s - loss: 0.0035 - val_loss: 0.0065
 - val_f1: 0.9967
Epoch 140/300
 - 0s - loss: 0.0037 - val_loss: 0.0074
 - val_f1: 0.9950
Epoch 141/300
 - 0s - loss: 0.0041 - val_loss: 0.0066
 - val_f1: 0.9963
Epoch 142/300
 - 0s - loss: 0.0039 - val_loss: 0.0067
 - val_f1: 0.9963
Epoch 143/300
 - 0s - loss: 0.0039 - val_loss: 0.0066
 - val_f1: 0.9964
Epoch 144/300
 - 0s - loss: 0.0038 - val_loss: 0.0070
 - val_f1: 0.9965
Epoch 145/300
 - 0s - loss: 0.0043 - val_loss: 0.0071
 - val_f1: 0.9961
Epoch 146/300
 - 0s - loss: 0.0036 - val_loss: 0.0065
 - val_f1: 0.9965
Epoch 147/300
 - 0s - loss: 0.0036 - val_loss: 0.0066
 - val_f1: 0.9965
Epoch 148/300
 - 0s - loss: 0.0035 - val_loss: 0.0064
 - val_f1: 0.9967
Epoch 149/300
 - 0s - loss: 0.0035 - val_loss: 0.0066
 - val_f1: 0.9968
Epoch 150/300
 - 0s - loss: 0.0035 - val_loss: 0.0065
 - val_f1: 0.9965
Epoch 151/300
 - 0s - loss: 0.0035 - val_loss: 0.0069
2019-12-23 13:38:09,405 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9968
Epoch 152/300
 - 0s - loss: 0.0035 - val_loss: 0.0067
 - val_f1: 0.9967
Epoch 153/300
 - 0s - loss: 0.0035 - val_loss: 0.0068
 - val_f1: 0.9965
Epoch 154/300
 - 0s - loss: 0.0034 - val_loss: 0.0064
 - val_f1: 0.9968
Epoch 155/300
 - 0s - loss: 0.0034 - val_loss: 0.0067
 - val_f1: 0.9963
Epoch 156/300
 - 0s - loss: 0.0036 - val_loss: 0.0074
 - val_f1: 0.9962
Epoch 157/300
 - 0s - loss: 0.0038 - val_loss: 0.0070
 - val_f1: 0.9966
Epoch 158/300
 - 0s - loss: 0.0035 - val_loss: 0.0067
 - val_f1: 0.9966
Epoch 159/300
 - 0s - loss: 0.0035 - val_loss: 0.0076
 - val_f1: 0.9961
Epoch 160/300
 - 0s - loss: 0.0036 - val_loss: 0.0071
 - val_f1: 0.9966
Epoch 161/300
 - 0s - loss: 0.0034 - val_loss: 0.0066
 - val_f1: 0.9965
Epoch 162/300
 - 0s - loss: 0.0036 - val_loss: 0.0068
 - val_f1: 0.9965
Epoch 163/300
 - 0s - loss: 0.0036 - val_loss: 0.0068
 - val_f1: 0.9966
Epoch 164/300
 - 0s - loss: 0.0036 - val_loss: 0.0065
 - val_f1: 0.9968
Epoch 165/300
 - 0s - loss: 0.0032 - val_loss: 0.0066
 - val_f1: 0.9963
Epoch 166/300
 - 0s - loss: 0.0033 - val_loss: 0.0066
2019-12-23 13:38:19,920 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 13:38:20,872 [INFO] Last epoch loss evaluation: train_loss = 0.002619, val_loss = 0.006212
2019-12-23 13:38:20,876 [INFO] Training complete. time_to_train = 116.49 sec, 1.94 min
2019-12-23 13:38:20,880 [INFO] Model saved to results_additional_exps/semi_sup_perf_nsl_ann_rep3/best_model.pickle
2019-12-23 13:38:21,065 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/training_error_history.png
2019-12-23 13:38:21,231 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/training_f1_history.png
2019-12-23 13:38:21,231 [INFO] Making predictions on training, validation, testing data
2019-12-23 13:38:22,654 [INFO] Evaluating predictions (results)
2019-12-23 13:38:22,914 [INFO] Dataset: Testing. Classification report below
2019-12-23 13:38:22,914 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.90      7458
      normal       0.68      0.97      0.80      9711
       probe       0.86      0.73      0.79      2421
         r2l       0.96      0.10      0.18      2421
         u2r       0.45      0.05      0.08       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.79      0.53      0.55     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-23 13:38:22,914 [INFO] Overall accuracy (micro avg): 0.7838449254790631
2019-12-23 13:38:23,210 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7838         0.7838                       0.7838                0.0540                   0.2162  0.7838
1     Macro avg        0.9135         0.7854                       0.5348                0.0737                   0.4652  0.5496
2  Weighted avg        0.8748         0.8218                       0.7838                0.1524                   0.2162  0.7482
2019-12-23 13:38:23,544 [INFO] Dataset: Validation. Classification report below
2019-12-23 13:38:23,544 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.96      0.86      0.91       199
         u2r       0.83      0.50      0.62        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.96      0.87      0.90     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 13:38:23,544 [INFO] Overall accuracy (micro avg): 0.9963881722564001
2019-12-23 13:38:23,901 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9964         0.9964                       0.9964                0.0009                   0.0036  0.9964
1     Macro avg        0.9986         0.9559                       0.8708                0.0012                   0.1292  0.9045
2  Weighted avg        0.9978         0.9963                       0.9964                0.0026                   0.0036  0.9963
2019-12-23 13:38:25,344 [INFO] Dataset: Training. Classification report below
2019-12-23 13:38:25,345 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.97      0.87      0.92       796
         u2r       0.78      0.74      0.76        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.95      0.92      0.93    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 13:38:25,345 [INFO] Overall accuracy (micro avg): 0.9970033142154041
2019-12-23 13:38:26,966 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0007                   0.0030  0.9970
1     Macro avg        0.9988         0.9473                       0.9195                0.0011                   0.0805  0.9327
2  Weighted avg        0.9981         0.9970                       0.9970                0.0024                   0.0030  0.9970
2019-12-23 13:38:27,003 [INFO] Results saved to: results_additional_exps/semi_sup_perf_nsl_ann_rep3/semi_sup_perf_nsl_ann_rep3_results.xlsx
2019-12-23 13:38:27,004 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 13:38:27,007 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep1/run_log.log
2019-12-23 13:38:27,007 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 13:38:27,007 [INFO] Experiment parameters given below
2019-12-23 13:38:27,007 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep1'}
2019-12-23 13:38:27,007 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep1/tf_logs_run_2019_12_23-13_38_27
2019-12-23 13:38:27,007 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 13:38:27,007 [INFO] Reading X, y files
2019-12-23 13:38:27,007 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 13:38:31,051 [INFO] Reading complete. time_to_read=4.04 seconds
2019-12-23 13:38:31,052 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 13:38:32,429 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 13:38:32,430 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 13:38:33,806 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 13:38:33,806 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 13:38:34,017 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-23 13:38:34,017 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 13:38:34,082 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 13:38:34,082 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 13:38:34,148 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 13:38:37,297 [INFO] Initializing model
2019-12-23 13:38:37,402 [INFO] _________________________________________________________________
2019-12-23 13:38:37,402 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 13:38:37,402 [INFO] =================================================================
2019-12-23 13:38:37,402 [INFO] dense_7 (Dense)              (None, 64)                5056      
2019-12-23 13:38:37,402 [INFO] _________________________________________________________________
2019-12-23 13:38:37,402 [INFO] batch_normalization_4 (Batch (None, 64)                256       
2019-12-23 13:38:37,402 [INFO] _________________________________________________________________
2019-12-23 13:38:37,402 [INFO] dropout_4 (Dropout)          (None, 64)                0         
2019-12-23 13:38:37,403 [INFO] _________________________________________________________________
2019-12-23 13:38:37,403 [INFO] dense_8 (Dense)              (None, 12)                780       
2019-12-23 13:38:37,403 [INFO] =================================================================
2019-12-23 13:38:37,403 [INFO] Total params: 6,092
2019-12-23 13:38:37,403 [INFO] Trainable params: 5,964
2019-12-23 13:38:37,403 [INFO] Non-trainable params: 128
2019-12-23 13:38:37,403 [INFO] _________________________________________________________________
2019-12-23 13:38:37,403 [INFO] Training model
2019-12-23 13:38:37,403 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 13:38:54,586 [INFO] Split sizes (instances). total = 1696684, set1 = 848342, set2 = 848342, set1 dataset hash = b75e78959164c90d19a336ef2d2a5a10f094d2bb
 - val_f1: 0.9966
Epoch 00166: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0256 - val_loss: 0.0226
 - val_f1: 0.9385
Epoch 2/300
 - 8s - loss: 0.0118 - val_loss: 0.0098
 - val_f1: 0.9739
Epoch 3/300
 - 8s - loss: 0.0102 - val_loss: 0.0092
 - val_f1: 0.9770
Epoch 4/300
 - 8s - loss: 0.0092 - val_loss: 0.0079
 - val_f1: 0.9788
Epoch 5/300
 - 8s - loss: 0.0085 - val_loss: 0.0077
 - val_f1: 0.9807
Epoch 6/300
 - 8s - loss: 0.0069 - val_loss: 0.0145
 - val_f1: 0.9732
Epoch 7/300
 - 8s - loss: 0.0062 - val_loss: 0.0055
 - val_f1: 0.9917
Epoch 8/300
 - 8s - loss: 0.0058 - val_loss: 0.0049
 - val_f1: 0.9884
Epoch 9/300
 - 8s - loss: 0.0056 - val_loss: 0.0064
 - val_f1: 0.9886
Epoch 10/300
 - 8s - loss: 0.0058 - val_loss: 0.0076
 - val_f1: 0.9819
Epoch 11/300
 - 8s - loss: 0.0056 - val_loss: 0.0084
 - val_f1: 0.9838
Epoch 12/300
 - 8s - loss: 0.0054 - val_loss: 0.0051
 - val_f1: 0.9894
Epoch 13/300
 - 8s - loss: 0.0052 - val_loss: 0.0059
 - val_f1: 0.9863
Epoch 14/300
 - 8s - loss: 0.0050 - val_loss: 0.0050
 - val_f1: 0.9895
Epoch 15/300
 - 8s - loss: 0.0055 - val_loss: 0.0043
 - val_f1: 0.9913
Epoch 16/300
 - 8s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9912
Epoch 17/300
 - 8s - loss: 0.0051 - val_loss: 0.0059
 - val_f1: 0.9865
Epoch 18/300
 - 8s - loss: 0.0051 - val_loss: 0.0045
 - val_f1: 0.9912
Epoch 19/300
 - 8s - loss: 0.0049 - val_loss: 0.0043
 - val_f1: 0.9937
Epoch 20/300
 - 8s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 21/300
 - 8s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 22/300
 - 8s - loss: 0.0047 - val_loss: 0.0050
 - val_f1: 0.9892
Epoch 23/300
 - 8s - loss: 0.0046 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 24/300
 - 8s - loss: 0.0046 - val_loss: 0.0040
 - val_f1: 0.9945
Epoch 25/300
 - 8s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9918
Epoch 26/300
 - 8s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 27/300
 - 8s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9910
Epoch 28/300
 - 8s - loss: 0.0044 - val_loss: 0.0043
 - val_f1: 0.9925
Epoch 29/300
 - 8s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9924
Epoch 30/300
 - 8s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9910
Epoch 31/300
 - 8s - loss: 0.0043 - val_loss: 0.0068
2019-12-23 13:46:09,031 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9745
Epoch 32/300
 - 8s - loss: 0.0043 - val_loss: 0.0043
 - val_f1: 0.9900
Epoch 33/300
 - 8s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 34/300
 - 8s - loss: 0.0042 - val_loss: 0.0045
 - val_f1: 0.9919
Epoch 35/300
 - 8s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 36/300
 - 8s - loss: 0.0045 - val_loss: 0.0058
 - val_f1: 0.9886
Epoch 37/300
 - 8s - loss: 0.0044 - val_loss: 0.0055
 - val_f1: 0.9890
Epoch 38/300
 - 8s - loss: 0.0042 - val_loss: 0.0064
 - val_f1: 0.9872
Epoch 39/300
 - 8s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 40/300
 - 8s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 41/300
 - 8s - loss: 0.0043 - val_loss: 0.0045
 - val_f1: 0.9914
Epoch 42/300
 - 8s - loss: 0.0042 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 43/300
 - 8s - loss: 0.0042 - val_loss: 0.0073
 - val_f1: 0.9775
Epoch 44/300
 - 8s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9943
Epoch 45/300
 - 8s - loss: 0.0040 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 46/300
 - 8s - loss: 0.0041 - val_loss: 0.0063
 - val_f1: 0.9836
Epoch 47/300
 - 8s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 48/300
 - 8s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 49/300
 - 8s - loss: 0.0041 - val_loss: 0.0047
 - val_f1: 0.9917
Epoch 50/300
 - 8s - loss: 0.0039 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 51/300
 - 8s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 52/300
 - 8s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 53/300
 - 8s - loss: 0.0039 - val_loss: 0.0054
 - val_f1: 0.9904
Epoch 54/300
 - 8s - loss: 0.0039 - val_loss: 0.0049
 - val_f1: 0.9897
Epoch 55/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 56/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 57/300
 - 8s - loss: 0.0039 - val_loss: 0.0034
 - val_f1: 0.9943
Epoch 58/300
 - 8s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9933
Epoch 59/300
 - 8s - loss: 0.0039 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 60/300
 - 8s - loss: 0.0039 - val_loss: 0.0048
 - val_f1: 0.9890
Epoch 61/300
 - 8s - loss: 0.0038 - val_loss: 0.0048
2019-12-23 13:53:14,376 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9911
Epoch 62/300
 - 8s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 63/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9930
Epoch 64/300
 - 8s - loss: 0.0038 - val_loss: 0.0064
 - val_f1: 0.9872
Epoch 65/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 66/300
 - 8s - loss: 0.0038 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 67/300
 - 8s - loss: 0.0038 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 68/300
 - 8s - loss: 0.0038 - val_loss: 0.0055
 - val_f1: 0.9871
Epoch 69/300
 - 8s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 70/300
 - 8s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 71/300
 - 8s - loss: 0.0038 - val_loss: 0.0039
 - val_f1: 0.9948
Epoch 72/300
 - 8s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9945
Epoch 73/300
 - 8s - loss: 0.0037 - val_loss: 0.0044
 - val_f1: 0.9910
Epoch 74/300
 - 8s - loss: 0.0038 - val_loss: 0.0042
 - val_f1: 0.9915
Epoch 75/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 76/300
 - 8s - loss: 0.0037 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 77/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 78/300
 - 8s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 79/300
 - 8s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 80/300
 - 8s - loss: 0.0036 - val_loss: 0.0054
 - val_f1: 0.9894
Epoch 81/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 82/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 83/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9915
Epoch 84/300
 - 8s - loss: 0.0036 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 85/300
 - 8s - loss: 0.0036 - val_loss: 0.0055
 - val_f1: 0.9896
Epoch 86/300
 - 8s - loss: 0.0036 - val_loss: 0.0064
 - val_f1: 0.9876
Epoch 87/300
 - 8s - loss: 0.0036 - val_loss: 0.0041
 - val_f1: 0.9914
Epoch 88/300
 - 8s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9900
Epoch 89/300
 - 8s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 90/300
 - 8s - loss: 0.0036 - val_loss: 0.0062
 - val_f1: 0.9866
Epoch 91/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
2019-12-23 14:00:19,886 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9939
Epoch 92/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 93/300
 - 8s - loss: 0.0036 - val_loss: 0.0052
 - val_f1: 0.9882
Epoch 94/300
 - 8s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 95/300
 - 8s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 96/300
 - 8s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9912
Epoch 97/300
 - 8s - loss: 0.0035 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 98/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 99/300
 - 8s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9949
Epoch 100/300
 - 8s - loss: 0.0034 - val_loss: 0.0041
 - val_f1: 0.9913
Epoch 101/300
 - 8s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 102/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 103/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 104/300
 - 8s - loss: 0.0034 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 105/300
 - 8s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9909
Epoch 106/300
 - 8s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 107/300
 - 8s - loss: 0.0036 - val_loss: 0.0069
 - val_f1: 0.9869
Epoch 108/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9910
Epoch 109/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 110/300
 - 8s - loss: 0.0035 - val_loss: 0.0048
 - val_f1: 0.9935
Epoch 111/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 112/300
 - 8s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 113/300
 - 8s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 114/300
 - 8s - loss: 0.0034 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 115/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 116/300
 - 8s - loss: 0.0034 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 117/300
 - 8s - loss: 0.0034 - val_loss: 0.0051
 - val_f1: 0.9878
Epoch 118/300
 - 8s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 119/300
 - 8s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 120/300
 - 8s - loss: 0.0034 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 121/300
 - 8s - loss: 0.0034 - val_loss: 0.0061
2019-12-23 14:07:26,084 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9876
Epoch 122/300
 - 8s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 123/300
 - 8s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9915
Epoch 124/300
 - 8s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9907
Epoch 125/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9914
Epoch 126/300
 - 8s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 127/300
 - 8s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9909
Epoch 128/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9927
Epoch 129/300
 - 8s - loss: 0.0033 - val_loss: 0.0051
 - val_f1: 0.9882
Epoch 130/300
 - 8s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9908
Epoch 131/300
 - 8s - loss: 0.0034 - val_loss: 0.0054
 - val_f1: 0.9885
Epoch 132/300
 - 8s - loss: 0.0034 - val_loss: 0.0047
 - val_f1: 0.9934
Epoch 133/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 134/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 135/300
 - 8s - loss: 0.0033 - val_loss: 0.0059
 - val_f1: 0.9859
Epoch 136/300
 - 8s - loss: 0.0033 - val_loss: 0.0040
 - val_f1: 0.9915
Epoch 137/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9929
Epoch 138/300
 - 8s - loss: 0.0033 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 139/300
 - 8s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 140/300
 - 8s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9926
Epoch 141/300
 - 8s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 142/300
 - 8s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9898
Epoch 143/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 144/300
 - 8s - loss: 0.0034 - val_loss: 0.0081
 - val_f1: 0.9851
Epoch 145/300
 - 8s - loss: 0.0033 - val_loss: 0.0074
 - val_f1: 0.9891
Epoch 146/300
 - 8s - loss: 0.0033 - val_loss: 0.0056
 - val_f1: 0.9884
Epoch 147/300
 - 8s - loss: 0.0033 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 148/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 149/300
 - 8s - loss: 0.0032 - val_loss: 0.0043
2019-12-23 14:14:09,584 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 14:14:26,684 [INFO] Last epoch loss evaluation: train_loss = 0.002586, val_loss = 0.002668
2019-12-23 14:14:26,716 [INFO] Training complete. time_to_train = 2149.31 sec, 35.82 min
2019-12-23 14:14:26,719 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep1/best_model.pickle
2019-12-23 14:14:26,897 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/training_error_history.png
2019-12-23 14:14:27,069 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/training_f1_history.png
2019-12-23 14:14:27,069 [INFO] Making predictions on training, validation, testing data
2019-12-23 14:14:54,047 [INFO] Evaluating predictions (results)
2019-12-23 14:15:04,188 [INFO] Dataset: Testing. Classification report below
2019-12-23 14:15:04,188 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.55       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.98      0.98      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.92      1100
         DoS slowloris       0.98      0.97      0.97      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       1.00      0.09      0.17       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.89      0.78      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 14:15:04,188 [INFO] Overall accuracy (micro avg): 0.9946796284050201
/home/sunanda/test/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 14:15:15,733 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8938                       0.7784                0.0014                   0.2216  0.7938
2  Weighted avg        0.9956         0.9945                       0.9947                0.0118                   0.0053  0.9943
2019-12-23 14:15:26,082 [INFO] Dataset: Validation. Classification report below
2019-12-23 14:15:26,082 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.98      0.98     46025
      DoS Slowhttptest       0.88      0.97      0.92      1099
         DoS slowloris       0.98      0.97      0.97      1159
           FTP-Patator       0.98      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.98      0.96      1180
Web Attack Brute Force       0.95      0.07      0.12       301
        Web Attack XSS       0.38      0.02      0.04       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.92      0.77      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 14:15:26,082 [INFO] Overall accuracy (micro avg): 0.9949165608721944
2019-12-23 14:15:37,833 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9992         0.9216                       0.7739                0.0014                   0.2261  0.7902
2  Weighted avg        0.9958         0.9948                       0.9949                0.0113                   0.0051  0.9945
2019-12-23 14:16:11,935 [INFO] Dataset: Training. Classification report below
2019-12-23 14:16:11,935 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.54      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.98      0.98      0.98    138074
      DoS Slowhttptest       0.89      0.97      0.93      3300
         DoS slowloris       0.98      0.97      0.98      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.99      0.08      0.15       904
        Web Attack XSS       0.38      0.03      0.06       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.93      0.78      0.80   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-23 14:16:11,935 [INFO] Overall accuracy (micro avg): 0.9949059459510433
2019-12-23 14:16:50,627 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9992         0.9280                       0.7795                0.0014                   0.2205  0.7979
2  Weighted avg        0.9958         0.9948                       0.9949                0.0116                   0.0051  0.9945
2019-12-23 14:16:50,678 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep1/semi_sup_perf_ids17_ann_rep1_results.xlsx
2019-12-23 14:16:50,683 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 14:16:50,750 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_ann_rep2
2019-12-23 14:16:50,750 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep2/run_log.log
2019-12-23 14:16:50,750 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 14:16:50,750 [INFO] Experiment parameters given below
2019-12-23 14:16:50,750 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep2'}
2019-12-23 14:16:50,750 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep2/tf_logs_run_2019_12_23-14_16_50
2019-12-23 14:16:50,750 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 14:16:50,751 [INFO] Reading X, y files
2019-12-23 14:16:50,751 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 14:16:54,763 [INFO] Reading complete. time_to_read=4.01 seconds
2019-12-23 14:16:54,764 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 14:16:56,138 [INFO] Reading complete. time_to_read=1.37 seconds
2019-12-23 14:16:56,138 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 14:16:57,523 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 14:16:57,523 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 14:16:57,740 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-23 14:16:57,740 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 14:16:57,806 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:16:57,806 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 14:16:57,872 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:17:01,015 [INFO] Initializing model
2019-12-23 14:17:01,119 [INFO] _________________________________________________________________
2019-12-23 14:17:01,119 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 14:17:01,119 [INFO] =================================================================
2019-12-23 14:17:01,119 [INFO] dense_9 (Dense)              (None, 64)                5056      
2019-12-23 14:17:01,119 [INFO] _________________________________________________________________
2019-12-23 14:17:01,120 [INFO] batch_normalization_5 (Batch (None, 64)                256       
2019-12-23 14:17:01,120 [INFO] _________________________________________________________________
2019-12-23 14:17:01,120 [INFO] dropout_5 (Dropout)          (None, 64)                0         
2019-12-23 14:17:01,120 [INFO] _________________________________________________________________
2019-12-23 14:17:01,120 [INFO] dense_10 (Dense)             (None, 12)                780       
2019-12-23 14:17:01,120 [INFO] =================================================================
2019-12-23 14:17:01,120 [INFO] Total params: 6,092
2019-12-23 14:17:01,120 [INFO] Trainable params: 5,964
2019-12-23 14:17:01,120 [INFO] Non-trainable params: 128
2019-12-23 14:17:01,120 [INFO] _________________________________________________________________
2019-12-23 14:17:01,120 [INFO] Training model
2019-12-23 14:17:01,120 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 14:17:18,338 [INFO] Split sizes (instances). total = 1696684, set1 = 848342, set2 = 848342, set1 dataset hash = b75e78959164c90d19a336ef2d2a5a10f094d2bb
 - val_f1: 0.9893
Epoch 00149: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0260 - val_loss: 0.0141
 - val_f1: 0.9618
Epoch 2/300
 - 8s - loss: 0.0118 - val_loss: 0.0109
 - val_f1: 0.9757
Epoch 3/300
 - 9s - loss: 0.0102 - val_loss: 0.0124
 - val_f1: 0.9613
Epoch 4/300
 - 9s - loss: 0.0085 - val_loss: 0.0056
 - val_f1: 0.9890
Epoch 5/300
 - 9s - loss: 0.0068 - val_loss: 0.0076
 - val_f1: 0.9831
Epoch 6/300
 - 8s - loss: 0.0064 - val_loss: 0.0053
 - val_f1: 0.9888
Epoch 7/300
 - 8s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9842
Epoch 8/300
 - 9s - loss: 0.0063 - val_loss: 0.0063
 - val_f1: 0.9856
Epoch 9/300
 - 8s - loss: 0.0057 - val_loss: 0.0071
 - val_f1: 0.9850
Epoch 10/300
 - 8s - loss: 0.0056 - val_loss: 0.0054
 - val_f1: 0.9878
Epoch 11/300
 - 9s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9916
Epoch 12/300
 - 8s - loss: 0.0053 - val_loss: 0.0056
 - val_f1: 0.9919
Epoch 13/300
 - 9s - loss: 0.0052 - val_loss: 0.0074
 - val_f1: 0.9763
Epoch 14/300
 - 8s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 15/300
 - 8s - loss: 0.0048 - val_loss: 0.0055
 - val_f1: 0.9877
Epoch 16/300
 - 9s - loss: 0.0048 - val_loss: 0.0071
 - val_f1: 0.9854
Epoch 17/300
 - 9s - loss: 0.0047 - val_loss: 0.0064
 - val_f1: 0.9840
Epoch 18/300
 - 9s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 19/300
 - 9s - loss: 0.0046 - val_loss: 0.0055
 - val_f1: 0.9871
Epoch 20/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9944
Epoch 21/300
 - 8s - loss: 0.0045 - val_loss: 0.0043
 - val_f1: 0.9923
Epoch 22/300
 - 8s - loss: 0.0044 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 23/300
 - 8s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9915
Epoch 24/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 25/300
 - 8s - loss: 0.0043 - val_loss: 0.0053
 - val_f1: 0.9883
Epoch 26/300
 - 8s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 27/300
 - 8s - loss: 0.0043 - val_loss: 0.0052
 - val_f1: 0.9870
Epoch 28/300
 - 8s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 29/300
 - 8s - loss: 0.0042 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 30/300
 - 9s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9929
Epoch 31/300
 - 9s - loss: 0.0042 - val_loss: 0.0040
2019-12-23 14:24:50,168 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9916
Epoch 32/300
 - 8s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9942
Epoch 33/300
 - 8s - loss: 0.0042 - val_loss: 0.0048
 - val_f1: 0.9904
Epoch 34/300
 - 8s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9944
Epoch 35/300
 - 8s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 36/300
 - 8s - loss: 0.0040 - val_loss: 0.0043
 - val_f1: 0.9908
Epoch 37/300
 - 8s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 38/300
 - 8s - loss: 0.0040 - val_loss: 0.0046
 - val_f1: 0.9899
Epoch 39/300
 - 8s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 40/300
 - 8s - loss: 0.0039 - val_loss: 0.0073
 - val_f1: 0.9734
Epoch 41/300
 - 8s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 42/300
 - 8s - loss: 0.0038 - val_loss: 0.0047
 - val_f1: 0.9894
Epoch 43/300
 - 8s - loss: 0.0038 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 44/300
 - 8s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 45/300
 - 8s - loss: 0.0039 - val_loss: 0.0073
 - val_f1: 0.9856
Epoch 46/300
 - 8s - loss: 0.0039 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 47/300
 - 8s - loss: 0.0038 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 48/300
 - 8s - loss: 0.0038 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 49/300
 - 8s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9950
Epoch 50/300
 - 8s - loss: 0.0039 - val_loss: 0.0051
 - val_f1: 0.9913
Epoch 51/300
 - 8s - loss: 0.0039 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 52/300
 - 8s - loss: 0.0039 - val_loss: 0.0050
 - val_f1: 0.9915
Epoch 53/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 54/300
 - 8s - loss: 0.0038 - val_loss: 0.0034
 - val_f1: 0.9948
Epoch 55/300
 - 8s - loss: 0.0037 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 56/300
 - 8s - loss: 0.0037 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 57/300
 - 8s - loss: 0.0037 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 58/300
 - 8s - loss: 0.0037 - val_loss: 0.0051
 - val_f1: 0.9895
Epoch 59/300
 - 8s - loss: 0.0035 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 60/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 61/300
 - 8s - loss: 0.0037 - val_loss: 0.0067
2019-12-23 14:32:08,719 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9754
Epoch 62/300
 - 8s - loss: 0.0036 - val_loss: 0.0042
 - val_f1: 0.9908
Epoch 63/300
 - 8s - loss: 0.0036 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 64/300
 - 8s - loss: 0.0036 - val_loss: 0.0048
 - val_f1: 0.9912
Epoch 65/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9927
Epoch 66/300
 - 8s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9905
Epoch 67/300
 - 8s - loss: 0.0037 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 68/300
 - 8s - loss: 0.0036 - val_loss: 0.0035
 - val_f1: 0.9918
Epoch 69/300
 - 8s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9906
Epoch 70/300
 - 8s - loss: 0.0036 - val_loss: 0.0049
 - val_f1: 0.9900
Epoch 71/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 72/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 73/300
 - 8s - loss: 0.0035 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 74/300
 - 8s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9906
Epoch 75/300
 - 8s - loss: 0.0036 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 76/300
 - 8s - loss: 0.0035 - val_loss: 0.0065
 - val_f1: 0.9862
Epoch 77/300
 - 8s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 78/300
 - 8s - loss: 0.0035 - val_loss: 0.0041
 - val_f1: 0.9940
Epoch 79/300
 - 8s - loss: 0.0035 - val_loss: 0.0049
 - val_f1: 0.9895
Epoch 80/300
 - 8s - loss: 0.0035 - val_loss: 0.0051
 - val_f1: 0.9914
Epoch 81/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 82/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 83/300
 - 8s - loss: 0.0035 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 84/300
 - 8s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9915
Epoch 85/300
 - 8s - loss: 0.0035 - val_loss: 0.0037
 - val_f1: 0.9927
Epoch 86/300
 - 8s - loss: 0.0035 - val_loss: 0.0036
 - val_f1: 0.9925
Epoch 87/300
 - 8s - loss: 0.0035 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 88/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 89/300
 - 8s - loss: 0.0034 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 90/300
 - 9s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 91/300
 - 8s - loss: 0.0036 - val_loss: 0.0030
2019-12-23 14:39:26,613 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9939
Epoch 92/300
 - 8s - loss: 0.0035 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 93/300
 - 8s - loss: 0.0035 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 94/300
 - 8s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 95/300
 - 8s - loss: 0.0035 - val_loss: 0.0050
 - val_f1: 0.9910
Epoch 96/300
 - 8s - loss: 0.0035 - val_loss: 0.0043
 - val_f1: 0.9929
Epoch 97/300
 - 8s - loss: 0.0034 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 98/300
 - 8s - loss: 0.0034 - val_loss: 0.0060
 - val_f1: 0.9767
Epoch 99/300
 - 8s - loss: 0.0034 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 100/300
 - 8s - loss: 0.0034 - val_loss: 0.0052
 - val_f1: 0.9879
Epoch 101/300
 - 8s - loss: 0.0034 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 102/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 103/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 104/300
 - 8s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9913
Epoch 105/300
 - 9s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 106/300
 - 8s - loss: 0.0034 - val_loss: 0.0047
 - val_f1: 0.9902
Epoch 107/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 108/300
 - 8s - loss: 0.0034 - val_loss: 0.0046
 - val_f1: 0.9906
Epoch 109/300
 - 8s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9902
Epoch 110/300
 - 8s - loss: 0.0034 - val_loss: 0.0039
 - val_f1: 0.9922
Epoch 111/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9931
Epoch 112/300
 - 8s - loss: 0.0033 - val_loss: 0.0047
 - val_f1: 0.9905
Epoch 113/300
 - 8s - loss: 0.0034 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 114/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 115/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9954
Epoch 116/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 117/300
 - 8s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9906
Epoch 118/300
 - 8s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 119/300
 - 8s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 120/300
 - 8s - loss: 0.0034 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 121/300
 - 8s - loss: 0.0034 - val_loss: 0.0030
2019-12-23 14:46:44,673 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9927
Epoch 122/300
 - 8s - loss: 0.0034 - val_loss: 0.0045
 - val_f1: 0.9903
Epoch 123/300
 - 8s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9939
Epoch 124/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 125/300
 - 8s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 126/300
 - 8s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9906
Epoch 127/300
 - 8s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 128/300
 - 8s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 129/300
 - 8s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 130/300
 - 8s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 131/300
 - 8s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 132/300
 - 8s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 133/300
 - 8s - loss: 0.0033 - val_loss: 0.0038
2019-12-23 14:49:45,681 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 14:50:03,634 [INFO] Last epoch loss evaluation: train_loss = 0.002653, val_loss = 0.002748
2019-12-23 14:50:03,665 [INFO] Training complete. time_to_train = 1982.54 sec, 33.04 min
2019-12-23 14:50:03,668 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep2/best_model.pickle
2019-12-23 14:50:03,847 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/training_error_history.png
2019-12-23 14:50:04,024 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/training_f1_history.png
2019-12-23 14:50:04,025 [INFO] Making predictions on training, validation, testing data
2019-12-23 14:50:33,067 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 14:50:43,230 [INFO] Dataset: Testing. Classification report below
2019-12-23 14:50:43,231 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.95      0.97      2058
              DoS Hulk       0.97      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1100
         DoS slowloris       0.98      0.95      0.96      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.97      0.94      0.95      1179
Web Attack Brute Force       1.00      0.08      0.15       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.90      0.77      0.79    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 14:50:43,231 [INFO] Overall accuracy (micro avg): 0.994927169788635
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 14:50:54,784 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9992         0.8968                       0.7713                0.0012                   0.2287  0.7900
2  Weighted avg        0.9958         0.9947                       0.9949                0.0093                   0.0051  0.9945
2019-12-23 14:51:05,133 [INFO] Dataset: Validation. Classification report below
2019-12-23 14:51:05,133 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.99      0.35      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       1.00      0.94      0.97      2059
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.98      0.94      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.97      0.95      0.96      1180
Web Attack Brute Force       0.88      0.05      0.09       301
        Web Attack XSS       1.00      0.02      0.04       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.97      0.77      0.79    565562
          weighted avg       1.00      1.00      0.99    565562

2019-12-23 14:51:05,133 [INFO] Overall accuracy (micro avg): 0.9950474041749623
2019-12-23 14:51:16,884 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.9706                       0.7674                0.0012                   0.2326  0.7861
2  Weighted avg        0.9959         0.9950                       0.9950                0.0090                   0.0050  0.9946
2019-12-23 14:51:50,954 [INFO] Dataset: Training. Classification report below
2019-12-23 14:51:50,955 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       1.00      0.95      0.97      6176
              DoS Hulk       0.98      0.99      0.98    138074
      DoS Slowhttptest       0.90      0.98      0.94      3300
         DoS slowloris       0.98      0.96      0.97      3478
           FTP-Patator       1.00      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.98      0.95      0.96      3538
Web Attack Brute Force       0.98      0.07      0.12       904
        Web Attack XSS       1.00      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.98      0.77      0.79   1696684
          weighted avg       1.00      1.00      0.99   1696684

2019-12-23 14:51:50,955 [INFO] Overall accuracy (micro avg): 0.9951269653040873
2019-12-23 14:52:29,635 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0004                   0.0049  0.9951
1     Macro avg        0.9992         0.9815                       0.7731                0.0012                   0.2269  0.7940
2  Weighted avg        0.9960         0.9952                       0.9951                0.0091                   0.0049  0.9947
2019-12-23 14:52:29,686 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep2/semi_sup_perf_ids17_ann_rep2_results.xlsx
2019-12-23 14:52:29,690 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 14:52:29,755 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids17_ann_rep3
2019-12-23 14:52:29,755 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids17_ann_rep3/run_log.log
2019-12-23 14:52:29,755 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 14:52:29,756 [INFO] Experiment parameters given below
2019-12-23 14:52:29,756 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids17_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'semi_sup_perf_ids17_ann_rep3'}
2019-12-23 14:52:29,756 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids17_ann_rep3/tf_logs_run_2019_12_23-14_52_29
2019-12-23 14:52:29,756 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 14:52:29,756 [INFO] Reading X, y files
2019-12-23 14:52:29,756 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 14:52:33,784 [INFO] Reading complete. time_to_read=4.03 seconds
2019-12-23 14:52:33,784 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 14:52:35,161 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 14:52:35,164 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 14:52:36,539 [INFO] Reading complete. time_to_read=1.38 seconds
2019-12-23 14:52:36,540 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 14:52:36,736 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-23 14:52:36,736 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 14:52:36,804 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:52:36,804 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 14:52:36,871 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:52:40,030 [INFO] Initializing model
2019-12-23 14:52:40,134 [INFO] _________________________________________________________________
2019-12-23 14:52:40,134 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 14:52:40,134 [INFO] =================================================================
2019-12-23 14:52:40,134 [INFO] dense_11 (Dense)             (None, 64)                5056      
2019-12-23 14:52:40,134 [INFO] _________________________________________________________________
2019-12-23 14:52:40,135 [INFO] batch_normalization_6 (Batch (None, 64)                256       
2019-12-23 14:52:40,135 [INFO] _________________________________________________________________
2019-12-23 14:52:40,135 [INFO] dropout_6 (Dropout)          (None, 64)                0         
2019-12-23 14:52:40,135 [INFO] _________________________________________________________________
2019-12-23 14:52:40,135 [INFO] dense_12 (Dense)             (None, 12)                780       
2019-12-23 14:52:40,135 [INFO] =================================================================
2019-12-23 14:52:40,135 [INFO] Total params: 6,092
2019-12-23 14:52:40,135 [INFO] Trainable params: 5,964
2019-12-23 14:52:40,135 [INFO] Non-trainable params: 128
2019-12-23 14:52:40,135 [INFO] _________________________________________________________________
2019-12-23 14:52:40,135 [INFO] Training model
2019-12-23 14:52:40,135 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2019-12-23 14:52:57,068 [INFO] Split sizes (instances). total = 1696684, set1 = 848342, set2 = 848342, set1 dataset hash = b75e78959164c90d19a336ef2d2a5a10f094d2bb
 - val_f1: 0.9922
Epoch 00133: early stopping
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0254 - val_loss: 0.0141
 - val_f1: 0.9625
Epoch 2/300
 - 8s - loss: 0.0118 - val_loss: 0.0103
 - val_f1: 0.9727
Epoch 3/300
 - 8s - loss: 0.0099 - val_loss: 0.0078
 - val_f1: 0.9802
Epoch 4/300
 - 8s - loss: 0.0077 - val_loss: 0.0056
 - val_f1: 0.9900
Epoch 5/300
 - 8s - loss: 0.0067 - val_loss: 0.0068
 - val_f1: 0.9859
Epoch 6/300
 - 8s - loss: 0.0061 - val_loss: 0.0085
 - val_f1: 0.9822
Epoch 7/300
 - 8s - loss: 0.0058 - val_loss: 0.0040
 - val_f1: 0.9907
Epoch 8/300
 - 8s - loss: 0.0055 - val_loss: 0.0045
 - val_f1: 0.9927
Epoch 9/300
 - 8s - loss: 0.0053 - val_loss: 0.0061
 - val_f1: 0.9886
Epoch 10/300
 - 8s - loss: 0.0055 - val_loss: 0.0051
 - val_f1: 0.9920
Epoch 11/300
 - 8s - loss: 0.0051 - val_loss: 0.0082
 - val_f1: 0.9723
Epoch 12/300
 - 8s - loss: 0.0051 - val_loss: 0.0054
 - val_f1: 0.9868
Epoch 13/300
 - 8s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 14/300
 - 8s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9939
Epoch 15/300
 - 8s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 16/300
 - 8s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 17/300
 - 8s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9904
Epoch 18/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 19/300
 - 8s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9904
Epoch 20/300
 - 8s - loss: 0.0044 - val_loss: 0.0071
 - val_f1: 0.9797
Epoch 21/300
 - 8s - loss: 0.0044 - val_loss: 0.0060
 - val_f1: 0.9857
Epoch 22/300
 - 8s - loss: 0.0043 - val_loss: 0.0073
 - val_f1: 0.9883
Epoch 23/300
 - 8s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9904
Epoch 24/300
 - 8s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9899
Epoch 25/300
 - 8s - loss: 0.0042 - val_loss: 0.0046
 - val_f1: 0.9903
Epoch 26/300
 - 8s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9946
Epoch 27/300
 - 8s - loss: 0.0041 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 28/300
 - 8s - loss: 0.0041 - val_loss: 0.0051
 - val_f1: 0.9882
Epoch 29/300
 - 8s - loss: 0.0041 - val_loss: 0.0057
 - val_f1: 0.9868
Epoch 30/300
 - 8s - loss: 0.0041 - val_loss: 0.0061
 - val_f1: 0.9877
Epoch 31/300
 - 8s - loss: 0.0041 - val_loss: 0.0033
2019-12-23 15:00:38,761 [INFO] epoch = 30. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9913
Epoch 32/300
 - 8s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 33/300
 - 8s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9911
Epoch 34/300
 - 8s - loss: 0.0040 - val_loss: 0.0071
 - val_f1: 0.9881
Epoch 35/300
 - 8s - loss: 0.0040 - val_loss: 0.0045
 - val_f1: 0.9927
Epoch 36/300
 - 8s - loss: 0.0040 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 37/300
 - 8s - loss: 0.0039 - val_loss: 0.0036
 - val_f1: 0.9944
Epoch 38/300
 - 8s - loss: 0.0039 - val_loss: 0.0039
 - val_f1: 0.9925
Epoch 39/300
 - 9s - loss: 0.0039 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 40/300
 - 9s - loss: 0.0039 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 41/300
 - 8s - loss: 0.0038 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 42/300
 - 9s - loss: 0.0039 - val_loss: 0.0045
 - val_f1: 0.9926
Epoch 43/300
 - 8s - loss: 0.0038 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 44/300
 - 8s - loss: 0.0038 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 45/300
 - 8s - loss: 0.0038 - val_loss: 0.0052
 - val_f1: 0.9880
Epoch 46/300
 - 8s - loss: 0.0038 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 47/300
 - 8s - loss: 0.0038 - val_loss: 0.0052
 - val_f1: 0.9881
Epoch 48/300
 - 8s - loss: 0.0037 - val_loss: 0.0038
 - val_f1: 0.9929
Epoch 49/300
 - 9s - loss: 0.0038 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 50/300
 - 9s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 51/300
 - 9s - loss: 0.0038 - val_loss: 0.0048
 - val_f1: 0.9876
Epoch 52/300
 - 9s - loss: 0.0037 - val_loss: 0.0054
 - val_f1: 0.9884
Epoch 53/300
 - 8s - loss: 0.0037 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 54/300
 - 9s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 55/300
 - 8s - loss: 0.0037 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 56/300
 - 8s - loss: 0.0037 - val_loss: 0.0076
 - val_f1: 0.9821
Epoch 57/300
 - 8s - loss: 0.0037 - val_loss: 0.0056
 - val_f1: 0.9857
Epoch 58/300
 - 9s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 59/300
 - 8s - loss: 0.0037 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 60/300
 - 9s - loss: 0.0036 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 61/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
2019-12-23 15:08:10,546 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9927
Epoch 62/300
 - 9s - loss: 0.0036 - val_loss: 0.0061
 - val_f1: 0.9811
Epoch 63/300
 - 8s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 64/300
 - 9s - loss: 0.0036 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 65/300
 - 8s - loss: 0.0036 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 66/300
 - 9s - loss: 0.0036 - val_loss: 0.0044
 - val_f1: 0.9921
Epoch 67/300
 - 8s - loss: 0.0036 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 68/300
 - 9s - loss: 0.0035 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 69/300
 - 8s - loss: 0.0035 - val_loss: 0.0046
 - val_f1: 0.9920
Epoch 70/300
 - 8s - loss: 0.0035 - val_loss: 0.0064
 - val_f1: 0.9910
Epoch 71/300
 - 8s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 72/300
 - 8s - loss: 0.0035 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 73/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 74/300
 - 8s - loss: 0.0035 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 75/300
 - 8s - loss: 0.0035 - val_loss: 0.0053
 - val_f1: 0.9892
Epoch 76/300
 - 9s - loss: 0.0034 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 77/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9927
Epoch 78/300
 - 9s - loss: 0.0034 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 79/300
 - 8s - loss: 0.0035 - val_loss: 0.0032
 - val_f1: 0.9952
Epoch 80/300
 - 9s - loss: 0.0035 - val_loss: 0.0028
 - val_f1: 0.9948
Epoch 81/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 82/300
 - 8s - loss: 0.0033 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 83/300
 - 8s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 84/300
 - 9s - loss: 0.0034 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 85/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9918
Epoch 86/300
 - 9s - loss: 0.0034 - val_loss: 0.0038
 - val_f1: 0.9936
Epoch 87/300
 - 9s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9952
Epoch 88/300
 - 8s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 89/300
 - 8s - loss: 0.0033 - val_loss: 0.0044
 - val_f1: 0.9912
Epoch 90/300
 - 9s - loss: 0.0034 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 91/300
 - 8s - loss: 0.0033 - val_loss: 0.0029
2019-12-23 15:15:43,789 [INFO] epoch = 90. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9929
Epoch 92/300
 - 9s - loss: 0.0033 - val_loss: 0.0081
 - val_f1: 0.9863
Epoch 93/300
 - 8s - loss: 0.0033 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 94/300
 - 9s - loss: 0.0033 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 95/300
 - 8s - loss: 0.0033 - val_loss: 0.0027
 - val_f1: 0.9954
Epoch 96/300
 - 9s - loss: 0.0034 - val_loss: 0.0028
 - val_f1: 0.9953
Epoch 97/300
 - 8s - loss: 0.0033 - val_loss: 0.0050
 - val_f1: 0.9904
Epoch 98/300
 - 9s - loss: 0.0033 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 99/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 100/300
 - 9s - loss: 0.0033 - val_loss: 0.0041
 - val_f1: 0.9915
Epoch 101/300
 - 8s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9953
Epoch 102/300
 - 8s - loss: 0.0033 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 103/300
 - 9s - loss: 0.0032 - val_loss: 0.0026
 - val_f1: 0.9952
Epoch 104/300
 - 8s - loss: 0.0033 - val_loss: 0.0026
 - val_f1: 0.9954
Epoch 105/300
 - 8s - loss: 0.0033 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 106/300
 - 9s - loss: 0.0033 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 107/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 108/300
 - 9s - loss: 0.0033 - val_loss: 0.0028
 - val_f1: 0.9929
Epoch 109/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 110/300
 - 9s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9910
Epoch 111/300
 - 8s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9933
Epoch 112/300
 - 9s - loss: 0.0032 - val_loss: 0.0054
 - val_f1: 0.9890
Epoch 113/300
 - 8s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 114/300
 - 9s - loss: 0.0032 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 115/300
 - 9s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9954
Epoch 116/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 117/300
 - 9s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 118/300
 - 8s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 119/300
 - 9s - loss: 0.0032 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 120/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 121/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
2019-12-23 15:23:17,267 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9942
Epoch 122/300
 - 9s - loss: 0.0032 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 123/300
 - 9s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9951
Epoch 124/300
 - 9s - loss: 0.0032 - val_loss: 0.0033
 - val_f1: 0.9929
Epoch 125/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9935
Epoch 126/300
 - 8s - loss: 0.0032 - val_loss: 0.0029
 - val_f1: 0.9930
Epoch 127/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 128/300
 - 9s - loss: 0.0033 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 129/300
 - 9s - loss: 0.0032 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 130/300
 - 9s - loss: 0.0032 - val_loss: 0.0046
 - val_f1: 0.9912
Epoch 131/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9931
Epoch 132/300
 - 8s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 133/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 134/300
 - 9s - loss: 0.0032 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 135/300
 - 8s - loss: 0.0032 - val_loss: 0.0039
 - val_f1: 0.9927
Epoch 136/300
 - 9s - loss: 0.0032 - val_loss: 0.0032
 - val_f1: 0.9928
Epoch 137/300
 - 8s - loss: 0.0032 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 138/300
 - 9s - loss: 0.0031 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 139/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 140/300
 - 9s - loss: 0.0032 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 141/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 142/300
 - 9s - loss: 0.0031 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 143/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 144/300
 - 9s - loss: 0.0031 - val_loss: 0.0027
 - val_f1: 0.9957
Epoch 145/300
 - 8s - loss: 0.0032 - val_loss: 0.0027
 - val_f1: 0.9944
Epoch 146/300
 - 8s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 147/300
 - 9s - loss: 0.0032 - val_loss: 0.0038
 - val_f1: 0.9937
Epoch 148/300
 - 8s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 149/300
 - 9s - loss: 0.0032 - val_loss: 0.0028
 - val_f1: 0.9943
Epoch 150/300
 - 8s - loss: 0.0032 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 151/300
 - 9s - loss: 0.0032 - val_loss: 0.0031
2019-12-23 15:30:51,134 [INFO] epoch = 150. Intermediate model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9938
Epoch 152/300
 - 9s - loss: 0.0032 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 153/300
 - 9s - loss: 0.0032 - val_loss: 0.0029
2019-12-23 15:31:28,212 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 15:31:46,956 [INFO] Last epoch loss evaluation: train_loss = 0.002526, val_loss = 0.002607
2019-12-23 15:31:46,988 [INFO] Training complete. time_to_train = 2346.85 sec, 39.11 min
2019-12-23 15:31:46,991 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids17_ann_rep3/best_model.pickle
2019-12-23 15:31:47,172 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/training_error_history.png
2019-12-23 15:31:47,452 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/training_f1_history.png
2019-12-23 15:31:47,452 [INFO] Making predictions on training, validation, testing data
2019-12-23 15:32:19,154 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 15:32:29,317 [INFO] Dataset: Testing. Classification report below
2019-12-23 15:32:29,317 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.38      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.99      0.93      1100
         DoS slowloris       0.98      0.95      0.96      1159
           FTP-Patator       1.00      0.99      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1179
Web Attack Brute Force       1.00      0.10      0.19       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.90      0.78      0.79    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-23 15:32:29,317 [INFO] Overall accuracy (micro avg): 0.9951358118119675
/home/sunanda/test/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 15:32:40,877 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0004                   0.0049  0.9951
1     Macro avg        0.9992         0.8952                       0.7775                0.0011                   0.2225  0.7946
2  Weighted avg        0.9960         0.9950                       0.9951                0.0085                   0.0049  0.9947
2019-12-23 15:32:51,236 [INFO] Dataset: Validation. Classification report below
2019-12-23 15:32:51,236 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.35      0.51       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2059
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.88      0.98      0.93      1099
         DoS slowloris       0.98      0.94      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.96      0.96      1180
Web Attack Brute Force       0.95      0.07      0.13       301
        Web Attack XSS       1.00      0.03      0.06       131

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.98      0.77      0.79    565562
          weighted avg       1.00      1.00      0.99    565562

2019-12-23 15:32:51,236 [INFO] Overall accuracy (micro avg): 0.9952224512962328
2019-12-23 15:33:02,985 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9952         0.9952                       0.9952                0.0004                   0.0048  0.9952
1     Macro avg        0.9992         0.9752                       0.7731                0.0011                   0.2269  0.7914
2  Weighted avg        0.9961         0.9953                       0.9952                0.0083                   0.0048  0.9948
2019-12-23 15:33:37,158 [INFO] Dataset: Training. Classification report below
2019-12-23 15:33:37,158 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.37      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.98      0.98      6176
              DoS Hulk       0.98      0.99      0.98    138074
      DoS Slowhttptest       0.89      0.98      0.93      3300
         DoS slowloris       0.98      0.95      0.97      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.97      0.97      3538
Web Attack Brute Force       0.99      0.09      0.16       904
        Web Attack XSS       1.00      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.98      0.78      0.80   1696684
          weighted avg       1.00      1.00      0.99   1696684

2019-12-23 15:33:37,158 [INFO] Overall accuracy (micro avg): 0.9953049595564053
2019-12-23 15:34:15,944 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9953         0.9953                       0.9953                0.0004                   0.0047  0.9953
1     Macro avg        0.9992         0.9800                       0.7784                0.0011                   0.2216  0.7980
2  Weighted avg        0.9961         0.9953                       0.9953                0.0083                   0.0047  0.9949
2019-12-23 15:34:15,995 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids17_ann_rep3/semi_sup_perf_ids17_ann_rep3_results.xlsx
2019-12-23 15:34:15,999 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 15:34:16,065 [INFO] ================= Finished running 6 experiments ================= 

 - val_f1: 0.9950
Epoch 00153: early stopping
Using TensorFlow backend.
2020-01-11 12:29:59,187 [INFO] Read 3 experiments from file: experiment_specs/additional_exps/semi_sup_perf_ann.csv
2020-01-11 12:29:59,187 [INFO] ================= Started running experiments ================= 

2020-01-11 12:29:59,188 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1
2020-01-11 12:29:59,188 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/run_log.log
2020-01-11 12:29:59,188 [INFO] ================= Running experiment no. 1  ================= 

2020-01-11 12:29:59,188 [INFO] Experiment parameters given below
2020-01-11 12:29:59,188 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep1'}
2020-01-11 12:29:59,188 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/tf_logs_run_2020_01_11-12_29_59
2020-01-11 12:29:59,188 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 12:29:59,189 [INFO] Reading X, y files
2020-01-11 12:29:59,189 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 12:30:03,522 [INFO] Reading complete. time_to_read=4.33 seconds
2020-01-11 12:30:03,522 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 12:30:05,006 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-11 12:30:05,006 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 12:30:06,491 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-11 12:30:06,491 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 12:30:06,760 [INFO] Reading complete. time_to_read=0.27 seconds
2020-01-11 12:30:06,760 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 12:30:06,836 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 12:30:06,836 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 12:30:06,914 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 12:30:10,541 [INFO] Initializing model
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2020-01-11 12:30:10,555 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-11 12:30:10,618 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2020-01-11 12:30:10,656 [INFO] _________________________________________________________________
2020-01-11 12:30:10,656 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 12:30:10,656 [INFO] =================================================================
2020-01-11 12:30:10,656 [INFO] dense_1 (Dense)              (None, 64)                4992      
2020-01-11 12:30:10,656 [INFO] _________________________________________________________________
2020-01-11 12:30:10,656 [INFO] batch_normalization_1 (Batch (None, 64)                256       
2020-01-11 12:30:10,656 [INFO] _________________________________________________________________
2020-01-11 12:30:10,656 [INFO] dropout_1 (Dropout)          (None, 64)                0         
2020-01-11 12:30:10,656 [INFO] _________________________________________________________________
2020-01-11 12:30:10,656 [INFO] dense_2 (Dense)              (None, 15)                975       
2020-01-11 12:30:10,656 [INFO] =================================================================
2020-01-11 12:30:10,656 [INFO] Total params: 6,223
2020-01-11 12:30:10,656 [INFO] Trainable params: 6,095
2020-01-11 12:30:10,656 [INFO] Non-trainable params: 128
2020-01-11 12:30:10,656 [INFO] _________________________________________________________________
2020-01-11 12:30:10,657 [INFO] Training model
2020-01-11 12:30:10,657 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-11 12:30:31,677 [INFO] Split sizes (instances). total = 1936462, set1 = 968231, set2 = 968231, set1 dataset hash = 29de1dd377723229ed7420efecc6b6eb2708be48
WARNING:tensorflow:From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-11 12:30:32,065 [WARNING] From /home/sunanda/test/ml_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2020-01-11 12:30:32.338663: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-11 12:30:32.360706: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299620000 Hz
2020-01-11 12:30:32.361018: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x59175c0 executing computations on platform Host. Devices:
2020-01-11 12:30:32.361041: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 10s - loss: 0.0198 - val_loss: 0.0090
 - val_f1: 0.9766
Epoch 2/200
 - 10s - loss: 0.0093 - val_loss: 0.0087
 - val_f1: 0.9770
Epoch 3/200
 - 10s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9750
Epoch 4/200
 - 10s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9776
Epoch 5/200
 - 10s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9775
Epoch 6/200
 - 10s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9781
Epoch 7/200
 - 10s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9778
Epoch 8/200
 - 10s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 9/200
 - 10s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 10/200
 - 10s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 11/200
 - 10s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9754
Epoch 12/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 13/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 14/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 15/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 16/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 17/200
 - 10s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 18/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 19/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 20/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 21/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 12:35:56,922 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_20.pickle
 - val_f1: 0.9779
Epoch 22/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 23/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 24/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 25/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 26/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 27/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 28/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 29/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 30/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 31/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 32/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 33/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 34/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 35/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 36/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 37/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 38/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 39/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 40/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 41/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 12:41:11,376 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_40.pickle
 - val_f1: 0.9785
Epoch 42/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 43/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 44/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 45/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 46/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 47/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 48/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 49/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 50/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 51/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 52/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 53/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 54/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 55/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 56/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 57/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 58/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 59/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 60/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 61/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 12:46:26,598 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9781
Epoch 62/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9761
Epoch 63/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 64/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 65/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 66/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 67/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 68/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 69/200
 - 10s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9783
Epoch 70/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 71/200
 - 10s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9766
Epoch 72/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 73/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 74/200
 - 10s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9781
Epoch 75/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9785
Epoch 76/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 77/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 78/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 79/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 80/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 81/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
2020-01-11 12:51:41,589 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_80.pickle
 - val_f1: 0.9782
Epoch 82/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9755
Epoch 83/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 84/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 85/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 86/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 87/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 88/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 89/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 90/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 91/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 92/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 93/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 94/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 95/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 96/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 97/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 98/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 99/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 100/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 101/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 12:56:56,273 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_100.pickle
 - val_f1: 0.9780
Epoch 102/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 103/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 104/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 105/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 106/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 107/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 108/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 109/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 110/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 111/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 112/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 113/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 114/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 115/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 116/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 117/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9782
Epoch 118/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 119/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9766
Epoch 120/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 121/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
2020-01-11 13:02:10,939 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9780
Epoch 122/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 123/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 124/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 125/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 126/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 127/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 128/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 129/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 130/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 131/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 132/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 133/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 134/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 135/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 136/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 137/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 138/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 139/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 140/200
 - 10s - loss: 0.0079 - val_loss: 0.0082
 - val_f1: 0.9785
Epoch 141/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
2020-01-11 13:07:25,615 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_140.pickle
 - val_f1: 0.9784
Epoch 142/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 143/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 144/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 145/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 146/200
 - 10s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 147/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 148/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 149/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 150/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 151/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 152/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9788
Epoch 153/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9784
Epoch 154/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 155/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 156/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9788
Epoch 157/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 158/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 159/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 160/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9787
Epoch 161/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
2020-01-11 13:12:40,447 [INFO] epoch = 160. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_160.pickle
 - val_f1: 0.9780
Epoch 162/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 163/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 164/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 165/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 166/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 167/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 168/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 169/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 170/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 171/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 172/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 173/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 174/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 175/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 176/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 177/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9787
Epoch 178/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 179/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 180/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 181/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
2020-01-11 13:17:55,874 [INFO] epoch = 180. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9779
Epoch 182/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 183/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 184/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 185/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 186/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 187/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 188/200
 - 10s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9784
Epoch 189/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 190/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 191/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 192/200
 - 10s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 193/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 194/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 195/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 196/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 197/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9788
Epoch 198/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 199/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 200/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
2020-01-11 13:23:01,306 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 13:23:18,594 [INFO] Last epoch loss evaluation: train_loss = 0.007795, val_loss = 0.007827
2020-01-11 13:23:18,636 [INFO] Training complete. time_to_train = 3187.98 sec, 53.13 min
2020-01-11 13:23:18,638 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/best_model.pickle
2020-01-11 13:23:18,641 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_error_history.csv
2020-01-11 13:23:18,836 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_error_history.png
2020-01-11 13:23:19,079 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/training_f1_history.png
2020-01-11 13:23:19,079 [INFO] Making predictions on training, validation, testing data
2020-01-11 13:23:44,431 [INFO] Evaluating predictions (results)
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 13:23:56,543 [INFO] Dataset: Testing. Classification report below
2020-01-11 13:23:56,543 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.77      0.69      0.72        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.47      0.57      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.43      0.02      0.03      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.84      0.72      0.75    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 13:23:56,543 [INFO] Overall accuracy (micro avg): 0.9831615769774187
/home/sunanda/test/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-11 13:24:10,201 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8367                       0.7229                0.0044                   0.2771  0.7478
2  Weighted avg        0.9909         0.9779                       0.9832                0.0497                   0.0168  0.9782
2020-01-11 13:24:22,294 [INFO] Dataset: Validation. Classification report below
2020-01-11 13:24:22,294 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.81      0.68      0.74        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.47      0.57      5596
   DoS attacks-Slowloris       0.95      0.98      0.97       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.48      0.02      0.03      6403
           SQL Injection       1.00      0.25      0.40         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.84      0.73      0.75    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 13:24:22,294 [INFO] Overall accuracy (micro avg): 0.983254503963674
2020-01-11 13:24:35,985 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.8426                       0.7284                0.0044                   0.2716  0.7509
2  Weighted avg        0.9910         0.9784                       0.9833                0.0496                   0.0167  0.9783
2020-01-11 13:25:15,258 [INFO] Dataset: Training. Classification report below
2020-01-11 13:25:15,258 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.82      0.71      0.77       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       1.00      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.47      0.57     16787
   DoS attacks-Slowloris       0.97      0.99      0.98      1318
          FTP-BruteForce       0.69      0.87      0.77     23153
           Infilteration       0.47      0.02      0.04     19210
           SQL Injection       1.00      0.33      0.50        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.84      0.73      0.75   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 13:25:15,258 [INFO] Overall accuracy (micro avg): 0.9832333399777532
2020-01-11 13:25:59,868 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8440                       0.7261                0.0044                   0.2739  0.7515
2  Weighted avg        0.9910         0.9784                       0.9832                0.0494                   0.0168  0.9783
2020-01-11 13:25:59,926 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep1/semi_sup_perf_ids18_subset_ann_rep1_results.xlsx
2020-01-11 13:25:59,934 [INFO] ================= Finished running experiment no. 1 ================= 

2020-01-11 13:26:00,009 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2
2020-01-11 13:26:00,009 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/run_log.log
2020-01-11 13:26:00,009 [INFO] ================= Running experiment no. 2  ================= 

2020-01-11 13:26:00,009 [INFO] Experiment parameters given below
2020-01-11 13:26:00,009 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep2'}
2020-01-11 13:26:00,009 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/tf_logs_run_2020_01_11-13_26_00
2020-01-11 13:26:00,009 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 13:26:00,010 [INFO] Reading X, y files
2020-01-11 13:26:00,010 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 13:26:04,321 [INFO] Reading complete. time_to_read=4.31 seconds
2020-01-11 13:26:04,321 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 13:26:05,807 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-11 13:26:05,807 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 13:26:07,294 [INFO] Reading complete. time_to_read=1.49 seconds
2020-01-11 13:26:07,295 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 13:26:07,548 [INFO] Reading complete. time_to_read=0.25 seconds
2020-01-11 13:26:07,548 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 13:26:07,625 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 13:26:07,625 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 13:26:07,703 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 13:26:11,352 [INFO] Initializing model
2020-01-11 13:26:11,456 [INFO] _________________________________________________________________
2020-01-11 13:26:11,457 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 13:26:11,457 [INFO] =================================================================
2020-01-11 13:26:11,457 [INFO] dense_3 (Dense)              (None, 64)                4992      
2020-01-11 13:26:11,457 [INFO] _________________________________________________________________
2020-01-11 13:26:11,457 [INFO] batch_normalization_2 (Batch (None, 64)                256       
2020-01-11 13:26:11,457 [INFO] _________________________________________________________________
2020-01-11 13:26:11,457 [INFO] dropout_2 (Dropout)          (None, 64)                0         
2020-01-11 13:26:11,457 [INFO] _________________________________________________________________
2020-01-11 13:26:11,457 [INFO] dense_4 (Dense)              (None, 15)                975       
2020-01-11 13:26:11,457 [INFO] =================================================================
2020-01-11 13:26:11,457 [INFO] Total params: 6,223
2020-01-11 13:26:11,457 [INFO] Trainable params: 6,095
2020-01-11 13:26:11,457 [INFO] Non-trainable params: 128
2020-01-11 13:26:11,457 [INFO] _________________________________________________________________
2020-01-11 13:26:11,457 [INFO] Training model
2020-01-11 13:26:11,457 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-11 13:26:32,505 [INFO] Split sizes (instances). total = 1936462, set1 = 968231, set2 = 968231, set1 dataset hash = df2add71ad9b72cb5233a111509b2b74ff33670a
 - val_f1: 0.9787
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 10s - loss: 0.0199 - val_loss: 0.0090
 - val_f1: 0.9759
Epoch 2/200
 - 10s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9771
Epoch 3/200
 - 10s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 4/200
 - 10s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 5/200
 - 10s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9775
Epoch 6/200
 - 10s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9781
Epoch 7/200
 - 10s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 8/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 9/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 10/200
 - 10s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9776
Epoch 11/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 12/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 13/200
 - 10s - loss: 0.0083 - val_loss: 0.0090
 - val_f1: 0.9769
Epoch 14/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 15/200
 - 10s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 16/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9762
Epoch 17/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 18/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 19/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 20/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 21/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 13:32:00,200 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_20.pickle
 - val_f1: 0.9777
Epoch 22/200
 - 10s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 23/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 24/200
 - 10s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 25/200
 - 10s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 26/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9756
Epoch 27/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9780
Epoch 28/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 29/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 30/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 31/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 32/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 33/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 34/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 35/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 36/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9776
Epoch 37/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 38/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 39/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 40/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9754
Epoch 41/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
2020-01-11 13:37:17,106 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_40.pickle
 - val_f1: 0.9783
Epoch 42/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 43/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 44/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 45/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 46/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 47/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 48/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 49/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 50/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 51/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 52/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 53/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 54/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 55/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 56/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9777
Epoch 57/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 58/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 59/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 60/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 61/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 13:42:34,677 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9780
Epoch 62/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 63/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 64/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 65/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 66/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 67/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 68/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 69/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 70/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 71/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 72/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 73/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9767
Epoch 74/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 75/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 76/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 77/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 78/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 79/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 80/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 81/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 13:47:50,941 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_80.pickle
 - val_f1: 0.9784
Epoch 82/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 83/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 84/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 85/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 86/200
 - 10s - loss: 0.0080 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 87/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 88/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 89/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9763
Epoch 90/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9757
Epoch 91/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 92/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 93/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9785
Epoch 94/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 95/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 96/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 97/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 98/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 99/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 100/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 101/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 13:53:07,533 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_100.pickle
 - val_f1: 0.9782
Epoch 102/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 103/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 104/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 105/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 106/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 107/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 108/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 109/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 110/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9765
Epoch 111/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 112/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 113/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 114/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 115/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9785
Epoch 116/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 117/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 118/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 119/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 120/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 121/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
2020-01-11 13:58:24,047 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9785
Epoch 122/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 123/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 124/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 125/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 126/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 127/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 128/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 129/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 130/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 131/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 132/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 133/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 134/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 135/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 136/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 137/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 138/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 139/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 140/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 141/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
2020-01-11 14:03:40,489 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/ann_model_epoch_140.pickle
 - val_f1: 0.9782
Epoch 142/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 143/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 144/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 145/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 146/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 147/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 148/200
 - 10s - loss: 0.0079 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 149/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 150/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 151/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 152/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 153/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 154/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 155/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 156/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 157/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
2020-01-11 14:07:59,811 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 14:08:18,088 [INFO] Last epoch loss evaluation: train_loss = 0.007824, val_loss = 0.007856
2020-01-11 14:08:18,127 [INFO] Training complete. time_to_train = 2526.67 sec, 42.11 min
2020-01-11 14:08:18,130 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/best_model.pickle
2020-01-11 14:08:18,132 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_error_history.csv
2020-01-11 14:08:18,318 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_error_history.png
2020-01-11 14:08:18,501 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/training_f1_history.png
2020-01-11 14:08:18,502 [INFO] Making predictions on training, validation, testing data
2020-01-11 14:08:45,883 [INFO] Evaluating predictions (results)
2020-01-11 14:08:57,903 [INFO] Dataset: Testing. Classification report below
2020-01-11 14:08:57,903 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.12      0.22        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.33      0.46        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.49      0.59      5596
   DoS attacks-Slowloris       0.96      0.98      0.97       440
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.33      0.00      0.00      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.90      0.71      0.74    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 14:08:57,903 [INFO] Overall accuracy (micro avg): 0.9835349379074436
2020-01-11 14:09:11,561 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.8982                       0.7085                0.0044                   0.2915  0.7448
2  Weighted avg        0.9911         0.9772                       0.9835                0.0498                   0.0165  0.9783
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 14:09:23,623 [INFO] Dataset: Validation. Classification report below
2020-01-11 14:09:23,623 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.80      0.16      0.27        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      0.34      0.46        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.75      0.48      0.59      5596
   DoS attacks-Slowloris       0.95      0.99      0.97       439
          FTP-BruteForce       0.70      0.89      0.78      7718
           Infilteration       0.14      0.00      0.00      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.80      0.70      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 14:09:23,623 [INFO] Overall accuracy (micro avg): 0.9835380108352298
/home/sunanda/test/ids_experiments/utility.py:328: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/sunanda/test/ids_experiments/utility.py:332: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2020-01-11 14:09:37,296 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.8009                       0.7007                0.0044                   0.2993  0.7227
2  Weighted avg        0.9910         0.9753                       0.9835                0.0497                   0.0165  0.9783
2020-01-11 14:10:16,880 [INFO] Dataset: Training. Classification report below
2020-01-11 14:10:16,880 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.69      0.12      0.21        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.35      0.48       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.75      0.48      0.59     16787
   DoS attacks-Slowloris       0.96      0.99      0.98      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.43      0.00      0.00     19210
           SQL Injection       1.00      0.25      0.40        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.88      0.71      0.74   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 14:10:16,880 [INFO] Overall accuracy (micro avg): 0.9835003217207464
2020-01-11 14:11:01,786 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9835         0.9835                       0.9835                0.0012                   0.0165  0.9835
1     Macro avg        0.9978         0.8834                       0.7050                0.0044                   0.2950  0.7387
2  Weighted avg        0.9910         0.9782                       0.9835                0.0498                   0.0165  0.9782
2020-01-11 14:11:01,844 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep2/semi_sup_perf_ids18_subset_ann_rep2_results.xlsx
2020-01-11 14:11:01,849 [INFO] ================= Finished running experiment no. 2 ================= 

2020-01-11 14:11:01,931 [INFO] Created directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3
2020-01-11 14:11:01,931 [INFO] Initialized logging. log_filename = results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/run_log.log
2020-01-11 14:11:01,931 [INFO] ================= Running experiment no. 3  ================= 

2020-01-11 14:11:01,931 [INFO] Experiment parameters given below
2020-01-11 14:11:01,931 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3', 'model_type': 'classifier', 'model': 'ann', 'normal_label': 'BENIGN', 'training_data_feed': 'preload', 'split_random_seed': 42, 'dataset_split_ratio': 0.5, 'ann_layer_units': [64], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'epochs': 200, 'early_stop_patience': 50, 'batch_size': 256, 'training_set': 'train_set_only', 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'semi_sup_perf_ids18_subset_ann_rep3'}
2020-01-11 14:11:01,931 [INFO] Created tensorboard log directory: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/tf_logs_run_2020_01_11-14_11_01
2020-01-11 14:11:01,931 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2020-01-11 14:11:01,931 [INFO] Reading X, y files
2020-01-11 14:11:01,931 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2020-01-11 14:11:06,353 [INFO] Reading complete. time_to_read=4.42 seconds
2020-01-11 14:11:06,353 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2020-01-11 14:11:07,836 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-11 14:11:07,836 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2020-01-11 14:11:09,320 [INFO] Reading complete. time_to_read=1.48 seconds
2020-01-11 14:11:09,320 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2020-01-11 14:11:09,548 [INFO] Reading complete. time_to_read=0.23 seconds
2020-01-11 14:11:09,548 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2020-01-11 14:11:09,626 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 14:11:09,626 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2020-01-11 14:11:09,704 [INFO] Reading complete. time_to_read=0.08 seconds
2020-01-11 14:11:13,372 [INFO] Initializing model
2020-01-11 14:11:13,477 [INFO] _________________________________________________________________
2020-01-11 14:11:13,478 [INFO] Layer (type)                 Output Shape              Param #   
2020-01-11 14:11:13,478 [INFO] =================================================================
2020-01-11 14:11:13,478 [INFO] dense_5 (Dense)              (None, 64)                4992      
2020-01-11 14:11:13,478 [INFO] _________________________________________________________________
2020-01-11 14:11:13,478 [INFO] batch_normalization_3 (Batch (None, 64)                256       
2020-01-11 14:11:13,478 [INFO] _________________________________________________________________
2020-01-11 14:11:13,478 [INFO] dropout_3 (Dropout)          (None, 64)                0         
2020-01-11 14:11:13,478 [INFO] _________________________________________________________________
2020-01-11 14:11:13,478 [INFO] dense_6 (Dense)              (None, 15)                975       
2020-01-11 14:11:13,478 [INFO] =================================================================
2020-01-11 14:11:13,478 [INFO] Total params: 6,223
2020-01-11 14:11:13,478 [INFO] Trainable params: 6,095
2020-01-11 14:11:13,478 [INFO] Non-trainable params: 128
2020-01-11 14:11:13,478 [INFO] _________________________________________________________________
2020-01-11 14:11:13,478 [INFO] Training model
2020-01-11 14:11:13,478 [INFO] Splitting train set into 2 sets (set1, set2), random_seed = 42
2020-01-11 14:11:35,106 [INFO] Split sizes (instances). total = 1936462, set1 = 968231, set2 = 968231, set1 dataset hash = df2add71ad9b72cb5233a111509b2b74ff33670a
 - val_f1: 0.9781
Epoch 00157: early stopping
Train on 968231 samples, validate on 645487 samples
Epoch 1/200
 - 11s - loss: 0.0203 - val_loss: 0.0090
 - val_f1: 0.9766
Epoch 2/200
 - 10s - loss: 0.0092 - val_loss: 0.0088
 - val_f1: 0.9770
Epoch 3/200
 - 10s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9776
Epoch 4/200
 - 10s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9760
Epoch 5/200
 - 10s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 6/200
 - 10s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 7/200
 - 10s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 8/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 9/200
 - 10s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 10/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9776
Epoch 11/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 12/200
 - 10s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 13/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 14/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 15/200
 - 10s - loss: 0.0082 - val_loss: 0.0083
 - val_f1: 0.9776
Epoch 16/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 17/200
 - 10s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9779
Epoch 18/200
 - 10s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9778
Epoch 19/200
 - 10s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 20/200
 - 10s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 21/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
/home/sunanda/test/ml_env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2020-01-11 14:17:15,678 [INFO] epoch = 20. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_20.pickle
 - val_f1: 0.9776
Epoch 22/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 23/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 24/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 25/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 26/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 27/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 28/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 29/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 30/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 31/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 32/200
 - 10s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9777
Epoch 33/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 34/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 35/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 36/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 37/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 38/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 39/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 40/200
 - 10s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 41/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
2020-01-11 14:22:41,111 [INFO] epoch = 40. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_40.pickle
 - val_f1: 0.9777
Epoch 42/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 43/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 44/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9782
Epoch 45/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 46/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 47/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 48/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 49/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 50/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 51/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9783
Epoch 52/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 53/200
 - 10s - loss: 0.0081 - val_loss: 0.0081
 - val_f1: 0.9779
Epoch 54/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 55/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 56/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9777
Epoch 57/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 58/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 59/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 60/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 61/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 14:28:05,921 [INFO] epoch = 60. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9779
Epoch 62/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 63/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 64/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 65/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 66/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 67/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 68/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 69/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 70/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 71/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9777
Epoch 72/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 73/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9778
Epoch 74/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 75/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 76/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 77/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 78/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9786
Epoch 79/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 80/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 81/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
2020-01-11 14:33:31,909 [INFO] epoch = 80. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_80.pickle
 - val_f1: 0.9776
Epoch 82/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 83/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 84/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 85/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 86/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9780
Epoch 87/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9781
Epoch 88/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 89/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 90/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 91/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 92/200
 - 10s - loss: 0.0080 - val_loss: 0.0081
 - val_f1: 0.9763
Epoch 93/200
 - 10s - loss: 0.0081 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 94/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9783
Epoch 95/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9786
Epoch 96/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 97/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 98/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9761
Epoch 99/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9784
Epoch 100/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 101/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
2020-01-11 14:38:56,852 [INFO] epoch = 100. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_100.pickle
 - val_f1: 0.9777
Epoch 102/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 103/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9784
Epoch 104/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 105/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 106/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 107/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 108/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 109/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 110/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 111/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 112/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 113/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9786
Epoch 114/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9779
Epoch 115/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 116/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 117/200
 - 10s - loss: 0.0080 - val_loss: 0.0080
 - val_f1: 0.9778
Epoch 118/200
 - 10s - loss: 0.0080 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 119/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9765
Epoch 120/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 121/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
2020-01-11 14:44:22,122 [INFO] epoch = 120. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9782
Epoch 122/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 123/200
 - 10s - loss: 0.0080 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 124/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 125/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 126/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9779
Epoch 127/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 128/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 129/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9782
Epoch 130/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9781
Epoch 131/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 132/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9778
Epoch 133/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 134/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9767
Epoch 135/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9781
Epoch 136/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 137/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9781
Epoch 138/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9780
Epoch 139/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9783
Epoch 140/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9780
Epoch 141/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
2020-01-11 14:49:47,542 [INFO] epoch = 140. Intermediate model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/ann_model_epoch_140.pickle
 - val_f1: 0.9778
Epoch 142/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9782
Epoch 143/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9773
Epoch 144/200
 - 10s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9780
Epoch 145/200
 - 10s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9779
Epoch 146/200
 - 10s - loss: 0.0079 - val_loss: 0.0079
2020-01-11 14:51:15,266 [INFO] WeightRestorer::on_train_end(): restoring best weights
2020-01-11 14:51:34,250 [INFO] Last epoch loss evaluation: train_loss = 0.007779, val_loss = 0.007823
2020-01-11 14:51:34,292 [INFO] Training complete. time_to_train = 2420.81 sec, 40.35 min
2020-01-11 14:51:34,295 [INFO] Model saved to results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/best_model.pickle
2020-01-11 14:51:34,297 [INFO] Training history saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_error_history.csv
2020-01-11 14:51:34,478 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_error_history.png
2020-01-11 14:51:34,654 [INFO] Plot saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/training_f1_history.png
2020-01-11 14:51:34,654 [INFO] Making predictions on training, validation, testing data
2020-01-11 14:52:03,016 [INFO] Evaluating predictions (results)
2020-01-11 14:52:15,036 [INFO] Dataset: Testing. Classification report below
2020-01-11 14:52:15,036 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.67      0.08      0.15        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.73      0.97      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.47      0.57      5596
   DoS attacks-Slowloris       0.93      0.97      0.95       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.42      0.01      0.02      6404
           SQL Injection       1.00      0.50      0.67         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.88      0.75      0.76    645488
            weighted avg       0.98      0.98      0.98    645488

2020-01-11 14:52:15,036 [INFO] Overall accuracy (micro avg): 0.9831073544357137
2020-01-11 14:52:28,694 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9831         0.9831                       0.9831                0.0012                   0.0169  0.9831
1     Macro avg        0.9977         0.8758                       0.7462                0.0045                   0.2538  0.7624
2  Weighted avg        0.9909         0.9777                       0.9831                0.0501                   0.0169  0.9780
2020-01-11 14:52:40,734 [INFO] Dataset: Validation. Classification report below
2020-01-11 14:52:40,734 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       1.00      0.08      0.15        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.74      0.97      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       1.00      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.57      5596
   DoS attacks-Slowloris       0.92      0.97      0.95       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.48      0.01      0.02      6403
           SQL Injection       0.50      0.25      0.33         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.87      0.75      0.76    645487
            weighted avg       0.98      0.98      0.98    645487

2020-01-11 14:52:40,734 [INFO] Overall accuracy (micro avg): 0.9831631001089101
2020-01-11 14:52:54,382 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8688                       0.7517                0.0044                   0.2483  0.7604
2  Weighted avg        0.9909         0.9783                       0.9832                0.0499                   0.0168  0.9781
2020-01-11 14:53:33,651 [INFO] Dataset: Training. Classification report below
2020-01-11 14:53:33,651 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       1.00      0.14      0.24        73
        Brute Force -XSS       0.93      0.50      0.65        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.97      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.46      0.56     16787
   DoS attacks-Slowloris       0.94      0.99      0.97      1318
          FTP-BruteForce       0.69      0.87      0.77     23153
           Infilteration       0.48      0.01      0.02     19210
           SQL Injection       0.80      0.33      0.47        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.89      0.75      0.77   1936462
            weighted avg       0.98      0.98      0.98   1936462

2020-01-11 14:53:33,651 [INFO] Overall accuracy (micro avg): 0.9831755025401996
2020-01-11 14:54:18,215 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.8856                       0.7512                0.0044                   0.2488  0.7672
2  Weighted avg        0.9910         0.9784                       0.9832                0.0498                   0.0168  0.9781
2020-01-11 14:54:18,273 [INFO] Results saved to: results_additional_exps/semi_sup_perf_ids18_subset_ann_rep3/semi_sup_perf_ids18_subset_ann_rep3_results.xlsx
2020-01-11 14:54:18,280 [INFO] ================= Finished running experiment no. 3 ================= 

2020-01-11 14:54:18,357 [INFO] ================= Finished running 3 experiments ================= 

 - val_f1: 0.9781
Epoch 00146: early stopping
