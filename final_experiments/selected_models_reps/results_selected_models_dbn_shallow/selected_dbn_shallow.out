Using TensorFlow backend.
2019-12-23 12:14:43,290 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_shallow_rep1/run_log.log
2019-12-23 12:14:43,290 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 12:14:43,290 [INFO] Experiment parameters given below
2019-12-23 12:14:43,290 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_nsl_dbn_shallow_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_shallow_rep1'}
2019-12-23 12:14:43,290 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_shallow_rep1/tf_logs_run_2019_12_23-12_14_43
2019-12-23 12:14:43,290 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 12:14:43,291 [INFO] Reading X, y files
2019-12-23 12:14:43,291 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 12:14:43,562 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-23 12:14:43,562 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 12:14:43,629 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 12:14:43,629 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 12:14:43,690 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:14:43,690 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 12:14:43,697 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 12:14:43,697 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 12:14:43,701 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:14:43,701 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 12:14:43,705 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:14:43,912 [INFO] Initializing model
2019-12-23 12:14:43,912 [INFO] Training model
2019-12-23 12:14:43,912 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:14:44,686 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 4ee7a306c1cbf095853550a63c9f029986b84bf3
2019-12-23 12:14:44,686 [INFO] Pretraining Deep Belief Network
2019-12-23 12:15:11,239 [INFO] Pretraining Complete
2019-12-23 12:15:11,239 [INFO] Getting pretrained weights
2019-12-23 12:15:11,239 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:15:11,239 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

2019-12-23 12:15:11,267 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

2019-12-23 12:15:11,268 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

2019-12-23 12:15:11,326 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

2019-12-23 12:15:11,341 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-23 12:15:11,359 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2019-12-23 12:15:11,372 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.

2019-12-23 12:15:11,375 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
2019-12-23 12:15:11,384 [INFO] _________________________________________________________________
2019-12-23 12:15:11,384 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:15:11,384 [INFO] =================================================================
2019-12-23 12:15:11,384 [INFO] dense_1 (Dense)              (None, 32)                3936      
2019-12-23 12:15:11,384 [INFO] _________________________________________________________________
2019-12-23 12:15:11,385 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2019-12-23 12:15:11,385 [INFO] _________________________________________________________________
2019-12-23 12:15:11,385 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2019-12-23 12:15:11,385 [INFO] _________________________________________________________________
2019-12-23 12:15:11,385 [INFO] dense_2 (Dense)              (None, 5)                 165       
2019-12-23 12:15:11,385 [INFO] =================================================================
2019-12-23 12:15:11,385 [INFO] Total params: 4,229
2019-12-23 12:15:11,385 [INFO] Trainable params: 4,165
2019-12-23 12:15:11,385 [INFO] Non-trainable params: 64
2019-12-23 12:15:11,385 [INFO] _________________________________________________________________
2019-12-23 12:15:11.385853: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-12-23 12:15:11.552992: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2893425000 Hz
2019-12-23 12:15:11.553416: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564a7439abb0 executing computations on platform Host. Devices:
2019-12-23 12:15:11.553450: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-23 12:15:11.611099: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2019-12-23 12:15:11,625 [INFO] Fine-tuning final neural network
2019-12-23 12:15:14,135 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

2019-12-23 12:15:14,135 [WARNING] From /home/hasitha/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

[BernoulliRBM] Iteration 1, pseudo-likelihood = -79.88, time = 0.37s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -76.48, time = 0.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -73.75, time = 0.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.50, time = 0.54s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -69.60, time = 0.54s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.96, time = 0.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -66.55, time = 0.54s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -65.31, time = 0.54s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -64.21, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -63.23, time = 0.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -62.35, time = 0.54s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -61.56, time = 0.53s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -60.85, time = 0.53s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.20, time = 0.53s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -59.61, time = 0.53s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -59.08, time = 0.53s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -58.59, time = 0.54s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -58.14, time = 0.53s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -57.74, time = 0.53s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.37, time = 0.54s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.03, time = 0.53s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -56.72, time = 0.53s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -56.44, time = 0.54s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.18, time = 0.53s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -55.95, time = 0.53s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -55.74, time = 0.53s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -55.55, time = 0.53s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -55.38, time = 0.53s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -55.23, time = 0.53s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -55.09, time = 0.53s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -54.97, time = 0.53s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -54.86, time = 0.53s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -54.77, time = 0.53s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -54.69, time = 0.53s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -54.62, time = 0.53s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -54.56, time = 0.52s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -54.52, time = 0.53s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -54.48, time = 0.52s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -54.46, time = 0.52s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -54.44, time = 0.53s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -54.43, time = 0.52s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -54.43, time = 0.52s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -54.45, time = 0.52s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -54.47, time = 0.52s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -54.50, time = 0.52s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -54.54, time = 0.52s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -54.60, time = 0.52s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -54.66, time = 0.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -54.74, time = 0.52s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -54.83, time = 0.51s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.2028 - val_loss: 0.0618
 - val_f1: 0.9596
Epoch 2/300
 - 0s - loss: 0.0492 - val_loss: 0.0321
 - val_f1: 0.9781
Epoch 3/300
 - 0s - loss: 0.0295 - val_loss: 0.0200
 - val_f1: 0.9854
Epoch 4/300
 - 0s - loss: 0.0238 - val_loss: 0.0165
 - val_f1: 0.9888
Epoch 5/300
 - 0s - loss: 0.0208 - val_loss: 0.0148
 - val_f1: 0.9898
Epoch 6/300
 - 0s - loss: 0.0186 - val_loss: 0.0135
 - val_f1: 0.9897
Epoch 7/300
 - 0s - loss: 0.0173 - val_loss: 0.0127
 - val_f1: 0.9914
Epoch 8/300
 - 0s - loss: 0.0167 - val_loss: 0.0118
 - val_f1: 0.9906
Epoch 9/300
 - 0s - loss: 0.0155 - val_loss: 0.0118
 - val_f1: 0.9919
Epoch 10/300
 - 0s - loss: 0.0153 - val_loss: 0.0117
 - val_f1: 0.9916
Epoch 11/300
 - 0s - loss: 0.0143 - val_loss: 0.0116
 - val_f1: 0.9907
Epoch 12/300
 - 0s - loss: 0.0136 - val_loss: 0.0108
 - val_f1: 0.9919
Epoch 13/300
 - 0s - loss: 0.0136 - val_loss: 0.0109
 - val_f1: 0.9911
Epoch 14/300
 - 0s - loss: 0.0128 - val_loss: 0.0099
 - val_f1: 0.9924
Epoch 15/300
 - 0s - loss: 0.0122 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 16/300
 - 0s - loss: 0.0118 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 17/300
 - 0s - loss: 0.0117 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 18/300
 - 0s - loss: 0.0117 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 19/300
 - 0s - loss: 0.0113 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 20/300
 - 0s - loss: 0.0110 - val_loss: 0.0096
 - val_f1: 0.9934
Epoch 21/300
 - 0s - loss: 0.0104 - val_loss: 0.0093
 - val_f1: 0.9930
Epoch 22/300
 - 0s - loss: 0.0106 - val_loss: 0.0098
 - val_f1: 0.9927
Epoch 23/300
 - 0s - loss: 0.0104 - val_loss: 0.0092
 - val_f1: 0.9937
Epoch 24/300
 - 0s - loss: 0.0106 - val_loss: 0.0091
 - val_f1: 0.9937
Epoch 25/300
 - 0s - loss: 0.0102 - val_loss: 0.0097
 - val_f1: 0.9931
Epoch 26/300
 - 0s - loss: 0.0100 - val_loss: 0.0095
 - val_f1: 0.9934
Epoch 27/300
 - 0s - loss: 0.0098 - val_loss: 0.0093
 - val_f1: 0.9943
Epoch 28/300
 - 0s - loss: 0.0097 - val_loss: 0.0090
 - val_f1: 0.9944
Epoch 29/300
 - 0s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9939
Epoch 30/300
 - 0s - loss: 0.0093 - val_loss: 0.0088
 - val_f1: 0.9944
Epoch 31/300
 - 0s - loss: 0.0092 - val_loss: 0.0087
2019-12-23 12:15:37,516 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9943
Epoch 32/300
 - 0s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9944
Epoch 33/300
 - 0s - loss: 0.0092 - val_loss: 0.0090
 - val_f1: 0.9938
Epoch 34/300
 - 0s - loss: 0.0090 - val_loss: 0.0088
 - val_f1: 0.9943
Epoch 35/300
 - 0s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9944
Epoch 36/300
 - 0s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9943
Epoch 37/300
 - 0s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 38/300
 - 0s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9943
Epoch 39/300
 - 0s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9945
Epoch 40/300
 - 0s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9952
Epoch 41/300
 - 0s - loss: 0.0081 - val_loss: 0.0082
 - val_f1: 0.9944
Epoch 42/300
 - 0s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9948
Epoch 43/300
 - 0s - loss: 0.0081 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 44/300
 - 0s - loss: 0.0078 - val_loss: 0.0080
 - val_f1: 0.9947
Epoch 45/300
 - 0s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9943
Epoch 46/300
 - 0s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9949
Epoch 47/300
 - 0s - loss: 0.0076 - val_loss: 0.0081
 - val_f1: 0.9945
Epoch 48/300
 - 0s - loss: 0.0079 - val_loss: 0.0079
 - val_f1: 0.9947
Epoch 49/300
 - 0s - loss: 0.0080 - val_loss: 0.0086
 - val_f1: 0.9943
Epoch 50/300
 - 0s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9949
Epoch 51/300
 - 0s - loss: 0.0077 - val_loss: 0.0082
 - val_f1: 0.9946
Epoch 52/300
 - 0s - loss: 0.0074 - val_loss: 0.0081
 - val_f1: 0.9946
Epoch 53/300
 - 0s - loss: 0.0072 - val_loss: 0.0080
 - val_f1: 0.9953
Epoch 54/300
 - 0s - loss: 0.0074 - val_loss: 0.0085
 - val_f1: 0.9944
Epoch 55/300
 - 0s - loss: 0.0076 - val_loss: 0.0085
 - val_f1: 0.9946
Epoch 56/300
 - 0s - loss: 0.0076 - val_loss: 0.0083
 - val_f1: 0.9949
Epoch 57/300
 - 0s - loss: 0.0074 - val_loss: 0.0086
 - val_f1: 0.9950
Epoch 58/300
 - 0s - loss: 0.0074 - val_loss: 0.0083
 - val_f1: 0.9951
Epoch 59/300
 - 0s - loss: 0.0072 - val_loss: 0.0082
 - val_f1: 0.9949
Epoch 60/300
 - 0s - loss: 0.0074 - val_loss: 0.0082
 - val_f1: 0.9950
Epoch 61/300
 - 0s - loss: 0.0070 - val_loss: 0.0080
2019-12-23 12:16:00,680 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9950
Epoch 62/300
 - 0s - loss: 0.0073 - val_loss: 0.0081
 - val_f1: 0.9949
Epoch 63/300
 - 0s - loss: 0.0071 - val_loss: 0.0084
 - val_f1: 0.9942
Epoch 64/300
 - 0s - loss: 0.0073 - val_loss: 0.0078
 - val_f1: 0.9951
Epoch 65/300
 - 0s - loss: 0.0073 - val_loss: 0.0077
 - val_f1: 0.9948
Epoch 66/300
 - 0s - loss: 0.0070 - val_loss: 0.0083
 - val_f1: 0.9946
Epoch 67/300
 - 0s - loss: 0.0071 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 68/300
 - 0s - loss: 0.0068 - val_loss: 0.0083
 - val_f1: 0.9946
Epoch 69/300
 - 0s - loss: 0.0070 - val_loss: 0.0084
 - val_f1: 0.9953
Epoch 70/300
 - 0s - loss: 0.0071 - val_loss: 0.0085
 - val_f1: 0.9950
Epoch 71/300
 - 0s - loss: 0.0069 - val_loss: 0.0079
 - val_f1: 0.9950
Epoch 72/300
 - 0s - loss: 0.0068 - val_loss: 0.0081
 - val_f1: 0.9951
Epoch 73/300
 - 0s - loss: 0.0067 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 74/300
 - 0s - loss: 0.0063 - val_loss: 0.0082
 - val_f1: 0.9951
Epoch 75/300
 - 0s - loss: 0.0068 - val_loss: 0.0081
 - val_f1: 0.9951
Epoch 76/300
 - 0s - loss: 0.0066 - val_loss: 0.0084
 - val_f1: 0.9945
Epoch 77/300
 - 0s - loss: 0.0070 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 78/300
 - 0s - loss: 0.0066 - val_loss: 0.0081
 - val_f1: 0.9953
Epoch 79/300
 - 0s - loss: 0.0070 - val_loss: 0.0083
 - val_f1: 0.9952
Epoch 80/300
 - 0s - loss: 0.0070 - val_loss: 0.0084
 - val_f1: 0.9940
Epoch 81/300
 - 0s - loss: 0.0063 - val_loss: 0.0081
 - val_f1: 0.9949
Epoch 82/300
 - 0s - loss: 0.0065 - val_loss: 0.0080
 - val_f1: 0.9947
Epoch 83/300
 - 0s - loss: 0.0064 - val_loss: 0.0080
 - val_f1: 0.9951
Epoch 84/300
 - 0s - loss: 0.0063 - val_loss: 0.0085
 - val_f1: 0.9951
Epoch 85/300
 - 0s - loss: 0.0066 - val_loss: 0.0080
 - val_f1: 0.9950
Epoch 86/300
 - 0s - loss: 0.0065 - val_loss: 0.0080
 - val_f1: 0.9951
Epoch 87/300
 - 0s - loss: 0.0065 - val_loss: 0.0087
 - val_f1: 0.9949
Epoch 88/300
 - 0s - loss: 0.0065 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 89/300
 - 0s - loss: 0.0065 - val_loss: 0.0078
 - val_f1: 0.9952
Epoch 90/300
 - 0s - loss: 0.0065 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 91/300
 - 0s - loss: 0.0062 - val_loss: 0.0081
2019-12-23 12:16:24,130 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9953
Epoch 92/300
 - 0s - loss: 0.0066 - val_loss: 0.0085
 - val_f1: 0.9943
Epoch 93/300
 - 0s - loss: 0.0065 - val_loss: 0.0077
 - val_f1: 0.9955
Epoch 94/300
 - 0s - loss: 0.0064 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 95/300
 - 0s - loss: 0.0063 - val_loss: 0.0081
 - val_f1: 0.9956
Epoch 96/300
 - 0s - loss: 0.0062 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 97/300
 - 0s - loss: 0.0062 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 98/300
 - 0s - loss: 0.0064 - val_loss: 0.0084
 - val_f1: 0.9948
Epoch 99/300
 - 0s - loss: 0.0060 - val_loss: 0.0082
 - val_f1: 0.9944
Epoch 100/300
 - 0s - loss: 0.0061 - val_loss: 0.0093
 - val_f1: 0.9951
Epoch 101/300
 - 0s - loss: 0.0064 - val_loss: 0.0081
 - val_f1: 0.9950
Epoch 102/300
 - 0s - loss: 0.0065 - val_loss: 0.0077
 - val_f1: 0.9951
Epoch 103/300
 - 0s - loss: 0.0060 - val_loss: 0.0080
 - val_f1: 0.9951
Epoch 104/300
 - 0s - loss: 0.0063 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 105/300
 - 0s - loss: 0.0061 - val_loss: 0.0080
 - val_f1: 0.9954
Epoch 106/300
 - 0s - loss: 0.0059 - val_loss: 0.0083
 - val_f1: 0.9952
Epoch 107/300
 - 0s - loss: 0.0059 - val_loss: 0.0078
 - val_f1: 0.9953
Epoch 108/300
 - 0s - loss: 0.0061 - val_loss: 0.0078
 - val_f1: 0.9953
Epoch 109/300
 - 0s - loss: 0.0058 - val_loss: 0.0079
 - val_f1: 0.9950
Epoch 110/300
 - 0s - loss: 0.0060 - val_loss: 0.0076
 - val_f1: 0.9956
Epoch 111/300
 - 0s - loss: 0.0059 - val_loss: 0.0075
 - val_f1: 0.9953
Epoch 112/300
 - 0s - loss: 0.0059 - val_loss: 0.0077
 - val_f1: 0.9952
Epoch 113/300
 - 0s - loss: 0.0060 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 114/300
 - 0s - loss: 0.0061 - val_loss: 0.0080
 - val_f1: 0.9950
Epoch 115/300
 - 0s - loss: 0.0063 - val_loss: 0.0076
 - val_f1: 0.9953
Epoch 116/300
 - 0s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9956
Epoch 117/300
 - 0s - loss: 0.0060 - val_loss: 0.0076
 - val_f1: 0.9953
Epoch 118/300
 - 0s - loss: 0.0060 - val_loss: 0.0075
 - val_f1: 0.9953
Epoch 119/300
 - 0s - loss: 0.0059 - val_loss: 0.0077
 - val_f1: 0.9951
Epoch 120/300
 - 0s - loss: 0.0060 - val_loss: 0.0076
 - val_f1: 0.9953
Epoch 121/300
 - 0s - loss: 0.0059 - val_loss: 0.0078
2019-12-23 12:16:47,282 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9954
Epoch 122/300
 - 0s - loss: 0.0060 - val_loss: 0.0082
 - val_f1: 0.9946
Epoch 123/300
 - 0s - loss: 0.0056 - val_loss: 0.0076
 - val_f1: 0.9952
Epoch 124/300
 - 0s - loss: 0.0058 - val_loss: 0.0078
 - val_f1: 0.9954
Epoch 125/300
 - 0s - loss: 0.0059 - val_loss: 0.0077
 - val_f1: 0.9953
Epoch 126/300
 - 0s - loss: 0.0057 - val_loss: 0.0078
 - val_f1: 0.9952
Epoch 127/300
 - 0s - loss: 0.0058 - val_loss: 0.0076
 - val_f1: 0.9954
Epoch 128/300
 - 0s - loss: 0.0059 - val_loss: 0.0080
 - val_f1: 0.9955
Epoch 129/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9954
Epoch 130/300
 - 0s - loss: 0.0060 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 131/300
 - 0s - loss: 0.0058 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 132/300
 - 0s - loss: 0.0057 - val_loss: 0.0085
 - val_f1: 0.9955
Epoch 133/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 134/300
 - 0s - loss: 0.0059 - val_loss: 0.0081
 - val_f1: 0.9953
Epoch 135/300
 - 0s - loss: 0.0059 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 136/300
 - 0s - loss: 0.0055 - val_loss: 0.0079
 - val_f1: 0.9955
Epoch 137/300
 - 0s - loss: 0.0056 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 138/300
 - 0s - loss: 0.0058 - val_loss: 0.0077
 - val_f1: 0.9957
Epoch 139/300
 - 0s - loss: 0.0057 - val_loss: 0.0077
 - val_f1: 0.9957
Epoch 140/300
 - 0s - loss: 0.0056 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 141/300
 - 0s - loss: 0.0059 - val_loss: 0.0078
 - val_f1: 0.9956
Epoch 142/300
 - 0s - loss: 0.0058 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 143/300
 - 0s - loss: 0.0059 - val_loss: 0.0079
 - val_f1: 0.9952
Epoch 144/300
 - 0s - loss: 0.0055 - val_loss: 0.0078
 - val_f1: 0.9957
Epoch 145/300
 - 0s - loss: 0.0056 - val_loss: 0.0080
 - val_f1: 0.9950
Epoch 146/300
 - 0s - loss: 0.0058 - val_loss: 0.0077
 - val_f1: 0.9957
Epoch 147/300
 - 0s - loss: 0.0057 - val_loss: 0.0079
 - val_f1: 0.9955
Epoch 148/300
 - 0s - loss: 0.0057 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 149/300
 - 0s - loss: 0.0057 - val_loss: 0.0077
 - val_f1: 0.9956
Epoch 150/300
 - 0s - loss: 0.0052 - val_loss: 0.0088
 - val_f1: 0.9932
Epoch 151/300
 - 0s - loss: 0.0056 - val_loss: 0.0075
2019-12-23 12:17:10,401 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9958
Epoch 152/300
 - 0s - loss: 0.0058 - val_loss: 0.0081
 - val_f1: 0.9954
Epoch 153/300
 - 0s - loss: 0.0058 - val_loss: 0.0079
 - val_f1: 0.9956
Epoch 154/300
 - 0s - loss: 0.0055 - val_loss: 0.0083
 - val_f1: 0.9954
Epoch 155/300
 - 0s - loss: 0.0057 - val_loss: 0.0077
 - val_f1: 0.9957
Epoch 156/300
 - 0s - loss: 0.0056 - val_loss: 0.0076
 - val_f1: 0.9957
Epoch 157/300
 - 0s - loss: 0.0056 - val_loss: 0.0078
 - val_f1: 0.9957
Epoch 158/300
 - 0s - loss: 0.0055 - val_loss: 0.0081
 - val_f1: 0.9956
Epoch 159/300
 - 0s - loss: 0.0052 - val_loss: 0.0081
 - val_f1: 0.9956
Epoch 160/300
 - 0s - loss: 0.0052 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 161/300
 - 0s - loss: 0.0054 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 162/300
 - 0s - loss: 0.0056 - val_loss: 0.0075
 - val_f1: 0.9958
Epoch 163/300
 - 0s - loss: 0.0054 - val_loss: 0.0076
 - val_f1: 0.9956
Epoch 164/300
 - 0s - loss: 0.0053 - val_loss: 0.0074
 - val_f1: 0.9957
Epoch 165/300
 - 0s - loss: 0.0053 - val_loss: 0.0074
 - val_f1: 0.9956
Epoch 166/300
 - 0s - loss: 0.0053 - val_loss: 0.0075
 - val_f1: 0.9956
Epoch 167/300
 - 0s - loss: 0.0055 - val_loss: 0.0074
 - val_f1: 0.9959
Epoch 168/300
 - 0s - loss: 0.0057 - val_loss: 0.0077
 - val_f1: 0.9958
Epoch 169/300
 - 0s - loss: 0.0056 - val_loss: 0.0076
 - val_f1: 0.9957
Epoch 170/300
 - 0s - loss: 0.0056 - val_loss: 0.0075
 - val_f1: 0.9959
Epoch 171/300
 - 0s - loss: 0.0049 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 172/300
 - 0s - loss: 0.0054 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 173/300
 - 0s - loss: 0.0052 - val_loss: 0.0073
 - val_f1: 0.9960
Epoch 174/300
 - 0s - loss: 0.0053 - val_loss: 0.0074
 - val_f1: 0.9960
Epoch 175/300
 - 0s - loss: 0.0051 - val_loss: 0.0076
 - val_f1: 0.9957
Epoch 176/300
 - 0s - loss: 0.0053 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 177/300
 - 0s - loss: 0.0050 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 178/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9956
Epoch 179/300
 - 0s - loss: 0.0049 - val_loss: 0.0076
 - val_f1: 0.9959
Epoch 180/300
 - 0s - loss: 0.0055 - val_loss: 0.0075
 - val_f1: 0.9959
Epoch 181/300
 - 0s - loss: 0.0053 - val_loss: 0.0076
2019-12-23 12:17:33,539 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9956
Epoch 182/300
 - 0s - loss: 0.0051 - val_loss: 0.0076
 - val_f1: 0.9958
Epoch 183/300
 - 0s - loss: 0.0050 - val_loss: 0.0075
 - val_f1: 0.9957
Epoch 184/300
 - 0s - loss: 0.0052 - val_loss: 0.0079
 - val_f1: 0.9955
Epoch 185/300
 - 0s - loss: 0.0055 - val_loss: 0.0078
 - val_f1: 0.9958
Epoch 186/300
 - 0s - loss: 0.0054 - val_loss: 0.0078
 - val_f1: 0.9955
Epoch 187/300
 - 0s - loss: 0.0052 - val_loss: 0.0074
 - val_f1: 0.9957
Epoch 188/300
 - 0s - loss: 0.0054 - val_loss: 0.0071
 - val_f1: 0.9958
Epoch 189/300
 - 0s - loss: 0.0048 - val_loss: 0.0076
 - val_f1: 0.9956
Epoch 190/300
 - 0s - loss: 0.0048 - val_loss: 0.0074
 - val_f1: 0.9959
Epoch 191/300
 - 0s - loss: 0.0051 - val_loss: 0.0079
 - val_f1: 0.9955
Epoch 192/300
 - 0s - loss: 0.0052 - val_loss: 0.0077
 - val_f1: 0.9952
Epoch 193/300
 - 0s - loss: 0.0048 - val_loss: 0.0082
 - val_f1: 0.9952
Epoch 194/300
 - 0s - loss: 0.0053 - val_loss: 0.0079
 - val_f1: 0.9956
Epoch 195/300
 - 0s - loss: 0.0054 - val_loss: 0.0077
 - val_f1: 0.9958
Epoch 196/300
 - 0s - loss: 0.0055 - val_loss: 0.0076
 - val_f1: 0.9959
Epoch 197/300
 - 0s - loss: 0.0053 - val_loss: 0.0075
 - val_f1: 0.9958
Epoch 198/300
 - 0s - loss: 0.0050 - val_loss: 0.0075
 - val_f1: 0.9959
Epoch 199/300
 - 0s - loss: 0.0050 - val_loss: 0.0080
 - val_f1: 0.9950
Epoch 200/300
 - 0s - loss: 0.0053 - val_loss: 0.0077
 - val_f1: 0.9954
Epoch 201/300
 - 0s - loss: 0.0049 - val_loss: 0.0078
 - val_f1: 0.9960
Epoch 202/300
 - 0s - loss: 0.0051 - val_loss: 0.0076
 - val_f1: 0.9961
Epoch 203/300
 - 0s - loss: 0.0049 - val_loss: 0.0081
 - val_f1: 0.9957
Epoch 204/300
 - 0s - loss: 0.0051 - val_loss: 0.0078
 - val_f1: 0.9962
Epoch 205/300
 - 0s - loss: 0.0048 - val_loss: 0.0076
 - val_f1: 0.9961
Epoch 206/300
 - 0s - loss: 0.0050 - val_loss: 0.0082
 - val_f1: 0.9956
Epoch 207/300
 - 0s - loss: 0.0048 - val_loss: 0.0079
 - val_f1: 0.9956
Epoch 208/300
 - 0s - loss: 0.0051 - val_loss: 0.0084
 - val_f1: 0.9952
Epoch 209/300
 - 0s - loss: 0.0050 - val_loss: 0.0081
 - val_f1: 0.9958
Epoch 210/300
 - 0s - loss: 0.0049 - val_loss: 0.0079
 - val_f1: 0.9960
Epoch 211/300
 - 0s - loss: 0.0053 - val_loss: 0.0079
2019-12-23 12:17:56,534 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9958
Epoch 212/300
 - 0s - loss: 0.0049 - val_loss: 0.0079
 - val_f1: 0.9959
Epoch 213/300
 - 0s - loss: 0.0048 - val_loss: 0.0084
 - val_f1: 0.9955
Epoch 214/300
 - 0s - loss: 0.0050 - val_loss: 0.0080
 - val_f1: 0.9960
Epoch 215/300
 - 0s - loss: 0.0048 - val_loss: 0.0086
 - val_f1: 0.9953
Epoch 216/300
 - 0s - loss: 0.0049 - val_loss: 0.0083
 - val_f1: 0.9956
Epoch 217/300
 - 0s - loss: 0.0051 - val_loss: 0.0080
 - val_f1: 0.9960
Epoch 218/300
 - 0s - loss: 0.0054 - val_loss: 0.0087
 - val_f1: 0.9954
Epoch 219/300
 - 0s - loss: 0.0050 - val_loss: 0.0086
 - val_f1: 0.9958
Epoch 220/300
 - 0s - loss: 0.0054 - val_loss: 0.0087
 - val_f1: 0.9959
Epoch 221/300
 - 0s - loss: 0.0049 - val_loss: 0.0081
 - val_f1: 0.9959
Epoch 222/300
 - 0s - loss: 0.0052 - val_loss: 0.0081
 - val_f1: 0.9958
Epoch 223/300
 - 0s - loss: 0.0052 - val_loss: 0.0079
 - val_f1: 0.9962
Epoch 224/300
 - 0s - loss: 0.0050 - val_loss: 0.0079
 - val_f1: 0.9954
Epoch 225/300
 - 0s - loss: 0.0049 - val_loss: 0.0082
 - val_f1: 0.9957
Epoch 226/300
 - 0s - loss: 0.0052 - val_loss: 0.0082
 - val_f1: 0.9956
Epoch 227/300
 - 0s - loss: 0.0052 - val_loss: 0.0086
 - val_f1: 0.9958
Epoch 228/300
 - 0s - loss: 0.0049 - val_loss: 0.0085
 - val_f1: 0.9958
Epoch 229/300
 - 0s - loss: 0.0048 - val_loss: 0.0084
 - val_f1: 0.9959
Epoch 230/300
 - 0s - loss: 0.0047 - val_loss: 0.0083
 - val_f1: 0.9957
Epoch 231/300
 - 0s - loss: 0.0047 - val_loss: 0.0080
 - val_f1: 0.9961
Epoch 232/300
 - 0s - loss: 0.0049 - val_loss: 0.0082
 - val_f1: 0.9960
Epoch 233/300
 - 0s - loss: 0.0049 - val_loss: 0.0083
 - val_f1: 0.9957
Epoch 234/300
 - 0s - loss: 0.0050 - val_loss: 0.0087
 - val_f1: 0.9956
Epoch 235/300
 - 0s - loss: 0.0049 - val_loss: 0.0084
 - val_f1: 0.9955
Epoch 236/300
 - 0s - loss: 0.0047 - val_loss: 0.0088
 - val_f1: 0.9955
Epoch 237/300
 - 0s - loss: 0.0049 - val_loss: 0.0085
 - val_f1: 0.9958
Epoch 238/300
 - 0s - loss: 0.0046 - val_loss: 0.0085
2019-12-23 12:18:17,635 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:18:18,723 [INFO] Last epoch loss evaluation: train_loss = 0.003204, val_loss = 0.007091
2019-12-23 12:18:18,728 [INFO] Training complete. time_to_train = 214.82 sec, 3.58 min
2019-12-23 12:18:18,731 [INFO] Model saved to results_selected_models/selected_nsl_dbn_shallow_rep1/best_model.pickle
2019-12-23 12:18:18,941 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep1/training_error_history.png
2019-12-23 12:18:19,066 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep1/training_f1_history.png
2019-12-23 12:18:19,066 [INFO] Making predictions on training, validation, testing data
2019-12-23 12:18:20,832 [INFO] Evaluating predictions (results)
2019-12-23 12:18:21,178 [INFO] Dataset: Testing. Classification report below
2019-12-23 12:18:21,178 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.67      0.97      0.80      9711
       probe       0.84      0.61      0.70      2421
         r2l       0.96      0.10      0.18      2421
         u2r       0.79      0.03      0.05       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.85      0.51      0.53     22544
weighted avg       0.82      0.77      0.74     22544

2019-12-23 12:18:21,178 [INFO] Overall accuracy (micro avg): 0.7745741660752307
2019-12-23 12:18:21,500 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7746         0.7746                       0.7746                0.0564                   0.2254  0.7746
1     Macro avg        0.9098         0.8456                       0.5106                0.0770                   0.4894  0.5278
2  Weighted avg        0.8706         0.8220                       0.7746                0.1595                   0.2254  0.7375
2019-12-23 12:18:21,856 [INFO] Dataset: Validation. Classification report below
2019-12-23 12:18:21,856 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.94      0.88      0.91       199
         u2r       0.71      0.50      0.59        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.93      0.87      0.90     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 12:18:21,857 [INFO] Overall accuracy (micro avg): 0.9957928160349275
2019-12-23 12:18:22,233 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0011                   0.0042  0.9958
1     Macro avg        0.9983         0.9276                       0.8741                0.0014                   0.1259  0.8969
2  Weighted avg        0.9974         0.9957                       0.9958                0.0027                   0.0042  0.9957
2019-12-23 12:18:23,744 [INFO] Dataset: Training. Classification report below
2019-12-23 12:18:23,745 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.96      0.92      0.94       796
         u2r       0.73      0.57      0.64        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.94      0.90      0.91    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 12:18:23,745 [INFO] Overall accuracy (micro avg): 0.9970430054178492
2019-12-23 12:18:25,458 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9970         0.9970                       0.9970                0.0007                   0.0030  0.9970
1     Macro avg        0.9988         0.9359                       0.8953                0.0010                   0.1047  0.9136
2  Weighted avg        0.9982         0.9970                       0.9970                0.0022                   0.0030  0.9970
2019-12-23 12:18:25,479 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_shallow_rep1/selected_nsl_dbn_shallow_rep1_results.xlsx
2019-12-23 12:18:25,479 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 12:18:25,484 [INFO] Created directory: results_selected_models/selected_nsl_dbn_shallow_rep2
2019-12-23 12:18:25,484 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_shallow_rep2/run_log.log
2019-12-23 12:18:25,484 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 12:18:25,484 [INFO] Experiment parameters given below
2019-12-23 12:18:25,484 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_nsl_dbn_shallow_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_shallow_rep2'}
2019-12-23 12:18:25,485 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_shallow_rep2/tf_logs_run_2019_12_23-12_18_25
2019-12-23 12:18:25,485 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 12:18:25,485 [INFO] Reading X, y files
2019-12-23 12:18:25,485 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 12:18:25,751 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-23 12:18:25,751 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 12:18:25,819 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 12:18:25,819 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 12:18:25,880 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:18:25,880 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 12:18:25,888 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 12:18:25,888 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 12:18:25,892 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:18:25,892 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 12:18:25,896 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:18:26,099 [INFO] Initializing model
2019-12-23 12:18:26,100 [INFO] Training model
2019-12-23 12:18:26,100 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:18:26,834 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = f20fce84160552ac9d5cd804eb086f181835b1e3
2019-12-23 12:18:26,834 [INFO] Pretraining Deep Belief Network
2019-12-23 12:18:53,702 [INFO] Pretraining Complete
2019-12-23 12:18:53,702 [INFO] Getting pretrained weights
2019-12-23 12:18:53,702 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:18:53,817 [INFO] _________________________________________________________________
2019-12-23 12:18:53,817 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:18:53,817 [INFO] =================================================================
2019-12-23 12:18:53,817 [INFO] dense_3 (Dense)              (None, 32)                3936      
2019-12-23 12:18:53,817 [INFO] _________________________________________________________________
2019-12-23 12:18:53,817 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-23 12:18:53,817 [INFO] _________________________________________________________________
2019-12-23 12:18:53,817 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-23 12:18:53,817 [INFO] _________________________________________________________________
2019-12-23 12:18:53,817 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-23 12:18:53,818 [INFO] =================================================================
2019-12-23 12:18:53,818 [INFO] Total params: 4,229
2019-12-23 12:18:53,818 [INFO] Trainable params: 4,165
2019-12-23 12:18:53,818 [INFO] Non-trainable params: 64
2019-12-23 12:18:53,818 [INFO] _________________________________________________________________
2019-12-23 12:18:53,942 [INFO] Fine-tuning final neural network
 - val_f1: 0.9959
Epoch 00238: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -79.93, time = 0.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -76.56, time = 0.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -73.85, time = 0.55s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.62, time = 0.55s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -69.73, time = 0.55s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.11, time = 0.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -66.71, time = 0.54s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -65.48, time = 0.54s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -64.39, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -63.43, time = 0.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -62.56, time = 0.54s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -61.78, time = 0.54s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -61.08, time = 0.55s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.44, time = 0.54s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -59.87, time = 0.54s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -59.34, time = 0.55s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -58.87, time = 0.54s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -58.43, time = 0.54s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.03, time = 0.55s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.67, time = 0.54s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.35, time = 0.54s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -57.05, time = 0.54s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -56.78, time = 0.54s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.53, time = 0.54s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -56.31, time = 0.54s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -56.11, time = 0.54s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -55.94, time = 0.54s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -55.78, time = 0.54s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -55.64, time = 0.54s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -55.51, time = 0.54s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -55.40, time = 0.54s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -55.31, time = 0.54s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -55.23, time = 0.54s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -55.16, time = 0.53s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -55.11, time = 0.53s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -55.06, time = 0.53s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -55.03, time = 0.53s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -55.01, time = 0.53s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -55.00, time = 0.53s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -55.00, time = 0.53s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -55.01, time = 0.53s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -55.03, time = 0.53s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -55.06, time = 0.53s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -55.10, time = 0.53s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -55.15, time = 0.52s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -55.21, time = 0.52s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -55.29, time = 0.53s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -55.37, time = 0.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -55.47, time = 0.52s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -55.58, time = 0.53s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.2007 - val_loss: 0.0637
 - val_f1: 0.9572
Epoch 2/300
 - 0s - loss: 0.0523 - val_loss: 0.0346
 - val_f1: 0.9762
Epoch 3/300
 - 0s - loss: 0.0317 - val_loss: 0.0214
 - val_f1: 0.9840
Epoch 4/300
 - 0s - loss: 0.0239 - val_loss: 0.0170
 - val_f1: 0.9867
Epoch 5/300
 - 0s - loss: 0.0206 - val_loss: 0.0144
 - val_f1: 0.9892
Epoch 6/300
 - 0s - loss: 0.0180 - val_loss: 0.0135
 - val_f1: 0.9896
Epoch 7/300
 - 0s - loss: 0.0169 - val_loss: 0.0124
 - val_f1: 0.9910
Epoch 8/300
 - 0s - loss: 0.0156 - val_loss: 0.0113
 - val_f1: 0.9912
Epoch 9/300
 - 0s - loss: 0.0148 - val_loss: 0.0110
 - val_f1: 0.9920
Epoch 10/300
 - 0s - loss: 0.0143 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 11/300
 - 0s - loss: 0.0136 - val_loss: 0.0103
 - val_f1: 0.9912
Epoch 12/300
 - 0s - loss: 0.0131 - val_loss: 0.0103
 - val_f1: 0.9929
Epoch 13/300
 - 0s - loss: 0.0124 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 14/300
 - 0s - loss: 0.0118 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 15/300
 - 0s - loss: 0.0115 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 16/300
 - 0s - loss: 0.0119 - val_loss: 0.0085
 - val_f1: 0.9935
Epoch 17/300
 - 0s - loss: 0.0116 - val_loss: 0.0087
 - val_f1: 0.9939
Epoch 18/300
 - 0s - loss: 0.0108 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 19/300
 - 0s - loss: 0.0110 - val_loss: 0.0089
 - val_f1: 0.9930
Epoch 20/300
 - 0s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 21/300
 - 0s - loss: 0.0102 - val_loss: 0.0080
 - val_f1: 0.9942
Epoch 22/300
 - 0s - loss: 0.0101 - val_loss: 0.0081
 - val_f1: 0.9932
Epoch 23/300
 - 0s - loss: 0.0101 - val_loss: 0.0077
 - val_f1: 0.9951
Epoch 24/300
 - 0s - loss: 0.0096 - val_loss: 0.0081
 - val_f1: 0.9935
Epoch 25/300
 - 0s - loss: 0.0096 - val_loss: 0.0077
 - val_f1: 0.9948
Epoch 26/300
 - 0s - loss: 0.0097 - val_loss: 0.0077
 - val_f1: 0.9939
Epoch 27/300
 - 0s - loss: 0.0092 - val_loss: 0.0077
 - val_f1: 0.9945
Epoch 28/300
 - 0s - loss: 0.0092 - val_loss: 0.0075
 - val_f1: 0.9944
Epoch 29/300
 - 0s - loss: 0.0094 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 30/300
 - 0s - loss: 0.0088 - val_loss: 0.0078
 - val_f1: 0.9947
Epoch 31/300
 - 0s - loss: 0.0083 - val_loss: 0.0076
2019-12-23 12:19:18,864 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9946
Epoch 32/300
 - 0s - loss: 0.0085 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 33/300
 - 0s - loss: 0.0090 - val_loss: 0.0073
 - val_f1: 0.9944
Epoch 34/300
 - 0s - loss: 0.0089 - val_loss: 0.0076
 - val_f1: 0.9946
Epoch 35/300
 - 0s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 36/300
 - 0s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9951
Epoch 37/300
 - 0s - loss: 0.0083 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 38/300
 - 0s - loss: 0.0081 - val_loss: 0.0074
 - val_f1: 0.9947
Epoch 39/300
 - 0s - loss: 0.0084 - val_loss: 0.0074
 - val_f1: 0.9947
Epoch 40/300
 - 0s - loss: 0.0085 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 41/300
 - 0s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 42/300
 - 0s - loss: 0.0081 - val_loss: 0.0074
 - val_f1: 0.9942
Epoch 43/300
 - 0s - loss: 0.0082 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 44/300
 - 0s - loss: 0.0079 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 45/300
 - 0s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9946
Epoch 46/300
 - 0s - loss: 0.0080 - val_loss: 0.0074
 - val_f1: 0.9940
Epoch 47/300
 - 0s - loss: 0.0080 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 48/300
 - 0s - loss: 0.0076 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 49/300
 - 0s - loss: 0.0076 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 50/300
 - 0s - loss: 0.0079 - val_loss: 0.0074
 - val_f1: 0.9945
Epoch 51/300
 - 0s - loss: 0.0076 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 52/300
 - 0s - loss: 0.0078 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 53/300
 - 0s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 54/300
 - 0s - loss: 0.0075 - val_loss: 0.0072
 - val_f1: 0.9944
Epoch 55/300
 - 0s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 56/300
 - 0s - loss: 0.0075 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 57/300
 - 0s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9950
Epoch 58/300
 - 0s - loss: 0.0068 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 59/300
 - 0s - loss: 0.0070 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 60/300
 - 0s - loss: 0.0070 - val_loss: 0.0070
 - val_f1: 0.9948
Epoch 61/300
 - 0s - loss: 0.0072 - val_loss: 0.0066
2019-12-23 12:19:42,362 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9954
Epoch 62/300
 - 0s - loss: 0.0069 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 63/300
 - 0s - loss: 0.0073 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 64/300
 - 0s - loss: 0.0070 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 65/300
 - 0s - loss: 0.0068 - val_loss: 0.0075
 - val_f1: 0.9944
Epoch 66/300
 - 0s - loss: 0.0072 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 67/300
 - 0s - loss: 0.0071 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 68/300
 - 0s - loss: 0.0070 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 69/300
 - 0s - loss: 0.0068 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 70/300
 - 0s - loss: 0.0072 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 71/300
 - 0s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 72/300
 - 0s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 73/300
 - 0s - loss: 0.0065 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 74/300
 - 0s - loss: 0.0073 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 75/300
 - 0s - loss: 0.0065 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 76/300
 - 0s - loss: 0.0066 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 77/300
 - 0s - loss: 0.0065 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 78/300
 - 0s - loss: 0.0066 - val_loss: 0.0076
 - val_f1: 0.9949
Epoch 79/300
 - 0s - loss: 0.0068 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 80/300
 - 0s - loss: 0.0065 - val_loss: 0.0066
 - val_f1: 0.9955
Epoch 81/300
 - 0s - loss: 0.0068 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 82/300
 - 0s - loss: 0.0068 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 83/300
 - 0s - loss: 0.0066 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 84/300
 - 0s - loss: 0.0063 - val_loss: 0.0072
 - val_f1: 0.9952
Epoch 85/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 86/300
 - 0s - loss: 0.0065 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 87/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 88/300
 - 0s - loss: 0.0070 - val_loss: 0.0067
 - val_f1: 0.9953
Epoch 89/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 90/300
 - 0s - loss: 0.0065 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 91/300
 - 0s - loss: 0.0064 - val_loss: 0.0068
2019-12-23 12:20:05,956 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9955
Epoch 92/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 93/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 94/300
 - 0s - loss: 0.0060 - val_loss: 0.0067
 - val_f1: 0.9953
Epoch 95/300
 - 0s - loss: 0.0060 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 96/300
 - 0s - loss: 0.0063 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 97/300
 - 0s - loss: 0.0064 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 98/300
 - 0s - loss: 0.0060 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 99/300
 - 0s - loss: 0.0064 - val_loss: 0.0074
 - val_f1: 0.9953
Epoch 100/300
 - 0s - loss: 0.0064 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 101/300
 - 0s - loss: 0.0061 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 102/300
 - 0s - loss: 0.0061 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 103/300
 - 0s - loss: 0.0061 - val_loss: 0.0070
 - val_f1: 0.9947
Epoch 104/300
 - 0s - loss: 0.0065 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 105/300
 - 0s - loss: 0.0058 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 106/300
 - 0s - loss: 0.0062 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 107/300
 - 0s - loss: 0.0058 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 108/300
 - 0s - loss: 0.0059 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 109/300
 - 0s - loss: 0.0058 - val_loss: 0.0066
 - val_f1: 0.9959
Epoch 110/300
 - 0s - loss: 0.0060 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 111/300
 - 0s - loss: 0.0061 - val_loss: 0.0096
 - val_f1: 0.9939
Epoch 112/300
 - 0s - loss: 0.0057 - val_loss: 0.0076
 - val_f1: 0.9950
Epoch 113/300
 - 0s - loss: 0.0059 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 114/300
 - 0s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 115/300
 - 0s - loss: 0.0057 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 116/300
 - 0s - loss: 0.0059 - val_loss: 0.0066
2019-12-23 12:20:25,763 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:20:26,944 [INFO] Last epoch loss evaluation: train_loss = 0.004664, val_loss = 0.006325
2019-12-23 12:20:26,950 [INFO] Training complete. time_to_train = 120.85 sec, 2.01 min
2019-12-23 12:20:26,954 [INFO] Model saved to results_selected_models/selected_nsl_dbn_shallow_rep2/best_model.pickle
2019-12-23 12:20:27,099 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep2/training_error_history.png
2019-12-23 12:20:27,228 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep2/training_f1_history.png
2019-12-23 12:20:27,228 [INFO] Making predictions on training, validation, testing data
2019-12-23 12:20:29,119 [INFO] Evaluating predictions (results)
2019-12-23 12:20:29,402 [INFO] Dataset: Testing. Classification report below
2019-12-23 12:20:29,402 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.67      0.96      0.79      9711
       probe       0.82      0.69      0.75      2421
         r2l       0.84      0.04      0.08      2421
         u2r       0.63      0.02      0.04       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.79      0.51      0.51     22544
weighted avg       0.80      0.77      0.73     22544

2019-12-23 12:20:29,402 [INFO] Overall accuracy (micro avg): 0.7718683463449255
2019-12-23 12:20:29,725 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7719         0.7719                       0.7719                0.0570                   0.2281  0.7719
1     Macro avg        0.9087         0.7862                       0.5114                0.0774                   0.4886  0.5121
2  Weighted avg        0.8688         0.8030                       0.7719                0.1588                   0.2281  0.7287
2019-12-23 12:20:30,067 [INFO] Dataset: Validation. Classification report below
2019-12-23 12:20:30,067 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.97      0.86      0.91       199
         u2r       0.80      0.40      0.53        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.95      0.85      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 12:20:30,067 [INFO] Overall accuracy (micro avg): 0.9957531256201627
2019-12-23 12:20:30,444 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9958         0.9958                       0.9958                0.0011                   0.0042  0.9958
1     Macro avg        0.9983         0.9493                       0.8495                0.0014                   0.1505  0.8855
2  Weighted avg        0.9973         0.9957                       0.9958                0.0028                   0.0042  0.9957
2019-12-23 12:20:31,953 [INFO] Dataset: Training. Classification report below
2019-12-23 12:20:31,953 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.97      0.85      0.90       796
         u2r       0.90      0.45      0.60        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.97      0.86      0.90    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 12:20:31,953 [INFO] Overall accuracy (micro avg): 0.9962789497707834
2019-12-23 12:20:33,660 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9963         0.9963                       0.9963                0.0009                   0.0037  0.9963
1     Macro avg        0.9985         0.9722                       0.8576                0.0013                   0.1424  0.8990
2  Weighted avg        0.9977         0.9962                       0.9963                0.0029                   0.0037  0.9962
2019-12-23 12:20:33,680 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_shallow_rep2/selected_nsl_dbn_shallow_rep2_results.xlsx
2019-12-23 12:20:33,680 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 12:20:33,684 [INFO] Created directory: results_selected_models/selected_nsl_dbn_shallow_rep3
2019-12-23 12:20:33,685 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_shallow_rep3/run_log.log
2019-12-23 12:20:33,685 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 12:20:33,685 [INFO] Experiment parameters given below
2019-12-23 12:20:33,685 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_nsl_dbn_shallow_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_shallow_rep3'}
2019-12-23 12:20:33,685 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_shallow_rep3/tf_logs_run_2019_12_23-12_20_33
2019-12-23 12:20:33,685 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 12:20:33,686 [INFO] Reading X, y files
2019-12-23 12:20:33,686 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 12:20:33,955 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-23 12:20:33,955 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 12:20:34,018 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:20:34,018 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 12:20:34,076 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:20:34,076 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 12:20:34,084 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 12:20:34,084 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 12:20:34,088 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:20:34,088 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 12:20:34,092 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:20:34,296 [INFO] Initializing model
2019-12-23 12:20:34,296 [INFO] Training model
2019-12-23 12:20:34,296 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:20:35,040 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 0779cb0cb960d43e0d74c2b9656f8770f32820bb
2019-12-23 12:20:35,040 [INFO] Pretraining Deep Belief Network
2019-12-23 12:21:01,542 [INFO] Pretraining Complete
2019-12-23 12:21:01,542 [INFO] Getting pretrained weights
2019-12-23 12:21:01,542 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:21:01,657 [INFO] _________________________________________________________________
2019-12-23 12:21:01,657 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:21:01,657 [INFO] =================================================================
2019-12-23 12:21:01,658 [INFO] dense_5 (Dense)              (None, 32)                3936      
2019-12-23 12:21:01,658 [INFO] _________________________________________________________________
2019-12-23 12:21:01,658 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-23 12:21:01,658 [INFO] _________________________________________________________________
2019-12-23 12:21:01,658 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-23 12:21:01,658 [INFO] _________________________________________________________________
2019-12-23 12:21:01,658 [INFO] dense_6 (Dense)              (None, 5)                 165       
2019-12-23 12:21:01,658 [INFO] =================================================================
2019-12-23 12:21:01,658 [INFO] Total params: 4,229
2019-12-23 12:21:01,658 [INFO] Trainable params: 4,165
2019-12-23 12:21:01,658 [INFO] Non-trainable params: 64
2019-12-23 12:21:01,658 [INFO] _________________________________________________________________
2019-12-23 12:21:01,852 [INFO] Fine-tuning final neural network
 - val_f1: 0.9956
Epoch 00116: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -79.91, time = 0.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -76.54, time = 0.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -73.85, time = 0.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.62, time = 0.54s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -69.74, time = 0.54s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -68.14, time = 0.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -66.74, time = 0.54s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -65.52, time = 0.54s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -64.44, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -63.48, time = 0.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -62.62, time = 0.53s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -61.85, time = 0.54s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -61.15, time = 0.54s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.52, time = 0.53s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -59.95, time = 0.53s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -59.43, time = 0.54s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -58.95, time = 0.53s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -58.52, time = 0.53s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -58.13, time = 0.54s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -57.77, time = 0.53s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -57.44, time = 0.53s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -57.15, time = 0.53s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -56.88, time = 0.53s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.63, time = 0.53s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -56.41, time = 0.54s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -56.21, time = 0.53s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -56.03, time = 0.54s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -55.87, time = 0.53s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -55.73, time = 0.53s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -55.60, time = 0.54s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -55.49, time = 0.53s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -55.39, time = 0.53s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -55.31, time = 0.53s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -55.24, time = 0.53s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -55.18, time = 0.52s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -55.13, time = 0.53s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -55.09, time = 0.52s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -55.06, time = 0.52s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -55.04, time = 0.52s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -55.03, time = 0.52s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -55.03, time = 0.52s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -55.04, time = 0.52s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -55.06, time = 0.52s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -55.09, time = 0.52s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -55.14, time = 0.52s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -55.19, time = 0.52s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -55.25, time = 0.52s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -55.33, time = 0.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -55.41, time = 0.51s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -55.51, time = 0.52s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1970 - val_loss: 0.0625
 - val_f1: 0.9603
Epoch 2/300
 - 0s - loss: 0.0518 - val_loss: 0.0341
 - val_f1: 0.9758
Epoch 3/300
 - 0s - loss: 0.0319 - val_loss: 0.0236
 - val_f1: 0.9838
Epoch 4/300
 - 0s - loss: 0.0246 - val_loss: 0.0171
 - val_f1: 0.9879
Epoch 5/300
 - 0s - loss: 0.0213 - val_loss: 0.0149
 - val_f1: 0.9891
Epoch 6/300
 - 0s - loss: 0.0183 - val_loss: 0.0135
 - val_f1: 0.9904
Epoch 7/300
 - 0s - loss: 0.0171 - val_loss: 0.0130
 - val_f1: 0.9900
Epoch 8/300
 - 0s - loss: 0.0159 - val_loss: 0.0116
 - val_f1: 0.9909
Epoch 9/300
 - 0s - loss: 0.0150 - val_loss: 0.0117
 - val_f1: 0.9906
Epoch 10/300
 - 0s - loss: 0.0144 - val_loss: 0.0114
 - val_f1: 0.9922
Epoch 11/300
 - 0s - loss: 0.0137 - val_loss: 0.0103
 - val_f1: 0.9927
Epoch 12/300
 - 0s - loss: 0.0129 - val_loss: 0.0105
 - val_f1: 0.9926
Epoch 13/300
 - 0s - loss: 0.0124 - val_loss: 0.0100
 - val_f1: 0.9930
Epoch 14/300
 - 0s - loss: 0.0123 - val_loss: 0.0097
 - val_f1: 0.9933
Epoch 15/300
 - 0s - loss: 0.0118 - val_loss: 0.0098
 - val_f1: 0.9925
Epoch 16/300
 - 0s - loss: 0.0112 - val_loss: 0.0093
 - val_f1: 0.9936
Epoch 17/300
 - 0s - loss: 0.0111 - val_loss: 0.0097
 - val_f1: 0.9938
Epoch 18/300
 - 0s - loss: 0.0108 - val_loss: 0.0093
 - val_f1: 0.9934
Epoch 19/300
 - 0s - loss: 0.0105 - val_loss: 0.0089
 - val_f1: 0.9940
Epoch 20/300
 - 0s - loss: 0.0102 - val_loss: 0.0087
 - val_f1: 0.9935
Epoch 21/300
 - 0s - loss: 0.0102 - val_loss: 0.0089
 - val_f1: 0.9939
Epoch 22/300
 - 0s - loss: 0.0094 - val_loss: 0.0087
 - val_f1: 0.9937
Epoch 23/300
 - 0s - loss: 0.0101 - val_loss: 0.0090
 - val_f1: 0.9923
Epoch 24/300
 - 0s - loss: 0.0092 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 25/300
 - 0s - loss: 0.0096 - val_loss: 0.0088
 - val_f1: 0.9929
Epoch 26/300
 - 0s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9938
Epoch 27/300
 - 0s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9918
Epoch 28/300
 - 0s - loss: 0.0091 - val_loss: 0.0077
 - val_f1: 0.9938
Epoch 29/300
 - 0s - loss: 0.0087 - val_loss: 0.0079
 - val_f1: 0.9945
Epoch 30/300
 - 0s - loss: 0.0087 - val_loss: 0.0077
 - val_f1: 0.9943
Epoch 31/300
 - 0s - loss: 0.0088 - val_loss: 0.0085
2019-12-23 12:21:27,844 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9938
Epoch 32/300
 - 0s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9941
Epoch 33/300
 - 0s - loss: 0.0085 - val_loss: 0.0077
 - val_f1: 0.9947
Epoch 34/300
 - 0s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9948
Epoch 35/300
 - 0s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9945
Epoch 36/300
 - 0s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9929
Epoch 37/300
 - 0s - loss: 0.0083 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 38/300
 - 0s - loss: 0.0081 - val_loss: 0.0079
 - val_f1: 0.9943
Epoch 39/300
 - 0s - loss: 0.0079 - val_loss: 0.0077
 - val_f1: 0.9945
Epoch 40/300
 - 0s - loss: 0.0081 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 41/300
 - 0s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9942
Epoch 42/300
 - 0s - loss: 0.0076 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 43/300
 - 0s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9939
Epoch 44/300
 - 0s - loss: 0.0082 - val_loss: 0.0092
 - val_f1: 0.9924
Epoch 45/300
 - 0s - loss: 0.0080 - val_loss: 0.0071
 - val_f1: 0.9950
Epoch 46/300
 - 0s - loss: 0.0079 - val_loss: 0.0075
 - val_f1: 0.9935
Epoch 47/300
 - 0s - loss: 0.0075 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 48/300
 - 0s - loss: 0.0074 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 49/300
 - 0s - loss: 0.0077 - val_loss: 0.0069
 - val_f1: 0.9947
Epoch 50/300
 - 0s - loss: 0.0070 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 51/300
 - 0s - loss: 0.0074 - val_loss: 0.0069
 - val_f1: 0.9944
Epoch 52/300
 - 0s - loss: 0.0074 - val_loss: 0.0068
 - val_f1: 0.9948
Epoch 53/300
 - 0s - loss: 0.0076 - val_loss: 0.0078
 - val_f1: 0.9942
Epoch 54/300
 - 0s - loss: 0.0074 - val_loss: 0.0070
 - val_f1: 0.9947
Epoch 55/300
 - 0s - loss: 0.0073 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 56/300
 - 0s - loss: 0.0073 - val_loss: 0.0071
 - val_f1: 0.9946
Epoch 57/300
 - 0s - loss: 0.0072 - val_loss: 0.0069
 - val_f1: 0.9948
Epoch 58/300
 - 0s - loss: 0.0070 - val_loss: 0.0073
 - val_f1: 0.9947
Epoch 59/300
 - 0s - loss: 0.0076 - val_loss: 0.0073
 - val_f1: 0.9946
Epoch 60/300
 - 0s - loss: 0.0069 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 61/300
 - 0s - loss: 0.0070 - val_loss: 0.0070
2019-12-23 12:21:52,415 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9950
Epoch 62/300
 - 0s - loss: 0.0066 - val_loss: 0.0070
 - val_f1: 0.9947
Epoch 63/300
 - 0s - loss: 0.0070 - val_loss: 0.0064
 - val_f1: 0.9954
Epoch 64/300
 - 0s - loss: 0.0067 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 65/300
 - 0s - loss: 0.0069 - val_loss: 0.0070
 - val_f1: 0.9946
Epoch 66/300
 - 0s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9950
Epoch 67/300
 - 0s - loss: 0.0071 - val_loss: 0.0069
 - val_f1: 0.9948
Epoch 68/300
 - 0s - loss: 0.0069 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 69/300
 - 0s - loss: 0.0067 - val_loss: 0.0068
 - val_f1: 0.9950
Epoch 70/300
 - 0s - loss: 0.0066 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 71/300
 - 0s - loss: 0.0069 - val_loss: 0.0067
 - val_f1: 0.9951
Epoch 72/300
 - 0s - loss: 0.0065 - val_loss: 0.0066
 - val_f1: 0.9950
Epoch 73/300
 - 0s - loss: 0.0066 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 74/300
 - 0s - loss: 0.0070 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 75/300
 - 0s - loss: 0.0066 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 76/300
 - 0s - loss: 0.0066 - val_loss: 0.0065
 - val_f1: 0.9960
Epoch 77/300
 - 0s - loss: 0.0065 - val_loss: 0.0078
 - val_f1: 0.9949
Epoch 78/300
 - 0s - loss: 0.0063 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 79/300
 - 0s - loss: 0.0063 - val_loss: 0.0075
 - val_f1: 0.9952
Epoch 80/300
 - 0s - loss: 0.0064 - val_loss: 0.0070
 - val_f1: 0.9954
Epoch 81/300
 - 0s - loss: 0.0069 - val_loss: 0.0075
 - val_f1: 0.9945
Epoch 82/300
 - 0s - loss: 0.0068 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 83/300
 - 0s - loss: 0.0063 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 84/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 85/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 86/300
 - 0s - loss: 0.0062 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 87/300
 - 0s - loss: 0.0062 - val_loss: 0.0064
 - val_f1: 0.9957
Epoch 88/300
 - 0s - loss: 0.0061 - val_loss: 0.0063
 - val_f1: 0.9954
Epoch 89/300
 - 0s - loss: 0.0061 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 90/300
 - 0s - loss: 0.0060 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 91/300
 - 0s - loss: 0.0059 - val_loss: 0.0073
2019-12-23 12:22:16,950 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9955
Epoch 92/300
 - 0s - loss: 0.0062 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 93/300
 - 0s - loss: 0.0059 - val_loss: 0.0062
 - val_f1: 0.9960
Epoch 94/300
 - 0s - loss: 0.0062 - val_loss: 0.0064
 - val_f1: 0.9951
Epoch 95/300
 - 0s - loss: 0.0061 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 96/300
 - 0s - loss: 0.0059 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 97/300
 - 0s - loss: 0.0059 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 98/300
 - 0s - loss: 0.0063 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 99/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 100/300
 - 0s - loss: 0.0058 - val_loss: 0.0062
 - val_f1: 0.9955
Epoch 101/300
 - 0s - loss: 0.0059 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 102/300
 - 0s - loss: 0.0057 - val_loss: 0.0064
 - val_f1: 0.9955
Epoch 103/300
 - 0s - loss: 0.0058 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 104/300
 - 0s - loss: 0.0060 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 105/300
 - 0s - loss: 0.0060 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 106/300
 - 0s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9961
Epoch 107/300
 - 0s - loss: 0.0056 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 108/300
 - 0s - loss: 0.0057 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 109/300
 - 0s - loss: 0.0058 - val_loss: 0.0064
 - val_f1: 0.9956
Epoch 110/300
 - 0s - loss: 0.0058 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 111/300
 - 0s - loss: 0.0057 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 112/300
 - 0s - loss: 0.0055 - val_loss: 0.0060
 - val_f1: 0.9960
Epoch 113/300
 - 0s - loss: 0.0059 - val_loss: 0.0061
 - val_f1: 0.9960
Epoch 114/300
 - 0s - loss: 0.0057 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 115/300
 - 0s - loss: 0.0060 - val_loss: 0.0066
 - val_f1: 0.9956
Epoch 116/300
 - 0s - loss: 0.0059 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 117/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 118/300
 - 0s - loss: 0.0063 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 119/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 120/300
 - 0s - loss: 0.0057 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 121/300
 - 0s - loss: 0.0057 - val_loss: 0.0064
2019-12-23 12:22:41,565 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9961
Epoch 122/300
 - 0s - loss: 0.0052 - val_loss: 0.0063
 - val_f1: 0.9958
Epoch 123/300
 - 0s - loss: 0.0053 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 124/300
 - 0s - loss: 0.0061 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 125/300
 - 0s - loss: 0.0057 - val_loss: 0.0067
 - val_f1: 0.9952
Epoch 126/300
 - 0s - loss: 0.0058 - val_loss: 0.0065
 - val_f1: 0.9958
Epoch 127/300
 - 0s - loss: 0.0057 - val_loss: 0.0063
 - val_f1: 0.9956
Epoch 128/300
 - 0s - loss: 0.0057 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 129/300
 - 0s - loss: 0.0057 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 130/300
 - 0s - loss: 0.0053 - val_loss: 0.0064
 - val_f1: 0.9960
Epoch 131/300
 - 0s - loss: 0.0054 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 132/300
 - 0s - loss: 0.0054 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 133/300
 - 0s - loss: 0.0056 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 134/300
 - 0s - loss: 0.0054 - val_loss: 0.0064
 - val_f1: 0.9956
Epoch 135/300
 - 0s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 136/300
 - 0s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 137/300
 - 0s - loss: 0.0053 - val_loss: 0.0062
 - val_f1: 0.9955
Epoch 138/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 139/300
 - 0s - loss: 0.0053 - val_loss: 0.0065
 - val_f1: 0.9960
Epoch 140/300
 - 0s - loss: 0.0049 - val_loss: 0.0062
 - val_f1: 0.9959
Epoch 141/300
 - 0s - loss: 0.0047 - val_loss: 0.0064
 - val_f1: 0.9957
Epoch 142/300
 - 0s - loss: 0.0053 - val_loss: 0.0061
 - val_f1: 0.9964
Epoch 143/300
 - 0s - loss: 0.0053 - val_loss: 0.0061
 - val_f1: 0.9964
Epoch 144/300
 - 0s - loss: 0.0052 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 145/300
 - 0s - loss: 0.0055 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 146/300
 - 0s - loss: 0.0055 - val_loss: 0.0070
 - val_f1: 0.9957
Epoch 147/300
 - 0s - loss: 0.0052 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 148/300
 - 0s - loss: 0.0053 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 149/300
 - 0s - loss: 0.0054 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 150/300
 - 0s - loss: 0.0054 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 151/300
 - 0s - loss: 0.0052 - val_loss: 0.0061
2019-12-23 12:23:06,149 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9957
Epoch 152/300
 - 0s - loss: 0.0054 - val_loss: 0.0066
 - val_f1: 0.9955
Epoch 153/300
 - 0s - loss: 0.0053 - val_loss: 0.0065
 - val_f1: 0.9959
Epoch 154/300
 - 0s - loss: 0.0051 - val_loss: 0.0062
 - val_f1: 0.9957
Epoch 155/300
 - 0s - loss: 0.0051 - val_loss: 0.0066
 - val_f1: 0.9955
Epoch 156/300
 - 0s - loss: 0.0053 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 157/300
 - 0s - loss: 0.0053 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 158/300
 - 0s - loss: 0.0051 - val_loss: 0.0065
 - val_f1: 0.9960
Epoch 159/300
 - 0s - loss: 0.0051 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 160/300
 - 0s - loss: 0.0054 - val_loss: 0.0062
 - val_f1: 0.9964
Epoch 161/300
 - 0s - loss: 0.0054 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 162/300
 - 0s - loss: 0.0049 - val_loss: 0.0060
 - val_f1: 0.9962
Epoch 163/300
 - 0s - loss: 0.0049 - val_loss: 0.0065
 - val_f1: 0.9961
Epoch 164/300
 - 0s - loss: 0.0052 - val_loss: 0.0065
 - val_f1: 0.9962
Epoch 165/300
 - 0s - loss: 0.0048 - val_loss: 0.0064
 - val_f1: 0.9962
Epoch 166/300
 - 0s - loss: 0.0049 - val_loss: 0.0066
 - val_f1: 0.9959
Epoch 167/300
 - 0s - loss: 0.0051 - val_loss: 0.0064
 - val_f1: 0.9961
Epoch 168/300
 - 0s - loss: 0.0052 - val_loss: 0.0064
 - val_f1: 0.9957
Epoch 169/300
 - 0s - loss: 0.0050 - val_loss: 0.0065
 - val_f1: 0.9959
Epoch 170/300
 - 0s - loss: 0.0049 - val_loss: 0.0064
 - val_f1: 0.9957
Epoch 171/300
 - 0s - loss: 0.0048 - val_loss: 0.0062
 - val_f1: 0.9960
Epoch 172/300
 - 0s - loss: 0.0049 - val_loss: 0.0065
 - val_f1: 0.9959
Epoch 173/300
 - 0s - loss: 0.0052 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 174/300
 - 0s - loss: 0.0050 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 175/300
 - 0s - loss: 0.0050 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 176/300
 - 0s - loss: 0.0051 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 177/300
 - 0s - loss: 0.0049 - val_loss: 0.0064
 - val_f1: 0.9962
Epoch 178/300
 - 0s - loss: 0.0050 - val_loss: 0.0064
 - val_f1: 0.9959
Epoch 179/300
 - 0s - loss: 0.0050 - val_loss: 0.0065
 - val_f1: 0.9958
Epoch 180/300
 - 0s - loss: 0.0049 - val_loss: 0.0069
 - val_f1: 0.9949
Epoch 181/300
 - 0s - loss: 0.0046 - val_loss: 0.0063
2019-12-23 12:23:30,695 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9961
Epoch 182/300
 - 0s - loss: 0.0048 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 183/300
 - 0s - loss: 0.0047 - val_loss: 0.0065
 - val_f1: 0.9961
Epoch 184/300
 - 0s - loss: 0.0048 - val_loss: 0.0063
 - val_f1: 0.9960
Epoch 185/300
 - 0s - loss: 0.0045 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 186/300
 - 0s - loss: 0.0051 - val_loss: 0.0061
 - val_f1: 0.9960
Epoch 187/300
 - 0s - loss: 0.0054 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 188/300
 - 0s - loss: 0.0050 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 189/300
 - 0s - loss: 0.0047 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 190/300
 - 0s - loss: 0.0053 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 191/300
 - 0s - loss: 0.0048 - val_loss: 0.0067
 - val_f1: 0.9962
Epoch 192/300
 - 0s - loss: 0.0046 - val_loss: 0.0065
 - val_f1: 0.9962
Epoch 193/300
 - 0s - loss: 0.0047 - val_loss: 0.0063
 - val_f1: 0.9961
Epoch 194/300
 - 0s - loss: 0.0049 - val_loss: 0.0065
 - val_f1: 0.9961
Epoch 195/300
 - 0s - loss: 0.0049 - val_loss: 0.0063
 - val_f1: 0.9961
Epoch 196/300
 - 0s - loss: 0.0049 - val_loss: 0.0062
 - val_f1: 0.9962
Epoch 197/300
 - 0s - loss: 0.0051 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 198/300
 - 0s - loss: 0.0049 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 199/300
 - 0s - loss: 0.0053 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 200/300
 - 0s - loss: 0.0052 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 201/300
 - 0s - loss: 0.0049 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 202/300
 - 0s - loss: 0.0050 - val_loss: 0.0063
 - val_f1: 0.9961
Epoch 203/300
 - 0s - loss: 0.0045 - val_loss: 0.0069
 - val_f1: 0.9950
Epoch 204/300
 - 0s - loss: 0.0048 - val_loss: 0.0066
 - val_f1: 0.9959
Epoch 205/300
 - 0s - loss: 0.0048 - val_loss: 0.0065
 - val_f1: 0.9963
Epoch 206/300
 - 0s - loss: 0.0046 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 207/300
 - 0s - loss: 0.0047 - val_loss: 0.0064
 - val_f1: 0.9960
Epoch 208/300
 - 0s - loss: 0.0048 - val_loss: 0.0067
 - val_f1: 0.9960
Epoch 209/300
 - 0s - loss: 0.0047 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 210/300
 - 0s - loss: 0.0044 - val_loss: 0.0065
 - val_f1: 0.9961
Epoch 211/300
 - 0s - loss: 0.0047 - val_loss: 0.0063
2019-12-23 12:23:55,238 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9961
Epoch 212/300
 - 0s - loss: 0.0050 - val_loss: 0.0064
2019-12-23 12:23:56,395 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:23:57,689 [INFO] Last epoch loss evaluation: train_loss = 0.003279, val_loss = 0.006035
2019-12-23 12:23:57,694 [INFO] Training complete. time_to_train = 203.40 sec, 3.39 min
2019-12-23 12:23:57,697 [INFO] Model saved to results_selected_models/selected_nsl_dbn_shallow_rep3/best_model.pickle
2019-12-23 12:23:57,836 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep3/training_error_history.png
2019-12-23 12:23:57,960 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep3/training_f1_history.png
2019-12-23 12:23:57,961 [INFO] Making predictions on training, validation, testing data
2019-12-23 12:23:59,947 [INFO] Evaluating predictions (results)
2019-12-23 12:24:00,231 [INFO] Dataset: Testing. Classification report below
2019-12-23 12:24:00,231 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.67      0.93      0.78      9711
       probe       0.71      0.71      0.71      2421
         r2l       0.95      0.10      0.18      2421
         u2r       0.91      0.04      0.07       533

   micro avg       0.77      0.77      0.77     22544
   macro avg       0.84      0.52      0.53     22544
weighted avg       0.81      0.77      0.73     22544

2019-12-23 12:24:00,231 [INFO] Overall accuracy (micro avg): 0.7668559261887864
2019-12-23 12:24:00,555 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7669         0.7669                       0.7669                0.0583                   0.2331  0.7669
1     Macro avg        0.9067         0.8436                       0.5241                0.0774                   0.4759  0.5291
2  Weighted avg        0.8659         0.8113                       0.7669                0.1541                   0.2331  0.7322
2019-12-23 12:24:00,897 [INFO] Dataset: Validation. Classification report below
2019-12-23 12:24:00,897 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.95      0.89      0.92       199
         u2r       0.62      0.50      0.56        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.91      0.88      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 12:24:00,897 [INFO] Overall accuracy (micro avg): 0.9962294105973407
2019-12-23 12:24:01,274 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9962         0.9962                       0.9962                0.0009                   0.0038  0.9962
1     Macro avg        0.9985         0.9125                       0.8765                0.0013                   0.1235  0.8929
2  Weighted avg        0.9976         0.9962                       0.9962                0.0025                   0.0038  0.9962
2019-12-23 12:24:02,785 [INFO] Dataset: Training. Classification report below
2019-12-23 12:24:02,786 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.96      0.90      0.93       796
         u2r       0.80      0.57      0.67        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.95      0.89      0.92    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 12:24:02,786 [INFO] Overall accuracy (micro avg): 0.9968147810037905
2019-12-23 12:24:04,496 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9968         0.9968                       0.9968                0.0008                   0.0032  0.9968
1     Macro avg        0.9987         0.9506                       0.8925                0.0011                   0.1075  0.9175
2  Weighted avg        0.9980         0.9968                       0.9968                0.0025                   0.0032  0.9968
2019-12-23 12:24:04,516 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_shallow_rep3/selected_nsl_dbn_shallow_rep3_results.xlsx
2019-12-23 12:24:04,516 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 12:24:04,520 [INFO] Created directory: results_selected_models/selected_nsl_dbn_shallow_rep4
2019-12-23 12:24:04,520 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_shallow_rep4/run_log.log
2019-12-23 12:24:04,520 [INFO] ================= Running experiment no. 4  ================= 

2019-12-23 12:24:04,520 [INFO] Experiment parameters given below
2019-12-23 12:24:04,520 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_nsl_dbn_shallow_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_shallow_rep4'}
2019-12-23 12:24:04,520 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_shallow_rep4/tf_logs_run_2019_12_23-12_24_04
2019-12-23 12:24:04,520 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 12:24:04,521 [INFO] Reading X, y files
2019-12-23 12:24:04,521 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 12:24:04,800 [INFO] Reading complete. time_to_read=0.28 seconds
2019-12-23 12:24:04,800 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 12:24:04,864 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:24:04,864 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 12:24:04,921 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:24:04,921 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 12:24:04,929 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 12:24:04,929 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 12:24:04,933 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:24:04,933 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 12:24:04,937 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:24:05,139 [INFO] Initializing model
2019-12-23 12:24:05,139 [INFO] Training model
2019-12-23 12:24:05,140 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:24:05,875 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = 106dbd32e80b51ad885305908614f4ee0d18735e
2019-12-23 12:24:05,875 [INFO] Pretraining Deep Belief Network
2019-12-23 12:24:32,500 [INFO] Pretraining Complete
2019-12-23 12:24:32,501 [INFO] Getting pretrained weights
2019-12-23 12:24:32,501 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:24:32,699 [INFO] _________________________________________________________________
2019-12-23 12:24:32,699 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:24:32,699 [INFO] =================================================================
2019-12-23 12:24:32,699 [INFO] dense_7 (Dense)              (None, 32)                3936      
2019-12-23 12:24:32,699 [INFO] _________________________________________________________________
2019-12-23 12:24:32,700 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-23 12:24:32,700 [INFO] _________________________________________________________________
2019-12-23 12:24:32,700 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-23 12:24:32,700 [INFO] _________________________________________________________________
2019-12-23 12:24:32,700 [INFO] dense_8 (Dense)              (None, 5)                 165       
2019-12-23 12:24:32,700 [INFO] =================================================================
2019-12-23 12:24:32,700 [INFO] Total params: 4,229
2019-12-23 12:24:32,700 [INFO] Trainable params: 4,165
2019-12-23 12:24:32,700 [INFO] Non-trainable params: 64
2019-12-23 12:24:32,700 [INFO] _________________________________________________________________
2019-12-23 12:24:32,975 [INFO] Fine-tuning final neural network
 - val_f1: 0.9960
Epoch 00212: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -79.85, time = 0.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -76.38, time = 0.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -73.60, time = 0.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.29, time = 0.54s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -69.34, time = 0.55s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.67, time = 0.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -66.21, time = 0.54s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -64.93, time = 0.54s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -63.80, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -62.78, time = 0.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -61.88, time = 0.54s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -61.06, time = 0.54s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -60.31, time = 0.54s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -59.64, time = 0.54s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -59.03, time = 0.54s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -58.47, time = 0.54s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -57.95, time = 0.54s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -57.48, time = 0.54s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -57.06, time = 0.54s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -56.66, time = 0.54s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -56.30, time = 0.54s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -55.97, time = 0.54s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.67, time = 0.54s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -55.40, time = 0.54s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -55.15, time = 0.53s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -54.92, time = 0.53s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -54.71, time = 0.53s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -54.52, time = 0.53s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -54.35, time = 0.53s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -54.20, time = 0.54s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -54.06, time = 0.53s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -53.94, time = 0.54s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -53.83, time = 0.53s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -53.73, time = 0.53s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -53.65, time = 0.53s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -53.58, time = 0.53s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -53.52, time = 0.52s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -53.47, time = 0.52s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -53.43, time = 0.53s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -53.40, time = 0.52s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -53.39, time = 0.52s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -53.38, time = 0.52s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -53.38, time = 0.52s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -53.40, time = 0.52s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -53.43, time = 0.52s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -53.47, time = 0.52s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -53.52, time = 0.52s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -53.58, time = 0.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -53.66, time = 0.52s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -53.75, time = 0.52s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1520 - val_loss: 0.0602
 - val_f1: 0.9608
Epoch 2/300
 - 0s - loss: 0.0499 - val_loss: 0.0308
 - val_f1: 0.9781
Epoch 3/300
 - 0s - loss: 0.0284 - val_loss: 0.0199
 - val_f1: 0.9862
Epoch 4/300
 - 0s - loss: 0.0223 - val_loss: 0.0154
 - val_f1: 0.9885
Epoch 5/300
 - 0s - loss: 0.0194 - val_loss: 0.0141
 - val_f1: 0.9907
Epoch 6/300
 - 0s - loss: 0.0173 - val_loss: 0.0132
 - val_f1: 0.9909
Epoch 7/300
 - 0s - loss: 0.0164 - val_loss: 0.0123
 - val_f1: 0.9898
Epoch 8/300
 - 0s - loss: 0.0152 - val_loss: 0.0119
 - val_f1: 0.9913
Epoch 9/300
 - 0s - loss: 0.0141 - val_loss: 0.0116
 - val_f1: 0.9914
Epoch 10/300
 - 0s - loss: 0.0137 - val_loss: 0.0113
 - val_f1: 0.9918
Epoch 11/300
 - 0s - loss: 0.0131 - val_loss: 0.0104
 - val_f1: 0.9923
Epoch 12/300
 - 0s - loss: 0.0127 - val_loss: 0.0103
 - val_f1: 0.9926
Epoch 13/300
 - 0s - loss: 0.0124 - val_loss: 0.0103
 - val_f1: 0.9928
Epoch 14/300
 - 0s - loss: 0.0122 - val_loss: 0.0097
 - val_f1: 0.9925
Epoch 15/300
 - 0s - loss: 0.0112 - val_loss: 0.0094
 - val_f1: 0.9934
Epoch 16/300
 - 0s - loss: 0.0114 - val_loss: 0.0098
 - val_f1: 0.9930
Epoch 17/300
 - 0s - loss: 0.0116 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 18/300
 - 0s - loss: 0.0112 - val_loss: 0.0093
 - val_f1: 0.9935
Epoch 19/300
 - 0s - loss: 0.0103 - val_loss: 0.0091
 - val_f1: 0.9940
Epoch 20/300
 - 0s - loss: 0.0104 - val_loss: 0.0095
 - val_f1: 0.9931
Epoch 21/300
 - 0s - loss: 0.0104 - val_loss: 0.0089
 - val_f1: 0.9938
Epoch 22/300
 - 0s - loss: 0.0100 - val_loss: 0.0085
 - val_f1: 0.9941
Epoch 23/300
 - 0s - loss: 0.0097 - val_loss: 0.0087
 - val_f1: 0.9932
Epoch 24/300
 - 0s - loss: 0.0095 - val_loss: 0.0099
 - val_f1: 0.9924
Epoch 25/300
 - 0s - loss: 0.0095 - val_loss: 0.0092
 - val_f1: 0.9934
Epoch 26/300
 - 0s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9937
Epoch 27/300
 - 0s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9933
Epoch 28/300
 - 0s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9943
Epoch 29/300
 - 0s - loss: 0.0094 - val_loss: 0.0083
 - val_f1: 0.9943
Epoch 30/300
 - 0s - loss: 0.0092 - val_loss: 0.0089
 - val_f1: 0.9937
Epoch 31/300
 - 0s - loss: 0.0091 - val_loss: 0.0086
2019-12-23 12:24:59,682 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9938
Epoch 32/300
 - 0s - loss: 0.0091 - val_loss: 0.0082
 - val_f1: 0.9944
Epoch 33/300
 - 0s - loss: 0.0088 - val_loss: 0.0086
 - val_f1: 0.9941
Epoch 34/300
 - 0s - loss: 0.0086 - val_loss: 0.0093
 - val_f1: 0.9942
Epoch 35/300
 - 0s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9944
Epoch 36/300
 - 0s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9944
Epoch 37/300
 - 0s - loss: 0.0085 - val_loss: 0.0087
 - val_f1: 0.9940
Epoch 38/300
 - 0s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9935
Epoch 39/300
 - 0s - loss: 0.0082 - val_loss: 0.0082
 - val_f1: 0.9943
Epoch 40/300
 - 0s - loss: 0.0079 - val_loss: 0.0080
 - val_f1: 0.9943
Epoch 41/300
 - 0s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9947
Epoch 42/300
 - 0s - loss: 0.0079 - val_loss: 0.0078
 - val_f1: 0.9940
Epoch 43/300
 - 0s - loss: 0.0081 - val_loss: 0.0078
 - val_f1: 0.9945
Epoch 44/300
 - 0s - loss: 0.0076 - val_loss: 0.0083
 - val_f1: 0.9945
Epoch 45/300
 - 0s - loss: 0.0077 - val_loss: 0.0078
 - val_f1: 0.9943
Epoch 46/300
 - 0s - loss: 0.0077 - val_loss: 0.0072
 - val_f1: 0.9947
Epoch 47/300
 - 0s - loss: 0.0077 - val_loss: 0.0070
 - val_f1: 0.9950
Epoch 48/300
 - 0s - loss: 0.0073 - val_loss: 0.0073
 - val_f1: 0.9944
Epoch 49/300
 - 0s - loss: 0.0074 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 50/300
 - 0s - loss: 0.0074 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 51/300
 - 0s - loss: 0.0073 - val_loss: 0.0077
 - val_f1: 0.9947
Epoch 52/300
 - 0s - loss: 0.0080 - val_loss: 0.0083
 - val_f1: 0.9931
Epoch 53/300
 - 0s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9943
Epoch 54/300
 - 0s - loss: 0.0077 - val_loss: 0.0081
 - val_f1: 0.9941
Epoch 55/300
 - 0s - loss: 0.0079 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 56/300
 - 0s - loss: 0.0075 - val_loss: 0.0075
 - val_f1: 0.9938
Epoch 57/300
 - 0s - loss: 0.0076 - val_loss: 0.0075
 - val_f1: 0.9939
Epoch 58/300
 - 0s - loss: 0.0077 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 59/300
 - 0s - loss: 0.0074 - val_loss: 0.0080
 - val_f1: 0.9944
Epoch 60/300
 - 0s - loss: 0.0077 - val_loss: 0.0077
 - val_f1: 0.9945
Epoch 61/300
 - 0s - loss: 0.0073 - val_loss: 0.0073
2019-12-23 12:25:24,650 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9949
Epoch 62/300
 - 0s - loss: 0.0069 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 63/300
 - 0s - loss: 0.0070 - val_loss: 0.0072
 - val_f1: 0.9952
Epoch 64/300
 - 0s - loss: 0.0073 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 65/300
 - 0s - loss: 0.0070 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 66/300
 - 0s - loss: 0.0072 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 67/300
 - 0s - loss: 0.0066 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 68/300
 - 0s - loss: 0.0067 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 69/300
 - 1s - loss: 0.0069 - val_loss: 0.0072
 - val_f1: 0.9945
Epoch 70/300
 - 0s - loss: 0.0067 - val_loss: 0.0078
 - val_f1: 0.9943
Epoch 71/300
 - 0s - loss: 0.0069 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 72/300
 - 0s - loss: 0.0068 - val_loss: 0.0069
 - val_f1: 0.9955
Epoch 73/300
 - 0s - loss: 0.0064 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 74/300
 - 0s - loss: 0.0067 - val_loss: 0.0072
 - val_f1: 0.9948
Epoch 75/300
 - 0s - loss: 0.0063 - val_loss: 0.0070
 - val_f1: 0.9949
Epoch 76/300
 - 0s - loss: 0.0067 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 77/300
 - 0s - loss: 0.0065 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 78/300
 - 0s - loss: 0.0069 - val_loss: 0.0074
 - val_f1: 0.9946
Epoch 79/300
 - 0s - loss: 0.0065 - val_loss: 0.0072
 - val_f1: 0.9946
Epoch 80/300
 - 0s - loss: 0.0062 - val_loss: 0.0074
 - val_f1: 0.9948
Epoch 81/300
 - 0s - loss: 0.0063 - val_loss: 0.0065
 - val_f1: 0.9955
Epoch 82/300
 - 0s - loss: 0.0064 - val_loss: 0.0071
 - val_f1: 0.9948
Epoch 83/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9952
Epoch 84/300
 - 0s - loss: 0.0060 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 85/300
 - 0s - loss: 0.0061 - val_loss: 0.0066
 - val_f1: 0.9951
Epoch 86/300
 - 0s - loss: 0.0064 - val_loss: 0.0072
 - val_f1: 0.9950
Epoch 87/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 88/300
 - 0s - loss: 0.0064 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 89/300
 - 0s - loss: 0.0063 - val_loss: 0.0073
 - val_f1: 0.9945
Epoch 90/300
 - 0s - loss: 0.0065 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 91/300
 - 0s - loss: 0.0062 - val_loss: 0.0070
2019-12-23 12:25:49,694 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9955
Epoch 92/300
 - 0s - loss: 0.0063 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 93/300
 - 0s - loss: 0.0061 - val_loss: 0.0066
 - val_f1: 0.9959
Epoch 94/300
 - 0s - loss: 0.0065 - val_loss: 0.0071
 - val_f1: 0.9951
Epoch 95/300
 - 0s - loss: 0.0061 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 96/300
 - 0s - loss: 0.0061 - val_loss: 0.0075
 - val_f1: 0.9952
Epoch 97/300
 - 0s - loss: 0.0060 - val_loss: 0.0073
 - val_f1: 0.9951
Epoch 98/300
 - 0s - loss: 0.0059 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 99/300
 - 0s - loss: 0.0059 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 100/300
 - 0s - loss: 0.0058 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 101/300
 - 0s - loss: 0.0058 - val_loss: 0.0076
 - val_f1: 0.9951
Epoch 102/300
 - 0s - loss: 0.0058 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 103/300
 - 0s - loss: 0.0062 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 104/300
 - 0s - loss: 0.0057 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 105/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9953
Epoch 106/300
 - 0s - loss: 0.0064 - val_loss: 0.0073
 - val_f1: 0.9956
Epoch 107/300
 - 0s - loss: 0.0061 - val_loss: 0.0070
 - val_f1: 0.9957
Epoch 108/300
 - 0s - loss: 0.0058 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 109/300
 - 0s - loss: 0.0061 - val_loss: 0.0065
 - val_f1: 0.9954
Epoch 110/300
 - 0s - loss: 0.0056 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 111/300
 - 0s - loss: 0.0061 - val_loss: 0.0065
 - val_f1: 0.9956
Epoch 112/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9952
Epoch 113/300
 - 0s - loss: 0.0056 - val_loss: 0.0068
 - val_f1: 0.9954
Epoch 114/300
 - 0s - loss: 0.0057 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 115/300
 - 0s - loss: 0.0059 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 116/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9960
Epoch 117/300
 - 0s - loss: 0.0058 - val_loss: 0.0066
 - val_f1: 0.9954
Epoch 118/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 119/300
 - 0s - loss: 0.0059 - val_loss: 0.0064
 - val_f1: 0.9959
Epoch 120/300
 - 0s - loss: 0.0056 - val_loss: 0.0070
 - val_f1: 0.9952
Epoch 121/300
 - 0s - loss: 0.0057 - val_loss: 0.0069
2019-12-23 12:26:14,696 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9956
Epoch 122/300
 - 0s - loss: 0.0057 - val_loss: 0.0068
 - val_f1: 0.9953
Epoch 123/300
 - 0s - loss: 0.0059 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 124/300
 - 0s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9957
Epoch 125/300
 - 0s - loss: 0.0056 - val_loss: 0.0073
 - val_f1: 0.9952
Epoch 126/300
 - 0s - loss: 0.0055 - val_loss: 0.0065
 - val_f1: 0.9952
Epoch 127/300
 - 0s - loss: 0.0056 - val_loss: 0.0064
 - val_f1: 0.9958
Epoch 128/300
 - 0s - loss: 0.0054 - val_loss: 0.0076
 - val_f1: 0.9949
Epoch 129/300
 - 0s - loss: 0.0056 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 130/300
 - 0s - loss: 0.0058 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 131/300
 - 0s - loss: 0.0056 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 132/300
 - 0s - loss: 0.0058 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 133/300
 - 0s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9956
Epoch 134/300
 - 0s - loss: 0.0055 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 135/300
 - 0s - loss: 0.0060 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 136/300
 - 0s - loss: 0.0054 - val_loss: 0.0066
 - val_f1: 0.9955
Epoch 137/300
 - 0s - loss: 0.0055 - val_loss: 0.0070
 - val_f1: 0.9951
Epoch 138/300
 - 0s - loss: 0.0055 - val_loss: 0.0065
 - val_f1: 0.9955
Epoch 139/300
 - 0s - loss: 0.0051 - val_loss: 0.0074
 - val_f1: 0.9950
Epoch 140/300
 - 0s - loss: 0.0056 - val_loss: 0.0066
 - val_f1: 0.9955
Epoch 141/300
 - 0s - loss: 0.0054 - val_loss: 0.0063
 - val_f1: 0.9957
Epoch 142/300
 - 0s - loss: 0.0056 - val_loss: 0.0065
 - val_f1: 0.9955
Epoch 143/300
 - 0s - loss: 0.0051 - val_loss: 0.0067
 - val_f1: 0.9954
Epoch 144/300
 - 0s - loss: 0.0050 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 145/300
 - 0s - loss: 0.0054 - val_loss: 0.0065
 - val_f1: 0.9953
Epoch 146/300
 - 0s - loss: 0.0059 - val_loss: 0.0073
 - val_f1: 0.9950
Epoch 147/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9957
Epoch 148/300
 - 0s - loss: 0.0056 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 149/300
 - 0s - loss: 0.0055 - val_loss: 0.0067
 - val_f1: 0.9958
Epoch 150/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 151/300
 - 0s - loss: 0.0054 - val_loss: 0.0069
2019-12-23 12:26:39,623 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9954
Epoch 152/300
 - 0s - loss: 0.0053 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 153/300
 - 0s - loss: 0.0053 - val_loss: 0.0069
 - val_f1: 0.9956
Epoch 154/300
 - 0s - loss: 0.0054 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 155/300
 - 0s - loss: 0.0057 - val_loss: 0.0067
 - val_f1: 0.9958
Epoch 156/300
 - 0s - loss: 0.0052 - val_loss: 0.0064
 - val_f1: 0.9953
Epoch 157/300
 - 0s - loss: 0.0054 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 158/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 159/300
 - 0s - loss: 0.0052 - val_loss: 0.0067
 - val_f1: 0.9955
Epoch 160/300
 - 0s - loss: 0.0051 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 161/300
 - 0s - loss: 0.0056 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 162/300
 - 0s - loss: 0.0052 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 163/300
 - 0s - loss: 0.0056 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 164/300
 - 0s - loss: 0.0053 - val_loss: 0.0072
 - val_f1: 0.9956
Epoch 165/300
 - 0s - loss: 0.0053 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 166/300
 - 0s - loss: 0.0051 - val_loss: 0.0075
 - val_f1: 0.9954
Epoch 167/300
 - 0s - loss: 0.0056 - val_loss: 0.0071
 - val_f1: 0.9962
Epoch 168/300
 - 0s - loss: 0.0054 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 169/300
 - 0s - loss: 0.0054 - val_loss: 0.0076
 - val_f1: 0.9953
Epoch 170/300
 - 0s - loss: 0.0055 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 171/300
 - 0s - loss: 0.0053 - val_loss: 0.0071
 - val_f1: 0.9957
Epoch 172/300
 - 0s - loss: 0.0055 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 173/300
 - 0s - loss: 0.0054 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 174/300
 - 0s - loss: 0.0053 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 175/300
 - 0s - loss: 0.0052 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 176/300
 - 0s - loss: 0.0053 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 177/300
 - 0s - loss: 0.0050 - val_loss: 0.0074
 - val_f1: 0.9954
Epoch 178/300
 - 0s - loss: 0.0055 - val_loss: 0.0072
 - val_f1: 0.9959
Epoch 179/300
 - 0s - loss: 0.0054 - val_loss: 0.0073
 - val_f1: 0.9957
Epoch 180/300
 - 0s - loss: 0.0052 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 181/300
 - 0s - loss: 0.0057 - val_loss: 0.0075
2019-12-23 12:27:04,968 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9954
Epoch 182/300
 - 0s - loss: 0.0054 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 183/300
 - 0s - loss: 0.0050 - val_loss: 0.0068
 - val_f1: 0.9960
Epoch 184/300
 - 0s - loss: 0.0050 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 185/300
 - 0s - loss: 0.0057 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 186/300
 - 0s - loss: 0.0051 - val_loss: 0.0069
 - val_f1: 0.9959
Epoch 187/300
 - 0s - loss: 0.0054 - val_loss: 0.0074
 - val_f1: 0.9955
Epoch 188/300
 - 0s - loss: 0.0054 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 189/300
 - 0s - loss: 0.0050 - val_loss: 0.0074
 - val_f1: 0.9954
Epoch 190/300
 - 0s - loss: 0.0049 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 191/300
 - 0s - loss: 0.0052 - val_loss: 0.0067
2019-12-23 12:27:13,670 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:27:14,974 [INFO] Last epoch loss evaluation: train_loss = 0.003422, val_loss = 0.006344
2019-12-23 12:27:14,980 [INFO] Training complete. time_to_train = 189.84 sec, 3.16 min
2019-12-23 12:27:14,983 [INFO] Model saved to results_selected_models/selected_nsl_dbn_shallow_rep4/best_model.pickle
2019-12-23 12:27:15,127 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep4/training_error_history.png
2019-12-23 12:27:15,261 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep4/training_f1_history.png
2019-12-23 12:27:15,261 [INFO] Making predictions on training, validation, testing data
2019-12-23 12:27:17,362 [INFO] Evaluating predictions (results)
2019-12-23 12:27:17,646 [INFO] Dataset: Testing. Classification report below
2019-12-23 12:27:17,646 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.83      0.90      7458
      normal       0.66      0.93      0.77      9711
       probe       0.71      0.69      0.70      2421
         r2l       0.91      0.03      0.06      2421
         u2r       0.67      0.03      0.06       533

   micro avg       0.75      0.75      0.75     22544
   macro avg       0.78      0.50      0.50     22544
weighted avg       0.79      0.75      0.71     22544

2019-12-23 12:27:17,646 [INFO] Overall accuracy (micro avg): 0.754125266146203
2019-12-23 12:27:17,970 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7541         0.7541                       0.7541                0.0615                   0.2459  0.7541
1     Macro avg        0.9017         0.7832                       0.5031                0.0820                   0.4969  0.4977
2  Weighted avg        0.8583         0.7948                       0.7541                0.1642                   0.2459  0.7117
2019-12-23 12:27:18,312 [INFO] Dataset: Validation. Classification report below
2019-12-23 12:27:18,312 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.99      0.99      0.99      2331
         r2l       0.94      0.89      0.92       199
         u2r       1.00      0.40      0.57        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.98      0.86      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 12:27:18,312 [INFO] Overall accuracy (micro avg): 0.9956340543758683
2019-12-23 12:27:18,690 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9956         0.9956                       0.9956                0.0011                   0.0044  0.9956
1     Macro avg        0.9983         0.9848                       0.8556                0.0015                   0.1444  0.8943
2  Weighted avg        0.9973         0.9956                       0.9956                0.0030                   0.0044  0.9956
2019-12-23 12:27:20,202 [INFO] Dataset: Training. Classification report below
2019-12-23 12:27:20,202 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.95      0.92      0.93       796
         u2r       0.68      0.50      0.58        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.92      0.88      0.90    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 12:27:20,202 [INFO] Overall accuracy (micro avg): 0.9966361705927881
2019-12-23 12:27:21,925 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9966         0.9966                       0.9966                0.0008                   0.0034  0.9966
1     Macro avg        0.9987         0.9223                       0.8814                0.0011                   0.1186  0.8991
2  Weighted avg        0.9979         0.9966                       0.9966                0.0022                   0.0034  0.9966
2019-12-23 12:27:21,946 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_shallow_rep4/selected_nsl_dbn_shallow_rep4_results.xlsx
2019-12-23 12:27:21,947 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-23 12:27:21,951 [INFO] Created directory: results_selected_models/selected_nsl_dbn_shallow_rep5
2019-12-23 12:27:21,951 [INFO] Initialized logging. log_filename = results_selected_models/selected_nsl_dbn_shallow_rep5/run_log.log
2019-12-23 12:27:21,951 [INFO] ================= Running experiment no. 5  ================= 

2019-12-23 12:27:21,951 [INFO] Experiment parameters given below
2019-12-23 12:27:21,951 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_nsl_dbn_shallow_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/nsl_kdd_five_classes', 'description': 'selected_nsl_dbn_shallow_rep5'}
2019-12-23 12:27:21,951 [INFO] Created tensorboard log directory: results_selected_models/selected_nsl_dbn_shallow_rep5/tf_logs_run_2019_12_23-12_27_21
2019-12-23 12:27:21,951 [INFO] Loading datsets from: ../Datasets/small_datasets/nsl_kdd_five_classes
2019-12-23 12:27:21,952 [INFO] Reading X, y files
2019-12-23 12:27:21,952 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_train.h5
2019-12-23 12:27:22,217 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-23 12:27:22,217 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_val.h5
2019-12-23 12:27:22,283 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 12:27:22,283 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/X_test.h5
2019-12-23 12:27:22,340 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-23 12:27:22,340 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_train.h5
2019-12-23 12:27:22,348 [INFO] Reading complete. time_to_read=0.01 seconds
2019-12-23 12:27:22,348 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_val.h5
2019-12-23 12:27:22,352 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:27:22,353 [INFO] Reading HDF dataset ../Datasets/small_datasets/nsl_kdd_five_classes/y_test.h5
2019-12-23 12:27:22,356 [INFO] Reading complete. time_to_read=0.00 seconds
2019-12-23 12:27:22,552 [INFO] Initializing model
2019-12-23 12:27:22,553 [INFO] Training model
2019-12-23 12:27:22,553 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:27:23,291 [INFO] Split sizes (instances). total = 100778, unsupervised = 50389, supervised = 50389, unsupervised dataset hash = f543c6a725653bdc5c4691e00a60911fd9363f1a
2019-12-23 12:27:23,291 [INFO] Pretraining Deep Belief Network
2019-12-23 12:27:49,869 [INFO] Pretraining Complete
2019-12-23 12:27:49,869 [INFO] Getting pretrained weights
2019-12-23 12:27:49,869 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:27:49,984 [INFO] _________________________________________________________________
2019-12-23 12:27:49,984 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:27:49,984 [INFO] =================================================================
2019-12-23 12:27:49,985 [INFO] dense_9 (Dense)              (None, 32)                3936      
2019-12-23 12:27:49,985 [INFO] _________________________________________________________________
2019-12-23 12:27:49,985 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-23 12:27:49,985 [INFO] _________________________________________________________________
2019-12-23 12:27:49,985 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-23 12:27:49,985 [INFO] _________________________________________________________________
2019-12-23 12:27:49,985 [INFO] dense_10 (Dense)             (None, 5)                 165       
2019-12-23 12:27:49,985 [INFO] =================================================================
2019-12-23 12:27:49,985 [INFO] Total params: 4,229
2019-12-23 12:27:49,985 [INFO] Trainable params: 4,165
2019-12-23 12:27:49,985 [INFO] Non-trainable params: 64
2019-12-23 12:27:49,985 [INFO] _________________________________________________________________
2019-12-23 12:27:50,319 [INFO] Fine-tuning final neural network
 - val_f1: 0.9959
Epoch 00191: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -79.79, time = 0.35s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -76.31, time = 0.55s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -73.51, time = 0.54s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -71.18, time = 0.54s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -69.21, time = 0.54s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -67.51, time = 0.54s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -66.03, time = 0.54s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -64.73, time = 0.54s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -63.57, time = 0.54s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -62.53, time = 0.54s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -61.60, time = 0.54s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -60.75, time = 0.54s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -59.98, time = 0.54s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -59.28, time = 0.54s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -58.64, time = 0.54s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -58.06, time = 0.54s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -57.52, time = 0.53s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -57.03, time = 0.54s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -56.57, time = 0.54s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -56.15, time = 0.53s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -55.77, time = 0.53s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -55.41, time = 0.54s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.08, time = 0.53s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -54.78, time = 0.53s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -54.50, time = 0.54s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -54.25, time = 0.53s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -54.01, time = 0.53s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -53.80, time = 0.53s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -53.60, time = 0.53s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -53.42, time = 0.53s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -53.25, time = 0.53s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -53.10, time = 0.53s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -52.97, time = 0.53s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -52.84, time = 0.53s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -52.73, time = 0.53s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -52.63, time = 0.53s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -52.54, time = 0.52s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -52.46, time = 0.52s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -52.40, time = 0.53s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -52.34, time = 0.52s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -52.29, time = 0.52s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -52.26, time = 0.53s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -52.23, time = 0.52s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -52.22, time = 0.52s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -52.22, time = 0.52s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -52.23, time = 0.52s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -52.25, time = 0.52s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -52.29, time = 0.52s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -52.33, time = 0.52s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -52.39, time = 0.52s
Train on 50389 samples, validate on 25195 samples
Epoch 1/300
 - 1s - loss: 0.1936 - val_loss: 0.0642
 - val_f1: 0.9590
Epoch 2/300
 - 0s - loss: 0.0558 - val_loss: 0.0403
 - val_f1: 0.9737
Epoch 3/300
 - 0s - loss: 0.0342 - val_loss: 0.0228
 - val_f1: 0.9862
Epoch 4/300
 - 0s - loss: 0.0248 - val_loss: 0.0166
 - val_f1: 0.9873
Epoch 5/300
 - 0s - loss: 0.0207 - val_loss: 0.0146
 - val_f1: 0.9887
Epoch 6/300
 - 0s - loss: 0.0191 - val_loss: 0.0138
 - val_f1: 0.9890
Epoch 7/300
 - 0s - loss: 0.0174 - val_loss: 0.0125
 - val_f1: 0.9906
Epoch 8/300
 - 0s - loss: 0.0159 - val_loss: 0.0113
 - val_f1: 0.9919
Epoch 9/300
 - 0s - loss: 0.0152 - val_loss: 0.0111
 - val_f1: 0.9904
Epoch 10/300
 - 0s - loss: 0.0144 - val_loss: 0.0109
 - val_f1: 0.9908
Epoch 11/300
 - 0s - loss: 0.0136 - val_loss: 0.0103
 - val_f1: 0.9921
Epoch 12/300
 - 0s - loss: 0.0130 - val_loss: 0.0099
 - val_f1: 0.9926
Epoch 13/300
 - 0s - loss: 0.0128 - val_loss: 0.0094
 - val_f1: 0.9931
Epoch 14/300
 - 0s - loss: 0.0122 - val_loss: 0.0097
 - val_f1: 0.9929
Epoch 15/300
 - 0s - loss: 0.0116 - val_loss: 0.0103
 - val_f1: 0.9905
Epoch 16/300
 - 0s - loss: 0.0119 - val_loss: 0.0092
 - val_f1: 0.9930
Epoch 17/300
 - 0s - loss: 0.0111 - val_loss: 0.0096
 - val_f1: 0.9926
Epoch 18/300
 - 0s - loss: 0.0114 - val_loss: 0.0088
 - val_f1: 0.9936
Epoch 19/300
 - 0s - loss: 0.0108 - val_loss: 0.0095
 - val_f1: 0.9924
Epoch 20/300
 - 0s - loss: 0.0106 - val_loss: 0.0085
 - val_f1: 0.9942
Epoch 21/300
 - 0s - loss: 0.0102 - val_loss: 0.0090
 - val_f1: 0.9935
Epoch 22/300
 - 0s - loss: 0.0104 - val_loss: 0.0087
 - val_f1: 0.9934
Epoch 23/300
 - 0s - loss: 0.0099 - val_loss: 0.0086
 - val_f1: 0.9936
Epoch 24/300
 - 0s - loss: 0.0098 - val_loss: 0.0083
 - val_f1: 0.9942
Epoch 25/300
 - 0s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9927
Epoch 26/300
 - 0s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9943
Epoch 27/300
 - 0s - loss: 0.0098 - val_loss: 0.0080
 - val_f1: 0.9939
Epoch 28/300
 - 0s - loss: 0.0094 - val_loss: 0.0082
 - val_f1: 0.9939
Epoch 29/300
 - 0s - loss: 0.0096 - val_loss: 0.0084
 - val_f1: 0.9937
Epoch 30/300
 - 0s - loss: 0.0091 - val_loss: 0.0080
 - val_f1: 0.9942
Epoch 31/300
 - 0s - loss: 0.0090 - val_loss: 0.0088
2019-12-23 12:28:17,807 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9935
Epoch 32/300
 - 0s - loss: 0.0088 - val_loss: 0.0080
 - val_f1: 0.9945
Epoch 33/300
 - 0s - loss: 0.0089 - val_loss: 0.0078
 - val_f1: 0.9946
Epoch 34/300
 - 0s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9939
Epoch 35/300
 - 0s - loss: 0.0086 - val_loss: 0.0080
 - val_f1: 0.9947
Epoch 36/300
 - 0s - loss: 0.0085 - val_loss: 0.0075
 - val_f1: 0.9941
Epoch 37/300
 - 0s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9941
Epoch 38/300
 - 0s - loss: 0.0083 - val_loss: 0.0076
 - val_f1: 0.9945
Epoch 39/300
 - 0s - loss: 0.0081 - val_loss: 0.0076
 - val_f1: 0.9948
Epoch 40/300
 - 0s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9929
Epoch 41/300
 - 0s - loss: 0.0085 - val_loss: 0.0077
 - val_f1: 0.9945
Epoch 42/300
 - 0s - loss: 0.0077 - val_loss: 0.0076
 - val_f1: 0.9948
Epoch 43/300
 - 0s - loss: 0.0079 - val_loss: 0.0076
 - val_f1: 0.9942
Epoch 44/300
 - 0s - loss: 0.0078 - val_loss: 0.0079
 - val_f1: 0.9949
Epoch 45/300
 - 0s - loss: 0.0075 - val_loss: 0.0081
 - val_f1: 0.9943
Epoch 46/300
 - 0s - loss: 0.0075 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 47/300
 - 0s - loss: 0.0078 - val_loss: 0.0073
 - val_f1: 0.9949
Epoch 48/300
 - 0s - loss: 0.0076 - val_loss: 0.0076
 - val_f1: 0.9946
Epoch 49/300
 - 0s - loss: 0.0074 - val_loss: 0.0081
 - val_f1: 0.9940
Epoch 50/300
 - 0s - loss: 0.0073 - val_loss: 0.0082
 - val_f1: 0.9951
Epoch 51/300
 - 0s - loss: 0.0073 - val_loss: 0.0075
 - val_f1: 0.9948
Epoch 52/300
 - 0s - loss: 0.0073 - val_loss: 0.0073
 - val_f1: 0.9948
Epoch 53/300
 - 0s - loss: 0.0074 - val_loss: 0.0079
 - val_f1: 0.9947
Epoch 54/300
 - 0s - loss: 0.0073 - val_loss: 0.0070
 - val_f1: 0.9953
Epoch 55/300
 - 0s - loss: 0.0072 - val_loss: 0.0073
 - val_f1: 0.9948
Epoch 56/300
 - 0s - loss: 0.0073 - val_loss: 0.0069
 - val_f1: 0.9951
Epoch 57/300
 - 0s - loss: 0.0070 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 58/300
 - 0s - loss: 0.0066 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 59/300
 - 0s - loss: 0.0070 - val_loss: 0.0077
 - val_f1: 0.9951
Epoch 60/300
 - 0s - loss: 0.0071 - val_loss: 0.0072
 - val_f1: 0.9953
Epoch 61/300
 - 0s - loss: 0.0066 - val_loss: 0.0069
2019-12-23 12:28:43,132 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9954
Epoch 62/300
 - 0s - loss: 0.0069 - val_loss: 0.0070
 - val_f1: 0.9955
Epoch 63/300
 - 0s - loss: 0.0065 - val_loss: 0.0072
 - val_f1: 0.9954
Epoch 64/300
 - 0s - loss: 0.0067 - val_loss: 0.0066
 - val_f1: 0.9961
Epoch 65/300
 - 0s - loss: 0.0066 - val_loss: 0.0065
 - val_f1: 0.9957
Epoch 66/300
 - 0s - loss: 0.0063 - val_loss: 0.0069
 - val_f1: 0.9957
Epoch 67/300
 - 0s - loss: 0.0066 - val_loss: 0.0075
 - val_f1: 0.9951
Epoch 68/300
 - 0s - loss: 0.0065 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 69/300
 - 0s - loss: 0.0066 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 70/300
 - 0s - loss: 0.0063 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 71/300
 - 0s - loss: 0.0062 - val_loss: 0.0071
 - val_f1: 0.9957
Epoch 72/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9955
Epoch 73/300
 - 0s - loss: 0.0064 - val_loss: 0.0066
 - val_f1: 0.9963
Epoch 74/300
 - 0s - loss: 0.0063 - val_loss: 0.0068
 - val_f1: 0.9951
Epoch 75/300
 - 0s - loss: 0.0065 - val_loss: 0.0068
 - val_f1: 0.9958
Epoch 76/300
 - 0s - loss: 0.0061 - val_loss: 0.0071
 - val_f1: 0.9956
Epoch 77/300
 - 0s - loss: 0.0063 - val_loss: 0.0072
 - val_f1: 0.9959
Epoch 78/300
 - 0s - loss: 0.0063 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 79/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
 - val_f1: 0.9952
Epoch 80/300
 - 0s - loss: 0.0061 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 81/300
 - 0s - loss: 0.0064 - val_loss: 0.0070
 - val_f1: 0.9958
Epoch 82/300
 - 0s - loss: 0.0060 - val_loss: 0.0069
 - val_f1: 0.9954
Epoch 83/300
 - 0s - loss: 0.0060 - val_loss: 0.0071
 - val_f1: 0.9954
Epoch 84/300
 - 0s - loss: 0.0058 - val_loss: 0.0069
 - val_f1: 0.9958
Epoch 85/300
 - 0s - loss: 0.0062 - val_loss: 0.0068
 - val_f1: 0.9956
Epoch 86/300
 - 0s - loss: 0.0064 - val_loss: 0.0075
 - val_f1: 0.9955
Epoch 87/300
 - 0s - loss: 0.0061 - val_loss: 0.0073
 - val_f1: 0.9959
Epoch 88/300
 - 0s - loss: 0.0063 - val_loss: 0.0076
 - val_f1: 0.9952
Epoch 89/300
 - 0s - loss: 0.0060 - val_loss: 0.0069
 - val_f1: 0.9961
Epoch 90/300
 - 0s - loss: 0.0061 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 91/300
 - 0s - loss: 0.0059 - val_loss: 0.0069
2019-12-23 12:29:08,427 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_nsl_dbn_shallow_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9956
Epoch 92/300
 - 0s - loss: 0.0062 - val_loss: 0.0068
 - val_f1: 0.9959
Epoch 93/300
 - 0s - loss: 0.0059 - val_loss: 0.0070
 - val_f1: 0.9960
Epoch 94/300
 - 0s - loss: 0.0057 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 95/300
 - 0s - loss: 0.0055 - val_loss: 0.0069
 - val_f1: 0.9953
Epoch 96/300
 - 0s - loss: 0.0060 - val_loss: 0.0072
 - val_f1: 0.9957
Epoch 97/300
 - 0s - loss: 0.0059 - val_loss: 0.0071
 - val_f1: 0.9955
Epoch 98/300
 - 0s - loss: 0.0061 - val_loss: 0.0072
 - val_f1: 0.9958
Epoch 99/300
 - 0s - loss: 0.0056 - val_loss: 0.0082
 - val_f1: 0.9950
Epoch 100/300
 - 0s - loss: 0.0062 - val_loss: 0.0067
 - val_f1: 0.9959
Epoch 101/300
 - 0s - loss: 0.0061 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 102/300
 - 0s - loss: 0.0058 - val_loss: 0.0073
 - val_f1: 0.9954
Epoch 103/300
 - 0s - loss: 0.0058 - val_loss: 0.0072
 - val_f1: 0.9961
Epoch 104/300
 - 0s - loss: 0.0061 - val_loss: 0.0072
 - val_f1: 0.9960
Epoch 105/300
 - 0s - loss: 0.0058 - val_loss: 0.0074
 - val_f1: 0.9952
Epoch 106/300
 - 0s - loss: 0.0060 - val_loss: 0.0068
 - val_f1: 0.9961
Epoch 107/300
 - 0s - loss: 0.0058 - val_loss: 0.0072
 - val_f1: 0.9949
Epoch 108/300
 - 0s - loss: 0.0057 - val_loss: 0.0075
 - val_f1: 0.9953
Epoch 109/300
 - 0s - loss: 0.0059 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 110/300
 - 0s - loss: 0.0061 - val_loss: 0.0070
 - val_f1: 0.9956
Epoch 111/300
 - 0s - loss: 0.0059 - val_loss: 0.0073
 - val_f1: 0.9955
Epoch 112/300
 - 0s - loss: 0.0058 - val_loss: 0.0070
 - val_f1: 0.9959
Epoch 113/300
 - 0s - loss: 0.0059 - val_loss: 0.0068
 - val_f1: 0.9957
Epoch 114/300
 - 0s - loss: 0.0057 - val_loss: 0.0066
 - val_f1: 0.9958
Epoch 115/300
 - 0s - loss: 0.0061 - val_loss: 0.0069
2019-12-23 12:29:29,143 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 12:29:30,498 [INFO] Last epoch loss evaluation: train_loss = 0.004243, val_loss = 0.006473
2019-12-23 12:29:30,503 [INFO] Training complete. time_to_train = 127.95 sec, 2.13 min
2019-12-23 12:29:30,507 [INFO] Model saved to results_selected_models/selected_nsl_dbn_shallow_rep5/best_model.pickle
2019-12-23 12:29:30,646 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep5/training_error_history.png
2019-12-23 12:29:30,773 [INFO] Plot saved to: results_selected_models/selected_nsl_dbn_shallow_rep5/training_f1_history.png
2019-12-23 12:29:30,773 [INFO] Making predictions on training, validation, testing data
2019-12-23 12:29:32,947 [INFO] Evaluating predictions (results)
2019-12-23 12:29:33,232 [INFO] Dataset: Testing. Classification report below
2019-12-23 12:29:33,232 [INFO] 
              precision    recall  f1-score   support

         dos       0.97      0.84      0.90      7458
      normal       0.69      0.94      0.80      9711
       probe       0.75      0.75      0.75      2421
         r2l       0.97      0.12      0.21      2421
         u2r       0.71      0.05      0.09       533

   micro avg       0.78      0.78      0.78     22544
   macro avg       0.82      0.54      0.55     22544
weighted avg       0.82      0.78      0.75     22544

2019-12-23 12:29:33,232 [INFO] Overall accuracy (micro avg): 0.7791873669268985
2019-12-23 12:29:33,555 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.7792         0.7792                       0.7792                0.0552                   0.2208  0.7792
1     Macro avg        0.9117         0.8169                       0.5397                0.0735                   0.4603  0.5482
2  Weighted avg        0.8737         0.8175                       0.7792                0.1465                   0.2208  0.7458
2019-12-23 12:29:33,896 [INFO] Dataset: Validation. Classification report below
2019-12-23 12:29:33,896 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00      9186
      normal       1.00      1.00      1.00     13469
       probe       0.98      0.99      0.99      2331
         r2l       0.96      0.87      0.91       199
         u2r       1.00      0.40      0.57        10

   micro avg       1.00      1.00      1.00     25195
   macro avg       0.99      0.85      0.89     25195
weighted avg       1.00      1.00      1.00     25195

2019-12-23 12:29:33,896 [INFO] Overall accuracy (micro avg): 0.9956737447906331
2019-12-23 12:29:34,274 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9957         0.9957                       0.9957                0.0011                   0.0043  0.9957
1     Macro avg        0.9983         0.9869                       0.8522                0.0014                   0.1478  0.8935
2  Weighted avg        0.9973         0.9957                       0.9957                0.0027                   0.0043  0.9956
2019-12-23 12:29:35,785 [INFO] Dataset: Training. Classification report below
2019-12-23 12:29:35,785 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00     36741
      normal       1.00      1.00      1.00     53874
       probe       0.99      0.99      0.99      9325
         r2l       0.96      0.88      0.92       796
         u2r       0.74      0.48      0.58        42

   micro avg       1.00      1.00      1.00    100778
   macro avg       0.94      0.87      0.90    100778
weighted avg       1.00      1.00      1.00    100778

2019-12-23 12:29:35,785 [INFO] Overall accuracy (micro avg): 0.995941574550001
2019-12-23 12:29:37,495 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9959         0.9959                       0.9959                0.0010                   0.0041  0.9959
1     Macro avg        0.9984         0.9369                       0.8682                0.0014                   0.1318  0.8964
2  Weighted avg        0.9975         0.9959                       0.9959                0.0028                   0.0041  0.9959
2019-12-23 12:29:37,515 [INFO] Results saved to: results_selected_models/selected_nsl_dbn_shallow_rep5/selected_nsl_dbn_shallow_rep5_results.xlsx
2019-12-23 12:29:37,515 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-23 12:29:37,519 [INFO] Created directory: results_selected_models/selected_ids17_dbn_shallow_rep1
2019-12-23 12:29:37,519 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_shallow_rep1/run_log.log
2019-12-23 12:29:37,519 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 12:29:37,519 [INFO] Experiment parameters given below
2019-12-23 12:29:37,520 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids17_dbn_shallow_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_shallow_rep1'}
2019-12-23 12:29:37,520 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_shallow_rep1/tf_logs_run_2019_12_23-12_29_37
2019-12-23 12:29:37,520 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 12:29:37,530 [INFO] Reading X, y files
2019-12-23 12:29:37,530 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 12:29:43,413 [INFO] Reading complete. time_to_read=5.88 seconds
2019-12-23 12:29:43,413 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 12:29:44,984 [INFO] Reading complete. time_to_read=1.57 seconds
2019-12-23 12:29:44,984 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 12:29:46,696 [INFO] Reading complete. time_to_read=1.71 seconds
2019-12-23 12:29:46,697 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 12:29:47,125 [INFO] Reading complete. time_to_read=0.43 seconds
2019-12-23 12:29:47,126 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 12:29:47,289 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-23 12:29:47,290 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 12:29:47,451 [INFO] Reading complete. time_to_read=0.16 seconds
2019-12-23 12:29:50,865 [INFO] Initializing model
2019-12-23 12:29:50,865 [INFO] Training model
2019-12-23 12:29:50,866 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 12:30:08,801 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = e0afcef66ada5dbfae43a62996546e5189650b4b
2019-12-23 12:30:08,802 [INFO] Pretraining Deep Belief Network
2019-12-23 12:35:54,730 [INFO] Pretraining Complete
2019-12-23 12:35:54,731 [INFO] Getting pretrained weights
2019-12-23 12:35:54,731 [INFO] Creating and initializing feed forward neural network
2019-12-23 12:35:54,846 [INFO] _________________________________________________________________
2019-12-23 12:35:54,846 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 12:35:54,846 [INFO] =================================================================
2019-12-23 12:35:54,846 [INFO] dense_11 (Dense)             (None, 32)                2528      
2019-12-23 12:35:54,847 [INFO] _________________________________________________________________
2019-12-23 12:35:54,847 [INFO] batch_normalization_6 (Batch (None, 32)                128       
2019-12-23 12:35:54,847 [INFO] _________________________________________________________________
2019-12-23 12:35:54,847 [INFO] dropout_6 (Dropout)          (None, 32)                0         
2019-12-23 12:35:54,847 [INFO] _________________________________________________________________
2019-12-23 12:35:54,847 [INFO] dense_12 (Dense)             (None, 12)                396       
2019-12-23 12:35:54,847 [INFO] =================================================================
2019-12-23 12:35:54,847 [INFO] Total params: 3,052
2019-12-23 12:35:54,847 [INFO] Trainable params: 2,988
2019-12-23 12:35:54,847 [INFO] Non-trainable params: 64
2019-12-23 12:35:54,847 [INFO] _________________________________________________________________
2019-12-23 12:35:55,271 [INFO] Fine-tuning final neural network
 - val_f1: 0.9953
Epoch 00115: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.16, time = 4.51s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.76, time = 7.44s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -28.09, time = 7.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -30.12, time = 7.15s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -32.55, time = 7.18s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.81, time = 7.16s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.70, time = 7.15s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -38.28, time = 7.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -39.66, time = 7.14s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -40.92, time = 7.13s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -42.11, time = 7.12s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -43.24, time = 7.11s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -44.36, time = 7.11s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -45.44, time = 7.10s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -46.52, time = 7.10s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -47.58, time = 7.10s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -48.64, time = 7.09s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -49.70, time = 7.09s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -50.76, time = 7.09s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -51.83, time = 7.08s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -52.89, time = 7.08s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -53.96, time = 7.03s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.03, time = 6.99s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.10, time = 6.92s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.16, time = 6.86s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -58.24, time = 6.84s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -59.31, time = 6.80s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -60.38, time = 6.79s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -61.45, time = 6.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -62.52, time = 6.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -63.60, time = 6.76s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -64.68, time = 6.75s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -65.75, time = 6.74s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -66.84, time = 6.74s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -67.92, time = 6.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -69.00, time = 6.73s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -70.09, time = 6.74s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -71.17, time = 6.73s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -72.26, time = 6.73s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -73.35, time = 6.73s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -74.44, time = 6.74s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -75.53, time = 6.73s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -76.62, time = 6.74s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -77.72, time = 6.73s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -78.82, time = 6.73s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -79.92, time = 6.73s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -81.01, time = 6.73s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -82.10, time = 6.73s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -83.20, time = 6.72s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -84.30, time = 6.72s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0849 - val_loss: 0.0563
 - val_f1: 0.8532
Epoch 2/300
 - 9s - loss: 0.0564 - val_loss: 0.0493
 - val_f1: 0.8590
Epoch 3/300
 - 9s - loss: 0.0446 - val_loss: 0.0315
 - val_f1: 0.9264
Epoch 4/300
 - 9s - loss: 0.0345 - val_loss: 0.0263
 - val_f1: 0.9415
Epoch 5/300
 - 9s - loss: 0.0301 - val_loss: 0.0227
 - val_f1: 0.9524
Epoch 6/300
 - 9s - loss: 0.0266 - val_loss: 0.0191
 - val_f1: 0.9595
Epoch 7/300
 - 9s - loss: 0.0241 - val_loss: 0.0172
 - val_f1: 0.9620
Epoch 8/300
 - 9s - loss: 0.0225 - val_loss: 0.0164
 - val_f1: 0.9636
Epoch 9/300
 - 9s - loss: 0.0208 - val_loss: 0.0155
 - val_f1: 0.9641
Epoch 10/300
 - 9s - loss: 0.0195 - val_loss: 0.0142
 - val_f1: 0.9659
Epoch 11/300
 - 9s - loss: 0.0185 - val_loss: 0.0150
 - val_f1: 0.9647
Epoch 12/300
 - 9s - loss: 0.0178 - val_loss: 0.0132
 - val_f1: 0.9662
Epoch 13/300
 - 9s - loss: 0.0171 - val_loss: 0.0123
 - val_f1: 0.9698
Epoch 14/300
 - 9s - loss: 0.0164 - val_loss: 0.0119
 - val_f1: 0.9700
Epoch 15/300
 - 9s - loss: 0.0157 - val_loss: 0.0116
 - val_f1: 0.9696
Epoch 16/300
 - 9s - loss: 0.0151 - val_loss: 0.0110
 - val_f1: 0.9754
Epoch 17/300
 - 9s - loss: 0.0147 - val_loss: 0.0106
 - val_f1: 0.9717
Epoch 18/300
 - 9s - loss: 0.0142 - val_loss: 0.0101
 - val_f1: 0.9789
Epoch 19/300
 - 9s - loss: 0.0136 - val_loss: 0.0096
 - val_f1: 0.9799
Epoch 20/300
 - 9s - loss: 0.0130 - val_loss: 0.0090
 - val_f1: 0.9837
Epoch 21/300
 - 9s - loss: 0.0124 - val_loss: 0.0082
 - val_f1: 0.9845
Epoch 22/300
 - 9s - loss: 0.0118 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 23/300
 - 9s - loss: 0.0112 - val_loss: 0.0074
 - val_f1: 0.9850
Epoch 24/300
 - 9s - loss: 0.0107 - val_loss: 0.0070
 - val_f1: 0.9850
Epoch 25/300
 - 9s - loss: 0.0102 - val_loss: 0.0068
 - val_f1: 0.9850
Epoch 26/300
 - 9s - loss: 0.0098 - val_loss: 0.0064
 - val_f1: 0.9870
Epoch 27/300
 - 9s - loss: 0.0094 - val_loss: 0.0061
 - val_f1: 0.9874
Epoch 28/300
 - 9s - loss: 0.0091 - val_loss: 0.0060
 - val_f1: 0.9905
Epoch 29/300
 - 9s - loss: 0.0089 - val_loss: 0.0058
 - val_f1: 0.9891
Epoch 30/300
 - 9s - loss: 0.0087 - val_loss: 0.0060
 - val_f1: 0.9857
Epoch 31/300
 - 9s - loss: 0.0085 - val_loss: 0.0056
2019-12-23 12:45:09,134 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9885
Epoch 32/300
 - 9s - loss: 0.0083 - val_loss: 0.0055
 - val_f1: 0.9917
Epoch 33/300
 - 9s - loss: 0.0082 - val_loss: 0.0056
 - val_f1: 0.9890
Epoch 34/300
 - 9s - loss: 0.0081 - val_loss: 0.0052
 - val_f1: 0.9911
Epoch 35/300
 - 9s - loss: 0.0079 - val_loss: 0.0050
 - val_f1: 0.9919
Epoch 36/300
 - 9s - loss: 0.0078 - val_loss: 0.0050
 - val_f1: 0.9922
Epoch 37/300
 - 9s - loss: 0.0076 - val_loss: 0.0049
 - val_f1: 0.9919
Epoch 38/300
 - 9s - loss: 0.0075 - val_loss: 0.0049
 - val_f1: 0.9920
Epoch 39/300
 - 9s - loss: 0.0074 - val_loss: 0.0048
 - val_f1: 0.9924
Epoch 40/300
 - 9s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 41/300
 - 9s - loss: 0.0072 - val_loss: 0.0047
 - val_f1: 0.9902
Epoch 42/300
 - 9s - loss: 0.0071 - val_loss: 0.0049
 - val_f1: 0.9908
Epoch 43/300
 - 9s - loss: 0.0070 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 44/300
 - 9s - loss: 0.0069 - val_loss: 0.0050
 - val_f1: 0.9898
Epoch 45/300
 - 9s - loss: 0.0069 - val_loss: 0.0045
 - val_f1: 0.9923
Epoch 46/300
 - 9s - loss: 0.0067 - val_loss: 0.0050
 - val_f1: 0.9902
Epoch 47/300
 - 9s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9928
Epoch 48/300
 - 9s - loss: 0.0066 - val_loss: 0.0048
 - val_f1: 0.9908
Epoch 49/300
 - 9s - loss: 0.0065 - val_loss: 0.0046
 - val_f1: 0.9912
Epoch 50/300
 - 9s - loss: 0.0065 - val_loss: 0.0049
 - val_f1: 0.9906
Epoch 51/300
 - 9s - loss: 0.0064 - val_loss: 0.0044
 - val_f1: 0.9925
Epoch 52/300
 - 9s - loss: 0.0064 - val_loss: 0.0044
 - val_f1: 0.9931
Epoch 53/300
 - 9s - loss: 0.0063 - val_loss: 0.0042
 - val_f1: 0.9933
Epoch 54/300
 - 9s - loss: 0.0063 - val_loss: 0.0046
 - val_f1: 0.9909
Epoch 55/300
 - 9s - loss: 0.0062 - val_loss: 0.0045
 - val_f1: 0.9908
Epoch 56/300
 - 9s - loss: 0.0061 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 57/300
 - 9s - loss: 0.0062 - val_loss: 0.0044
 - val_f1: 0.9909
Epoch 58/300
 - 9s - loss: 0.0061 - val_loss: 0.0042
 - val_f1: 0.9927
Epoch 59/300
 - 9s - loss: 0.0061 - val_loss: 0.0043
 - val_f1: 0.9911
Epoch 60/300
 - 9s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9932
Epoch 61/300
 - 9s - loss: 0.0060 - val_loss: 0.0043
2019-12-23 12:54:12,170 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9930
Epoch 62/300
 - 9s - loss: 0.0060 - val_loss: 0.0046
 - val_f1: 0.9915
Epoch 63/300
 - 9s - loss: 0.0059 - val_loss: 0.0042
 - val_f1: 0.9933
Epoch 64/300
 - 9s - loss: 0.0059 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 65/300
 - 9s - loss: 0.0059 - val_loss: 0.0048
 - val_f1: 0.9909
Epoch 66/300
 - 9s - loss: 0.0058 - val_loss: 0.0041
 - val_f1: 0.9933
Epoch 67/300
 - 9s - loss: 0.0058 - val_loss: 0.0052
 - val_f1: 0.9901
Epoch 68/300
 - 9s - loss: 0.0057 - val_loss: 0.0042
 - val_f1: 0.9916
Epoch 69/300
 - 9s - loss: 0.0058 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 70/300
 - 9s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9933
Epoch 71/300
 - 9s - loss: 0.0057 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 72/300
 - 9s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 73/300
 - 9s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9930
Epoch 74/300
 - 9s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9922
Epoch 75/300
 - 9s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9933
Epoch 76/300
 - 9s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9929
Epoch 77/300
 - 9s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 78/300
 - 9s - loss: 0.0055 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 79/300
 - 9s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 80/300
 - 9s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 81/300
 - 9s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9913
Epoch 82/300
 - 9s - loss: 0.0054 - val_loss: 0.0038
 - val_f1: 0.9938
Epoch 83/300
 - 9s - loss: 0.0053 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 84/300
 - 9s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 85/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9938
Epoch 86/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9936
Epoch 87/300
 - 9s - loss: 0.0053 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 88/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 89/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9937
Epoch 90/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 91/300
 - 9s - loss: 0.0052 - val_loss: 0.0043
2019-12-23 13:03:14,881 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9914
Epoch 92/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9913
Epoch 93/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 94/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9938
Epoch 95/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 96/300
 - 9s - loss: 0.0052 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 97/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9939
Epoch 98/300
 - 9s - loss: 0.0052 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 99/300
 - 9s - loss: 0.0051 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 100/300
 - 9s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 101/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9937
Epoch 102/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9937
Epoch 103/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9930
Epoch 104/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 105/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 106/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 107/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 108/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 109/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 110/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9916
Epoch 111/300
 - 9s - loss: 0.0050 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 112/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 113/300
 - 9s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9935
Epoch 114/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 115/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9938
Epoch 116/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 117/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 118/300
 - 9s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 119/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9940
Epoch 120/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 121/300
 - 9s - loss: 0.0049 - val_loss: 0.0038
2019-12-23 13:12:18,083 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9934
Epoch 122/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 123/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 124/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 125/300
 - 9s - loss: 0.0049 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 126/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9914
Epoch 127/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 128/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9913
Epoch 129/300
 - 9s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 130/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 131/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 132/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 133/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 134/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9941
Epoch 135/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 136/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 137/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 138/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 139/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 140/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 141/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9939
Epoch 142/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 143/300
 - 9s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 144/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 145/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9917
Epoch 146/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 147/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 148/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9942
Epoch 149/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 150/300
 - 9s - loss: 0.0047 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 151/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
2019-12-23 13:21:22,412 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9934
Epoch 152/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 153/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 154/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 155/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 156/300
 - 9s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 157/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 158/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 159/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 160/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 161/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 162/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 163/300
 - 9s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 164/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 165/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 166/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 167/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9909
Epoch 168/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 169/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 170/300
 - 9s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 171/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9942
Epoch 172/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 173/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 174/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 175/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 176/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 177/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 178/300
 - 9s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 179/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 180/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9915
Epoch 181/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
2019-12-23 13:30:27,592 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9940
Epoch 182/300
 - 9s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 183/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 184/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 185/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 186/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 187/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 188/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 189/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 190/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 191/300
 - 9s - loss: 0.0044 - val_loss: 0.0045
 - val_f1: 0.9915
Epoch 192/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 193/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 194/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 195/300
 - 9s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 196/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 197/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 198/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9913
Epoch 199/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 200/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 201/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 202/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9922
Epoch 203/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 204/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 205/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 206/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 207/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9926
Epoch 208/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 209/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9919
Epoch 210/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 211/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
2019-12-23 13:39:33,231 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9943
Epoch 212/300
 - 9s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 213/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 214/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 215/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 216/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 217/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 218/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 219/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9943
Epoch 220/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 221/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 222/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9916
Epoch 223/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9945
Epoch 224/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 225/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9916
Epoch 226/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 227/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 228/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 229/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9945
Epoch 230/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 231/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 232/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 233/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 234/300
 - 9s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9919
Epoch 235/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9944
Epoch 236/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 237/300
 - 9s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 238/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 239/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 240/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 241/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
2019-12-23 13:48:39,192 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9947
Epoch 242/300
 - 9s - loss: 0.0041 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 243/300
 - 9s - loss: 0.0040 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 244/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 245/300
 - 9s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 246/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 247/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 248/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 249/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 250/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 251/300
 - 9s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 252/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 253/300
 - 9s - loss: 0.0040 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 254/300
 - 9s - loss: 0.0040 - val_loss: 0.0038
 - val_f1: 0.9924
Epoch 255/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 256/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 257/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 258/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 259/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9922
Epoch 260/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 261/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 262/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 263/300
 - 9s - loss: 0.0040 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 264/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 265/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9929
Epoch 266/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9922
Epoch 267/300
 - 9s - loss: 0.0040 - val_loss: 0.0037
 - val_f1: 0.9914
Epoch 268/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9928
Epoch 269/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 270/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 271/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
2019-12-23 13:57:45,355 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9945
Epoch 272/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9922
Epoch 273/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 274/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9946
Epoch 275/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9946
Epoch 276/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 277/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9928
Epoch 278/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 279/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9918
Epoch 280/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9928
Epoch 281/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9923
Epoch 282/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 283/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 284/300
 - 9s - loss: 0.0039 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 285/300
 - 9s - loss: 0.0039 - val_loss: 0.0032
 - val_f1: 0.9933
Epoch 286/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9917
Epoch 287/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 288/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9930
Epoch 289/300
 - 9s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 290/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9918
Epoch 291/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 292/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9919
Epoch 293/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9944
Epoch 294/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 295/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 296/300
 - 9s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9945
Epoch 297/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
 - val_f1: 0.9929
Epoch 298/300
 - 9s - loss: 0.0039 - val_loss: 0.0028
 - val_f1: 0.9949
Epoch 299/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 300/300
 - 9s - loss: 0.0039 - val_loss: 0.0030
2019-12-23 14:06:41,988 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 14:07:05,743 [INFO] Last epoch loss evaluation: train_loss = 0.002675, val_loss = 0.002788
2019-12-23 14:07:05,782 [INFO] Training complete. time_to_train = 5834.92 sec, 97.25 min
2019-12-23 14:07:05,786 [INFO] Model saved to results_selected_models/selected_ids17_dbn_shallow_rep1/best_model.pickle
2019-12-23 14:07:05,915 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep1/training_error_history.png
2019-12-23 14:07:06,045 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep1/training_f1_history.png
2019-12-23 14:07:06,045 [INFO] Making predictions on training, validation, testing data
2019-12-23 14:07:49,014 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 14:07:59,388 [INFO] Dataset: Testing. Classification report below
2019-12-23 14:07:59,388 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.98      2058
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.87      0.93      0.90      1100
         DoS slowloris       0.98      0.90      0.94      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.66      0.83      0.73       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       1.00      1.00      1.00    565562
             macro avg       0.86      0.83      0.83    565562
          weighted avg       0.99      1.00      0.99    565562

2019-12-23 14:07:59,388 [INFO] Overall accuracy (micro avg): 0.9950032003564596
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 14:08:11,165 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9950         0.9950                       0.9950                0.0005                   0.0050  0.9950
1     Macro avg        0.9992         0.8630                       0.8296                0.0009                   0.1704  0.8339
2  Weighted avg        0.9961         0.9949                       0.9950                0.0054                   0.0050  0.9948
2019-12-23 14:08:21,628 [INFO] Dataset: Validation. Classification report below
2019-12-23 14:08:21,628 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.48       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.95      0.97      2059
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.88      0.92      0.90      1099
         DoS slowloris       0.98      0.91      0.94      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.66      0.83      0.73       301
        Web Attack XSS       1.00      0.02      0.03       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.95      0.83      0.83    565562
          weighted avg       1.00      0.99      0.99    565562

2019-12-23 14:08:21,628 [INFO] Overall accuracy (micro avg): 0.9949377787050756
2019-12-23 14:08:33,526 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9992         0.9490                       0.8253                0.0009                   0.1747  0.8321
2  Weighted avg        0.9960         0.9951                       0.9949                0.0057                   0.0051  0.9947
2019-12-23 14:09:08,046 [INFO] Dataset: Training. Classification report below
2019-12-23 14:09:08,047 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.99      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.96      0.97      6176
              DoS Hulk       0.97      1.00      0.98    138074
      DoS Slowhttptest       0.88      0.93      0.91      3300
         DoS slowloris       0.98      0.92      0.94      3478
           FTP-Patator       1.00      1.00      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.68      0.87      0.77       904
        Web Attack XSS       0.92      0.03      0.06       391

             micro avg       1.00      1.00      1.00   1696684
             macro avg       0.95      0.84      0.84   1696684
          weighted avg       1.00      1.00      0.99   1696684

2019-12-23 14:09:08,047 [INFO] Overall accuracy (micro avg): 0.9951452362372722
2019-12-23 14:09:47,257 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9951         0.9951                       0.9951                0.0004                   0.0049  0.9951
1     Macro avg        0.9992         0.9463                       0.8358                0.0008                   0.1642  0.8429
2  Weighted avg        0.9962         0.9953                       0.9951                0.0053                   0.0049  0.9950
2019-12-23 14:09:47,307 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_shallow_rep1/selected_ids17_dbn_shallow_rep1_results.xlsx
2019-12-23 14:09:47,311 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 14:09:47,378 [INFO] Created directory: results_selected_models/selected_ids17_dbn_shallow_rep2
2019-12-23 14:09:47,379 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_shallow_rep2/run_log.log
2019-12-23 14:09:47,379 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 14:09:47,379 [INFO] Experiment parameters given below
2019-12-23 14:09:47,379 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids17_dbn_shallow_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_shallow_rep2'}
2019-12-23 14:09:47,379 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_shallow_rep2/tf_logs_run_2019_12_23-14_09_47
2019-12-23 14:09:47,379 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 14:09:47,379 [INFO] Reading X, y files
2019-12-23 14:09:47,379 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 14:09:51,577 [INFO] Reading complete. time_to_read=4.20 seconds
2019-12-23 14:09:51,577 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 14:09:53,010 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-23 14:09:53,010 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 14:09:54,445 [INFO] Reading complete. time_to_read=1.44 seconds
2019-12-23 14:09:54,446 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 14:09:54,662 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-23 14:09:54,662 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 14:09:54,735 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:09:54,735 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 14:09:54,809 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 14:09:58,225 [INFO] Initializing model
2019-12-23 14:09:58,226 [INFO] Training model
2019-12-23 14:09:58,226 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 14:10:16,083 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = b352d3873fe1e8ee64e88e6f1612433351201d67
2019-12-23 14:10:16,083 [INFO] Pretraining Deep Belief Network
2019-12-23 14:16:02,482 [INFO] Pretraining Complete
2019-12-23 14:16:02,482 [INFO] Getting pretrained weights
2019-12-23 14:16:02,482 [INFO] Creating and initializing feed forward neural network
2019-12-23 14:16:02,598 [INFO] _________________________________________________________________
2019-12-23 14:16:02,599 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 14:16:02,599 [INFO] =================================================================
2019-12-23 14:16:02,599 [INFO] dense_13 (Dense)             (None, 32)                2528      
2019-12-23 14:16:02,599 [INFO] _________________________________________________________________
2019-12-23 14:16:02,599 [INFO] batch_normalization_7 (Batch (None, 32)                128       
2019-12-23 14:16:02,599 [INFO] _________________________________________________________________
2019-12-23 14:16:02,599 [INFO] dropout_7 (Dropout)          (None, 32)                0         
2019-12-23 14:16:02,599 [INFO] _________________________________________________________________
2019-12-23 14:16:02,599 [INFO] dense_14 (Dense)             (None, 12)                396       
2019-12-23 14:16:02,599 [INFO] =================================================================
2019-12-23 14:16:02,599 [INFO] Total params: 3,052
2019-12-23 14:16:02,599 [INFO] Trainable params: 2,988
2019-12-23 14:16:02,600 [INFO] Non-trainable params: 64
2019-12-23 14:16:02,600 [INFO] _________________________________________________________________
2019-12-23 14:16:03,102 [INFO] Fine-tuning final neural network
 - val_f1: 0.9943
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.00, time = 4.53s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.55, time = 7.41s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -27.88, time = 7.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -29.89, time = 7.16s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -32.25, time = 7.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.45, time = 7.18s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.29, time = 7.16s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -37.83, time = 7.16s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -39.18, time = 7.15s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -40.41, time = 7.14s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -41.57, time = 7.14s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -42.69, time = 7.13s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -43.78, time = 7.12s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -44.84, time = 7.11s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -45.89, time = 7.11s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -46.94, time = 7.10s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -47.98, time = 7.10s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -49.03, time = 7.11s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -50.07, time = 7.10s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -51.12, time = 7.09s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -52.16, time = 7.09s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -53.21, time = 7.04s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -54.26, time = 7.00s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -55.30, time = 6.93s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -56.35, time = 6.87s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -57.40, time = 6.84s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -58.45, time = 6.82s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -59.49, time = 6.80s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -60.54, time = 6.78s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -61.59, time = 6.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -62.64, time = 6.76s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -63.69, time = 6.76s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -64.74, time = 6.75s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -65.80, time = 6.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -66.86, time = 6.75s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -67.91, time = 6.75s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -68.97, time = 6.74s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -70.03, time = 6.74s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -71.09, time = 6.74s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -72.15, time = 6.74s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -73.21, time = 6.74s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -74.28, time = 6.74s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -75.34, time = 6.74s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -76.41, time = 6.74s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -77.48, time = 6.75s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -78.55, time = 6.74s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -79.61, time = 6.74s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -80.67, time = 6.73s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -81.74, time = 6.73s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -82.82, time = 6.73s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0862 - val_loss: 0.0561
 - val_f1: 0.8532
Epoch 2/300
 - 9s - loss: 0.0559 - val_loss: 0.0444
 - val_f1: 0.9036
Epoch 3/300
 - 9s - loss: 0.0408 - val_loss: 0.0314
 - val_f1: 0.9314
Epoch 4/300
 - 9s - loss: 0.0322 - val_loss: 0.0223
 - val_f1: 0.9552
Epoch 5/300
 - 9s - loss: 0.0271 - val_loss: 0.0190
 - val_f1: 0.9603
Epoch 6/300
 - 9s - loss: 0.0241 - val_loss: 0.0175
 - val_f1: 0.9624
Epoch 7/300
 - 9s - loss: 0.0221 - val_loss: 0.0162
 - val_f1: 0.9640
Epoch 8/300
 - 9s - loss: 0.0206 - val_loss: 0.0153
 - val_f1: 0.9652
Epoch 9/300
 - 9s - loss: 0.0196 - val_loss: 0.0149
 - val_f1: 0.9662
Epoch 10/300
 - 9s - loss: 0.0189 - val_loss: 0.0143
 - val_f1: 0.9669
Epoch 11/300
 - 9s - loss: 0.0182 - val_loss: 0.0138
 - val_f1: 0.9687
Epoch 12/300
 - 9s - loss: 0.0177 - val_loss: 0.0131
 - val_f1: 0.9681
Epoch 13/300
 - 9s - loss: 0.0170 - val_loss: 0.0126
 - val_f1: 0.9695
Epoch 14/300
 - 9s - loss: 0.0163 - val_loss: 0.0124
 - val_f1: 0.9701
Epoch 15/300
 - 9s - loss: 0.0158 - val_loss: 0.0117
 - val_f1: 0.9706
Epoch 16/300
 - 9s - loss: 0.0153 - val_loss: 0.0114
 - val_f1: 0.9708
Epoch 17/300
 - 9s - loss: 0.0149 - val_loss: 0.0110
 - val_f1: 0.9770
Epoch 18/300
 - 9s - loss: 0.0144 - val_loss: 0.0106
 - val_f1: 0.9730
Epoch 19/300
 - 9s - loss: 0.0141 - val_loss: 0.0104
 - val_f1: 0.9731
Epoch 20/300
 - 9s - loss: 0.0136 - val_loss: 0.0100
 - val_f1: 0.9779
Epoch 21/300
 - 9s - loss: 0.0132 - val_loss: 0.0093
 - val_f1: 0.9803
Epoch 22/300
 - 9s - loss: 0.0126 - val_loss: 0.0087
 - val_f1: 0.9829
Epoch 23/300
 - 9s - loss: 0.0121 - val_loss: 0.0081
 - val_f1: 0.9848
Epoch 24/300
 - 9s - loss: 0.0116 - val_loss: 0.0077
 - val_f1: 0.9874
Epoch 25/300
 - 9s - loss: 0.0111 - val_loss: 0.0075
 - val_f1: 0.9888
Epoch 26/300
 - 9s - loss: 0.0106 - val_loss: 0.0069
 - val_f1: 0.9897
Epoch 27/300
 - 9s - loss: 0.0102 - val_loss: 0.0066
 - val_f1: 0.9904
Epoch 28/300
 - 9s - loss: 0.0097 - val_loss: 0.0065
 - val_f1: 0.9874
Epoch 29/300
 - 9s - loss: 0.0094 - val_loss: 0.0078
 - val_f1: 0.9835
Epoch 30/300
 - 9s - loss: 0.0091 - val_loss: 0.0062
 - val_f1: 0.9866
Epoch 31/300
 - 9s - loss: 0.0088 - val_loss: 0.0055
2019-12-23 14:25:31,213 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9876
Epoch 32/300
 - 9s - loss: 0.0085 - val_loss: 0.0054
 - val_f1: 0.9891
Epoch 33/300
 - 9s - loss: 0.0083 - val_loss: 0.0053
 - val_f1: 0.9914
Epoch 34/300
 - 9s - loss: 0.0080 - val_loss: 0.0069
 - val_f1: 0.9847
Epoch 35/300
 - 9s - loss: 0.0079 - val_loss: 0.0064
 - val_f1: 0.9859
Epoch 36/300
 - 9s - loss: 0.0077 - val_loss: 0.0049
 - val_f1: 0.9901
Epoch 37/300
 - 9s - loss: 0.0076 - val_loss: 0.0048
 - val_f1: 0.9922
Epoch 38/300
 - 9s - loss: 0.0075 - val_loss: 0.0047
 - val_f1: 0.9891
Epoch 39/300
 - 9s - loss: 0.0073 - val_loss: 0.0048
 - val_f1: 0.9922
Epoch 40/300
 - 9s - loss: 0.0072 - val_loss: 0.0053
 - val_f1: 0.9901
Epoch 41/300
 - 9s - loss: 0.0071 - val_loss: 0.0067
 - val_f1: 0.9844
Epoch 42/300
 - 9s - loss: 0.0070 - val_loss: 0.0045
 - val_f1: 0.9923
Epoch 43/300
 - 9s - loss: 0.0070 - val_loss: 0.0050
 - val_f1: 0.9897
Epoch 44/300
 - 9s - loss: 0.0069 - val_loss: 0.0050
 - val_f1: 0.9896
Epoch 45/300
 - 9s - loss: 0.0068 - val_loss: 0.0044
 - val_f1: 0.9911
Epoch 46/300
 - 9s - loss: 0.0067 - val_loss: 0.0048
 - val_f1: 0.9916
Epoch 47/300
 - 9s - loss: 0.0066 - val_loss: 0.0042
 - val_f1: 0.9926
Epoch 48/300
 - 9s - loss: 0.0066 - val_loss: 0.0049
 - val_f1: 0.9891
Epoch 49/300
 - 9s - loss: 0.0066 - val_loss: 0.0042
 - val_f1: 0.9926
Epoch 50/300
 - 9s - loss: 0.0064 - val_loss: 0.0044
 - val_f1: 0.9904
Epoch 51/300
 - 9s - loss: 0.0063 - val_loss: 0.0043
 - val_f1: 0.9922
Epoch 52/300
 - 9s - loss: 0.0063 - val_loss: 0.0042
 - val_f1: 0.9924
Epoch 53/300
 - 9s - loss: 0.0063 - val_loss: 0.0047
 - val_f1: 0.9897
Epoch 54/300
 - 9s - loss: 0.0061 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 55/300
 - 9s - loss: 0.0061 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 56/300
 - 9s - loss: 0.0060 - val_loss: 0.0043
 - val_f1: 0.9902
Epoch 57/300
 - 9s - loss: 0.0061 - val_loss: 0.0040
 - val_f1: 0.9904
Epoch 58/300
 - 9s - loss: 0.0060 - val_loss: 0.0041
 - val_f1: 0.9908
Epoch 59/300
 - 9s - loss: 0.0059 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 60/300
 - 9s - loss: 0.0059 - val_loss: 0.0040
 - val_f1: 0.9927
Epoch 61/300
 - 9s - loss: 0.0059 - val_loss: 0.0042
2019-12-23 14:34:52,783 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9912
Epoch 62/300
 - 9s - loss: 0.0059 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 63/300
 - 9s - loss: 0.0058 - val_loss: 0.0040
 - val_f1: 0.9908
Epoch 64/300
 - 9s - loss: 0.0058 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 65/300
 - 9s - loss: 0.0058 - val_loss: 0.0038
 - val_f1: 0.9931
Epoch 66/300
 - 9s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9908
Epoch 67/300
 - 9s - loss: 0.0057 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 68/300
 - 9s - loss: 0.0057 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 69/300
 - 9s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 70/300
 - 9s - loss: 0.0057 - val_loss: 0.0039
 - val_f1: 0.9913
Epoch 71/300
 - 9s - loss: 0.0057 - val_loss: 0.0039
 - val_f1: 0.9915
Epoch 72/300
 - 9s - loss: 0.0057 - val_loss: 0.0038
 - val_f1: 0.9929
Epoch 73/300
 - 9s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9908
Epoch 74/300
 - 9s - loss: 0.0056 - val_loss: 0.0038
 - val_f1: 0.9915
Epoch 75/300
 - 9s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9926
Epoch 76/300
 - 9s - loss: 0.0055 - val_loss: 0.0038
 - val_f1: 0.9912
Epoch 77/300
 - 9s - loss: 0.0055 - val_loss: 0.0038
 - val_f1: 0.9934
Epoch 78/300
 - 9s - loss: 0.0055 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 79/300
 - 9s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9913
Epoch 80/300
 - 9s - loss: 0.0055 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 81/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 82/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 83/300
 - 9s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9925
Epoch 84/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9923
Epoch 85/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 86/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9913
Epoch 87/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9932
Epoch 88/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 89/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 90/300
 - 9s - loss: 0.0052 - val_loss: 0.0044
 - val_f1: 0.9922
Epoch 91/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
2019-12-23 14:44:14,963 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9927
Epoch 92/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9911
Epoch 93/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9910
Epoch 94/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9915
Epoch 95/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 96/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9916
Epoch 97/300
 - 9s - loss: 0.0051 - val_loss: 0.0041
 - val_f1: 0.9909
Epoch 98/300
 - 9s - loss: 0.0051 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 99/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 100/300
 - 9s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 101/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 102/300
 - 9s - loss: 0.0050 - val_loss: 0.0043
 - val_f1: 0.9927
Epoch 103/300
 - 9s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9917
Epoch 104/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 105/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9917
Epoch 106/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 107/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 108/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9913
Epoch 109/300
 - 9s - loss: 0.0050 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 110/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 111/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9929
Epoch 112/300
 - 9s - loss: 0.0048 - val_loss: 0.0042
 - val_f1: 0.9923
Epoch 113/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9912
Epoch 114/300
 - 9s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 115/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 116/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 117/300
 - 9s - loss: 0.0048 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 118/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 119/300
 - 9s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9914
Epoch 120/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 121/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
2019-12-23 14:53:37,196 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9933
Epoch 122/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 123/300
 - 9s - loss: 0.0048 - val_loss: 0.0046
 - val_f1: 0.9923
Epoch 124/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9918
Epoch 125/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9913
Epoch 126/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 127/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9921
Epoch 128/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 129/300
 - 9s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 130/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 131/300
 - 9s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9928
Epoch 132/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 133/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 134/300
 - 9s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9913
Epoch 135/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 136/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 137/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 138/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9914
Epoch 139/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 140/300
 - 9s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9935
Epoch 141/300
 - 9s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 142/300
 - 9s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 143/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 144/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9934
Epoch 145/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 146/300
 - 9s - loss: 0.0047 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 147/300
 - 9s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 148/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 149/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 150/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 151/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
2019-12-23 15:02:59,968 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9911
Epoch 152/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 153/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 154/300
 - 9s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 155/300
 - 9s - loss: 0.0046 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 156/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 157/300
 - 9s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 158/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 159/300
 - 9s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 160/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9921
Epoch 161/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 162/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 163/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 164/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 165/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9943
Epoch 166/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 167/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 168/300
 - 9s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9919
Epoch 169/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 170/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 171/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 172/300
 - 9s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 173/300
 - 9s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 174/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 175/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 176/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 177/300
 - 9s - loss: 0.0044 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 178/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 179/300
 - 9s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 180/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 181/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
2019-12-23 15:12:22,469 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9939
Epoch 182/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 183/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 184/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 185/300
 - 9s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 186/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 187/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 188/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 189/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9919
Epoch 190/300
 - 9s - loss: 0.0044 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 191/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 192/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 193/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 194/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9934
Epoch 195/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 196/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 197/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9918
Epoch 198/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 199/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 200/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9912
Epoch 201/300
 - 9s - loss: 0.0043 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 202/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 203/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9919
Epoch 204/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 205/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 206/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 207/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 208/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 209/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 210/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 211/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
2019-12-23 15:21:44,645 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9943
Epoch 212/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 213/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 214/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 215/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 216/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 217/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 218/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 219/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 220/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 221/300
 - 9s - loss: 0.0044 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 222/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 223/300
 - 9s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 224/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 225/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 226/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 227/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 228/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 229/300
 - 9s - loss: 0.0043 - val_loss: 0.0043
 - val_f1: 0.9914
Epoch 230/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 231/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 232/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 233/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9942
Epoch 234/300
 - 9s - loss: 0.0042 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 235/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 236/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 237/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 238/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 239/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 240/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 241/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
2019-12-23 15:31:06,524 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9924
Epoch 242/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 243/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9940
Epoch 244/300
 - 9s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9917
Epoch 245/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 246/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9946
Epoch 247/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 248/300
 - 9s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 249/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 250/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 251/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9921
Epoch 252/300
 - 9s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 253/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 254/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 255/300
 - 9s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 256/300
 - 9s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9923
Epoch 257/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9938
Epoch 258/300
 - 9s - loss: 0.0041 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 259/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 260/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9934
Epoch 261/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 262/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9948
Epoch 263/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9920
Epoch 264/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 265/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 266/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 267/300
 - 9s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 268/300
 - 9s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 269/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9920
Epoch 270/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 271/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
2019-12-23 15:40:27,596 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9946
Epoch 272/300
 - 9s - loss: 0.0041 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 273/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9921
Epoch 274/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9918
Epoch 275/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 276/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 277/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 278/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9920
Epoch 279/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 280/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9923
Epoch 281/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9918
Epoch 282/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9927
Epoch 283/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9942
Epoch 284/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 285/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 286/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9931
Epoch 287/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9923
Epoch 288/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 289/300
 - 9s - loss: 0.0040 - val_loss: 0.0040
 - val_f1: 0.9934
Epoch 290/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9922
Epoch 291/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 292/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 293/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9945
Epoch 294/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9919
Epoch 295/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 296/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 297/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9944
Epoch 298/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9924
Epoch 299/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9943
Epoch 300/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
2019-12-23 15:49:40,605 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 15:50:04,681 [INFO] Last epoch loss evaluation: train_loss = 0.002792, val_loss = 0.002858
2019-12-23 15:50:04,717 [INFO] Training complete. time_to_train = 6006.49 sec, 100.11 min
2019-12-23 15:50:04,721 [INFO] Model saved to results_selected_models/selected_ids17_dbn_shallow_rep2/best_model.pickle
2019-12-23 15:50:04,850 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep2/training_error_history.png
2019-12-23 15:50:04,979 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep2/training_f1_history.png
2019-12-23 15:50:04,979 [INFO] Making predictions on training, validation, testing data
2019-12-23 15:50:49,795 [INFO] Evaluating predictions (results)
2019-12-23 15:51:00,114 [INFO] Dataset: Testing. Classification report below
2019-12-23 15:51:00,114 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.97      2058
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.88      0.97      0.92      1100
         DoS slowloris       0.98      0.93      0.96      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.96      0.97      0.97      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.77      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 15:51:00,114 [INFO] Overall accuracy (micro avg): 0.9946018296844554
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 15:51:11,850 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0005                   0.0054  0.9946
1     Macro avg        0.9991         0.8115                       0.7653                0.0011                   0.2347  0.7766
2  Weighted avg        0.9955         0.9939                       0.9946                0.0081                   0.0054  0.9941
2019-12-23 15:51:22,329 [INFO] Dataset: Validation. Classification report below
2019-12-23 15:51:22,329 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.32      0.48       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.95      0.97      2059
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.88      0.96      0.92      1099
         DoS slowloris       0.98      0.93      0.96      1159
           FTP-Patator       1.00      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.97      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 15:51:22,329 [INFO] Overall accuracy (micro avg): 0.9944851316036084
2019-12-23 15:51:34,246 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9945         0.9945                       0.9945                0.0005                   0.0055  0.9945
1     Macro avg        0.9991         0.8123                       0.7594                0.0012                   0.2406  0.7717
2  Weighted avg        0.9954         0.9938                       0.9945                0.0085                   0.0055  0.9940
2019-12-23 15:52:08,875 [INFO] Dataset: Training. Classification report below
2019-12-23 15:52:08,875 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.52      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.96      0.97      6176
              DoS Hulk       0.97      1.00      0.98    138074
      DoS Slowhttptest       0.89      0.97      0.93      3300
         DoS slowloris       0.98      0.94      0.96      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.97      0.97      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.81      0.76      0.78   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-23 15:52:08,875 [INFO] Overall accuracy (micro avg): 0.9946701919744632
2019-12-23 15:52:48,192 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9947         0.9947                       0.9947                0.0005                   0.0053  0.9947
1     Macro avg        0.9991         0.8143                       0.7644                0.0011                   0.2356  0.7769
2  Weighted avg        0.9956         0.9940                       0.9947                0.0082                   0.0053  0.9942
2019-12-23 15:52:48,227 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_shallow_rep2/selected_ids17_dbn_shallow_rep2_results.xlsx
2019-12-23 15:52:48,234 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-23 15:52:48,300 [INFO] Created directory: results_selected_models/selected_ids17_dbn_shallow_rep3
2019-12-23 15:52:48,301 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_shallow_rep3/run_log.log
2019-12-23 15:52:48,301 [INFO] ================= Running experiment no. 3  ================= 

2019-12-23 15:52:48,301 [INFO] Experiment parameters given below
2019-12-23 15:52:48,301 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids17_dbn_shallow_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_shallow_rep3'}
2019-12-23 15:52:48,301 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_shallow_rep3/tf_logs_run_2019_12_23-15_52_48
2019-12-23 15:52:48,301 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 15:52:48,301 [INFO] Reading X, y files
2019-12-23 15:52:48,301 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 15:52:52,514 [INFO] Reading complete. time_to_read=4.21 seconds
2019-12-23 15:52:52,514 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 15:52:53,947 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-23 15:52:53,947 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 15:52:55,381 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-23 15:52:55,381 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 15:52:55,602 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-23 15:52:55,602 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 15:52:55,675 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 15:52:55,675 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 15:52:55,749 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 15:52:59,172 [INFO] Initializing model
2019-12-23 15:52:59,172 [INFO] Training model
2019-12-23 15:52:59,172 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 15:53:17,238 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = 093f597479124d98ea8f34684c4f2013e977c63d
2019-12-23 15:53:17,238 [INFO] Pretraining Deep Belief Network
2019-12-23 15:59:03,160 [INFO] Pretraining Complete
2019-12-23 15:59:03,160 [INFO] Getting pretrained weights
2019-12-23 15:59:03,160 [INFO] Creating and initializing feed forward neural network
2019-12-23 15:59:03,278 [INFO] _________________________________________________________________
2019-12-23 15:59:03,278 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 15:59:03,278 [INFO] =================================================================
2019-12-23 15:59:03,278 [INFO] dense_15 (Dense)             (None, 32)                2528      
2019-12-23 15:59:03,278 [INFO] _________________________________________________________________
2019-12-23 15:59:03,278 [INFO] batch_normalization_8 (Batch (None, 32)                128       
2019-12-23 15:59:03,278 [INFO] _________________________________________________________________
2019-12-23 15:59:03,278 [INFO] dropout_8 (Dropout)          (None, 32)                0         
2019-12-23 15:59:03,278 [INFO] _________________________________________________________________
2019-12-23 15:59:03,278 [INFO] dense_16 (Dense)             (None, 12)                396       
2019-12-23 15:59:03,278 [INFO] =================================================================
2019-12-23 15:59:03,279 [INFO] Total params: 3,052
2019-12-23 15:59:03,279 [INFO] Trainable params: 2,988
2019-12-23 15:59:03,279 [INFO] Non-trainable params: 64
2019-12-23 15:59:03,279 [INFO] _________________________________________________________________
2019-12-23 15:59:03,863 [INFO] Fine-tuning final neural network
 - val_f1: 0.9941
Epoch 00300: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.06, time = 4.51s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.66, time = 7.42s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -28.01, time = 7.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -30.06, time = 7.16s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -32.49, time = 7.18s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.75, time = 7.17s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.64, time = 7.15s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -38.22, time = 7.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -39.60, time = 7.14s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -40.86, time = 7.13s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -42.04, time = 7.12s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -43.18, time = 7.12s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -44.30, time = 7.11s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -45.39, time = 7.11s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -46.47, time = 7.11s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -47.54, time = 7.10s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -48.62, time = 7.09s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -49.69, time = 7.09s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -50.76, time = 7.09s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -51.83, time = 7.08s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -52.91, time = 7.07s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -53.99, time = 7.03s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.06, time = 6.99s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.14, time = 6.91s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.21, time = 6.86s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -58.30, time = 6.84s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -59.37, time = 6.80s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -60.45, time = 6.78s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -61.53, time = 6.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -62.62, time = 6.76s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -63.70, time = 6.76s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -64.79, time = 6.75s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -65.87, time = 6.74s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -66.97, time = 6.74s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -68.06, time = 6.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -69.15, time = 6.73s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -70.24, time = 6.73s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -71.34, time = 6.73s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -72.44, time = 6.73s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -73.53, time = 6.74s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -74.63, time = 6.73s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -75.73, time = 6.73s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -76.83, time = 6.73s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -77.93, time = 6.73s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -79.04, time = 6.73s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -80.14, time = 6.73s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -81.24, time = 6.72s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -82.34, time = 6.72s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -83.45, time = 6.72s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -84.56, time = 6.72s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 10s - loss: 0.0862 - val_loss: 0.0565
 - val_f1: 0.8541
Epoch 2/300
 - 9s - loss: 0.0570 - val_loss: 0.0507
 - val_f1: 0.8510
Epoch 3/300
 - 9s - loss: 0.0442 - val_loss: 0.0285
 - val_f1: 0.9406
Epoch 4/300
 - 10s - loss: 0.0289 - val_loss: 0.0213
 - val_f1: 0.9527
Epoch 5/300
 - 9s - loss: 0.0251 - val_loss: 0.0189
 - val_f1: 0.9579
Epoch 6/300
 - 9s - loss: 0.0225 - val_loss: 0.0168
 - val_f1: 0.9610
Epoch 7/300
 - 10s - loss: 0.0205 - val_loss: 0.0158
 - val_f1: 0.9639
Epoch 8/300
 - 9s - loss: 0.0192 - val_loss: 0.0142
 - val_f1: 0.9646
Epoch 9/300
 - 9s - loss: 0.0184 - val_loss: 0.0136
 - val_f1: 0.9660
Epoch 10/300
 - 9s - loss: 0.0177 - val_loss: 0.0132
 - val_f1: 0.9659
Epoch 11/300
 - 9s - loss: 0.0170 - val_loss: 0.0133
 - val_f1: 0.9659
Epoch 12/300
 - 9s - loss: 0.0165 - val_loss: 0.0123
 - val_f1: 0.9683
Epoch 13/300
 - 10s - loss: 0.0160 - val_loss: 0.0133
 - val_f1: 0.9669
Epoch 14/300
 - 10s - loss: 0.0154 - val_loss: 0.0114
 - val_f1: 0.9708
Epoch 15/300
 - 9s - loss: 0.0148 - val_loss: 0.0132
 - val_f1: 0.9696
Epoch 16/300
 - 9s - loss: 0.0142 - val_loss: 0.0121
 - val_f1: 0.9682
Epoch 17/300
 - 9s - loss: 0.0136 - val_loss: 0.0103
 - val_f1: 0.9723
Epoch 18/300
 - 9s - loss: 0.0132 - val_loss: 0.0098
 - val_f1: 0.9730
Epoch 19/300
 - 9s - loss: 0.0129 - val_loss: 0.0096
 - val_f1: 0.9741
Epoch 20/300
 - 9s - loss: 0.0125 - val_loss: 0.0093
 - val_f1: 0.9830
Epoch 21/300
 - 9s - loss: 0.0120 - val_loss: 0.0093
 - val_f1: 0.9839
Epoch 22/300
 - 9s - loss: 0.0116 - val_loss: 0.0084
 - val_f1: 0.9784
Epoch 23/300
 - 9s - loss: 0.0114 - val_loss: 0.0078
 - val_f1: 0.9849
Epoch 24/300
 - 10s - loss: 0.0109 - val_loss: 0.0078
 - val_f1: 0.9848
Epoch 25/300
 - 9s - loss: 0.0105 - val_loss: 0.0074
 - val_f1: 0.9848
Epoch 26/300
 - 9s - loss: 0.0100 - val_loss: 0.0066
 - val_f1: 0.9849
Epoch 27/300
 - 9s - loss: 0.0097 - val_loss: 0.0064
 - val_f1: 0.9873
Epoch 28/300
 - 9s - loss: 0.0094 - val_loss: 0.0061
 - val_f1: 0.9854
Epoch 29/300
 - 9s - loss: 0.0092 - val_loss: 0.0063
 - val_f1: 0.9854
Epoch 30/300
 - 9s - loss: 0.0088 - val_loss: 0.0063
 - val_f1: 0.9864
Epoch 31/300
 - 9s - loss: 0.0087 - val_loss: 0.0057
2019-12-23 16:08:49,089 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9883
Epoch 32/300
 - 9s - loss: 0.0084 - val_loss: 0.0053
 - val_f1: 0.9894
Epoch 33/300
 - 9s - loss: 0.0082 - val_loss: 0.0053
 - val_f1: 0.9890
Epoch 34/300
 - 9s - loss: 0.0080 - val_loss: 0.0052
 - val_f1: 0.9913
Epoch 35/300
 - 9s - loss: 0.0077 - val_loss: 0.0050
 - val_f1: 0.9894
Epoch 36/300
 - 9s - loss: 0.0076 - val_loss: 0.0048
 - val_f1: 0.9896
Epoch 37/300
 - 9s - loss: 0.0074 - val_loss: 0.0047
 - val_f1: 0.9915
Epoch 38/300
 - 9s - loss: 0.0073 - val_loss: 0.0046
 - val_f1: 0.9915
Epoch 39/300
 - 9s - loss: 0.0072 - val_loss: 0.0048
 - val_f1: 0.9915
Epoch 40/300
 - 9s - loss: 0.0070 - val_loss: 0.0046
 - val_f1: 0.9917
Epoch 41/300
 - 9s - loss: 0.0070 - val_loss: 0.0045
 - val_f1: 0.9927
Epoch 42/300
 - 9s - loss: 0.0069 - val_loss: 0.0045
 - val_f1: 0.9921
Epoch 43/300
 - 9s - loss: 0.0068 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 44/300
 - 9s - loss: 0.0067 - val_loss: 0.0044
 - val_f1: 0.9921
Epoch 45/300
 - 10s - loss: 0.0067 - val_loss: 0.0046
 - val_f1: 0.9920
Epoch 46/300
 - 9s - loss: 0.0066 - val_loss: 0.0044
 - val_f1: 0.9922
Epoch 47/300
 - 9s - loss: 0.0065 - val_loss: 0.0048
 - val_f1: 0.9911
Epoch 48/300
 - 9s - loss: 0.0064 - val_loss: 0.0049
 - val_f1: 0.9898
Epoch 49/300
 - 9s - loss: 0.0064 - val_loss: 0.0043
 - val_f1: 0.9928
Epoch 50/300
 - 9s - loss: 0.0063 - val_loss: 0.0043
 - val_f1: 0.9910
Epoch 51/300
 - 9s - loss: 0.0063 - val_loss: 0.0042
 - val_f1: 0.9909
Epoch 52/300
 - 10s - loss: 0.0062 - val_loss: 0.0044
 - val_f1: 0.9911
Epoch 53/300
 - 9s - loss: 0.0062 - val_loss: 0.0042
 - val_f1: 0.9905
Epoch 54/300
 - 9s - loss: 0.0062 - val_loss: 0.0041
 - val_f1: 0.9932
Epoch 55/300
 - 9s - loss: 0.0061 - val_loss: 0.0047
 - val_f1: 0.9903
Epoch 56/300
 - 9s - loss: 0.0061 - val_loss: 0.0041
 - val_f1: 0.9911
Epoch 57/300
 - 9s - loss: 0.0061 - val_loss: 0.0043
 - val_f1: 0.9925
Epoch 58/300
 - 9s - loss: 0.0060 - val_loss: 0.0040
 - val_f1: 0.9929
Epoch 59/300
 - 10s - loss: 0.0060 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 60/300
 - 9s - loss: 0.0060 - val_loss: 0.0048
 - val_f1: 0.9924
Epoch 61/300
 - 9s - loss: 0.0059 - val_loss: 0.0060
2019-12-23 16:18:25,321 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9877
Epoch 62/300
 - 9s - loss: 0.0059 - val_loss: 0.0059
 - val_f1: 0.9885
Epoch 63/300
 - 9s - loss: 0.0059 - val_loss: 0.0048
 - val_f1: 0.9911
Epoch 64/300
 - 9s - loss: 0.0058 - val_loss: 0.0064
 - val_f1: 0.9891
Epoch 65/300
 - 9s - loss: 0.0058 - val_loss: 0.0040
 - val_f1: 0.9932
Epoch 66/300
 - 9s - loss: 0.0058 - val_loss: 0.0040
 - val_f1: 0.9929
Epoch 67/300
 - 9s - loss: 0.0058 - val_loss: 0.0042
 - val_f1: 0.9914
Epoch 68/300
 - 9s - loss: 0.0057 - val_loss: 0.0039
 - val_f1: 0.9936
Epoch 69/300
 - 9s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9928
Epoch 70/300
 - 9s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 71/300
 - 9s - loss: 0.0057 - val_loss: 0.0040
 - val_f1: 0.9933
Epoch 72/300
 - 9s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9927
Epoch 73/300
 - 9s - loss: 0.0056 - val_loss: 0.0039
 - val_f1: 0.9936
Epoch 74/300
 - 9s - loss: 0.0056 - val_loss: 0.0038
 - val_f1: 0.9932
Epoch 75/300
 - 9s - loss: 0.0056 - val_loss: 0.0039
 - val_f1: 0.9934
Epoch 76/300
 - 9s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9932
Epoch 77/300
 - 9s - loss: 0.0056 - val_loss: 0.0039
 - val_f1: 0.9927
Epoch 78/300
 - 9s - loss: 0.0056 - val_loss: 0.0039
 - val_f1: 0.9927
Epoch 79/300
 - 9s - loss: 0.0055 - val_loss: 0.0039
 - val_f1: 0.9936
Epoch 80/300
 - 10s - loss: 0.0055 - val_loss: 0.0057
 - val_f1: 0.9900
Epoch 81/300
 - 9s - loss: 0.0055 - val_loss: 0.0037
 - val_f1: 0.9936
Epoch 82/300
 - 9s - loss: 0.0055 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 83/300
 - 10s - loss: 0.0054 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 84/300
 - 9s - loss: 0.0054 - val_loss: 0.0038
 - val_f1: 0.9929
Epoch 85/300
 - 9s - loss: 0.0055 - val_loss: 0.0038
 - val_f1: 0.9910
Epoch 86/300
 - 10s - loss: 0.0054 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 87/300
 - 9s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 88/300
 - 10s - loss: 0.0054 - val_loss: 0.0038
 - val_f1: 0.9931
Epoch 89/300
 - 9s - loss: 0.0053 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 90/300
 - 10s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 91/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
2019-12-23 16:28:04,004 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9930
Epoch 92/300
 - 9s - loss: 0.0053 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 93/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 94/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 95/300
 - 9s - loss: 0.0052 - val_loss: 0.0039
 - val_f1: 0.9928
Epoch 96/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 97/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 98/300
 - 9s - loss: 0.0052 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 99/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 100/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9934
Epoch 101/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9938
Epoch 102/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 103/300
 - 9s - loss: 0.0051 - val_loss: 0.0042
 - val_f1: 0.9928
Epoch 104/300
 - 9s - loss: 0.0051 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 105/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 106/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 107/300
 - 9s - loss: 0.0050 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 108/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 109/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9917
Epoch 110/300
 - 9s - loss: 0.0050 - val_loss: 0.0039
 - val_f1: 0.9930
Epoch 111/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 112/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 113/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 114/300
 - 10s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9914
Epoch 115/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 116/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 117/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 118/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 119/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 120/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 121/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
2019-12-23 16:37:42,407 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9922
Epoch 122/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 123/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 124/300
 - 9s - loss: 0.0049 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 125/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 126/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9912
Epoch 127/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 128/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 129/300
 - 10s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 130/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 131/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9914
Epoch 132/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 133/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 134/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 135/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 136/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 137/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 138/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 139/300
 - 10s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 140/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 141/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 142/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 143/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9922
Epoch 144/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9939
Epoch 145/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 146/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 147/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 148/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 149/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 150/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 151/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
2019-12-23 16:47:20,206 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9950
Epoch 152/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 153/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 154/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 155/300
 - 9s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9927
Epoch 156/300
 - 9s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 157/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 158/300
 - 10s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 159/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 160/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 161/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 162/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 163/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9949
Epoch 164/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 165/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 166/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 167/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 168/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 169/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 170/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 171/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9951
Epoch 172/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 173/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 174/300
 - 9s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9931
Epoch 175/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 176/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 177/300
 - 9s - loss: 0.0045 - val_loss: 0.0041
 - val_f1: 0.9918
Epoch 178/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 179/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 180/300
 - 9s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 181/300
 - 10s - loss: 0.0044 - val_loss: 0.0033
2019-12-23 16:56:59,036 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9925
Epoch 182/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 183/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9949
Epoch 184/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 185/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 186/300
 - 9s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 187/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 188/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 189/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 190/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 191/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 192/300
 - 9s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 193/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 194/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 195/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9937
Epoch 196/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 197/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9923
Epoch 198/300
 - 9s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9943
Epoch 199/300
 - 10s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 200/300
 - 10s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 201/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9951
Epoch 202/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 203/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 204/300
 - 10s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9924
Epoch 205/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 206/300
 - 9s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 207/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 208/300
 - 10s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 209/300
 - 9s - loss: 0.0043 - val_loss: 0.0030
 - val_f1: 0.9945
Epoch 210/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9948
Epoch 211/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
2019-12-23 17:06:38,218 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9925
Epoch 212/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 213/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 214/300
 - 9s - loss: 0.0043 - val_loss: 0.0042
 - val_f1: 0.9924
Epoch 215/300
 - 10s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 216/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 217/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 218/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9934
Epoch 219/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 220/300
 - 9s - loss: 0.0042 - val_loss: 0.0047
 - val_f1: 0.9895
Epoch 221/300
 - 10s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9935
Epoch 222/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9941
Epoch 223/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 224/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 225/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 226/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 227/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 228/300
 - 10s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 229/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 230/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 231/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 232/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9924
Epoch 233/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9937
Epoch 234/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9946
Epoch 235/300
 - 10s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9938
Epoch 236/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 237/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9947
Epoch 238/300
 - 9s - loss: 0.0042 - val_loss: 0.0029
 - val_f1: 0.9942
Epoch 239/300
 - 9s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9925
Epoch 240/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 241/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
2019-12-23 17:16:17,615 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9941
Epoch 242/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 243/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9940
Epoch 244/300
 - 9s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 245/300
 - 10s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 246/300
 - 10s - loss: 0.0042 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 247/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 248/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 249/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 250/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 251/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 252/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 253/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 254/300
 - 10s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9952
Epoch 255/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 256/300
 - 10s - loss: 0.0041 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 257/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 258/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 259/300
 - 9s - loss: 0.0041 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 260/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 261/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 262/300
 - 9s - loss: 0.0041 - val_loss: 0.0032
 - val_f1: 0.9926
Epoch 263/300
 - 10s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9949
Epoch 264/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9949
Epoch 265/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 266/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9939
Epoch 267/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 268/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 269/300
 - 9s - loss: 0.0041 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 270/300
 - 9s - loss: 0.0041 - val_loss: 0.0029
 - val_f1: 0.9925
Epoch 271/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
2019-12-23 17:25:56,916 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9927
Epoch 272/300
 - 9s - loss: 0.0040 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 273/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9952
Epoch 274/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9951
Epoch 275/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 276/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9925
Epoch 277/300
 - 9s - loss: 0.0041 - val_loss: 0.0028
 - val_f1: 0.9951
Epoch 278/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9935
Epoch 279/300
 - 9s - loss: 0.0041 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 280/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 281/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9953
Epoch 282/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9937
Epoch 283/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 284/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 285/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 286/300
 - 10s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9942
Epoch 287/300
 - 10s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9951
Epoch 288/300
 - 9s - loss: 0.0040 - val_loss: 0.0031
 - val_f1: 0.9926
Epoch 289/300
 - 10s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9954
Epoch 290/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9938
Epoch 291/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9939
Epoch 292/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9941
Epoch 293/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9929
Epoch 294/300
 - 9s - loss: 0.0040 - val_loss: 0.0029
 - val_f1: 0.9926
Epoch 295/300
 - 9s - loss: 0.0039 - val_loss: 0.0037
 - val_f1: 0.9913
Epoch 296/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9927
Epoch 297/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9941
Epoch 298/300
 - 9s - loss: 0.0040 - val_loss: 0.0028
 - val_f1: 0.9947
Epoch 299/300
 - 9s - loss: 0.0040 - val_loss: 0.0030
 - val_f1: 0.9926
Epoch 300/300
 - 9s - loss: 0.0039 - val_loss: 0.0029
2019-12-23 17:35:25,694 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 17:35:51,300 [INFO] Last epoch loss evaluation: train_loss = 0.002683, val_loss = 0.002793
2019-12-23 17:35:51,340 [INFO] Training complete. time_to_train = 6172.17 sec, 102.87 min
2019-12-23 17:35:51,343 [INFO] Model saved to results_selected_models/selected_ids17_dbn_shallow_rep3/best_model.pickle
2019-12-23 17:35:51,472 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep3/training_error_history.png
2019-12-23 17:35:51,602 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep3/training_f1_history.png
2019-12-23 17:35:51,602 [INFO] Making predictions on training, validation, testing data
2019-12-23 17:36:38,332 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 17:36:48,650 [INFO] Dataset: Testing. Classification report below
2019-12-23 17:36:48,651 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.96      0.36      0.52       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.98      0.96      0.97      2058
              DoS Hulk       0.96      1.00      0.98     46025
      DoS Slowhttptest       0.86      0.96      0.91      1100
         DoS slowloris       0.99      0.94      0.96      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.95      0.98      0.96      1179
Web Attack Brute Force       1.00      0.06      0.11       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.89      0.77      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 17:36:48,651 [INFO] Overall accuracy (micro avg): 0.9942994755658973
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 17:37:00,386 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9943         0.9943                       0.9943                0.0005                   0.0057  0.9943
1     Macro avg        0.9990         0.8910                       0.7708                0.0011                   0.2292  0.7843
2  Weighted avg        0.9953         0.9942                       0.9943                0.0071                   0.0057  0.9939
2019-12-23 17:37:10,853 [INFO] Dataset: Validation. Classification report below
2019-12-23 17:37:10,853 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.95      0.31      0.47       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.97      2059
              DoS Hulk       0.96      1.00      0.98     46025
      DoS Slowhttptest       0.87      0.96      0.91      1099
         DoS slowloris       0.99      0.94      0.96      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.96      0.98      0.97      1180
Web Attack Brute Force       0.73      0.04      0.07       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.87      0.76      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 17:37:10,853 [INFO] Overall accuracy (micro avg): 0.9942800258857561
2019-12-23 17:37:22,765 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9943         0.9943                       0.9943                0.0005                   0.0057  0.9943
1     Macro avg        0.9990         0.8692                       0.7639                0.0011                   0.2361  0.7765
2  Weighted avg        0.9953         0.9940                       0.9943                0.0072                   0.0057  0.9938
2019-12-23 17:37:57,365 [INFO] Dataset: Training. Classification report below
2019-12-23 17:37:57,365 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.94      0.35      0.51      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.98      0.96      0.97      6176
              DoS Hulk       0.96      1.00      0.98    138074
      DoS Slowhttptest       0.88      0.97      0.92      3300
         DoS slowloris       0.99      0.95      0.97      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.96      0.98      0.97      3538
Web Attack Brute Force       0.77      0.05      0.09       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.87      0.77      0.78   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-23 17:37:57,365 [INFO] Overall accuracy (micro avg): 0.9944332592280001
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 17:38:36,643 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9944         0.9944                       0.9944                0.0005                   0.0056  0.9944
1     Macro avg        0.9991         0.8737                       0.7701                0.0011                   0.2299  0.7834
2  Weighted avg        0.9954         0.9942                       0.9944                0.0071                   0.0056  0.9940
2019-12-23 17:38:36,667 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_shallow_rep3/selected_ids17_dbn_shallow_rep3_results.xlsx
2019-12-23 17:38:36,671 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-23 17:38:36,738 [INFO] Created directory: results_selected_models/selected_ids17_dbn_shallow_rep4
2019-12-23 17:38:36,738 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_shallow_rep4/run_log.log
2019-12-23 17:38:36,738 [INFO] ================= Running experiment no. 4  ================= 

2019-12-23 17:38:36,738 [INFO] Experiment parameters given below
2019-12-23 17:38:36,739 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids17_dbn_shallow_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_shallow_rep4'}
2019-12-23 17:38:36,739 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_shallow_rep4/tf_logs_run_2019_12_23-17_38_36
2019-12-23 17:38:36,739 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 17:38:36,739 [INFO] Reading X, y files
2019-12-23 17:38:36,739 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 17:38:40,980 [INFO] Reading complete. time_to_read=4.24 seconds
2019-12-23 17:38:40,980 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 17:38:42,406 [INFO] Reading complete. time_to_read=1.43 seconds
2019-12-23 17:38:42,406 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 17:38:43,830 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-23 17:38:43,830 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 17:38:44,045 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-23 17:38:44,045 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 17:38:44,118 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 17:38:44,118 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 17:38:44,193 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 17:38:47,644 [INFO] Initializing model
2019-12-23 17:38:47,644 [INFO] Training model
2019-12-23 17:38:47,644 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 17:39:05,974 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = b4eaf97850109e4c2e6c9a78a54176aff38405d6
2019-12-23 17:39:05,974 [INFO] Pretraining Deep Belief Network
2019-12-23 17:44:52,108 [INFO] Pretraining Complete
2019-12-23 17:44:52,109 [INFO] Getting pretrained weights
2019-12-23 17:44:52,109 [INFO] Creating and initializing feed forward neural network
2019-12-23 17:44:52,225 [INFO] _________________________________________________________________
2019-12-23 17:44:52,226 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 17:44:52,226 [INFO] =================================================================
2019-12-23 17:44:52,226 [INFO] dense_17 (Dense)             (None, 32)                2528      
2019-12-23 17:44:52,226 [INFO] _________________________________________________________________
2019-12-23 17:44:52,226 [INFO] batch_normalization_9 (Batch (None, 32)                128       
2019-12-23 17:44:52,226 [INFO] _________________________________________________________________
2019-12-23 17:44:52,226 [INFO] dropout_9 (Dropout)          (None, 32)                0         
2019-12-23 17:44:52,226 [INFO] _________________________________________________________________
2019-12-23 17:44:52,226 [INFO] dense_18 (Dense)             (None, 12)                396       
2019-12-23 17:44:52,226 [INFO] =================================================================
2019-12-23 17:44:52,226 [INFO] Total params: 3,052
2019-12-23 17:44:52,227 [INFO] Trainable params: 2,988
2019-12-23 17:44:52,227 [INFO] Non-trainable params: 64
2019-12-23 17:44:52,227 [INFO] _________________________________________________________________
2019-12-23 17:44:52,897 [INFO] Fine-tuning final neural network
 - val_f1: 0.9943
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.21, time = 4.53s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.81, time = 7.40s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -28.14, time = 7.15s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -30.15, time = 7.15s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -32.55, time = 7.18s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -34.78, time = 7.17s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.65, time = 7.16s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -38.21, time = 7.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -39.58, time = 7.14s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -40.82, time = 7.14s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -42.00, time = 7.13s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -43.13, time = 7.12s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -44.24, time = 7.11s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -45.32, time = 7.11s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -46.40, time = 7.11s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -47.47, time = 7.10s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -48.54, time = 7.10s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -49.60, time = 7.10s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -50.67, time = 7.09s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -51.75, time = 7.09s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -52.82, time = 7.08s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -53.89, time = 7.03s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -54.97, time = 6.99s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.04, time = 6.92s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.11, time = 6.87s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -58.19, time = 6.84s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -59.27, time = 6.81s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -60.34, time = 6.79s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -61.42, time = 6.78s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -62.50, time = 6.77s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -63.58, time = 6.76s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -64.66, time = 6.75s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -65.74, time = 6.75s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -66.83, time = 6.75s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -67.91, time = 6.74s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -69.00, time = 6.74s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -70.09, time = 6.74s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -71.18, time = 6.74s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -72.28, time = 6.74s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -73.37, time = 6.74s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -74.46, time = 6.74s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -75.56, time = 6.74s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -76.65, time = 6.74s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -77.75, time = 6.74s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -78.85, time = 6.74s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -79.96, time = 6.73s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -81.05, time = 6.73s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -82.15, time = 6.73s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -83.25, time = 6.73s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -84.36, time = 6.73s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 9s - loss: 0.0849 - val_loss: 0.0563
 - val_f1: 0.8541
Epoch 2/300
 - 10s - loss: 0.0566 - val_loss: 0.0496
 - val_f1: 0.8647
Epoch 3/300
 - 10s - loss: 0.0497 - val_loss: 0.0411
 - val_f1: 0.8943
Epoch 4/300
 - 10s - loss: 0.0389 - val_loss: 0.0304
 - val_f1: 0.9260
Epoch 5/300
 - 9s - loss: 0.0342 - val_loss: 0.0287
 - val_f1: 0.9288
Epoch 6/300
 - 10s - loss: 0.0320 - val_loss: 0.0270
 - val_f1: 0.9314
Epoch 7/300
 - 10s - loss: 0.0302 - val_loss: 0.0233
 - val_f1: 0.9504
Epoch 8/300
 - 9s - loss: 0.0248 - val_loss: 0.0172
 - val_f1: 0.9620
Epoch 9/300
 - 9s - loss: 0.0209 - val_loss: 0.0143
 - val_f1: 0.9664
Epoch 10/300
 - 9s - loss: 0.0195 - val_loss: 0.0139
 - val_f1: 0.9683
Epoch 11/300
 - 10s - loss: 0.0186 - val_loss: 0.0134
 - val_f1: 0.9682
Epoch 12/300
 - 10s - loss: 0.0180 - val_loss: 0.0132
 - val_f1: 0.9693
Epoch 13/300
 - 10s - loss: 0.0176 - val_loss: 0.0122
 - val_f1: 0.9704
Epoch 14/300
 - 10s - loss: 0.0171 - val_loss: 0.0137
 - val_f1: 0.9681
Epoch 15/300
 - 9s - loss: 0.0167 - val_loss: 0.0117
 - val_f1: 0.9720
Epoch 16/300
 - 9s - loss: 0.0161 - val_loss: 0.0114
 - val_f1: 0.9726
Epoch 17/300
 - 9s - loss: 0.0154 - val_loss: 0.0102
 - val_f1: 0.9795
Epoch 18/300
 - 9s - loss: 0.0144 - val_loss: 0.0104
 - val_f1: 0.9725
Epoch 19/300
 - 10s - loss: 0.0137 - val_loss: 0.0097
 - val_f1: 0.9859
Epoch 20/300
 - 9s - loss: 0.0131 - val_loss: 0.0097
 - val_f1: 0.9839
Epoch 21/300
 - 9s - loss: 0.0125 - val_loss: 0.0091
 - val_f1: 0.9844
Epoch 22/300
 - 10s - loss: 0.0120 - val_loss: 0.0088
 - val_f1: 0.9839
Epoch 23/300
 - 9s - loss: 0.0116 - val_loss: 0.0082
 - val_f1: 0.9843
Epoch 24/300
 - 10s - loss: 0.0112 - val_loss: 0.0095
 - val_f1: 0.9831
Epoch 25/300
 - 10s - loss: 0.0108 - val_loss: 0.0074
 - val_f1: 0.9860
Epoch 26/300
 - 10s - loss: 0.0104 - val_loss: 0.0070
 - val_f1: 0.9871
Epoch 27/300
 - 10s - loss: 0.0102 - val_loss: 0.0076
 - val_f1: 0.9844
Epoch 28/300
 - 9s - loss: 0.0098 - val_loss: 0.0065
 - val_f1: 0.9882
Epoch 29/300
 - 9s - loss: 0.0096 - val_loss: 0.0075
 - val_f1: 0.9836
Epoch 30/300
 - 10s - loss: 0.0095 - val_loss: 0.0065
 - val_f1: 0.9852
Epoch 31/300
 - 9s - loss: 0.0092 - val_loss: 0.0063
2019-12-23 17:54:48,639 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9871
Epoch 32/300
 - 9s - loss: 0.0090 - val_loss: 0.0067
 - val_f1: 0.9863
Epoch 33/300
 - 10s - loss: 0.0088 - val_loss: 0.0060
 - val_f1: 0.9874
Epoch 34/300
 - 9s - loss: 0.0086 - val_loss: 0.0063
 - val_f1: 0.9887
Epoch 35/300
 - 10s - loss: 0.0086 - val_loss: 0.0069
 - val_f1: 0.9855
Epoch 36/300
 - 9s - loss: 0.0084 - val_loss: 0.0057
 - val_f1: 0.9904
Epoch 37/300
 - 10s - loss: 0.0082 - val_loss: 0.0068
 - val_f1: 0.9860
Epoch 38/300
 - 10s - loss: 0.0081 - val_loss: 0.0056
 - val_f1: 0.9894
Epoch 39/300
 - 10s - loss: 0.0080 - val_loss: 0.0062
 - val_f1: 0.9874
Epoch 40/300
 - 10s - loss: 0.0078 - val_loss: 0.0058
 - val_f1: 0.9886
Epoch 41/300
 - 10s - loss: 0.0078 - val_loss: 0.0056
 - val_f1: 0.9891
Epoch 42/300
 - 10s - loss: 0.0077 - val_loss: 0.0058
 - val_f1: 0.9870
Epoch 43/300
 - 9s - loss: 0.0075 - val_loss: 0.0058
 - val_f1: 0.9871
Epoch 44/300
 - 10s - loss: 0.0075 - val_loss: 0.0055
 - val_f1: 0.9888
Epoch 45/300
 - 10s - loss: 0.0073 - val_loss: 0.0053
 - val_f1: 0.9910
Epoch 46/300
 - 10s - loss: 0.0072 - val_loss: 0.0057
 - val_f1: 0.9883
Epoch 47/300
 - 9s - loss: 0.0072 - val_loss: 0.0055
 - val_f1: 0.9896
Epoch 48/300
 - 10s - loss: 0.0071 - val_loss: 0.0059
 - val_f1: 0.9866
Epoch 49/300
 - 10s - loss: 0.0070 - val_loss: 0.0050
 - val_f1: 0.9900
Epoch 50/300
 - 9s - loss: 0.0070 - val_loss: 0.0050
 - val_f1: 0.9919
Epoch 51/300
 - 9s - loss: 0.0068 - val_loss: 0.0050
 - val_f1: 0.9913
Epoch 52/300
 - 10s - loss: 0.0068 - val_loss: 0.0050
 - val_f1: 0.9899
Epoch 53/300
 - 10s - loss: 0.0068 - val_loss: 0.0055
 - val_f1: 0.9877
Epoch 54/300
 - 10s - loss: 0.0067 - val_loss: 0.0050
 - val_f1: 0.9901
Epoch 55/300
 - 9s - loss: 0.0067 - val_loss: 0.0050
 - val_f1: 0.9908
Epoch 56/300
 - 10s - loss: 0.0067 - val_loss: 0.0051
 - val_f1: 0.9899
Epoch 57/300
 - 9s - loss: 0.0065 - val_loss: 0.0055
 - val_f1: 0.9885
Epoch 58/300
 - 9s - loss: 0.0066 - val_loss: 0.0048
 - val_f1: 0.9900
Epoch 59/300
 - 9s - loss: 0.0065 - val_loss: 0.0047
 - val_f1: 0.9919
Epoch 60/300
 - 9s - loss: 0.0064 - val_loss: 0.0047
 - val_f1: 0.9901
Epoch 61/300
 - 9s - loss: 0.0064 - val_loss: 0.0048
2019-12-23 18:04:32,643 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9905
Epoch 62/300
 - 9s - loss: 0.0064 - val_loss: 0.0049
 - val_f1: 0.9907
Epoch 63/300
 - 9s - loss: 0.0063 - val_loss: 0.0046
 - val_f1: 0.9909
Epoch 64/300
 - 9s - loss: 0.0063 - val_loss: 0.0048
 - val_f1: 0.9910
Epoch 65/300
 - 10s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9904
Epoch 66/300
 - 10s - loss: 0.0062 - val_loss: 0.0046
 - val_f1: 0.9913
Epoch 67/300
 - 10s - loss: 0.0061 - val_loss: 0.0046
 - val_f1: 0.9913
Epoch 68/300
 - 9s - loss: 0.0061 - val_loss: 0.0045
 - val_f1: 0.9924
Epoch 69/300
 - 9s - loss: 0.0061 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 70/300
 - 9s - loss: 0.0061 - val_loss: 0.0045
 - val_f1: 0.9919
Epoch 71/300
 - 9s - loss: 0.0061 - val_loss: 0.0043
 - val_f1: 0.9902
Epoch 72/300
 - 9s - loss: 0.0060 - val_loss: 0.0044
 - val_f1: 0.9922
Epoch 73/300
 - 10s - loss: 0.0060 - val_loss: 0.0043
 - val_f1: 0.9931
Epoch 74/300
 - 9s - loss: 0.0060 - val_loss: 0.0045
 - val_f1: 0.9933
Epoch 75/300
 - 9s - loss: 0.0059 - val_loss: 0.0044
 - val_f1: 0.9925
Epoch 76/300
 - 10s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9916
Epoch 77/300
 - 9s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9904
Epoch 78/300
 - 9s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9907
Epoch 79/300
 - 9s - loss: 0.0058 - val_loss: 0.0042
 - val_f1: 0.9926
Epoch 80/300
 - 9s - loss: 0.0058 - val_loss: 0.0043
 - val_f1: 0.9924
Epoch 81/300
 - 10s - loss: 0.0057 - val_loss: 0.0045
 - val_f1: 0.9914
Epoch 82/300
 - 9s - loss: 0.0057 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 83/300
 - 9s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9921
Epoch 84/300
 - 10s - loss: 0.0057 - val_loss: 0.0044
 - val_f1: 0.9914
Epoch 85/300
 - 10s - loss: 0.0056 - val_loss: 0.0042
 - val_f1: 0.9919
Epoch 86/300
 - 10s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9929
Epoch 87/300
 - 10s - loss: 0.0056 - val_loss: 0.0040
 - val_f1: 0.9930
Epoch 88/300
 - 10s - loss: 0.0056 - val_loss: 0.0043
 - val_f1: 0.9917
Epoch 89/300
 - 9s - loss: 0.0055 - val_loss: 0.0041
 - val_f1: 0.9929
Epoch 90/300
 - 9s - loss: 0.0055 - val_loss: 0.0039
 - val_f1: 0.9934
Epoch 91/300
 - 10s - loss: 0.0055 - val_loss: 0.0042
2019-12-23 18:14:21,175 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9915
Epoch 92/300
 - 10s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 93/300
 - 10s - loss: 0.0054 - val_loss: 0.0046
 - val_f1: 0.9914
Epoch 94/300
 - 10s - loss: 0.0055 - val_loss: 0.0041
 - val_f1: 0.9915
Epoch 95/300
 - 9s - loss: 0.0054 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 96/300
 - 9s - loss: 0.0054 - val_loss: 0.0041
 - val_f1: 0.9924
Epoch 97/300
 - 10s - loss: 0.0054 - val_loss: 0.0041
 - val_f1: 0.9916
Epoch 98/300
 - 10s - loss: 0.0054 - val_loss: 0.0039
 - val_f1: 0.9932
Epoch 99/300
 - 10s - loss: 0.0053 - val_loss: 0.0044
 - val_f1: 0.9918
Epoch 100/300
 - 10s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 101/300
 - 10s - loss: 0.0053 - val_loss: 0.0049
 - val_f1: 0.9911
Epoch 102/300
 - 10s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9938
Epoch 103/300
 - 10s - loss: 0.0052 - val_loss: 0.0039
 - val_f1: 0.9915
Epoch 104/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9920
Epoch 105/300
 - 10s - loss: 0.0053 - val_loss: 0.0046
 - val_f1: 0.9910
Epoch 106/300
 - 9s - loss: 0.0052 - val_loss: 0.0041
 - val_f1: 0.9910
Epoch 107/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9931
Epoch 108/300
 - 10s - loss: 0.0052 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 109/300
 - 9s - loss: 0.0052 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 110/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9934
Epoch 111/300
 - 9s - loss: 0.0051 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 112/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9911
Epoch 113/300
 - 9s - loss: 0.0052 - val_loss: 0.0037
 - val_f1: 0.9915
Epoch 114/300
 - 10s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9909
Epoch 115/300
 - 10s - loss: 0.0051 - val_loss: 0.0046
 - val_f1: 0.9919
Epoch 116/300
 - 10s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9935
Epoch 117/300
 - 9s - loss: 0.0051 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 118/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9912
Epoch 119/300
 - 10s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9926
Epoch 120/300
 - 9s - loss: 0.0051 - val_loss: 0.0035
 - val_f1: 0.9916
Epoch 121/300
 - 10s - loss: 0.0051 - val_loss: 0.0037
2019-12-23 18:24:10,624 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9930
Epoch 122/300
 - 9s - loss: 0.0051 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 123/300
 - 9s - loss: 0.0051 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 124/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9935
Epoch 125/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9927
Epoch 126/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9915
Epoch 127/300
 - 10s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9930
Epoch 128/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 129/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 130/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 131/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 132/300
 - 10s - loss: 0.0050 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 133/300
 - 10s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9930
Epoch 134/300
 - 10s - loss: 0.0050 - val_loss: 0.0049
 - val_f1: 0.9914
Epoch 135/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 136/300
 - 10s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 137/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9917
Epoch 138/300
 - 10s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9938
Epoch 139/300
 - 10s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 140/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 141/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 142/300
 - 10s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9933
Epoch 143/300
 - 10s - loss: 0.0048 - val_loss: 0.0041
 - val_f1: 0.9920
Epoch 144/300
 - 10s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 145/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 146/300
 - 10s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9913
Epoch 147/300
 - 10s - loss: 0.0048 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 148/300
 - 10s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 149/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9933
Epoch 150/300
 - 10s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 151/300
 - 9s - loss: 0.0048 - val_loss: 0.0039
2019-12-23 18:34:00,114 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9921
Epoch 152/300
 - 9s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 153/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9925
Epoch 154/300
 - 10s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9921
Epoch 155/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 156/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 157/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 158/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 159/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 160/300
 - 10s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 161/300
 - 9s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9927
Epoch 162/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 163/300
 - 10s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 164/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 165/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9920
Epoch 166/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 167/300
 - 10s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 168/300
 - 10s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9941
Epoch 169/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 170/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 171/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9939
Epoch 172/300
 - 10s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9920
Epoch 173/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 174/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 175/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 176/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 177/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9935
Epoch 178/300
 - 9s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9924
Epoch 179/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 180/300
 - 10s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 181/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
2019-12-23 18:43:49,470 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9924
Epoch 182/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 183/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9934
Epoch 184/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9915
Epoch 185/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 186/300
 - 10s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 187/300
 - 10s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 188/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 189/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 190/300
 - 10s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 191/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 192/300
 - 9s - loss: 0.0046 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 193/300
 - 10s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 194/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9918
Epoch 195/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 196/300
 - 10s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9913
Epoch 197/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 198/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 199/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9924
Epoch 200/300
 - 10s - loss: 0.0045 - val_loss: 0.0040
 - val_f1: 0.9923
Epoch 201/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 202/300
 - 10s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9923
Epoch 203/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 204/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9916
Epoch 205/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 206/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9937
Epoch 207/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9928
Epoch 208/300
 - 9s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 209/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 210/300
 - 10s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 211/300
 - 10s - loss: 0.0044 - val_loss: 0.0034
2019-12-23 18:53:40,003 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9935
Epoch 212/300
 - 10s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 213/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 214/300
 - 10s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 215/300
 - 10s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 216/300
 - 10s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 217/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 218/300
 - 9s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9937
Epoch 219/300
 - 10s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 220/300
 - 10s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 221/300
 - 10s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 222/300
 - 10s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9925
Epoch 223/300
 - 10s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 224/300
 - 10s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9922
Epoch 225/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9926
Epoch 226/300
 - 9s - loss: 0.0043 - val_loss: 0.0035
 - val_f1: 0.9935
Epoch 227/300
 - 10s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 228/300
 - 9s - loss: 0.0044 - val_loss: 0.0040
 - val_f1: 0.9922
Epoch 229/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 230/300
 - 10s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 231/300
 - 10s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 232/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 233/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9920
Epoch 234/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9944
Epoch 235/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 236/300
 - 10s - loss: 0.0044 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 237/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 238/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 239/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 240/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 241/300
 - 9s - loss: 0.0043 - val_loss: 0.0039
2019-12-23 19:03:30,040 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9934
Epoch 242/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 243/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 244/300
 - 9s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9923
Epoch 245/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 246/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 247/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9942
Epoch 248/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9936
Epoch 249/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 250/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9936
Epoch 251/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9917
Epoch 252/300
 - 9s - loss: 0.0043 - val_loss: 0.0036
 - val_f1: 0.9924
Epoch 253/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 254/300
 - 10s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 255/300
 - 10s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 256/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 257/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 258/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 259/300
 - 10s - loss: 0.0043 - val_loss: 0.0037
 - val_f1: 0.9915
Epoch 260/300
 - 10s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 261/300
 - 10s - loss: 0.0043 - val_loss: 0.0040
 - val_f1: 0.9921
Epoch 262/300
 - 10s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 263/300
 - 10s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9943
Epoch 264/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 265/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9937
Epoch 266/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 267/300
 - 10s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 268/300
 - 10s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 269/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 270/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9919
Epoch 271/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
2019-12-23 19:13:19,828 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9925
Epoch 272/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9940
Epoch 273/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9925
Epoch 274/300
 - 9s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 275/300
 - 9s - loss: 0.0043 - val_loss: 0.0034
 - val_f1: 0.9926
Epoch 276/300
 - 10s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 277/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9923
Epoch 278/300
 - 10s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 279/300
 - 9s - loss: 0.0042 - val_loss: 0.0031
 - val_f1: 0.9920
Epoch 280/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 281/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 282/300
 - 10s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9938
Epoch 283/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 284/300
 - 10s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9919
Epoch 285/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9915
Epoch 286/300
 - 10s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 287/300
 - 10s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 288/300
 - 10s - loss: 0.0043 - val_loss: 0.0047
 - val_f1: 0.9909
Epoch 289/300
 - 9s - loss: 0.0042 - val_loss: 0.0032
 - val_f1: 0.9914
Epoch 290/300
 - 10s - loss: 0.0042 - val_loss: 0.0041
 - val_f1: 0.9919
Epoch 291/300
 - 9s - loss: 0.0042 - val_loss: 0.0035
 - val_f1: 0.9924
Epoch 292/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 293/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 294/300
 - 9s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 295/300
 - 9s - loss: 0.0042 - val_loss: 0.0034
 - val_f1: 0.9923
Epoch 296/300
 - 10s - loss: 0.0042 - val_loss: 0.0033
 - val_f1: 0.9938
Epoch 297/300
 - 10s - loss: 0.0042 - val_loss: 0.0037
2019-12-23 19:22:00,375 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 19:22:26,540 [INFO] Last epoch loss evaluation: train_loss = 0.002976, val_loss = 0.003051
2019-12-23 19:22:26,581 [INFO] Training complete. time_to_train = 6218.94 sec, 103.65 min
2019-12-23 19:22:26,585 [INFO] Model saved to results_selected_models/selected_ids17_dbn_shallow_rep4/best_model.pickle
2019-12-23 19:22:26,729 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep4/training_error_history.png
2019-12-23 19:22:26,858 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep4/training_f1_history.png
2019-12-23 19:22:26,858 [INFO] Making predictions on training, validation, testing data
2019-12-23 19:23:15,706 [INFO] Evaluating predictions (results)
2019-12-23 19:23:26,025 [INFO] Dataset: Testing. Classification report below
2019-12-23 19:23:26,025 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.53       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.95      0.97      2058
              DoS Hulk       0.97      1.00      0.98     46025
      DoS Slowhttptest       0.87      0.95      0.91      1100
         DoS slowloris       0.98      0.90      0.94      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.93      0.98      0.96      1179
Web Attack Brute Force       0.00      0.00      0.00       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 19:23:26,025 [INFO] Overall accuracy (micro avg): 0.9941633278049091
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 19:23:37,747 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9942         0.9942                       0.9942                0.0005                   0.0058  0.9942
1     Macro avg        0.9990         0.8075                       0.7612                0.0012                   0.2388  0.7726
2  Weighted avg        0.9952         0.9935                       0.9942                0.0083                   0.0058  0.9937
2019-12-23 19:23:48,202 [INFO] Dataset: Validation. Classification report below
2019-12-23 19:23:48,202 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.98      0.33      0.50       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.94      0.97      2059
              DoS Hulk       0.96      1.00      0.98     46025
      DoS Slowhttptest       0.88      0.94      0.91      1099
         DoS slowloris       0.98      0.91      0.94      1159
           FTP-Patator       0.99      0.99      0.99      1587
              PortScan       0.99      1.00      1.00     31761
           SSH-Patator       0.95      0.97      0.96      1180
Web Attack Brute Force       0.00      0.00      0.00       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.81      0.76      0.77    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 19:23:48,202 [INFO] Overall accuracy (micro avg): 0.9941438781247679
2019-12-23 19:24:00,093 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9941         0.9941                       0.9941                0.0005                   0.0059  0.9941
1     Macro avg        0.9990         0.8093                       0.7564                0.0012                   0.2436  0.7694
2  Weighted avg        0.9952         0.9935                       0.9941                0.0085                   0.0059  0.9937
2019-12-23 19:24:34,770 [INFO] Dataset: Training. Classification report below
2019-12-23 19:24:34,770 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.98      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.95      0.97      6176
              DoS Hulk       0.97      1.00      0.98    138074
      DoS Slowhttptest       0.88      0.95      0.91      3300
         DoS slowloris       0.98      0.92      0.94      3478
           FTP-Patator       0.99      0.99      0.99      4761
              PortScan       0.99      1.00      1.00     95282
           SSH-Patator       0.95      0.98      0.97      3538
Web Attack Brute Force       0.00      0.00      0.00       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.81      0.76      0.77   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-23 19:24:34,770 [INFO] Overall accuracy (micro avg): 0.9942894493022861
2019-12-23 19:25:14,157 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9943         0.9943                       0.9943                0.0005                   0.0057  0.9943
1     Macro avg        0.9990         0.8104                       0.7609                0.0012                   0.2391  0.7735
2  Weighted avg        0.9953         0.9936                       0.9943                0.0082                   0.0057  0.9938
2019-12-23 19:25:14,181 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_shallow_rep4/selected_ids17_dbn_shallow_rep4_results.xlsx
2019-12-23 19:25:14,186 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-23 19:25:14,256 [INFO] Created directory: results_selected_models/selected_ids17_dbn_shallow_rep5
2019-12-23 19:25:14,257 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids17_dbn_shallow_rep5/run_log.log
2019-12-23 19:25:14,257 [INFO] ================= Running experiment no. 5  ================= 

2019-12-23 19:25:14,257 [INFO] Experiment parameters given below
2019-12-23 19:25:14,257 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids17_dbn_shallow_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/ids2017', 'description': 'selected_ids17_dbn_shallow_rep5'}
2019-12-23 19:25:14,257 [INFO] Created tensorboard log directory: results_selected_models/selected_ids17_dbn_shallow_rep5/tf_logs_run_2019_12_23-19_25_14
2019-12-23 19:25:14,257 [INFO] Loading datsets from: ../Datasets/full_datasets/ids2017
2019-12-23 19:25:14,257 [INFO] Reading X, y files
2019-12-23 19:25:14,257 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_train.h5
2019-12-23 19:25:18,413 [INFO] Reading complete. time_to_read=4.16 seconds
2019-12-23 19:25:18,413 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_val.h5
2019-12-23 19:25:19,837 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-23 19:25:19,838 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/X_test.h5
2019-12-23 19:25:21,263 [INFO] Reading complete. time_to_read=1.42 seconds
2019-12-23 19:25:21,263 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_train.h5
2019-12-23 19:25:21,488 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-23 19:25:21,488 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_val.h5
2019-12-23 19:25:21,562 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 19:25:21,562 [INFO] Reading HDF dataset ../Datasets/full_datasets/ids2017/y_test.h5
2019-12-23 19:25:21,636 [INFO] Reading complete. time_to_read=0.07 seconds
2019-12-23 19:25:25,096 [INFO] Initializing model
2019-12-23 19:25:25,097 [INFO] Training model
2019-12-23 19:25:25,097 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 19:25:43,525 [INFO] Split sizes (instances). total = 1696684, unsupervised = 848342, supervised = 848342, unsupervised dataset hash = cc144a8fdb92e7c9ec731e3ff0e008c725027590
2019-12-23 19:25:43,525 [INFO] Pretraining Deep Belief Network
2019-12-23 19:31:29,058 [INFO] Pretraining Complete
2019-12-23 19:31:29,058 [INFO] Getting pretrained weights
2019-12-23 19:31:29,058 [INFO] Creating and initializing feed forward neural network
2019-12-23 19:31:29,176 [INFO] _________________________________________________________________
2019-12-23 19:31:29,176 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 19:31:29,176 [INFO] =================================================================
2019-12-23 19:31:29,176 [INFO] dense_19 (Dense)             (None, 32)                2528      
2019-12-23 19:31:29,176 [INFO] _________________________________________________________________
2019-12-23 19:31:29,176 [INFO] batch_normalization_10 (Batc (None, 32)                128       
2019-12-23 19:31:29,176 [INFO] _________________________________________________________________
2019-12-23 19:31:29,176 [INFO] dropout_10 (Dropout)         (None, 32)                0         
2019-12-23 19:31:29,176 [INFO] _________________________________________________________________
2019-12-23 19:31:29,177 [INFO] dense_20 (Dense)             (None, 12)                396       
2019-12-23 19:31:29,177 [INFO] =================================================================
2019-12-23 19:31:29,177 [INFO] Total params: 3,052
2019-12-23 19:31:29,177 [INFO] Trainable params: 2,988
2019-12-23 19:31:29,177 [INFO] Non-trainable params: 64
2019-12-23 19:31:29,177 [INFO] _________________________________________________________________
2019-12-23 19:31:29,926 [INFO] Fine-tuning final neural network
 - val_f1: 0.9924
Epoch 00297: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -29.17, time = 4.51s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -26.82, time = 7.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -28.24, time = 7.13s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -30.34, time = 7.14s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -32.78, time = 7.17s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -35.05, time = 7.15s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -36.96, time = 7.14s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -38.56, time = 7.13s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -39.96, time = 7.13s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -41.24, time = 7.12s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -42.45, time = 7.11s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -43.62, time = 7.11s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -44.76, time = 7.11s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -45.87, time = 7.10s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -46.98, time = 7.09s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -48.07, time = 7.09s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -49.17, time = 7.08s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -50.26, time = 7.08s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -51.35, time = 7.08s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -52.45, time = 7.07s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -53.55, time = 7.07s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -54.64, time = 7.03s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -55.74, time = 6.98s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -56.84, time = 6.91s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -57.93, time = 6.85s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -59.03, time = 6.82s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -60.13, time = 6.80s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -61.23, time = 6.78s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -62.33, time = 6.77s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -63.43, time = 6.75s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -64.53, time = 6.75s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -65.64, time = 6.74s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -66.74, time = 6.74s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -67.85, time = 6.73s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -68.95, time = 6.73s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -70.06, time = 6.72s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -71.17, time = 6.72s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -72.28, time = 6.73s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -73.40, time = 6.73s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -74.51, time = 6.73s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -75.62, time = 6.72s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -76.74, time = 6.74s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -77.85, time = 6.73s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -78.97, time = 6.73s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -80.09, time = 6.74s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -81.21, time = 6.72s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -82.33, time = 6.72s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -83.45, time = 6.72s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -84.57, time = 6.71s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -85.69, time = 6.72s
Train on 848342 samples, validate on 565562 samples
Epoch 1/300
 - 10s - loss: 0.0842 - val_loss: 0.0559
 - val_f1: 0.8546
Epoch 2/300
 - 9s - loss: 0.0559 - val_loss: 0.0486
 - val_f1: 0.8652
Epoch 3/300
 - 9s - loss: 0.0478 - val_loss: 0.0353
 - val_f1: 0.9048
Epoch 4/300
 - 9s - loss: 0.0361 - val_loss: 0.0260
 - val_f1: 0.9458
Epoch 5/300
 - 9s - loss: 0.0280 - val_loss: 0.0205
 - val_f1: 0.9564
Epoch 6/300
 - 9s - loss: 0.0252 - val_loss: 0.0184
 - val_f1: 0.9594
Epoch 7/300
 - 9s - loss: 0.0234 - val_loss: 0.0173
 - val_f1: 0.9611
Epoch 8/300
 - 9s - loss: 0.0220 - val_loss: 0.0162
 - val_f1: 0.9635
Epoch 9/300
 - 9s - loss: 0.0207 - val_loss: 0.0150
 - val_f1: 0.9655
Epoch 10/300
 - 9s - loss: 0.0195 - val_loss: 0.0143
 - val_f1: 0.9664
Epoch 11/300
 - 9s - loss: 0.0183 - val_loss: 0.0133
 - val_f1: 0.9680
Epoch 12/300
 - 9s - loss: 0.0173 - val_loss: 0.0125
 - val_f1: 0.9699
Epoch 13/300
 - 9s - loss: 0.0165 - val_loss: 0.0124
 - val_f1: 0.9696
Epoch 14/300
 - 9s - loss: 0.0160 - val_loss: 0.0126
 - val_f1: 0.9686
Epoch 15/300
 - 9s - loss: 0.0155 - val_loss: 0.0117
 - val_f1: 0.9709
Epoch 16/300
 - 9s - loss: 0.0151 - val_loss: 0.0112
 - val_f1: 0.9752
Epoch 17/300
 - 9s - loss: 0.0147 - val_loss: 0.0105
 - val_f1: 0.9721
Epoch 18/300
 - 9s - loss: 0.0141 - val_loss: 0.0103
 - val_f1: 0.9721
Epoch 19/300
 - 9s - loss: 0.0136 - val_loss: 0.0098
 - val_f1: 0.9723
Epoch 20/300
 - 9s - loss: 0.0132 - val_loss: 0.0111
 - val_f1: 0.9697
Epoch 21/300
 - 9s - loss: 0.0127 - val_loss: 0.0092
 - val_f1: 0.9775
Epoch 22/300
 - 9s - loss: 0.0123 - val_loss: 0.0088
 - val_f1: 0.9841
Epoch 23/300
 - 9s - loss: 0.0117 - val_loss: 0.0084
 - val_f1: 0.9842
Epoch 24/300
 - 9s - loss: 0.0111 - val_loss: 0.0084
 - val_f1: 0.9840
Epoch 25/300
 - 9s - loss: 0.0108 - val_loss: 0.0074
 - val_f1: 0.9874
Epoch 26/300
 - 9s - loss: 0.0104 - val_loss: 0.0092
 - val_f1: 0.9817
Epoch 27/300
 - 9s - loss: 0.0100 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 28/300
 - 9s - loss: 0.0095 - val_loss: 0.0072
 - val_f1: 0.9851
Epoch 29/300
 - 9s - loss: 0.0091 - val_loss: 0.0067
 - val_f1: 0.9863
Epoch 30/300
 - 9s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 31/300
 - 9s - loss: 0.0087 - val_loss: 0.0074
2019-12-23 19:41:36,229 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9841
Epoch 32/300
 - 9s - loss: 0.0085 - val_loss: 0.0066
 - val_f1: 0.9858
Epoch 33/300
 - 9s - loss: 0.0084 - val_loss: 0.0071
 - val_f1: 0.9841
Epoch 34/300
 - 9s - loss: 0.0082 - val_loss: 0.0079
 - val_f1: 0.9833
Epoch 35/300
 - 9s - loss: 0.0081 - val_loss: 0.0085
 - val_f1: 0.9832
Epoch 36/300
 - 9s - loss: 0.0079 - val_loss: 0.0059
 - val_f1: 0.9890
Epoch 37/300
 - 9s - loss: 0.0078 - val_loss: 0.0059
 - val_f1: 0.9887
Epoch 38/300
 - 9s - loss: 0.0076 - val_loss: 0.0070
 - val_f1: 0.9858
Epoch 39/300
 - 9s - loss: 0.0076 - val_loss: 0.0064
 - val_f1: 0.9870
Epoch 40/300
 - 9s - loss: 0.0076 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 41/300
 - 9s - loss: 0.0074 - val_loss: 0.0062
 - val_f1: 0.9865
Epoch 42/300
 - 9s - loss: 0.0073 - val_loss: 0.0056
 - val_f1: 0.9900
Epoch 43/300
 - 9s - loss: 0.0073 - val_loss: 0.0058
 - val_f1: 0.9886
Epoch 44/300
 - 10s - loss: 0.0072 - val_loss: 0.0066
 - val_f1: 0.9865
Epoch 45/300
 - 9s - loss: 0.0071 - val_loss: 0.0064
 - val_f1: 0.9867
Epoch 46/300
 - 9s - loss: 0.0071 - val_loss: 0.0065
 - val_f1: 0.9858
Epoch 47/300
 - 9s - loss: 0.0071 - val_loss: 0.0087
 - val_f1: 0.9839
Epoch 48/300
 - 9s - loss: 0.0070 - val_loss: 0.0064
 - val_f1: 0.9868
Epoch 49/300
 - 9s - loss: 0.0070 - val_loss: 0.0070
 - val_f1: 0.9854
Epoch 50/300
 - 9s - loss: 0.0069 - val_loss: 0.0077
 - val_f1: 0.9847
Epoch 51/300
 - 9s - loss: 0.0069 - val_loss: 0.0053
 - val_f1: 0.9913
Epoch 52/300
 - 9s - loss: 0.0068 - val_loss: 0.0060
 - val_f1: 0.9866
Epoch 53/300
 - 9s - loss: 0.0068 - val_loss: 0.0065
 - val_f1: 0.9862
Epoch 54/300
 - 9s - loss: 0.0067 - val_loss: 0.0075
 - val_f1: 0.9843
Epoch 55/300
 - 9s - loss: 0.0067 - val_loss: 0.0050
 - val_f1: 0.9912
Epoch 56/300
 - 9s - loss: 0.0065 - val_loss: 0.0054
 - val_f1: 0.9894
Epoch 57/300
 - 9s - loss: 0.0066 - val_loss: 0.0057
 - val_f1: 0.9887
Epoch 58/300
 - 9s - loss: 0.0065 - val_loss: 0.0053
 - val_f1: 0.9904
Epoch 59/300
 - 9s - loss: 0.0065 - val_loss: 0.0064
 - val_f1: 0.9855
Epoch 60/300
 - 9s - loss: 0.0064 - val_loss: 0.0055
 - val_f1: 0.9895
Epoch 61/300
 - 9s - loss: 0.0064 - val_loss: 0.0052
2019-12-23 19:51:31,420 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9908
Epoch 62/300
 - 9s - loss: 0.0064 - val_loss: 0.0055
 - val_f1: 0.9874
Epoch 63/300
 - 9s - loss: 0.0064 - val_loss: 0.0067
 - val_f1: 0.9866
Epoch 64/300
 - 10s - loss: 0.0064 - val_loss: 0.0068
 - val_f1: 0.9869
Epoch 65/300
 - 9s - loss: 0.0063 - val_loss: 0.0056
 - val_f1: 0.9878
Epoch 66/300
 - 9s - loss: 0.0063 - val_loss: 0.0055
 - val_f1: 0.9892
Epoch 67/300
 - 9s - loss: 0.0063 - val_loss: 0.0050
 - val_f1: 0.9892
Epoch 68/300
 - 9s - loss: 0.0062 - val_loss: 0.0049
 - val_f1: 0.9911
Epoch 69/300
 - 9s - loss: 0.0063 - val_loss: 0.0062
 - val_f1: 0.9872
Epoch 70/300
 - 9s - loss: 0.0062 - val_loss: 0.0060
 - val_f1: 0.9873
Epoch 71/300
 - 9s - loss: 0.0061 - val_loss: 0.0055
 - val_f1: 0.9894
Epoch 72/300
 - 9s - loss: 0.0061 - val_loss: 0.0049
 - val_f1: 0.9910
Epoch 73/300
 - 9s - loss: 0.0061 - val_loss: 0.0049
 - val_f1: 0.9910
Epoch 74/300
 - 9s - loss: 0.0061 - val_loss: 0.0046
 - val_f1: 0.9927
Epoch 75/300
 - 9s - loss: 0.0061 - val_loss: 0.0047
 - val_f1: 0.9912
Epoch 76/300
 - 9s - loss: 0.0061 - val_loss: 0.0050
 - val_f1: 0.9890
Epoch 77/300
 - 9s - loss: 0.0061 - val_loss: 0.0046
 - val_f1: 0.9915
Epoch 78/300
 - 9s - loss: 0.0061 - val_loss: 0.0048
 - val_f1: 0.9907
Epoch 79/300
 - 9s - loss: 0.0060 - val_loss: 0.0066
 - val_f1: 0.9859
Epoch 80/300
 - 9s - loss: 0.0059 - val_loss: 0.0050
 - val_f1: 0.9903
Epoch 81/300
 - 9s - loss: 0.0059 - val_loss: 0.0044
 - val_f1: 0.9930
Epoch 82/300
 - 9s - loss: 0.0059 - val_loss: 0.0045
 - val_f1: 0.9926
Epoch 83/300
 - 9s - loss: 0.0059 - val_loss: 0.0049
 - val_f1: 0.9905
Epoch 84/300
 - 9s - loss: 0.0059 - val_loss: 0.0059
 - val_f1: 0.9879
Epoch 85/300
 - 9s - loss: 0.0059 - val_loss: 0.0043
 - val_f1: 0.9937
Epoch 86/300
 - 9s - loss: 0.0059 - val_loss: 0.0052
 - val_f1: 0.9892
Epoch 87/300
 - 9s - loss: 0.0058 - val_loss: 0.0044
 - val_f1: 0.9928
Epoch 88/300
 - 9s - loss: 0.0058 - val_loss: 0.0048
 - val_f1: 0.9905
Epoch 89/300
 - 9s - loss: 0.0058 - val_loss: 0.0045
 - val_f1: 0.9908
Epoch 90/300
 - 9s - loss: 0.0057 - val_loss: 0.0056
 - val_f1: 0.9893
Epoch 91/300
 - 9s - loss: 0.0057 - val_loss: 0.0044
2019-12-23 20:01:26,861 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9933
Epoch 92/300
 - 9s - loss: 0.0057 - val_loss: 0.0045
 - val_f1: 0.9901
Epoch 93/300
 - 9s - loss: 0.0058 - val_loss: 0.0047
 - val_f1: 0.9908
Epoch 94/300
 - 10s - loss: 0.0057 - val_loss: 0.0051
 - val_f1: 0.9894
Epoch 95/300
 - 9s - loss: 0.0057 - val_loss: 0.0048
 - val_f1: 0.9909
Epoch 96/300
 - 9s - loss: 0.0057 - val_loss: 0.0048
 - val_f1: 0.9911
Epoch 97/300
 - 9s - loss: 0.0056 - val_loss: 0.0044
 - val_f1: 0.9933
Epoch 98/300
 - 9s - loss: 0.0056 - val_loss: 0.0053
 - val_f1: 0.9894
Epoch 99/300
 - 9s - loss: 0.0057 - val_loss: 0.0042
 - val_f1: 0.9918
Epoch 100/300
 - 9s - loss: 0.0056 - val_loss: 0.0042
 - val_f1: 0.9922
Epoch 101/300
 - 9s - loss: 0.0056 - val_loss: 0.0046
 - val_f1: 0.9909
Epoch 102/300
 - 9s - loss: 0.0056 - val_loss: 0.0050
 - val_f1: 0.9898
Epoch 103/300
 - 9s - loss: 0.0056 - val_loss: 0.0041
 - val_f1: 0.9936
Epoch 104/300
 - 9s - loss: 0.0056 - val_loss: 0.0052
 - val_f1: 0.9893
Epoch 105/300
 - 9s - loss: 0.0056 - val_loss: 0.0045
 - val_f1: 0.9907
Epoch 106/300
 - 9s - loss: 0.0055 - val_loss: 0.0053
 - val_f1: 0.9900
Epoch 107/300
 - 9s - loss: 0.0055 - val_loss: 0.0042
 - val_f1: 0.9938
Epoch 108/300
 - 9s - loss: 0.0055 - val_loss: 0.0041
 - val_f1: 0.9933
Epoch 109/300
 - 9s - loss: 0.0055 - val_loss: 0.0053
 - val_f1: 0.9886
Epoch 110/300
 - 9s - loss: 0.0055 - val_loss: 0.0040
 - val_f1: 0.9937
Epoch 111/300
 - 9s - loss: 0.0055 - val_loss: 0.0051
 - val_f1: 0.9891
Epoch 112/300
 - 9s - loss: 0.0055 - val_loss: 0.0048
 - val_f1: 0.9894
Epoch 113/300
 - 9s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 114/300
 - 9s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 115/300
 - 9s - loss: 0.0054 - val_loss: 0.0041
 - val_f1: 0.9923
Epoch 116/300
 - 9s - loss: 0.0054 - val_loss: 0.0045
 - val_f1: 0.9910
Epoch 117/300
 - 9s - loss: 0.0054 - val_loss: 0.0058
 - val_f1: 0.9883
Epoch 118/300
 - 9s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9919
Epoch 119/300
 - 9s - loss: 0.0054 - val_loss: 0.0043
 - val_f1: 0.9916
Epoch 120/300
 - 9s - loss: 0.0054 - val_loss: 0.0040
 - val_f1: 0.9938
Epoch 121/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
2019-12-23 20:11:22,068 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9934
Epoch 122/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9919
Epoch 123/300
 - 9s - loss: 0.0053 - val_loss: 0.0052
 - val_f1: 0.9888
Epoch 124/300
 - 9s - loss: 0.0053 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 125/300
 - 9s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9933
Epoch 126/300
 - 9s - loss: 0.0053 - val_loss: 0.0039
 - val_f1: 0.9932
Epoch 127/300
 - 9s - loss: 0.0052 - val_loss: 0.0040
 - val_f1: 0.9924
Epoch 128/300
 - 9s - loss: 0.0053 - val_loss: 0.0051
 - val_f1: 0.9890
Epoch 129/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9924
Epoch 130/300
 - 9s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9892
Epoch 131/300
 - 9s - loss: 0.0053 - val_loss: 0.0040
 - val_f1: 0.9918
Epoch 132/300
 - 9s - loss: 0.0052 - val_loss: 0.0043
 - val_f1: 0.9905
Epoch 133/300
 - 9s - loss: 0.0052 - val_loss: 0.0038
 - val_f1: 0.9938
Epoch 134/300
 - 9s - loss: 0.0052 - val_loss: 0.0047
 - val_f1: 0.9906
Epoch 135/300
 - 9s - loss: 0.0052 - val_loss: 0.0041
 - val_f1: 0.9915
Epoch 136/300
 - 9s - loss: 0.0052 - val_loss: 0.0046
 - val_f1: 0.9899
Epoch 137/300
 - 9s - loss: 0.0051 - val_loss: 0.0042
 - val_f1: 0.9914
Epoch 138/300
 - 9s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9936
Epoch 139/300
 - 9s - loss: 0.0051 - val_loss: 0.0038
 - val_f1: 0.9933
Epoch 140/300
 - 9s - loss: 0.0051 - val_loss: 0.0037
 - val_f1: 0.9941
Epoch 141/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9937
Epoch 142/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9936
Epoch 143/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 144/300
 - 9s - loss: 0.0051 - val_loss: 0.0036
 - val_f1: 0.9943
Epoch 145/300
 - 9s - loss: 0.0050 - val_loss: 0.0049
 - val_f1: 0.9891
Epoch 146/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9934
Epoch 147/300
 - 9s - loss: 0.0050 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 148/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9939
Epoch 149/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9933
Epoch 150/300
 - 9s - loss: 0.0050 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 151/300
 - 9s - loss: 0.0050 - val_loss: 0.0040
2019-12-23 20:21:17,178 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9915
Epoch 152/300
 - 9s - loss: 0.0050 - val_loss: 0.0035
 - val_f1: 0.9938
Epoch 153/300
 - 9s - loss: 0.0050 - val_loss: 0.0042
 - val_f1: 0.9907
Epoch 154/300
 - 9s - loss: 0.0050 - val_loss: 0.0052
 - val_f1: 0.9900
Epoch 155/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9932
Epoch 156/300
 - 9s - loss: 0.0050 - val_loss: 0.0036
 - val_f1: 0.9941
Epoch 157/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9922
Epoch 158/300
 - 9s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9917
Epoch 159/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9939
Epoch 160/300
 - 9s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9916
Epoch 161/300
 - 9s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9912
Epoch 162/300
 - 9s - loss: 0.0049 - val_loss: 0.0040
 - val_f1: 0.9916
Epoch 163/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9942
Epoch 164/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 165/300
 - 9s - loss: 0.0049 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 166/300
 - 9s - loss: 0.0049 - val_loss: 0.0036
 - val_f1: 0.9920
Epoch 167/300
 - 9s - loss: 0.0049 - val_loss: 0.0037
 - val_f1: 0.9926
Epoch 168/300
 - 9s - loss: 0.0048 - val_loss: 0.0044
 - val_f1: 0.9897
Epoch 169/300
 - 9s - loss: 0.0049 - val_loss: 0.0038
 - val_f1: 0.9920
Epoch 170/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9931
Epoch 171/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9944
Epoch 172/300
 - 9s - loss: 0.0049 - val_loss: 0.0046
 - val_f1: 0.9907
Epoch 173/300
 - 9s - loss: 0.0048 - val_loss: 0.0040
 - val_f1: 0.9909
Epoch 174/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9903
Epoch 175/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9926
Epoch 176/300
 - 9s - loss: 0.0048 - val_loss: 0.0038
 - val_f1: 0.9927
Epoch 177/300
 - 9s - loss: 0.0049 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 178/300
 - 9s - loss: 0.0049 - val_loss: 0.0035
 - val_f1: 0.9928
Epoch 179/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9940
Epoch 180/300
 - 9s - loss: 0.0048 - val_loss: 0.0039
 - val_f1: 0.9911
Epoch 181/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
2019-12-23 20:31:12,038 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9938
Epoch 182/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 183/300
 - 9s - loss: 0.0048 - val_loss: 0.0037
 - val_f1: 0.9919
Epoch 184/300
 - 9s - loss: 0.0048 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 185/300
 - 9s - loss: 0.0048 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 186/300
 - 9s - loss: 0.0047 - val_loss: 0.0054
 - val_f1: 0.9896
Epoch 187/300
 - 9s - loss: 0.0048 - val_loss: 0.0034
 - val_f1: 0.9940
Epoch 188/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9938
Epoch 189/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9934
Epoch 190/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9930
Epoch 191/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 192/300
 - 9s - loss: 0.0048 - val_loss: 0.0035
 - val_f1: 0.9922
Epoch 193/300
 - 9s - loss: 0.0047 - val_loss: 0.0044
 - val_f1: 0.9902
Epoch 194/300
 - 9s - loss: 0.0047 - val_loss: 0.0042
 - val_f1: 0.9913
Epoch 195/300
 - 9s - loss: 0.0047 - val_loss: 0.0045
 - val_f1: 0.9904
Epoch 196/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 197/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 198/300
 - 9s - loss: 0.0047 - val_loss: 0.0047
 - val_f1: 0.9906
Epoch 199/300
 - 9s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9916
Epoch 200/300
 - 9s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 201/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 202/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9943
Epoch 203/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9936
Epoch 204/300
 - 9s - loss: 0.0047 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 205/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9929
Epoch 206/300
 - 9s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9918
Epoch 207/300
 - 9s - loss: 0.0047 - val_loss: 0.0034
 - val_f1: 0.9931
Epoch 208/300
 - 9s - loss: 0.0047 - val_loss: 0.0041
 - val_f1: 0.9912
Epoch 209/300
 - 9s - loss: 0.0047 - val_loss: 0.0037
 - val_f1: 0.9920
Epoch 210/300
 - 9s - loss: 0.0047 - val_loss: 0.0033
 - val_f1: 0.9943
Epoch 211/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
2019-12-23 20:41:07,528 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9922
Epoch 212/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 213/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9936
Epoch 214/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 215/300
 - 9s - loss: 0.0047 - val_loss: 0.0035
 - val_f1: 0.9921
Epoch 216/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 217/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9939
Epoch 218/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9943
Epoch 219/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9932
Epoch 220/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9937
Epoch 221/300
 - 9s - loss: 0.0046 - val_loss: 0.0057
 - val_f1: 0.9887
Epoch 222/300
 - 9s - loss: 0.0047 - val_loss: 0.0039
 - val_f1: 0.9917
Epoch 223/300
 - 9s - loss: 0.0046 - val_loss: 0.0042
 - val_f1: 0.9913
Epoch 224/300
 - 9s - loss: 0.0046 - val_loss: 0.0037
 - val_f1: 0.9931
Epoch 225/300
 - 9s - loss: 0.0046 - val_loss: 0.0053
 - val_f1: 0.9904
Epoch 226/300
 - 9s - loss: 0.0046 - val_loss: 0.0041
 - val_f1: 0.9907
Epoch 227/300
 - 9s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9942
Epoch 228/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9934
Epoch 229/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9919
Epoch 230/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9944
Epoch 231/300
 - 9s - loss: 0.0046 - val_loss: 0.0083
 - val_f1: 0.9862
Epoch 232/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9929
Epoch 233/300
 - 9s - loss: 0.0046 - val_loss: 0.0035
 - val_f1: 0.9932
Epoch 234/300
 - 9s - loss: 0.0045 - val_loss: 0.0038
 - val_f1: 0.9914
Epoch 235/300
 - 9s - loss: 0.0046 - val_loss: 0.0038
 - val_f1: 0.9910
Epoch 236/300
 - 9s - loss: 0.0045 - val_loss: 0.0037
 - val_f1: 0.9940
Epoch 237/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9939
Epoch 238/300
 - 9s - loss: 0.0045 - val_loss: 0.0035
 - val_f1: 0.9923
Epoch 239/300
 - 10s - loss: 0.0046 - val_loss: 0.0033
 - val_f1: 0.9931
Epoch 240/300
 - 9s - loss: 0.0046 - val_loss: 0.0034
 - val_f1: 0.9932
Epoch 241/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
2019-12-23 20:51:02,943 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9943
Epoch 242/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9921
Epoch 243/300
 - 9s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9920
Epoch 244/300
 - 9s - loss: 0.0045 - val_loss: 0.0051
 - val_f1: 0.9906
Epoch 245/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9933
Epoch 246/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 247/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9942
Epoch 248/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9943
Epoch 249/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 250/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9918
Epoch 251/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 252/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 253/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 254/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9926
Epoch 255/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9949
Epoch 256/300
 - 9s - loss: 0.0045 - val_loss: 0.0036
 - val_f1: 0.9923
Epoch 257/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9941
Epoch 258/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9948
Epoch 259/300
 - 9s - loss: 0.0045 - val_loss: 0.0039
 - val_f1: 0.9909
Epoch 260/300
 - 9s - loss: 0.0044 - val_loss: 0.0039
 - val_f1: 0.9918
Epoch 261/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9931
Epoch 262/300
 - 9s - loss: 0.0045 - val_loss: 0.0042
 - val_f1: 0.9919
Epoch 263/300
 - 9s - loss: 0.0045 - val_loss: 0.0034
 - val_f1: 0.9933
Epoch 264/300
 - 9s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 265/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9940
Epoch 266/300
 - 9s - loss: 0.0045 - val_loss: 0.0032
 - val_f1: 0.9941
Epoch 267/300
 - 9s - loss: 0.0044 - val_loss: 0.0044
 - val_f1: 0.9902
Epoch 268/300
 - 9s - loss: 0.0044 - val_loss: 0.0035
 - val_f1: 0.9919
Epoch 269/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 270/300
 - 9s - loss: 0.0045 - val_loss: 0.0033
 - val_f1: 0.9922
Epoch 271/300
 - 9s - loss: 0.0044 - val_loss: 0.0035
2019-12-23 21:00:58,795 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9923
Epoch 272/300
 - 9s - loss: 0.0045 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 273/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9916
Epoch 274/300
 - 9s - loss: 0.0044 - val_loss: 0.0044
 - val_f1: 0.9913
Epoch 275/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9922
Epoch 276/300
 - 9s - loss: 0.0044 - val_loss: 0.0038
 - val_f1: 0.9934
Epoch 277/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9936
Epoch 278/300
 - 10s - loss: 0.0044 - val_loss: 0.0030
 - val_f1: 0.9950
Epoch 279/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9938
Epoch 280/300
 - 10s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9925
Epoch 281/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9924
Epoch 282/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 283/300
 - 9s - loss: 0.0044 - val_loss: 0.0033
 - val_f1: 0.9947
Epoch 284/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9947
Epoch 285/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9948
Epoch 286/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9932
Epoch 287/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9939
Epoch 288/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9925
Epoch 289/300
 - 9s - loss: 0.0044 - val_loss: 0.0036
 - val_f1: 0.9925
Epoch 290/300
 - 9s - loss: 0.0044 - val_loss: 0.0031
 - val_f1: 0.9941
Epoch 291/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9940
Epoch 292/300
 - 9s - loss: 0.0043 - val_loss: 0.0032
 - val_f1: 0.9949
Epoch 293/300
 - 9s - loss: 0.0044 - val_loss: 0.0037
 - val_f1: 0.9921
Epoch 294/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9944
Epoch 295/300
 - 9s - loss: 0.0044 - val_loss: 0.0032
 - val_f1: 0.9945
Epoch 296/300
 - 9s - loss: 0.0043 - val_loss: 0.0033
 - val_f1: 0.9930
Epoch 297/300
 - 9s - loss: 0.0043 - val_loss: 0.0038
 - val_f1: 0.9918
Epoch 298/300
 - 9s - loss: 0.0043 - val_loss: 0.0041
 - val_f1: 0.9908
Epoch 299/300
 - 9s - loss: 0.0043 - val_loss: 0.0031
 - val_f1: 0.9946
Epoch 300/300
 - 9s - loss: 0.0043 - val_loss: 0.0061
2019-12-23 21:10:44,393 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 21:11:11,325 [INFO] Last epoch loss evaluation: train_loss = 0.002909, val_loss = 0.002982
2019-12-23 21:11:11,365 [INFO] Training complete. time_to_train = 6346.27 sec, 105.77 min
2019-12-23 21:11:11,368 [INFO] Model saved to results_selected_models/selected_ids17_dbn_shallow_rep5/best_model.pickle
2019-12-23 21:11:11,510 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep5/training_error_history.png
2019-12-23 21:11:11,639 [INFO] Plot saved to: results_selected_models/selected_ids17_dbn_shallow_rep5/training_f1_history.png
2019-12-23 21:11:11,639 [INFO] Making predictions on training, validation, testing data
2019-12-23 21:12:01,303 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 21:12:11,648 [INFO] Dataset: Testing. Classification report below
2019-12-23 21:12:11,648 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454265
                   Bot       0.97      0.37      0.54       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.97      0.98      2058
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.86      0.95      0.90      1100
         DoS slowloris       0.99      0.87      0.93      1159
           FTP-Patator       1.00      1.00      1.00      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.94      0.98      0.96      1179
Web Attack Brute Force       0.76      0.05      0.10       302
        Web Attack XSS       0.00      0.00      0.00       130

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.87      0.76      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 21:12:11,648 [INFO] Overall accuracy (micro avg): 0.9946478016556982
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-23 21:12:23,418 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9946         0.9946                       0.9946                0.0005                   0.0054  0.9946
1     Macro avg        0.9991         0.8720                       0.7644                0.0013                   0.2356  0.7807
2  Weighted avg        0.9957         0.9943                       0.9946                0.0102                   0.0054  0.9942
2019-12-23 21:12:33,920 [INFO] Dataset: Validation. Classification report below
2019-12-23 21:12:33,920 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00    454264
                   Bot       0.97      0.34      0.50       391
                  DDoS       1.00      1.00      1.00     25605
         DoS GoldenEye       0.99      0.96      0.97      2059
              DoS Hulk       0.98      0.99      0.98     46025
      DoS Slowhttptest       0.86      0.94      0.90      1099
         DoS slowloris       0.99      0.88      0.93      1159
           FTP-Patator       0.99      1.00      0.99      1587
              PortScan       0.99      1.00      0.99     31761
           SSH-Patator       0.94      0.97      0.96      1180
Web Attack Brute Force       0.86      0.06      0.11       301
        Web Attack XSS       0.00      0.00      0.00       131

             micro avg       0.99      0.99      0.99    565562
             macro avg       0.88      0.76      0.78    565562
          weighted avg       0.99      0.99      0.99    565562

2019-12-23 21:12:33,920 [INFO] Overall accuracy (micro avg): 0.9947910220276468
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 21:12:45,872 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9948         0.9948                       0.9948                0.0005                   0.0052  0.9948
1     Macro avg        0.9991         0.8804                       0.7615                0.0013                   0.2385  0.7790
2  Weighted avg        0.9958         0.9945                       0.9948                0.0099                   0.0052  0.9944
2019-12-23 21:13:20,732 [INFO] Dataset: Training. Classification report below
2019-12-23 21:13:20,733 [INFO] 
                        precision    recall  f1-score   support

                BENIGN       1.00      1.00      1.00   1362791
                   Bot       0.97      0.36      0.53      1174
                  DDoS       1.00      1.00      1.00     76815
         DoS GoldenEye       0.99      0.97      0.98      6176
              DoS Hulk       0.98      0.99      0.99    138074
      DoS Slowhttptest       0.87      0.95      0.91      3300
         DoS slowloris       0.99      0.89      0.94      3478
           FTP-Patator       1.00      0.99      1.00      4761
              PortScan       0.99      1.00      0.99     95282
           SSH-Patator       0.95      0.98      0.97      3538
Web Attack Brute Force       0.78      0.07      0.12       904
        Web Attack XSS       0.00      0.00      0.00       391

             micro avg       0.99      0.99      0.99   1696684
             macro avg       0.88      0.77      0.78   1696684
          weighted avg       0.99      0.99      0.99   1696684

2019-12-23 21:13:20,733 [INFO] Overall accuracy (micro avg): 0.9948735297792636
2019-12-23 21:14:00,297 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9949         0.9949                       0.9949                0.0005                   0.0051  0.9949
1     Macro avg        0.9991         0.8765                       0.7661                0.0013                   0.2339  0.7841
2  Weighted avg        0.9958         0.9946                       0.9949                0.0099                   0.0051  0.9945
2019-12-23 21:14:00,322 [INFO] Results saved to: results_selected_models/selected_ids17_dbn_shallow_rep5/selected_ids17_dbn_shallow_rep5_results.xlsx
2019-12-23 21:14:00,328 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-23 21:14:00,397 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep1
2019-12-23 21:14:00,397 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_shallow_rep1/run_log.log
2019-12-23 21:14:00,397 [INFO] ================= Running experiment no. 1  ================= 

2019-12-23 21:14:00,397 [INFO] Experiment parameters given below
2019-12-23 21:14:00,397 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_shallow_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_shallow_rep1'}
2019-12-23 21:14:00,397 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep1/tf_logs_run_2019_12_23-21_14_00
2019-12-23 21:14:00,397 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-23 21:14:00,398 [INFO] Reading X, y files
2019-12-23 21:14:00,398 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-23 21:14:06,097 [INFO] Reading complete. time_to_read=5.70 seconds
2019-12-23 21:14:06,097 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-23 21:14:07,640 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-23 21:14:07,640 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-23 21:14:09,183 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-23 21:14:09,183 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-23 21:14:09,450 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-23 21:14:09,450 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-23 21:14:09,536 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-23 21:14:09,536 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-23 21:14:09,621 [INFO] Reading complete. time_to_read=0.08 seconds
2019-12-23 21:14:13,576 [INFO] Initializing model
2019-12-23 21:14:13,577 [INFO] Training model
2019-12-23 21:14:13,577 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 21:14:37,262 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 6c92556f737a8ab4f18fdf91db738b2bc13dee53
2019-12-23 21:14:37,262 [INFO] Pretraining Deep Belief Network
2019-12-23 21:21:09,791 [INFO] Pretraining Complete
2019-12-23 21:21:09,791 [INFO] Getting pretrained weights
2019-12-23 21:21:09,791 [INFO] Creating and initializing feed forward neural network
2019-12-23 21:21:09,923 [INFO] _________________________________________________________________
2019-12-23 21:21:09,923 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 21:21:09,923 [INFO] =================================================================
2019-12-23 21:21:09,923 [INFO] dense_21 (Dense)             (None, 32)                2496      
2019-12-23 21:21:09,923 [INFO] _________________________________________________________________
2019-12-23 21:21:09,924 [INFO] batch_normalization_11 (Batc (None, 32)                128       
2019-12-23 21:21:09,924 [INFO] _________________________________________________________________
2019-12-23 21:21:09,924 [INFO] dropout_11 (Dropout)         (None, 32)                0         
2019-12-23 21:21:09,924 [INFO] _________________________________________________________________
2019-12-23 21:21:09,924 [INFO] dense_22 (Dense)             (None, 15)                495       
2019-12-23 21:21:09,924 [INFO] =================================================================
2019-12-23 21:21:09,924 [INFO] Total params: 3,119
2019-12-23 21:21:09,924 [INFO] Trainable params: 3,055
2019-12-23 21:21:09,924 [INFO] Non-trainable params: 64
2019-12-23 21:21:09,924 [INFO] _________________________________________________________________
2019-12-23 21:21:10,748 [INFO] Fine-tuning final neural network
 - val_f1: 0.9897
[BernoulliRBM] Iteration 1, pseudo-likelihood = -32.96, time = 5.15s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.34, time = 8.39s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -34.11, time = 8.15s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.84, time = 8.18s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -39.82, time = 8.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -42.81, time = 8.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -45.52, time = 8.19s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.97, time = 8.17s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -50.25, time = 8.17s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -52.40, time = 8.12s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.50, time = 8.10s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.54, time = 8.08s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -58.54, time = 8.06s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.51, time = 8.07s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -62.49, time = 8.01s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -64.43, time = 7.95s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -66.35, time = 7.93s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -68.25, time = 7.90s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -70.14, time = 7.85s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -72.03, time = 7.81s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -73.92, time = 7.80s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -75.81, time = 7.76s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -77.70, time = 7.75s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -79.59, time = 7.74s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -81.48, time = 7.73s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -83.36, time = 7.73s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -85.25, time = 7.73s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -87.14, time = 7.72s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -89.03, time = 7.72s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -90.93, time = 7.71s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -92.82, time = 7.72s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -94.72, time = 7.72s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -96.61, time = 7.72s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -98.52, time = 7.71s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -100.43, time = 7.70s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -102.34, time = 7.70s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -104.25, time = 7.70s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -106.17, time = 7.69s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -108.09, time = 7.69s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -110.01, time = 7.70s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -111.93, time = 7.69s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.86, time = 7.69s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -115.79, time = 7.69s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -117.71, time = 7.68s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -119.64, time = 7.68s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -121.57, time = 7.68s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -123.49, time = 7.68s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -125.42, time = 7.68s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -127.35, time = 7.68s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -129.29, time = 7.68s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 12s - loss: 0.0745 - val_loss: 0.0494
 - val_f1: 0.8861
Epoch 2/300
 - 12s - loss: 0.0473 - val_loss: 0.0403
 - val_f1: 0.9149
Epoch 3/300
 - 12s - loss: 0.0413 - val_loss: 0.0376
 - val_f1: 0.9203
Epoch 4/300
 - 12s - loss: 0.0391 - val_loss: 0.0360
 - val_f1: 0.9231
Epoch 5/300
 - 12s - loss: 0.0373 - val_loss: 0.0334
 - val_f1: 0.9238
Epoch 6/300
 - 12s - loss: 0.0349 - val_loss: 0.0314
 - val_f1: 0.9247
Epoch 7/300
 - 12s - loss: 0.0298 - val_loss: 0.0206
 - val_f1: 0.9423
Epoch 8/300
 - 12s - loss: 0.0227 - val_loss: 0.0365
 - val_f1: 0.9067
Epoch 9/300
 - 12s - loss: 0.0183 - val_loss: 0.0126
 - val_f1: 0.9756
Epoch 10/300
 - 12s - loss: 0.0169 - val_loss: 0.0123
 - val_f1: 0.9790
Epoch 11/300
 - 12s - loss: 0.0155 - val_loss: 0.0108
 - val_f1: 0.9790
Epoch 12/300
 - 12s - loss: 0.0139 - val_loss: 0.0104
 - val_f1: 0.9796
Epoch 13/300
 - 12s - loss: 0.0132 - val_loss: 0.0108
 - val_f1: 0.9796
Epoch 14/300
 - 12s - loss: 0.0127 - val_loss: 0.0595
 - val_f1: 0.9009
Epoch 15/300
 - 12s - loss: 0.0124 - val_loss: 0.0095
 - val_f1: 0.9806
Epoch 16/300
 - 12s - loss: 0.0120 - val_loss: 0.0147
 - val_f1: 0.9589
Epoch 17/300
 - 12s - loss: 0.0117 - val_loss: 0.0126
 - val_f1: 0.9694
Epoch 18/300
 - 12s - loss: 0.0115 - val_loss: 0.0137
 - val_f1: 0.9666
Epoch 19/300
 - 12s - loss: 0.0113 - val_loss: 0.0095
 - val_f1: 0.9808
Epoch 20/300
 - 12s - loss: 0.0111 - val_loss: 0.0091
 - val_f1: 0.9820
Epoch 21/300
 - 12s - loss: 0.0108 - val_loss: 0.0127
 - val_f1: 0.9771
Epoch 22/300
 - 12s - loss: 0.0105 - val_loss: 0.0088
 - val_f1: 0.9819
Epoch 23/300
 - 12s - loss: 0.0104 - val_loss: 0.0096
 - val_f1: 0.9807
Epoch 24/300
 - 12s - loss: 0.0102 - val_loss: 0.0636
 - val_f1: 0.8730
Epoch 25/300
 - 12s - loss: 0.0101 - val_loss: 0.0292
 - val_f1: 0.9215
Epoch 26/300
 - 12s - loss: 0.0101 - val_loss: 0.0092
 - val_f1: 0.9813
Epoch 27/300
 - 12s - loss: 0.0100 - val_loss: 0.0213
 - val_f1: 0.9413
Epoch 28/300
 - 12s - loss: 0.0099 - val_loss: 0.0094
 - val_f1: 0.9814
Epoch 29/300
 - 12s - loss: 0.0098 - val_loss: 0.0087
 - val_f1: 0.9821
Epoch 30/300
 - 12s - loss: 0.0097 - val_loss: 0.0224
 - val_f1: 0.9366
Epoch 31/300
 - 12s - loss: 0.0096 - val_loss: 0.0088
2019-12-23 21:33:35,787 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9822
Epoch 32/300
 - 12s - loss: 0.0095 - val_loss: 0.0133
 - val_f1: 0.9775
Epoch 33/300
 - 12s - loss: 0.0095 - val_loss: 0.0088
 - val_f1: 0.9827
Epoch 34/300
 - 12s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9823
Epoch 35/300
 - 12s - loss: 0.0094 - val_loss: 0.0087
 - val_f1: 0.9823
Epoch 36/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 37/300
 - 12s - loss: 0.0093 - val_loss: 0.0821
 - val_f1: 0.8726
Epoch 38/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 39/300
 - 12s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 40/300
 - 12s - loss: 0.0092 - val_loss: 0.0186
 - val_f1: 0.9366
Epoch 41/300
 - 12s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 42/300
 - 12s - loss: 0.0091 - val_loss: 0.0208
 - val_f1: 0.9537
Epoch 43/300
 - 12s - loss: 0.0091 - val_loss: 0.0095
 - val_f1: 0.9806
Epoch 44/300
 - 12s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 45/300
 - 12s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9825
Epoch 46/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 47/300
 - 12s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 48/300
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 49/300
 - 12s - loss: 0.0090 - val_loss: 0.0480
 - val_f1: 0.9026
Epoch 50/300
 - 12s - loss: 0.0090 - val_loss: 0.0087
 - val_f1: 0.9822
Epoch 51/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9822
Epoch 52/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 53/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 54/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 55/300
 - 12s - loss: 0.0089 - val_loss: 0.0167
 - val_f1: 0.9557
Epoch 56/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 57/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9808
Epoch 58/300
 - 12s - loss: 0.0089 - val_loss: 0.0122
 - val_f1: 0.9774
Epoch 59/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 60/300
 - 12s - loss: 0.0089 - val_loss: 0.0168
 - val_f1: 0.9716
Epoch 61/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
2019-12-23 21:45:43,062 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9809
Epoch 62/300
 - 12s - loss: 0.0088 - val_loss: 0.0088
 - val_f1: 0.9822
Epoch 63/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 64/300
 - 12s - loss: 0.0088 - val_loss: 0.0102
 - val_f1: 0.9780
Epoch 65/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 66/300
 - 12s - loss: 0.0088 - val_loss: 0.0291
 - val_f1: 0.9375
Epoch 67/300
 - 12s - loss: 0.0088 - val_loss: 0.0123
 - val_f1: 0.9723
Epoch 68/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 69/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 70/300
 - 12s - loss: 0.0088 - val_loss: 0.0150
 - val_f1: 0.9646
Epoch 71/300
 - 12s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 72/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 73/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 74/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9825
Epoch 75/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 76/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 77/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9825
Epoch 78/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 79/300
 - 12s - loss: 0.0087 - val_loss: 0.0099
 - val_f1: 0.9789
Epoch 80/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 81/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 82/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 83/300
 - 12s - loss: 0.0087 - val_loss: 0.0302
 - val_f1: 0.9293
Epoch 84/300
 - 12s - loss: 0.0087 - val_loss: 0.0091
 - val_f1: 0.9808
Epoch 85/300
 - 12s - loss: 0.0087 - val_loss: 0.0129
 - val_f1: 0.9714
Epoch 86/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 87/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9825
Epoch 88/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 89/300
 - 12s - loss: 0.0087 - val_loss: 0.0099
 - val_f1: 0.9790
Epoch 90/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 91/300
 - 12s - loss: 0.0087 - val_loss: 0.0137
2019-12-23 21:57:57,460 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9694
Epoch 92/300
 - 12s - loss: 0.0087 - val_loss: 0.0325
 - val_f1: 0.9288
Epoch 93/300
 - 12s - loss: 0.0086 - val_loss: 0.0088
 - val_f1: 0.9818
Epoch 94/300
 - 12s - loss: 0.0086 - val_loss: 0.0634
 - val_f1: 0.8926
Epoch 95/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 96/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 97/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 98/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 99/300
 - 12s - loss: 0.0086 - val_loss: 0.0088
 - val_f1: 0.9823
Epoch 100/300
 - 12s - loss: 0.0086 - val_loss: 0.0196
 - val_f1: 0.9410
Epoch 101/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 102/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 103/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 104/300
 - 12s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9807
Epoch 105/300
 - 12s - loss: 0.0086 - val_loss: 0.0105
 - val_f1: 0.9791
Epoch 106/300
 - 12s - loss: 0.0086 - val_loss: 0.0111
 - val_f1: 0.9724
Epoch 107/300
 - 12s - loss: 0.0086 - val_loss: 0.0108
 - val_f1: 0.9784
Epoch 108/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 109/300
 - 12s - loss: 0.0086 - val_loss: 0.0235
 - val_f1: 0.9370
Epoch 110/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 111/300
 - 12s - loss: 0.0086 - val_loss: 0.0128
 - val_f1: 0.9714
Epoch 112/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 113/300
 - 12s - loss: 0.0085 - val_loss: 0.0133
 - val_f1: 0.9654
Epoch 114/300
 - 12s - loss: 0.0085 - val_loss: 0.0098
 - val_f1: 0.9732
Epoch 115/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 116/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 117/300
 - 12s - loss: 0.0086 - val_loss: 0.0117
 - val_f1: 0.9694
Epoch 118/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 119/300
 - 12s - loss: 0.0085 - val_loss: 0.0106
 - val_f1: 0.9720
Epoch 120/300
 - 12s - loss: 0.0085 - val_loss: 0.0100
 - val_f1: 0.9787
Epoch 121/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
2019-12-23 22:10:12,114 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9826
Epoch 122/300
 - 12s - loss: 0.0085 - val_loss: 0.0097
 - val_f1: 0.9778
Epoch 123/300
 - 12s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 124/300
 - 12s - loss: 0.0085 - val_loss: 0.0227
 - val_f1: 0.9651
Epoch 125/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9820
Epoch 126/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 127/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 128/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 129/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 130/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 131/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 132/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 133/300
 - 12s - loss: 0.0085 - val_loss: 0.0100
 - val_f1: 0.9792
Epoch 134/300
 - 12s - loss: 0.0085 - val_loss: 0.0111
 - val_f1: 0.9724
Epoch 135/300
 - 12s - loss: 0.0085 - val_loss: 0.0102
 - val_f1: 0.9785
Epoch 136/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9810
Epoch 137/300
 - 12s - loss: 0.0085 - val_loss: 0.0101
 - val_f1: 0.9792
Epoch 138/300
 - 12s - loss: 0.0085 - val_loss: 0.0112
 - val_f1: 0.9734
Epoch 139/300
 - 12s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 140/300
 - 12s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 141/300
 - 12s - loss: 0.0085 - val_loss: 0.0189
 - val_f1: 0.9708
Epoch 142/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 143/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 144/300
 - 12s - loss: 0.0085 - val_loss: 0.0095
 - val_f1: 0.9812
Epoch 145/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 146/300
 - 12s - loss: 0.0085 - val_loss: 0.0109
 - val_f1: 0.9727
Epoch 147/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 148/300
 - 12s - loss: 0.0085 - val_loss: 0.0211
 - val_f1: 0.9693
Epoch 149/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 150/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 151/300
 - 12s - loss: 0.0084 - val_loss: 0.0092
2019-12-23 22:22:26,622 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9816
Epoch 152/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 153/300
 - 12s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9821
Epoch 154/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 155/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 156/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 157/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 158/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 159/300
 - 12s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9821
Epoch 160/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 161/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 162/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9811
Epoch 163/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 164/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 165/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 166/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 167/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 168/300
 - 12s - loss: 0.0084 - val_loss: 0.0100
 - val_f1: 0.9724
Epoch 169/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 170/300
 - 12s - loss: 0.0084 - val_loss: 0.0161
 - val_f1: 0.9708
Epoch 171/300
 - 12s - loss: 0.0084 - val_loss: 0.0196
 - val_f1: 0.9501
Epoch 172/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 173/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 174/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 175/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 176/300
 - 12s - loss: 0.0084 - val_loss: 0.0292
 - val_f1: 0.9125
Epoch 177/300
 - 12s - loss: 0.0084 - val_loss: 0.0095
 - val_f1: 0.9796
Epoch 178/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 179/300
 - 12s - loss: 0.0084 - val_loss: 0.0087
 - val_f1: 0.9822
Epoch 180/300
 - 12s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 181/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
2019-12-23 22:34:43,560 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_180.pickle
 - val_f1: 0.9829
Epoch 182/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 183/300
 - 12s - loss: 0.0084 - val_loss: 0.0147
 - val_f1: 0.9716
Epoch 184/300
 - 12s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9807
Epoch 185/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 186/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 187/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 188/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 189/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 190/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 191/300
 - 12s - loss: 0.0084 - val_loss: 0.0185
 - val_f1: 0.9667
Epoch 192/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 193/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 194/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 195/300
 - 12s - loss: 0.0084 - val_loss: 0.0132
 - val_f1: 0.9669
Epoch 196/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9825
Epoch 197/300
 - 12s - loss: 0.0084 - val_loss: 0.0103
 - val_f1: 0.9724
Epoch 198/300
 - 12s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9805
Epoch 199/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 200/300
 - 12s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9814
Epoch 201/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 202/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 203/300
 - 12s - loss: 0.0084 - val_loss: 0.0099
 - val_f1: 0.9805
Epoch 204/300
 - 12s - loss: 0.0084 - val_loss: 0.0111
 - val_f1: 0.9730
Epoch 205/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 206/300
 - 12s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 207/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 208/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 209/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 210/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 211/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
2019-12-23 22:47:01,084 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_210.pickle
 - val_f1: 0.9833
Epoch 212/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 213/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 214/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 215/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9811
Epoch 216/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 217/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 218/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 219/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 220/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 221/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 222/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 223/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 224/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 225/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 226/300
 - 12s - loss: 0.0084 - val_loss: 0.0135
 - val_f1: 0.9723
Epoch 227/300
 - 12s - loss: 0.0083 - val_loss: 0.0127
 - val_f1: 0.9723
Epoch 228/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 229/300
 - 12s - loss: 0.0084 - val_loss: 0.0095
 - val_f1: 0.9807
Epoch 230/300
 - 12s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9800
Epoch 231/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 232/300
 - 12s - loss: 0.0083 - val_loss: 0.0089
 - val_f1: 0.9813
Epoch 233/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 234/300
 - 12s - loss: 0.0084 - val_loss: 0.0134
 - val_f1: 0.9723
Epoch 235/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 236/300
 - 12s - loss: 0.0084 - val_loss: 0.0114
 - val_f1: 0.9724
Epoch 237/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 238/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 239/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 240/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 241/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
2019-12-23 22:59:19,420 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_240.pickle
 - val_f1: 0.9829
Epoch 242/300
 - 12s - loss: 0.0083 - val_loss: 0.0249
 - val_f1: 0.9290
Epoch 243/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 244/300
 - 12s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 245/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 246/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9831
Epoch 247/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 248/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 249/300
 - 12s - loss: 0.0084 - val_loss: 0.0100
 - val_f1: 0.9793
Epoch 250/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 251/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 252/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 253/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 254/300
 - 12s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9804
Epoch 255/300
 - 12s - loss: 0.0083 - val_loss: 0.0095
 - val_f1: 0.9801
Epoch 256/300
 - 12s - loss: 0.0083 - val_loss: 0.0117
 - val_f1: 0.9724
Epoch 257/300
 - 12s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 258/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 259/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 260/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 261/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 262/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 263/300
 - 12s - loss: 0.0084 - val_loss: 0.0100
 - val_f1: 0.9798
Epoch 264/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9815
Epoch 265/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 266/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 267/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 268/300
 - 12s - loss: 0.0083 - val_loss: 0.0118
 - val_f1: 0.9721
Epoch 269/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 270/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9820
Epoch 271/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
2019-12-23 23:11:36,538 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/ann_model_epoch_270.pickle
 - val_f1: 0.9832
Epoch 272/300
 - 12s - loss: 0.0083 - val_loss: 0.0136
 - val_f1: 0.9717
Epoch 273/300
 - 12s - loss: 0.0083 - val_loss: 0.0091
 - val_f1: 0.9807
Epoch 274/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 275/300
 - 12s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9806
Epoch 276/300
 - 12s - loss: 0.0083 - val_loss: 0.0145
 - val_f1: 0.9717
Epoch 277/300
 - 12s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9797
Epoch 278/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 279/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 280/300
 - 12s - loss: 0.0083 - val_loss: 0.0093
 - val_f1: 0.9802
Epoch 281/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 282/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 283/300
 - 12s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 284/300
 - 12s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9805
Epoch 285/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 286/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 287/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 288/300
 - 12s - loss: 0.0083 - val_loss: 0.0138
 - val_f1: 0.9720
Epoch 289/300
 - 12s - loss: 0.0083 - val_loss: 0.0110
 - val_f1: 0.9724
Epoch 290/300
 - 12s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9822
Epoch 291/300
 - 12s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9805
Epoch 292/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 293/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9826
Epoch 294/300
 - 12s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9783
Epoch 295/300
 - 12s - loss: 0.0083 - val_loss: 0.0090
 - val_f1: 0.9814
Epoch 296/300
 - 12s - loss: 0.0083 - val_loss: 0.0090
 - val_f1: 0.9810
Epoch 297/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 298/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 299/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 300/300
 - 12s - loss: 0.0083 - val_loss: 0.0170
2019-12-23 23:23:46,946 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-23 23:24:19,446 [INFO] Last epoch loss evaluation: train_loss = 0.008057, val_loss = 0.008076
2019-12-23 23:24:19,491 [INFO] Training complete. time_to_train = 7805.91 sec, 130.10 min
2019-12-23 23:24:19,494 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep1/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-23 23:24:19,673 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep1/training_error_history.png
2019-12-23 23:24:19,803 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep1/training_f1_history.png
2019-12-23 23:24:19,803 [INFO] Making predictions on training, validation, testing data
2019-12-23 23:25:19,378 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-23 23:25:31,578 [INFO] Dataset: Testing. Classification report below
2019-12-23 23:25:31,579 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.49      0.59      5596
   DoS attacks-Slowloris       0.96      0.97      0.96       440
          FTP-BruteForce       0.70      0.87      0.78      7718
           Infilteration       0.33      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.69      0.69      0.68    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-23 23:25:31,579 [INFO] Overall accuracy (micro avg): 0.9832948095084649
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-23 23:25:45,448 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.6933                       0.6880                0.0045                   0.3120  0.6763
2  Weighted avg        0.9909         0.9770                       0.9833                0.0501                   0.0167  0.9783
2019-12-23 23:25:57,634 [INFO] Dataset: Validation. Classification report below
2019-12-23 23:25:57,634 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.75      0.99      0.85        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.48      0.58      5596
   DoS attacks-Slowloris       0.95      0.97      0.96       439
          FTP-BruteForce       0.70      0.88      0.78      7718
           Infilteration       0.32      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.70      0.69      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-23 23:25:57,634 [INFO] Overall accuracy (micro avg): 0.9833273172039096
2019-12-23 23:26:11,496 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.6957                       0.6875                0.0044                   0.3125  0.6781
2  Weighted avg        0.9909         0.9769                       0.9833                0.0499                   0.0167  0.9783
2019-12-23 23:26:51,302 [INFO] Dataset: Training. Classification report below
2019-12-23 23:26:51,302 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.48      0.58     16787
   DoS attacks-Slowloris       0.96      0.98      0.97      1318
          FTP-BruteForce       0.70      0.88      0.78     23153
           Infilteration       0.38      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.70      0.69      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-23 23:26:51,302 [INFO] Overall accuracy (micro avg): 0.9833366211162419
2019-12-23 23:27:36,494 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.6982                       0.6872                0.0044                   0.3128  0.6771
2  Weighted avg        0.9909         0.9775                       0.9833                0.0498                   0.0167  0.9783
2019-12-23 23:27:36,533 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep1/selected_ids18_subset_dbn_shallow_rep1_results.xlsx
2019-12-23 23:27:36,538 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-23 23:27:36,622 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep2
2019-12-23 23:27:36,623 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_shallow_rep2/run_log.log
2019-12-23 23:27:36,623 [INFO] ================= Running experiment no. 2  ================= 

2019-12-23 23:27:36,623 [INFO] Experiment parameters given below
2019-12-23 23:27:36,623 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_shallow_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_shallow_rep2'}
2019-12-23 23:27:36,623 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep2/tf_logs_run_2019_12_23-23_27_36
2019-12-23 23:27:36,623 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-23 23:27:36,623 [INFO] Reading X, y files
2019-12-23 23:27:36,623 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-23 23:27:41,091 [INFO] Reading complete. time_to_read=4.47 seconds
2019-12-23 23:27:41,091 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-23 23:27:42,627 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-23 23:27:42,627 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-23 23:27:44,161 [INFO] Reading complete. time_to_read=1.53 seconds
2019-12-23 23:27:44,162 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-23 23:27:44,422 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-23 23:27:44,422 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-23 23:27:44,510 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-23 23:27:44,510 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-23 23:27:44,597 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-23 23:27:48,529 [INFO] Initializing model
2019-12-23 23:27:48,529 [INFO] Training model
2019-12-23 23:27:48,529 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-23 23:28:11,937 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 0866581d1416733ae4d4af268010d5a95bce4774
2019-12-23 23:28:11,937 [INFO] Pretraining Deep Belief Network
2019-12-23 23:34:42,926 [INFO] Pretraining Complete
2019-12-23 23:34:42,927 [INFO] Getting pretrained weights
2019-12-23 23:34:42,927 [INFO] Creating and initializing feed forward neural network
2019-12-23 23:34:43,044 [INFO] _________________________________________________________________
2019-12-23 23:34:43,044 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-23 23:34:43,044 [INFO] =================================================================
2019-12-23 23:34:43,044 [INFO] dense_23 (Dense)             (None, 32)                2496      
2019-12-23 23:34:43,044 [INFO] _________________________________________________________________
2019-12-23 23:34:43,044 [INFO] batch_normalization_12 (Batc (None, 32)                128       
2019-12-23 23:34:43,044 [INFO] _________________________________________________________________
2019-12-23 23:34:43,044 [INFO] dropout_12 (Dropout)         (None, 32)                0         
2019-12-23 23:34:43,044 [INFO] _________________________________________________________________
2019-12-23 23:34:43,045 [INFO] dense_24 (Dense)             (None, 15)                495       
2019-12-23 23:34:43,045 [INFO] =================================================================
2019-12-23 23:34:43,045 [INFO] Total params: 3,119
2019-12-23 23:34:43,045 [INFO] Trainable params: 3,055
2019-12-23 23:34:43,045 [INFO] Non-trainable params: 64
2019-12-23 23:34:43,045 [INFO] _________________________________________________________________
2019-12-23 23:34:43,964 [INFO] Fine-tuning final neural network
 - val_f1: 0.9719
[BernoulliRBM] Iteration 1, pseudo-likelihood = -32.95, time = 5.12s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.31, time = 8.35s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -34.00, time = 8.12s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.68, time = 8.15s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -39.64, time = 8.16s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -42.62, time = 8.16s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -45.33, time = 8.16s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.78, time = 8.14s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -50.06, time = 8.13s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -52.22, time = 8.10s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.33, time = 8.07s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.38, time = 8.05s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -58.40, time = 8.03s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.38, time = 8.03s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -62.37, time = 7.99s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -64.31, time = 7.92s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -66.24, time = 7.90s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -68.15, time = 7.87s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -70.05, time = 7.82s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -71.94, time = 7.79s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -73.83, time = 7.76s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -75.73, time = 7.73s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -77.62, time = 7.73s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -79.52, time = 7.71s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -81.41, time = 7.70s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -83.31, time = 7.70s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -85.20, time = 7.70s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -87.10, time = 7.70s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -89.00, time = 7.69s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -90.91, time = 7.69s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -92.81, time = 7.68s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -94.73, time = 7.68s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -96.64, time = 7.69s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -98.56, time = 7.67s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -100.47, time = 7.67s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -102.40, time = 7.67s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -104.32, time = 7.67s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -106.25, time = 7.68s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -108.18, time = 7.66s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -110.10, time = 7.66s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -112.04, time = 7.66s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.97, time = 7.66s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -115.89, time = 7.65s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -117.82, time = 7.66s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -119.74, time = 7.65s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -121.67, time = 7.65s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -123.60, time = 7.65s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -125.53, time = 7.66s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -127.46, time = 7.65s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -129.40, time = 7.65s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 12s - loss: 0.0738 - val_loss: 0.0508
 - val_f1: 0.8816
Epoch 2/300
 - 11s - loss: 0.0488 - val_loss: 0.0413
 - val_f1: 0.9136
Epoch 3/300
 - 12s - loss: 0.0421 - val_loss: 0.0382
 - val_f1: 0.9188
Epoch 4/300
 - 11s - loss: 0.0388 - val_loss: 0.0345
 - val_f1: 0.9236
Epoch 5/300
 - 12s - loss: 0.0363 - val_loss: 0.0324
 - val_f1: 0.9253
Epoch 6/300
 - 11s - loss: 0.0321 - val_loss: 0.0207
 - val_f1: 0.9522
Epoch 7/300
 - 12s - loss: 0.0218 - val_loss: 0.0150
 - val_f1: 0.9687
Epoch 8/300
 - 11s - loss: 0.0191 - val_loss: 0.0136
 - val_f1: 0.9711
Epoch 9/300
 - 11s - loss: 0.0177 - val_loss: 0.0128
 - val_f1: 0.9716
Epoch 10/300
 - 11s - loss: 0.0166 - val_loss: 0.0123
 - val_f1: 0.9719
Epoch 11/300
 - 12s - loss: 0.0160 - val_loss: 0.0123
 - val_f1: 0.9718
Epoch 12/300
 - 12s - loss: 0.0157 - val_loss: 0.0117
 - val_f1: 0.9721
Epoch 13/300
 - 12s - loss: 0.0151 - val_loss: 0.0114
 - val_f1: 0.9744
Epoch 14/300
 - 12s - loss: 0.0137 - val_loss: 0.0100
 - val_f1: 0.9800
Epoch 15/300
 - 12s - loss: 0.0126 - val_loss: 0.0096
 - val_f1: 0.9804
Epoch 16/300
 - 12s - loss: 0.0120 - val_loss: 0.0094
 - val_f1: 0.9805
Epoch 17/300
 - 11s - loss: 0.0113 - val_loss: 0.0091
 - val_f1: 0.9815
Epoch 18/300
 - 12s - loss: 0.0107 - val_loss: 0.0089
 - val_f1: 0.9813
Epoch 19/300
 - 12s - loss: 0.0104 - val_loss: 0.0088
 - val_f1: 0.9824
Epoch 20/300
 - 12s - loss: 0.0102 - val_loss: 0.0088
 - val_f1: 0.9822
Epoch 21/300
 - 12s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9826
Epoch 22/300
 - 12s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9826
Epoch 23/300
 - 12s - loss: 0.0099 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 24/300
 - 12s - loss: 0.0098 - val_loss: 0.0086
 - val_f1: 0.9827
Epoch 25/300
 - 12s - loss: 0.0097 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 26/300
 - 11s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9826
Epoch 27/300
 - 12s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 28/300
 - 11s - loss: 0.0095 - val_loss: 0.0085
 - val_f1: 0.9828
Epoch 29/300
 - 11s - loss: 0.0094 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 30/300
 - 12s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 31/300
 - 12s - loss: 0.0093 - val_loss: 0.0084
2019-12-23 23:47:17,637 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9828
Epoch 32/300
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 33/300
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 34/300
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 35/300
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 36/300
 - 11s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 37/300
 - 11s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9812
Epoch 38/300
 - 11s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 39/300
 - 11s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 40/300
 - 11s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 41/300
 - 11s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 42/300
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 43/300
 - 11s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 44/300
 - 11s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 45/300
 - 11s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 46/300
 - 11s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 47/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 48/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 49/300
 - 12s - loss: 0.0089 - val_loss: 0.0087
 - val_f1: 0.9820
Epoch 50/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 51/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 52/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 53/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 54/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 55/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 56/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 57/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 58/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 59/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 60/300
 - 11s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 61/300
 - 12s - loss: 0.0087 - val_loss: 0.0087
2019-12-23 23:59:36,900 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9820
Epoch 62/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9812
Epoch 63/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 64/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 65/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 66/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 67/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 68/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 69/300
 - 11s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 70/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 71/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 72/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9812
Epoch 73/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 74/300
 - 11s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 75/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 76/300
 - 11s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 77/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 78/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 79/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 80/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 81/300
 - 11s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 82/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 83/300
 - 11s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 84/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 85/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 86/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 87/300
 - 11s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 88/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 89/300
 - 12s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9822
Epoch 90/300
 - 11s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 91/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
2019-12-24 00:11:55,010 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9831
Epoch 92/300
 - 11s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 93/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 94/300
 - 11s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 95/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 96/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 97/300
 - 11s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 98/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 99/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 100/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 101/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 102/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 103/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 104/300
 - 11s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9822
Epoch 105/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 106/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 107/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 108/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 109/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 110/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 111/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 112/300
 - 11s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 113/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 114/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 115/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 116/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9819
Epoch 117/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9823
Epoch 118/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 119/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 120/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 121/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
2019-12-24 00:24:14,741 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9830
Epoch 122/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 123/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9815
Epoch 124/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 125/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 126/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 127/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 128/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 129/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 130/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 131/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 132/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 133/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 134/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 135/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 136/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 137/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 138/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 139/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 140/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 141/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 142/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 143/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 144/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 145/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 146/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 147/300
 - 11s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 148/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 149/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 150/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 151/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
2019-12-24 00:36:32,179 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9836
Epoch 152/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 153/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9818
Epoch 154/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 155/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 156/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 157/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 158/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 159/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 160/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 161/300
 - 11s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 162/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 163/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 164/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 165/300
 - 11s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 166/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 167/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 168/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 169/300
 - 11s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 170/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 171/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 172/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 173/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 174/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 175/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 176/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 177/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 178/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 179/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 180/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 181/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 00:48:50,321 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9833
Epoch 182/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 183/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 184/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 185/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 186/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 187/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 188/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 189/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 190/300
 - 12s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 191/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 192/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 193/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 194/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 195/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 196/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 197/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 198/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 199/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 200/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 201/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 202/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 203/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 204/300
 - 11s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 205/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 206/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 207/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 208/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 209/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 210/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 211/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 01:01:09,922 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9834
Epoch 212/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 213/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 214/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 215/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 216/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 217/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 218/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 219/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 220/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 221/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 222/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 223/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9819
Epoch 224/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 225/300
 - 11s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 226/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 227/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 228/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 229/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9815
Epoch 230/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 231/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 232/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 233/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 234/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 235/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 236/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 237/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 238/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 239/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 240/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 241/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 01:13:28,970 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9834
Epoch 242/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 243/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 244/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 245/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 246/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 247/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 248/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 249/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 250/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 251/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 252/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 253/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 254/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 255/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 256/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 257/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 258/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 259/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 260/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 261/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 262/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 263/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 264/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 265/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 266/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 267/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 268/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 269/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 270/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 271/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 01:25:49,047 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/ann_model_epoch_270.pickle
 - val_f1: 0.9831
Epoch 272/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9815
Epoch 273/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 274/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 275/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 276/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 277/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 278/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 279/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 280/300
 - 12s - loss: 0.0082 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 281/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 282/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 283/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 284/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9829
Epoch 285/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 286/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 287/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 288/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 289/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 290/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 291/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 292/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 293/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 294/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 295/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 296/300
 - 11s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 297/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 298/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 299/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 300/300
 - 12s - loss: 0.0082 - val_loss: 0.0080
2019-12-24 01:37:56,696 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 01:38:29,988 [INFO] Last epoch loss evaluation: train_loss = 0.007925, val_loss = 0.007955
2019-12-24 01:38:30,033 [INFO] Training complete. time_to_train = 7841.50 sec, 130.69 min
2019-12-24 01:38:30,036 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep2/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-24 01:38:30,182 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep2/training_error_history.png
2019-12-24 01:38:30,305 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep2/training_f1_history.png
2019-12-24 01:38:30,305 [INFO] Making predictions on training, validation, testing data
2019-12-24 01:39:31,726 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 01:39:43,914 [INFO] Dataset: Testing. Classification report below
2019-12-24 01:39:43,914 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.73      0.99      0.84        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.45      0.56      5596
   DoS attacks-Slowloris       0.97      0.96      0.96       440
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.45      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.70      0.69      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-24 01:39:43,914 [INFO] Overall accuracy (micro avg): 0.9832607267679647
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-24 01:39:57,762 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7022                       0.6850                0.0044                   0.3150  0.6750
2  Weighted avg        0.9911         0.9781                       0.9833                0.0495                   0.0167  0.9781
2019-12-24 01:40:09,994 [INFO] Dataset: Validation. Classification report below
2019-12-24 01:40:09,995 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.80      0.97      0.88        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.45      0.56      5596
   DoS attacks-Slowloris       0.95      0.95      0.95       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.42      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.71      0.68      0.68    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-24 01:40:09,995 [INFO] Overall accuracy (micro avg): 0.9832684469245702
2019-12-24 01:40:23,899 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7051                       0.6838                0.0044                   0.3162  0.6774
2  Weighted avg        0.9910         0.9778                       0.9833                0.0494                   0.0167  0.9781
2019-12-24 01:41:03,793 [INFO] Dataset: Training. Classification report below
2019-12-24 01:41:03,793 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.74      0.97      0.84       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.45      0.56     16787
   DoS attacks-Slowloris       0.97      0.97      0.97      1318
          FTP-BruteForce       0.69      0.88      0.77     23153
           Infilteration       0.50      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.71      0.68      0.68   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-24 01:41:03,794 [INFO] Overall accuracy (micro avg): 0.9832891117925371
2019-12-24 01:41:49,073 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9833         0.9833                       0.9833                0.0012                   0.0167  0.9833
1     Macro avg        0.9978         0.7073                       0.6846                0.0044                   0.3154  0.6758
2  Weighted avg        0.9911         0.9787                       0.9833                0.0494                   0.0167  0.9781
2019-12-24 01:41:49,101 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep2/selected_ids18_subset_dbn_shallow_rep2_results.xlsx
2019-12-24 01:41:49,106 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-24 01:41:49,188 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep3
2019-12-24 01:41:49,188 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_shallow_rep3/run_log.log
2019-12-24 01:41:49,188 [INFO] ================= Running experiment no. 3  ================= 

2019-12-24 01:41:49,188 [INFO] Experiment parameters given below
2019-12-24 01:41:49,188 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_shallow_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_shallow_rep3'}
2019-12-24 01:41:49,188 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep3/tf_logs_run_2019_12_24-01_41_49
2019-12-24 01:41:49,188 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-24 01:41:49,188 [INFO] Reading X, y files
2019-12-24 01:41:49,188 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-24 01:41:53,628 [INFO] Reading complete. time_to_read=4.44 seconds
2019-12-24 01:41:53,628 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-24 01:41:55,172 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-24 01:41:55,172 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-24 01:41:56,720 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-24 01:41:56,720 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-24 01:41:56,987 [INFO] Reading complete. time_to_read=0.27 seconds
2019-12-24 01:41:56,988 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-24 01:41:57,074 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 01:41:57,074 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-24 01:41:57,161 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 01:42:01,094 [INFO] Initializing model
2019-12-24 01:42:01,095 [INFO] Training model
2019-12-24 01:42:01,095 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 01:42:24,486 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 3d7dd553214ab8ddc353fe1f76cf392969e184dd
2019-12-24 01:42:24,486 [INFO] Pretraining Deep Belief Network
2019-12-24 01:48:56,683 [INFO] Pretraining Complete
2019-12-24 01:48:56,683 [INFO] Getting pretrained weights
2019-12-24 01:48:56,683 [INFO] Creating and initializing feed forward neural network
2019-12-24 01:48:56,800 [INFO] _________________________________________________________________
2019-12-24 01:48:56,800 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 01:48:56,800 [INFO] =================================================================
2019-12-24 01:48:56,800 [INFO] dense_25 (Dense)             (None, 32)                2496      
2019-12-24 01:48:56,800 [INFO] _________________________________________________________________
2019-12-24 01:48:56,800 [INFO] batch_normalization_13 (Batc (None, 32)                128       
2019-12-24 01:48:56,800 [INFO] _________________________________________________________________
2019-12-24 01:48:56,800 [INFO] dropout_13 (Dropout)         (None, 32)                0         
2019-12-24 01:48:56,800 [INFO] _________________________________________________________________
2019-12-24 01:48:56,801 [INFO] dense_26 (Dense)             (None, 15)                495       
2019-12-24 01:48:56,801 [INFO] =================================================================
2019-12-24 01:48:56,801 [INFO] Total params: 3,119
2019-12-24 01:48:56,801 [INFO] Trainable params: 3,055
2019-12-24 01:48:56,801 [INFO] Non-trainable params: 64
2019-12-24 01:48:56,801 [INFO] _________________________________________________________________
2019-12-24 01:48:57,823 [INFO] Fine-tuning final neural network
 - val_f1: 0.9832
[BernoulliRBM] Iteration 1, pseudo-likelihood = -32.83, time = 5.14s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.13, time = 8.36s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -33.80, time = 8.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.44, time = 8.17s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -39.35, time = 8.19s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -42.27, time = 8.19s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -44.92, time = 8.18s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.31, time = 8.17s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -49.54, time = 8.16s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -51.66, time = 8.12s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -53.73, time = 8.10s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -55.74, time = 8.07s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -57.72, time = 8.06s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -59.67, time = 8.06s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.63, time = 8.01s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -63.56, time = 7.95s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -65.47, time = 7.93s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -67.37, time = 7.89s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -69.26, time = 7.84s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -71.15, time = 7.81s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -73.04, time = 7.78s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -74.93, time = 7.76s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -76.82, time = 7.75s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -78.71, time = 7.73s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -80.60, time = 7.73s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -82.49, time = 7.72s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -84.38, time = 7.72s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -86.28, time = 7.72s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -88.17, time = 7.71s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -90.07, time = 7.71s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -91.97, time = 7.71s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -93.87, time = 7.71s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -95.77, time = 7.71s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -97.68, time = 7.70s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -99.59, time = 7.69s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -101.51, time = 7.69s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -103.42, time = 7.69s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -105.34, time = 7.69s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -107.26, time = 7.69s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -109.19, time = 7.69s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -111.11, time = 7.69s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.04, time = 7.68s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -114.97, time = 7.68s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -116.91, time = 7.68s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -118.84, time = 7.68s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -120.78, time = 7.68s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -122.72, time = 7.68s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -124.67, time = 7.68s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -126.61, time = 7.68s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -128.57, time = 7.68s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 12s - loss: 0.0745 - val_loss: 0.0512
 - val_f1: 0.8677
Epoch 2/300
 - 12s - loss: 0.0475 - val_loss: 0.0403
 - val_f1: 0.9158
Epoch 3/300
 - 12s - loss: 0.0409 - val_loss: 0.0373
 - val_f1: 0.9202
Epoch 4/300
 - 12s - loss: 0.0387 - val_loss: 0.0358
 - val_f1: 0.9240
Epoch 5/300
 - 12s - loss: 0.0375 - val_loss: 0.0351
 - val_f1: 0.9243
Epoch 6/300
 - 12s - loss: 0.0363 - val_loss: 0.0324
 - val_f1: 0.9256
Epoch 7/300
 - 12s - loss: 0.0323 - val_loss: 0.0228
 - val_f1: 0.9346
Epoch 8/300
 - 12s - loss: 0.0222 - val_loss: 0.0262
 - val_f1: 0.9261
Epoch 9/300
 - 12s - loss: 0.0168 - val_loss: 0.0115
 - val_f1: 0.9771
Epoch 10/300
 - 12s - loss: 0.0147 - val_loss: 0.0220
 - val_f1: 0.9607
Epoch 11/300
 - 12s - loss: 0.0136 - val_loss: 0.0101
 - val_f1: 0.9789
Epoch 12/300
 - 12s - loss: 0.0126 - val_loss: 0.0100
 - val_f1: 0.9806
Epoch 13/300
 - 12s - loss: 0.0119 - val_loss: 0.0096
 - val_f1: 0.9803
Epoch 14/300
 - 12s - loss: 0.0114 - val_loss: 0.0093
 - val_f1: 0.9811
Epoch 15/300
 - 12s - loss: 0.0110 - val_loss: 0.0160
 - val_f1: 0.9613
Epoch 16/300
 - 12s - loss: 0.0108 - val_loss: 0.0491
 - val_f1: 0.8821
Epoch 17/300
 - 12s - loss: 0.0106 - val_loss: 0.0089
 - val_f1: 0.9819
Epoch 18/300
 - 12s - loss: 0.0104 - val_loss: 0.0239
 - val_f1: 0.9346
Epoch 19/300
 - 12s - loss: 0.0103 - val_loss: 0.0088
 - val_f1: 0.9821
Epoch 20/300
 - 12s - loss: 0.0101 - val_loss: 0.0087
 - val_f1: 0.9825
Epoch 21/300
 - 12s - loss: 0.0101 - val_loss: 0.0129
 - val_f1: 0.9712
Epoch 22/300
 - 12s - loss: 0.0100 - val_loss: 0.0087
 - val_f1: 0.9827
Epoch 23/300
 - 12s - loss: 0.0099 - val_loss: 0.0086
 - val_f1: 0.9827
Epoch 24/300
 - 12s - loss: 0.0098 - val_loss: 0.0085
 - val_f1: 0.9828
Epoch 25/300
 - 12s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 26/300
 - 12s - loss: 0.0096 - val_loss: 0.1206
 - val_f1: 0.8720
Epoch 27/300
 - 12s - loss: 0.0095 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 28/300
 - 12s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 29/300
 - 12s - loss: 0.0094 - val_loss: 0.0091
 - val_f1: 0.9814
Epoch 30/300
 - 12s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 31/300
 - 12s - loss: 0.0093 - val_loss: 0.0156
2019-12-24 02:01:53,895 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9549
Epoch 32/300
 - 12s - loss: 0.0094 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 33/300
 - 12s - loss: 0.0093 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 34/300
 - 12s - loss: 0.0093 - val_loss: 0.1344
 - val_f1: 0.8727
Epoch 35/300
 - 12s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 36/300
 - 12s - loss: 0.0092 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 37/300
 - 12s - loss: 0.0091 - val_loss: 0.0613
 - val_f1: 0.8692
Epoch 38/300
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 39/300
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 40/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9831
Epoch 41/300
 - 12s - loss: 0.0091 - val_loss: 0.0300
 - val_f1: 0.8970
Epoch 42/300
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 43/300
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 44/300
 - 12s - loss: 0.0090 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 45/300
 - 12s - loss: 0.0089 - val_loss: 0.0164
 - val_f1: 0.9399
Epoch 46/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 47/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9809
Epoch 48/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 49/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 50/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 51/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 52/300
 - 12s - loss: 0.0089 - val_loss: 0.0089
 - val_f1: 0.9820
Epoch 53/300
 - 12s - loss: 0.0089 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 54/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 55/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 56/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 57/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 58/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 59/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 60/300
 - 12s - loss: 0.0088 - val_loss: 0.0970
 - val_f1: 0.8735
Epoch 61/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
2019-12-24 02:14:33,368 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9833
Epoch 62/300
 - 12s - loss: 0.0088 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 63/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 64/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 65/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 66/300
 - 12s - loss: 0.0087 - val_loss: 0.1049
 - val_f1: 0.8609
Epoch 67/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 68/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 69/300
 - 12s - loss: 0.0087 - val_loss: 0.0180
 - val_f1: 0.9499
Epoch 70/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 71/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 72/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 73/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9818
Epoch 74/300
 - 12s - loss: 0.0087 - val_loss: 0.0086
 - val_f1: 0.9827
Epoch 75/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 76/300
 - 12s - loss: 0.0086 - val_loss: 0.1492
 - val_f1: 0.8710
Epoch 77/300
 - 12s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9833
Epoch 78/300
 - 12s - loss: 0.0086 - val_loss: 0.1188
 - val_f1: 0.8731
Epoch 79/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 80/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 81/300
 - 12s - loss: 0.0086 - val_loss: 0.0233
 - val_f1: 0.9399
Epoch 82/300
 - 12s - loss: 0.0087 - val_loss: 0.0115
 - val_f1: 0.9727
Epoch 83/300
 - 12s - loss: 0.0086 - val_loss: 0.0086
 - val_f1: 0.9830
Epoch 84/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 85/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 86/300
 - 12s - loss: 0.0086 - val_loss: 0.0567
 - val_f1: 0.8911
Epoch 87/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 88/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 89/300
 - 12s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9830
Epoch 90/300
 - 12s - loss: 0.0087 - val_loss: 0.0177
 - val_f1: 0.9611
Epoch 91/300
 - 12s - loss: 0.0086 - val_loss: 0.1365
2019-12-24 02:27:16,491 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.8701
Epoch 92/300
 - 12s - loss: 0.0086 - val_loss: 0.1364
 - val_f1: 0.8720
Epoch 93/300
 - 12s - loss: 0.0086 - val_loss: 0.0086
 - val_f1: 0.9825
Epoch 94/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 95/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 96/300
 - 12s - loss: 0.0086 - val_loss: 0.0119
 - val_f1: 0.9724
Epoch 97/300
 - 12s - loss: 0.0086 - val_loss: 0.1058
 - val_f1: 0.8732
Epoch 98/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 99/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 100/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 101/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 102/300
 - 12s - loss: 0.0085 - val_loss: 0.1341
 - val_f1: 0.8726
Epoch 103/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 104/300
 - 11s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 105/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 106/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 107/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 108/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 109/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 110/300
 - 12s - loss: 0.0085 - val_loss: 0.0161
 - val_f1: 0.9724
Epoch 111/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 112/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 113/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 114/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 115/300
 - 12s - loss: 0.0085 - val_loss: 0.0413
 - val_f1: 0.8935
Epoch 116/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 117/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 118/300
 - 12s - loss: 0.0085 - val_loss: 0.0088
 - val_f1: 0.9815
Epoch 119/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 120/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 121/300
 - 12s - loss: 0.0085 - val_loss: 0.0186
2019-12-24 02:39:59,615 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9610
Epoch 122/300
 - 12s - loss: 0.0085 - val_loss: 0.0569
 - val_f1: 0.8912
Epoch 123/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 124/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 125/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 126/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 127/300
 - 12s - loss: 0.0084 - val_loss: 0.0183
 - val_f1: 0.9700
Epoch 128/300
 - 12s - loss: 0.0085 - val_loss: 0.1195
 - val_f1: 0.8722
Epoch 129/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 130/300
 - 12s - loss: 0.0085 - val_loss: 0.1633
 - val_f1: 0.8305
Epoch 131/300
 - 12s - loss: 0.0085 - val_loss: 0.1074
 - val_f1: 0.8722
Epoch 132/300
 - 12s - loss: 0.0084 - val_loss: 0.1208
 - val_f1: 0.8719
Epoch 133/300
 - 12s - loss: 0.0085 - val_loss: 0.0400
 - val_f1: 0.9166
Epoch 134/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 135/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 136/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 137/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 138/300
 - 12s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 139/300
 - 12s - loss: 0.0084 - val_loss: 0.0181
 - val_f1: 0.9703
Epoch 140/300
 - 12s - loss: 0.0084 - val_loss: 0.0087
 - val_f1: 0.9823
Epoch 141/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 142/300
 - 12s - loss: 0.0084 - val_loss: 0.0105
 - val_f1: 0.9734
Epoch 143/300
 - 12s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9726
Epoch 144/300
 - 12s - loss: 0.0084 - val_loss: 0.0219
 - val_f1: 0.9542
Epoch 145/300
 - 12s - loss: 0.0084 - val_loss: 0.1486
 - val_f1: 0.8308
Epoch 146/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 147/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 148/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9813
Epoch 149/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 150/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 151/300
 - 12s - loss: 0.0084 - val_loss: 0.0751
2019-12-24 02:52:46,810 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.8730
Epoch 152/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 153/300
 - 12s - loss: 0.0084 - val_loss: 0.0286
 - val_f1: 0.9333
Epoch 154/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 155/300
 - 12s - loss: 0.0084 - val_loss: 0.0273
 - val_f1: 0.9365
Epoch 156/300
 - 12s - loss: 0.0084 - val_loss: 0.0950
 - val_f1: 0.8727
Epoch 157/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 158/300
 - 12s - loss: 0.0084 - val_loss: 0.0285
 - val_f1: 0.9389
Epoch 159/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 160/300
 - 12s - loss: 0.0084 - val_loss: 0.0138
 - val_f1: 0.9727
Epoch 161/300
 - 12s - loss: 0.0084 - val_loss: 0.0531
 - val_f1: 0.8912
Epoch 162/300
 - 12s - loss: 0.0084 - val_loss: 0.0952
 - val_f1: 0.8382
Epoch 163/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 164/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 165/300
 - 12s - loss: 0.0084 - val_loss: 0.0399
 - val_f1: 0.8912
Epoch 166/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 167/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 168/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 169/300
 - 12s - loss: 0.0084 - val_loss: 0.0138
 - val_f1: 0.9733
Epoch 170/300
 - 12s - loss: 0.0084 - val_loss: 0.0229
 - val_f1: 0.9702
Epoch 171/300
 - 12s - loss: 0.0084 - val_loss: 0.0216
 - val_f1: 0.9706
Epoch 172/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 173/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9818
Epoch 174/300
 - 12s - loss: 0.0084 - val_loss: 0.0225
 - val_f1: 0.9699
Epoch 175/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 176/300
 - 12s - loss: 0.0084 - val_loss: 0.0751
 - val_f1: 0.8734
Epoch 177/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 178/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 179/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 180/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 181/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
2019-12-24 03:05:36,508 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9812
Epoch 182/300
 - 12s - loss: 0.0084 - val_loss: 0.1410
 - val_f1: 0.8374
Epoch 183/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 184/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 185/300
 - 12s - loss: 0.0084 - val_loss: 0.0098
 - val_f1: 0.9731
Epoch 186/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 187/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 188/300
 - 12s - loss: 0.0084 - val_loss: 0.0347
 - val_f1: 0.9249
Epoch 189/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 190/300
 - 12s - loss: 0.0084 - val_loss: 0.0111
 - val_f1: 0.9710
Epoch 191/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 192/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 193/300
 - 12s - loss: 0.0083 - val_loss: 0.0240
 - val_f1: 0.9356
Epoch 194/300
 - 12s - loss: 0.0084 - val_loss: 0.1009
 - val_f1: 0.8695
Epoch 195/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9815
Epoch 196/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 197/300
 - 12s - loss: 0.0084 - val_loss: 0.0837
 - val_f1: 0.8726
Epoch 198/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 199/300
 - 12s - loss: 0.0084 - val_loss: 0.0801
 - val_f1: 0.8727
Epoch 200/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 201/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 202/300
 - 12s - loss: 0.0084 - val_loss: 0.0823
 - val_f1: 0.8706
Epoch 203/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9831
Epoch 204/300
 - 12s - loss: 0.0084 - val_loss: 0.0678
 - val_f1: 0.8728
Epoch 205/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 206/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 207/300
 - 12s - loss: 0.0084 - val_loss: 0.0892
 - val_f1: 0.8700
Epoch 208/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 209/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 210/300
 - 12s - loss: 0.0083 - val_loss: 0.0218
 - val_f1: 0.9705
Epoch 211/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
2019-12-24 03:18:27,706 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9832
Epoch 212/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9816
Epoch 213/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 214/300
 - 12s - loss: 0.0083 - val_loss: 0.0453
 - val_f1: 0.9216
Epoch 215/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 216/300
 - 12s - loss: 0.0083 - val_loss: 0.0236
 - val_f1: 0.9504
Epoch 217/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 218/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 219/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 220/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 221/300
 - 12s - loss: 0.0083 - val_loss: 0.0155
 - val_f1: 0.9680
Epoch 222/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 223/300
 - 12s - loss: 0.0083 - val_loss: 0.0106
 - val_f1: 0.9730
Epoch 224/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 225/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9816
Epoch 226/300
 - 12s - loss: 0.0083 - val_loss: 0.0797
 - val_f1: 0.8729
Epoch 227/300
 - 12s - loss: 0.0083 - val_loss: 0.0787
 - val_f1: 0.8725
Epoch 228/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 229/300
 - 12s - loss: 0.0083 - val_loss: 0.0862
 - val_f1: 0.8722
Epoch 230/300
 - 12s - loss: 0.0083 - val_loss: 0.0166
 - val_f1: 0.9714
Epoch 231/300
 - 12s - loss: 0.0083 - val_loss: 0.0244
 - val_f1: 0.9418
Epoch 232/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 233/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9800
Epoch 234/300
 - 12s - loss: 0.0084 - val_loss: 0.1225
 - val_f1: 0.8374
Epoch 235/300
 - 12s - loss: 0.0083 - val_loss: 0.0085
 - val_f1: 0.9831
Epoch 236/300
 - 12s - loss: 0.0083 - val_loss: 0.0087
 - val_f1: 0.9820
Epoch 237/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 238/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 239/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 240/300
 - 12s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 241/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 03:31:16,760 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9830
Epoch 242/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9837
Epoch 243/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 244/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 245/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 246/300
 - 12s - loss: 0.0083 - val_loss: 0.1151
 - val_f1: 0.8373
Epoch 247/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 248/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 249/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 250/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 251/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 252/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 253/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 254/300
 - 12s - loss: 0.0083 - val_loss: 0.0194
 - val_f1: 0.9703
Epoch 255/300
 - 12s - loss: 0.0083 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 256/300
 - 12s - loss: 0.0083 - val_loss: 0.0151
 - val_f1: 0.9690
Epoch 257/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 258/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 259/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 260/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 261/300
 - 12s - loss: 0.0083 - val_loss: 0.0196
 - val_f1: 0.9700
Epoch 262/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 263/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 264/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 265/300
 - 12s - loss: 0.0083 - val_loss: 0.0121
 - val_f1: 0.9709
Epoch 266/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 267/300
 - 12s - loss: 0.0083 - val_loss: 0.0255
 - val_f1: 0.9455
Epoch 268/300
 - 12s - loss: 0.0083 - val_loss: 0.0761
 - val_f1: 0.8700
Epoch 269/300
 - 12s - loss: 0.0083 - val_loss: 0.0587
 - val_f1: 0.9205
Epoch 270/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 271/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 03:44:06,469 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9832
Epoch 272/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 273/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 274/300
 - 12s - loss: 0.0083 - val_loss: 0.0177
 - val_f1: 0.9686
Epoch 275/300
 - 12s - loss: 0.0083 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 276/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 277/300
 - 12s - loss: 0.0083 - val_loss: 0.0661
 - val_f1: 0.8700
Epoch 278/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9810
Epoch 279/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 280/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9836
Epoch 281/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 282/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9819
Epoch 283/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 284/300
 - 12s - loss: 0.0083 - val_loss: 0.0190
 - val_f1: 0.9689
Epoch 285/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 286/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 287/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 288/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 289/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 290/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 291/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 292/300
 - 12s - loss: 0.0083 - val_loss: 0.0162
 - val_f1: 0.9700
Epoch 293/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 294/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 295/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 296/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 297/300
 - 12s - loss: 0.0083 - val_loss: 0.0177
 - val_f1: 0.9705
Epoch 298/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 299/300
 - 12s - loss: 0.0083 - val_loss: 0.0399
 - val_f1: 0.9235
Epoch 300/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 03:56:41,564 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 03:57:16,627 [INFO] Last epoch loss evaluation: train_loss = 0.007926, val_loss = 0.007995
2019-12-24 03:57:16,674 [INFO] Training complete. time_to_train = 8115.58 sec, 135.26 min
2019-12-24 03:57:16,678 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep3/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-24 03:57:16,831 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep3/training_error_history.png
2019-12-24 03:57:16,983 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep3/training_f1_history.png
2019-12-24 03:57:16,983 [INFO] Making predictions on training, validation, testing data
2019-12-24 03:58:20,894 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 03:58:33,089 [INFO] Dataset: Testing. Classification report below
2019-12-24 03:58:33,089 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.68      1.00      0.81        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.72      0.47      0.57      5596
   DoS attacks-Slowloris       0.89      0.97      0.93       440
          FTP-BruteForce       0.69      0.87      0.77      7718
           Infilteration       0.41      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.69      0.69      0.67    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-24 03:58:33,089 [INFO] Overall accuracy (micro avg): 0.9831677738393277
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-24 03:58:46,942 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6903                       0.6868                0.0044                   0.3132  0.6710
2  Weighted avg        0.9910         0.9776                       0.9832                0.0492                   0.0168  0.9781
2019-12-24 03:58:59,118 [INFO] Dataset: Validation. Classification report below
2019-12-24 03:58:59,118 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.00      0.00      0.00         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.72      1.00      0.84        68
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.73      0.46      0.57      5596
   DoS attacks-Slowloris       0.89      0.97      0.93       439
          FTP-BruteForce       0.69      0.88      0.77      7718
           Infilteration       0.36      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.69      0.69      0.67    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-24 03:58:59,118 [INFO] Overall accuracy (micro avg): 0.9831832399413156
2019-12-24 03:59:12,955 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6912                       0.6868                0.0044                   0.3132  0.6733
2  Weighted avg        0.9910         0.9772                       0.9832                0.0493                   0.0168  0.9781
2019-12-24 03:59:52,820 [INFO] Dataset: Training. Classification report below
2019-12-24 03:59:52,820 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.00      0.00      0.00        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.71      1.00      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      1.00      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.73      0.46      0.56     16787
   DoS attacks-Slowloris       0.92      0.99      0.95      1318
          FTP-BruteForce       0.69      0.87      0.77     23153
           Infilteration       0.44      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.70      0.69      0.67   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-24 03:59:52,820 [INFO] Overall accuracy (micro avg): 0.9832188806183648
2019-12-24 04:00:38,087 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9832         0.9832                       0.9832                0.0012                   0.0168  0.9832
1     Macro avg        0.9978         0.6965                       0.6878                0.0044                   0.3122  0.6740
2  Weighted avg        0.9910         0.9780                       0.9832                0.0491                   0.0168  0.9781
2019-12-24 04:00:38,121 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep3/selected_ids18_subset_dbn_shallow_rep3_results.xlsx
2019-12-24 04:00:38,126 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-24 04:00:38,208 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep4
2019-12-24 04:00:38,209 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_shallow_rep4/run_log.log
2019-12-24 04:00:38,209 [INFO] ================= Running experiment no. 4  ================= 

2019-12-24 04:00:38,209 [INFO] Experiment parameters given below
2019-12-24 04:00:38,209 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_shallow_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_shallow_rep4'}
2019-12-24 04:00:38,209 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep4/tf_logs_run_2019_12_24-04_00_38
2019-12-24 04:00:38,209 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-24 04:00:38,209 [INFO] Reading X, y files
2019-12-24 04:00:38,209 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-24 04:00:42,649 [INFO] Reading complete. time_to_read=4.44 seconds
2019-12-24 04:00:42,649 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-24 04:00:44,185 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-24 04:00:44,185 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-24 04:00:45,721 [INFO] Reading complete. time_to_read=1.54 seconds
2019-12-24 04:00:45,721 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-24 04:00:45,977 [INFO] Reading complete. time_to_read=0.26 seconds
2019-12-24 04:00:45,977 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-24 04:00:46,063 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 04:00:46,063 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-24 04:00:46,148 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 04:00:50,062 [INFO] Initializing model
2019-12-24 04:00:50,063 [INFO] Training model
2019-12-24 04:00:50,063 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 04:01:13,575 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = 17c03e621f4813f4256066726aaf6bf315b9bc73
2019-12-24 04:01:13,576 [INFO] Pretraining Deep Belief Network
2019-12-24 04:07:45,238 [INFO] Pretraining Complete
2019-12-24 04:07:45,238 [INFO] Getting pretrained weights
2019-12-24 04:07:45,238 [INFO] Creating and initializing feed forward neural network
2019-12-24 04:07:45,356 [INFO] _________________________________________________________________
2019-12-24 04:07:45,356 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 04:07:45,356 [INFO] =================================================================
2019-12-24 04:07:45,356 [INFO] dense_27 (Dense)             (None, 32)                2496      
2019-12-24 04:07:45,356 [INFO] _________________________________________________________________
2019-12-24 04:07:45,356 [INFO] batch_normalization_14 (Batc (None, 32)                128       
2019-12-24 04:07:45,356 [INFO] _________________________________________________________________
2019-12-24 04:07:45,357 [INFO] dropout_14 (Dropout)         (None, 32)                0         
2019-12-24 04:07:45,357 [INFO] _________________________________________________________________
2019-12-24 04:07:45,357 [INFO] dense_28 (Dense)             (None, 15)                495       
2019-12-24 04:07:45,357 [INFO] =================================================================
2019-12-24 04:07:45,357 [INFO] Total params: 3,119
2019-12-24 04:07:45,357 [INFO] Trainable params: 3,055
2019-12-24 04:07:45,357 [INFO] Non-trainable params: 64
2019-12-24 04:07:45,357 [INFO] _________________________________________________________________
2019-12-24 04:07:46,440 [INFO] Fine-tuning final neural network
 - val_f1: 0.9832
[BernoulliRBM] Iteration 1, pseudo-likelihood = -32.96, time = 5.13s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.30, time = 8.38s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -33.99, time = 8.14s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.70, time = 8.16s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -39.70, time = 8.18s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -42.71, time = 8.18s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -45.45, time = 8.17s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.93, time = 8.16s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -50.23, time = 8.15s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -52.40, time = 8.11s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.52, time = 8.09s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.57, time = 8.06s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -58.58, time = 8.05s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -60.56, time = 8.04s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -62.53, time = 8.00s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -64.46, time = 7.93s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -66.37, time = 7.92s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -68.26, time = 7.88s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -70.15, time = 7.83s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -72.02, time = 7.80s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -73.90, time = 7.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -75.78, time = 7.75s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -77.66, time = 7.74s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -79.54, time = 7.72s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -81.42, time = 7.72s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -83.30, time = 7.71s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -85.18, time = 7.71s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -87.06, time = 7.71s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -88.94, time = 7.70s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -90.83, time = 7.70s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -92.72, time = 7.70s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -94.61, time = 7.70s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -96.50, time = 7.70s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -98.40, time = 7.69s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -100.30, time = 7.68s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -102.20, time = 7.68s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -104.11, time = 7.68s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -106.02, time = 7.68s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -107.93, time = 7.68s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -109.84, time = 7.67s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -111.76, time = 7.67s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.67, time = 7.67s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -115.59, time = 7.67s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -117.51, time = 7.67s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -119.43, time = 7.67s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -121.35, time = 7.67s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -123.28, time = 7.67s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -125.20, time = 7.67s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -127.14, time = 7.66s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -129.07, time = 7.66s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 12s - loss: 0.0737 - val_loss: 0.0503
 - val_f1: 0.8828
Epoch 2/300
 - 12s - loss: 0.0480 - val_loss: 0.0408
 - val_f1: 0.9138
Epoch 3/300
 - 12s - loss: 0.0415 - val_loss: 0.0380
 - val_f1: 0.9210
Epoch 4/300
 - 12s - loss: 0.0392 - val_loss: 0.0408
 - val_f1: 0.9201
Epoch 5/300
 - 12s - loss: 0.0378 - val_loss: 0.0351
 - val_f1: 0.9240
Epoch 6/300
 - 12s - loss: 0.0369 - val_loss: 0.0336
 - val_f1: 0.9244
Epoch 7/300
 - 12s - loss: 0.0351 - val_loss: 0.0314
 - val_f1: 0.9252
Epoch 8/300
 - 12s - loss: 0.0327 - val_loss: 0.0265
 - val_f1: 0.9346
Epoch 9/300
 - 12s - loss: 0.0262 - val_loss: 0.0172
 - val_f1: 0.9510
Epoch 10/300
 - 12s - loss: 0.0183 - val_loss: 0.0115
 - val_f1: 0.9761
Epoch 11/300
 - 12s - loss: 0.0150 - val_loss: 0.0435
 - val_f1: 0.8831
Epoch 12/300
 - 12s - loss: 0.0138 - val_loss: 0.0383
 - val_f1: 0.8810
Epoch 13/300
 - 12s - loss: 0.0130 - val_loss: 0.0101
 - val_f1: 0.9798
Epoch 14/300
 - 12s - loss: 0.0124 - val_loss: 0.1095
 - val_f1: 0.8429
Epoch 15/300
 - 12s - loss: 0.0119 - val_loss: 0.0094
 - val_f1: 0.9809
Epoch 16/300
 - 12s - loss: 0.0116 - val_loss: 0.0092
 - val_f1: 0.9810
Epoch 17/300
 - 12s - loss: 0.0113 - val_loss: 0.0091
 - val_f1: 0.9814
Epoch 18/300
 - 12s - loss: 0.0110 - val_loss: 0.0963
 - val_f1: 0.8420
Epoch 19/300
 - 12s - loss: 0.0108 - val_loss: 0.0092
 - val_f1: 0.9792
Epoch 20/300
 - 12s - loss: 0.0106 - val_loss: 0.0089
 - val_f1: 0.9817
Epoch 21/300
 - 12s - loss: 0.0103 - val_loss: 0.0091
 - val_f1: 0.9816
Epoch 22/300
 - 12s - loss: 0.0102 - val_loss: 0.0932
 - val_f1: 0.8712
Epoch 23/300
 - 12s - loss: 0.0101 - val_loss: 0.0093
 - val_f1: 0.9810
Epoch 24/300
 - 12s - loss: 0.0101 - val_loss: 0.0089
 - val_f1: 0.9821
Epoch 25/300
 - 12s - loss: 0.0100 - val_loss: 0.0088
 - val_f1: 0.9822
Epoch 26/300
 - 12s - loss: 0.0100 - val_loss: 0.0499
 - val_f1: 0.8784
Epoch 27/300
 - 12s - loss: 0.0099 - val_loss: 0.0323
 - val_f1: 0.8819
Epoch 28/300
 - 12s - loss: 0.0099 - val_loss: 0.0092
 - val_f1: 0.9815
Epoch 29/300
 - 12s - loss: 0.0098 - val_loss: 0.0164
 - val_f1: 0.9557
Epoch 30/300
 - 12s - loss: 0.0097 - val_loss: 0.0647
 - val_f1: 0.8782
Epoch 31/300
 - 12s - loss: 0.0097 - val_loss: 0.0087
2019-12-24 04:20:45,888 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9824
Epoch 32/300
 - 12s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 33/300
 - 12s - loss: 0.0096 - val_loss: 0.0087
 - val_f1: 0.9806
Epoch 34/300
 - 12s - loss: 0.0096 - val_loss: 0.0088
 - val_f1: 0.9823
Epoch 35/300
 - 12s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9827
Epoch 36/300
 - 12s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9827
Epoch 37/300
 - 12s - loss: 0.0095 - val_loss: 0.1308
 - val_f1: 0.8432
Epoch 38/300
 - 12s - loss: 0.0095 - val_loss: 0.0087
 - val_f1: 0.9825
Epoch 39/300
 - 12s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9827
Epoch 40/300
 - 12s - loss: 0.0094 - val_loss: 0.1410
 - val_f1: 0.8415
Epoch 41/300
 - 12s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 42/300
 - 12s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9815
Epoch 43/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9831
Epoch 44/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9825
Epoch 45/300
 - 12s - loss: 0.0094 - val_loss: 0.0086
 - val_f1: 0.9832
Epoch 46/300
 - 12s - loss: 0.0093 - val_loss: 0.1200
 - val_f1: 0.8416
Epoch 47/300
 - 12s - loss: 0.0093 - val_loss: 0.0116
 - val_f1: 0.9784
Epoch 48/300
 - 12s - loss: 0.0093 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 49/300
 - 12s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9830
Epoch 50/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 51/300
 - 12s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9830
Epoch 52/300
 - 12s - loss: 0.0092 - val_loss: 0.0086
 - val_f1: 0.9831
Epoch 53/300
 - 12s - loss: 0.0092 - val_loss: 0.0085
 - val_f1: 0.9830
Epoch 54/300
 - 12s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 55/300
 - 12s - loss: 0.0091 - val_loss: 0.0085
 - val_f1: 0.9829
Epoch 56/300
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9831
Epoch 57/300
 - 12s - loss: 0.0091 - val_loss: 0.0086
 - val_f1: 0.9828
Epoch 58/300
 - 12s - loss: 0.0090 - val_loss: 0.1579
 - val_f1: 0.8387
Epoch 59/300
 - 12s - loss: 0.0090 - val_loss: 0.0089
 - val_f1: 0.9803
Epoch 60/300
 - 12s - loss: 0.0090 - val_loss: 0.0157
 - val_f1: 0.9563
Epoch 61/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
2019-12-24 04:33:32,246 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9830
Epoch 62/300
 - 12s - loss: 0.0090 - val_loss: 0.0090
 - val_f1: 0.9812
Epoch 63/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 64/300
 - 12s - loss: 0.0090 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 65/300
 - 12s - loss: 0.0090 - val_loss: 0.0148
 - val_f1: 0.9657
Epoch 66/300
 - 12s - loss: 0.0090 - val_loss: 0.0086
 - val_f1: 0.9830
Epoch 67/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9826
Epoch 68/300
 - 12s - loss: 0.0089 - val_loss: 0.0397
 - val_f1: 0.8792
Epoch 69/300
 - 12s - loss: 0.0089 - val_loss: 0.0088
 - val_f1: 0.9829
Epoch 70/300
 - 12s - loss: 0.0089 - val_loss: 0.0204
 - val_f1: 0.9323
Epoch 71/300
 - 12s - loss: 0.0089 - val_loss: 0.0086
 - val_f1: 0.9829
Epoch 72/300
 - 12s - loss: 0.0089 - val_loss: 0.0113
 - val_f1: 0.9785
Epoch 73/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9831
Epoch 74/300
 - 12s - loss: 0.0089 - val_loss: 0.0172
 - val_f1: 0.9548
Epoch 75/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 76/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 77/300
 - 12s - loss: 0.0088 - val_loss: 0.0239
 - val_f1: 0.9177
Epoch 78/300
 - 12s - loss: 0.0088 - val_loss: 0.0662
 - val_f1: 0.8721
Epoch 79/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 80/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 81/300
 - 12s - loss: 0.0088 - val_loss: 0.0795
 - val_f1: 0.8450
Epoch 82/300
 - 12s - loss: 0.0088 - val_loss: 0.0109
 - val_f1: 0.9719
Epoch 83/300
 - 12s - loss: 0.0088 - val_loss: 0.0098
 - val_f1: 0.9795
Epoch 84/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9826
Epoch 85/300
 - 12s - loss: 0.0087 - val_loss: 0.0553
 - val_f1: 0.8735
Epoch 86/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 87/300
 - 12s - loss: 0.0088 - val_loss: 0.0101
 - val_f1: 0.9797
Epoch 88/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 89/300
 - 12s - loss: 0.0088 - val_loss: 0.0707
 - val_f1: 0.8695
Epoch 90/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 91/300
 - 12s - loss: 0.0088 - val_loss: 0.0107
2019-12-24 04:46:17,897 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9786
Epoch 92/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 93/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 94/300
 - 12s - loss: 0.0088 - val_loss: 0.1049
 - val_f1: 0.8451
Epoch 95/300
 - 12s - loss: 0.0087 - val_loss: 0.0457
 - val_f1: 0.9006
Epoch 96/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9831
Epoch 97/300
 - 12s - loss: 0.0087 - val_loss: 0.0188
 - val_f1: 0.9504
Epoch 98/300
 - 12s - loss: 0.0087 - val_loss: 0.0498
 - val_f1: 0.8702
Epoch 99/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 100/300
 - 12s - loss: 0.0087 - val_loss: 0.1624
 - val_f1: 0.8353
Epoch 101/300
 - 12s - loss: 0.0087 - val_loss: 0.0212
 - val_f1: 0.9394
Epoch 102/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 103/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 104/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9830
Epoch 105/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 106/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 107/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 108/300
 - 12s - loss: 0.0087 - val_loss: 0.0438
 - val_f1: 0.8747
Epoch 109/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 110/300
 - 12s - loss: 0.0086 - val_loss: 0.0349
 - val_f1: 0.9017
Epoch 111/300
 - 12s - loss: 0.0086 - val_loss: 0.0296
 - val_f1: 0.8938
Epoch 112/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9835
Epoch 113/300
 - 12s - loss: 0.0087 - val_loss: 0.0325
 - val_f1: 0.8994
Epoch 114/300
 - 12s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 115/300
 - 12s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 116/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 117/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 118/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 119/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 120/300
 - 12s - loss: 0.0086 - val_loss: 0.0458
 - val_f1: 0.8909
Epoch 121/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
2019-12-24 04:59:03,742 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9828
Epoch 122/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 123/300
 - 12s - loss: 0.0086 - val_loss: 0.0318
 - val_f1: 0.8990
Epoch 124/300
 - 12s - loss: 0.0087 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 125/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 126/300
 - 12s - loss: 0.0086 - val_loss: 0.0087
 - val_f1: 0.9814
Epoch 127/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 128/300
 - 12s - loss: 0.0086 - val_loss: 0.0334
 - val_f1: 0.8998
Epoch 129/300
 - 12s - loss: 0.0086 - val_loss: 0.0258
 - val_f1: 0.9079
Epoch 130/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 131/300
 - 12s - loss: 0.0086 - val_loss: 0.0140
 - val_f1: 0.9705
Epoch 132/300
 - 12s - loss: 0.0086 - val_loss: 0.0084
 - val_f1: 0.9824
Epoch 133/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 134/300
 - 12s - loss: 0.0086 - val_loss: 0.0239
 - val_f1: 0.9364
Epoch 135/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9833
Epoch 136/300
 - 12s - loss: 0.0086 - val_loss: 0.0135
 - val_f1: 0.9748
Epoch 137/300
 - 12s - loss: 0.0086 - val_loss: 0.0361
 - val_f1: 0.9122
Epoch 138/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 139/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 140/300
 - 12s - loss: 0.0086 - val_loss: 0.0089
 - val_f1: 0.9814
Epoch 141/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 142/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 143/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 144/300
 - 12s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9827
Epoch 145/300
 - 12s - loss: 0.0086 - val_loss: 0.0129
 - val_f1: 0.9720
Epoch 146/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 147/300
 - 12s - loss: 0.0086 - val_loss: 0.1705
 - val_f1: 0.8298
Epoch 148/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 149/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 150/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 151/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
2019-12-24 05:11:49,939 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9810
Epoch 152/300
 - 12s - loss: 0.0086 - val_loss: 0.0123
 - val_f1: 0.9702
Epoch 153/300
 - 12s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9817
Epoch 154/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9810
Epoch 155/300
 - 12s - loss: 0.0086 - val_loss: 0.0096
 - val_f1: 0.9796
Epoch 156/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9834
Epoch 157/300
 - 12s - loss: 0.0085 - val_loss: 0.0371
 - val_f1: 0.8974
Epoch 158/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 159/300
 - 12s - loss: 0.0085 - val_loss: 0.0380
 - val_f1: 0.8894
Epoch 160/300
 - 12s - loss: 0.0085 - val_loss: 0.0359
 - val_f1: 0.9022
Epoch 161/300
 - 12s - loss: 0.0085 - val_loss: 0.1362
 - val_f1: 0.8314
Epoch 162/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 163/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 164/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 165/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 166/300
 - 12s - loss: 0.0085 - val_loss: 0.0152
 - val_f1: 0.9668
Epoch 167/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 168/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 169/300
 - 12s - loss: 0.0085 - val_loss: 0.0159
 - val_f1: 0.9566
Epoch 170/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 171/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 172/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 173/300
 - 12s - loss: 0.0085 - val_loss: 0.0099
 - val_f1: 0.9798
Epoch 174/300
 - 12s - loss: 0.0085 - val_loss: 0.0180
 - val_f1: 0.9429
Epoch 175/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 176/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 177/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9831
Epoch 178/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 179/300
 - 12s - loss: 0.0085 - val_loss: 0.0181
 - val_f1: 0.9529
Epoch 180/300
 - 12s - loss: 0.0085 - val_loss: 0.0499
 - val_f1: 0.9046
Epoch 181/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
2019-12-24 05:24:36,402 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9828
Epoch 182/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 183/300
 - 12s - loss: 0.0085 - val_loss: 0.0096
 - val_f1: 0.9805
Epoch 184/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 185/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 186/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 187/300
 - 12s - loss: 0.0085 - val_loss: 0.0328
 - val_f1: 0.9124
Epoch 188/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 189/300
 - 12s - loss: 0.0085 - val_loss: 0.0135
 - val_f1: 0.9734
Epoch 190/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 191/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 192/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 193/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 194/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 195/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 196/300
 - 12s - loss: 0.0085 - val_loss: 0.0095
 - val_f1: 0.9804
Epoch 197/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 198/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 199/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 200/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9836
Epoch 201/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 202/300
 - 12s - loss: 0.0085 - val_loss: 0.0101
 - val_f1: 0.9793
Epoch 203/300
 - 12s - loss: 0.0085 - val_loss: 0.0180
 - val_f1: 0.9446
Epoch 204/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 205/300
 - 12s - loss: 0.0085 - val_loss: 0.0085
 - val_f1: 0.9826
Epoch 206/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9836
Epoch 207/300
 - 12s - loss: 0.0085 - val_loss: 0.0105
 - val_f1: 0.9789
Epoch 208/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 209/300
 - 12s - loss: 0.0085 - val_loss: 0.0358
 - val_f1: 0.9152
Epoch 210/300
 - 12s - loss: 0.0085 - val_loss: 0.0319
 - val_f1: 0.9175
Epoch 211/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
2019-12-24 05:37:23,414 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9833
Epoch 212/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9810
Epoch 213/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 214/300
 - 12s - loss: 0.0085 - val_loss: 0.0157
 - val_f1: 0.9700
Epoch 215/300
 - 12s - loss: 0.0085 - val_loss: 0.0309
 - val_f1: 0.9281
Epoch 216/300
 - 12s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9819
Epoch 217/300
 - 12s - loss: 0.0085 - val_loss: 0.0320
 - val_f1: 0.9164
Epoch 218/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 219/300
 - 12s - loss: 0.0084 - val_loss: 0.0118
 - val_f1: 0.9703
Epoch 220/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 221/300
 - 12s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9813
Epoch 222/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 223/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 224/300
 - 12s - loss: 0.0085 - val_loss: 0.0917
 - val_f1: 0.8664
Epoch 225/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 226/300
 - 12s - loss: 0.0085 - val_loss: 0.0108
 - val_f1: 0.9785
Epoch 227/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 228/300
 - 12s - loss: 0.0085 - val_loss: 0.0276
 - val_f1: 0.9257
Epoch 229/300
 - 12s - loss: 0.0084 - val_loss: 0.0825
 - val_f1: 0.8664
Epoch 230/300
 - 12s - loss: 0.0085 - val_loss: 0.0235
 - val_f1: 0.9277
Epoch 231/300
 - 12s - loss: 0.0085 - val_loss: 0.0101
 - val_f1: 0.9731
Epoch 232/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 233/300
 - 12s - loss: 0.0085 - val_loss: 0.0222
 - val_f1: 0.9529
Epoch 234/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9832
Epoch 235/300
 - 12s - loss: 0.0084 - val_loss: 0.0236
 - val_f1: 0.9301
Epoch 236/300
 - 12s - loss: 0.0085 - val_loss: 0.0110
 - val_f1: 0.9774
Epoch 237/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 238/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 239/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 240/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 241/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
2019-12-24 05:50:09,479 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9835
Epoch 242/300
 - 12s - loss: 0.0085 - val_loss: 0.0136
 - val_f1: 0.9722
Epoch 243/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 244/300
 - 12s - loss: 0.0084 - val_loss: 0.0127
 - val_f1: 0.9682
Epoch 245/300
 - 12s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9822
Epoch 246/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 247/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9835
Epoch 248/300
 - 12s - loss: 0.0084 - val_loss: 0.0237
 - val_f1: 0.9344
Epoch 249/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 250/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 251/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 252/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 253/300
 - 12s - loss: 0.0085 - val_loss: 0.0143
 - val_f1: 0.9710
Epoch 254/300
 - 12s - loss: 0.0084 - val_loss: 0.0210
 - val_f1: 0.9691
Epoch 255/300
 - 12s - loss: 0.0085 - val_loss: 0.0118
 - val_f1: 0.9769
Epoch 256/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9821
Epoch 257/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 258/300
 - 12s - loss: 0.0084 - val_loss: 0.0111
 - val_f1: 0.9777
Epoch 259/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 260/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 261/300
 - 12s - loss: 0.0084 - val_loss: 0.0168
 - val_f1: 0.9594
Epoch 262/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 263/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 264/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 265/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 266/300
 - 12s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9800
Epoch 267/300
 - 12s - loss: 0.0084 - val_loss: 0.0144
 - val_f1: 0.9651
Epoch 268/300
 - 12s - loss: 0.0084 - val_loss: 0.0099
 - val_f1: 0.9788
Epoch 269/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 270/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 271/300
 - 12s - loss: 0.0084 - val_loss: 0.0114
2019-12-24 06:02:56,845 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9755
Epoch 272/300
 - 12s - loss: 0.0084 - val_loss: 0.0135
 - val_f1: 0.9625
Epoch 273/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 274/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 275/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9834
Epoch 276/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9811
Epoch 277/300
 - 12s - loss: 0.0084 - val_loss: 0.0184
 - val_f1: 0.9678
Epoch 278/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 279/300
 - 12s - loss: 0.0084 - val_loss: 0.0169
 - val_f1: 0.9689
Epoch 280/300
 - 12s - loss: 0.0084 - val_loss: 0.0347
 - val_f1: 0.8883
Epoch 281/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 282/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 283/300
 - 12s - loss: 0.0084 - val_loss: 0.0249
 - val_f1: 0.9532
Epoch 284/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9820
Epoch 285/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 286/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 287/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 288/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 289/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 290/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 291/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 292/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 293/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 294/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9836
Epoch 295/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9835
Epoch 296/300
 - 12s - loss: 0.0084 - val_loss: 0.0086
 - val_f1: 0.9811
Epoch 297/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 298/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 299/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 300/300
 - 12s - loss: 0.0083 - val_loss: 0.0174
2019-12-24 06:15:36,877 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 06:16:13,003 [INFO] Last epoch loss evaluation: train_loss = 0.008078, val_loss = 0.008107
2019-12-24 06:16:13,046 [INFO] Training complete. time_to_train = 8122.98 sec, 135.38 min
2019-12-24 06:16:13,050 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep4/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-24 06:16:13,200 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep4/training_error_history.png
2019-12-24 06:16:13,351 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep4/training_f1_history.png
2019-12-24 06:16:13,351 [INFO] Making predictions on training, validation, testing data
2019-12-24 06:17:21,668 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 06:17:33,863 [INFO] Dataset: Testing. Classification report below
2019-12-24 06:17:33,863 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       0.50      0.22      0.31         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.70      1.00      0.82        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.65      0.56      0.60      5596
   DoS attacks-Slowloris       0.94      0.96      0.95       440
          FTP-BruteForce       0.71      0.78      0.74      7718
           Infilteration       0.43      0.01      0.02      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.73      0.70      0.69    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-24 06:17:33,863 [INFO] Overall accuracy (micro avg): 0.9826549835163473
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
2019-12-24 06:17:47,711 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9827         0.9827                       0.9827                0.0012                   0.0173  0.9827
1     Macro avg        0.9977         0.7264                       0.7001                0.0045                   0.2999  0.6940
2  Weighted avg        0.9908         0.9772                       0.9827                0.0504                   0.0173  0.9778
2019-12-24 06:17:59,879 [INFO] Dataset: Validation. Classification report below
2019-12-24 06:17:59,879 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       0.55      0.67      0.60         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.75      1.00      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      0.99      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.65      0.55      0.60      5596
   DoS attacks-Slowloris       0.93      0.96      0.95       439
          FTP-BruteForce       0.71      0.79      0.74      7718
           Infilteration       0.40      0.01      0.02      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.73      0.73      0.72    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-24 06:17:59,879 [INFO] Overall accuracy (micro avg): 0.982721573013864
2019-12-24 06:18:13,705 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9827         0.9827                       0.9827                0.0012                   0.0173  0.9827
1     Macro avg        0.9977         0.7306                       0.7302                0.0045                   0.2698  0.7157
2  Weighted avg        0.9908         0.9769                       0.9827                0.0503                   0.0173  0.9779
2019-12-24 06:18:53,578 [INFO] Dataset: Training. Classification report below
2019-12-24 06:18:53,578 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       0.62      0.50      0.55        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.73      1.00      0.85       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      0.99      0.99      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.64      0.55      0.59     16787
   DoS attacks-Slowloris       0.95      0.98      0.96      1318
          FTP-BruteForce       0.71      0.78      0.74     23153
           Infilteration       0.47      0.01      0.02     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.74      0.72      0.71   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-24 06:18:53,578 [INFO] Overall accuracy (micro avg): 0.9827086717942309
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-24 06:19:38,852 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9827         0.9827                       0.9827                0.0012                   0.0173  0.9827
1     Macro avg        0.9977         0.7398                       0.7201                0.0045                   0.2799  0.7130
2  Weighted avg        0.9909         0.9776                       0.9827                0.0501                   0.0173  0.9779
2019-12-24 06:19:38,879 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep4/selected_ids18_subset_dbn_shallow_rep4_results.xlsx
2019-12-24 06:19:38,884 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-24 06:19:38,963 [INFO] Created directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep5
2019-12-24 06:19:38,964 [INFO] Initialized logging. log_filename = results_selected_models/selected_ids18_subset_dbn_shallow_rep5/run_log.log
2019-12-24 06:19:38,964 [INFO] ================= Running experiment no. 5  ================= 

2019-12-24 06:19:38,964 [INFO] Experiment parameters given below
2019-12-24 06:19:38,964 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_ids18_subset_dbn_shallow_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'BENIGN', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/small_datasets/ids2018', 'description': 'selected_ids18_subset_dbn_shallow_rep5'}
2019-12-24 06:19:38,964 [INFO] Created tensorboard log directory: results_selected_models/selected_ids18_subset_dbn_shallow_rep5/tf_logs_run_2019_12_24-06_19_38
2019-12-24 06:19:38,964 [INFO] Loading datsets from: ../Datasets/small_datasets/ids2018
2019-12-24 06:19:38,964 [INFO] Reading X, y files
2019-12-24 06:19:38,964 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_train.h5
2019-12-24 06:19:43,578 [INFO] Reading complete. time_to_read=4.61 seconds
2019-12-24 06:19:43,579 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_val.h5
2019-12-24 06:19:45,132 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-24 06:19:45,132 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/X_test.h5
2019-12-24 06:19:46,679 [INFO] Reading complete. time_to_read=1.55 seconds
2019-12-24 06:19:46,679 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_train.h5
2019-12-24 06:19:46,931 [INFO] Reading complete. time_to_read=0.25 seconds
2019-12-24 06:19:46,931 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_val.h5
2019-12-24 06:19:47,016 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 06:19:47,017 [INFO] Reading HDF dataset ../Datasets/small_datasets/ids2018/y_test.h5
2019-12-24 06:19:47,102 [INFO] Reading complete. time_to_read=0.09 seconds
2019-12-24 06:19:51,038 [INFO] Initializing model
2019-12-24 06:19:51,038 [INFO] Training model
2019-12-24 06:19:51,038 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-24 06:20:14,700 [INFO] Split sizes (instances). total = 1936462, unsupervised = 968231, supervised = 968231, unsupervised dataset hash = eaed33d6161084dc4817486d96edc3ef18705ff0
2019-12-24 06:20:14,700 [INFO] Pretraining Deep Belief Network
2019-12-24 06:26:46,021 [INFO] Pretraining Complete
2019-12-24 06:26:46,021 [INFO] Getting pretrained weights
2019-12-24 06:26:46,021 [INFO] Creating and initializing feed forward neural network
2019-12-24 06:26:46,142 [INFO] _________________________________________________________________
2019-12-24 06:26:46,142 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-24 06:26:46,142 [INFO] =================================================================
2019-12-24 06:26:46,142 [INFO] dense_29 (Dense)             (None, 32)                2496      
2019-12-24 06:26:46,142 [INFO] _________________________________________________________________
2019-12-24 06:26:46,142 [INFO] batch_normalization_15 (Batc (None, 32)                128       
2019-12-24 06:26:46,142 [INFO] _________________________________________________________________
2019-12-24 06:26:46,142 [INFO] dropout_15 (Dropout)         (None, 32)                0         
2019-12-24 06:26:46,142 [INFO] _________________________________________________________________
2019-12-24 06:26:46,142 [INFO] dense_30 (Dense)             (None, 15)                495       
2019-12-24 06:26:46,142 [INFO] =================================================================
2019-12-24 06:26:46,142 [INFO] Total params: 3,119
2019-12-24 06:26:46,143 [INFO] Trainable params: 3,055
2019-12-24 06:26:46,143 [INFO] Non-trainable params: 64
2019-12-24 06:26:46,143 [INFO] _________________________________________________________________
2019-12-24 06:26:47,315 [INFO] Fine-tuning final neural network
 - val_f1: 0.9683
[BernoulliRBM] Iteration 1, pseudo-likelihood = -32.86, time = 5.13s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -32.18, time = 8.35s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -33.88, time = 8.13s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -36.57, time = 8.15s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -39.52, time = 8.17s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -42.47, time = 8.17s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -45.15, time = 8.17s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -47.57, time = 8.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -49.81, time = 8.14s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -51.93, time = 8.10s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -54.00, time = 8.08s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -56.01, time = 8.05s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -57.99, time = 8.05s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -59.93, time = 8.03s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -61.88, time = 7.99s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -63.79, time = 7.92s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -65.69, time = 7.91s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -67.58, time = 7.87s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -69.46, time = 7.83s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -71.34, time = 7.79s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -73.22, time = 7.77s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -75.11, time = 7.74s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -76.99, time = 7.73s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -78.87, time = 7.71s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -80.75, time = 7.71s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -82.63, time = 7.70s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -84.52, time = 7.71s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -86.40, time = 7.70s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -88.29, time = 7.70s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -90.18, time = 7.69s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -92.07, time = 7.69s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -93.97, time = 7.69s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -95.86, time = 7.69s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -97.76, time = 7.68s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -99.66, time = 7.68s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -101.57, time = 7.68s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -103.47, time = 7.68s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -105.38, time = 7.67s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -107.29, time = 7.67s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -109.21, time = 7.66s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -111.12, time = 7.67s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -113.04, time = 7.67s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -114.95, time = 7.66s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -116.87, time = 7.66s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -118.78, time = 7.66s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -120.71, time = 7.66s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -122.63, time = 7.67s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -124.55, time = 7.66s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -126.48, time = 7.66s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -128.41, time = 7.66s
Train on 968231 samples, validate on 645487 samples
Epoch 1/300
 - 12s - loss: 0.0737 - val_loss: 0.0506
 - val_f1: 0.8706
Epoch 2/300
 - 11s - loss: 0.0481 - val_loss: 0.0410
 - val_f1: 0.9138
Epoch 3/300
 - 12s - loss: 0.0419 - val_loss: 0.0384
 - val_f1: 0.9190
Epoch 4/300
 - 12s - loss: 0.0397 - val_loss: 0.0365
 - val_f1: 0.9201
Epoch 5/300
 - 12s - loss: 0.0384 - val_loss: 0.0354
 - val_f1: 0.9239
Epoch 6/300
 - 12s - loss: 0.0359 - val_loss: 0.0314
 - val_f1: 0.9232
Epoch 7/300
 - 12s - loss: 0.0315 - val_loss: 0.0248
 - val_f1: 0.9336
Epoch 8/300
 - 12s - loss: 0.0262 - val_loss: 0.0277
 - val_f1: 0.9260
Epoch 9/300
 - 12s - loss: 0.0216 - val_loss: 0.0195
 - val_f1: 0.9297
Epoch 10/300
 - 12s - loss: 0.0173 - val_loss: 0.0119
 - val_f1: 0.9785
Epoch 11/300
 - 12s - loss: 0.0151 - val_loss: 0.0106
 - val_f1: 0.9788
Epoch 12/300
 - 12s - loss: 0.0139 - val_loss: 0.0123
 - val_f1: 0.9740
Epoch 13/300
 - 12s - loss: 0.0128 - val_loss: 0.0099
 - val_f1: 0.9807
Epoch 14/300
 - 12s - loss: 0.0119 - val_loss: 0.0094
 - val_f1: 0.9790
Epoch 15/300
 - 12s - loss: 0.0113 - val_loss: 0.0105
 - val_f1: 0.9796
Epoch 16/300
 - 12s - loss: 0.0110 - val_loss: 0.0091
 - val_f1: 0.9815
Epoch 17/300
 - 12s - loss: 0.0107 - val_loss: 0.0092
 - val_f1: 0.9812
Epoch 18/300
 - 12s - loss: 0.0105 - val_loss: 0.0090
 - val_f1: 0.9813
Epoch 19/300
 - 12s - loss: 0.0104 - val_loss: 0.0090
 - val_f1: 0.9812
Epoch 20/300
 - 12s - loss: 0.0102 - val_loss: 0.0111
 - val_f1: 0.9782
Epoch 21/300
 - 12s - loss: 0.0100 - val_loss: 0.0152
 - val_f1: 0.9744
Epoch 22/300
 - 12s - loss: 0.0099 - val_loss: 0.0088
 - val_f1: 0.9819
Epoch 23/300
 - 12s - loss: 0.0098 - val_loss: 0.0088
 - val_f1: 0.9820
Epoch 24/300
 - 12s - loss: 0.0097 - val_loss: 0.0088
 - val_f1: 0.9819
Epoch 25/300
 - 12s - loss: 0.0097 - val_loss: 0.0086
 - val_f1: 0.9823
Epoch 26/300
 - 12s - loss: 0.0096 - val_loss: 0.0100
 - val_f1: 0.9803
Epoch 27/300
 - 12s - loss: 0.0096 - val_loss: 0.0086
 - val_f1: 0.9826
Epoch 28/300
 - 12s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9822
Epoch 29/300
 - 12s - loss: 0.0095 - val_loss: 0.0086
 - val_f1: 0.9820
Epoch 30/300
 - 12s - loss: 0.0094 - val_loss: 0.0097
 - val_f1: 0.9798
Epoch 31/300
 - 12s - loss: 0.0094 - val_loss: 0.0085
2019-12-24 06:40:02,633 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9828
Epoch 32/300
 - 12s - loss: 0.0093 - val_loss: 0.0086
 - val_f1: 0.9824
Epoch 33/300
 - 12s - loss: 0.0093 - val_loss: 0.0120
 - val_f1: 0.9787
Epoch 34/300
 - 12s - loss: 0.0093 - val_loss: 0.0108
 - val_f1: 0.9792
Epoch 35/300
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 36/300
 - 12s - loss: 0.0092 - val_loss: 0.0131
 - val_f1: 0.9742
Epoch 37/300
 - 12s - loss: 0.0092 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 38/300
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 39/300
 - 12s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9823
Epoch 40/300
 - 12s - loss: 0.0091 - val_loss: 0.0083
 - val_f1: 0.9824
Epoch 41/300
 - 12s - loss: 0.0091 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 42/300
 - 12s - loss: 0.0090 - val_loss: 0.0084
 - val_f1: 0.9828
Epoch 43/300
 - 12s - loss: 0.0091 - val_loss: 0.0108
 - val_f1: 0.9790
Epoch 44/300
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 45/300
 - 12s - loss: 0.0090 - val_loss: 0.0083
 - val_f1: 0.9828
Epoch 46/300
 - 12s - loss: 0.0090 - val_loss: 0.0091
 - val_f1: 0.9808
Epoch 47/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9809
Epoch 48/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 49/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9830
Epoch 50/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 51/300
 - 12s - loss: 0.0089 - val_loss: 0.0084
 - val_f1: 0.9829
Epoch 52/300
 - 12s - loss: 0.0089 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 53/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9829
Epoch 54/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 55/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 56/300
 - 12s - loss: 0.0088 - val_loss: 0.0084
 - val_f1: 0.9825
Epoch 57/300
 - 12s - loss: 0.0088 - val_loss: 0.0087
 - val_f1: 0.9815
Epoch 58/300
 - 12s - loss: 0.0088 - val_loss: 0.0102
 - val_f1: 0.9795
Epoch 59/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 60/300
 - 12s - loss: 0.0088 - val_loss: 0.0094
 - val_f1: 0.9808
Epoch 61/300
 - 12s - loss: 0.0088 - val_loss: 0.0083
2019-12-24 06:53:06,527 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9825
Epoch 62/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 63/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 64/300
 - 12s - loss: 0.0088 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 65/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 66/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9826
Epoch 67/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 68/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9825
Epoch 69/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 70/300
 - 12s - loss: 0.0087 - val_loss: 0.0113
 - val_f1: 0.9781
Epoch 71/300
 - 12s - loss: 0.0087 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 72/300
 - 12s - loss: 0.0087 - val_loss: 0.0092
 - val_f1: 0.9798
Epoch 73/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 74/300
 - 12s - loss: 0.0087 - val_loss: 0.0095
 - val_f1: 0.9797
Epoch 75/300
 - 12s - loss: 0.0087 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 76/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 77/300
 - 12s - loss: 0.0087 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 78/300
 - 12s - loss: 0.0086 - val_loss: 0.0104
 - val_f1: 0.9790
Epoch 79/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 80/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 81/300
 - 12s - loss: 0.0086 - val_loss: 0.0095
 - val_f1: 0.9793
Epoch 82/300
 - 12s - loss: 0.0086 - val_loss: 0.0095
 - val_f1: 0.9794
Epoch 83/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 84/300
 - 12s - loss: 0.0086 - val_loss: 0.0082
 - val_f1: 0.9829
Epoch 85/300
 - 12s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9799
Epoch 86/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 87/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 88/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 89/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 90/300
 - 12s - loss: 0.0086 - val_loss: 0.0091
 - val_f1: 0.9803
Epoch 91/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
2019-12-24 07:06:11,173 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9831
Epoch 92/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 93/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 94/300
 - 12s - loss: 0.0086 - val_loss: 0.0085
 - val_f1: 0.9821
Epoch 95/300
 - 12s - loss: 0.0086 - val_loss: 0.0083
 - val_f1: 0.9827
Epoch 96/300
 - 12s - loss: 0.0086 - val_loss: 0.0102
 - val_f1: 0.9794
Epoch 97/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 98/300
 - 12s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9802
Epoch 99/300
 - 12s - loss: 0.0085 - val_loss: 0.0084
 - val_f1: 0.9818
Epoch 100/300
 - 12s - loss: 0.0085 - val_loss: 0.0094
 - val_f1: 0.9797
Epoch 101/300
 - 12s - loss: 0.0086 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 102/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 103/300
 - 12s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9811
Epoch 104/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 105/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 106/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9799
Epoch 107/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 108/300
 - 12s - loss: 0.0085 - val_loss: 0.0088
 - val_f1: 0.9810
Epoch 109/300
 - 12s - loss: 0.0085 - val_loss: 0.0096
 - val_f1: 0.9803
Epoch 110/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 111/300
 - 12s - loss: 0.0085 - val_loss: 0.0116
 - val_f1: 0.9703
Epoch 112/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 113/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 114/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 115/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 116/300
 - 12s - loss: 0.0085 - val_loss: 0.0093
 - val_f1: 0.9804
Epoch 117/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9803
Epoch 118/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 119/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 120/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 121/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
2019-12-24 07:19:14,505 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9831
Epoch 122/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 123/300
 - 12s - loss: 0.0085 - val_loss: 0.0087
 - val_f1: 0.9810
Epoch 124/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 125/300
 - 12s - loss: 0.0085 - val_loss: 0.0086
 - val_f1: 0.9823
Epoch 126/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9825
Epoch 127/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 128/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 129/300
 - 12s - loss: 0.0085 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 130/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 131/300
 - 12s - loss: 0.0085 - val_loss: 0.0082
 - val_f1: 0.9830
Epoch 132/300
 - 12s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9801
Epoch 133/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 134/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 135/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 136/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9800
Epoch 137/300
 - 12s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9814
Epoch 138/300
 - 12s - loss: 0.0085 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 139/300
 - 12s - loss: 0.0085 - val_loss: 0.0090
 - val_f1: 0.9803
Epoch 140/300
 - 12s - loss: 0.0084 - val_loss: 0.0098
 - val_f1: 0.9802
Epoch 141/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9821
Epoch 142/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9824
Epoch 143/300
 - 12s - loss: 0.0085 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 144/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 145/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 146/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 147/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 148/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 149/300
 - 12s - loss: 0.0084 - val_loss: 0.0102
 - val_f1: 0.9794
Epoch 150/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 151/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
2019-12-24 07:32:18,936 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9831
Epoch 152/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9827
Epoch 153/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9831
Epoch 154/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9804
Epoch 155/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 156/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 157/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9805
Epoch 158/300
 - 11s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 159/300
 - 12s - loss: 0.0084 - val_loss: 0.0107
 - val_f1: 0.9713
Epoch 160/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9809
Epoch 161/300
 - 12s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9803
Epoch 162/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 163/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 164/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 165/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 166/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 167/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9834
Epoch 168/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 169/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9814
Epoch 170/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 171/300
 - 12s - loss: 0.0084 - val_loss: 0.0088
 - val_f1: 0.9816
Epoch 172/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 173/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 174/300
 - 12s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9810
Epoch 175/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9821
Epoch 176/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9830
Epoch 177/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9804
Epoch 178/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 179/300
 - 12s - loss: 0.0084 - val_loss: 0.0083
 - val_f1: 0.9826
Epoch 180/300
 - 12s - loss: 0.0084 - val_loss: 0.0095
 - val_f1: 0.9805
Epoch 181/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
2019-12-24 07:45:23,353 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9835
Epoch 182/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 183/300
 - 12s - loss: 0.0084 - val_loss: 0.0091
 - val_f1: 0.9805
Epoch 184/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 185/300
 - 12s - loss: 0.0084 - val_loss: 0.0093
 - val_f1: 0.9804
Epoch 186/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 187/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 188/300
 - 12s - loss: 0.0084 - val_loss: 0.0097
 - val_f1: 0.9804
Epoch 189/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 190/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 191/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 192/300
 - 12s - loss: 0.0084 - val_loss: 0.0112
 - val_f1: 0.9702
Epoch 193/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9803
Epoch 194/300
 - 12s - loss: 0.0084 - val_loss: 0.0084
 - val_f1: 0.9823
Epoch 195/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 196/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 197/300
 - 12s - loss: 0.0084 - val_loss: 0.0081
 - val_f1: 0.9829
Epoch 198/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 199/300
 - 12s - loss: 0.0084 - val_loss: 0.0096
 - val_f1: 0.9801
Epoch 200/300
 - 12s - loss: 0.0084 - val_loss: 0.0090
 - val_f1: 0.9808
Epoch 201/300
 - 12s - loss: 0.0084 - val_loss: 0.0085
 - val_f1: 0.9818
Epoch 202/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 203/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 204/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 205/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 206/300
 - 12s - loss: 0.0084 - val_loss: 0.0092
 - val_f1: 0.9804
Epoch 207/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 208/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9827
Epoch 209/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 210/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 211/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
2019-12-24 07:58:38,614 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9814
Epoch 212/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 213/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 214/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 215/300
 - 12s - loss: 0.0083 - val_loss: 0.0107
 - val_f1: 0.9711
Epoch 216/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 217/300
 - 12s - loss: 0.0084 - val_loss: 0.0089
 - val_f1: 0.9809
Epoch 218/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9805
Epoch 219/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 220/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9828
Epoch 221/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 222/300
 - 12s - loss: 0.0083 - val_loss: 0.0093
 - val_f1: 0.9805
Epoch 223/300
 - 12s - loss: 0.0084 - val_loss: 0.0082
 - val_f1: 0.9831
Epoch 224/300
 - 12s - loss: 0.0085 - val_loss: 0.0091
 - val_f1: 0.9803
Epoch 225/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9810
Epoch 226/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 227/300
 - 12s - loss: 0.0084 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 228/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 229/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 230/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9832
Epoch 231/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 232/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 233/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 234/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 235/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 236/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9832
Epoch 237/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 238/300
 - 12s - loss: 0.0083 - val_loss: 0.0088
 - val_f1: 0.9820
Epoch 239/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9828
Epoch 240/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 241/300
 - 12s - loss: 0.0083 - val_loss: 0.0097
2019-12-24 08:11:53,002 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9721
Epoch 242/300
 - 12s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9808
Epoch 243/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 244/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 245/300
 - 12s - loss: 0.0083 - val_loss: 0.0084
 - val_f1: 0.9820
Epoch 246/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 247/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 248/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 249/300
 - 12s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9749
Epoch 250/300
 - 12s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9807
Epoch 251/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 252/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 253/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 254/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9828
Epoch 255/300
 - 12s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9806
Epoch 256/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9835
Epoch 257/300
 - 12s - loss: 0.0083 - val_loss: 0.0113
 - val_f1: 0.9714
Epoch 258/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 259/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 260/300
 - 12s - loss: 0.0083 - val_loss: 0.0094
 - val_f1: 0.9806
Epoch 261/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 262/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9837
Epoch 263/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9833
Epoch 264/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 265/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 266/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9830
Epoch 267/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 268/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9837
Epoch 269/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 270/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9831
Epoch 271/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
2019-12-24 08:25:07,702 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9831
Epoch 272/300
 - 12s - loss: 0.0083 - val_loss: 0.0096
 - val_f1: 0.9773
Epoch 273/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 274/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 275/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 276/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 277/300
 - 12s - loss: 0.0083 - val_loss: 0.0093
 - val_f1: 0.9807
Epoch 278/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9836
Epoch 279/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 280/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9833
Epoch 281/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9807
Epoch 282/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 283/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9835
Epoch 284/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 285/300
 - 12s - loss: 0.0083 - val_loss: 0.0091
 - val_f1: 0.9811
Epoch 286/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9808
Epoch 287/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 288/300
 - 12s - loss: 0.0083 - val_loss: 0.0104
 - val_f1: 0.9725
Epoch 289/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9836
Epoch 290/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 291/300
 - 12s - loss: 0.0083 - val_loss: 0.0082
 - val_f1: 0.9833
Epoch 292/300
 - 12s - loss: 0.0083 - val_loss: 0.0099
 - val_f1: 0.9756
Epoch 293/300
 - 12s - loss: 0.0083 - val_loss: 0.0126
 - val_f1: 0.9702
Epoch 294/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9832
Epoch 295/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9834
Epoch 296/300
 - 12s - loss: 0.0083 - val_loss: 0.0092
 - val_f1: 0.9810
Epoch 297/300
 - 12s - loss: 0.0083 - val_loss: 0.0080
 - val_f1: 0.9831
Epoch 298/300
 - 12s - loss: 0.0083 - val_loss: 0.0081
 - val_f1: 0.9827
Epoch 299/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
 - val_f1: 0.9832
Epoch 300/300
 - 12s - loss: 0.0083 - val_loss: 0.0079
2019-12-24 08:38:10,918 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-24 08:38:46,792 [INFO] Last epoch loss evaluation: train_loss = 0.007894, val_loss = 0.007937
2019-12-24 08:38:46,838 [INFO] Training complete. time_to_train = 8335.80 sec, 138.93 min
2019-12-24 08:38:46,842 [INFO] Model saved to results_selected_models/selected_ids18_subset_dbn_shallow_rep5/best_model.pickle
/home/hasitha/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  max_open_warning, RuntimeWarning)
2019-12-24 08:38:46,977 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep5/training_error_history.png
2019-12-24 08:38:47,101 [INFO] Plot saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep5/training_f1_history.png
2019-12-24 08:38:47,102 [INFO] Making predictions on training, validation, testing data
2019-12-24 08:39:56,183 [INFO] Evaluating predictions (results)
/home/hasitha/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-24 08:40:08,392 [INFO] Dataset: Testing. Classification report below
2019-12-24 08:40:08,392 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        24
        Brute Force -XSS       1.00      0.33      0.50         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.71      1.00      0.83        67
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23010
   DoS attacks-GoldenEye       0.99      1.00      0.99      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.53      0.61      5596
   DoS attacks-Slowloris       0.95      0.95      0.95       440
          FTP-BruteForce       0.72      0.86      0.78      7718
           Infilteration       0.41      0.01      0.01      6404
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645488
               macro avg       0.77      0.71      0.71    645488
            weighted avg       0.98      0.98      0.98    645488

2019-12-24 08:40:08,392 [INFO] Overall accuracy (micro avg): 0.9836325384825124
/home/hasitha/sunanda/ids_experiments/utility.py:307: RuntimeWarning: invalid value encountered in true_divide
  PPV = TP / (TP + FP)    # Precision or positive predictive value
/home/hasitha/sunanda/ids_experiments/utility.py:311: RuntimeWarning: invalid value encountered in true_divide
  FDR = FP / (TP + FP)    # False discovery rate
/home/hasitha/sunanda/ids_experiments/utility.py:313: RuntimeWarning: invalid value encountered in true_divide
  F1 = (2 * PPV * TPR) / (PPV + TPR)  # F1 score
2019-12-24 08:40:22,262 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9836         0.9836                       0.9836                0.0012                   0.0164  0.9836
1     Macro avg        0.9978         0.7663                       0.7114                0.0044                   0.2886  0.7112
2  Weighted avg        0.9910         0.9780                       0.9836                0.0498                   0.0164  0.9786
2019-12-24 08:40:34,465 [INFO] Dataset: Validation. Classification report below
2019-12-24 08:40:34,465 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99    535650
                     Bot       1.00      1.00      1.00     11465
        Brute Force -Web       0.00      0.00      0.00        25
        Brute Force -XSS       1.00      0.67      0.80         9
        DDOS attack-HOIC       1.00      1.00      1.00     27447
    DDOS attack-LOIC-UDP       0.76      0.99      0.86        68
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     23009
   DoS attacks-GoldenEye       0.99      1.00      1.00      1651
        DoS attacks-Hulk       1.00      1.00      1.00     18478
DoS attacks-SlowHTTPTest       0.74      0.52      0.61      5596
   DoS attacks-Slowloris       0.94      0.96      0.95       439
          FTP-BruteForce       0.71      0.87      0.79      7718
           Infilteration       0.44      0.01      0.01      6403
           SQL Injection       0.00      0.00      0.00         4
          SSH-Bruteforce       1.00      1.00      1.00      7525

               micro avg       0.98      0.98      0.98    645487
               macro avg       0.77      0.73      0.73    645487
            weighted avg       0.98      0.98      0.98    645487

2019-12-24 08:40:34,465 [INFO] Overall accuracy (micro avg): 0.9836867357514559
2019-12-24 08:40:48,331 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7714                       0.7330                0.0044                   0.2670  0.7333
2  Weighted avg        0.9910         0.9784                       0.9837                0.0495                   0.0163  0.9787
2019-12-24 08:41:28,352 [INFO] Dataset: Training. Classification report below
2019-12-24 08:41:28,352 [INFO] 
                          precision    recall  f1-score   support

                  Benign       0.99      1.00      0.99   1606949
                     Bot       1.00      1.00      1.00     34396
        Brute Force -Web       0.00      0.00      0.00        73
        Brute Force -XSS       1.00      0.50      0.67        26
        DDOS attack-HOIC       1.00      1.00      1.00     82341
    DDOS attack-LOIC-UDP       0.72      0.98      0.83       203
  DDoS attacks-LOIC-HTTP       0.99      0.99      0.99     69029
   DoS attacks-GoldenEye       0.99      1.00      1.00      4954
        DoS attacks-Hulk       1.00      1.00      1.00     55435
DoS attacks-SlowHTTPTest       0.74      0.52      0.61     16787
   DoS attacks-Slowloris       0.96      0.98      0.97      1318
          FTP-BruteForce       0.71      0.87      0.78     23153
           Infilteration       0.45      0.01      0.01     19210
           SQL Injection       0.00      0.00      0.00        12
          SSH-Bruteforce       1.00      1.00      1.00     22576

               micro avg       0.98      0.98      0.98   1936462
               macro avg       0.77      0.72      0.72   1936462
            weighted avg       0.98      0.98      0.98   1936462

2019-12-24 08:41:28,352 [INFO] Overall accuracy (micro avg): 0.9836573090512492
2019-12-24 08:42:13,789 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9837         0.9837                       0.9837                0.0012                   0.0163  0.9837
1     Macro avg        0.9978         0.7700                       0.7229                0.0044                   0.2771  0.7236
2  Weighted avg        0.9910         0.9784                       0.9837                0.0495                   0.0163  0.9786
2019-12-24 08:42:13,816 [INFO] Results saved to: results_selected_models/selected_ids18_subset_dbn_shallow_rep5/selected_ids18_subset_dbn_shallow_rep5_results.xlsx
2019-12-24 08:42:13,821 [INFO] ================= Finished running experiment no. 5 ================= 

2019-12-24 08:42:13,903 [INFO] ================= Finished running 15 experiments ================= 

 - val_f1: 0.9837
Using TensorFlow backend.
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
2019-12-29 10:39:32,816 [INFO] Read 10 experiments from file: experiment_specs/selected_model_tests/selected_dbn.csv
2019-12-29 10:39:32,816 [INFO] ================= Started running experiments ================= 

2019-12-29 10:39:32,816 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_shallow_rep1
2019-12-29 10:39:32,816 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_shallow_rep1/run_log.log
2019-12-29 10:39:32,816 [INFO] ================= Running experiment no. 1  ================= 

2019-12-29 10:39:32,816 [INFO] Experiment parameters given below
2019-12-29 10:39:32,816 [INFO] 
{'experiment_num': 1, 'results_dir': 'results_selected_models/selected_kdd99_dbn_shallow_rep1', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_shallow_rep1'}
2019-12-29 10:39:32,816 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_shallow_rep1/tf_logs_run_2019_12_29-10_39_32
2019-12-29 10:39:32,817 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-29 10:39:32,817 [INFO] Reading X, y files
2019-12-29 10:39:32,817 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-29 10:39:32,826 [INFO] NumExpr defaulting to 8 threads.
2019-12-29 10:39:39,224 [INFO] Reading complete. time_to_read=6.41 seconds
2019-12-29 10:39:39,224 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-29 10:39:40,845 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-29 10:39:40,845 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-29 10:39:41,300 [INFO] Reading complete. time_to_read=0.45 seconds
2019-12-29 10:39:41,300 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-29 10:39:41,518 [INFO] Reading complete. time_to_read=0.22 seconds
2019-12-29 10:39:41,518 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-29 10:39:41,573 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-29 10:39:41,573 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-29 10:39:41,593 [INFO] Reading complete. time_to_read=0.02 seconds
OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.
OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info
OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7
OMP: Info #156: KMP_AFFINITY: 8 available OS procs
OMP: Info #157: KMP_AFFINITY: Uniform topology
OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)
OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:
OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 
OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 
OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1161 thread 0 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1199 thread 1 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1203 thread 2 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1207 thread 3 bound to OS proc set 3
2019-12-29 10:39:48,799 [INFO] Initializing model
2019-12-29 10:39:48,800 [INFO] Training model
2019-12-29 10:39:48,800 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-29 10:40:28,728 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 2c14c8e528610ff3198f9b8c7bf5c4728fcad5cd
2019-12-29 10:40:28,728 [INFO] Pretraining Deep Belief Network
2019-12-29 10:59:59,112 [INFO] Pretraining Complete
2019-12-29 10:59:59,112 [INFO] Getting pretrained weights
2019-12-29 10:59:59,112 [INFO] Creating and initializing feed forward neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2019-12-29 10:59:59,126 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-29 10:59:59,199 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2019-12-29 10:59:59,243 [INFO] _________________________________________________________________
2019-12-29 10:59:59,243 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-29 10:59:59,243 [INFO] =================================================================
2019-12-29 10:59:59,243 [INFO] dense_1 (Dense)              (None, 32)                3968      
2019-12-29 10:59:59,243 [INFO] _________________________________________________________________
2019-12-29 10:59:59,243 [INFO] batch_normalization_1 (Batch (None, 32)                128       
2019-12-29 10:59:59,243 [INFO] _________________________________________________________________
2019-12-29 10:59:59,244 [INFO] dropout_1 (Dropout)          (None, 32)                0         
2019-12-29 10:59:59,244 [INFO] _________________________________________________________________
2019-12-29 10:59:59,244 [INFO] dense_2 (Dense)              (None, 5)                 165       
2019-12-29 10:59:59,244 [INFO] =================================================================
2019-12-29 10:59:59,244 [INFO] Total params: 4,261
2019-12-29 10:59:59,244 [INFO] Trainable params: 4,197
2019-12-29 10:59:59,244 [INFO] Non-trainable params: 64
2019-12-29 10:59:59,244 [INFO] _________________________________________________________________
2019-12-29 10:59:59.244847: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2019-12-29 10:59:59.263599: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3701985000 Hz
2019-12-29 10:59:59.263749: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56034de2d320 executing computations on platform Host. Devices:
2019-12-29 10:59:59.263774: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-12-29 10:59:59.263866: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2019-12-29 10:59:59,348 [INFO] Fine-tuning final neural network
WARNING:tensorflow:From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2019-12-29 10:59:59,754 [WARNING] From /home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1309 thread 4 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1364 thread 5 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1365 thread 6 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1366 thread 7 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1367 thread 8 bound to OS proc set 0
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1313 thread 9 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1370 thread 12 bound to OS proc set 4
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1368 thread 10 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1369 thread 11 bound to OS proc set 3
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1371 thread 13 bound to OS proc set 5
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1372 thread 14 bound to OS proc set 6
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1373 thread 15 bound to OS proc set 7
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1374 thread 16 bound to OS proc set 0
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.58, time = 16.69s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -34.14, time = 24.24s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.30, time = 24.13s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.71, time = 24.07s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.99, time = 24.08s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.65, time = 24.03s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -40.95, time = 23.99s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.11, time = 23.85s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.25, time = 23.82s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -47.40, time = 23.82s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -49.54, time = 23.79s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -51.62, time = 23.76s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.67, time = 24.74s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -55.69, time = 23.69s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -57.54, time = 23.68s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -59.57, time = 23.41s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -61.59, time = 23.31s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -63.72, time = 23.31s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -65.95, time = 23.29s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -68.15, time = 23.28s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -70.31, time = 23.27s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -72.61, time = 23.27s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -74.83, time = 23.26s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -77.24, time = 23.25s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -79.45, time = 23.24s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -81.81, time = 23.22s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -84.15, time = 23.20s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -86.44, time = 23.20s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -88.76, time = 23.18s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -91.10, time = 23.13s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -93.41, time = 23.17s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -95.78, time = 23.15s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -98.09, time = 23.16s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -100.46, time = 23.14s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -102.72, time = 23.15s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -105.06, time = 23.14s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -107.47, time = 23.14s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -109.82, time = 23.13s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -112.12, time = 23.13s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -114.45, time = 23.13s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -116.72, time = 23.13s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -119.00, time = 23.11s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -121.46, time = 23.13s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -123.73, time = 23.11s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -126.00, time = 23.13s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -128.31, time = 23.12s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -130.70, time = 23.12s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -132.96, time = 23.13s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -135.29, time = 23.11s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -137.63, time = 23.11s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/300
 - 24s - loss: 0.0322 - val_loss: 0.0043
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1388 thread 17 bound to OS proc set 1
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1389 thread 18 bound to OS proc set 2
OMP: Info #250: KMP_AFFINITY: pid 1161 tid 1390 thread 19 bound to OS proc set 3
 - val_f1: 0.9976
Epoch 2/300
 - 23s - loss: 0.0047 - val_loss: 0.0025
 - val_f1: 0.9983
Epoch 3/300
 - 23s - loss: 0.0030 - val_loss: 0.0016
 - val_f1: 0.9990
Epoch 4/300
 - 23s - loss: 0.0022 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 5/300
 - 23s - loss: 0.0019 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 6/300
 - 23s - loss: 0.0017 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 7/300
 - 23s - loss: 0.0016 - val_loss: 9.5771e-04
 - val_f1: 0.9995
Epoch 8/300
 - 23s - loss: 0.0015 - val_loss: 9.1702e-04
 - val_f1: 0.9995
Epoch 9/300
 - 23s - loss: 0.0014 - val_loss: 8.8090e-04
 - val_f1: 0.9995
Epoch 10/300
 - 23s - loss: 0.0013 - val_loss: 8.7536e-04
 - val_f1: 0.9995
Epoch 11/300
 - 23s - loss: 0.0013 - val_loss: 8.3157e-04
 - val_f1: 0.9995
Epoch 12/300
 - 23s - loss: 0.0012 - val_loss: 8.0785e-04
 - val_f1: 0.9996
Epoch 13/300
 - 23s - loss: 0.0012 - val_loss: 7.9517e-04
 - val_f1: 0.9996
Epoch 14/300
 - 23s - loss: 0.0012 - val_loss: 7.7476e-04
 - val_f1: 0.9996
Epoch 15/300
 - 23s - loss: 0.0012 - val_loss: 7.5671e-04
 - val_f1: 0.9996
Epoch 16/300
 - 23s - loss: 0.0011 - val_loss: 7.3609e-04
 - val_f1: 0.9996
Epoch 17/300
 - 23s - loss: 0.0011 - val_loss: 7.1555e-04
 - val_f1: 0.9996
Epoch 18/300
 - 23s - loss: 0.0011 - val_loss: 7.0701e-04
 - val_f1: 0.9996
Epoch 19/300
 - 23s - loss: 0.0010 - val_loss: 6.9588e-04
 - val_f1: 0.9996
Epoch 20/300
 - 23s - loss: 0.0010 - val_loss: 6.8996e-04
 - val_f1: 0.9996
Epoch 21/300
 - 23s - loss: 9.9958e-04 - val_loss: 6.6819e-04
 - val_f1: 0.9997
Epoch 22/300
 - 23s - loss: 9.7147e-04 - val_loss: 6.8623e-04
 - val_f1: 0.9996
Epoch 23/300
 - 23s - loss: 9.3561e-04 - val_loss: 6.6921e-04
 - val_f1: 0.9997
Epoch 24/300
 - 23s - loss: 9.3922e-04 - val_loss: 6.6185e-04
 - val_f1: 0.9997
Epoch 25/300
 - 23s - loss: 9.0578e-04 - val_loss: 6.5949e-04
 - val_f1: 0.9997
Epoch 26/300
 - 23s - loss: 8.9378e-04 - val_loss: 6.4321e-04
 - val_f1: 0.9997
Epoch 27/300
 - 23s - loss: 8.5656e-04 - val_loss: 6.2129e-04
 - val_f1: 0.9997
Epoch 28/300
 - 23s - loss: 8.5766e-04 - val_loss: 6.4777e-04
 - val_f1: 0.9997
Epoch 29/300
 - 23s - loss: 8.3782e-04 - val_loss: 6.4024e-04
 - val_f1: 0.9997
Epoch 30/300
 - 23s - loss: 8.2103e-04 - val_loss: 6.1966e-04
 - val_f1: 0.9997
Epoch 31/300
 - 23s - loss: 8.0437e-04 - val_loss: 6.0780e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-29 11:19:16,511 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/ann_model_epoch_30.pickle
 - val_f1: 0.9997
Epoch 32/300
 - 23s - loss: 7.9258e-04 - val_loss: 5.7144e-04
 - val_f1: 0.9997
Epoch 33/300
 - 23s - loss: 7.5186e-04 - val_loss: 5.4319e-04
 - val_f1: 0.9997
Epoch 34/300
 - 23s - loss: 7.2648e-04 - val_loss: 5.4388e-04
 - val_f1: 0.9997
Epoch 35/300
 - 23s - loss: 7.2567e-04 - val_loss: 5.4408e-04
 - val_f1: 0.9997
Epoch 36/300
 - 23s - loss: 6.9996e-04 - val_loss: 5.5468e-04
 - val_f1: 0.9997
Epoch 37/300
 - 23s - loss: 6.9856e-04 - val_loss: 5.2957e-04
 - val_f1: 0.9997
Epoch 38/300
 - 23s - loss: 6.7700e-04 - val_loss: 5.3380e-04
 - val_f1: 0.9997
Epoch 39/300
 - 23s - loss: 6.8028e-04 - val_loss: 5.2896e-04
 - val_f1: 0.9997
Epoch 40/300
 - 23s - loss: 6.5688e-04 - val_loss: 5.1631e-04
 - val_f1: 0.9997
Epoch 41/300
 - 23s - loss: 6.7139e-04 - val_loss: 5.1552e-04
 - val_f1: 0.9997
Epoch 42/300
 - 23s - loss: 6.4313e-04 - val_loss: 5.0058e-04
 - val_f1: 0.9997
Epoch 43/300
 - 23s - loss: 6.6955e-04 - val_loss: 4.8738e-04
 - val_f1: 0.9997
Epoch 44/300
 - 23s - loss: 6.4071e-04 - val_loss: 4.8860e-04
 - val_f1: 0.9997
Epoch 45/300
 - 23s - loss: 6.4402e-04 - val_loss: 4.6507e-04
 - val_f1: 0.9997
Epoch 46/300
 - 23s - loss: 6.4015e-04 - val_loss: 4.5995e-04
 - val_f1: 0.9997
Epoch 47/300
 - 23s - loss: 6.2355e-04 - val_loss: 4.6665e-04
 - val_f1: 0.9997
Epoch 48/300
 - 23s - loss: 6.2356e-04 - val_loss: 4.6140e-04
 - val_f1: 0.9997
Epoch 49/300
 - 23s - loss: 6.2757e-04 - val_loss: 4.6997e-04
 - val_f1: 0.9997
Epoch 50/300
 - 23s - loss: 5.9627e-04 - val_loss: 4.5796e-04
 - val_f1: 0.9997
Epoch 51/300
 - 23s - loss: 6.1331e-04 - val_loss: 4.5551e-04
 - val_f1: 0.9997
Epoch 52/300
 - 23s - loss: 6.1326e-04 - val_loss: 4.6311e-04
 - val_f1: 0.9997
Epoch 53/300
 - 23s - loss: 5.9525e-04 - val_loss: 4.6761e-04
 - val_f1: 0.9997
Epoch 54/300
 - 23s - loss: 6.3037e-04 - val_loss: 4.4354e-04
 - val_f1: 0.9997
Epoch 55/300
 - 23s - loss: 6.0214e-04 - val_loss: 4.4325e-04
 - val_f1: 0.9997
Epoch 56/300
 - 23s - loss: 5.9935e-04 - val_loss: 4.6598e-04
 - val_f1: 0.9997
Epoch 57/300
 - 23s - loss: 5.9999e-04 - val_loss: 4.3714e-04
 - val_f1: 0.9997
Epoch 58/300
 - 23s - loss: 5.9791e-04 - val_loss: 4.3085e-04
 - val_f1: 0.9997
Epoch 59/300
 - 23s - loss: 5.7866e-04 - val_loss: 4.3193e-04
 - val_f1: 0.9997
Epoch 60/300
 - 23s - loss: 5.6744e-04 - val_loss: 4.2502e-04
 - val_f1: 0.9997
Epoch 61/300
 - 23s - loss: 5.8405e-04 - val_loss: 4.2772e-04
2019-12-29 11:38:10,666 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/ann_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 23s - loss: 5.5101e-04 - val_loss: 4.3687e-04
 - val_f1: 0.9998
Epoch 63/300
 - 23s - loss: 5.6125e-04 - val_loss: 4.5246e-04
 - val_f1: 0.9998
Epoch 64/300
 - 23s - loss: 5.8187e-04 - val_loss: 4.2907e-04
 - val_f1: 0.9997
Epoch 65/300
 - 23s - loss: 5.4469e-04 - val_loss: 4.2244e-04
 - val_f1: 0.9998
Epoch 66/300
 - 23s - loss: 5.4921e-04 - val_loss: 4.3233e-04
 - val_f1: 0.9997
Epoch 67/300
 - 23s - loss: 5.2327e-04 - val_loss: 4.1585e-04
 - val_f1: 0.9998
Epoch 68/300
 - 23s - loss: 5.3736e-04 - val_loss: 4.1630e-04
 - val_f1: 0.9998
Epoch 69/300
 - 23s - loss: 5.5085e-04 - val_loss: 4.3265e-04
 - val_f1: 0.9998
Epoch 70/300
 - 23s - loss: 5.0937e-04 - val_loss: 4.1951e-04
 - val_f1: 0.9998
Epoch 71/300
 - 23s - loss: 5.1945e-04 - val_loss: 4.2455e-04
 - val_f1: 0.9998
Epoch 72/300
 - 23s - loss: 5.0108e-04 - val_loss: 4.2621e-04
 - val_f1: 0.9998
Epoch 73/300
 - 23s - loss: 5.1391e-04 - val_loss: 4.1464e-04
 - val_f1: 0.9998
Epoch 74/300
 - 23s - loss: 5.3004e-04 - val_loss: 4.1041e-04
 - val_f1: 0.9998
Epoch 75/300
 - 23s - loss: 5.3056e-04 - val_loss: 4.0933e-04
 - val_f1: 0.9998
Epoch 76/300
 - 23s - loss: 5.0421e-04 - val_loss: 4.0502e-04
 - val_f1: 0.9998
Epoch 77/300
 - 23s - loss: 5.0778e-04 - val_loss: 4.7820e-04
 - val_f1: 0.9997
Epoch 78/300
 - 23s - loss: 4.9914e-04 - val_loss: 4.0596e-04
 - val_f1: 0.9998
Epoch 79/300
 - 23s - loss: 4.9057e-04 - val_loss: 4.0118e-04
 - val_f1: 0.9998
Epoch 80/300
 - 23s - loss: 4.9889e-04 - val_loss: 3.9021e-04
 - val_f1: 0.9998
Epoch 81/300
 - 23s - loss: 4.9159e-04 - val_loss: 4.0795e-04
 - val_f1: 0.9998
Epoch 82/300
 - 23s - loss: 4.8728e-04 - val_loss: 4.1192e-04
 - val_f1: 0.9998
Epoch 83/300
 - 23s - loss: 4.8700e-04 - val_loss: 4.0951e-04
 - val_f1: 0.9998
Epoch 84/300
 - 23s - loss: 4.7487e-04 - val_loss: 3.9914e-04
 - val_f1: 0.9998
Epoch 85/300
 - 23s - loss: 4.8926e-04 - val_loss: 4.0341e-04
 - val_f1: 0.9998
Epoch 86/300
 - 23s - loss: 4.6823e-04 - val_loss: 4.3423e-04
 - val_f1: 0.9997
Epoch 87/300
 - 23s - loss: 4.9552e-04 - val_loss: 4.0965e-04
 - val_f1: 0.9998
Epoch 88/300
 - 23s - loss: 4.7356e-04 - val_loss: 3.9530e-04
 - val_f1: 0.9998
Epoch 89/300
 - 23s - loss: 4.7674e-04 - val_loss: 4.1215e-04
 - val_f1: 0.9998
Epoch 90/300
 - 23s - loss: 4.8263e-04 - val_loss: 4.2169e-04
 - val_f1: 0.9998
Epoch 91/300
 - 23s - loss: 4.5802e-04 - val_loss: 4.0380e-04
2019-12-29 11:57:04,884 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 23s - loss: 4.7943e-04 - val_loss: 4.0829e-04
 - val_f1: 0.9998
Epoch 93/300
 - 23s - loss: 4.7129e-04 - val_loss: 4.1911e-04
 - val_f1: 0.9998
Epoch 94/300
 - 23s - loss: 4.7155e-04 - val_loss: 4.1623e-04
 - val_f1: 0.9998
Epoch 95/300
 - 23s - loss: 4.6323e-04 - val_loss: 4.1100e-04
 - val_f1: 0.9998
Epoch 96/300
 - 23s - loss: 4.6185e-04 - val_loss: 3.9979e-04
 - val_f1: 0.9998
Epoch 97/300
 - 23s - loss: 4.5855e-04 - val_loss: 3.9364e-04
 - val_f1: 0.9998
Epoch 98/300
 - 23s - loss: 4.4625e-04 - val_loss: 3.9745e-04
 - val_f1: 0.9998
Epoch 99/300
 - 23s - loss: 4.6177e-04 - val_loss: 4.2448e-04
 - val_f1: 0.9998
Epoch 100/300
 - 23s - loss: 4.4900e-04 - val_loss: 5.8926e-04
 - val_f1: 0.9995
Epoch 101/300
 - 23s - loss: 4.5282e-04 - val_loss: 4.0556e-04
 - val_f1: 0.9998
Epoch 102/300
 - 23s - loss: 4.3499e-04 - val_loss: 4.1726e-04
 - val_f1: 0.9998
Epoch 103/300
 - 23s - loss: 4.5377e-04 - val_loss: 4.3071e-04
 - val_f1: 0.9998
Epoch 104/300
 - 23s - loss: 4.4839e-04 - val_loss: 3.8687e-04
 - val_f1: 0.9998
Epoch 105/300
 - 23s - loss: 4.5296e-04 - val_loss: 3.8922e-04
 - val_f1: 0.9998
Epoch 106/300
 - 23s - loss: 4.4826e-04 - val_loss: 3.9237e-04
 - val_f1: 0.9998
Epoch 107/300
 - 23s - loss: 4.2989e-04 - val_loss: 4.0150e-04
 - val_f1: 0.9998
Epoch 108/300
 - 23s - loss: 4.4411e-04 - val_loss: 3.8735e-04
 - val_f1: 0.9998
Epoch 109/300
 - 23s - loss: 4.5398e-04 - val_loss: 3.9627e-04
 - val_f1: 0.9998
Epoch 110/300
 - 23s - loss: 4.6241e-04 - val_loss: 3.7924e-04
 - val_f1: 0.9998
Epoch 111/300
 - 23s - loss: 4.2301e-04 - val_loss: 3.7912e-04
 - val_f1: 0.9998
Epoch 112/300
 - 23s - loss: 4.3660e-04 - val_loss: 3.7252e-04
 - val_f1: 0.9998
Epoch 113/300
 - 23s - loss: 4.4182e-04 - val_loss: 4.0189e-04
 - val_f1: 0.9998
Epoch 114/300
 - 23s - loss: 4.3657e-04 - val_loss: 3.8319e-04
 - val_f1: 0.9998
Epoch 115/300
 - 23s - loss: 4.4310e-04 - val_loss: 3.6951e-04
 - val_f1: 0.9998
Epoch 116/300
 - 23s - loss: 4.3672e-04 - val_loss: 3.6597e-04
 - val_f1: 0.9998
Epoch 117/300
 - 23s - loss: 4.3318e-04 - val_loss: 4.0018e-04
 - val_f1: 0.9998
Epoch 118/300
 - 23s - loss: 4.0666e-04 - val_loss: 3.7640e-04
 - val_f1: 0.9998
Epoch 119/300
 - 23s - loss: 4.3378e-04 - val_loss: 3.8526e-04
 - val_f1: 0.9998
Epoch 120/300
 - 23s - loss: 4.3939e-04 - val_loss: 3.8709e-04
 - val_f1: 0.9998
Epoch 121/300
 - 23s - loss: 4.2338e-04 - val_loss: 4.0178e-04
2019-12-29 12:15:59,165 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 23s - loss: 4.3427e-04 - val_loss: 3.7154e-04
 - val_f1: 0.9998
Epoch 123/300
 - 23s - loss: 4.2638e-04 - val_loss: 3.7423e-04
 - val_f1: 0.9998
Epoch 124/300
 - 23s - loss: 4.1527e-04 - val_loss: 3.9568e-04
 - val_f1: 0.9998
Epoch 125/300
 - 23s - loss: 4.2997e-04 - val_loss: 3.8423e-04
 - val_f1: 0.9998
Epoch 126/300
 - 23s - loss: 3.9998e-04 - val_loss: 3.8216e-04
 - val_f1: 0.9998
Epoch 127/300
 - 23s - loss: 4.1711e-04 - val_loss: 4.1187e-04
 - val_f1: 0.9998
Epoch 128/300
 - 23s - loss: 4.2172e-04 - val_loss: 3.8419e-04
 - val_f1: 0.9998
Epoch 129/300
 - 23s - loss: 4.1497e-04 - val_loss: 3.7619e-04
 - val_f1: 0.9998
Epoch 130/300
 - 23s - loss: 4.3511e-04 - val_loss: 3.7865e-04
 - val_f1: 0.9998
Epoch 131/300
 - 23s - loss: 4.3170e-04 - val_loss: 3.7015e-04
 - val_f1: 0.9998
Epoch 132/300
 - 23s - loss: 4.1426e-04 - val_loss: 3.9943e-04
 - val_f1: 0.9998
Epoch 133/300
 - 23s - loss: 4.0363e-04 - val_loss: 3.9277e-04
 - val_f1: 0.9998
Epoch 134/300
 - 23s - loss: 4.1767e-04 - val_loss: 3.9033e-04
 - val_f1: 0.9998
Epoch 135/300
 - 23s - loss: 4.1192e-04 - val_loss: 3.8372e-04
 - val_f1: 0.9998
Epoch 136/300
 - 23s - loss: 4.2329e-04 - val_loss: 3.8571e-04
 - val_f1: 0.9998
Epoch 137/300
 - 23s - loss: 4.0500e-04 - val_loss: 3.7810e-04
 - val_f1: 0.9998
Epoch 138/300
 - 23s - loss: 3.9882e-04 - val_loss: 3.7886e-04
 - val_f1: 0.9998
Epoch 139/300
 - 23s - loss: 4.0135e-04 - val_loss: 4.1078e-04
 - val_f1: 0.9998
Epoch 140/300
 - 23s - loss: 4.1594e-04 - val_loss: 4.0715e-04
 - val_f1: 0.9998
Epoch 141/300
 - 23s - loss: 4.2437e-04 - val_loss: 3.9876e-04
 - val_f1: 0.9998
Epoch 142/300
 - 23s - loss: 3.9621e-04 - val_loss: 4.8435e-04
 - val_f1: 0.9997
Epoch 143/300
 - 23s - loss: 4.0795e-04 - val_loss: 4.0370e-04
 - val_f1: 0.9998
Epoch 144/300
 - 23s - loss: 3.9843e-04 - val_loss: 3.9368e-04
 - val_f1: 0.9998
Epoch 145/300
 - 23s - loss: 4.0364e-04 - val_loss: 4.0032e-04
 - val_f1: 0.9998
Epoch 146/300
 - 23s - loss: 4.0756e-04 - val_loss: 4.1415e-04
 - val_f1: 0.9998
Epoch 147/300
 - 23s - loss: 3.8293e-04 - val_loss: 4.0226e-04
 - val_f1: 0.9998
Epoch 148/300
 - 23s - loss: 4.0085e-04 - val_loss: 4.4784e-04
 - val_f1: 0.9997
Epoch 149/300
 - 23s - loss: 4.1746e-04 - val_loss: 4.1255e-04
 - val_f1: 0.9998
Epoch 150/300
 - 23s - loss: 3.8627e-04 - val_loss: 3.8290e-04
 - val_f1: 0.9998
Epoch 151/300
 - 23s - loss: 4.0631e-04 - val_loss: 3.9285e-04
2019-12-29 12:34:49,342 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 23s - loss: 4.0641e-04 - val_loss: 3.9336e-04
 - val_f1: 0.9998
Epoch 153/300
 - 23s - loss: 4.1337e-04 - val_loss: 4.0081e-04
 - val_f1: 0.9998
Epoch 154/300
 - 23s - loss: 3.8800e-04 - val_loss: 4.6532e-04
 - val_f1: 0.9998
Epoch 155/300
 - 23s - loss: 4.3625e-04 - val_loss: 3.9386e-04
 - val_f1: 0.9998
Epoch 156/300
 - 23s - loss: 3.8520e-04 - val_loss: 3.9442e-04
 - val_f1: 0.9998
Epoch 157/300
 - 23s - loss: 3.9103e-04 - val_loss: 4.1091e-04
 - val_f1: 0.9998
Epoch 158/300
 - 23s - loss: 3.9631e-04 - val_loss: 4.1346e-04
 - val_f1: 0.9998
Epoch 159/300
 - 23s - loss: 4.1311e-04 - val_loss: 3.9822e-04
 - val_f1: 0.9998
Epoch 160/300
 - 23s - loss: 4.0971e-04 - val_loss: 5.1398e-04
 - val_f1: 0.9997
Epoch 161/300
 - 23s - loss: 3.7665e-04 - val_loss: 3.9718e-04
 - val_f1: 0.9998
Epoch 162/300
 - 23s - loss: 3.8121e-04 - val_loss: 4.0254e-04
 - val_f1: 0.9998
Epoch 163/300
 - 23s - loss: 3.7843e-04 - val_loss: 3.9838e-04
 - val_f1: 0.9998
Epoch 164/300
 - 23s - loss: 3.8356e-04 - val_loss: 4.1442e-04
 - val_f1: 0.9998
Epoch 165/300
 - 23s - loss: 3.8821e-04 - val_loss: 3.8448e-04
 - val_f1: 0.9998
Epoch 166/300
 - 23s - loss: 3.8931e-04 - val_loss: 3.9762e-04
2019-12-29 12:44:28,726 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-29 12:45:20,995 [INFO] Last epoch loss evaluation: train_loss = 0.000265, val_loss = 0.000366
2019-12-29 12:45:21,009 [INFO] Training complete. time_to_train = 7532.21 sec, 125.54 min
2019-12-29 12:45:21,013 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_shallow_rep1/best_model.pickle
2019-12-29 12:45:21,016 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_shallow_rep1/training_error_history.csv
2019-12-29 12:45:21,205 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep1/training_error_history.png
2019-12-29 12:45:21,369 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep1/training_f1_history.png
2019-12-29 12:45:21,369 [INFO] Making predictions on training, validation, testing data
2019-12-29 12:46:34,304 [INFO] Evaluating predictions (results)
2019-12-29 12:46:43,100 [INFO] Dataset: Testing. Classification report below
2019-12-29 12:46:43,100 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.77      0.80      0.79      4166
         r2l       0.98      0.03      0.05     13781
         u2r       0.92      0.00      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.88      0.56      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-29 12:46:43,100 [INFO] Overall accuracy (micro avg): 0.9237884570249076
2019-12-29 12:46:52,404 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9238         0.9238                       0.9238                0.0191                   0.0762  0.9238
1     Macro avg        0.9695         0.8793                       0.5590                0.0193                   0.4410  0.5347
2  Weighted avg        0.9686         0.9413                       0.9238                0.0200                   0.0762  0.9049
2019-12-29 12:47:22,611 [INFO] Dataset: Validation. Classification report below
2019-12-29 12:47:22,611 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       0.99      0.99      0.99      8221
         r2l       0.95      0.87      0.90       225
         u2r       0.50      0.20      0.29        10

    accuracy                           1.00    979687
   macro avg       0.89      0.81      0.84    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-29 12:47:22,611 [INFO] Overall accuracy (micro avg): 0.9998019775703872
2019-12-29 12:47:55,191 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8879                       0.8121                0.0001                   0.1879  0.8368
2  Weighted avg        0.9999         0.9998                       0.9998                0.0002                   0.0002  0.9998
2019-12-29 12:50:08,099 [INFO] Dataset: Training. Classification report below
2019-12-29 12:50:08,099 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       0.99      0.99      0.99     32881
         r2l       0.92      0.87      0.90       901
         u2r       0.92      0.52      0.67        42

    accuracy                           1.00   3918744
   macro avg       0.97      0.88      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-29 12:50:08,099 [INFO] Overall accuracy (micro avg): 0.9998170332126824
2019-12-29 12:52:31,550 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9667                       0.8782                0.0001                   0.1218  0.9116
2  Weighted avg        0.9999         0.9998                       0.9998                0.0002                   0.0002  0.9998
2019-12-29 12:52:31,597 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_shallow_rep1/selected_kdd99_dbn_shallow_rep1_results.xlsx
2019-12-29 12:52:31,604 [INFO] ================= Finished running experiment no. 1 ================= 

2019-12-29 12:52:31,630 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_shallow_rep2
2019-12-29 12:52:31,631 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_shallow_rep2/run_log.log
2019-12-29 12:52:31,631 [INFO] ================= Running experiment no. 2  ================= 

2019-12-29 12:52:31,631 [INFO] Experiment parameters given below
2019-12-29 12:52:31,631 [INFO] 
{'experiment_num': 2, 'results_dir': 'results_selected_models/selected_kdd99_dbn_shallow_rep2', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_shallow_rep2'}
2019-12-29 12:52:31,631 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_shallow_rep2/tf_logs_run_2019_12_29-12_52_31
2019-12-29 12:52:31,631 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-29 12:52:31,631 [INFO] Reading X, y files
2019-12-29 12:52:31,631 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-29 12:52:38,017 [INFO] Reading complete. time_to_read=6.39 seconds
2019-12-29 12:52:38,017 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-29 12:52:39,635 [INFO] Reading complete. time_to_read=1.62 seconds
2019-12-29 12:52:39,635 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-29 12:52:40,090 [INFO] Reading complete. time_to_read=0.45 seconds
2019-12-29 12:52:40,090 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-29 12:52:40,287 [INFO] Reading complete. time_to_read=0.20 seconds
2019-12-29 12:52:40,288 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-29 12:52:40,342 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-29 12:52:40,342 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-29 12:52:40,362 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-29 12:52:47,537 [INFO] Initializing model
2019-12-29 12:52:47,537 [INFO] Training model
2019-12-29 12:52:47,537 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-29 12:53:27,560 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 4a0e5b84cb5fe5166180e5705f743fb0a6189fc9
2019-12-29 12:53:27,561 [INFO] Pretraining Deep Belief Network
2019-12-29 13:14:01,773 [INFO] Pretraining Complete
2019-12-29 13:14:01,774 [INFO] Getting pretrained weights
2019-12-29 13:14:01,774 [INFO] Creating and initializing feed forward neural network
2019-12-29 13:14:01,900 [INFO] _________________________________________________________________
2019-12-29 13:14:01,900 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-29 13:14:01,901 [INFO] =================================================================
2019-12-29 13:14:01,901 [INFO] dense_3 (Dense)              (None, 32)                3968      
2019-12-29 13:14:01,901 [INFO] _________________________________________________________________
2019-12-29 13:14:01,901 [INFO] batch_normalization_2 (Batch (None, 32)                128       
2019-12-29 13:14:01,901 [INFO] _________________________________________________________________
2019-12-29 13:14:01,901 [INFO] dropout_2 (Dropout)          (None, 32)                0         
2019-12-29 13:14:01,901 [INFO] _________________________________________________________________
2019-12-29 13:14:01,901 [INFO] dense_4 (Dense)              (None, 5)                 165       
2019-12-29 13:14:01,901 [INFO] =================================================================
2019-12-29 13:14:01,902 [INFO] Total params: 4,261
2019-12-29 13:14:01,902 [INFO] Trainable params: 4,197
2019-12-29 13:14:01,902 [INFO] Non-trainable params: 64
2019-12-29 13:14:01,902 [INFO] _________________________________________________________________
2019-12-29 13:14:02,031 [INFO] Fine-tuning final neural network
 - val_f1: 0.9998
Epoch 00166: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.48, time = 16.53s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -33.96, time = 25.51s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.18, time = 25.40s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.83, time = 25.34s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -36.31, time = 25.32s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.75, time = 25.28s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -41.00, time = 25.25s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.25, time = 25.11s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.51, time = 25.12s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -47.77, time = 25.08s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -49.96, time = 25.04s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -52.07, time = 25.02s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -54.14, time = 24.97s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -56.15, time = 24.95s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -58.12, time = 24.94s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -60.24, time = 24.68s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -62.41, time = 24.58s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -64.67, time = 24.57s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -66.94, time = 24.56s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -69.24, time = 24.54s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -71.53, time = 24.53s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -73.98, time = 24.53s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -76.27, time = 24.54s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -78.74, time = 24.52s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -81.09, time = 24.54s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -83.54, time = 24.54s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -85.96, time = 24.52s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -88.32, time = 24.51s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -90.72, time = 24.51s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -93.20, time = 24.45s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -95.58, time = 24.49s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -98.02, time = 24.48s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -100.44, time = 24.49s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -102.87, time = 24.47s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -105.28, time = 24.49s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -107.68, time = 24.49s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -110.16, time = 24.47s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -112.61, time = 24.47s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -114.98, time = 24.47s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -117.43, time = 24.46s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -119.77, time = 24.45s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -122.13, time = 24.44s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -124.59, time = 24.44s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -126.99, time = 24.44s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -129.32, time = 24.45s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -131.76, time = 24.45s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -134.20, time = 24.44s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -136.55, time = 24.45s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -138.97, time = 24.44s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -141.36, time = 24.42s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/300
 - 24s - loss: 0.0363 - val_loss: 0.0048
 - val_f1: 0.9972
Epoch 2/300
 - 23s - loss: 0.0053 - val_loss: 0.0023
 - val_f1: 0.9983
Epoch 3/300
 - 23s - loss: 0.0031 - val_loss: 0.0015
 - val_f1: 0.9991
Epoch 4/300
 - 23s - loss: 0.0023 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 5/300
 - 23s - loss: 0.0019 - val_loss: 0.0010
 - val_f1: 0.9994
Epoch 6/300
 - 23s - loss: 0.0017 - val_loss: 9.3065e-04
 - val_f1: 0.9995
Epoch 7/300
 - 23s - loss: 0.0016 - val_loss: 8.9543e-04
 - val_f1: 0.9995
Epoch 8/300
 - 23s - loss: 0.0015 - val_loss: 8.4606e-04
 - val_f1: 0.9995
Epoch 9/300
 - 23s - loss: 0.0014 - val_loss: 8.3438e-04
 - val_f1: 0.9995
Epoch 10/300
 - 23s - loss: 0.0013 - val_loss: 7.7653e-04
 - val_f1: 0.9996
Epoch 11/300
 - 23s - loss: 0.0013 - val_loss: 7.8568e-04
 - val_f1: 0.9996
Epoch 12/300
 - 23s - loss: 0.0012 - val_loss: 7.7596e-04
 - val_f1: 0.9996
Epoch 13/300
 - 23s - loss: 0.0012 - val_loss: 7.4750e-04
 - val_f1: 0.9996
Epoch 14/300
 - 23s - loss: 0.0012 - val_loss: 7.4814e-04
 - val_f1: 0.9996
Epoch 15/300
 - 23s - loss: 0.0011 - val_loss: 7.2368e-04
 - val_f1: 0.9996
Epoch 16/300
 - 23s - loss: 0.0011 - val_loss: 7.1027e-04
 - val_f1: 0.9996
Epoch 17/300
 - 23s - loss: 0.0011 - val_loss: 6.8010e-04
 - val_f1: 0.9996
Epoch 18/300
 - 24s - loss: 0.0010 - val_loss: 6.8566e-04
 - val_f1: 0.9996
Epoch 19/300
 - 23s - loss: 9.9720e-04 - val_loss: 6.7770e-04
 - val_f1: 0.9996
Epoch 20/300
 - 23s - loss: 0.0010 - val_loss: 6.7355e-04
 - val_f1: 0.9996
Epoch 21/300
 - 23s - loss: 9.2556e-04 - val_loss: 6.5725e-04
 - val_f1: 0.9996
Epoch 22/300
 - 24s - loss: 9.1219e-04 - val_loss: 6.5720e-04
 - val_f1: 0.9996
Epoch 23/300
 - 23s - loss: 9.2111e-04 - val_loss: 6.3096e-04
 - val_f1: 0.9997
Epoch 24/300
 - 23s - loss: 8.6164e-04 - val_loss: 6.5096e-04
 - val_f1: 0.9996
Epoch 25/300
 - 23s - loss: 8.5626e-04 - val_loss: 6.3825e-04
 - val_f1: 0.9996
Epoch 26/300
 - 23s - loss: 8.4543e-04 - val_loss: 6.1740e-04
 - val_f1: 0.9997
Epoch 27/300
 - 23s - loss: 8.3149e-04 - val_loss: 5.9397e-04
 - val_f1: 0.9997
Epoch 28/300
 - 23s - loss: 8.2741e-04 - val_loss: 5.7276e-04
 - val_f1: 0.9997
Epoch 29/300
 - 23s - loss: 7.8030e-04 - val_loss: 5.8402e-04
 - val_f1: 0.9997
Epoch 30/300
 - 23s - loss: 7.7655e-04 - val_loss: 5.7894e-04
 - val_f1: 0.9997
Epoch 31/300
 - 23s - loss: 7.7559e-04 - val_loss: 5.8292e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-29 13:33:57,073 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_30.pickle
 - val_f1: 0.9997
Epoch 32/300
 - 23s - loss: 7.6885e-04 - val_loss: 5.6345e-04
 - val_f1: 0.9997
Epoch 33/300
 - 23s - loss: 7.5688e-04 - val_loss: 5.5964e-04
 - val_f1: 0.9997
Epoch 34/300
 - 23s - loss: 7.5355e-04 - val_loss: 5.2609e-04
 - val_f1: 0.9997
Epoch 35/300
 - 23s - loss: 7.1319e-04 - val_loss: 5.2701e-04
 - val_f1: 0.9997
Epoch 36/300
 - 24s - loss: 7.2204e-04 - val_loss: 5.4831e-04
 - val_f1: 0.9997
Epoch 37/300
 - 23s - loss: 7.0054e-04 - val_loss: 5.3580e-04
 - val_f1: 0.9997
Epoch 38/300
 - 24s - loss: 6.9553e-04 - val_loss: 5.1259e-04
 - val_f1: 0.9997
Epoch 39/300
 - 23s - loss: 6.8199e-04 - val_loss: 5.0044e-04
 - val_f1: 0.9997
Epoch 40/300
 - 23s - loss: 6.8921e-04 - val_loss: 4.8800e-04
 - val_f1: 0.9997
Epoch 41/300
 - 23s - loss: 6.7684e-04 - val_loss: 5.0891e-04
 - val_f1: 0.9997
Epoch 42/300
 - 23s - loss: 6.7508e-04 - val_loss: 5.2149e-04
 - val_f1: 0.9997
Epoch 43/300
 - 23s - loss: 6.7318e-04 - val_loss: 4.8299e-04
 - val_f1: 0.9997
Epoch 44/300
 - 23s - loss: 6.4194e-04 - val_loss: 5.0053e-04
 - val_f1: 0.9997
Epoch 45/300
 - 23s - loss: 6.4337e-04 - val_loss: 4.7347e-04
 - val_f1: 0.9997
Epoch 46/300
 - 23s - loss: 6.4201e-04 - val_loss: 4.7352e-04
 - val_f1: 0.9997
Epoch 47/300
 - 23s - loss: 6.3830e-04 - val_loss: 4.4678e-04
 - val_f1: 0.9997
Epoch 48/300
 - 23s - loss: 6.2321e-04 - val_loss: 4.6982e-04
 - val_f1: 0.9997
Epoch 49/300
 - 23s - loss: 6.1734e-04 - val_loss: 4.5205e-04
 - val_f1: 0.9997
Epoch 50/300
 - 23s - loss: 6.1577e-04 - val_loss: 4.4886e-04
 - val_f1: 0.9997
Epoch 51/300
 - 23s - loss: 5.9805e-04 - val_loss: 4.5619e-04
 - val_f1: 0.9997
Epoch 52/300
 - 23s - loss: 6.0216e-04 - val_loss: 4.3585e-04
 - val_f1: 0.9997
Epoch 53/300
 - 23s - loss: 6.0314e-04 - val_loss: 4.3734e-04
 - val_f1: 0.9998
Epoch 54/300
 - 23s - loss: 6.1906e-04 - val_loss: 4.2503e-04
 - val_f1: 0.9998
Epoch 55/300
 - 23s - loss: 5.9803e-04 - val_loss: 4.3824e-04
 - val_f1: 0.9997
Epoch 56/300
 - 24s - loss: 5.8156e-04 - val_loss: 4.7894e-04
 - val_f1: 0.9997
Epoch 57/300
 - 23s - loss: 5.8771e-04 - val_loss: 4.5808e-04
 - val_f1: 0.9997
Epoch 58/300
 - 23s - loss: 5.8011e-04 - val_loss: 4.4465e-04
 - val_f1: 0.9998
Epoch 59/300
 - 23s - loss: 5.8836e-04 - val_loss: 4.3067e-04
 - val_f1: 0.9998
Epoch 60/300
 - 23s - loss: 5.7469e-04 - val_loss: 4.3344e-04
 - val_f1: 0.9998
Epoch 61/300
 - 23s - loss: 5.8839e-04 - val_loss: 4.1090e-04
2019-12-29 13:53:28,809 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_60.pickle
 - val_f1: 0.9998
Epoch 62/300
 - 24s - loss: 5.6165e-04 - val_loss: 4.1992e-04
 - val_f1: 0.9998
Epoch 63/300
 - 23s - loss: 5.5434e-04 - val_loss: 4.1217e-04
 - val_f1: 0.9998
Epoch 64/300
 - 23s - loss: 5.5553e-04 - val_loss: 4.7301e-04
 - val_f1: 0.9997
Epoch 65/300
 - 23s - loss: 5.6272e-04 - val_loss: 4.3681e-04
 - val_f1: 0.9997
Epoch 66/300
 - 23s - loss: 5.6531e-04 - val_loss: 4.4930e-04
 - val_f1: 0.9997
Epoch 67/300
 - 23s - loss: 5.5401e-04 - val_loss: 4.1309e-04
 - val_f1: 0.9998
Epoch 68/300
 - 23s - loss: 5.5283e-04 - val_loss: 4.2713e-04
 - val_f1: 0.9997
Epoch 69/300
 - 23s - loss: 5.4412e-04 - val_loss: 4.0888e-04
 - val_f1: 0.9998
Epoch 70/300
 - 23s - loss: 5.3712e-04 - val_loss: 4.1502e-04
 - val_f1: 0.9998
Epoch 71/300
 - 23s - loss: 5.2056e-04 - val_loss: 4.3443e-04
 - val_f1: 0.9998
Epoch 72/300
 - 23s - loss: 5.3284e-04 - val_loss: 4.6069e-04
 - val_f1: 0.9997
Epoch 73/300
 - 23s - loss: 5.2821e-04 - val_loss: 4.2070e-04
 - val_f1: 0.9998
Epoch 74/300
 - 23s - loss: 5.3315e-04 - val_loss: 4.0189e-04
 - val_f1: 0.9998
Epoch 75/300
 - 23s - loss: 5.4718e-04 - val_loss: 3.9915e-04
 - val_f1: 0.9998
Epoch 76/300
 - 23s - loss: 5.3642e-04 - val_loss: 4.1378e-04
 - val_f1: 0.9998
Epoch 77/300
 - 23s - loss: 5.3587e-04 - val_loss: 4.2878e-04
 - val_f1: 0.9998
Epoch 78/300
 - 23s - loss: 5.4709e-04 - val_loss: 4.1134e-04
 - val_f1: 0.9998
Epoch 79/300
 - 23s - loss: 5.2375e-04 - val_loss: 4.0841e-04
 - val_f1: 0.9998
Epoch 80/300
 - 23s - loss: 5.2770e-04 - val_loss: 3.9961e-04
 - val_f1: 0.9998
Epoch 81/300
 - 23s - loss: 5.1673e-04 - val_loss: 4.0803e-04
 - val_f1: 0.9998
Epoch 82/300
 - 24s - loss: 5.2470e-04 - val_loss: 4.1640e-04
 - val_f1: 0.9998
Epoch 83/300
 - 23s - loss: 5.2729e-04 - val_loss: 4.0445e-04
 - val_f1: 0.9998
Epoch 84/300
 - 23s - loss: 5.1384e-04 - val_loss: 4.1072e-04
 - val_f1: 0.9998
Epoch 85/300
 - 23s - loss: 5.0766e-04 - val_loss: 4.1390e-04
 - val_f1: 0.9998
Epoch 86/300
 - 23s - loss: 5.2904e-04 - val_loss: 3.9590e-04
 - val_f1: 0.9998
Epoch 87/300
 - 23s - loss: 5.0844e-04 - val_loss: 4.0280e-04
 - val_f1: 0.9998
Epoch 88/300
 - 23s - loss: 5.0662e-04 - val_loss: 4.1468e-04
 - val_f1: 0.9998
Epoch 89/300
 - 23s - loss: 5.1757e-04 - val_loss: 4.1338e-04
 - val_f1: 0.9998
Epoch 90/300
 - 23s - loss: 4.9629e-04 - val_loss: 4.2034e-04
 - val_f1: 0.9998
Epoch 91/300
 - 23s - loss: 5.2816e-04 - val_loss: 4.0703e-04
2019-12-29 14:13:00,047 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 23s - loss: 5.1590e-04 - val_loss: 4.0624e-04
 - val_f1: 0.9998
Epoch 93/300
 - 23s - loss: 5.0476e-04 - val_loss: 4.0758e-04
 - val_f1: 0.9998
Epoch 94/300
 - 23s - loss: 5.1151e-04 - val_loss: 4.1622e-04
 - val_f1: 0.9998
Epoch 95/300
 - 23s - loss: 5.0364e-04 - val_loss: 4.0594e-04
 - val_f1: 0.9998
Epoch 96/300
 - 23s - loss: 4.9230e-04 - val_loss: 3.9902e-04
 - val_f1: 0.9998
Epoch 97/300
 - 23s - loss: 4.8896e-04 - val_loss: 3.9118e-04
 - val_f1: 0.9998
Epoch 98/300
 - 23s - loss: 4.9638e-04 - val_loss: 4.1354e-04
 - val_f1: 0.9998
Epoch 99/300
 - 23s - loss: 4.8500e-04 - val_loss: 4.0326e-04
 - val_f1: 0.9998
Epoch 100/300
 - 23s - loss: 4.8335e-04 - val_loss: 3.9951e-04
 - val_f1: 0.9998
Epoch 101/300
 - 23s - loss: 4.9329e-04 - val_loss: 4.2483e-04
 - val_f1: 0.9998
Epoch 102/300
 - 23s - loss: 4.7414e-04 - val_loss: 4.5552e-04
 - val_f1: 0.9998
Epoch 103/300
 - 23s - loss: 4.9779e-04 - val_loss: 3.9975e-04
 - val_f1: 0.9998
Epoch 104/300
 - 23s - loss: 4.8057e-04 - val_loss: 4.0439e-04
 - val_f1: 0.9998
Epoch 105/300
 - 23s - loss: 4.8458e-04 - val_loss: 3.9842e-04
 - val_f1: 0.9998
Epoch 106/300
 - 23s - loss: 4.6842e-04 - val_loss: 3.9164e-04
 - val_f1: 0.9998
Epoch 107/300
 - 23s - loss: 4.7345e-04 - val_loss: 3.9903e-04
 - val_f1: 0.9998
Epoch 108/300
 - 23s - loss: 4.7208e-04 - val_loss: 3.9660e-04
 - val_f1: 0.9998
Epoch 109/300
 - 23s - loss: 4.8263e-04 - val_loss: 3.9036e-04
 - val_f1: 0.9998
Epoch 110/300
 - 23s - loss: 4.7972e-04 - val_loss: 4.1751e-04
 - val_f1: 0.9998
Epoch 111/300
 - 23s - loss: 4.7223e-04 - val_loss: 3.9957e-04
 - val_f1: 0.9998
Epoch 112/300
 - 23s - loss: 4.5942e-04 - val_loss: 4.0376e-04
 - val_f1: 0.9998
Epoch 113/300
 - 23s - loss: 4.7437e-04 - val_loss: 3.9385e-04
 - val_f1: 0.9998
Epoch 114/300
 - 23s - loss: 4.7416e-04 - val_loss: 4.0828e-04
 - val_f1: 0.9998
Epoch 115/300
 - 23s - loss: 4.6502e-04 - val_loss: 3.9695e-04
 - val_f1: 0.9998
Epoch 116/300
 - 23s - loss: 4.6815e-04 - val_loss: 3.8731e-04
 - val_f1: 0.9998
Epoch 117/300
 - 23s - loss: 4.7343e-04 - val_loss: 4.0166e-04
 - val_f1: 0.9998
Epoch 118/300
 - 23s - loss: 4.6709e-04 - val_loss: 3.9553e-04
 - val_f1: 0.9998
Epoch 119/300
 - 23s - loss: 4.6386e-04 - val_loss: 3.8867e-04
 - val_f1: 0.9998
Epoch 120/300
 - 23s - loss: 4.5945e-04 - val_loss: 3.9519e-04
 - val_f1: 0.9998
Epoch 121/300
 - 23s - loss: 4.4675e-04 - val_loss: 4.2066e-04
2019-12-29 14:32:30,280 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 23s - loss: 4.5507e-04 - val_loss: 3.9703e-04
 - val_f1: 0.9998
Epoch 123/300
 - 23s - loss: 4.5847e-04 - val_loss: 3.8607e-04
 - val_f1: 0.9998
Epoch 124/300
 - 23s - loss: 4.6645e-04 - val_loss: 4.0677e-04
 - val_f1: 0.9998
Epoch 125/300
 - 23s - loss: 4.4784e-04 - val_loss: 3.9069e-04
 - val_f1: 0.9998
Epoch 126/300
 - 23s - loss: 4.6426e-04 - val_loss: 4.0938e-04
 - val_f1: 0.9998
Epoch 127/300
 - 23s - loss: 4.6407e-04 - val_loss: 3.9508e-04
 - val_f1: 0.9998
Epoch 128/300
 - 23s - loss: 4.7328e-04 - val_loss: 4.2093e-04
 - val_f1: 0.9998
Epoch 129/300
 - 23s - loss: 4.4639e-04 - val_loss: 4.1446e-04
 - val_f1: 0.9998
Epoch 130/300
 - 23s - loss: 4.3280e-04 - val_loss: 4.0081e-04
 - val_f1: 0.9998
Epoch 131/300
 - 23s - loss: 4.4470e-04 - val_loss: 3.9892e-04
 - val_f1: 0.9998
Epoch 132/300
 - 23s - loss: 4.3434e-04 - val_loss: 4.0195e-04
 - val_f1: 0.9998
Epoch 133/300
 - 23s - loss: 4.5477e-04 - val_loss: 3.8903e-04
 - val_f1: 0.9998
Epoch 134/300
 - 23s - loss: 4.6051e-04 - val_loss: 3.9281e-04
 - val_f1: 0.9998
Epoch 135/300
 - 23s - loss: 4.4785e-04 - val_loss: 3.9669e-04
 - val_f1: 0.9998
Epoch 136/300
 - 23s - loss: 4.3371e-04 - val_loss: 4.0549e-04
 - val_f1: 0.9998
Epoch 137/300
 - 23s - loss: 4.4573e-04 - val_loss: 3.8359e-04
 - val_f1: 0.9998
Epoch 138/300
 - 23s - loss: 4.2555e-04 - val_loss: 3.9107e-04
 - val_f1: 0.9998
Epoch 139/300
 - 23s - loss: 4.4706e-04 - val_loss: 3.8924e-04
 - val_f1: 0.9998
Epoch 140/300
 - 23s - loss: 4.4203e-04 - val_loss: 4.0807e-04
 - val_f1: 0.9998
Epoch 141/300
 - 23s - loss: 4.3373e-04 - val_loss: 3.9579e-04
 - val_f1: 0.9998
Epoch 142/300
 - 23s - loss: 4.2033e-04 - val_loss: 3.9243e-04
 - val_f1: 0.9998
Epoch 143/300
 - 23s - loss: 4.3365e-04 - val_loss: 4.0387e-04
 - val_f1: 0.9998
Epoch 144/300
 - 23s - loss: 4.2790e-04 - val_loss: 6.4464e-04
 - val_f1: 0.9994
Epoch 145/300
 - 23s - loss: 4.3331e-04 - val_loss: 3.7502e-04
 - val_f1: 0.9998
Epoch 146/300
 - 23s - loss: 4.2858e-04 - val_loss: 3.8186e-04
 - val_f1: 0.9998
Epoch 147/300
 - 23s - loss: 4.3063e-04 - val_loss: 3.9496e-04
 - val_f1: 0.9998
Epoch 148/300
 - 23s - loss: 4.3387e-04 - val_loss: 3.8505e-04
 - val_f1: 0.9998
Epoch 149/300
 - 23s - loss: 4.4323e-04 - val_loss: 3.7597e-04
 - val_f1: 0.9998
Epoch 150/300
 - 23s - loss: 4.3271e-04 - val_loss: 3.7037e-04
 - val_f1: 0.9998
Epoch 151/300
 - 23s - loss: 4.3254e-04 - val_loss: 3.7103e-04
2019-12-29 14:52:00,827 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 23s - loss: 4.2598e-04 - val_loss: 3.7961e-04
 - val_f1: 0.9998
Epoch 153/300
 - 23s - loss: 4.4044e-04 - val_loss: 3.7145e-04
 - val_f1: 0.9998
Epoch 154/300
 - 23s - loss: 4.2958e-04 - val_loss: 3.6431e-04
 - val_f1: 0.9998
Epoch 155/300
 - 23s - loss: 4.3060e-04 - val_loss: 3.5861e-04
 - val_f1: 0.9998
Epoch 156/300
 - 23s - loss: 4.2881e-04 - val_loss: 3.5941e-04
 - val_f1: 0.9998
Epoch 157/300
 - 23s - loss: 4.2130e-04 - val_loss: 3.7215e-04
 - val_f1: 0.9998
Epoch 158/300
 - 23s - loss: 4.1318e-04 - val_loss: 3.7980e-04
 - val_f1: 0.9998
Epoch 159/300
 - 23s - loss: 4.1936e-04 - val_loss: 3.7765e-04
 - val_f1: 0.9998
Epoch 160/300
 - 23s - loss: 4.1115e-04 - val_loss: 3.6852e-04
 - val_f1: 0.9998
Epoch 161/300
 - 23s - loss: 4.3505e-04 - val_loss: 3.7144e-04
 - val_f1: 0.9998
Epoch 162/300
 - 23s - loss: 4.2377e-04 - val_loss: 3.7108e-04
 - val_f1: 0.9998
Epoch 163/300
 - 23s - loss: 4.2628e-04 - val_loss: 3.5639e-04
 - val_f1: 0.9998
Epoch 164/300
 - 23s - loss: 4.1166e-04 - val_loss: 4.3448e-04
 - val_f1: 0.9998
Epoch 165/300
 - 23s - loss: 3.9845e-04 - val_loss: 3.7089e-04
 - val_f1: 0.9998
Epoch 166/300
 - 23s - loss: 4.1324e-04 - val_loss: 3.8604e-04
 - val_f1: 0.9998
Epoch 167/300
 - 23s - loss: 4.2920e-04 - val_loss: 3.7426e-04
 - val_f1: 0.9998
Epoch 168/300
 - 23s - loss: 4.1684e-04 - val_loss: 3.5851e-04
 - val_f1: 0.9998
Epoch 169/300
 - 23s - loss: 4.1057e-04 - val_loss: 3.6078e-04
 - val_f1: 0.9998
Epoch 170/300
 - 23s - loss: 4.0951e-04 - val_loss: 3.6003e-04
 - val_f1: 0.9998
Epoch 171/300
 - 23s - loss: 4.1553e-04 - val_loss: 3.5938e-04
 - val_f1: 0.9998
Epoch 172/300
 - 23s - loss: 4.0888e-04 - val_loss: 3.9272e-04
 - val_f1: 0.9998
Epoch 173/300
 - 23s - loss: 4.2794e-04 - val_loss: 3.5964e-04
 - val_f1: 0.9998
Epoch 174/300
 - 23s - loss: 4.1090e-04 - val_loss: 3.6384e-04
 - val_f1: 0.9998
Epoch 175/300
 - 23s - loss: 4.0652e-04 - val_loss: 3.7779e-04
 - val_f1: 0.9998
Epoch 176/300
 - 23s - loss: 3.8661e-04 - val_loss: 3.8127e-04
 - val_f1: 0.9998
Epoch 177/300
 - 23s - loss: 4.0219e-04 - val_loss: 4.1831e-04
 - val_f1: 0.9997
Epoch 178/300
 - 23s - loss: 3.8883e-04 - val_loss: 3.6206e-04
 - val_f1: 0.9998
Epoch 179/300
 - 23s - loss: 4.0785e-04 - val_loss: 3.7877e-04
 - val_f1: 0.9998
Epoch 180/300
 - 23s - loss: 4.1713e-04 - val_loss: 4.3972e-04
 - val_f1: 0.9997
Epoch 181/300
 - 23s - loss: 3.9037e-04 - val_loss: 3.6110e-04
2019-12-29 15:11:31,455 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 23s - loss: 3.9895e-04 - val_loss: 3.6036e-04
 - val_f1: 0.9998
Epoch 183/300
 - 23s - loss: 3.8419e-04 - val_loss: 3.5433e-04
 - val_f1: 0.9998
Epoch 184/300
 - 23s - loss: 4.1783e-04 - val_loss: 3.5933e-04
 - val_f1: 0.9998
Epoch 185/300
 - 23s - loss: 3.9984e-04 - val_loss: 3.5648e-04
 - val_f1: 0.9998
Epoch 186/300
 - 23s - loss: 4.0168e-04 - val_loss: 3.6824e-04
 - val_f1: 0.9998
Epoch 187/300
 - 23s - loss: 3.9045e-04 - val_loss: 3.7193e-04
 - val_f1: 0.9998
Epoch 188/300
 - 23s - loss: 3.8851e-04 - val_loss: 3.5617e-04
 - val_f1: 0.9998
Epoch 189/300
 - 23s - loss: 3.8481e-04 - val_loss: 3.6768e-04
 - val_f1: 0.9998
Epoch 190/300
 - 23s - loss: 3.9496e-04 - val_loss: 3.4913e-04
 - val_f1: 0.9998
Epoch 191/300
 - 23s - loss: 3.9755e-04 - val_loss: 4.5194e-04
 - val_f1: 0.9997
Epoch 192/300
 - 23s - loss: 3.8331e-04 - val_loss: 3.6414e-04
 - val_f1: 0.9998
Epoch 193/300
 - 23s - loss: 3.9939e-04 - val_loss: 3.6142e-04
 - val_f1: 0.9998
Epoch 194/300
 - 23s - loss: 3.8525e-04 - val_loss: 3.5752e-04
 - val_f1: 0.9998
Epoch 195/300
 - 23s - loss: 3.9436e-04 - val_loss: 3.6316e-04
 - val_f1: 0.9998
Epoch 196/300
 - 23s - loss: 3.8072e-04 - val_loss: 4.3876e-04
 - val_f1: 0.9998
Epoch 197/300
 - 23s - loss: 3.8597e-04 - val_loss: 4.8912e-04
 - val_f1: 0.9997
Epoch 198/300
 - 23s - loss: 3.8812e-04 - val_loss: 3.6065e-04
 - val_f1: 0.9998
Epoch 199/300
 - 23s - loss: 3.7932e-04 - val_loss: 3.5306e-04
 - val_f1: 0.9998
Epoch 200/300
 - 23s - loss: 4.0458e-04 - val_loss: 3.6062e-04
 - val_f1: 0.9998
Epoch 201/300
 - 23s - loss: 3.8363e-04 - val_loss: 3.7773e-04
 - val_f1: 0.9998
Epoch 202/300
 - 23s - loss: 3.8978e-04 - val_loss: 3.8795e-04
 - val_f1: 0.9998
Epoch 203/300
 - 23s - loss: 3.9669e-04 - val_loss: 3.5284e-04
 - val_f1: 0.9998
Epoch 204/300
 - 23s - loss: 3.9620e-04 - val_loss: 3.6558e-04
 - val_f1: 0.9998
Epoch 205/300
 - 23s - loss: 3.8688e-04 - val_loss: 3.5046e-04
 - val_f1: 0.9998
Epoch 206/300
 - 23s - loss: 3.7980e-04 - val_loss: 3.4438e-04
 - val_f1: 0.9998
Epoch 207/300
 - 23s - loss: 3.7983e-04 - val_loss: 3.4311e-04
 - val_f1: 0.9998
Epoch 208/300
 - 23s - loss: 3.7129e-04 - val_loss: 3.6861e-04
 - val_f1: 0.9998
Epoch 209/300
 - 23s - loss: 3.9322e-04 - val_loss: 3.5033e-04
 - val_f1: 0.9998
Epoch 210/300
 - 23s - loss: 3.8249e-04 - val_loss: 3.6074e-04
 - val_f1: 0.9998
Epoch 211/300
 - 23s - loss: 3.8786e-04 - val_loss: 3.6599e-04
2019-12-29 15:31:01,761 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 23s - loss: 4.0742e-04 - val_loss: 3.5770e-04
 - val_f1: 0.9998
Epoch 213/300
 - 23s - loss: 3.7218e-04 - val_loss: 3.6079e-04
 - val_f1: 0.9998
Epoch 214/300
 - 23s - loss: 3.7593e-04 - val_loss: 4.3229e-04
 - val_f1: 0.9997
Epoch 215/300
 - 23s - loss: 3.8218e-04 - val_loss: 4.1514e-04
 - val_f1: 0.9998
Epoch 216/300
 - 23s - loss: 3.7078e-04 - val_loss: 3.4991e-04
 - val_f1: 0.9998
Epoch 217/300
 - 23s - loss: 3.8521e-04 - val_loss: 3.6744e-04
 - val_f1: 0.9998
Epoch 218/300
 - 23s - loss: 3.8404e-04 - val_loss: 3.6140e-04
 - val_f1: 0.9998
Epoch 219/300
 - 23s - loss: 3.8277e-04 - val_loss: 4.9136e-04
 - val_f1: 0.9997
Epoch 220/300
 - 23s - loss: 3.7858e-04 - val_loss: 3.5550e-04
 - val_f1: 0.9998
Epoch 221/300
 - 23s - loss: 3.7243e-04 - val_loss: 3.4826e-04
 - val_f1: 0.9998
Epoch 222/300
 - 23s - loss: 3.9454e-04 - val_loss: 3.5691e-04
 - val_f1: 0.9998
Epoch 223/300
 - 23s - loss: 3.6599e-04 - val_loss: 3.8669e-04
 - val_f1: 0.9998
Epoch 224/300
 - 23s - loss: 3.8016e-04 - val_loss: 3.8839e-04
 - val_f1: 0.9998
Epoch 225/300
 - 23s - loss: 3.7448e-04 - val_loss: 3.8678e-04
 - val_f1: 0.9998
Epoch 226/300
 - 23s - loss: 3.7128e-04 - val_loss: 3.6044e-04
 - val_f1: 0.9998
Epoch 227/300
 - 23s - loss: 3.7030e-04 - val_loss: 4.4566e-04
 - val_f1: 0.9997
Epoch 228/300
 - 23s - loss: 3.6875e-04 - val_loss: 3.7959e-04
 - val_f1: 0.9998
Epoch 229/300
 - 23s - loss: 3.6194e-04 - val_loss: 3.6661e-04
 - val_f1: 0.9998
Epoch 230/300
 - 23s - loss: 3.5960e-04 - val_loss: 3.5278e-04
 - val_f1: 0.9998
Epoch 231/300
 - 23s - loss: 3.7477e-04 - val_loss: 3.5506e-04
 - val_f1: 0.9998
Epoch 232/300
 - 23s - loss: 3.8567e-04 - val_loss: 3.6735e-04
 - val_f1: 0.9998
Epoch 233/300
 - 23s - loss: 3.7565e-04 - val_loss: 3.6824e-04
 - val_f1: 0.9998
Epoch 234/300
 - 23s - loss: 3.8090e-04 - val_loss: 3.8221e-04
 - val_f1: 0.9998
Epoch 235/300
 - 23s - loss: 3.7487e-04 - val_loss: 3.6125e-04
 - val_f1: 0.9998
Epoch 236/300
 - 23s - loss: 3.6582e-04 - val_loss: 3.9029e-04
 - val_f1: 0.9998
Epoch 237/300
 - 23s - loss: 3.6294e-04 - val_loss: 3.8552e-04
 - val_f1: 0.9998
Epoch 238/300
 - 23s - loss: 3.6018e-04 - val_loss: 3.7365e-04
 - val_f1: 0.9998
Epoch 239/300
 - 23s - loss: 3.7631e-04 - val_loss: 3.7362e-04
 - val_f1: 0.9998
Epoch 240/300
 - 23s - loss: 3.8600e-04 - val_loss: 3.8317e-04
 - val_f1: 0.9998
Epoch 241/300
 - 23s - loss: 3.5883e-04 - val_loss: 3.7235e-04
2019-12-29 15:50:31,510 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 23s - loss: 3.6932e-04 - val_loss: 8.5970e-04
 - val_f1: 0.9993
Epoch 243/300
 - 23s - loss: 3.6340e-04 - val_loss: 3.7412e-04
 - val_f1: 0.9998
Epoch 244/300
 - 23s - loss: 3.6360e-04 - val_loss: 3.6507e-04
 - val_f1: 0.9998
Epoch 245/300
 - 23s - loss: 3.6470e-04 - val_loss: 3.6409e-04
 - val_f1: 0.9998
Epoch 246/300
 - 23s - loss: 3.6583e-04 - val_loss: 3.7571e-04
 - val_f1: 0.9998
Epoch 247/300
 - 23s - loss: 3.6357e-04 - val_loss: 3.6210e-04
 - val_f1: 0.9998
Epoch 248/300
 - 23s - loss: 3.4635e-04 - val_loss: 3.6202e-04
 - val_f1: 0.9998
Epoch 249/300
 - 23s - loss: 3.6440e-04 - val_loss: 3.7136e-04
 - val_f1: 0.9998
Epoch 250/300
 - 23s - loss: 3.5180e-04 - val_loss: 3.5675e-04
 - val_f1: 0.9998
Epoch 251/300
 - 23s - loss: 3.6687e-04 - val_loss: 3.5261e-04
 - val_f1: 0.9998
Epoch 252/300
 - 23s - loss: 3.7042e-04 - val_loss: 3.5746e-04
 - val_f1: 0.9998
Epoch 253/300
 - 23s - loss: 3.4939e-04 - val_loss: 3.8606e-04
 - val_f1: 0.9998
Epoch 254/300
 - 23s - loss: 3.5204e-04 - val_loss: 3.7848e-04
 - val_f1: 0.9998
Epoch 255/300
 - 23s - loss: 3.6961e-04 - val_loss: 3.8632e-04
 - val_f1: 0.9998
Epoch 256/300
 - 23s - loss: 3.6552e-04 - val_loss: 3.7653e-04
 - val_f1: 0.9998
Epoch 257/300
 - 23s - loss: 3.5502e-04 - val_loss: 3.8201e-04
2019-12-29 16:01:10,824 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-29 16:02:06,461 [INFO] Last epoch loss evaluation: train_loss = 0.000230, val_loss = 0.000343
2019-12-29 16:02:06,475 [INFO] Training complete. time_to_train = 11358.94 sec, 189.32 min
2019-12-29 16:02:06,479 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_shallow_rep2/best_model.pickle
2019-12-29 16:02:06,483 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_shallow_rep2/training_error_history.csv
2019-12-29 16:02:06,666 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep2/training_error_history.png
2019-12-29 16:02:06,827 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep2/training_f1_history.png
2019-12-29 16:02:06,828 [INFO] Making predictions on training, validation, testing data
2019-12-29 16:03:25,709 [INFO] Evaluating predictions (results)
2019-12-29 16:03:34,416 [INFO] Dataset: Testing. Classification report below
2019-12-29 16:03:34,417 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.72      0.98      0.83     60593
       probe       0.77      0.81      0.79      4166
         r2l       0.98      0.03      0.05     13781
         u2r       0.83      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.86      0.56      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-29 16:03:34,417 [INFO] Overall accuracy (micro avg): 0.9221648142134656
2019-12-29 16:03:43,742 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9222         0.9222                       0.9222                0.0195                   0.0778  0.9222
1     Macro avg        0.9689         0.8607                       0.5597                0.0196                   0.4403  0.5341
2  Weighted avg        0.9672         0.9396                       0.9222                0.0203                   0.0778  0.9034
2019-12-29 16:04:14,038 [INFO] Dataset: Validation. Classification report below
2019-12-29 16:04:14,039 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      0.99      8221
         r2l       0.92      0.80      0.86       225
         u2r       0.60      0.30      0.40        10

    accuracy                           1.00    979687
   macro avg       0.90      0.82      0.85    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-29 16:04:14,039 [INFO] Overall accuracy (micro avg): 0.9998111641779466
2019-12-29 16:04:46,716 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9027                       0.8188                0.0001                   0.1812  0.8499
2  Weighted avg        0.9999         0.9998                       0.9998                0.0002                   0.0002  0.9998
2019-12-29 16:06:59,602 [INFO] Dataset: Training. Classification report below
2019-12-29 16:06:59,602 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.93      0.84      0.88       901
         u2r       0.83      0.57      0.68        42

    accuracy                           1.00   3918744
   macro avg       0.95      0.88      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-29 16:06:59,602 [INFO] Overall accuracy (micro avg): 0.999839489387416
2019-12-29 16:09:23,043 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9500                       0.8810                0.0001                   0.1190  0.9104
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-29 16:09:23,090 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_shallow_rep2/selected_kdd99_dbn_shallow_rep2_results.xlsx
2019-12-29 16:09:23,097 [INFO] ================= Finished running experiment no. 2 ================= 

2019-12-29 16:09:23,121 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_shallow_rep3
2019-12-29 16:09:23,121 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_shallow_rep3/run_log.log
2019-12-29 16:09:23,121 [INFO] ================= Running experiment no. 3  ================= 

2019-12-29 16:09:23,122 [INFO] Experiment parameters given below
2019-12-29 16:09:23,122 [INFO] 
{'experiment_num': 3, 'results_dir': 'results_selected_models/selected_kdd99_dbn_shallow_rep3', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_shallow_rep3'}
2019-12-29 16:09:23,122 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_shallow_rep3/tf_logs_run_2019_12_29-16_09_23
2019-12-29 16:09:23,122 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-29 16:09:23,122 [INFO] Reading X, y files
2019-12-29 16:09:23,122 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-29 16:09:29,533 [INFO] Reading complete. time_to_read=6.41 seconds
2019-12-29 16:09:29,533 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-29 16:09:31,148 [INFO] Reading complete. time_to_read=1.61 seconds
2019-12-29 16:09:31,148 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-29 16:09:31,610 [INFO] Reading complete. time_to_read=0.46 seconds
2019-12-29 16:09:31,610 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-29 16:09:31,818 [INFO] Reading complete. time_to_read=0.21 seconds
2019-12-29 16:09:31,818 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-29 16:09:31,874 [INFO] Reading complete. time_to_read=0.06 seconds
2019-12-29 16:09:31,874 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-29 16:09:31,894 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-29 16:09:39,064 [INFO] Initializing model
2019-12-29 16:09:39,065 [INFO] Training model
2019-12-29 16:09:39,065 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-29 16:10:19,806 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = ec32ff04d5e193355f8ef193f3b169950433de0c
2019-12-29 16:10:19,806 [INFO] Pretraining Deep Belief Network
2019-12-29 16:30:53,043 [INFO] Pretraining Complete
2019-12-29 16:30:53,043 [INFO] Getting pretrained weights
2019-12-29 16:30:53,044 [INFO] Creating and initializing feed forward neural network
2019-12-29 16:30:53,164 [INFO] _________________________________________________________________
2019-12-29 16:30:53,164 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-29 16:30:53,164 [INFO] =================================================================
2019-12-29 16:30:53,165 [INFO] dense_5 (Dense)              (None, 32)                3968      
2019-12-29 16:30:53,165 [INFO] _________________________________________________________________
2019-12-29 16:30:53,165 [INFO] batch_normalization_3 (Batch (None, 32)                128       
2019-12-29 16:30:53,165 [INFO] _________________________________________________________________
2019-12-29 16:30:53,165 [INFO] dropout_3 (Dropout)          (None, 32)                0         
2019-12-29 16:30:53,165 [INFO] _________________________________________________________________
2019-12-29 16:30:53,165 [INFO] dense_6 (Dense)              (None, 5)                 165       
2019-12-29 16:30:53,165 [INFO] =================================================================
2019-12-29 16:30:53,165 [INFO] Total params: 4,261
2019-12-29 16:30:53,165 [INFO] Trainable params: 4,197
2019-12-29 16:30:53,166 [INFO] Non-trainable params: 64
2019-12-29 16:30:53,166 [INFO] _________________________________________________________________
2019-12-29 16:30:53,350 [INFO] Fine-tuning final neural network
 - val_f1: 0.9998
Epoch 00257: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.24, time = 16.54s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -33.99, time = 25.53s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.10, time = 25.40s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.35, time = 25.37s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.25, time = 25.36s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -37.94, time = 25.31s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -40.55, time = 25.28s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -42.78, time = 25.13s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -44.83, time = 25.12s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -46.86, time = 25.10s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -48.89, time = 25.07s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -50.84, time = 25.05s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -52.81, time = 25.01s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -54.70, time = 24.97s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -56.56, time = 24.96s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -58.52, time = 24.68s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -60.52, time = 24.58s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -62.61, time = 24.58s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -64.82, time = 24.56s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -67.01, time = 24.57s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -69.18, time = 24.56s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -71.51, time = 24.55s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -73.74, time = 24.53s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -76.06, time = 24.52s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -78.32, time = 24.53s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -80.64, time = 24.50s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -82.98, time = 24.48s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -85.26, time = 24.46s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -87.66, time = 24.41s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -89.93, time = 24.42s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -92.29, time = 24.43s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -94.62, time = 24.44s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -96.96, time = 24.43s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -99.30, time = 24.43s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -101.63, time = 24.42s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -103.92, time = 24.40s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -106.32, time = 24.42s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -108.64, time = 24.42s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -110.96, time = 24.40s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -113.34, time = 24.41s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -115.57, time = 24.41s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -117.86, time = 24.40s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -120.29, time = 24.38s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -122.57, time = 24.39s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -124.86, time = 24.40s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -127.16, time = 24.40s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -129.56, time = 24.40s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -131.83, time = 24.38s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -134.15, time = 24.40s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -136.47, time = 24.38s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/300
 - 24s - loss: 0.0351 - val_loss: 0.0042
 - val_f1: 0.9977
Epoch 2/300
 - 24s - loss: 0.0047 - val_loss: 0.0025
 - val_f1: 0.9983
Epoch 3/300
 - 24s - loss: 0.0031 - val_loss: 0.0017
 - val_f1: 0.9989
Epoch 4/300
 - 24s - loss: 0.0023 - val_loss: 0.0013
 - val_f1: 0.9992
Epoch 5/300
 - 24s - loss: 0.0020 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 6/300
 - 24s - loss: 0.0018 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 7/300
 - 24s - loss: 0.0016 - val_loss: 9.7975e-04
 - val_f1: 0.9994
Epoch 8/300
 - 24s - loss: 0.0015 - val_loss: 8.9382e-04
 - val_f1: 0.9994
Epoch 9/300
 - 24s - loss: 0.0014 - val_loss: 8.4319e-04
 - val_f1: 0.9995
Epoch 10/300
 - 24s - loss: 0.0014 - val_loss: 8.3921e-04
 - val_f1: 0.9995
Epoch 11/300
 - 24s - loss: 0.0013 - val_loss: 8.0123e-04
 - val_f1: 0.9996
Epoch 12/300
 - 23s - loss: 0.0012 - val_loss: 7.9428e-04
 - val_f1: 0.9996
Epoch 13/300
 - 24s - loss: 0.0012 - val_loss: 7.5494e-04
 - val_f1: 0.9996
Epoch 14/300
 - 23s - loss: 0.0012 - val_loss: 7.5349e-04
 - val_f1: 0.9996
Epoch 15/300
 - 23s - loss: 0.0011 - val_loss: 7.4691e-04
 - val_f1: 0.9996
Epoch 16/300
 - 24s - loss: 0.0011 - val_loss: 7.2973e-04
 - val_f1: 0.9996
Epoch 17/300
 - 24s - loss: 0.0011 - val_loss: 6.9473e-04
 - val_f1: 0.9996
Epoch 18/300
 - 23s - loss: 0.0010 - val_loss: 7.0707e-04
 - val_f1: 0.9996
Epoch 19/300
 - 24s - loss: 0.0010 - val_loss: 6.8038e-04
 - val_f1: 0.9997
Epoch 20/300
 - 24s - loss: 9.7338e-04 - val_loss: 6.7261e-04
 - val_f1: 0.9997
Epoch 21/300
 - 23s - loss: 9.1510e-04 - val_loss: 6.7526e-04
 - val_f1: 0.9996
Epoch 22/300
 - 24s - loss: 9.0875e-04 - val_loss: 6.7210e-04
 - val_f1: 0.9997
Epoch 23/300
 - 24s - loss: 8.5784e-04 - val_loss: 6.3159e-04
 - val_f1: 0.9997
Epoch 24/300
 - 24s - loss: 8.2642e-04 - val_loss: 6.2987e-04
 - val_f1: 0.9997
Epoch 25/300
 - 23s - loss: 8.4495e-04 - val_loss: 6.3528e-04
 - val_f1: 0.9996
Epoch 26/300
 - 24s - loss: 8.1695e-04 - val_loss: 6.1720e-04
 - val_f1: 0.9997
Epoch 27/300
 - 24s - loss: 7.8873e-04 - val_loss: 6.0061e-04
 - val_f1: 0.9997
Epoch 28/300
 - 23s - loss: 7.8798e-04 - val_loss: 5.9374e-04
 - val_f1: 0.9997
Epoch 29/300
 - 24s - loss: 7.6654e-04 - val_loss: 5.8056e-04
 - val_f1: 0.9997
Epoch 30/300
 - 23s - loss: 7.6923e-04 - val_loss: 5.8443e-04
 - val_f1: 0.9997
Epoch 31/300
 - 24s - loss: 7.5211e-04 - val_loss: 5.6156e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-29 16:51:24,505 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_30.pickle
 - val_f1: 0.9997
Epoch 32/300
 - 24s - loss: 7.4641e-04 - val_loss: 5.6663e-04
 - val_f1: 0.9997
Epoch 33/300
 - 24s - loss: 7.3836e-04 - val_loss: 5.5172e-04
 - val_f1: 0.9997
Epoch 34/300
 - 24s - loss: 7.0735e-04 - val_loss: 5.3212e-04
 - val_f1: 0.9997
Epoch 35/300
 - 24s - loss: 6.9394e-04 - val_loss: 5.5851e-04
 - val_f1: 0.9997
Epoch 36/300
 - 24s - loss: 7.2327e-04 - val_loss: 5.1321e-04
 - val_f1: 0.9997
Epoch 37/300
 - 24s - loss: 7.1223e-04 - val_loss: 5.3203e-04
 - val_f1: 0.9997
Epoch 38/300
 - 24s - loss: 6.6645e-04 - val_loss: 5.1904e-04
 - val_f1: 0.9997
Epoch 39/300
 - 24s - loss: 6.9232e-04 - val_loss: 5.2051e-04
 - val_f1: 0.9997
Epoch 40/300
 - 24s - loss: 6.6767e-04 - val_loss: 5.0916e-04
 - val_f1: 0.9997
Epoch 41/300
 - 24s - loss: 6.8339e-04 - val_loss: 5.1868e-04
 - val_f1: 0.9997
Epoch 42/300
 - 24s - loss: 6.7775e-04 - val_loss: 4.9106e-04
 - val_f1: 0.9997
Epoch 43/300
 - 24s - loss: 6.8237e-04 - val_loss: 5.1015e-04
 - val_f1: 0.9997
Epoch 44/300
 - 24s - loss: 6.4604e-04 - val_loss: 4.9765e-04
 - val_f1: 0.9997
Epoch 45/300
 - 24s - loss: 6.6242e-04 - val_loss: 4.9713e-04
 - val_f1: 0.9997
Epoch 46/300
 - 24s - loss: 6.4224e-04 - val_loss: 4.8905e-04
 - val_f1: 0.9997
Epoch 47/300
 - 24s - loss: 6.4295e-04 - val_loss: 4.8234e-04
 - val_f1: 0.9997
Epoch 48/300
 - 24s - loss: 6.3380e-04 - val_loss: 4.9650e-04
 - val_f1: 0.9997
Epoch 49/300
 - 24s - loss: 6.4649e-04 - val_loss: 4.9398e-04
 - val_f1: 0.9997
Epoch 50/300
 - 24s - loss: 6.2991e-04 - val_loss: 4.9107e-04
 - val_f1: 0.9997
Epoch 51/300
 - 24s - loss: 6.2381e-04 - val_loss: 5.0591e-04
 - val_f1: 0.9997
Epoch 52/300
 - 24s - loss: 6.2349e-04 - val_loss: 4.8250e-04
 - val_f1: 0.9997
Epoch 53/300
 - 24s - loss: 6.2872e-04 - val_loss: 5.1712e-04
 - val_f1: 0.9997
Epoch 54/300
 - 24s - loss: 6.2346e-04 - val_loss: 4.7252e-04
 - val_f1: 0.9997
Epoch 55/300
 - 24s - loss: 6.1855e-04 - val_loss: 4.7405e-04
 - val_f1: 0.9997
Epoch 56/300
 - 24s - loss: 6.1785e-04 - val_loss: 4.7580e-04
 - val_f1: 0.9997
Epoch 57/300
 - 24s - loss: 6.1559e-04 - val_loss: 4.8340e-04
 - val_f1: 0.9997
Epoch 58/300
 - 24s - loss: 6.1015e-04 - val_loss: 4.7493e-04
 - val_f1: 0.9997
Epoch 59/300
 - 24s - loss: 5.9831e-04 - val_loss: 4.7054e-04
 - val_f1: 0.9997
Epoch 60/300
 - 24s - loss: 6.1426e-04 - val_loss: 4.7054e-04
 - val_f1: 0.9997
Epoch 61/300
 - 24s - loss: 6.0399e-04 - val_loss: 4.7917e-04
2019-12-29 17:11:37,821 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/300
 - 24s - loss: 6.0026e-04 - val_loss: 4.7013e-04
 - val_f1: 0.9997
Epoch 63/300
 - 24s - loss: 6.1091e-04 - val_loss: 4.5345e-04
 - val_f1: 0.9997
Epoch 64/300
 - 24s - loss: 5.8917e-04 - val_loss: 4.6902e-04
 - val_f1: 0.9997
Epoch 65/300
 - 24s - loss: 5.7024e-04 - val_loss: 4.5884e-04
 - val_f1: 0.9997
Epoch 66/300
 - 24s - loss: 5.8420e-04 - val_loss: 4.5273e-04
 - val_f1: 0.9997
Epoch 67/300
 - 24s - loss: 5.8081e-04 - val_loss: 4.6816e-04
 - val_f1: 0.9997
Epoch 68/300
 - 24s - loss: 5.7483e-04 - val_loss: 4.5754e-04
 - val_f1: 0.9997
Epoch 69/300
 - 24s - loss: 5.6152e-04 - val_loss: 4.4782e-04
 - val_f1: 0.9998
Epoch 70/300
 - 24s - loss: 5.8333e-04 - val_loss: 4.4878e-04
 - val_f1: 0.9998
Epoch 71/300
 - 24s - loss: 5.8291e-04 - val_loss: 4.6625e-04
 - val_f1: 0.9997
Epoch 72/300
 - 24s - loss: 5.8440e-04 - val_loss: 4.4657e-04
 - val_f1: 0.9997
Epoch 73/300
 - 24s - loss: 5.6067e-04 - val_loss: 4.3996e-04
 - val_f1: 0.9997
Epoch 74/300
 - 24s - loss: 5.7312e-04 - val_loss: 4.4872e-04
 - val_f1: 0.9997
Epoch 75/300
 - 24s - loss: 5.5904e-04 - val_loss: 4.3804e-04
 - val_f1: 0.9998
Epoch 76/300
 - 24s - loss: 5.5910e-04 - val_loss: 4.4211e-04
 - val_f1: 0.9997
Epoch 77/300
 - 24s - loss: 5.5341e-04 - val_loss: 4.4871e-04
 - val_f1: 0.9998
Epoch 78/300
 - 24s - loss: 5.7598e-04 - val_loss: 4.9130e-04
 - val_f1: 0.9997
Epoch 79/300
 - 24s - loss: 5.7730e-04 - val_loss: 4.6072e-04
 - val_f1: 0.9997
Epoch 80/300
 - 24s - loss: 5.7242e-04 - val_loss: 4.5517e-04
 - val_f1: 0.9997
Epoch 81/300
 - 24s - loss: 5.9024e-04 - val_loss: 4.5721e-04
 - val_f1: 0.9997
Epoch 82/300
 - 24s - loss: 5.6008e-04 - val_loss: 4.3298e-04
 - val_f1: 0.9997
Epoch 83/300
 - 24s - loss: 5.5809e-04 - val_loss: 4.1752e-04
 - val_f1: 0.9998
Epoch 84/300
 - 24s - loss: 5.6063e-04 - val_loss: 4.3773e-04
 - val_f1: 0.9997
Epoch 85/300
 - 24s - loss: 5.4044e-04 - val_loss: 4.4832e-04
 - val_f1: 0.9997
Epoch 86/300
 - 24s - loss: 5.6649e-04 - val_loss: 4.4328e-04
 - val_f1: 0.9997
Epoch 87/300
 - 24s - loss: 5.4462e-04 - val_loss: 4.3197e-04
 - val_f1: 0.9998
Epoch 88/300
 - 24s - loss: 5.4062e-04 - val_loss: 4.4537e-04
 - val_f1: 0.9997
Epoch 89/300
 - 24s - loss: 5.4438e-04 - val_loss: 4.2534e-04
 - val_f1: 0.9998
Epoch 90/300
 - 24s - loss: 5.4694e-04 - val_loss: 4.2511e-04
 - val_f1: 0.9997
Epoch 91/300
 - 24s - loss: 5.6138e-04 - val_loss: 4.2402e-04
2019-12-29 17:31:51,259 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 24s - loss: 5.6179e-04 - val_loss: 4.4120e-04
 - val_f1: 0.9997
Epoch 93/300
 - 24s - loss: 5.3077e-04 - val_loss: 4.3431e-04
 - val_f1: 0.9998
Epoch 94/300
 - 24s - loss: 5.4534e-04 - val_loss: 4.3080e-04
 - val_f1: 0.9998
Epoch 95/300
 - 24s - loss: 5.5908e-04 - val_loss: 4.2613e-04
 - val_f1: 0.9998
Epoch 96/300
 - 24s - loss: 5.4439e-04 - val_loss: 4.3095e-04
 - val_f1: 0.9998
Epoch 97/300
 - 24s - loss: 5.4774e-04 - val_loss: 4.2297e-04
 - val_f1: 0.9998
Epoch 98/300
 - 24s - loss: 5.2122e-04 - val_loss: 4.1465e-04
 - val_f1: 0.9998
Epoch 99/300
 - 24s - loss: 5.3179e-04 - val_loss: 4.1811e-04
 - val_f1: 0.9998
Epoch 100/300
 - 24s - loss: 5.4120e-04 - val_loss: 4.3479e-04
 - val_f1: 0.9998
Epoch 101/300
 - 24s - loss: 5.3051e-04 - val_loss: 4.2359e-04
 - val_f1: 0.9998
Epoch 102/300
 - 24s - loss: 5.2011e-04 - val_loss: 4.1004e-04
 - val_f1: 0.9998
Epoch 103/300
 - 24s - loss: 5.1983e-04 - val_loss: 4.2469e-04
 - val_f1: 0.9998
Epoch 104/300
 - 24s - loss: 5.1191e-04 - val_loss: 4.2704e-04
 - val_f1: 0.9998
Epoch 105/300
 - 24s - loss: 5.1794e-04 - val_loss: 4.2338e-04
 - val_f1: 0.9998
Epoch 106/300
 - 24s - loss: 5.1716e-04 - val_loss: 4.2701e-04
 - val_f1: 0.9998
Epoch 107/300
 - 24s - loss: 5.1115e-04 - val_loss: 4.3121e-04
 - val_f1: 0.9998
Epoch 108/300
 - 24s - loss: 5.3041e-04 - val_loss: 4.2818e-04
 - val_f1: 0.9998
Epoch 109/300
 - 24s - loss: 5.2348e-04 - val_loss: 4.2302e-04
 - val_f1: 0.9998
Epoch 110/300
 - 24s - loss: 5.0059e-04 - val_loss: 4.1838e-04
 - val_f1: 0.9998
Epoch 111/300
 - 24s - loss: 4.9903e-04 - val_loss: 4.0492e-04
 - val_f1: 0.9998
Epoch 112/300
 - 24s - loss: 4.9416e-04 - val_loss: 4.3008e-04
 - val_f1: 0.9998
Epoch 113/300
 - 24s - loss: 4.8890e-04 - val_loss: 3.9744e-04
 - val_f1: 0.9998
Epoch 114/300
 - 24s - loss: 4.9813e-04 - val_loss: 4.1990e-04
 - val_f1: 0.9998
Epoch 115/300
 - 24s - loss: 4.9086e-04 - val_loss: 5.4770e-04
 - val_f1: 0.9995
Epoch 116/300
 - 24s - loss: 4.9811e-04 - val_loss: 4.7647e-04
 - val_f1: 0.9997
Epoch 117/300
 - 24s - loss: 4.8658e-04 - val_loss: 4.2192e-04
 - val_f1: 0.9998
Epoch 118/300
 - 24s - loss: 5.0060e-04 - val_loss: 3.9645e-04
 - val_f1: 0.9998
Epoch 119/300
 - 24s - loss: 4.7443e-04 - val_loss: 4.1460e-04
 - val_f1: 0.9998
Epoch 120/300
 - 24s - loss: 4.8892e-04 - val_loss: 4.2565e-04
 - val_f1: 0.9998
Epoch 121/300
 - 24s - loss: 4.9120e-04 - val_loss: 4.0818e-04
2019-12-29 17:52:04,260 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 24s - loss: 4.8675e-04 - val_loss: 4.2708e-04
 - val_f1: 0.9998
Epoch 123/300
 - 24s - loss: 4.7529e-04 - val_loss: 4.0261e-04
 - val_f1: 0.9998
Epoch 124/300
 - 24s - loss: 4.7786e-04 - val_loss: 4.0456e-04
 - val_f1: 0.9998
Epoch 125/300
 - 24s - loss: 4.6972e-04 - val_loss: 4.1976e-04
 - val_f1: 0.9997
Epoch 126/300
 - 24s - loss: 4.6614e-04 - val_loss: 3.8867e-04
 - val_f1: 0.9998
Epoch 127/300
 - 24s - loss: 4.7492e-04 - val_loss: 4.1057e-04
 - val_f1: 0.9998
Epoch 128/300
 - 24s - loss: 4.6069e-04 - val_loss: 3.9331e-04
 - val_f1: 0.9998
Epoch 129/300
 - 24s - loss: 4.8222e-04 - val_loss: 3.9979e-04
 - val_f1: 0.9998
Epoch 130/300
 - 24s - loss: 4.8306e-04 - val_loss: 4.1880e-04
 - val_f1: 0.9998
Epoch 131/300
 - 24s - loss: 4.7273e-04 - val_loss: 3.9601e-04
 - val_f1: 0.9998
Epoch 132/300
 - 24s - loss: 4.7706e-04 - val_loss: 4.8061e-04
 - val_f1: 0.9997
Epoch 133/300
 - 24s - loss: 4.5940e-04 - val_loss: 4.1663e-04
 - val_f1: 0.9998
Epoch 134/300
 - 24s - loss: 4.6913e-04 - val_loss: 4.0370e-04
 - val_f1: 0.9998
Epoch 135/300
 - 24s - loss: 4.6485e-04 - val_loss: 4.2122e-04
 - val_f1: 0.9998
Epoch 136/300
 - 24s - loss: 4.4758e-04 - val_loss: 4.0647e-04
 - val_f1: 0.9998
Epoch 137/300
 - 24s - loss: 4.5177e-04 - val_loss: 4.2479e-04
 - val_f1: 0.9998
Epoch 138/300
 - 24s - loss: 4.5503e-04 - val_loss: 4.1695e-04
 - val_f1: 0.9998
Epoch 139/300
 - 24s - loss: 4.7037e-04 - val_loss: 4.1854e-04
 - val_f1: 0.9998
Epoch 140/300
 - 24s - loss: 4.5058e-04 - val_loss: 4.1886e-04
 - val_f1: 0.9998
Epoch 141/300
 - 24s - loss: 4.6999e-04 - val_loss: 4.2508e-04
 - val_f1: 0.9998
Epoch 142/300
 - 24s - loss: 4.3849e-04 - val_loss: 4.2512e-04
 - val_f1: 0.9998
Epoch 143/300
 - 24s - loss: 4.5580e-04 - val_loss: 4.3280e-04
 - val_f1: 0.9998
Epoch 144/300
 - 24s - loss: 4.5183e-04 - val_loss: 4.0471e-04
 - val_f1: 0.9998
Epoch 145/300
 - 24s - loss: 4.5801e-04 - val_loss: 4.2759e-04
 - val_f1: 0.9998
Epoch 146/300
 - 24s - loss: 4.4178e-04 - val_loss: 4.6759e-04
 - val_f1: 0.9997
Epoch 147/300
 - 24s - loss: 4.5262e-04 - val_loss: 4.1299e-04
 - val_f1: 0.9998
Epoch 148/300
 - 24s - loss: 4.6251e-04 - val_loss: 4.1362e-04
 - val_f1: 0.9998
Epoch 149/300
 - 24s - loss: 4.3095e-04 - val_loss: 4.1704e-04
 - val_f1: 0.9998
Epoch 150/300
 - 24s - loss: 4.4245e-04 - val_loss: 4.0848e-04
 - val_f1: 0.9998
Epoch 151/300
 - 24s - loss: 4.4852e-04 - val_loss: 3.9579e-04
2019-12-29 18:12:17,216 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 24s - loss: 4.3582e-04 - val_loss: 5.3210e-04
 - val_f1: 0.9997
Epoch 153/300
 - 24s - loss: 4.5100e-04 - val_loss: 3.9961e-04
 - val_f1: 0.9998
Epoch 154/300
 - 24s - loss: 4.3530e-04 - val_loss: 3.9658e-04
 - val_f1: 0.9998
Epoch 155/300
 - 24s - loss: 4.4802e-04 - val_loss: 4.1109e-04
 - val_f1: 0.9998
Epoch 156/300
 - 24s - loss: 4.2628e-04 - val_loss: 4.1171e-04
 - val_f1: 0.9998
Epoch 157/300
 - 24s - loss: 4.3191e-04 - val_loss: 5.6885e-04
 - val_f1: 0.9995
Epoch 158/300
 - 24s - loss: 4.4441e-04 - val_loss: 4.9035e-04
 - val_f1: 0.9997
Epoch 159/300
 - 24s - loss: 4.4134e-04 - val_loss: 3.8730e-04
 - val_f1: 0.9998
Epoch 160/300
 - 24s - loss: 4.2985e-04 - val_loss: 3.8424e-04
 - val_f1: 0.9998
Epoch 161/300
 - 24s - loss: 4.2892e-04 - val_loss: 3.8258e-04
 - val_f1: 0.9998
Epoch 162/300
 - 24s - loss: 4.2771e-04 - val_loss: 3.8689e-04
 - val_f1: 0.9998
Epoch 163/300
 - 24s - loss: 4.3454e-04 - val_loss: 3.8516e-04
 - val_f1: 0.9998
Epoch 164/300
 - 24s - loss: 4.2454e-04 - val_loss: 3.8085e-04
 - val_f1: 0.9998
Epoch 165/300
 - 24s - loss: 4.3532e-04 - val_loss: 3.8443e-04
 - val_f1: 0.9998
Epoch 166/300
 - 24s - loss: 4.2512e-04 - val_loss: 4.0479e-04
 - val_f1: 0.9998
Epoch 167/300
 - 24s - loss: 4.2992e-04 - val_loss: 3.7602e-04
 - val_f1: 0.9998
Epoch 168/300
 - 24s - loss: 4.3426e-04 - val_loss: 3.8845e-04
 - val_f1: 0.9998
Epoch 169/300
 - 24s - loss: 4.3411e-04 - val_loss: 3.9127e-04
 - val_f1: 0.9998
Epoch 170/300
 - 24s - loss: 4.1708e-04 - val_loss: 3.9241e-04
 - val_f1: 0.9998
Epoch 171/300
 - 24s - loss: 4.2884e-04 - val_loss: 3.8609e-04
 - val_f1: 0.9998
Epoch 172/300
 - 24s - loss: 4.2230e-04 - val_loss: 3.7371e-04
 - val_f1: 0.9998
Epoch 173/300
 - 24s - loss: 4.3004e-04 - val_loss: 3.8956e-04
 - val_f1: 0.9998
Epoch 174/300
 - 24s - loss: 4.2517e-04 - val_loss: 3.9150e-04
 - val_f1: 0.9998
Epoch 175/300
 - 24s - loss: 4.1945e-04 - val_loss: 3.9056e-04
 - val_f1: 0.9998
Epoch 176/300
 - 24s - loss: 4.2268e-04 - val_loss: 4.1812e-04
 - val_f1: 0.9998
Epoch 177/300
 - 24s - loss: 4.3718e-04 - val_loss: 3.9237e-04
 - val_f1: 0.9998
Epoch 178/300
 - 24s - loss: 4.2080e-04 - val_loss: 3.8182e-04
 - val_f1: 0.9998
Epoch 179/300
 - 24s - loss: 4.2758e-04 - val_loss: 3.9910e-04
 - val_f1: 0.9998
Epoch 180/300
 - 24s - loss: 4.1391e-04 - val_loss: 3.9098e-04
 - val_f1: 0.9998
Epoch 181/300
 - 24s - loss: 4.3923e-04 - val_loss: 3.9985e-04
2019-12-29 18:32:30,256 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 24s - loss: 3.9337e-04 - val_loss: 3.8557e-04
 - val_f1: 0.9998
Epoch 183/300
 - 23s - loss: 4.2476e-04 - val_loss: 3.8779e-04
 - val_f1: 0.9998
Epoch 184/300
 - 24s - loss: 4.2297e-04 - val_loss: 4.4675e-04
 - val_f1: 0.9997
Epoch 185/300
 - 24s - loss: 4.0858e-04 - val_loss: 3.7402e-04
 - val_f1: 0.9998
Epoch 186/300
 - 24s - loss: 4.2138e-04 - val_loss: 4.4109e-04
 - val_f1: 0.9998
Epoch 187/300
 - 24s - loss: 4.1550e-04 - val_loss: 3.8189e-04
 - val_f1: 0.9998
Epoch 188/300
 - 24s - loss: 4.1814e-04 - val_loss: 3.7730e-04
 - val_f1: 0.9998
Epoch 189/300
 - 24s - loss: 4.0433e-04 - val_loss: 3.9244e-04
 - val_f1: 0.9998
Epoch 190/300
 - 24s - loss: 4.0164e-04 - val_loss: 3.7258e-04
 - val_f1: 0.9998
Epoch 191/300
 - 24s - loss: 4.2070e-04 - val_loss: 3.7874e-04
 - val_f1: 0.9998
Epoch 192/300
 - 24s - loss: 4.0589e-04 - val_loss: 5.5474e-04
 - val_f1: 0.9996
Epoch 193/300
 - 24s - loss: 4.1526e-04 - val_loss: 3.8869e-04
 - val_f1: 0.9998
Epoch 194/300
 - 24s - loss: 3.9889e-04 - val_loss: 3.8979e-04
 - val_f1: 0.9998
Epoch 195/300
 - 24s - loss: 4.0557e-04 - val_loss: 3.9228e-04
 - val_f1: 0.9998
Epoch 196/300
 - 24s - loss: 4.2160e-04 - val_loss: 5.9068e-04
 - val_f1: 0.9996
Epoch 197/300
 - 23s - loss: 3.9818e-04 - val_loss: 3.9169e-04
 - val_f1: 0.9998
Epoch 198/300
 - 24s - loss: 3.9935e-04 - val_loss: 3.9499e-04
 - val_f1: 0.9998
Epoch 199/300
 - 24s - loss: 4.0736e-04 - val_loss: 3.8474e-04
 - val_f1: 0.9998
Epoch 200/300
 - 24s - loss: 4.0538e-04 - val_loss: 3.6595e-04
 - val_f1: 0.9998
Epoch 201/300
 - 24s - loss: 4.1951e-04 - val_loss: 3.8152e-04
 - val_f1: 0.9998
Epoch 202/300
 - 24s - loss: 4.0402e-04 - val_loss: 4.0374e-04
 - val_f1: 0.9998
Epoch 203/300
 - 24s - loss: 4.2089e-04 - val_loss: 3.9088e-04
 - val_f1: 0.9998
Epoch 204/300
 - 24s - loss: 4.0756e-04 - val_loss: 3.8253e-04
 - val_f1: 0.9998
Epoch 205/300
 - 24s - loss: 3.8991e-04 - val_loss: 3.8985e-04
 - val_f1: 0.9998
Epoch 206/300
 - 24s - loss: 3.9745e-04 - val_loss: 3.8092e-04
 - val_f1: 0.9998
Epoch 207/300
 - 24s - loss: 3.9014e-04 - val_loss: 3.7876e-04
 - val_f1: 0.9998
Epoch 208/300
 - 24s - loss: 4.0580e-04 - val_loss: 3.7715e-04
 - val_f1: 0.9998
Epoch 209/300
 - 24s - loss: 3.9819e-04 - val_loss: 3.9483e-04
 - val_f1: 0.9998
Epoch 210/300
 - 24s - loss: 4.0967e-04 - val_loss: 3.8437e-04
 - val_f1: 0.9998
Epoch 211/300
 - 24s - loss: 3.8570e-04 - val_loss: 3.9338e-04
2019-12-29 18:52:41,734 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 24s - loss: 3.9327e-04 - val_loss: 3.7633e-04
 - val_f1: 0.9998
Epoch 213/300
 - 24s - loss: 4.0969e-04 - val_loss: 3.8255e-04
 - val_f1: 0.9998
Epoch 214/300
 - 24s - loss: 4.0519e-04 - val_loss: 3.8049e-04
 - val_f1: 0.9998
Epoch 215/300
 - 24s - loss: 3.9698e-04 - val_loss: 3.9409e-04
 - val_f1: 0.9998
Epoch 216/300
 - 24s - loss: 3.9282e-04 - val_loss: 3.9254e-04
 - val_f1: 0.9998
Epoch 217/300
 - 24s - loss: 3.8430e-04 - val_loss: 3.7601e-04
 - val_f1: 0.9998
Epoch 218/300
 - 24s - loss: 3.9846e-04 - val_loss: 3.6742e-04
 - val_f1: 0.9998
Epoch 219/300
 - 24s - loss: 3.9468e-04 - val_loss: 3.7505e-04
 - val_f1: 0.9998
Epoch 220/300
 - 24s - loss: 4.1076e-04 - val_loss: 3.8774e-04
 - val_f1: 0.9998
Epoch 221/300
 - 24s - loss: 3.8958e-04 - val_loss: 3.9929e-04
 - val_f1: 0.9998
Epoch 222/300
 - 24s - loss: 3.9798e-04 - val_loss: 3.7523e-04
 - val_f1: 0.9998
Epoch 223/300
 - 24s - loss: 3.8709e-04 - val_loss: 3.7425e-04
 - val_f1: 0.9998
Epoch 224/300
 - 24s - loss: 3.9686e-04 - val_loss: 3.9318e-04
 - val_f1: 0.9998
Epoch 225/300
 - 24s - loss: 4.0543e-04 - val_loss: 3.6687e-04
 - val_f1: 0.9998
Epoch 226/300
 - 24s - loss: 4.0636e-04 - val_loss: 3.8901e-04
 - val_f1: 0.9998
Epoch 227/300
 - 24s - loss: 3.9779e-04 - val_loss: 3.8713e-04
 - val_f1: 0.9998
Epoch 228/300
 - 24s - loss: 4.0944e-04 - val_loss: 4.2324e-04
 - val_f1: 0.9998
Epoch 229/300
 - 24s - loss: 3.8462e-04 - val_loss: 3.6519e-04
 - val_f1: 0.9998
Epoch 230/300
 - 24s - loss: 3.8951e-04 - val_loss: 3.9439e-04
 - val_f1: 0.9998
Epoch 231/300
 - 24s - loss: 3.9700e-04 - val_loss: 3.9363e-04
 - val_f1: 0.9998
Epoch 232/300
 - 24s - loss: 3.8811e-04 - val_loss: 3.9204e-04
 - val_f1: 0.9998
Epoch 233/300
 - 24s - loss: 3.9242e-04 - val_loss: 4.1728e-04
 - val_f1: 0.9998
Epoch 234/300
 - 24s - loss: 3.8203e-04 - val_loss: 3.7888e-04
 - val_f1: 0.9998
Epoch 235/300
 - 24s - loss: 3.8878e-04 - val_loss: 3.7801e-04
 - val_f1: 0.9998
Epoch 236/300
 - 24s - loss: 3.7759e-04 - val_loss: 3.7775e-04
 - val_f1: 0.9998
Epoch 237/300
 - 24s - loss: 3.8150e-04 - val_loss: 3.8690e-04
 - val_f1: 0.9998
Epoch 238/300
 - 24s - loss: 3.8498e-04 - val_loss: 4.7237e-04
 - val_f1: 0.9996
Epoch 239/300
 - 24s - loss: 3.6795e-04 - val_loss: 4.9485e-04
 - val_f1: 0.9996
Epoch 240/300
 - 24s - loss: 3.7278e-04 - val_loss: 4.0147e-04
 - val_f1: 0.9998
Epoch 241/300
 - 24s - loss: 3.9251e-04 - val_loss: 3.7013e-04
2019-12-29 19:12:54,833 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 24s - loss: 3.7471e-04 - val_loss: 3.8055e-04
 - val_f1: 0.9998
Epoch 243/300
 - 24s - loss: 3.7434e-04 - val_loss: 3.6973e-04
 - val_f1: 0.9998
Epoch 244/300
 - 24s - loss: 3.6981e-04 - val_loss: 3.8521e-04
 - val_f1: 0.9998
Epoch 245/300
 - 24s - loss: 3.9846e-04 - val_loss: 3.9354e-04
 - val_f1: 0.9998
Epoch 246/300
 - 24s - loss: 3.8428e-04 - val_loss: 3.8232e-04
 - val_f1: 0.9998
Epoch 247/300
 - 24s - loss: 3.7408e-04 - val_loss: 4.5575e-04
 - val_f1: 0.9998
Epoch 248/300
 - 24s - loss: 3.7085e-04 - val_loss: 3.9122e-04
 - val_f1: 0.9998
Epoch 249/300
 - 24s - loss: 3.8092e-04 - val_loss: 3.7028e-04
 - val_f1: 0.9998
Epoch 250/300
 - 24s - loss: 3.6176e-04 - val_loss: 3.8469e-04
 - val_f1: 0.9998
Epoch 251/300
 - 24s - loss: 3.6504e-04 - val_loss: 3.7096e-04
 - val_f1: 0.9998
Epoch 252/300
 - 24s - loss: 3.8387e-04 - val_loss: 3.6419e-04
 - val_f1: 0.9998
Epoch 253/300
 - 24s - loss: 3.7173e-04 - val_loss: 3.7552e-04
 - val_f1: 0.9998
Epoch 254/300
 - 24s - loss: 3.7492e-04 - val_loss: 3.6224e-04
 - val_f1: 0.9998
Epoch 255/300
 - 24s - loss: 3.7411e-04 - val_loss: 3.6189e-04
 - val_f1: 0.9998
Epoch 256/300
 - 24s - loss: 3.7835e-04 - val_loss: 3.6841e-04
 - val_f1: 0.9998
Epoch 257/300
 - 24s - loss: 3.5334e-04 - val_loss: 3.9145e-04
 - val_f1: 0.9998
Epoch 258/300
 - 24s - loss: 3.8047e-04 - val_loss: 3.6205e-04
 - val_f1: 0.9998
Epoch 259/300
 - 24s - loss: 3.7387e-04 - val_loss: 3.7620e-04
 - val_f1: 0.9998
Epoch 260/300
 - 24s - loss: 3.6911e-04 - val_loss: 3.9700e-04
 - val_f1: 0.9998
Epoch 261/300
 - 24s - loss: 3.8101e-04 - val_loss: 3.8409e-04
 - val_f1: 0.9998
Epoch 262/300
 - 24s - loss: 3.6914e-04 - val_loss: 4.1391e-04
 - val_f1: 0.9998
Epoch 263/300
 - 24s - loss: 3.7502e-04 - val_loss: 4.1427e-04
 - val_f1: 0.9998
Epoch 264/300
 - 24s - loss: 3.6619e-04 - val_loss: 3.8835e-04
 - val_f1: 0.9998
Epoch 265/300
 - 24s - loss: 3.7988e-04 - val_loss: 3.8673e-04
 - val_f1: 0.9998
Epoch 266/300
 - 24s - loss: 3.7099e-04 - val_loss: 3.7977e-04
 - val_f1: 0.9998
Epoch 267/300
 - 24s - loss: 3.5806e-04 - val_loss: 3.7835e-04
 - val_f1: 0.9998
Epoch 268/300
 - 24s - loss: 3.6953e-04 - val_loss: 3.5889e-04
 - val_f1: 0.9998
Epoch 269/300
 - 24s - loss: 3.7714e-04 - val_loss: 3.6457e-04
 - val_f1: 0.9998
Epoch 270/300
 - 24s - loss: 3.7146e-04 - val_loss: 3.7154e-04
 - val_f1: 0.9998
Epoch 271/300
 - 24s - loss: 3.7037e-04 - val_loss: 3.8699e-04
2019-12-29 19:33:08,276 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 24s - loss: 3.6049e-04 - val_loss: 3.9623e-04
 - val_f1: 0.9998
Epoch 273/300
 - 24s - loss: 3.5395e-04 - val_loss: 3.7680e-04
 - val_f1: 0.9998
Epoch 274/300
 - 24s - loss: 3.5944e-04 - val_loss: 3.8925e-04
 - val_f1: 0.9998
Epoch 275/300
 - 24s - loss: 3.7331e-04 - val_loss: 3.6188e-04
 - val_f1: 0.9998
Epoch 276/300
 - 24s - loss: 3.5386e-04 - val_loss: 3.6360e-04
 - val_f1: 0.9998
Epoch 277/300
 - 24s - loss: 3.7539e-04 - val_loss: 3.6546e-04
 - val_f1: 0.9998
Epoch 278/300
 - 24s - loss: 3.5700e-04 - val_loss: 3.7808e-04
 - val_f1: 0.9998
Epoch 279/300
 - 24s - loss: 3.4788e-04 - val_loss: 3.5253e-04
 - val_f1: 0.9998
Epoch 280/300
 - 24s - loss: 3.5237e-04 - val_loss: 3.6906e-04
 - val_f1: 0.9998
Epoch 281/300
 - 24s - loss: 3.4717e-04 - val_loss: 3.7753e-04
 - val_f1: 0.9998
Epoch 282/300
 - 24s - loss: 3.6187e-04 - val_loss: 3.7544e-04
 - val_f1: 0.9998
Epoch 283/300
 - 24s - loss: 3.6905e-04 - val_loss: 3.8022e-04
 - val_f1: 0.9998
Epoch 284/300
 - 24s - loss: 3.5699e-04 - val_loss: 3.8231e-04
 - val_f1: 0.9998
Epoch 285/300
 - 24s - loss: 3.6478e-04 - val_loss: 3.7937e-04
 - val_f1: 0.9998
Epoch 286/300
 - 24s - loss: 3.7312e-04 - val_loss: 3.7271e-04
 - val_f1: 0.9998
Epoch 287/300
 - 24s - loss: 3.6090e-04 - val_loss: 3.8738e-04
 - val_f1: 0.9998
Epoch 288/300
 - 24s - loss: 3.6430e-04 - val_loss: 4.1849e-04
 - val_f1: 0.9998
Epoch 289/300
 - 24s - loss: 3.4452e-04 - val_loss: 4.0357e-04
 - val_f1: 0.9998
Epoch 290/300
 - 24s - loss: 3.6433e-04 - val_loss: 4.9003e-04
 - val_f1: 0.9996
Epoch 291/300
 - 24s - loss: 3.6337e-04 - val_loss: 3.9339e-04
 - val_f1: 0.9998
Epoch 292/300
 - 24s - loss: 3.5275e-04 - val_loss: 3.8263e-04
 - val_f1: 0.9998
Epoch 293/300
 - 24s - loss: 3.5713e-04 - val_loss: 3.6232e-04
 - val_f1: 0.9998
Epoch 294/300
 - 24s - loss: 3.3776e-04 - val_loss: 3.7318e-04
 - val_f1: 0.9998
Epoch 295/300
 - 24s - loss: 3.6532e-04 - val_loss: 3.9681e-04
 - val_f1: 0.9998
Epoch 296/300
 - 24s - loss: 3.6769e-04 - val_loss: 3.6730e-04
 - val_f1: 0.9998
Epoch 297/300
 - 24s - loss: 3.5749e-04 - val_loss: 3.4396e-04
 - val_f1: 0.9998
Epoch 298/300
 - 24s - loss: 3.5661e-04 - val_loss: 3.5702e-04
 - val_f1: 0.9998
Epoch 299/300
 - 24s - loss: 3.5762e-04 - val_loss: 3.6236e-04
 - val_f1: 0.9998
Epoch 300/300
 - 24s - loss: 3.5081e-04 - val_loss: 3.7594e-04
2019-12-29 19:52:58,071 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-29 19:53:58,975 [INFO] Last epoch loss evaluation: train_loss = 0.000216, val_loss = 0.000344
2019-12-29 19:53:58,990 [INFO] Training complete. time_to_train = 13459.92 sec, 224.33 min
2019-12-29 19:53:58,994 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_shallow_rep3/best_model.pickle
2019-12-29 19:53:58,997 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_shallow_rep3/training_error_history.csv
2019-12-29 19:53:59,184 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep3/training_error_history.png
2019-12-29 19:53:59,346 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep3/training_f1_history.png
2019-12-29 19:53:59,346 [INFO] Making predictions on training, validation, testing data
2019-12-29 19:55:23,584 [INFO] Evaluating predictions (results)
2019-12-29 19:55:32,285 [INFO] Dataset: Testing. Classification report below
2019-12-29 19:55:32,285 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.71      0.78      0.74      4166
         r2l       0.97      0.03      0.06     13781
         u2r       0.86      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.85      0.55      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-29 19:55:32,285 [INFO] Overall accuracy (micro avg): 0.9228014108009222
2019-12-29 19:55:41,598 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9228         0.9228                       0.9228                0.0193                   0.0772  0.9228
1     Macro avg        0.9691         0.8525                       0.5538                0.0194                   0.4462  0.5268
2  Weighted avg        0.9682         0.9394                       0.9228                0.0200                   0.0772  0.9041
2019-12-29 19:56:11,873 [INFO] Dataset: Validation. Classification report below
2019-12-29 19:56:11,873 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      0.99      8221
         r2l       0.92      0.90      0.91       225
         u2r       0.50      0.30      0.37        10

    accuracy                           1.00    979687
   macro avg       0.88      0.84      0.86    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-29 19:56:11,873 [INFO] Overall accuracy (micro avg): 0.9998356617981049
2019-12-29 19:56:44,539 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8826                       0.8384                0.0001                   0.1616  0.8555
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-29 19:58:57,633 [INFO] Dataset: Training. Classification report below
2019-12-29 19:58:57,633 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.89      0.93      0.91       901
         u2r       0.79      0.52      0.63        42

    accuracy                           1.00   3918744
   macro avg       0.93      0.89      0.91   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-29 19:58:57,633 [INFO] Overall accuracy (micro avg): 0.9998448482472956
2019-12-29 20:01:21,294 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9346                       0.8898                0.0001                   0.1102  0.9069
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-29 20:01:21,341 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_shallow_rep3/selected_kdd99_dbn_shallow_rep3_results.xlsx
2019-12-29 20:01:21,348 [INFO] ================= Finished running experiment no. 3 ================= 

2019-12-29 20:01:21,373 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_shallow_rep4
2019-12-29 20:01:21,373 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_shallow_rep4/run_log.log
2019-12-29 20:01:21,373 [INFO] ================= Running experiment no. 4  ================= 

2019-12-29 20:01:21,373 [INFO] Experiment parameters given below
2019-12-29 20:01:21,373 [INFO] 
{'experiment_num': 4, 'results_dir': 'results_selected_models/selected_kdd99_dbn_shallow_rep4', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_shallow_rep4'}
2019-12-29 20:01:21,373 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_shallow_rep4/tf_logs_run_2019_12_29-20_01_21
2019-12-29 20:01:21,373 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-29 20:01:21,374 [INFO] Reading X, y files
2019-12-29 20:01:21,374 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-29 20:01:27,759 [INFO] Reading complete. time_to_read=6.39 seconds
2019-12-29 20:01:27,759 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-29 20:01:29,373 [INFO] Reading complete. time_to_read=1.61 seconds
2019-12-29 20:01:29,374 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-29 20:01:29,841 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-29 20:01:29,841 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-29 20:01:30,073 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-29 20:01:30,073 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-29 20:01:30,128 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-29 20:01:30,128 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-29 20:01:30,147 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-29 20:01:37,333 [INFO] Initializing model
2019-12-29 20:01:37,334 [INFO] Training model
2019-12-29 20:01:37,334 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-29 20:02:18,553 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 5ded24bd143e9983ce6731b31dd52c0b91d910d2
2019-12-29 20:02:18,553 [INFO] Pretraining Deep Belief Network
2019-12-29 20:22:53,297 [INFO] Pretraining Complete
2019-12-29 20:22:53,297 [INFO] Getting pretrained weights
2019-12-29 20:22:53,297 [INFO] Creating and initializing feed forward neural network
2019-12-29 20:22:53,419 [INFO] _________________________________________________________________
2019-12-29 20:22:53,419 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-29 20:22:53,419 [INFO] =================================================================
2019-12-29 20:22:53,419 [INFO] dense_7 (Dense)              (None, 32)                3968      
2019-12-29 20:22:53,419 [INFO] _________________________________________________________________
2019-12-29 20:22:53,419 [INFO] batch_normalization_4 (Batch (None, 32)                128       
2019-12-29 20:22:53,419 [INFO] _________________________________________________________________
2019-12-29 20:22:53,419 [INFO] dropout_4 (Dropout)          (None, 32)                0         
2019-12-29 20:22:53,420 [INFO] _________________________________________________________________
2019-12-29 20:22:53,420 [INFO] dense_8 (Dense)              (None, 5)                 165       
2019-12-29 20:22:53,420 [INFO] =================================================================
2019-12-29 20:22:53,420 [INFO] Total params: 4,261
2019-12-29 20:22:53,420 [INFO] Trainable params: 4,197
2019-12-29 20:22:53,420 [INFO] Non-trainable params: 64
2019-12-29 20:22:53,420 [INFO] _________________________________________________________________
2019-12-29 20:22:53,664 [INFO] Fine-tuning final neural network
 - val_f1: 0.9998
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.30, time = 16.57s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -33.66, time = 25.56s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -31.78, time = 25.47s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -33.41, time = 25.39s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -35.88, time = 25.38s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.24, time = 25.33s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -40.43, time = 25.30s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -42.62, time = 25.17s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -44.84, time = 25.13s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -47.06, time = 25.12s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -49.26, time = 25.08s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -51.39, time = 25.08s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -53.50, time = 25.00s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -55.49, time = 25.00s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -57.39, time = 24.98s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -59.45, time = 24.71s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -61.49, time = 24.62s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -63.65, time = 24.61s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -65.86, time = 24.60s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -68.07, time = 24.59s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -70.28, time = 24.58s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -72.68, time = 24.57s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -74.95, time = 24.57s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -77.29, time = 24.57s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -79.69, time = 24.55s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -82.04, time = 24.53s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -84.42, time = 24.51s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -86.79, time = 24.50s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -89.16, time = 24.49s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -91.54, time = 24.45s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -93.92, time = 24.47s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -96.30, time = 24.46s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -98.69, time = 24.46s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -101.12, time = 24.45s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -103.51, time = 24.47s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -105.85, time = 24.46s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -108.31, time = 24.44s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -110.73, time = 24.44s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -113.08, time = 24.43s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -115.52, time = 24.43s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -117.83, time = 24.43s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -120.15, time = 24.43s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -122.64, time = 24.42s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -125.03, time = 24.43s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -127.34, time = 24.42s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -129.71, time = 24.42s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -132.18, time = 24.42s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -134.48, time = 24.41s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -136.87, time = 24.41s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -139.27, time = 24.41s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/300
 - 25s - loss: 0.0338 - val_loss: 0.0042
 - val_f1: 0.9976
Epoch 2/300
 - 24s - loss: 0.0046 - val_loss: 0.0023
 - val_f1: 0.9984
Epoch 3/300
 - 24s - loss: 0.0030 - val_loss: 0.0016
 - val_f1: 0.9989
Epoch 4/300
 - 24s - loss: 0.0023 - val_loss: 0.0013
 - val_f1: 0.9993
Epoch 5/300
 - 24s - loss: 0.0020 - val_loss: 0.0011
 - val_f1: 0.9993
Epoch 6/300
 - 24s - loss: 0.0018 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 7/300
 - 24s - loss: 0.0017 - val_loss: 9.3153e-04
 - val_f1: 0.9995
Epoch 8/300
 - 24s - loss: 0.0015 - val_loss: 9.0309e-04
 - val_f1: 0.9995
Epoch 9/300
 - 24s - loss: 0.0014 - val_loss: 8.4460e-04
 - val_f1: 0.9995
Epoch 10/300
 - 24s - loss: 0.0014 - val_loss: 8.1497e-04
 - val_f1: 0.9996
Epoch 11/300
 - 24s - loss: 0.0013 - val_loss: 8.0919e-04
 - val_f1: 0.9995
Epoch 12/300
 - 24s - loss: 0.0013 - val_loss: 8.0323e-04
 - val_f1: 0.9996
Epoch 13/300
 - 24s - loss: 0.0012 - val_loss: 7.4366e-04
 - val_f1: 0.9996
Epoch 14/300
 - 24s - loss: 0.0012 - val_loss: 7.5077e-04
 - val_f1: 0.9996
Epoch 15/300
 - 24s - loss: 0.0012 - val_loss: 7.4300e-04
 - val_f1: 0.9996
Epoch 16/300
 - 24s - loss: 0.0012 - val_loss: 7.3228e-04
 - val_f1: 0.9996
Epoch 17/300
 - 24s - loss: 0.0012 - val_loss: 7.1802e-04
 - val_f1: 0.9996
Epoch 18/300
 - 24s - loss: 0.0011 - val_loss: 6.9496e-04
 - val_f1: 0.9996
Epoch 19/300
 - 24s - loss: 0.0011 - val_loss: 6.8041e-04
 - val_f1: 0.9996
Epoch 20/300
 - 24s - loss: 0.0011 - val_loss: 6.8090e-04
 - val_f1: 0.9996
Epoch 21/300
 - 24s - loss: 0.0010 - val_loss: 6.7365e-04
 - val_f1: 0.9997
Epoch 22/300
 - 24s - loss: 0.0010 - val_loss: 6.6817e-04
 - val_f1: 0.9997
Epoch 23/300
 - 24s - loss: 0.0010 - val_loss: 6.5772e-04
 - val_f1: 0.9997
Epoch 24/300
 - 24s - loss: 9.8496e-04 - val_loss: 6.3396e-04
 - val_f1: 0.9997
Epoch 25/300
 - 24s - loss: 9.8445e-04 - val_loss: 6.2792e-04
 - val_f1: 0.9997
Epoch 26/300
 - 24s - loss: 9.3444e-04 - val_loss: 6.0357e-04
 - val_f1: 0.9997
Epoch 27/300
 - 24s - loss: 9.0817e-04 - val_loss: 5.9805e-04
 - val_f1: 0.9997
Epoch 28/300
 - 24s - loss: 8.6886e-04 - val_loss: 5.9286e-04
 - val_f1: 0.9997
Epoch 29/300
 - 24s - loss: 8.6336e-04 - val_loss: 5.8085e-04
 - val_f1: 0.9997
Epoch 30/300
 - 24s - loss: 8.4780e-04 - val_loss: 6.0746e-04
 - val_f1: 0.9997
Epoch 31/300
 - 24s - loss: 8.3734e-04 - val_loss: 5.8043e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-29 20:44:11,124 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_30.pickle
 - val_f1: 0.9997
Epoch 32/300
 - 24s - loss: 8.2053e-04 - val_loss: 5.9633e-04
 - val_f1: 0.9997
Epoch 33/300
 - 24s - loss: 7.8692e-04 - val_loss: 5.8054e-04
 - val_f1: 0.9997
Epoch 34/300
 - 24s - loss: 8.0516e-04 - val_loss: 5.6286e-04
 - val_f1: 0.9997
Epoch 35/300
 - 24s - loss: 7.6447e-04 - val_loss: 5.4175e-04
 - val_f1: 0.9997
Epoch 36/300
 - 24s - loss: 7.5387e-04 - val_loss: 5.4565e-04
 - val_f1: 0.9997
Epoch 37/300
 - 24s - loss: 7.6760e-04 - val_loss: 5.5419e-04
 - val_f1: 0.9997
Epoch 38/300
 - 24s - loss: 7.5491e-04 - val_loss: 5.3937e-04
 - val_f1: 0.9997
Epoch 39/300
 - 24s - loss: 7.4932e-04 - val_loss: 5.2733e-04
 - val_f1: 0.9997
Epoch 40/300
 - 24s - loss: 7.2496e-04 - val_loss: 5.2921e-04
 - val_f1: 0.9997
Epoch 41/300
 - 24s - loss: 7.1470e-04 - val_loss: 5.2067e-04
 - val_f1: 0.9997
Epoch 42/300
 - 24s - loss: 7.0971e-04 - val_loss: 5.2546e-04
 - val_f1: 0.9997
Epoch 43/300
 - 24s - loss: 7.0533e-04 - val_loss: 5.0925e-04
 - val_f1: 0.9997
Epoch 44/300
 - 24s - loss: 7.0922e-04 - val_loss: 5.0796e-04
 - val_f1: 0.9997
Epoch 45/300
 - 24s - loss: 6.8450e-04 - val_loss: 5.2304e-04
 - val_f1: 0.9997
Epoch 46/300
 - 24s - loss: 6.9240e-04 - val_loss: 4.9727e-04
 - val_f1: 0.9997
Epoch 47/300
 - 24s - loss: 6.7046e-04 - val_loss: 4.9286e-04
 - val_f1: 0.9997
Epoch 48/300
 - 24s - loss: 6.7772e-04 - val_loss: 5.1136e-04
 - val_f1: 0.9997
Epoch 49/300
 - 24s - loss: 6.7878e-04 - val_loss: 5.0847e-04
 - val_f1: 0.9997
Epoch 50/300
 - 24s - loss: 6.7138e-04 - val_loss: 4.8624e-04
 - val_f1: 0.9997
Epoch 51/300
 - 24s - loss: 6.7376e-04 - val_loss: 4.7377e-04
 - val_f1: 0.9997
Epoch 52/300
 - 24s - loss: 6.4845e-04 - val_loss: 4.7117e-04
 - val_f1: 0.9997
Epoch 53/300
 - 24s - loss: 6.2622e-04 - val_loss: 4.7467e-04
 - val_f1: 0.9997
Epoch 54/300
 - 24s - loss: 6.4336e-04 - val_loss: 4.7198e-04
 - val_f1: 0.9997
Epoch 55/300
 - 24s - loss: 6.0557e-04 - val_loss: 4.7176e-04
 - val_f1: 0.9997
Epoch 56/300
 - 24s - loss: 6.1684e-04 - val_loss: 4.8480e-04
 - val_f1: 0.9997
Epoch 57/300
 - 24s - loss: 6.1561e-04 - val_loss: 4.8504e-04
 - val_f1: 0.9997
Epoch 58/300
 - 24s - loss: 5.8922e-04 - val_loss: 4.7251e-04
 - val_f1: 0.9997
Epoch 59/300
 - 24s - loss: 5.9701e-04 - val_loss: 4.7174e-04
 - val_f1: 0.9997
Epoch 60/300
 - 24s - loss: 5.9192e-04 - val_loss: 4.5602e-04
 - val_f1: 0.9997
Epoch 61/300
 - 24s - loss: 5.8428e-04 - val_loss: 4.6640e-04
2019-12-29 21:04:58,809 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/300
 - 24s - loss: 6.0345e-04 - val_loss: 4.4492e-04
 - val_f1: 0.9997
Epoch 63/300
 - 24s - loss: 5.7539e-04 - val_loss: 4.3253e-04
 - val_f1: 0.9997
Epoch 64/300
 - 24s - loss: 5.7840e-04 - val_loss: 4.3852e-04
 - val_f1: 0.9997
Epoch 65/300
 - 24s - loss: 5.8681e-04 - val_loss: 4.3667e-04
 - val_f1: 0.9997
Epoch 66/300
 - 24s - loss: 5.4853e-04 - val_loss: 4.3625e-04
 - val_f1: 0.9997
Epoch 67/300
 - 24s - loss: 5.6950e-04 - val_loss: 4.6217e-04
 - val_f1: 0.9997
Epoch 68/300
 - 24s - loss: 5.5304e-04 - val_loss: 4.4472e-04
 - val_f1: 0.9997
Epoch 69/300
 - 24s - loss: 5.6576e-04 - val_loss: 4.4006e-04
 - val_f1: 0.9997
Epoch 70/300
 - 24s - loss: 5.5412e-04 - val_loss: 4.3124e-04
 - val_f1: 0.9997
Epoch 71/300
 - 24s - loss: 5.3703e-04 - val_loss: 4.7285e-04
 - val_f1: 0.9997
Epoch 72/300
 - 24s - loss: 5.4895e-04 - val_loss: 4.2997e-04
 - val_f1: 0.9997
Epoch 73/300
 - 24s - loss: 5.5812e-04 - val_loss: 4.3110e-04
 - val_f1: 0.9997
Epoch 74/300
 - 24s - loss: 5.3949e-04 - val_loss: 4.2118e-04
 - val_f1: 0.9997
Epoch 75/300
 - 24s - loss: 5.4674e-04 - val_loss: 4.1604e-04
 - val_f1: 0.9997
Epoch 76/300
 - 24s - loss: 5.1506e-04 - val_loss: 4.3467e-04
 - val_f1: 0.9997
Epoch 77/300
 - 24s - loss: 5.1762e-04 - val_loss: 4.3447e-04
 - val_f1: 0.9997
Epoch 78/300
 - 24s - loss: 5.0801e-04 - val_loss: 4.2751e-04
 - val_f1: 0.9997
Epoch 79/300
 - 24s - loss: 5.2313e-04 - val_loss: 4.5984e-04
 - val_f1: 0.9997
Epoch 80/300
 - 24s - loss: 5.2157e-04 - val_loss: 4.1302e-04
 - val_f1: 0.9998
Epoch 81/300
 - 24s - loss: 5.1025e-04 - val_loss: 4.6800e-04
 - val_f1: 0.9997
Epoch 82/300
 - 24s - loss: 5.3274e-04 - val_loss: 4.2530e-04
 - val_f1: 0.9997
Epoch 83/300
 - 24s - loss: 5.2200e-04 - val_loss: 4.1638e-04
 - val_f1: 0.9997
Epoch 84/300
 - 24s - loss: 5.0468e-04 - val_loss: 4.1919e-04
 - val_f1: 0.9998
Epoch 85/300
 - 24s - loss: 5.0932e-04 - val_loss: 4.3536e-04
 - val_f1: 0.9997
Epoch 86/300
 - 24s - loss: 5.0412e-04 - val_loss: 4.2407e-04
 - val_f1: 0.9998
Epoch 87/300
 - 24s - loss: 5.0723e-04 - val_loss: 4.3477e-04
 - val_f1: 0.9997
Epoch 88/300
 - 24s - loss: 4.8505e-04 - val_loss: 4.2975e-04
 - val_f1: 0.9998
Epoch 89/300
 - 24s - loss: 4.9927e-04 - val_loss: 4.1241e-04
 - val_f1: 0.9998
Epoch 90/300
 - 24s - loss: 5.1405e-04 - val_loss: 4.1520e-04
 - val_f1: 0.9998
Epoch 91/300
 - 24s - loss: 5.0203e-04 - val_loss: 4.1156e-04
2019-12-29 21:25:47,697 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 24s - loss: 4.9496e-04 - val_loss: 4.0915e-04
 - val_f1: 0.9998
Epoch 93/300
 - 24s - loss: 4.8977e-04 - val_loss: 4.5958e-04
 - val_f1: 0.9997
Epoch 94/300
 - 24s - loss: 4.9068e-04 - val_loss: 4.0079e-04
 - val_f1: 0.9998
Epoch 95/300
 - 24s - loss: 5.2068e-04 - val_loss: 4.2381e-04
 - val_f1: 0.9998
Epoch 96/300
 - 24s - loss: 4.9372e-04 - val_loss: 4.2915e-04
 - val_f1: 0.9998
Epoch 97/300
 - 24s - loss: 4.7895e-04 - val_loss: 4.1587e-04
 - val_f1: 0.9998
Epoch 98/300
 - 24s - loss: 4.9932e-04 - val_loss: 4.4925e-04
 - val_f1: 0.9997
Epoch 99/300
 - 24s - loss: 4.8495e-04 - val_loss: 4.2293e-04
 - val_f1: 0.9998
Epoch 100/300
 - 24s - loss: 4.9672e-04 - val_loss: 4.0563e-04
 - val_f1: 0.9998
Epoch 101/300
 - 24s - loss: 4.9671e-04 - val_loss: 4.6603e-04
 - val_f1: 0.9997
Epoch 102/300
 - 24s - loss: 4.6947e-04 - val_loss: 4.0861e-04
 - val_f1: 0.9998
Epoch 103/300
 - 24s - loss: 4.7592e-04 - val_loss: 4.0474e-04
 - val_f1: 0.9998
Epoch 104/300
 - 24s - loss: 4.9364e-04 - val_loss: 4.3263e-04
 - val_f1: 0.9998
Epoch 105/300
 - 24s - loss: 4.7099e-04 - val_loss: 3.9646e-04
 - val_f1: 0.9998
Epoch 106/300
 - 24s - loss: 4.6371e-04 - val_loss: 4.2777e-04
 - val_f1: 0.9998
Epoch 107/300
 - 24s - loss: 4.6871e-04 - val_loss: 4.1502e-04
 - val_f1: 0.9998
Epoch 108/300
 - 24s - loss: 4.8070e-04 - val_loss: 4.3528e-04
 - val_f1: 0.9998
Epoch 109/300
 - 24s - loss: 4.7286e-04 - val_loss: 4.1798e-04
 - val_f1: 0.9997
Epoch 110/300
 - 24s - loss: 4.7099e-04 - val_loss: 4.1902e-04
 - val_f1: 0.9998
Epoch 111/300
 - 24s - loss: 4.6545e-04 - val_loss: 4.2551e-04
 - val_f1: 0.9998
Epoch 112/300
 - 24s - loss: 4.7247e-04 - val_loss: 4.1809e-04
 - val_f1: 0.9998
Epoch 113/300
 - 24s - loss: 4.5063e-04 - val_loss: 4.0996e-04
 - val_f1: 0.9998
Epoch 114/300
 - 24s - loss: 4.5390e-04 - val_loss: 4.1596e-04
 - val_f1: 0.9998
Epoch 115/300
 - 24s - loss: 4.6538e-04 - val_loss: 4.1822e-04
 - val_f1: 0.9998
Epoch 116/300
 - 24s - loss: 4.5688e-04 - val_loss: 4.1526e-04
 - val_f1: 0.9998
Epoch 117/300
 - 24s - loss: 4.3973e-04 - val_loss: 4.0999e-04
 - val_f1: 0.9998
Epoch 118/300
 - 24s - loss: 4.4679e-04 - val_loss: 4.0538e-04
 - val_f1: 0.9998
Epoch 119/300
 - 24s - loss: 4.5716e-04 - val_loss: 4.0878e-04
 - val_f1: 0.9998
Epoch 120/300
 - 24s - loss: 4.6531e-04 - val_loss: 4.0186e-04
 - val_f1: 0.9998
Epoch 121/300
 - 24s - loss: 4.4436e-04 - val_loss: 4.0289e-04
2019-12-29 21:46:36,439 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 24s - loss: 4.4876e-04 - val_loss: 3.9223e-04
 - val_f1: 0.9998
Epoch 123/300
 - 24s - loss: 4.7031e-04 - val_loss: 4.0752e-04
 - val_f1: 0.9998
Epoch 124/300
 - 24s - loss: 4.5269e-04 - val_loss: 4.4034e-04
 - val_f1: 0.9998
Epoch 125/300
 - 24s - loss: 4.4338e-04 - val_loss: 4.0109e-04
 - val_f1: 0.9998
Epoch 126/300
 - 24s - loss: 4.3035e-04 - val_loss: 4.0258e-04
 - val_f1: 0.9998
Epoch 127/300
 - 24s - loss: 4.4573e-04 - val_loss: 4.0175e-04
 - val_f1: 0.9998
Epoch 128/300
 - 24s - loss: 4.4167e-04 - val_loss: 4.1497e-04
 - val_f1: 0.9998
Epoch 129/300
 - 24s - loss: 4.5534e-04 - val_loss: 4.0719e-04
 - val_f1: 0.9998
Epoch 130/300
 - 24s - loss: 4.4198e-04 - val_loss: 3.9806e-04
 - val_f1: 0.9998
Epoch 131/300
 - 24s - loss: 4.3363e-04 - val_loss: 4.0609e-04
 - val_f1: 0.9998
Epoch 132/300
 - 24s - loss: 4.3558e-04 - val_loss: 4.0133e-04
 - val_f1: 0.9998
Epoch 133/300
 - 24s - loss: 4.3809e-04 - val_loss: 4.0101e-04
 - val_f1: 0.9998
Epoch 134/300
 - 24s - loss: 4.3558e-04 - val_loss: 4.1322e-04
 - val_f1: 0.9998
Epoch 135/300
 - 24s - loss: 4.4560e-04 - val_loss: 4.1333e-04
 - val_f1: 0.9998
Epoch 136/300
 - 24s - loss: 4.4423e-04 - val_loss: 4.0318e-04
 - val_f1: 0.9998
Epoch 137/300
 - 24s - loss: 4.4376e-04 - val_loss: 4.1060e-04
 - val_f1: 0.9998
Epoch 138/300
 - 24s - loss: 4.2900e-04 - val_loss: 4.9286e-04
 - val_f1: 0.9997
Epoch 139/300
 - 24s - loss: 4.3217e-04 - val_loss: 3.9294e-04
 - val_f1: 0.9998
Epoch 140/300
 - 24s - loss: 4.3066e-04 - val_loss: 4.3136e-04
 - val_f1: 0.9998
Epoch 141/300
 - 24s - loss: 4.4271e-04 - val_loss: 4.1400e-04
 - val_f1: 0.9998
Epoch 142/300
 - 24s - loss: 4.3377e-04 - val_loss: 3.8777e-04
 - val_f1: 0.9998
Epoch 143/300
 - 24s - loss: 4.2726e-04 - val_loss: 3.9585e-04
 - val_f1: 0.9998
Epoch 144/300
 - 24s - loss: 4.1855e-04 - val_loss: 3.8889e-04
 - val_f1: 0.9998
Epoch 145/300
 - 24s - loss: 4.3485e-04 - val_loss: 3.8493e-04
 - val_f1: 0.9998
Epoch 146/300
 - 24s - loss: 4.2480e-04 - val_loss: 4.0416e-04
 - val_f1: 0.9998
Epoch 147/300
 - 24s - loss: 4.4091e-04 - val_loss: 3.7982e-04
 - val_f1: 0.9998
Epoch 148/300
 - 24s - loss: 4.1992e-04 - val_loss: 3.9808e-04
 - val_f1: 0.9998
Epoch 149/300
 - 24s - loss: 4.3421e-04 - val_loss: 3.9822e-04
 - val_f1: 0.9998
Epoch 150/300
 - 24s - loss: 4.2392e-04 - val_loss: 3.8870e-04
 - val_f1: 0.9998
Epoch 151/300
 - 24s - loss: 4.1824e-04 - val_loss: 4.0066e-04
2019-12-29 22:07:25,550 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 24s - loss: 4.1930e-04 - val_loss: 3.9004e-04
 - val_f1: 0.9998
Epoch 153/300
 - 24s - loss: 4.0823e-04 - val_loss: 4.8113e-04
 - val_f1: 0.9997
Epoch 154/300
 - 24s - loss: 4.0948e-04 - val_loss: 3.7538e-04
 - val_f1: 0.9998
Epoch 155/300
 - 24s - loss: 4.1463e-04 - val_loss: 3.9101e-04
 - val_f1: 0.9998
Epoch 156/300
 - 24s - loss: 4.2087e-04 - val_loss: 3.8309e-04
 - val_f1: 0.9998
Epoch 157/300
 - 24s - loss: 4.1476e-04 - val_loss: 3.9366e-04
 - val_f1: 0.9998
Epoch 158/300
 - 24s - loss: 4.2552e-04 - val_loss: 3.9317e-04
 - val_f1: 0.9998
Epoch 159/300
 - 24s - loss: 4.2124e-04 - val_loss: 3.8554e-04
 - val_f1: 0.9998
Epoch 160/300
 - 24s - loss: 4.2287e-04 - val_loss: 4.0212e-04
 - val_f1: 0.9998
Epoch 161/300
 - 24s - loss: 4.3069e-04 - val_loss: 3.7629e-04
 - val_f1: 0.9998
Epoch 162/300
 - 24s - loss: 4.1306e-04 - val_loss: 3.7105e-04
 - val_f1: 0.9998
Epoch 163/300
 - 24s - loss: 4.1822e-04 - val_loss: 3.6663e-04
 - val_f1: 0.9998
Epoch 164/300
 - 24s - loss: 4.2344e-04 - val_loss: 3.8144e-04
 - val_f1: 0.9998
Epoch 165/300
 - 24s - loss: 4.1003e-04 - val_loss: 3.6801e-04
 - val_f1: 0.9998
Epoch 166/300
 - 24s - loss: 4.0477e-04 - val_loss: 3.7774e-04
 - val_f1: 0.9998
Epoch 167/300
 - 24s - loss: 4.1471e-04 - val_loss: 3.8742e-04
 - val_f1: 0.9998
Epoch 168/300
 - 24s - loss: 4.0094e-04 - val_loss: 3.6601e-04
 - val_f1: 0.9998
Epoch 169/300
 - 24s - loss: 4.0074e-04 - val_loss: 3.7465e-04
 - val_f1: 0.9998
Epoch 170/300
 - 24s - loss: 3.8727e-04 - val_loss: 3.8660e-04
 - val_f1: 0.9998
Epoch 171/300
 - 24s - loss: 4.0395e-04 - val_loss: 3.9433e-04
 - val_f1: 0.9998
Epoch 172/300
 - 24s - loss: 4.0982e-04 - val_loss: 3.6640e-04
 - val_f1: 0.9998
Epoch 173/300
 - 24s - loss: 3.8033e-04 - val_loss: 3.9126e-04
 - val_f1: 0.9998
Epoch 174/300
 - 24s - loss: 4.0255e-04 - val_loss: 3.9332e-04
 - val_f1: 0.9998
Epoch 175/300
 - 24s - loss: 3.9219e-04 - val_loss: 3.7603e-04
 - val_f1: 0.9998
Epoch 176/300
 - 24s - loss: 3.9121e-04 - val_loss: 3.8299e-04
 - val_f1: 0.9998
Epoch 177/300
 - 24s - loss: 3.9042e-04 - val_loss: 4.0225e-04
 - val_f1: 0.9998
Epoch 178/300
 - 24s - loss: 3.9811e-04 - val_loss: 3.8356e-04
 - val_f1: 0.9998
Epoch 179/300
 - 24s - loss: 3.9683e-04 - val_loss: 3.6596e-04
 - val_f1: 0.9998
Epoch 180/300
 - 24s - loss: 3.9106e-04 - val_loss: 3.7953e-04
 - val_f1: 0.9998
Epoch 181/300
 - 24s - loss: 3.9587e-04 - val_loss: 3.7029e-04
2019-12-29 22:28:12,992 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 24s - loss: 4.0038e-04 - val_loss: 3.9310e-04
 - val_f1: 0.9998
Epoch 183/300
 - 24s - loss: 3.9663e-04 - val_loss: 3.7978e-04
 - val_f1: 0.9998
Epoch 184/300
 - 24s - loss: 3.7707e-04 - val_loss: 3.8383e-04
 - val_f1: 0.9998
Epoch 185/300
 - 24s - loss: 3.8705e-04 - val_loss: 4.0207e-04
 - val_f1: 0.9998
Epoch 186/300
 - 24s - loss: 4.0577e-04 - val_loss: 3.8872e-04
 - val_f1: 0.9998
Epoch 187/300
 - 24s - loss: 3.8570e-04 - val_loss: 3.9682e-04
 - val_f1: 0.9998
Epoch 188/300
 - 24s - loss: 3.8020e-04 - val_loss: 3.8223e-04
 - val_f1: 0.9998
Epoch 189/300
 - 24s - loss: 3.8493e-04 - val_loss: 3.8308e-04
 - val_f1: 0.9998
Epoch 190/300
 - 24s - loss: 3.8633e-04 - val_loss: 3.8108e-04
 - val_f1: 0.9998
Epoch 191/300
 - 24s - loss: 3.8852e-04 - val_loss: 3.9017e-04
 - val_f1: 0.9998
Epoch 192/300
 - 24s - loss: 3.7530e-04 - val_loss: 3.7717e-04
 - val_f1: 0.9998
Epoch 193/300
 - 24s - loss: 3.8973e-04 - val_loss: 3.7788e-04
 - val_f1: 0.9998
Epoch 194/300
 - 24s - loss: 3.8720e-04 - val_loss: 3.6902e-04
 - val_f1: 0.9998
Epoch 195/300
 - 24s - loss: 3.8218e-04 - val_loss: 3.8336e-04
 - val_f1: 0.9998
Epoch 196/300
 - 24s - loss: 3.8272e-04 - val_loss: 3.7227e-04
 - val_f1: 0.9998
Epoch 197/300
 - 24s - loss: 3.8622e-04 - val_loss: 3.7304e-04
 - val_f1: 0.9998
Epoch 198/300
 - 24s - loss: 3.7984e-04 - val_loss: 3.8980e-04
 - val_f1: 0.9998
Epoch 199/300
 - 24s - loss: 3.8090e-04 - val_loss: 3.8355e-04
 - val_f1: 0.9998
Epoch 200/300
 - 24s - loss: 3.7053e-04 - val_loss: 4.1194e-04
 - val_f1: 0.9998
Epoch 201/300
 - 24s - loss: 3.7329e-04 - val_loss: 4.5118e-04
 - val_f1: 0.9997
Epoch 202/300
 - 24s - loss: 3.7315e-04 - val_loss: 3.7717e-04
 - val_f1: 0.9998
Epoch 203/300
 - 24s - loss: 3.8928e-04 - val_loss: 3.7760e-04
 - val_f1: 0.9998
Epoch 204/300
 - 24s - loss: 3.8738e-04 - val_loss: 3.7195e-04
 - val_f1: 0.9998
Epoch 205/300
 - 24s - loss: 3.6945e-04 - val_loss: 3.7047e-04
 - val_f1: 0.9998
Epoch 206/300
 - 24s - loss: 3.8153e-04 - val_loss: 3.7447e-04
 - val_f1: 0.9998
Epoch 207/300
 - 24s - loss: 3.8048e-04 - val_loss: 3.8069e-04
 - val_f1: 0.9998
Epoch 208/300
 - 24s - loss: 3.8107e-04 - val_loss: 3.6105e-04
 - val_f1: 0.9998
Epoch 209/300
 - 24s - loss: 3.9351e-04 - val_loss: 3.6636e-04
 - val_f1: 0.9998
Epoch 210/300
 - 24s - loss: 3.6923e-04 - val_loss: 3.7126e-04
 - val_f1: 0.9998
Epoch 211/300
 - 24s - loss: 3.7366e-04 - val_loss: 3.6294e-04
2019-12-29 22:49:00,443 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 24s - loss: 3.6825e-04 - val_loss: 3.8585e-04
 - val_f1: 0.9998
Epoch 213/300
 - 24s - loss: 3.7731e-04 - val_loss: 3.7941e-04
 - val_f1: 0.9998
Epoch 214/300
 - 24s - loss: 3.7071e-04 - val_loss: 3.7594e-04
 - val_f1: 0.9998
Epoch 215/300
 - 24s - loss: 3.7439e-04 - val_loss: 3.5666e-04
 - val_f1: 0.9998
Epoch 216/300
 - 24s - loss: 3.7288e-04 - val_loss: 3.7233e-04
 - val_f1: 0.9998
Epoch 217/300
 - 24s - loss: 3.7740e-04 - val_loss: 3.9318e-04
 - val_f1: 0.9998
Epoch 218/300
 - 24s - loss: 3.6577e-04 - val_loss: 3.6548e-04
 - val_f1: 0.9998
Epoch 219/300
 - 24s - loss: 3.6979e-04 - val_loss: 3.7117e-04
 - val_f1: 0.9998
Epoch 220/300
 - 24s - loss: 3.5991e-04 - val_loss: 3.6726e-04
 - val_f1: 0.9998
Epoch 221/300
 - 24s - loss: 3.4608e-04 - val_loss: 3.8167e-04
 - val_f1: 0.9998
Epoch 222/300
 - 24s - loss: 3.5374e-04 - val_loss: 3.8012e-04
 - val_f1: 0.9998
Epoch 223/300
 - 24s - loss: 3.7238e-04 - val_loss: 3.7080e-04
 - val_f1: 0.9998
Epoch 224/300
 - 24s - loss: 3.6893e-04 - val_loss: 3.6739e-04
 - val_f1: 0.9998
Epoch 225/300
 - 24s - loss: 3.7720e-04 - val_loss: 4.0013e-04
 - val_f1: 0.9998
Epoch 226/300
 - 24s - loss: 3.5854e-04 - val_loss: 3.8472e-04
 - val_f1: 0.9998
Epoch 227/300
 - 24s - loss: 3.6085e-04 - val_loss: 3.6165e-04
 - val_f1: 0.9998
Epoch 228/300
 - 24s - loss: 3.6091e-04 - val_loss: 3.6724e-04
 - val_f1: 0.9998
Epoch 229/300
 - 24s - loss: 3.8045e-04 - val_loss: 3.7417e-04
 - val_f1: 0.9998
Epoch 230/300
 - 24s - loss: 3.6351e-04 - val_loss: 3.7666e-04
 - val_f1: 0.9998
Epoch 231/300
 - 24s - loss: 3.6355e-04 - val_loss: 3.6729e-04
 - val_f1: 0.9998
Epoch 232/300
 - 24s - loss: 3.5906e-04 - val_loss: 3.7657e-04
 - val_f1: 0.9998
Epoch 233/300
 - 24s - loss: 3.5467e-04 - val_loss: 3.6891e-04
 - val_f1: 0.9998
Epoch 234/300
 - 24s - loss: 3.5168e-04 - val_loss: 3.5854e-04
 - val_f1: 0.9998
Epoch 235/300
 - 24s - loss: 3.7642e-04 - val_loss: 3.7844e-04
 - val_f1: 0.9998
Epoch 236/300
 - 24s - loss: 3.6876e-04 - val_loss: 4.0181e-04
 - val_f1: 0.9998
Epoch 237/300
 - 24s - loss: 3.5365e-04 - val_loss: 3.6995e-04
 - val_f1: 0.9998
Epoch 238/300
 - 24s - loss: 3.4330e-04 - val_loss: 3.6209e-04
 - val_f1: 0.9998
Epoch 239/300
 - 24s - loss: 3.6702e-04 - val_loss: 3.5508e-04
 - val_f1: 0.9998
Epoch 240/300
 - 24s - loss: 3.6578e-04 - val_loss: 5.1642e-04
 - val_f1: 0.9997
Epoch 241/300
 - 24s - loss: 3.5996e-04 - val_loss: 3.6637e-04
2019-12-29 23:09:46,676 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 24s - loss: 3.6823e-04 - val_loss: 3.8544e-04
 - val_f1: 0.9998
Epoch 243/300
 - 24s - loss: 3.5612e-04 - val_loss: 3.5955e-04
 - val_f1: 0.9998
Epoch 244/300
 - 24s - loss: 3.5146e-04 - val_loss: 3.8102e-04
 - val_f1: 0.9998
Epoch 245/300
 - 24s - loss: 3.5816e-04 - val_loss: 3.6354e-04
 - val_f1: 0.9998
Epoch 246/300
 - 24s - loss: 3.5413e-04 - val_loss: 3.6124e-04
 - val_f1: 0.9998
Epoch 247/300
 - 24s - loss: 3.6244e-04 - val_loss: 3.6598e-04
 - val_f1: 0.9998
Epoch 248/300
 - 24s - loss: 3.5220e-04 - val_loss: 3.8074e-04
 - val_f1: 0.9998
Epoch 249/300
 - 24s - loss: 3.6390e-04 - val_loss: 3.7908e-04
 - val_f1: 0.9998
Epoch 250/300
 - 24s - loss: 3.6468e-04 - val_loss: 3.4120e-04
 - val_f1: 0.9998
Epoch 251/300
 - 24s - loss: 3.5519e-04 - val_loss: 3.6199e-04
 - val_f1: 0.9998
Epoch 252/300
 - 24s - loss: 3.5574e-04 - val_loss: 3.6653e-04
 - val_f1: 0.9998
Epoch 253/300
 - 24s - loss: 3.6032e-04 - val_loss: 3.5522e-04
 - val_f1: 0.9998
Epoch 254/300
 - 24s - loss: 3.4909e-04 - val_loss: 3.6885e-04
 - val_f1: 0.9998
Epoch 255/300
 - 24s - loss: 3.5083e-04 - val_loss: 3.6432e-04
 - val_f1: 0.9998
Epoch 256/300
 - 24s - loss: 3.5462e-04 - val_loss: 3.5318e-04
 - val_f1: 0.9998
Epoch 257/300
 - 24s - loss: 3.4337e-04 - val_loss: 3.5671e-04
 - val_f1: 0.9998
Epoch 258/300
 - 24s - loss: 3.5925e-04 - val_loss: 3.7384e-04
 - val_f1: 0.9998
Epoch 259/300
 - 24s - loss: 3.5264e-04 - val_loss: 3.5123e-04
 - val_f1: 0.9998
Epoch 260/300
 - 24s - loss: 3.5659e-04 - val_loss: 3.5762e-04
 - val_f1: 0.9998
Epoch 261/300
 - 24s - loss: 3.4600e-04 - val_loss: 3.7208e-04
 - val_f1: 0.9998
Epoch 262/300
 - 24s - loss: 3.5829e-04 - val_loss: 3.8557e-04
 - val_f1: 0.9998
Epoch 263/300
 - 24s - loss: 3.4167e-04 - val_loss: 3.7224e-04
 - val_f1: 0.9998
Epoch 264/300
 - 24s - loss: 3.3472e-04 - val_loss: 3.7762e-04
 - val_f1: 0.9998
Epoch 265/300
 - 24s - loss: 3.4881e-04 - val_loss: 3.7749e-04
 - val_f1: 0.9998
Epoch 266/300
 - 24s - loss: 3.3271e-04 - val_loss: 3.8285e-04
 - val_f1: 0.9998
Epoch 267/300
 - 24s - loss: 3.3891e-04 - val_loss: 3.6847e-04
 - val_f1: 0.9998
Epoch 268/300
 - 24s - loss: 3.3761e-04 - val_loss: 3.6219e-04
 - val_f1: 0.9998
Epoch 269/300
 - 24s - loss: 3.3972e-04 - val_loss: 3.7444e-04
 - val_f1: 0.9998
Epoch 270/300
 - 24s - loss: 3.4208e-04 - val_loss: 3.7673e-04
 - val_f1: 0.9998
Epoch 271/300
 - 24s - loss: 3.5971e-04 - val_loss: 3.6803e-04
2019-12-29 23:30:34,644 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 24s - loss: 3.2886e-04 - val_loss: 3.5954e-04
 - val_f1: 0.9998
Epoch 273/300
 - 24s - loss: 3.5829e-04 - val_loss: 3.5802e-04
 - val_f1: 0.9998
Epoch 274/300
 - 24s - loss: 3.5033e-04 - val_loss: 3.7634e-04
 - val_f1: 0.9998
Epoch 275/300
 - 24s - loss: 3.3861e-04 - val_loss: 3.6594e-04
 - val_f1: 0.9998
Epoch 276/300
 - 24s - loss: 3.2864e-04 - val_loss: 3.6622e-04
 - val_f1: 0.9998
Epoch 277/300
 - 24s - loss: 3.5318e-04 - val_loss: 5.6136e-04
 - val_f1: 0.9996
Epoch 278/300
 - 24s - loss: 3.3877e-04 - val_loss: 3.7483e-04
 - val_f1: 0.9998
Epoch 279/300
 - 24s - loss: 3.5316e-04 - val_loss: 3.6310e-04
 - val_f1: 0.9998
Epoch 280/300
 - 24s - loss: 3.5636e-04 - val_loss: 3.5943e-04
 - val_f1: 0.9998
Epoch 281/300
 - 24s - loss: 3.3775e-04 - val_loss: 3.5441e-04
 - val_f1: 0.9998
Epoch 282/300
 - 24s - loss: 3.2923e-04 - val_loss: 3.8214e-04
 - val_f1: 0.9998
Epoch 283/300
 - 24s - loss: 3.4971e-04 - val_loss: 3.5782e-04
 - val_f1: 0.9998
Epoch 284/300
 - 24s - loss: 3.5327e-04 - val_loss: 3.4709e-04
 - val_f1: 0.9998
Epoch 285/300
 - 24s - loss: 3.4229e-04 - val_loss: 3.6633e-04
 - val_f1: 0.9998
Epoch 286/300
 - 24s - loss: 3.2669e-04 - val_loss: 3.5283e-04
 - val_f1: 0.9998
Epoch 287/300
 - 24s - loss: 3.2075e-04 - val_loss: 3.7178e-04
 - val_f1: 0.9998
Epoch 288/300
 - 24s - loss: 3.2172e-04 - val_loss: 3.8036e-04
 - val_f1: 0.9998
Epoch 289/300
 - 24s - loss: 3.5056e-04 - val_loss: 3.5979e-04
 - val_f1: 0.9998
Epoch 290/300
 - 24s - loss: 3.3189e-04 - val_loss: 3.7645e-04
 - val_f1: 0.9998
Epoch 291/300
 - 24s - loss: 3.3104e-04 - val_loss: 3.6409e-04
 - val_f1: 0.9998
Epoch 292/300
 - 24s - loss: 3.3289e-04 - val_loss: 4.1371e-04
 - val_f1: 0.9998
Epoch 293/300
 - 24s - loss: 3.3343e-04 - val_loss: 3.7873e-04
 - val_f1: 0.9998
Epoch 294/300
 - 24s - loss: 3.3540e-04 - val_loss: 3.7459e-04
 - val_f1: 0.9998
Epoch 295/300
 - 24s - loss: 3.3525e-04 - val_loss: 3.8947e-04
 - val_f1: 0.9998
Epoch 296/300
 - 24s - loss: 3.2639e-04 - val_loss: 4.5452e-04
 - val_f1: 0.9998
Epoch 297/300
 - 24s - loss: 3.3772e-04 - val_loss: 3.7079e-04
 - val_f1: 0.9998
Epoch 298/300
 - 24s - loss: 3.4532e-04 - val_loss: 3.6459e-04
 - val_f1: 0.9998
Epoch 299/300
 - 24s - loss: 3.3144e-04 - val_loss: 3.6704e-04
 - val_f1: 0.9998
Epoch 300/300
 - 24s - loss: 3.4967e-04 - val_loss: 3.7250e-04
2019-12-29 23:50:56,492 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-29 23:52:02,667 [INFO] Last epoch loss evaluation: train_loss = 0.000216, val_loss = 0.000341
2019-12-29 23:52:02,681 [INFO] Training complete. time_to_train = 13825.35 sec, 230.42 min
2019-12-29 23:52:02,686 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_shallow_rep4/best_model.pickle
2019-12-29 23:52:02,689 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_shallow_rep4/training_error_history.csv
2019-12-29 23:52:02,876 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep4/training_error_history.png
2019-12-29 23:52:03,037 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep4/training_f1_history.png
2019-12-29 23:52:03,037 [INFO] Making predictions on training, validation, testing data
2019-12-29 23:53:32,540 [INFO] Evaluating predictions (results)
2019-12-29 23:53:41,219 [INFO] Dataset: Testing. Classification report below
2019-12-29 23:53:41,219 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.98      0.84     60593
       probe       0.74      0.80      0.77      4166
         r2l       0.96      0.03      0.05     13781
         u2r       0.70      0.00      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.83      0.56      0.53    311029
weighted avg       0.94      0.92      0.90    311029

2019-12-29 23:53:41,219 [INFO] Overall accuracy (micro avg): 0.9232033025859325
2019-12-29 23:53:50,512 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9232         0.9232                       0.9232                0.0192                   0.0768  0.9232
1     Macro avg        0.9693         0.8257                       0.5567                0.0193                   0.4433  0.5293
2  Weighted avg        0.9684         0.9380                       0.9232                0.0198                   0.0768  0.9042
2019-12-29 23:54:20,659 [INFO] Dataset: Validation. Classification report below
2019-12-29 23:54:20,659 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      0.99      8221
         r2l       0.95      0.87      0.91       225
         u2r       0.67      0.20      0.31        10

    accuracy                           1.00    979687
   macro avg       0.92      0.81      0.84    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-29 23:54:20,659 [INFO] Overall accuracy (micro avg): 0.9998336203297584
2019-12-29 23:54:53,182 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9226                       0.8130                0.0001                   0.1870  0.8423
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-29 23:57:06,203 [INFO] Dataset: Training. Classification report below
2019-12-29 23:57:06,203 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.93      0.90      0.91       901
         u2r       0.79      0.45      0.58        42

    accuracy                           1.00   3918744
   macro avg       0.94      0.87      0.90   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-29 23:57:06,203 [INFO] Overall accuracy (micro avg): 0.9998481656367448
2019-12-29 23:59:29,738 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.9427                       0.8687                0.0001                   0.1313  0.8964
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-29 23:59:29,785 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_shallow_rep4/selected_kdd99_dbn_shallow_rep4_results.xlsx
2019-12-29 23:59:29,792 [INFO] ================= Finished running experiment no. 4 ================= 

2019-12-29 23:59:29,816 [INFO] Created directory: results_selected_models/selected_kdd99_dbn_shallow_rep5
2019-12-29 23:59:29,817 [INFO] Initialized logging. log_filename = results_selected_models/selected_kdd99_dbn_shallow_rep5/run_log.log
2019-12-29 23:59:29,817 [INFO] ================= Running experiment no. 5  ================= 

2019-12-29 23:59:29,817 [INFO] Experiment parameters given below
2019-12-29 23:59:29,817 [INFO] 
{'experiment_num': 5, 'results_dir': 'results_selected_models/selected_kdd99_dbn_shallow_rep5', 'model_type': 'classifier', 'model': 'dbn', 'normal_label': 'normal', 'scaling_type': 'NA', 'dbn_layer_units': [32], 'ann_layer_activations': ['relu'], 'ann_layer_dropout_rates': [0.2], 'unsupervised_ratio': 0.5, 'dbn_learning_rate': 0.0001, 'pretrain_epochs': 50, 'fine_tune_epochs': 300, 'early_stop_patience': 50, 'batch_size': 256, 'dataset_dir': '../Datasets/full_datasets/kdd99_five_classes', 'description': 'selected_kdd99_dbn_shallow_rep5'}
2019-12-29 23:59:29,817 [INFO] Created tensorboard log directory: results_selected_models/selected_kdd99_dbn_shallow_rep5/tf_logs_run_2019_12_29-23_59_29
2019-12-29 23:59:29,817 [INFO] Loading datsets from: ../Datasets/full_datasets/kdd99_five_classes
2019-12-29 23:59:29,817 [INFO] Reading X, y files
2019-12-29 23:59:29,817 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_train.h5
2019-12-29 23:59:36,215 [INFO] Reading complete. time_to_read=6.40 seconds
2019-12-29 23:59:36,215 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_val.h5
2019-12-29 23:59:37,825 [INFO] Reading complete. time_to_read=1.61 seconds
2019-12-29 23:59:37,826 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/X_test.h5
2019-12-29 23:59:38,292 [INFO] Reading complete. time_to_read=0.47 seconds
2019-12-29 23:59:38,292 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_train.h5
2019-12-29 23:59:38,518 [INFO] Reading complete. time_to_read=0.23 seconds
2019-12-29 23:59:38,518 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_val.h5
2019-12-29 23:59:38,572 [INFO] Reading complete. time_to_read=0.05 seconds
2019-12-29 23:59:38,573 [INFO] Reading HDF dataset ../Datasets/full_datasets/kdd99_five_classes/y_test.h5
2019-12-29 23:59:38,592 [INFO] Reading complete. time_to_read=0.02 seconds
2019-12-29 23:59:45,757 [INFO] Initializing model
2019-12-29 23:59:45,758 [INFO] Training model
2019-12-29 23:59:45,758 [INFO] Splitting train set into 2 sets (unsupervised, supervised), random_seed = None
2019-12-30 00:00:26,566 [INFO] Split sizes (instances). total = 3918744, unsupervised = 1959372, supervised = 1959372, unsupervised dataset hash = 9ff7a9c81395f0e9cd4a06d0a794435c58fc45f5
2019-12-30 00:00:26,567 [INFO] Pretraining Deep Belief Network
2019-12-30 00:21:00,623 [INFO] Pretraining Complete
2019-12-30 00:21:00,624 [INFO] Getting pretrained weights
2019-12-30 00:21:00,624 [INFO] Creating and initializing feed forward neural network
2019-12-30 00:21:00,746 [INFO] _________________________________________________________________
2019-12-30 00:21:00,746 [INFO] Layer (type)                 Output Shape              Param #   
2019-12-30 00:21:00,746 [INFO] =================================================================
2019-12-30 00:21:00,746 [INFO] dense_9 (Dense)              (None, 32)                3968      
2019-12-30 00:21:00,746 [INFO] _________________________________________________________________
2019-12-30 00:21:00,747 [INFO] batch_normalization_5 (Batch (None, 32)                128       
2019-12-30 00:21:00,747 [INFO] _________________________________________________________________
2019-12-30 00:21:00,747 [INFO] dropout_5 (Dropout)          (None, 32)                0         
2019-12-30 00:21:00,747 [INFO] _________________________________________________________________
2019-12-30 00:21:00,747 [INFO] dense_10 (Dense)             (None, 5)                 165       
2019-12-30 00:21:00,747 [INFO] =================================================================
2019-12-30 00:21:00,747 [INFO] Total params: 4,261
2019-12-30 00:21:00,747 [INFO] Trainable params: 4,197
2019-12-30 00:21:00,747 [INFO] Non-trainable params: 64
2019-12-30 00:21:00,747 [INFO] _________________________________________________________________
2019-12-30 00:21:01,056 [INFO] Fine-tuning final neural network
 - val_f1: 0.9998
Epoch 00300: early stopping
[BernoulliRBM] Iteration 1, pseudo-likelihood = -42.64, time = 16.55s
[BernoulliRBM] Iteration 2, pseudo-likelihood = -34.06, time = 25.56s
[BernoulliRBM] Iteration 3, pseudo-likelihood = -32.32, time = 25.48s
[BernoulliRBM] Iteration 4, pseudo-likelihood = -34.05, time = 25.39s
[BernoulliRBM] Iteration 5, pseudo-likelihood = -36.54, time = 25.36s
[BernoulliRBM] Iteration 6, pseudo-likelihood = -38.87, time = 25.33s
[BernoulliRBM] Iteration 7, pseudo-likelihood = -41.13, time = 25.30s
[BernoulliRBM] Iteration 8, pseudo-likelihood = -43.41, time = 25.15s
[BernoulliRBM] Iteration 9, pseudo-likelihood = -45.72, time = 25.12s
[BernoulliRBM] Iteration 10, pseudo-likelihood = -48.03, time = 25.11s
[BernoulliRBM] Iteration 11, pseudo-likelihood = -50.29, time = 25.06s
[BernoulliRBM] Iteration 12, pseudo-likelihood = -52.53, time = 25.06s
[BernoulliRBM] Iteration 13, pseudo-likelihood = -54.72, time = 24.99s
[BernoulliRBM] Iteration 14, pseudo-likelihood = -56.80, time = 24.97s
[BernoulliRBM] Iteration 15, pseudo-likelihood = -58.78, time = 24.97s
[BernoulliRBM] Iteration 16, pseudo-likelihood = -60.86, time = 24.71s
[BernoulliRBM] Iteration 17, pseudo-likelihood = -62.97, time = 24.59s
[BernoulliRBM] Iteration 18, pseudo-likelihood = -65.11, time = 24.59s
[BernoulliRBM] Iteration 19, pseudo-likelihood = -67.37, time = 24.73s
[BernoulliRBM] Iteration 20, pseudo-likelihood = -69.58, time = 24.57s
[BernoulliRBM] Iteration 21, pseudo-likelihood = -71.88, time = 24.56s
[BernoulliRBM] Iteration 22, pseudo-likelihood = -74.27, time = 24.56s
[BernoulliRBM] Iteration 23, pseudo-likelihood = -76.61, time = 24.56s
[BernoulliRBM] Iteration 24, pseudo-likelihood = -78.93, time = 24.55s
[BernoulliRBM] Iteration 25, pseudo-likelihood = -81.41, time = 24.53s
[BernoulliRBM] Iteration 26, pseudo-likelihood = -83.78, time = 24.50s
[BernoulliRBM] Iteration 27, pseudo-likelihood = -86.21, time = 24.49s
[BernoulliRBM] Iteration 28, pseudo-likelihood = -88.59, time = 24.48s
[BernoulliRBM] Iteration 29, pseudo-likelihood = -91.02, time = 24.46s
[BernoulliRBM] Iteration 30, pseudo-likelihood = -93.44, time = 24.43s
[BernoulliRBM] Iteration 31, pseudo-likelihood = -95.83, time = 24.44s
[BernoulliRBM] Iteration 32, pseudo-likelihood = -98.27, time = 24.44s
[BernoulliRBM] Iteration 33, pseudo-likelihood = -100.65, time = 24.44s
[BernoulliRBM] Iteration 34, pseudo-likelihood = -103.13, time = 24.43s
[BernoulliRBM] Iteration 35, pseudo-likelihood = -105.60, time = 24.43s
[BernoulliRBM] Iteration 36, pseudo-likelihood = -107.95, time = 24.43s
[BernoulliRBM] Iteration 37, pseudo-likelihood = -110.37, time = 24.43s
[BernoulliRBM] Iteration 38, pseudo-likelihood = -112.82, time = 24.43s
[BernoulliRBM] Iteration 39, pseudo-likelihood = -115.23, time = 24.41s
[BernoulliRBM] Iteration 40, pseudo-likelihood = -117.67, time = 24.41s
[BernoulliRBM] Iteration 41, pseudo-likelihood = -120.05, time = 24.42s
[BernoulliRBM] Iteration 42, pseudo-likelihood = -122.44, time = 24.40s
[BernoulliRBM] Iteration 43, pseudo-likelihood = -124.93, time = 24.40s
[BernoulliRBM] Iteration 44, pseudo-likelihood = -127.33, time = 24.40s
[BernoulliRBM] Iteration 45, pseudo-likelihood = -129.70, time = 24.41s
[BernoulliRBM] Iteration 46, pseudo-likelihood = -132.10, time = 24.40s
[BernoulliRBM] Iteration 47, pseudo-likelihood = -134.58, time = 24.40s
[BernoulliRBM] Iteration 48, pseudo-likelihood = -136.93, time = 24.40s
[BernoulliRBM] Iteration 49, pseudo-likelihood = -139.34, time = 24.40s
[BernoulliRBM] Iteration 50, pseudo-likelihood = -141.76, time = 24.39s
Train on 1959372 samples, validate on 979687 samples
Epoch 1/300
 - 25s - loss: 0.0325 - val_loss: 0.0041
 - val_f1: 0.9977
Epoch 2/300
 - 24s - loss: 0.0047 - val_loss: 0.0025
 - val_f1: 0.9984
Epoch 3/300
 - 24s - loss: 0.0032 - val_loss: 0.0017
 - val_f1: 0.9989
Epoch 4/300
 - 24s - loss: 0.0024 - val_loss: 0.0014
 - val_f1: 0.9991
Epoch 5/300
 - 24s - loss: 0.0021 - val_loss: 0.0012
 - val_f1: 0.9993
Epoch 6/300
 - 24s - loss: 0.0019 - val_loss: 0.0011
 - val_f1: 0.9994
Epoch 7/300
 - 24s - loss: 0.0016 - val_loss: 9.8142e-04
 - val_f1: 0.9994
Epoch 8/300
 - 24s - loss: 0.0015 - val_loss: 9.1605e-04
 - val_f1: 0.9995
Epoch 9/300
 - 24s - loss: 0.0014 - val_loss: 8.4954e-04
 - val_f1: 0.9995
Epoch 10/300
 - 24s - loss: 0.0014 - val_loss: 8.2581e-04
 - val_f1: 0.9995
Epoch 11/300
 - 24s - loss: 0.0013 - val_loss: 8.1149e-04
 - val_f1: 0.9995
Epoch 12/300
 - 24s - loss: 0.0013 - val_loss: 7.8714e-04
 - val_f1: 0.9996
Epoch 13/300
 - 24s - loss: 0.0012 - val_loss: 7.4367e-04
 - val_f1: 0.9996
Epoch 14/300
 - 24s - loss: 0.0012 - val_loss: 7.1893e-04
 - val_f1: 0.9996
Epoch 15/300
 - 24s - loss: 0.0011 - val_loss: 7.4098e-04
 - val_f1: 0.9996
Epoch 16/300
 - 24s - loss: 0.0011 - val_loss: 7.0724e-04
 - val_f1: 0.9996
Epoch 17/300
 - 24s - loss: 0.0011 - val_loss: 6.8713e-04
 - val_f1: 0.9996
Epoch 18/300
 - 24s - loss: 0.0011 - val_loss: 6.6433e-04
 - val_f1: 0.9997
Epoch 19/300
 - 24s - loss: 0.0011 - val_loss: 6.5808e-04
 - val_f1: 0.9997
Epoch 20/300
 - 24s - loss: 0.0010 - val_loss: 6.5042e-04
 - val_f1: 0.9997
Epoch 21/300
 - 24s - loss: 9.5943e-04 - val_loss: 6.6703e-04
 - val_f1: 0.9997
Epoch 22/300
 - 24s - loss: 9.5488e-04 - val_loss: 6.7260e-04
 - val_f1: 0.9996
Epoch 23/300
 - 24s - loss: 9.2297e-04 - val_loss: 6.0676e-04
 - val_f1: 0.9997
Epoch 24/300
 - 24s - loss: 9.2289e-04 - val_loss: 6.5707e-04
 - val_f1: 0.9997
Epoch 25/300
 - 24s - loss: 8.8524e-04 - val_loss: 6.0501e-04
 - val_f1: 0.9997
Epoch 26/300
 - 24s - loss: 8.8439e-04 - val_loss: 6.1551e-04
 - val_f1: 0.9997
Epoch 27/300
 - 24s - loss: 8.9016e-04 - val_loss: 5.9836e-04
 - val_f1: 0.9997
Epoch 28/300
 - 24s - loss: 8.2072e-04 - val_loss: 6.0062e-04
 - val_f1: 0.9997
Epoch 29/300
 - 24s - loss: 8.4709e-04 - val_loss: 5.8919e-04
 - val_f1: 0.9997
Epoch 30/300
 - 24s - loss: 8.5394e-04 - val_loss: 5.9065e-04
 - val_f1: 0.9997
Epoch 31/300
 - 24s - loss: 8.0136e-04 - val_loss: 5.8193e-04
/home/sunanda/anaconda3/envs/ml_env_cpu/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
2019-12-30 00:42:58,077 [INFO] epoch = 30. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_30.pickle
 - val_f1: 0.9997
Epoch 32/300
 - 24s - loss: 8.3863e-04 - val_loss: 5.5890e-04
 - val_f1: 0.9997
Epoch 33/300
 - 24s - loss: 7.9391e-04 - val_loss: 5.6863e-04
 - val_f1: 0.9996
Epoch 34/300
 - 24s - loss: 7.7455e-04 - val_loss: 5.4274e-04
 - val_f1: 0.9997
Epoch 35/300
 - 25s - loss: 7.4977e-04 - val_loss: 5.4753e-04
 - val_f1: 0.9997
Epoch 36/300
 - 24s - loss: 7.3319e-04 - val_loss: 5.3593e-04
 - val_f1: 0.9997
Epoch 37/300
 - 24s - loss: 7.3222e-04 - val_loss: 5.2202e-04
 - val_f1: 0.9997
Epoch 38/300
 - 24s - loss: 7.2528e-04 - val_loss: 5.4010e-04
 - val_f1: 0.9997
Epoch 39/300
 - 24s - loss: 7.1359e-04 - val_loss: 5.2187e-04
 - val_f1: 0.9997
Epoch 40/300
 - 24s - loss: 7.2705e-04 - val_loss: 5.2819e-04
 - val_f1: 0.9997
Epoch 41/300
 - 24s - loss: 7.0808e-04 - val_loss: 5.1121e-04
 - val_f1: 0.9997
Epoch 42/300
 - 24s - loss: 6.9737e-04 - val_loss: 5.0561e-04
 - val_f1: 0.9997
Epoch 43/300
 - 24s - loss: 7.0599e-04 - val_loss: 5.2171e-04
 - val_f1: 0.9997
Epoch 44/300
 - 24s - loss: 6.8606e-04 - val_loss: 5.1277e-04
 - val_f1: 0.9997
Epoch 45/300
 - 24s - loss: 6.3742e-04 - val_loss: 5.0867e-04
 - val_f1: 0.9997
Epoch 46/300
 - 24s - loss: 6.4740e-04 - val_loss: 5.0151e-04
 - val_f1: 0.9997
Epoch 47/300
 - 24s - loss: 6.5624e-04 - val_loss: 4.9161e-04
 - val_f1: 0.9997
Epoch 48/300
 - 24s - loss: 6.5451e-04 - val_loss: 4.6578e-04
 - val_f1: 0.9997
Epoch 49/300
 - 24s - loss: 6.3920e-04 - val_loss: 4.6704e-04
 - val_f1: 0.9997
Epoch 50/300
 - 24s - loss: 6.4872e-04 - val_loss: 4.7122e-04
 - val_f1: 0.9997
Epoch 51/300
 - 24s - loss: 6.3462e-04 - val_loss: 4.6137e-04
 - val_f1: 0.9997
Epoch 52/300
 - 24s - loss: 6.1891e-04 - val_loss: 4.6960e-04
 - val_f1: 0.9997
Epoch 53/300
 - 24s - loss: 6.0522e-04 - val_loss: 4.7288e-04
 - val_f1: 0.9997
Epoch 54/300
 - 24s - loss: 5.6330e-04 - val_loss: 4.6168e-04
 - val_f1: 0.9997
Epoch 55/300
 - 24s - loss: 5.8635e-04 - val_loss: 4.4892e-04
 - val_f1: 0.9997
Epoch 56/300
 - 24s - loss: 5.9668e-04 - val_loss: 4.6438e-04
 - val_f1: 0.9997
Epoch 57/300
 - 24s - loss: 5.7710e-04 - val_loss: 4.5384e-04
 - val_f1: 0.9997
Epoch 58/300
 - 24s - loss: 5.9179e-04 - val_loss: 4.5042e-04
 - val_f1: 0.9997
Epoch 59/300
 - 24s - loss: 5.7225e-04 - val_loss: 4.7936e-04
 - val_f1: 0.9997
Epoch 60/300
 - 24s - loss: 5.8431e-04 - val_loss: 4.5924e-04
 - val_f1: 0.9997
Epoch 61/300
 - 24s - loss: 5.6904e-04 - val_loss: 4.4981e-04
2019-12-30 01:04:28,430 [INFO] epoch = 60. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_60.pickle
 - val_f1: 0.9997
Epoch 62/300
 - 24s - loss: 5.7507e-04 - val_loss: 4.5913e-04
 - val_f1: 0.9997
Epoch 63/300
 - 24s - loss: 5.8109e-04 - val_loss: 4.4457e-04
 - val_f1: 0.9997
Epoch 64/300
 - 24s - loss: 5.6669e-04 - val_loss: 4.6409e-04
 - val_f1: 0.9997
Epoch 65/300
 - 24s - loss: 5.7032e-04 - val_loss: 4.5923e-04
 - val_f1: 0.9997
Epoch 66/300
 - 24s - loss: 5.5754e-04 - val_loss: 4.4777e-04
 - val_f1: 0.9997
Epoch 67/300
 - 24s - loss: 5.5307e-04 - val_loss: 4.5785e-04
 - val_f1: 0.9997
Epoch 68/300
 - 24s - loss: 5.5767e-04 - val_loss: 4.5051e-04
 - val_f1: 0.9997
Epoch 69/300
 - 24s - loss: 5.2785e-04 - val_loss: 4.4208e-04
 - val_f1: 0.9998
Epoch 70/300
 - 24s - loss: 5.4094e-04 - val_loss: 4.4869e-04
 - val_f1: 0.9997
Epoch 71/300
 - 24s - loss: 5.2018e-04 - val_loss: 4.4495e-04
 - val_f1: 0.9998
Epoch 72/300
 - 24s - loss: 5.3864e-04 - val_loss: 4.4678e-04
 - val_f1: 0.9997
Epoch 73/300
 - 24s - loss: 5.3600e-04 - val_loss: 4.4834e-04
 - val_f1: 0.9997
Epoch 74/300
 - 24s - loss: 5.2523e-04 - val_loss: 4.7788e-04
 - val_f1: 0.9997
Epoch 75/300
 - 24s - loss: 5.3099e-04 - val_loss: 4.4403e-04
 - val_f1: 0.9997
Epoch 76/300
 - 24s - loss: 5.2424e-04 - val_loss: 4.4659e-04
 - val_f1: 0.9997
Epoch 77/300
 - 24s - loss: 5.1522e-04 - val_loss: 4.5814e-04
 - val_f1: 0.9997
Epoch 78/300
 - 24s - loss: 5.2924e-04 - val_loss: 4.4297e-04
 - val_f1: 0.9998
Epoch 79/300
 - 24s - loss: 5.2153e-04 - val_loss: 4.3113e-04
 - val_f1: 0.9998
Epoch 80/300
 - 24s - loss: 5.1013e-04 - val_loss: 4.0701e-04
 - val_f1: 0.9998
Epoch 81/300
 - 24s - loss: 5.2929e-04 - val_loss: 4.2092e-04
 - val_f1: 0.9998
Epoch 82/300
 - 24s - loss: 5.2864e-04 - val_loss: 4.3869e-04
 - val_f1: 0.9998
Epoch 83/300
 - 24s - loss: 5.0961e-04 - val_loss: 4.3826e-04
 - val_f1: 0.9998
Epoch 84/300
 - 24s - loss: 5.0391e-04 - val_loss: 4.1120e-04
 - val_f1: 0.9998
Epoch 85/300
 - 24s - loss: 5.2574e-04 - val_loss: 4.1694e-04
 - val_f1: 0.9998
Epoch 86/300
 - 24s - loss: 5.0276e-04 - val_loss: 4.2549e-04
 - val_f1: 0.9998
Epoch 87/300
 - 24s - loss: 4.8361e-04 - val_loss: 4.1993e-04
 - val_f1: 0.9998
Epoch 88/300
 - 24s - loss: 5.1484e-04 - val_loss: 4.2695e-04
 - val_f1: 0.9998
Epoch 89/300
 - 24s - loss: 4.9851e-04 - val_loss: 4.2394e-04
 - val_f1: 0.9998
Epoch 90/300
 - 24s - loss: 4.9618e-04 - val_loss: 4.2663e-04
 - val_f1: 0.9997
Epoch 91/300
 - 24s - loss: 5.1162e-04 - val_loss: 4.0581e-04
2019-12-30 01:25:52,599 [INFO] epoch = 90. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_90.pickle
 - val_f1: 0.9998
Epoch 92/300
 - 24s - loss: 5.1630e-04 - val_loss: 4.2325e-04
 - val_f1: 0.9998
Epoch 93/300
 - 24s - loss: 5.1343e-04 - val_loss: 4.2597e-04
 - val_f1: 0.9998
Epoch 94/300
 - 24s - loss: 4.8950e-04 - val_loss: 4.4743e-04
 - val_f1: 0.9998
Epoch 95/300
 - 24s - loss: 4.9956e-04 - val_loss: 4.4046e-04
 - val_f1: 0.9998
Epoch 96/300
 - 24s - loss: 5.0044e-04 - val_loss: 4.4676e-04
 - val_f1: 0.9998
Epoch 97/300
 - 24s - loss: 4.9764e-04 - val_loss: 4.3279e-04
 - val_f1: 0.9998
Epoch 98/300
 - 24s - loss: 4.9489e-04 - val_loss: 4.2687e-04
 - val_f1: 0.9998
Epoch 99/300
 - 24s - loss: 4.6798e-04 - val_loss: 4.2496e-04
 - val_f1: 0.9998
Epoch 100/300
 - 24s - loss: 5.0255e-04 - val_loss: 4.1273e-04
 - val_f1: 0.9998
Epoch 101/300
 - 24s - loss: 4.9445e-04 - val_loss: 4.3405e-04
 - val_f1: 0.9998
Epoch 102/300
 - 24s - loss: 4.8793e-04 - val_loss: 4.2586e-04
 - val_f1: 0.9998
Epoch 103/300
 - 24s - loss: 4.8292e-04 - val_loss: 4.3219e-04
 - val_f1: 0.9998
Epoch 104/300
 - 24s - loss: 4.7398e-04 - val_loss: 4.2149e-04
 - val_f1: 0.9998
Epoch 105/300
 - 24s - loss: 5.1192e-04 - val_loss: 4.3151e-04
 - val_f1: 0.9998
Epoch 106/300
 - 24s - loss: 4.7742e-04 - val_loss: 4.2569e-04
 - val_f1: 0.9998
Epoch 107/300
 - 24s - loss: 4.8068e-04 - val_loss: 4.4201e-04
 - val_f1: 0.9998
Epoch 108/300
 - 24s - loss: 4.7386e-04 - val_loss: 4.0907e-04
 - val_f1: 0.9998
Epoch 109/300
 - 24s - loss: 4.8587e-04 - val_loss: 4.0637e-04
 - val_f1: 0.9998
Epoch 110/300
 - 24s - loss: 4.7616e-04 - val_loss: 4.2273e-04
 - val_f1: 0.9998
Epoch 111/300
 - 24s - loss: 4.8160e-04 - val_loss: 4.1100e-04
 - val_f1: 0.9998
Epoch 112/300
 - 24s - loss: 4.7784e-04 - val_loss: 4.1586e-04
 - val_f1: 0.9998
Epoch 113/300
 - 24s - loss: 4.8258e-04 - val_loss: 4.1384e-04
 - val_f1: 0.9998
Epoch 114/300
 - 24s - loss: 4.6217e-04 - val_loss: 4.0284e-04
 - val_f1: 0.9998
Epoch 115/300
 - 24s - loss: 4.7776e-04 - val_loss: 6.4586e-04
 - val_f1: 0.9996
Epoch 116/300
 - 24s - loss: 4.7546e-04 - val_loss: 4.2608e-04
 - val_f1: 0.9998
Epoch 117/300
 - 24s - loss: 4.6023e-04 - val_loss: 4.1403e-04
 - val_f1: 0.9998
Epoch 118/300
 - 24s - loss: 4.7448e-04 - val_loss: 4.1415e-04
 - val_f1: 0.9998
Epoch 119/300
 - 24s - loss: 4.6722e-04 - val_loss: 4.4168e-04
 - val_f1: 0.9998
Epoch 120/300
 - 24s - loss: 4.7319e-04 - val_loss: 4.0444e-04
 - val_f1: 0.9998
Epoch 121/300
 - 24s - loss: 4.7377e-04 - val_loss: 4.1641e-04
2019-12-30 01:47:17,129 [INFO] epoch = 120. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_120.pickle
 - val_f1: 0.9998
Epoch 122/300
 - 24s - loss: 4.6548e-04 - val_loss: 4.2309e-04
 - val_f1: 0.9998
Epoch 123/300
 - 24s - loss: 4.5796e-04 - val_loss: 4.3449e-04
 - val_f1: 0.9998
Epoch 124/300
 - 24s - loss: 4.4911e-04 - val_loss: 4.2350e-04
 - val_f1: 0.9998
Epoch 125/300
 - 24s - loss: 4.7770e-04 - val_loss: 3.9890e-04
 - val_f1: 0.9998
Epoch 126/300
 - 24s - loss: 4.4370e-04 - val_loss: 4.0291e-04
 - val_f1: 0.9998
Epoch 127/300
 - 24s - loss: 4.6664e-04 - val_loss: 4.0279e-04
 - val_f1: 0.9998
Epoch 128/300
 - 24s - loss: 4.5985e-04 - val_loss: 3.9098e-04
 - val_f1: 0.9998
Epoch 129/300
 - 24s - loss: 4.5210e-04 - val_loss: 4.0679e-04
 - val_f1: 0.9998
Epoch 130/300
 - 24s - loss: 4.5695e-04 - val_loss: 4.0480e-04
 - val_f1: 0.9998
Epoch 131/300
 - 24s - loss: 4.6531e-04 - val_loss: 4.1241e-04
 - val_f1: 0.9998
Epoch 132/300
 - 24s - loss: 4.6504e-04 - val_loss: 3.8708e-04
 - val_f1: 0.9998
Epoch 133/300
 - 24s - loss: 4.4997e-04 - val_loss: 4.0378e-04
 - val_f1: 0.9998
Epoch 134/300
 - 24s - loss: 4.5690e-04 - val_loss: 3.7414e-04
 - val_f1: 0.9998
Epoch 135/300
 - 24s - loss: 4.5524e-04 - val_loss: 4.0382e-04
 - val_f1: 0.9998
Epoch 136/300
 - 24s - loss: 4.4631e-04 - val_loss: 4.2353e-04
 - val_f1: 0.9998
Epoch 137/300
 - 24s - loss: 4.6613e-04 - val_loss: 3.9311e-04
 - val_f1: 0.9998
Epoch 138/300
 - 24s - loss: 4.4039e-04 - val_loss: 3.8484e-04
 - val_f1: 0.9998
Epoch 139/300
 - 24s - loss: 4.3980e-04 - val_loss: 4.5142e-04
 - val_f1: 0.9997
Epoch 140/300
 - 24s - loss: 4.3321e-04 - val_loss: 3.9460e-04
 - val_f1: 0.9998
Epoch 141/300
 - 24s - loss: 4.3302e-04 - val_loss: 3.8388e-04
 - val_f1: 0.9998
Epoch 142/300
 - 24s - loss: 4.3896e-04 - val_loss: 3.9995e-04
 - val_f1: 0.9998
Epoch 143/300
 - 24s - loss: 4.4907e-04 - val_loss: 3.9035e-04
 - val_f1: 0.9998
Epoch 144/300
 - 24s - loss: 4.3990e-04 - val_loss: 4.0985e-04
 - val_f1: 0.9998
Epoch 145/300
 - 24s - loss: 4.3435e-04 - val_loss: 3.8604e-04
 - val_f1: 0.9998
Epoch 146/300
 - 24s - loss: 4.5026e-04 - val_loss: 3.8695e-04
 - val_f1: 0.9998
Epoch 147/300
 - 24s - loss: 4.3584e-04 - val_loss: 4.0513e-04
 - val_f1: 0.9998
Epoch 148/300
 - 24s - loss: 4.3105e-04 - val_loss: 3.9111e-04
 - val_f1: 0.9998
Epoch 149/300
 - 24s - loss: 4.3478e-04 - val_loss: 4.1469e-04
 - val_f1: 0.9998
Epoch 150/300
 - 24s - loss: 4.6189e-04 - val_loss: 3.8948e-04
 - val_f1: 0.9998
Epoch 151/300
 - 24s - loss: 4.3274e-04 - val_loss: 4.0326e-04
2019-12-30 02:08:41,791 [INFO] epoch = 150. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_150.pickle
 - val_f1: 0.9998
Epoch 152/300
 - 24s - loss: 4.2270e-04 - val_loss: 4.0832e-04
 - val_f1: 0.9998
Epoch 153/300
 - 24s - loss: 4.3729e-04 - val_loss: 3.8534e-04
 - val_f1: 0.9998
Epoch 154/300
 - 24s - loss: 4.3033e-04 - val_loss: 4.0000e-04
 - val_f1: 0.9998
Epoch 155/300
 - 24s - loss: 4.3206e-04 - val_loss: 3.9988e-04
 - val_f1: 0.9998
Epoch 156/300
 - 24s - loss: 4.3131e-04 - val_loss: 4.0616e-04
 - val_f1: 0.9998
Epoch 157/300
 - 24s - loss: 4.4639e-04 - val_loss: 4.0136e-04
 - val_f1: 0.9998
Epoch 158/300
 - 24s - loss: 4.3493e-04 - val_loss: 4.0372e-04
 - val_f1: 0.9998
Epoch 159/300
 - 24s - loss: 4.3339e-04 - val_loss: 3.9111e-04
 - val_f1: 0.9998
Epoch 160/300
 - 24s - loss: 4.3405e-04 - val_loss: 3.9075e-04
 - val_f1: 0.9998
Epoch 161/300
 - 24s - loss: 4.3113e-04 - val_loss: 4.1046e-04
 - val_f1: 0.9998
Epoch 162/300
 - 24s - loss: 4.2609e-04 - val_loss: 4.0266e-04
 - val_f1: 0.9998
Epoch 163/300
 - 24s - loss: 4.3965e-04 - val_loss: 4.0156e-04
 - val_f1: 0.9998
Epoch 164/300
 - 24s - loss: 4.2291e-04 - val_loss: 5.2131e-04
 - val_f1: 0.9997
Epoch 165/300
 - 24s - loss: 4.3202e-04 - val_loss: 3.9779e-04
 - val_f1: 0.9998
Epoch 166/300
 - 24s - loss: 4.2218e-04 - val_loss: 3.9717e-04
 - val_f1: 0.9998
Epoch 167/300
 - 24s - loss: 4.0603e-04 - val_loss: 3.8839e-04
 - val_f1: 0.9998
Epoch 168/300
 - 24s - loss: 4.0286e-04 - val_loss: 4.0388e-04
 - val_f1: 0.9998
Epoch 169/300
 - 24s - loss: 4.2606e-04 - val_loss: 4.1319e-04
 - val_f1: 0.9998
Epoch 170/300
 - 24s - loss: 4.1772e-04 - val_loss: 3.9215e-04
 - val_f1: 0.9998
Epoch 171/300
 - 24s - loss: 4.1877e-04 - val_loss: 3.9882e-04
 - val_f1: 0.9998
Epoch 172/300
 - 24s - loss: 4.2280e-04 - val_loss: 4.3357e-04
 - val_f1: 0.9998
Epoch 173/300
 - 24s - loss: 4.0959e-04 - val_loss: 4.1598e-04
 - val_f1: 0.9998
Epoch 174/300
 - 24s - loss: 4.2293e-04 - val_loss: 4.0888e-04
 - val_f1: 0.9998
Epoch 175/300
 - 24s - loss: 4.1935e-04 - val_loss: 3.9958e-04
 - val_f1: 0.9998
Epoch 176/300
 - 24s - loss: 3.9011e-04 - val_loss: 3.9620e-04
 - val_f1: 0.9998
Epoch 177/300
 - 24s - loss: 4.1939e-04 - val_loss: 4.0513e-04
 - val_f1: 0.9998
Epoch 178/300
 - 24s - loss: 4.2069e-04 - val_loss: 4.9059e-04
 - val_f1: 0.9997
Epoch 179/300
 - 24s - loss: 4.1917e-04 - val_loss: 3.9964e-04
 - val_f1: 0.9998
Epoch 180/300
 - 24s - loss: 4.0834e-04 - val_loss: 3.9224e-04
 - val_f1: 0.9998
Epoch 181/300
 - 24s - loss: 4.1460e-04 - val_loss: 3.8854e-04
2019-12-30 02:30:07,231 [INFO] epoch = 180. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_180.pickle
 - val_f1: 0.9998
Epoch 182/300
 - 24s - loss: 4.1807e-04 - val_loss: 3.8344e-04
 - val_f1: 0.9998
Epoch 183/300
 - 24s - loss: 4.1167e-04 - val_loss: 3.7855e-04
 - val_f1: 0.9998
Epoch 184/300
 - 24s - loss: 4.2401e-04 - val_loss: 3.7357e-04
 - val_f1: 0.9998
Epoch 185/300
 - 24s - loss: 4.0341e-04 - val_loss: 3.8792e-04
 - val_f1: 0.9998
Epoch 186/300
 - 24s - loss: 4.0109e-04 - val_loss: 4.0294e-04
 - val_f1: 0.9998
Epoch 187/300
 - 24s - loss: 4.0117e-04 - val_loss: 3.7829e-04
 - val_f1: 0.9998
Epoch 188/300
 - 24s - loss: 4.1019e-04 - val_loss: 4.0431e-04
 - val_f1: 0.9998
Epoch 189/300
 - 24s - loss: 3.9296e-04 - val_loss: 3.8575e-04
 - val_f1: 0.9998
Epoch 190/300
 - 24s - loss: 3.9070e-04 - val_loss: 3.8902e-04
 - val_f1: 0.9998
Epoch 191/300
 - 24s - loss: 4.0220e-04 - val_loss: 3.8069e-04
 - val_f1: 0.9998
Epoch 192/300
 - 24s - loss: 3.8225e-04 - val_loss: 4.4449e-04
 - val_f1: 0.9998
Epoch 193/300
 - 24s - loss: 3.8083e-04 - val_loss: 3.8608e-04
 - val_f1: 0.9998
Epoch 194/300
 - 24s - loss: 4.1248e-04 - val_loss: 3.9679e-04
 - val_f1: 0.9998
Epoch 195/300
 - 24s - loss: 3.9921e-04 - val_loss: 3.9990e-04
 - val_f1: 0.9998
Epoch 196/300
 - 24s - loss: 3.8099e-04 - val_loss: 3.6665e-04
 - val_f1: 0.9998
Epoch 197/300
 - 24s - loss: 3.7857e-04 - val_loss: 3.8312e-04
 - val_f1: 0.9998
Epoch 198/300
 - 24s - loss: 3.8758e-04 - val_loss: 3.6889e-04
 - val_f1: 0.9998
Epoch 199/300
 - 24s - loss: 3.9328e-04 - val_loss: 3.8250e-04
 - val_f1: 0.9998
Epoch 200/300
 - 24s - loss: 3.9082e-04 - val_loss: 3.6614e-04
 - val_f1: 0.9998
Epoch 201/300
 - 24s - loss: 3.8590e-04 - val_loss: 3.6971e-04
 - val_f1: 0.9998
Epoch 202/300
 - 24s - loss: 4.0606e-04 - val_loss: 3.8261e-04
 - val_f1: 0.9998
Epoch 203/300
 - 24s - loss: 3.7937e-04 - val_loss: 3.9867e-04
 - val_f1: 0.9998
Epoch 204/300
 - 24s - loss: 3.8223e-04 - val_loss: 4.4393e-04
 - val_f1: 0.9998
Epoch 205/300
 - 24s - loss: 3.9166e-04 - val_loss: 3.7743e-04
 - val_f1: 0.9998
Epoch 206/300
 - 24s - loss: 3.6770e-04 - val_loss: 3.7384e-04
 - val_f1: 0.9998
Epoch 207/300
 - 24s - loss: 3.6817e-04 - val_loss: 3.8235e-04
 - val_f1: 0.9998
Epoch 208/300
 - 24s - loss: 3.9164e-04 - val_loss: 3.8839e-04
 - val_f1: 0.9998
Epoch 209/300
 - 24s - loss: 3.8171e-04 - val_loss: 3.9031e-04
 - val_f1: 0.9998
Epoch 210/300
 - 24s - loss: 3.7798e-04 - val_loss: 3.7974e-04
 - val_f1: 0.9998
Epoch 211/300
 - 24s - loss: 3.7057e-04 - val_loss: 3.8781e-04
2019-12-30 02:51:30,961 [INFO] epoch = 210. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_210.pickle
 - val_f1: 0.9998
Epoch 212/300
 - 24s - loss: 3.7954e-04 - val_loss: 3.9436e-04
 - val_f1: 0.9998
Epoch 213/300
 - 24s - loss: 3.7770e-04 - val_loss: 3.8766e-04
 - val_f1: 0.9998
Epoch 214/300
 - 24s - loss: 3.7871e-04 - val_loss: 3.6671e-04
 - val_f1: 0.9998
Epoch 215/300
 - 24s - loss: 3.7114e-04 - val_loss: 3.8124e-04
 - val_f1: 0.9998
Epoch 216/300
 - 24s - loss: 3.5596e-04 - val_loss: 6.4763e-04
 - val_f1: 0.9996
Epoch 217/300
 - 24s - loss: 3.7780e-04 - val_loss: 3.7596e-04
 - val_f1: 0.9998
Epoch 218/300
 - 24s - loss: 3.6707e-04 - val_loss: 3.8773e-04
 - val_f1: 0.9998
Epoch 219/300
 - 24s - loss: 3.7149e-04 - val_loss: 4.0052e-04
 - val_f1: 0.9998
Epoch 220/300
 - 24s - loss: 3.6874e-04 - val_loss: 3.7156e-04
 - val_f1: 0.9998
Epoch 221/300
 - 24s - loss: 3.5604e-04 - val_loss: 3.8365e-04
 - val_f1: 0.9998
Epoch 222/300
 - 24s - loss: 3.8538e-04 - val_loss: 3.7986e-04
 - val_f1: 0.9998
Epoch 223/300
 - 24s - loss: 3.7138e-04 - val_loss: 3.5876e-04
 - val_f1: 0.9998
Epoch 224/300
 - 24s - loss: 3.5687e-04 - val_loss: 3.8522e-04
 - val_f1: 0.9998
Epoch 225/300
 - 24s - loss: 3.6429e-04 - val_loss: 3.8803e-04
 - val_f1: 0.9998
Epoch 226/300
 - 24s - loss: 3.8557e-04 - val_loss: 4.0970e-04
 - val_f1: 0.9998
Epoch 227/300
 - 24s - loss: 3.6342e-04 - val_loss: 3.7214e-04
 - val_f1: 0.9998
Epoch 228/300
 - 24s - loss: 3.7652e-04 - val_loss: 4.0139e-04
 - val_f1: 0.9998
Epoch 229/300
 - 24s - loss: 3.7223e-04 - val_loss: 3.8701e-04
 - val_f1: 0.9998
Epoch 230/300
 - 24s - loss: 3.5650e-04 - val_loss: 4.1711e-04
 - val_f1: 0.9998
Epoch 231/300
 - 24s - loss: 3.4710e-04 - val_loss: 3.8436e-04
 - val_f1: 0.9998
Epoch 232/300
 - 24s - loss: 3.7931e-04 - val_loss: 7.3186e-04
 - val_f1: 0.9995
Epoch 233/300
 - 24s - loss: 3.6874e-04 - val_loss: 3.9611e-04
 - val_f1: 0.9998
Epoch 234/300
 - 24s - loss: 3.5744e-04 - val_loss: 3.9132e-04
 - val_f1: 0.9998
Epoch 235/300
 - 24s - loss: 3.6929e-04 - val_loss: 3.8716e-04
 - val_f1: 0.9998
Epoch 236/300
 - 24s - loss: 3.6715e-04 - val_loss: 3.8417e-04
 - val_f1: 0.9998
Epoch 237/300
 - 24s - loss: 3.7230e-04 - val_loss: 3.5210e-04
 - val_f1: 0.9998
Epoch 238/300
 - 24s - loss: 3.5082e-04 - val_loss: 3.5443e-04
 - val_f1: 0.9998
Epoch 239/300
 - 24s - loss: 3.8287e-04 - val_loss: 3.3840e-04
 - val_f1: 0.9998
Epoch 240/300
 - 24s - loss: 3.6000e-04 - val_loss: 4.1743e-04
 - val_f1: 0.9998
Epoch 241/300
 - 24s - loss: 3.7346e-04 - val_loss: 3.5795e-04
2019-12-30 03:12:56,230 [INFO] epoch = 240. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_240.pickle
 - val_f1: 0.9998
Epoch 242/300
 - 24s - loss: 3.7322e-04 - val_loss: 3.5976e-04
 - val_f1: 0.9998
Epoch 243/300
 - 24s - loss: 3.7954e-04 - val_loss: 3.5818e-04
 - val_f1: 0.9998
Epoch 244/300
 - 24s - loss: 3.7114e-04 - val_loss: 3.7273e-04
 - val_f1: 0.9998
Epoch 245/300
 - 24s - loss: 3.7111e-04 - val_loss: 3.7494e-04
 - val_f1: 0.9998
Epoch 246/300
 - 24s - loss: 3.8996e-04 - val_loss: 3.5752e-04
 - val_f1: 0.9998
Epoch 247/300
 - 24s - loss: 3.6021e-04 - val_loss: 3.5116e-04
 - val_f1: 0.9998
Epoch 248/300
 - 24s - loss: 3.7435e-04 - val_loss: 3.6697e-04
 - val_f1: 0.9998
Epoch 249/300
 - 24s - loss: 3.5909e-04 - val_loss: 3.5496e-04
 - val_f1: 0.9998
Epoch 250/300
 - 24s - loss: 3.7955e-04 - val_loss: 3.6856e-04
 - val_f1: 0.9998
Epoch 251/300
 - 24s - loss: 3.6595e-04 - val_loss: 3.9868e-04
 - val_f1: 0.9998
Epoch 252/300
 - 24s - loss: 3.5178e-04 - val_loss: 3.7376e-04
 - val_f1: 0.9998
Epoch 253/300
 - 24s - loss: 3.6051e-04 - val_loss: 3.7731e-04
 - val_f1: 0.9998
Epoch 254/300
 - 24s - loss: 3.5536e-04 - val_loss: 4.0460e-04
 - val_f1: 0.9998
Epoch 255/300
 - 24s - loss: 3.6112e-04 - val_loss: 3.6305e-04
 - val_f1: 0.9998
Epoch 256/300
 - 24s - loss: 3.5922e-04 - val_loss: 3.7929e-04
 - val_f1: 0.9998
Epoch 257/300
 - 24s - loss: 3.7795e-04 - val_loss: 3.5362e-04
 - val_f1: 0.9998
Epoch 258/300
 - 24s - loss: 3.6951e-04 - val_loss: 4.6242e-04
 - val_f1: 0.9997
Epoch 259/300
 - 24s - loss: 3.6026e-04 - val_loss: 3.8050e-04
 - val_f1: 0.9998
Epoch 260/300
 - 24s - loss: 3.5664e-04 - val_loss: 3.6079e-04
 - val_f1: 0.9998
Epoch 261/300
 - 24s - loss: 3.7920e-04 - val_loss: 3.6464e-04
 - val_f1: 0.9998
Epoch 262/300
 - 24s - loss: 3.6004e-04 - val_loss: 3.7966e-04
 - val_f1: 0.9998
Epoch 263/300
 - 24s - loss: 3.7079e-04 - val_loss: 4.3340e-04
 - val_f1: 0.9997
Epoch 264/300
 - 24s - loss: 3.5840e-04 - val_loss: 3.9052e-04
 - val_f1: 0.9998
Epoch 265/300
 - 24s - loss: 3.6431e-04 - val_loss: 3.7231e-04
 - val_f1: 0.9998
Epoch 266/300
 - 24s - loss: 3.6978e-04 - val_loss: 3.5463e-04
 - val_f1: 0.9998
Epoch 267/300
 - 24s - loss: 3.5296e-04 - val_loss: 3.4947e-04
 - val_f1: 0.9998
Epoch 268/300
 - 24s - loss: 3.6385e-04 - val_loss: 3.9647e-04
 - val_f1: 0.9998
Epoch 269/300
 - 24s - loss: 3.4589e-04 - val_loss: 3.4823e-04
 - val_f1: 0.9998
Epoch 270/300
 - 24s - loss: 3.7346e-04 - val_loss: 3.6638e-04
 - val_f1: 0.9998
Epoch 271/300
 - 24s - loss: 3.5815e-04 - val_loss: 3.8296e-04
2019-12-30 03:34:21,695 [INFO] epoch = 270. Intermediate model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/ann_model_epoch_270.pickle
 - val_f1: 0.9998
Epoch 272/300
 - 24s - loss: 3.4225e-04 - val_loss: 3.7536e-04
 - val_f1: 0.9998
Epoch 273/300
 - 24s - loss: 3.5599e-04 - val_loss: 3.7114e-04
 - val_f1: 0.9998
Epoch 274/300
 - 24s - loss: 3.7239e-04 - val_loss: 3.6844e-04
 - val_f1: 0.9998
Epoch 275/300
 - 24s - loss: 3.5902e-04 - val_loss: 5.3102e-04
 - val_f1: 0.9997
Epoch 276/300
 - 24s - loss: 3.7219e-04 - val_loss: 3.8139e-04
 - val_f1: 0.9998
Epoch 277/300
 - 24s - loss: 3.5361e-04 - val_loss: 4.2308e-04
 - val_f1: 0.9998
Epoch 278/300
 - 24s - loss: 3.6693e-04 - val_loss: 4.0259e-04
 - val_f1: 0.9998
Epoch 279/300
 - 24s - loss: 3.4079e-04 - val_loss: 3.8554e-04
 - val_f1: 0.9998
Epoch 280/300
 - 24s - loss: 3.5568e-04 - val_loss: 3.5155e-04
 - val_f1: 0.9998
Epoch 281/300
 - 24s - loss: 3.5057e-04 - val_loss: 3.8479e-04
 - val_f1: 0.9998
Epoch 282/300
 - 24s - loss: 3.5725e-04 - val_loss: 3.6134e-04
 - val_f1: 0.9998
Epoch 283/300
 - 24s - loss: 3.5696e-04 - val_loss: 3.4973e-04
 - val_f1: 0.9998
Epoch 284/300
 - 24s - loss: 3.5174e-04 - val_loss: 4.7923e-04
 - val_f1: 0.9997
Epoch 285/300
 - 24s - loss: 3.5721e-04 - val_loss: 3.6672e-04
 - val_f1: 0.9998
Epoch 286/300
 - 24s - loss: 3.6517e-04 - val_loss: 3.6568e-04
 - val_f1: 0.9998
Epoch 287/300
 - 24s - loss: 3.4691e-04 - val_loss: 3.5146e-04
 - val_f1: 0.9998
Epoch 288/300
 - 24s - loss: 3.5725e-04 - val_loss: 3.4845e-04
 - val_f1: 0.9998
Epoch 289/300
 - 24s - loss: 3.4832e-04 - val_loss: 3.5747e-04
2019-12-30 03:47:31,610 [INFO] WeightRestorer::on_train_end(): restoring best weights
2019-12-30 03:48:38,963 [INFO] Last epoch loss evaluation: train_loss = 0.000216, val_loss = 0.000338
2019-12-30 03:48:38,977 [INFO] Training complete. time_to_train = 13733.22 sec, 228.89 min
2019-12-30 03:48:38,981 [INFO] Model saved to results_selected_models/selected_kdd99_dbn_shallow_rep5/best_model.pickle
2019-12-30 03:48:38,985 [INFO] Training history saved to: results_selected_models/selected_kdd99_dbn_shallow_rep5/training_error_history.csv
2019-12-30 03:48:39,168 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep5/training_error_history.png
2019-12-30 03:48:39,329 [INFO] Plot saved to: results_selected_models/selected_kdd99_dbn_shallow_rep5/training_f1_history.png
2019-12-30 03:48:39,329 [INFO] Making predictions on training, validation, testing data
2019-12-30 03:50:13,237 [INFO] Evaluating predictions (results)
2019-12-30 03:50:21,923 [INFO] Dataset: Testing. Classification report below
2019-12-30 03:50:21,923 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      0.97      0.99    229853
     normal.       0.73      0.99      0.84     60593
       probe       0.81      0.78      0.80      4166
         r2l       0.92      0.02      0.04     13781
         u2r       0.03      0.01      0.01      2636

    accuracy                           0.92    311029
   macro avg       0.70      0.56      0.54    311029
weighted avg       0.93      0.92      0.90    311029

2019-12-30 03:50:21,923 [INFO] Overall accuracy (micro avg): 0.9233833501056171
2019-12-30 03:50:31,220 [INFO] Average metrics for Testing dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9234         0.9234                       0.9234                0.0192                   0.0766  0.9234
1     Macro avg        0.9694         0.6956                       0.5551                0.0192                   0.4449  0.5352
2  Weighted avg        0.9684         0.9320                       0.9234                0.0196                   0.0766  0.9049
2019-12-30 03:51:01,341 [INFO] Dataset: Validation. Classification report below
2019-12-30 03:51:01,341 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00    776675
     normal.       1.00      1.00      1.00    194556
       probe       1.00      0.99      0.99      8221
         r2l       0.93      0.87      0.90       225
         u2r       0.20      0.20      0.20        10

    accuracy                           1.00    979687
   macro avg       0.82      0.81      0.82    979687
weighted avg       1.00      1.00      1.00    979687

2019-12-30 03:51:01,341 [INFO] Overall accuracy (micro avg): 0.9998336203297584
2019-12-30 03:51:33,849 [INFO] Average metrics for Validation dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9998         0.9998                       0.9998                0.0000                   0.0002  0.9998
1     Macro avg        0.9999         0.8247                       0.8121                0.0001                   0.1879  0.8182
2  Weighted avg        0.9999         0.9998                       0.9998                0.0001                   0.0002  0.9998
2019-12-30 03:53:46,945 [INFO] Dataset: Training. Classification report below
2019-12-30 03:53:46,945 [INFO] 
              precision    recall  f1-score   support

         dos       1.00      1.00      1.00   3106695
     normal.       1.00      1.00      1.00    778225
       probe       1.00      0.99      1.00     32881
         r2l       0.91      0.89      0.90       901
         u2r       0.60      0.60      0.60        42

    accuracy                           1.00   3918744
   macro avg       0.90      0.90      0.90   3918744
weighted avg       1.00      1.00      1.00   3918744

2019-12-30 03:53:46,945 [INFO] Overall accuracy (micro avg): 0.9998509726585866
2019-12-30 03:56:10,635 [INFO] Average metrics for Training dataset below
   average type  avg accuracy  avg precision  avg detection rate (recall)  avg false alarm rate  avg false negative rate  avg f1
0     Micro avg        0.9999         0.9999                       0.9999                0.0000                   0.0001  0.9999
1     Macro avg        0.9999         0.9003                       0.8955                0.0000                   0.1045  0.8979
2  Weighted avg        0.9999         0.9999                       0.9999                0.0001                   0.0001  0.9999
2019-12-30 03:56:10,682 [INFO] Results saved to: results_selected_models/selected_kdd99_dbn_shallow_rep5/selected_kdd99_dbn_shallow_rep5_results.xlsx
2019-12-30 03:56:10,689 [INFO] ================= Finished running experiment no. 5 ================= 

